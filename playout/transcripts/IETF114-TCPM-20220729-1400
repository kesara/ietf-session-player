[
  {
    "startTime": "00:00:13",
    "text": "oh okay uh should we give people a couple of minutes or should we start"
  },
  {
    "startTime": "00:02:35",
    "text": "um okay i guess we can start can you hear me yes yes okay this is tcpm um so if you are not interested in tcp you might have chosen the wrong rule um you have three coaches here my name is michael jackson i'm remote and in front of you are ian's what finish perfect thanks this is the note well i've i think you have seen it a lot of times this week so i won't spend much time on it it applies to this session the logistics the session is being recorded thank you to richard chef and egger for taking notes we have a javascript yoshi will look it the chat and"
  },
  {
    "startTime": "00:04:01",
    "text": "if there are any comments he will make sure that they come to like um one information if you are writing a document and think tcpm is a venue for it which might be interested in it then use tcpm in the name and it's on our radar so then type draft whatever your name is tcpm and then the subject this is the agenda for today we gave you a short update on the working group status then we have four presentations regarding working group documents two of them have at least been for a while on the working group last call two of them will be in the working group class called sometime in the future and we have two presentations um one is uh based on the feedback of the tcpm regarding the tcp yang module by gaian who is presenting what features are needed from a user perspective and we have one non-working good document presentation the tcpa great request an update on that are there any uh should this be changed any comments regarding that so i i have seen the presenters i think um mahesh is still on the train he's heading to a hotel and once the document once the presentation is up he should be in the hotel being online so that should"
  },
  {
    "startTime": "00:06:00",
    "text": "work these are the on the uh on the milestones of the working group the tcpmao test vectors has been published since the last ietf it's rsc 9235 and you might have seen a couple of emails regarding errata so there's one issue which means which is that the tcp checksum is wrong in the example packets when using ipv4 is the network layer this is for 12 packets so they're 12 or 6 in packets i think so that's why you see 16 erratas right now it's up to the 80 to figure out whether to apply them individually or change this stuff to a single errata that's up to up to the 80 whatever is however this is handled best in the in the tools yeah spartan um i i don't want to like have an extended debate about this i think probably the least i mean you've already filed the errata thank you for that but i think the least aggregate work for everyone is if we just have a single if you just do the step of filing a single errata for all of them that doesn't that's general to the document um well let me think i guess we have to we have to tell the rfc editor i'm sorry i'm thinking about this in real time but i guess we have to tell the rc editor to make all the changes so actually you know what you file the 16 i'll just approve them all and that way the rfc end has no ambiguity but they're going to do so i changed my mind in the middle of my comment let's just leave it"
  },
  {
    "startTime": "00:08:00",
    "text": "like it is okay i mean if talk to the rfc editor if they want it in a different way just drop me a note i can do that okay that's a good point i'll i'll ask them i'll ask owls before i get out of here how she wants me to handle it thanks okay um [Music] rfc 793 bis that's the tcp spec uh the base back it's an auth 48 and there have been a lot of comments from the rfc editor which have been addressed recently by wes and so the document is moving forward the tcp yang document is after working group last call in the isg last call a couple of comments have been raised and the authors are working on addressing them we'll get a status update here and also we will have a presentation about uh potential additional features which some users think would be very useful so we can then i think they are maybe suggesting something like another more detailed yang module the next two documents prr and the next one is cubic uh the prr is we have a presentation on that uh it's still in progress uh the cubic one we will also have a presentation on their we are past working group last call but got substantial comments and are still in the uh in the face of discussing them um we will we will get a status update uh of that during the discussion unfortunately the person raising the comments couldn't attend this meeting histor plus i marked it as green i"
  },
  {
    "startTime": "00:10:00",
    "text": "am the document shepherd so i read it i have some editorial formal changes requested once that is done i'll do my shattered write-up and pass it to the ad so that's from a working group perspective it's it's done right now accurate ecn is also uh on the list of drafts which will be presented that's ongoing work um almost ready for working group last call i would say we have generalized ecm which builds on that and tcp edo which has not had lots of changes related to the last meeting yeah um this is all fine but just and you know i realize things have to be done when they're done but if if at all possible it's to if it's possible to prioritize accurate ecn and like maybe deliver it to me well i don't know if if it's at all like if you have two documents in front of you and one of those accurate ecn please process equity cn first because the l4s stuff is already kind of going through so i think it's a little it's a little awkward for this to be you know significantly behind that but you know don't you know so i hope that guidance made sense just if you if if you have any do you have any document which you would are you asking us to delay oh i mean so so like the practical implication of this guidance would be that if like say as a document shepard you had two documents and one of them was accurate ecn that you would work work on the shepherd write up for accurate ecn first this this dilemma may not arise like you may just have a document in front of you and then accurate dcn is the only thing on your plate and um you know obviously accuracy it"
  },
  {
    "startTime": "00:12:00",
    "text": "has to be done first and it's not done we haven't done the last call but to the extent that you have you know process gates and something is blocking accurate ecn like i would i would encourage you to i don't think anything is blocking you accurately so i think the the thing we are working on is uh basically is cubic yeah [Music] so so i don't see anything being blocked so we can we can start working the glass call of accurate ecm whenever we think it's it's ready we are not waiting for anything and bob is coming and telling us that it's ready um yeah this is bob briscoe yes that's true um i just wanted to ask whether we're going to get a working group last call on an attempt at it on generalized ecm as well because that's part of the same thing so like rule number one is it is ready and um i'm not saying like can't stop all work so we all just sit here and focus on ecn but to the extent that there's a process thing where you're doing one one working last call at a time or one separate write up at a time or whatever if there's an ec and doc in the queue it would be nice if those were given priority does that make sense okay okay thanks any other comments regarding these issues or any other working group related issues if that's not the case then i would suggest we move on to um to the first presentation we have 15 minutes spare from our agenda and if there is for any of the"
  },
  {
    "startTime": "00:14:01",
    "text": "the the issues we have discussed fruitful discussion we are willing to run over the time limit in in a certain way but um still trying to make sure that all presentations can be happened um so then i would say vidi video you hear me yes we do are you running the slides from your computer i'm trying to ask to screen share [Music] you don't need to screen share you can just do the job sorry sorry yeah the document is uploaded can everybody see the yes slides thank you perfect um so uh this is um update on revised cubic um and we are you know aiming to publish it as a proposed standard um so there are some issues that were raised by markup and um [Music] i've been exchanging emails with him regarding some of the issues that i couldn't really um figure out from the mailing list and i'll talk about it in a little bit issue one is um about the tcp friendly model and it seems like marco said that the tcp friendly model used by cubic is not correct and he pointed to a paper i think wrote by bob um so maybe we will take this"
  },
  {
    "startTime": "00:16:01",
    "text": "after i present this and ask for bob's input on this issue that marco has raised the second issue is changing beta from 0.7 to 0.5 it is an interesting thing i i do i have spoken to many other folks in parts who participate in tcpm and it seems like you know the 0.7 to 0.5 is kind of like related to the doubling in the slow start and when you double it and you see a loss you have it you kind of reach the um basically you you get one x times the condition window which still means the queues are going to be full even if there won't be a second round of loss so um it's not the best but it still avoids probably a second round of loss having said that um i have also spoken about this to a lot of folks and and the authors and my and in my personal opinion is that changing this at this point is not something we think is the right thing to do because there is just literally no deployment with 0.5 not in linux not in apple not in any stack quick stack that uses cubic and i suppose free psd as well as microsoft if anybody has or has been using 0.5 please let us know but this is something i think we cannot change at this point"
  },
  {
    "startTime": "00:18:02",
    "text": "um then there was issue number three which has been resolved by neil this issue was about um basically you know it's just a bug um where we were um initially we were saying if the congestion window is over w max then set alpha cubic to one and there was a bug here which where it should rather say and the conduction window is higher than the prior condition window so neil has fixed the issue thank you neo for that and i think he also said this issue was fixed in linux issue number six was about the implementations that still use congestion window directly during a condition event to do the reduction and there's a pr open for this um [Music] i think uh there is just a small edit left in this one as mark who sent an email about it yesterday but i think this is something we can resolve um so as i was saying uh i did email him to ask what are issue number four and five and he replied um a day ago so i have not covered that but i think the issue number four if i understand it correctly um he mentioned that 0.5 should also be used when we are in congestion avoidance and not just after slow start um i have my opinion on that but i would like to hear more from the folks here have any opinion about uh how does changing 0.705 impact the congestion avoidance"
  },
  {
    "startTime": "00:20:02",
    "text": "um last slide um there are open issues and pull requests actually there are no open issues on github but there are open issues on mailing last but there are pull requests and github so if you are interested in reviewing them please go ahead we're trying to convert as soon as possible so please help us to review the pull request and march into the draft there is support for publication um sps on mailing list as well as on in the last meeting um and then for issue two um i just noted here it's it's not um it can be considered for future but not now that's what that's what we think um that's all i have but we can we can go through the queue richard so richard just an observation so i believe uh none of the current implementations of cubic are pure um just look at just implementing cubic as it is in this draft so for the slow start it will typically always have some kind of high start or more advanced functionality there if perhaps the notable exception of freebsd but their cubic is not the default method so maybe it would be worthwhile so i would want to say that i agree with your statement here that it would not be advisable to change the recommended beta value at this stage however perhaps make a note in the document that a pure slow start as you know in the in the past is maybe not the best uh ideal situation to determine when to stop slowstar when running kubic thank you okay thank you richard and that's covered in the document"
  },
  {
    "startTime": "00:22:04",
    "text": "all right bob briscoe i think if you are going to mention anything about 0.5 in the document and i don't know whether that is needed given the way richard said that but if you are i think um there's also potential problems with 0.5 in that you then get more queue variation so you get more delay variation and so you know that's that's obviously something as you say has not been measured and if it was i think you you'd find things were worse thank you bob uh you see from the floor this is my individual command for each one and each one is kind of overshooting issues rostered but uh i think you know this is the issue for roster not the security cubic if we use cubic it's more visible compared to rena but even we know we have overshooting issues so i think the problem should be fixed in slow start not a cubic which all we can do in cubic is just tuning but at this point i'm not sure if we need to do that uh putting my chair hat on uh if folks could try to add themselves to the cue uh even if you're in person uh that'd be great thanks any more comments on the chat um rodney is asking whether you can run high start plus for this cubic um yes people are running that already it's also mentioned in the draft yep uh stuart cheshire from apple so my quick comment is this is largely documenting"
  },
  {
    "startTime": "00:24:00",
    "text": "what is incredibly prevalent on the internet today so if somebody wanted to propose a cubic version 2 with a different beta parameter that's fine as a proposal that the itf would discuss but that is really not the purpose of this and um this is reflecting the reality as several people have said the reality has had the benefit good or bad of lots and lots of testing this proposed alternative uh would take years of study to get to the same level of understanding about how it behaves at the large scale okay um any more comment and then um sir rodney asked on the chat does that solve the alpha issue of issue one i don't know if folks understand the issue one um yeah sorry so the issue one is a little bit complicated if you read on the mailing list it might provide some insight but it's really hard to explain it um in in short time yeah for each one is our model and so i have some you know mark and i have been a discussion and then um i i have some comment and mike mark has some comment and then we exchange a lot of comment each other then um right now i have some common argument his comment but for babies come to argument contrary i will have a counter argument i've contacted me to comment argument so the conclusion is this is not the easy issue that's a conclusion from my from this point and that means in order to settle down"
  },
  {
    "startTime": "00:26:01",
    "text": "this issue we need more detail analysis otherwise we cannot settle down discussion but at this point i don't know if we should you know wait for the conclusion of the discussion may take years for detailed analysis and if our purpose is you know like uh publishing the cubic draft in 2025 this is a perfect version of tubing then we can wait but uh this is i don't know this is what we want basically um so if that's just says no if we want to make a cute version too it's totally fine we should do it but not this draft i think that's i think that's the you know general consensus of the working group uh we have you know analyze the consensus in the previous meeting and then we see sorry the concerns that that we are going to publish this draft as a proposed standard and i don't see any you know big opposition to change current situation from my point of view and the one thing i want to emphasize is the cubic draft is not a threat for the internet if we deploy cubic there is no congestion crap happen nobody says that so what we are arguing is if we compare renault and the cubic and then cubic might be aggressive and then some people say it's not true aggressive it's maybe really aggressive but some people say it's drastically aggressive but this is you know under discussion we don't see any conclusion yet but in order to see the conclusion we need more analysis not the kind of situation and then at this point um does people want to wait for the data analysis of the result what we want to publish and then let's discuss about the qb version too which"
  },
  {
    "startTime": "00:28:02",
    "text": "discussion in my understanding and if there is if people any comment on this one i would like to hear it if there is no strong opinion i think i would like to proceed it and i just want to add i just want to add to what yoshi said about doing these analysis these are more research thing at this point and not something that would get to the standards or ietf organization before folks do research on it so that's a lot of time corey hello yeah i am going to say again what i said last time of the night i don't like this position i think we should have done respect differently this has been deployed it's the one we're using i think we should publish this as a ps i think we should note down this important discussion we're having now as part of that ps and we should keep progressing i don't think we should stop and start evaluating something different to what's actually being deployed marching martin do google no hats to be clear we're talking about the 0.5 thing on whether we want to see more data there before we move forward or did i misunderstand your statement yoshi which issue do is are we debating more more study of um one thing is uh issue one uh cubic uh tcp friendly model and second one is uh beta for rate zero point zero point seven to zero point five uh after three step that's another the two things okay"
  },
  {
    "startTime": "00:30:02",
    "text": "um well all right well with issue one i think um the case was made that was too complicated to discuss in person um and i've not read the email so i will i don't know issue two like i i think i'm gonna concur with the other people that 0.7 is what we deployed and um 0.5 is very researchy and i think um like opening a research topic is not appropriate for this effort yeah thanks thank you so um my position as an individual is um we should spend some time on discussing the issues because uh if it's if it's a mistake in the specification we can fix it as the one new fixed um if we have something like the dot zero versus dot five i would be happy with documenting that people are now using um 5.7 and give a short description why there was a discussion that dot five might be appropriate or the better value or whatever but it is about documenting what's now being used whether that is related to a mistake or not doesn't matter richard [Music] i believe we should be documenting in this draft what has been deployed where we have a lot of uh experience already we have known that we haven't corrupted or collapsed the entire internet and going at this stage to 0.5 and holding"
  },
  {
    "startTime": "00:32:01",
    "text": "this document for an extended period of time then quite frankly nobody will actually change the beta parameter i don't know how what value that would really bring stuart trasher from apple um uh i'm kind of repeating my previous comments but uh this conversation sounds very strange to me taking a step back it is widely been observed that cubic probably the most dominant congestion control in use on the internet doesn't have an rfc specifying it and that's a gap we need to fix if we choose to write an rfc specifying some other fictional protocol that no one uses we've totally failed in that first goal one of the goals is document what is whether we liked or not the dominant congestion control for the last decade let's write it down okay um i i just want to switch to issue one i think issue is stunned from my point of view um all i will say is that the um model i wrote up um was uh for tailed well for tail drop and aqm and i couldn't acrom is more difficult because it depends on which one it is um and for the aqm model um results we showed yesterday comparing prague against cubic and prague against reno gave exactly the same results in which over a range of link rates and round"
  },
  {
    "startTime": "00:34:01",
    "text": "so you know i can't believe that no one else has done results like that but we have results as of now that show that reno in its tcp friendly mode with an aqm is um identical to cubic within the ability of the human eye to see differences in graphs so so yes that's true and then bob presented that with those results yesterday if somebody wants to look at it those are available on the iccrg slides about this um 0.7 to 0.5 i want to reply to michael about about whether it was a mistake i don't think there's pros and cons to things uh probably in slow start it is a little bit um maybe takes two rounds to reduce the uh to basically get below the um you know the basically avoid second loss um it's it's for that that's the con and i i think um probably in slow start there is no pro but i have to think thoroughly uh but in congestion avoidance it's the queueing delay variation is lower when you use 0.7 because your reduction is smaller that means you were you need you need don't need as deep buffers as new reno need and perhaps it also makes sense for slow start because if you have less deeper buffer then this slow start will also kind of have low delay variation so correct me if i'm wrong but it's not it's just a mystic it's it's about pros and cons and we can't just look at just look at one side to make a decision"
  },
  {
    "startTime": "00:36:02",
    "text": "as i said this is not going to be decided right away it needs some research thank you uh yeah hi can you hear me yes okay great yeah i just had a a few comments to follow up on a few of the things said recently um i think there was a statement made that probably no one would change the beta value in practice um i i would tend to disagree with that i think there are definite issues with the 0.7 versus 0.5 and i think in the future um i could see for example linux deploying something different um you know after appropriate research but i agree with the consensus in the room that for this document we should document what's deployed already rather than embarking on a research expedition before publishing this um in terms of bob's remark about the tests recently showing reno and cubic look the same if i recall correctly those tests were reno by itself and cubic by itself but i don't think we would expect that to show the issue one i think issue one is about the interaction between reno and cubic interacting in the same queue where the difference is basically the cubic increases at sea wind every other round trip time and is therefore um you know potentially less likely to see uh packet loss than reno is when sharing the same queue so i think we might need more more testing really to to understand issue one more deeply but again i think that's something that should be put off to the future we should just document what cubic does now um and then i do another question earlier was do we"
  },
  {
    "startTime": "00:38:01",
    "text": "what about this 0.7 versus 0.5 in congestion avoidance and i think as i think as stated on the email list i think there is a potential concern with that 0.7 versus 0.5 distinction and congestion avoidance as well because cubic can increase its congestion window at up to 1.5 x per round trip time and so if it gets to that rate of increase then 0.7 is not enough to pull the sea wind back down to a level that will actually fit in the network so i think there is a issue there as well again worth being making a long-term research priority and not something in this document um uh thanks a lot i just wanted to say that that the word mistake i was choosing was not i mean i wanted to my point was please document what is out there and in the case there is a discussion about whether anything else is better or not or this kind of stuff we might want to document it but we don't want to discuss this for years to figure out what's what is what is better so it's about documenting what is out there martin it was a comeback on what neil said so yeah um yeah so bob briscoe yeah neil there were results of um prague versus cubic and pride versus reno in the same scenario so you could see compare how reno fights a different congestion control and how cubic does as well in an aqm um and they're also cubic with ecn versus cubic without and cubic versus reno and so on so it wasn't just one flow on its own uh martin do google again no hats um i would like to zoom out a little bit because i think the basic tension here is between documenting what is actually out there"
  },
  {
    "startTime": "00:40:01",
    "text": "and like you know because we sort of change control this document um maybe making some fixes and correcting you know bugs so-called bugs and what what is how it is implemented and i think the right way to think about this is that we have a bunch of cubic implementers in the room and i think if in relatively short order we able to reach the rough consensus that like we really should do this with cubic and you know we will probably go back and do this in our implementations that it would be appropriate to put that in the document um and make maybe make a note that some implementations might not do this because you know the previous consensus was x and that's fine um i'm not suggesting we start research projects in this area that that could be a different document but like if everyone says oh this number you know was four but it actually should be five and that was just a dumb thing it's a bug and we all sort of agree with that then we can absolutely make changes to what is deployed out there um i hope that's helpful but i think that's the right principle to apply to these sort of tensions thanks this is yoshi from my personal opinion and yeah i basically i agree to describing the issues but uh what i'm wondering is if we you know describe the detail of the issuance and then uh i'm afraid that document is getting bigger and bigger and complex so maybe i'm thinking about you know we can write about some simple no simple information document describe this documentation and then and motivate people to do some more experiment that might be you know from my point of view might be preferable to describe this specific issue specifically detail that's what i'm thinking"
  },
  {
    "startTime": "00:42:02",
    "text": "thank you thanks for the discussion um [Music] please continue discussing this on the mailing list and get the issues i just like to make sure that our current consensus is published this document has proposed standard and then there is no holding back at this point if you have any objection of it this is a good chance to speak up okay no one does this right now okay thank you um then i would suggest we move on to u-turn regarding prl vidi can you undo the presentation can you will you present will you run the slides your channel uh sorry i thought will you run your slides or should uh could you run the slide thank you i can try to do that thanks okay um i'm here to present the second revision of the rfc 6937 this um please next slide so what is rc 6937 is to remind people is the prr proportional rate reduction um for tcp um congestion control specifically during fast recovery basically it decides what the sea would and how much how fast to send uh during the fast recovery so it's a kind of mini"
  },
  {
    "startTime": "00:44:01",
    "text": "congestion control uh well it's mini it's actually can be used very very often when a connection is experiencing very frequent losses it was published in 2013 as an experimental and only implement by linux at that time uh without rock and pop um so it uses the previous rc 3517 the conservative stack based recovery at that time so over nine years we have done some large experiments uh through real deployments and revised the algorithm several times and it's now default in several stacks here on linux esd netflix rack stack and windows um and i want to emphasize one thing is that this sort of uh fast recovery congestion control uh is actually the default no matter what transition control module you use in linux except bbr but bbr has a lot of this shirt sort of um principle or algorithm like rc 6937 as well so i think uh two a year ago uh i think our group decided that this should move to standard now given the large implementation expand pose and the experience that we have next slide please so let's talk about the most important improvement of uh the original algorithm uh that is when the in-flight drops below ss stretch"
  },
  {
    "startTime": "00:46:01",
    "text": "right so for example if your um ceiling was 20 and you use reno and your ssres the ring congestion control is lower to 10 but your in flight has dropped to say three or two like below that 10 number uh this is when the original algorithm asks you to hand pick two different algorithms one is more aggressive uh the other is more conservative but it comes with pros and cons so let's look at that the aggressive version is you during that time you slow start right since your c1 is below excess stretch um obvious upside is that it's a lock and recovery uh because it's slow starting uh the downside is that if during this loss fast recovery the buffer remains very fall um it's not just a single burst drop um or you are going through a policer which runs out of tokens that's why it's essentially dropping any excess rate that you send it through that policer then this could result in terrible uh losses because literally you are pouring gas to fire um so it will be like keep repeating shelling sense trying to ramp up at twice the the speed that the rink is draining and those just keep getting lost uh very easily if you don't have rack that results in uh repeated timeout because you run out of any ad clocking and but on the other side if you pick the conservative one um basically it's a strict packet conservation when you get a packet sacked you send one more into it um obvious downside linear recovery time and packet losses and round trips for"
  },
  {
    "startTime": "00:48:01",
    "text": "large congestion window um this is terrible um but the upside is that since you are just sending exactly as the link draining way of your connection you are less subject to further losses in this case so the improvement really is to dynamically pick this based on the situation uh that what the next act or the the most recent act indicates by default we want to be conservative uh but if the last act indicates that hey the repair is in good progress meaning that the same una is advancing uh that means your last retransmit has been delivered successfully right and more importantly since then una is advancing that means receiver application is making progress uh as well that he can reach more um and also this act does not further indicate packet losses i mean that thing's looking good making progress and there's no further losses then we'll do slow start and this has been shown that this simple technique is very useful to make it dynamic next slide please um another smaller issue is that the original one doesn't really define nang sac case um what do you really do so here we apply some very simple technique that was actually implemented but just didn't get documented uh which is if the act is a due back right without fact all you get is due back and you simply just assume that you know one packet has been acknowledged or delivered of course this comes with that famous caveat that neo uh found years ago that hey"
  },
  {
    "startTime": "00:50:01",
    "text": "what if i just send you back every bite i receive so here we add some more protection meaning that we assume that you cannot act more than whatever that has been um that was in flight right uh as a sort of protection to this uh attack uh to some degree um so this accounting change will allow downsack to also use pr very easily and doesn't really require any extra state next slide please other minor issue uh the original um rc does not trying to force fast retransmit uh upon entering the recovery uh for example in the original algorithm that you have a sencondstay variable to decide how many packets you are allowed to send um for the given act that you just processed and it's possible it's zero because you want to make sure it's proportionally the rate um is according to the new asset stretch whatever the sort of guiding congestion control says that what what the new window should be this has an obvious downside is that you could potentially lost ad clock uh because you don't know if there's gonna be more act coming right uh what if there's only one packet that survived this uh stone um so here we added this well for the fast retransmit only once during recovery and that fast return is also accounted in the out delivery package so the algorithm just make a little bit tweak uh but fourth one out to keep the ad clock uh going this was originally implemented by linux it just didn't get documented in the rc um so we put it in"
  },
  {
    "startTime": "00:52:01",
    "text": "there um another one is like the original obviously didn't even define how do you calculate the seaweed and here we define it like it's simply the in flight or the pipe plus the cent state variable um so that with this ceiling calculation you would send exactly the same time number of packets out to make it more clear next slide please other minor edits we also recommend that you should use rack tlp so that remember we talked about we want to make the algorithm more dynamic and we want to say hey does this act indicate further losses um that usually means is this some fast returns but also get lost again uh in that you do need the rack plp to detect that properly we use a recommended because there could be other techniques to detect that rack top is only one better detection algorithm and remove some deprecated way having text uh and the experiment section since now the extreme have been concluded um and update the examples to reflect the new algorithm uh we also noticed that linux had a bug that was reported by bob thank you bob um about the original implementation so we also send a linux patch to fix that um so that's all for my presentation uh i hope that um we can uh maybe discuss if we should move to sort of conclude this uh this revision so that we can uh turn the experimental rc into standard okay thank you"
  },
  {
    "startTime": "00:54:00",
    "text": "thank you for the presentation any comments yashi hello um so i think i sent some kind of review comment on the mailing list a couple of months ago and it seems the new version seems to be under some of my comment but uh if you could respond to my review email then this one this point you guys updated or this coin you know it's not necessary to update and so on if you could do that that would be very helpful for me uh sure i think i went through all your comments and i believe i have addressed all of them but i'll reply it explicitly on to your email to show where which part i change in the draft yeah richard uh so this is richard i just wanted to say that i'm very happy that uh this uh now finally seems to be progressing again um i would uh want this uh to become uh uh going through a working group last call quite rather quickly having implemented the pr on the on the old draft and i would like to improve the especially the heuristics but would want also to have the proper rfc at the time so that it can be made upstream right thanks i think gauri left the queue hopefully intentionally any other comments then thank you and follow up on the email with yoshi thank you okay um i think the next"
  },
  {
    "startTime": "00:56:00",
    "text": "speaker is bob bob are you running your slides he wants you to run the slides since you probably didn't hear that thank you i didn't hear that oh yeah um next slide please michael right a very quick recap accurate ecn is a change to the tcpy protocol to deal with the problem that the existing ecn feedback is only for congestion controls that need only one feedback per round whether or not there's more than more congestion than that um and it involves two pieces a um small three bit field is essential and the supplementary option um and having this feedback allow gives you the fine grained control that allows you to reduce delay a lot more um we're using nl4s but it's got other uses as well thank you next so um since the last cycle of the i or within the last cycle of the itf it's been two updates um links there on the um if you go to the slide for the two diffs and um also an english summary of the diffs on the list um in response to requests from gory from ilpo um from again or a follow until the change to oppo and"
  },
  {
    "startTime": "00:58:01",
    "text": "um uh finally some work that was happening earlier in the week on the interop we found uh we hadn't properly documented the experimental ids the tcp options and two different implementers had guessed two different numbers so um we um you'll see we've sorted that next slide so firstly um gary wasn't happy with the section on act filtering which updated rsd 3449 which is as the little um asterisk says at the bottom tcp performance implications of network path asymmetry and it particularly updated the act filtering um part of that rfc and gauri pointed out and he was right that that rfc referred to 3168 and so because accurate ecn says it is going to update 3168 that rfc will then apply to accurate ecn as well so we don't need to specifically update it it just automatically happens by updating rfc 3168 so we change things around um and we added a bit more technical detail on how to do it um how a filtering node might handle accurate ecn feedback um if it was trying to improve improve performance which is the whole point of act filtering nodes okay um any questions on that move on so the second change after el po had implemented this he said the um the implementation for sending the tcp option the accurate ecm tcp option was um much simpler than the receiving side of it and so the the previous recommendation in the draft was um that you uh you're recommended to at"
  },
  {
    "startTime": "01:00:01",
    "text": "least do the receiving side even if you don't do the sending side obviously i recommend it to do both but if you're if you're trying to start out um do the receiving side first and so we switch that to be do the sending side first because that's the easier side and that means that um anyone that does do the receiving side if they're getting um this option arriving at them then they sort of can unilaterally get it working by just implementing the the receiver side this means the receiving of the option not the risk the data receiver because it's the the option is feedback so it's the opposite half connection to the to the data direction okay um and this this um cycle in draft 20 we just added a little more strength to the recommendation as to why it's important to um to implement this and you'll see the green text there says that i won't read it out um any comments on that um would have been on the list um it's had a i think a week so um there's one little point there that um because ilpo has implemented both send and receive logic in linux if that does go through to the main line then most linux servers will be able to handle both sender and receiver which is another argument for if you're a client receiver and you don't really want to bother implementing this at least if you do the sending side then um the server will be getting feedback on on the downstream at least okay next right um this is the point about us um omitting to register the experiment"
  },
  {
    "startTime": "01:02:00",
    "text": "mental ids that we've been using for this tcp option in implementations um retrospectively registered them or richard did earlier this week they're now um on when as of wednesday evening i think they're on the iona registry um as shown there but then what we want to do now is go for an early um registration no early assignment i think it's called of of the actual ids that we want to use um while this is in in parallel to this going through the working group last call process and and so on um so that the implementations can start um using the real thing next and the next is the next step slide we have a um one early security error um review that ends up showing has issues but um it was all resolved and the the author of that review has agreed it's it would be almost ready if he put that stages in again so i believe we're ready for working group last call i don't think there's anything else um i've seen on the list anyone wanting anything done and well the authors are all happy that everything is done that should be done um so um i don't know whether we're gonna do that here now i just wanted to also add the other two points there we're gonna um i don't know whether we need or the chairs need a feel from the room whether we should go for an early assignment as well and um finally whether generalized ecn um i mean that's that's been ready for working group last call for some time"
  },
  {
    "startTime": "01:04:01",
    "text": "whether we go for actually doing that it has a dependency on accurate ecm uh martin duke google uh yeah like early allocation i think is a good idea because if if it turns out that whatever we allocate um gets eaten in the internet that would be good to know before we published before before it goes to the rcn um and i don't know if their magic like unallocated options that would make it through the internet or not um but you know who knows uh i did have a question i mean you said you implemented for linux and i'm wondering if you reached out to the linux kernel maintainers about accepting any of this in particular at least the receive side well the the the reason this issue came up is neil was testing his linux implementation with uh interrupt with richard's freebsd implementation at the interop earlier in the week so yes neil is the guy that but but he's saying but he's not a kernel maintainer like the actual like linux mainline it would be great if the sending of the option was in the kernel because then you know commodity linux servers would do the right thing well i mean with um ilpo's original um patches he produced a patch set for the net dev um community and um basically it was it was all ready there weren't any problems but waiting for the iatf to do the rfc um and um i mean neil is one of the people i mean the lens community tends to work on trust you know and neil is one of the people that would be a name against that i think um i'm not okay presuming that neil will say it's okay or anything but you know okay neil but you know all right well alex neil that's going some other time then thanks um quick question is the linux community waiting for the"
  },
  {
    "startTime": "01:06:02",
    "text": "um for the rfc or waiting for the option kind assignments you'd have to ask them sorry but when we originally put it in it was waiting for the itf approval it wasn't clear whether like if it got through working group last call or if it got approved by the aisg or whether it would actually have to you know be a published rfc um i don't know at what point they would be happy but um we can find that out okay neutral yeah a couple things i think we definitely should get a real auction id um uh as early as possible and don't use the experimental id uh in implementation uh this is based on a a real my my own experience with fast open because um if you have those then you need some way to upgrade on the id right when there is a server that only talks the experiment and um the other one that talks post um so it's a pin um pen another one is for the generalized ecn a quick comment is that is it possible to make that generalized easiest generalized ecn also good for the bctcp cases because we don't expect people that use dc-tcp ecm will hop on this accurate ecn anytime soon right because there's a real um implementation blog right so that's my question yeah that's a good point we can we can i have to think how we would word that but um because we have to be careful that we don't sort of endorse using dc tcp over the internet somehow but well well"
  },
  {
    "startTime": "01:08:02",
    "text": "well um we should be able to do that yeah so this is richard um just to the comment around generalized acn for data center tcp i have a private patch to do this exactly because of the same reason that aqm that is compatible with l4s would mostly be compatible uh with database and the tcp as well and therefore generalized ecn and data center tcp would in my opinion be a natural fit however we need to progress on that on that draft in order for this actual implementations to progress thanks do you want to no okay so um i just wanted to add that the dc-tcp implementation in linux already does what um generalized ecm says it just sets ect on all packets it doesn't um not set it on sins and acts and things like that i think i was just asking for that to be endorsed by the rfc okay i'm not aware of that but they we can confront our offline since it's just implementation issues yeah could i ask martin what the procedure of early assignment is i mean how does it work who decides which part um i think i have to like give my approval but um i think you could just send an email to ayanna you will approve that and then ayanna will execute that or is ayanna discussing that or he is it the secretary of state ryana that you do early allocations first"
  },
  {
    "startTime": "01:10:01",
    "text": "who's the first contact yeah just call just email ayanna and cc me and uh things will move forward and we'll figure it out from there do you have the answer to this um i'm being an australian so i started the process earlier on an information to get closer to the mind sorry i'm richard i'm from austria so i've started this process on an informal basis um jana is aware that this is going uh going on and quite frankly the process as far as i understood is that the formal request has to come from the chairs of this group after the group has agreed the ad has to has to basically sign it off and as soon as that is gone just send the email with those approvals to iana and they will do it yeah i would just send them an email cc me and i'll like just reply i approve and we'll be good to go okay we'll discuss this with another choice well one question bob so i think the draft is most ready for working group plus to go from my point of view but i sometimes you know exchange email with you and gory about some you know editorial things i i just would like to check we've already settled down and you can you think you're ready for working with rascal sorry did you say that uh are you saying that there's some emails we've missed or yeah i think so my i'd like to confirm the discussion is still going on or it's finished i think discussion is finished but if you point me to anything that i missed or anything then no i don't think i just tried to confirm i can confirm that now and i can confirm it by email as well if you want yeah yeah and then another thing listen you want to wait for earlier assignments no i think the two can go in parallel because um you know i don't think either needs to depend on the other"
  },
  {
    "startTime": "01:12:12",
    "text": "richard do you want to be in the queue or did you forgot to exit okay you tune do you have something to say okay could i release the mic uh button um yeah i just want to uh double check that um we accurate ecn um is now have a working implementation that can show it works with gro and tso without any issues um like if we just run it now say inside they are centers right the tso gro will all work fine no fine prints yeah i believe it doesn't i believe it this is bob sorry i believe it doesn't i believe it should but um i you know yes obviously test it yourself is the um is the answer to that question um but yeah the code should work like that yep okay so that has been my most uh concern of accuracy yeah but and if that's clear then i'm happy to support that corey very fairness i'm just responding that i think bob solved the issues we discussed i don't have more issues on that one thank you mia"
  },
  {
    "startTime": "01:14:01",
    "text": "um yeah i just wanted to follow up on uh youtube's questions about uh offload support i guess the the one um big question i remember was this question of uh whether various network devices in their tso um transmission offload facilities might might do the wrong thing with the ace um bits since they don't know that they're trying to be used as ace bits and might interpret them as other tcp flag bits is there anyone who can sort of quickly summarize where we are with this this question of nick compatibility within the ace field um i can i can summarize that um the when tso and gso or gso is done in the linux stack that's all handled with hardware um we haven't had those discussions yet we sort of need um the community that um uh like yourselves so that we can start those discussions any other questions so the early assignment stuff we'll discuss between the chairs and then um send the appropriate mail thank you so now it becomes interesting um this is my hash able to give a presentation now so he is not on site he is in the train"
  },
  {
    "startTime": "01:16:02",
    "text": "or maybe not anymore so he dropped me a note that he might be just out of the train heading to the hotel are you there oh yeah do you want you do you want to run your slides it's very hard to hear you can you say something yeah i think you're muted no he's not muted i can hear him but it's very very silent now he's so quiet that i can't hear him at all well i can but so he's not muted completely but yeah that's not better okay can you hear me now yes so i think you can start no that's worse again whenever you use your earphones we can even heal a bit of the music"
  },
  {
    "startTime": "01:18:13",
    "text": "okay i don't know if this is any better yes it is just start presenting okay all right sorry for that snafu um i'm in a public place so do not mind the noise behind me i'm here to give an update on the tcp yang model so we started the scope of the of this yang model for tcp with a fairly narrow scope of providing basic statistics which by definition were optional to implement a list of tcp connections and a newly added list of listeners for uh that was added in the recent version that definition of that listener list was established by what is existing in tcp map uh the third item there is the modifications to support tcpao and md5 previously we were trying to implement another by not augmenting the keychain model and that didn't go down very well so the recent changes now add the augmentation of the keychain model to support tcpao and md5 the final edition was the import of keep a live groupings from netcom tcp client server draft and this is mostly for alignment between the two documents"
  },
  {
    "startTime": "01:20:00",
    "text": "the current status of the document is it's in isc evaluation there is a revised id needed currently to address three discusses and several comments that were received and the authors are working on an updated id which will post right after the holidays uh no fundamental extensions of the scope of of the model are planned as as of this time but some minor edits will be required to address all the discus comments now if i can only move to the next slide all right so here's the overview of the isc feedback we have got as i said three discusses and several comments um a lot of them are have been addressed in a working copy that you can see the status on the right side um a lot of the discusses and comments were related to the encoding of any in the tcp listener list and i think that does need some minor changes that we'll be working on the the other was the uh the new edition of to support tcpa 0 and md5 and the corresponding examples that we have in the draft there were some inconsistencies in that example that we have tried to now address and then um some inconsistency in the 2019 language we have also addressed um there is no uh there was a suggestion to remove md5 support which the authors are not planning to because we do have a requirement from the bgp yang model for support of md5"
  },
  {
    "startTime": "01:22:02",
    "text": "anyway the status of all these and the changes is being tracked in the github location link at the bottom of the slide so as soon as the encoding of the any listener list is concerned it's currently encoded as a union or that you see the definition of which you see below and this definition is comes from the tcp myth and i think the question or the discuss comment that we received was how is um the ipv4 address of all zeros or the ipv6 address interpreted by this particular union and we'll um the yang 1.1 language essentially says that if in a union you have two type definitions a you're supposed to parse the types in that particular order so if it's a interprets what it has received as a string it will assign it to a type string but in this case if the type is actually a value of four outputs of all zeroes then it will be assigned the type of inet ip address and we'll try to clarify that in the next version of the draft the final slide as i mentioned the ao configuration examples there were a couple of suggestions on how to make uh the containers for ao and md5 presence containers which we have adopted in the draft it's a minor change doesn't fundamentally change the model in any way what is new and and required edition is that because tcpao supports um"
  },
  {
    "startTime": "01:24:00",
    "text": "aes 128 and the example in the draft did not reflect the fact that the crypto type that a ao supports only 120 aes 128 we needed to add that to the draft so after adding that we had to update the examples to align it with rfc 9235 also i think that's pretty much all i had from an update perspective thank you very much for the comments for the presentation and for arranging that you can make the presentation um the sheer stroke of luck are there any comments i only have one which means um you said you changed the examples are you able to check the examples that they still work or or yeah so as part of the draft we do run it run the example against the model um and we use yang lind to do the verification that the example does correspond to the okay are there any other questions if that's not the case then thank you for the presentation and we this presentation was kind of an foundation to the next one given by um guyan on um what might be missing so"
  },
  {
    "startTime": "01:26:01",
    "text": "are you there are you running the slides locally or should i run them for you okay i understood thank you martin hi my name is hello my name is gion mishra with verizon and i'm i will be presenting uh the next gen tcp yang model a discussion that came up um through the um um hopster review um recently next slide so here's some motivation and some history related to the uh nextgen tcp yang model so during the opsec review of the tcp ganging model that was just discussed um the as a result i we started looking at a possible uh next-gen tcp yang model and would like to get feedback from the tcpm working group as well on this um on on thoughts regarding this uh process and if it's something that's feasible so as a result we discussed the yang motto and what would actually go into it on on the mailing list so yang is about visibility similar to the snmp mib and not remote management uh just some discussion that we've had that the current yang kind of really mirrors the snmp mib and uh from the routing area grouping kind of what we're interested related to the next ntcp management i mean sorry tcp yang model so it's not really necessarily remote management but what we would like to be able to do is observe the tcp parameters"
  },
  {
    "startTime": "01:28:03",
    "text": "um related to the tcp session state and telemetry um either back to a controller or a netcof netcom slash yang just being able to pull our statistics um we would like to see we would like to be able to see everything that could be seen um if you're looking at like a local like an os hook into the kernel just visibility into a tcp parameters related to the connection state next slide so the motivation here on the tcp gang model and reasons why be so i would say the main use case it's really related to bgp bgp has over the years has expanded its scope one of them is related to data centers uh massively scalable data centers and which which uh is bgp only now with rfc 7938 and that's something that a lot of operators are looking towards so kind of really the visibility and the need for stability with bgp and being able to have monitoring capabilities related to bgp is really really important for operators next slide so this is a just a use case that came up uh it's it's it's come up a few times in the idr working group and it's related to internet outages that have that have occurred with the tcp window going into collapsing and having a zero window resulting in a stuck state and i just put in there the mail mailing list archives related to that discussion so in this in this state what ends up happening is you have like a router a on the left that the control plane is congested he's got a send window greater than zero but then he's got a receive window at zero"
  },
  {
    "startTime": "01:30:02",
    "text": "and then router b he's uncongested he's got to send windows 0 but a receive window greater than zero and then the router a he's not able to write to his tcp buffer so even though the router b sends like a log message notification back towards a a is congested and the session ends up staying up so we're not able to reroute traffic and so it which results in a internet outage next slide um the second use case is related to uh compute nodes and a tcp session just being able to monitor statistics uh related to the session state and then windowing and the window scaling and mostly for throughput and application traffic uh i guess server to server or client server i guess response time next slide so i guess the really the big question is that what do we want to add to this next gen tcp yang model so just in summary i just threw in a few just some bullets of what we were thinking one is all the tcp states that are part of the fsm state machine tcp flags in respective states tcp parameters that would be accessible through the local kernel windowing parameters tcp options and optimizations and then um and then this the the c-win tcp uh congestion control so the cc parameters next slide and so um i'd like to get feedback from the tcp working group uh just thoughts related to this thank you um michael did you just say bob i think"
  },
  {
    "startTime": "01:32:01",
    "text": "i read your lips but you're muted i think yep you can read my lips correctly um just just to point out all tcp options is probably um excessive because um probably i don't know how we make a list of those that are actually used but there's a lot that aren't so i understood maybe parsing through because i'm not really you know if i i don't know what the how large the list is but probably parsing the list and see what would be pertinent i guess would make sense because i'm sure if it's a lengthy lengthy probably doesn't make sense every single one but just finding the ones that are pertinent that would make sense uh martin duke google can you go back to the uh use case one sure so um i'm a little confused by example so you have um keep going michael let's it's just which one was it that one okay so in this case like from a to b the both the sender received windows are nonzero so data can be sent and then in in b to a it's um like both sides are deadlocked right right so um like what is the cause of this issue i mean is this just a question where like we just need to wait for an ack from b to get a unclogged yes so what what ended up happening this stage of the router a he's a he's not able to um i guess he's he's the one that kind of has its management plane it's kind of"
  },
  {
    "startTime": "01:34:01",
    "text": "it's hung okay so his uh since the management plan uses tcp as well as bgp using tcp he's not able to uh like to write to the uh i guess the us is i believe it's the uh receive window so he's not able to write to his buffer and so he is not able to uh process i guess anything like if you even if he gets the uh message he had what ends up happening he just doesn't close the session i think that's the thing he's not aware of the other end he thinks everything is still up and he keeps the session like i think the best thing that would happen is if somehow he was able to like close the session or do a tcp reset and then traffic would converge to an alternate path but the session just kind of it ends up just staying in an upstate so that's that's where the i think in like if you it you know like a client server application where you have you know tcp zero window which happens and then the window opens up in this particular case because it's router to router in this for when when that happens that congested state happens it's like the management plane is just completely hung but then the bgp just kind of because the managing plane is hung and it's using tcp um these state of the connection ends up remains remaining active and unfortunately bgp doesn't reroute okay so the problem here is a is hung and b doesn't realize that a is fine okay that's right but like your remedy is to reboot a then i would imagine it is but i think what ends up happening i think with the knock whenever this has happened because the session is up it's hard for the not to realize that it's um it sees routes and everything seems like normal but it's not able to process anything so it takes time so so the issue so i'm guessing that in this scenario a is not like is not reporting yang stuff because it's toast so it's b is so what you're trying to do here is use b to ascertain the state of a by looking"
  },
  {
    "startTime": "01:36:01",
    "text": "at the tcp parameters okay all right that that at least makes sense and just to be clear these are not like commodity tcp implementations these are specific to the routers that are they have their own distinct tcp implementation yes probably yes okay different different vendors i guess or because i'm interesting like if you're just using linux tcp i don't know you can install i mean i doubt they're going to implement the yang and so um there's no market for this if that's if that's the case um yeah i mean i'm a little i'm a little like it seems like you're not like tuning since since by since you stated you were not tuning these parameters right i i do it seems like your actual um option you're just like reset connections reboot stuff right and like i'm wondering if a much simpler like i am dead locked model is much simpler than trying to like have like dozens and dozens of parameters you're specifying and reporting and like having complex logic for what means what um just having looked at this and thought about it for 10 minutes but um thanks i i think i understand your use case better now thank you um regarding this deadlock situation i'm wondering i mean tcp the tcp connection can be up and happy even if you are not able to progress user data so if the application is stuck from from from a tcp point of view that's fine so normally what you do there is application layer heart beating or application layer test messages and then you figure out that your peer application you can't talk to your peer application layer anymore but on the on these points i'm trying to so i i don't know much about yang so that's why i want to figure out what you what you are looking for looking at tcp flags"
  },
  {
    "startTime": "01:38:02",
    "text": "live tracing of which packets are being sent and received and reading that you want where is it state you you want to all tcp parameters that would be accessible with the local os kernel hook this looks like a lot of implementation specific values and i think it's very hard to to to standardize them so my understanding is that you can you can get you can get a snapshot of a state but like continuous monitoring seems to be different that's correct you know as far as the tcp parameters i think as i think someone else had asked that question but i think really maybe the pertinent parameters i don't think we'd probably need all of all of the parameters but i think what's pertinent to the connection state that actually would help us in determining whether a problem i guess for like the knock i guess if if there's a problem and maybe parsing through the parameters and there may be some key parameters that would be helpful i guess i mean do you want to know that time stems have been negotiated sec has been negotiated and window scaling these are the typical tcp options which are negotiated in your case i guess tcpao or tcp md5 also but that's a static thing that's that's something you can query and get a response but i don't see how that helps in the problem you showed jeffrey jeffrey haase juniper networks bgb developer yang no author so"
  },
  {
    "startTime": "01:40:00",
    "text": "you gave me a giant list to try to work through i wish i could have hit them one at a time sorry so uh to guyan's point the stuff that's in here state-wise is all appropriate uh your point about we're not trying to implement t-speed dump on top of yang that does not make sense so being able to look at the tcp flags modeling all those that's not a big deal for the session if you think about most tcp you know stacks you're setting these things as socket options and that's an appropriate thing to see as part of socket state as an example there may be appropriate things like you know if you've seen an expected tcp option on the session you could also record that and basically say so this was the thing that's seen but trying to snapshot live state for flag for each packet is not part of the goal so rolling back to the use case one stuff no with the stuck sessions there's multiple reasons this stuff can happen sometimes you have you know drop packets at inopportune times where each side sort of thinks that's trying to get out of the state and it just never gets there for some reason sometimes you have that due to specific types of network drop sometimes authentication can cause that in certain circumstances but in the vast majority of cases these things are either bugs or other unusual circumstances that the whole issue is this session is wedged the client you know bgp is the example case but this can happen for other things it's sort of stuck waiting to get out of the circumstance and you know if you're not implementing a form of protocol go keep alive or hold timer that expects to get out of the situation because as far as each side can tell you have you know data pending you're waiting to actually move along so the challenge comes you know when you get into these stuck situations how do you troubleshoot them and if you're on the box you're going to sit down type netstat and see what's going on what's needed for operators that are trying to troubleshoot applications like bgp that are used in routers"
  },
  {
    "startTime": "01:42:02",
    "text": "to be able to troubleshoot the situation you know remotely is being able to simply get the status of the session see what's going on and you know there may be opportunities for some level of telemetry for these stuck situations like zero windowing is a common thing you don't want to generate a gang notification or trap out of this sort of thing just like you wouldn't want to do an snmp but it's very appropriate that if you're monitoring these things and you see that a bgp session sort of gotten stuck being able to query you know via netcave you know what is the status of the socket you know it's been zero windowed and if i see that's been that way for you know a minute you can then take action you like resetting the session you know using your new router protocol so there's a lot of options for things that you can do here but most of this is the same type of visibility you'd get via cli and just simply you know putting into the management plane in a generic fashion and uh there's a throwaway comment about you know modern stacks you know we run bsd drive stacks we run linux drive stacks and we layer stuff on top of all that for management so this is not an unusual thing thank you thank you jeff thank you jeff quick question again yes so are you going to propose a new document sorry um so i want to generally reflect uh i think the comments that both jeff and michael provided both as uh author of the bgp yang model and the tcp yang model that i think trying to keep track of state information or at least the live state information doesn't probably doesn't make sense as a replacement for um tcp dump but definitely for conditions just like jeff pointed out about stuck"
  },
  {
    "startTime": "01:44:01",
    "text": "connections and zero window though that certainly can be helpful piece of information that we could add to the model that would be perfect i mean that's really as jeff described that's exactly what we're looking for somehow that we can get an alert you know when that stuck state happens with the zero you know when that zero window happens and being able to you know get a report you know you know flagged i guess to the knock and then being able to you know act on it as soon as the stuck stage like if it's stuck for a period of time then we can act on it and reset the session uh martin duke google again um so like uh you know obviously the bg community bgp community uses yang and so i i'm you know we're doing getting work now for them and i think doing more work for them is fine i just think um i think the principle we're trying to apply to our yang work is to not um not try to do all of tcp because the mib experience was a terrible one and to be very very deliberate in adding stuff to that so like i mean if this work i don't i fundamentally object to this work progressing but i would like to like i would like the the proponents to think hard about what kind of information would be actionable and whether you need like really fine-grained stuff like window sizes or like where like booleans could be used there's or like if there's a bunch of stuff where the answer is reboot the box like just have like a i need to be rebooted indicator or whatever um uh i mean you know i'm off top of my head i'm probably not saying that right but um to not have like try to have a very like small yang model if possible that covers what you really need for this use for these use cases and um that you know"
  },
  {
    "startTime": "01:46:00",
    "text": "that relates to actionable stuff and that will just make this a much more practical thing to get through the process makes make sense jeffrey hans following up i don't disagree with you you want to keep the model as small as reasonable yang has the property that it can be extended especially no proprietary in a very easy manner offering advice to this working group having done lobbying stuff for itf at the moment you have a choice in front of you you can either do enough of the work such that everybody that wants to use the stuff and you'll leave a lot of stuff optional and model it once or risk all the vendors coming out and saying you missed a important thing and every one of them doing a proprietary extension and forking everything so it's a hard walk to do but it's doable thank you thank you jeff all right yoshi how did you did you want to ask a question does anyone have any other questions okay all right thank you okay any comments regarding the young stuff if that's not the case then we are at the last presentation charts okay hello can you hear me yep are you running a slide can you do it i can do it you can do it on your own you have on your upper so below your name the second item from the left yeah you can choose your slides"
  },
  {
    "startTime": "01:48:00",
    "text": "slightly requested so i pressed ask to share yeah okay now i see the slides then you control them yourself okay okay so uh hello everyone my name is carlos gomez i'm going to present the updated version of the draft entitled tcp a great request star option my co-author is john krugrad from the university of cambridge so first of all let's take a look at the motivation for this draft delay tax is a widely used mechanism which is intended to reduce protocol overhead however it may also contribute to suboptimal performance in some cases for example in so-called large congestion window scenarios meaning congestion window size much greater than the mss where saving up to one of every 2x may be insufficient for example when there are performance limitations due to a symmetric path capacity or due when we want to reduce further the computational cost and network load and then there are also so-called small congestion window scenarios that is a congestion window size up to the order of one mss for example in data centers where the bandwidth delay product can be up to the order of one mss in this case the latex will incur a delay much greater than the rtt and also when there are transactional data exchanges or when congestion window decreases then yeah the ability of requesting immediate acts may help avoid idle times or it may allow a faster congestion with their growth so on the status of this draft before the creation of the document there was some related prior discussion in the area of center control of tcp x which appeared to converge to defining a new tcp option serving to purposes the ability of"
  },
  {
    "startTime": "01:50:02",
    "text": "requesting a given act rate and the ability of requesting immediate acts so since the last idf we produced versions zero four and zero five with the address comments received in the last idea but also uh on the mailing list and by the way thanks a lot to everyone for the useful very useful feedback received so now let's go through the update in the last versions of the draft so here on the slide you can see the main format of the option you have the old version which is zero three and also the new format in zero five so there are several things to mention here first is that in previous versions of the draft there was a feature called ignore order however it was not very clear whether this was actually useful we received a significant amount of feedback in this regard so we decided to remove it from the document a second point is that now in in zero five we state that the kind field value is 254 as you may recall the intended status for this document is experimental so we are following rfc 6994 which defines the shared use of experimental tcp options and according to that rfc the kind field can take only two values two five three or two five four so we have chosen the latter and the last common uh for this light is that uh well it was mentioned on the mailing list that the old format having an odd length in some cases the implementations might or implementers might want to add some padding to make the size even so based on that we decided to make the size even by ourselves by extending the"
  },
  {
    "startTime": "01:52:02",
    "text": "size of the option by one byte so this is by increasing the size of the r field which carries the requested upgrade and also adding a few more reserve bits for future purposes so uh regarding the r field as you may recall in version 0.3 of the draft we were considering two different options for encoding the r value the option one was uh using a simple binary encoding where the maximum value of r was 63 then there was option two which was a bit more complex with mantissa an exponent and a possible maximum value of one thousand twenty four so now in zero five uh making use of the additional bits now um we state that the r field carries the binary encoding of the accredit then we also state that r equal to 0 is a special case where we request the sender requests an immediate pack while not modifying the default or steady state acc rate and with this encoding now the maximum value of r is actually 2047 at least in version 0.5 so there has actually been discussion already in the past regarding the maximum value for this parameter the request attack rate are so again in zero five it is 2047. this perhaps is for discussion but well in the past there have been questions on why values greater than 63 would be needed so there have already been some answers given for example jonathan wrote a nice and detailed explanation of why there are some values for r in the range of 100 few hundred or even one thousand which could be even justifiable in"
  },
  {
    "startTime": "01:54:00",
    "text": "current scenarios for example assuming a long rate of one gigabit per second rtt is up to the order of 100 milliseconds but those large values for r would still comply with a sort of rule of thumb of having at least four acts per rtd and then they have also been comments for example by bob or juhamati expressing that it would be nice to make sure that that our option could be useful as well in future scenarios where the expectation is that there will be even greater link rates so uh i don't know if there are any comments on this maximum value of r if not yeah i think there's gory in the queue whoa yeah i'm going to argue that flexibility here isn't a good thing but having one act every 100 packets is still pretty infrequent we've used it with rtp and other protocols it's not a big overhead why would we ever want to go to a thousand even on gigabit links one one every 100 data packets is a very low load in rate or volume okay so yeah i understand for example uh some of the reasons expressed for larger maximum values in that order would be to reduce for example the amount of acts that would need to be processed by the network but also i understand that the concern uh for large values of ours so yeah i guess and i'm wondering how to to achieve a suitable trade-off here"
  },
  {
    "startTime": "01:56:07",
    "text": "hi this is bob briscoe um i've just discovered that a male i thought i'd send i never sent so i'll say it now um obviously i didn't click send and it's sitting in my drafts um i i noticed that the format of this has now become very close to the at congestion control rfc that we already have um which is just basically an 8-bit number and the rules as to when you can send that are very similar so well i don't like to sort of point this out but maybe we've converged on something where you don't need to do anything anymore charles we already have we already have an rfc and we can just use it um and um that gives you eight bits so it's 256. um as your number just just think about it you know i i should have sent this i'm really sorry i should have sent that mail earlier but just see whether there's stuff in that rfc that precludes the use cases you're thinking of and maybe it's an update to the rfc that's needed or whatever okay so i guess if if you can send the message you had prepared with possibly the details i think it will be very helpful probably got some old stuff in it because it was in answer to something from jonathan morton but that was just a side comment so i'll send it i'll press send but i'll put a little note on saying some of this might be out of date thank you okay so yeah bro uh your thing is that just personal opinion if we want to save the options with just even just one byte maybe"
  },
  {
    "startTime": "01:58:01",
    "text": "we can use the previous version and if we need big value and we can utilize an elizabethan bit and then arrogate new formats something like that then maybe we can address your concern okay i see that there's some pressure on one hand to to maybe have uh an even length for the option but then also we want to to keep the format short so yeah let's see if we can find a suitable solution as an individual i at least looking at the tcp options we are using right now they are all they all have an even length so um that's why are we really saving a byte if we have one option with with a knot length that was my point in suggesting if that's not the case then we can just use two because you will you will pet it anyway okay richard so while while we are generally doing padding uh padding is something that we could uh really do away with i would really more like to see an argument made that a larger field length or option length is really valuable and as gorge has pointed out even a value of 100 is already quite excessive at least at this age having having a transport protocol flying without feedback for thousands of a flight of thousands of packets it i can hardly imagine a transport"
  },
  {
    "startTime": "02:00:00",
    "text": "protocol that would you know have a decent decent properties with such a rare feedback on the other hand i mean this is advisory and not a mandatory option so the receiver can use it can delay but it's not that it has to follow that so therefore it's uh it's that's the other thing the other aspect why i don't think that we need really that lengthy option thank you regarding the regarding the option um the concatenation of all tcp options has to be length divisible by four so that's that's the padding i was referring to i by the way i closed the queue since we are at the end of the time and carl says let's start outside jonathan so [Music] there's question about whether [Music] whether the large value of r is harmful and that's why we have the rule of thumb of having 4x per rtt because that gives um sufficiently rapid feedback to suit the network path it's also worth remembering that if a congestion event occurs that will result in immediate feedback regardless of the value of the delayed act timer cards do we have do you want to have uh show more slides or are you basically done well perhaps just one which is super quick then do that because we are running"
  },
  {
    "startTime": "02:02:00",
    "text": "already over time yeah so just mentioning that uh yeah we have running code so this is great news and as michael announced on the mailing list he has been leading the development of a prototype implementation of the draft for freebsd my understanding is that there are some features already supported and it will be completed in the next few months so yes so it's it's basically it was a student's project to get this to get this implemented and there will be some final touches before it can be open sourced any other comments if that's not the case then thank you um [Music] do you want to say last words from philadelphia see you in london see you in london see you in london bye oh you"
  }
]
