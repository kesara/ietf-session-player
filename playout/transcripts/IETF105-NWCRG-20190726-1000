[
  {
    "startTime": "00:00:13",
    "text": "and we need someone to take notes their hands yeah there\u0027s a conflict with something else we were discussing [Music] [Music] [Music] look what you get that better no you\u0027re too young to choke "
  },
  {
    "startTime": "00:03:17",
    "text": "[Music] egle person in fact that comes up okay I think we\u0027re going to start since some people need to leave and it\u0027s Friday so thank you for showing up again this is the coding for efficient network communication research group where we do all kinds of fun things to recover lost packets so again okay so a goal obviously is to foster research in network and application layer coding and to improve network performance and so what we are doing for those of you who historically were not with us we started very much by looking at codes and coding libraries because there was some development that was interesting but we\u0027ve really really fast moved in to protocols to facilitate the use of coding and also more and more moving into real world applications and and work in progress and we know that there\u0027s currently work that may be done in the IETF related to this and obviously the expertise of this group is going to be very important so this is the usual note well I know that there\u0027s going to be another approach to coding later in the presentation and I hope the people Mihiel and company that you have really looked at note well because I know you work for a company so if there\u0027s any IP are related to your presentation please mention it we really have moved I think this group has done it much better than my other group we have moved very much into the github to maintain the list of papers and drafts and related material obviously the Charter is did that attract her like everybody else we have a mailing list that you probably all are all subscribe to our slides are going to be on the github and under data tracker and we\u0027re going to have net echo and actually when we did the you who got to put that when we did the hackathon that was also a slack channel which was interesting for the people who were part of the hackathon to be able to collaborate so this is the agenda we have in fact six presentation I think "
  },
  {
    "startTime": "00:06:17",
    "text": "the hackathon feedback was going to be pretty fast then we have a update on that we\u0027re coding and satellite then updates on what we are doing for coding for quick and there\u0027s actually three presentations on that there\u0027s the approach that we\u0027re doing which we do here then quick and you\u0027re going to see that there\u0027s a presentation that does it as some kind of a quick tunnel or I see it coding tunnels were quick and then I\u0027m going to do a small presentation on what\u0027s going on with the other groups that are related to this actually at the chairs dinner on Wednesday we all recognize that they should be more collaborations between the different groups because a lot of time what we\u0027re doing is closely related buzzie its she was about 180 intern dress loser in the group we will talk about a few of them today morning so I did not mention them in the lists but otherwise there was no update for the network korean forces yen and yen requirements and challenges engine draft so we discussed with the authors and they explained that didn\u0027t have time to do that for this side chef meeting so their position and agreed to to have it ready for for next idea so so the idea is to send this dating document to both our group and IC energy to give to get a feeling of both groups and if this feeling is positive then we may and research classical this is what we decided last time so it\u0027s still valid yes Dave just by way of advertising the the base protocol specs for CCN have been published as RFC s experimental RFC so we have a concrete pretty stable base to do the binding of any protocol machinery that you for the network hurting to refer to so something we might want to tell them is when they change their references to the MC version thanks okay thank you there was a slight update from the RNC based symbol representation documents not much difference but the office did not believe it was meaningful to have a new presentation today there was a much bigger update for the bats coding scheme for multi of data transport documents and I hope we will be able to discuss about this at next ITF in Singapore and finally the good news also is not work being done in this group but closely rated the free documents that I pushed "
  },
  {
    "startTime": "00:09:19",
    "text": "forward in DTS vwg working group or fake frame extension for sliding window codes and the second one on Alice\u0027s lining Widow cards and the third one on tini mg42 PNG for being used in RC and perhaps somewhere else protocols all those free documents of being accepting the grid by GE and now there are the I\u0027ve CID talked you so that\u0027s the good news so for next time we can say today that there will be a katana at next ITF that will also be a new meeting at next ITF in Singapore so just to tell you so that you can make arrangements so that\u0027s all for the chest slides so next presentation is a quick update on the icater on what we did from this time so this is the swift codec a katana just to remind you the goals of this Agathon is to design reference open source and free correct for slanging window cards this is the third time you meet the we we did the work we organized the work in such a way to be able to in the first step produce something that is somewhat compatible with what we did in the I\u0027ll see draft so just end-to-end encoding and decoding no nothing in the middle that\u0027s the first step and the second step would be to improve this further improve this correct so as to be able to do Rhian coding within the network if there is a desire for doing this the goal of course is to facilitate tests testings batch markings and also adoption another goal is to challenge our Jerrica api in the draft that specifies our to interact with such a collection of something else that would become so in terms of API so this time the team was a bit smaller than it used to be in the past we were free people silic was there for the two days Saturday and Sunday but was obliged to work also in a different project so he was he was sharing his time between these two projects Francois Michel was there on Saturday remotely but he contributed actively and as far as I\u0027m concerned I was supposed to be there both from Saturday and Sunday and fortunately I had some programs and I was only able to to attend this Sunday so that\u0027s all of this to say that okay we didn\u0027t make as much "
  },
  {
    "startTime": "00:12:21",
    "text": "progress as we anticipated as we would decide but okay it\u0027s like we also add some contributions from ume√• we would since the previous ITF meeting managed to further update some parts of the correction she will continue on doing that so anyway we achieved to do a few things first of all we change the license that\u0027s something important just to make it clear we move to something which is compatible with the IGF requirements in terms of documents and code means inside document so this is a simplified bsd license the ending part is more or less well the main part of the encoder is done we still have to include a few additional work a foolish move method for sharing a few things anyway but most of it is done the decoder is in progress that\u0027s the most complicated part this is where we have to manage and solve linear systems and do all this complex mathematical machinery we managed to more or less finalize the demo application so it\u0027s not working from the moment because we don\u0027t do decoding but it\u0027s in good shape it\u0027s almost done and the Python wrapper and testimo in Python this is also something where we made much much progress we\u0027ve fixed one thing in the generic API internet draft mistake in the way we specify the point or it was a point or it should have been a renewable point or something like that and then we still a few open points that we did not manage to fly if I will still need to think about it again so the next step in for fight EF I kep on in the next ITF Agathon will be to have something that\u0027s working that managed to do encoding and decoding and interoperate I think it may be physical if we manage to do some work in between and then we will continue as I said with the oil and sea so being able to do rien coding within the network so that\u0027s the goal I don\u0027t know if there\u0027s any comment question no ok custom custom moment how would you characterize the performance of what you are doing is this high-performance of limitation is just proof of concept implementation that the goal is to have a proof of concept which is functional and all those performance optimization stuff that should be done will be left for volunteers who won\u0027t have an interest in doing so so what the goal of this - Timo is really - to have a functional connection before you agree "
  },
  {
    "startTime": "00:15:21",
    "text": "with that so what what level of performance improvement version will you will get this effect attend faster I think there will be potential for performance improvement at the end a significant performance improvement for what I saw in the mathematical operations then with a few things we can that could be done but whoever wants to contribute on this particular point is welcome of course to do that now also some conflict of interest for some of us myself included I have a proprietary implementation of this so the limits to what I can do in this context but we will have something from for sure and since it is open-source bsd open BSD license anybody can further improve it it\u0027s totally free and I\u0027ve pretty sure that people will do that okay hello everyone this is an update from the draft on networking for satellite systems we were in working who pressed call process since the last ACF and we had lots of comments from john and lloyd and yourself forgot you on the slide sorry for theft I should have put it some like and many others well basically think there were some very deep changes in all the wording and lots of different aspects on the draft rather than just presenting a deef as we did a lot recently for this draft I\u0027d rather I prefer to present it all again and also for some of the use cases where with a net recording is of interest we haven\u0027t read some experimental results so I will go through the document and first starting with the abstract where we insist on the fact that we follow and we base everything on the taxonomic document so coding in the "
  },
  {
    "startTime": "00:18:22",
    "text": "document is a linear combination of packets and operates above the network layer and it\u0027s true that for that previous versions of the draft was not always very clear if there were lots of small issues in wordings so I think for that and the reviews in the comments we received our very own food in improving the document so we have the break TVs to detail what is a multi gateway satellite systems to identify cases where ad encoding is what happened so we have residual losses and to end we have some multicast services as we want to make on a level and many other use case which I will go through now and the main objective then is to contribute to larger debugging deployment of coding techniques in SATCOM systems or four-second systems may not have to be specific but at least deployed and we try to identify some open research issues and the end of the document so if we go more into the details on what the taxonomy document says is that we do not consider a physical layer coding all that is physical layer related is out of the scope of the document we have FEC that operates above the network layer and we only have a combination linear combination of packets we don\u0027t know any application level coding such as it could be the case to compress the video flow for example and we see that this activity has been very widely discussed in the research community and we think document Alps in the notifying we\u0027re using coding is relevant just a quick clarification question you actually mean above the network layer or in or above the network layer in or above ah I mean we don\u0027t because if you say above you can\u0027t do recoding in a router okay I should what we should say is we do not do layered cutting because if that\u0027s not what the slide says just hope that\u0027s not what the document says it is what the document says so thank you for that and we will have to make an update I will look at a note later or not to forget thank you so this is a description of what you can find in to the generic satellite system today following the gbps2 standard so when I say above the network layer is that we don\u0027t play with these BB frames and specific DBS to latest standards because this is very out of the scope of the ITF and what so it\u0027s so this is I think most more to introduce some of the wording that I used in the rest of the documents as towards for the first use "
  },
  {
    "startTime": "00:21:25",
    "text": "case I will now go through the different use cases and for all some of them these are not high level description use cases this one is the use case where basically we have two satellite terminals communicating to each other to the recording server on the return link we have with we have settled at Terminal A who sends a satellite on Nibiru things be and basically the coding server sent a and B on the forward link so that is huge capacity optimization we have introduced this use case not really because there are lots of industrial and application use cases that are relevant but this is something that we can do and has been demonstrated using will satellites in a SMS 2010 so we should at least that\u0027s why we mention it they\u0027ve the variable multicast when we have a multicast and flow going to different users satellite terminal ay and B but we have packets losses so a and B can send the to the mallika server the packets that are not received and a em flow can induce coded packets to recover what has been lost we agree that this could be done by lots of other multicast about CAD systems such as norm or fruit but they do not use the limited to block coding and the newt actually supports sliding window schemes so that is why we mentioned that in the document another use case is it would access if when you have and that is really typical in many satakam applications when you have ample users in the boat or in oil platform or whatever there is not only the satellite satellite is one of the many links that are available so we can have a CPE on the end user side and a concentrator in the operator network so we have lots of MPCP for example could go through these networks and sometimes there are packet losses on one of these links and in using coding techniques could be introduced both at the CPE or the concentrator to cover an cup from packet losses so this is open lots of research questions on how do you impact on MPT CP congestion control for example so that\u0027s why we mentioned that in this document this use case concerns a lot more than the others I think that in this figure you have basically your web applications every hour that com-system a multi gateway system so if you look at the operator thank you that fat growing segment this is what good light look could look like we have tens of gateways "
  },
  {
    "startTime": "00:24:27",
    "text": "in Europe for example and then you have a satellite that you use a dvb-s to standards to send the data from the Gateway to that right Tammy no and the user DiBiase\u0027s to standards for the returning so we have apart from some regions where we have rain fades and packet losses we can consider in general that even error of a link and we have a IOT but the problem is most of the users today are connecting through the satellite box with Wi-Fi loss Wi-Fi link so in this case we don\u0027t have only an IOT network but we also have an IAT with losses network and in this case I think that if people working on quick and fake are looking for use cases if they can make it work in this use case that would help us a lot so if you want sizing numbers or use cases that would be very relevant for you to experiment and for us to have the results because this is we have not experimented network coding in this version but we have a satellite at home we have a good wave of satellite terminal so this is a real experiment you think a real satellite flying above and basically we have an HTTP to transfer of 2 megabytes file from the two endpoints and here we have one opossum classes I will not go deep into the details but because I have all the results and show you if you are interested you can have a chat but basically if we look at the page loading time without these losses there is no congestion is only one to make by megabytes file transfer basically we have we compare these PDF without and with losses and what we can see is that when you have one person losses for the median median page loading time we have more than five seconds increase and for the 80% of the cases we have 18 seconds increase and so we go from 11 to 30 seconds so that very bad quality of experience so we need to do we are trying to find ways of doing something about that if you see the solution maybe you want to L a press that may be an interesting with reduce case we have platforms if you want to experiment so contact me if you want to experiment your solutions in this use case another use case we haven\u0027t satellite is that I told you that in this use case we have no losses but there are cases where we have loss reasons that are a satellite link and we think that in these cases the physical layer is very constrained so providing higher layers relevancy can help in releasing the constraints on the physical layer sorry for mentioning the physical layer here and this is more something that I\u0027m not really perfectly familiar with but what I can tell you is that we have basically "
  },
  {
    "startTime": "00:27:28",
    "text": "the losses pattern you have when you are an antenna on the train so we can see that we have this we have very low snr areas of the DBS 2x standard so you have here the signal-to-noise ratios and the modulations that are used and in this context we have raised your losses and the picks with here are basically the poles along the railway so you have repeated losses in in another case we have been looking at we have an LMS so basically mobile and mobile user so neither in moving through the trees a lot of issues so we have this kind of patterns these traces are available and then to the lists if you want to play with that we have we can easily play them in open source tools we have so if you want to so to put that in your experiments but would be great we have been another use case that is very trendy in that calm industry at the moment is using optical links but the problem with optical link that we have at the moment it\u0027s at sometimes a cloud and so we have on a very short fading even\u0027s I don\u0027t understand everything in this figure but I put it here and the reference just to explain that basically we have lots of people working on it and we want to explain them that they\u0027re not there\u0027s not much needs in improving a lot of equal layer let her let us deal with improving the quality of experience and dealing with these losses so we expect to do some measurements in this use case in the next coming months but we have done some results with the previous traces I had shown earlier so that\u0027s the train that the mobile user so this is an open source tool we have and we we through port so if you want to use it it here everything is on the wiki everything is available so we have a gateway of that comm satellite terminal between the fat and the factory know we have we induce these losses and we have on top of that Anu has recorded shadow with a sliding window effect with the K or 4 in the age of 20 I hope I think the room is familiar with these kind of schemes if you want more details we can have a chat but basically what I show here is the residual losses so on the train case because the pattern is very big you are we can actually find the parameterization and K value of K that solve all the problem with at some point K is too high and basically we have residual losses Servais and in the other case the pattern is so strange that we can we can\u0027t actually do anything with the basic scheme represented so I think "
  },
  {
    "startTime": "00:30:32",
    "text": "that this is very open research issue that may be of interest for the persons in this group we also are trying to see all this impact on TCP first and then when we have mpeg-dash traffic and because that is the use case that we are interested in and we think that is very at least funny to look at because when you have all these multiple layers that play to each other and strange things happen with at least interesting use case and so how much time do I have left so another but that we go still card question what are the C\u0027s what are the little C labels the picture you just had no the picture you just put up okay C\u0027s cccc I think that yeah if I am might be beating in the legend here is where we could add meta coding because a network function block is basically we have IP packets coming in and that IP packets coming out and so we can that is where we have all these pipes and all lots of firewalls and all these things you could expect and access gateways as they have IP packets coming in they could also do some things on it and so one of the the trend at the moment is to try to thought basically that is a use case where we have lots of gateway and overs for lots of values reasons we may want to move the traffic from one gateway to another and in this case we may have losses so we may be that may be a use case of interest for network owning enough of the research challenge part so we know that we have proprietary solutions to hosts coding techniques in terms of deployment we are I know that it is possible but then we have a problem on the interactions that is something that has been discussed in the group and that basically what we are doing at the moment is looking at the fact that when you are adding with agency and you basically induce lots of jitter on the end-to-end and we don\u0027t know if RAC timers actually work well in this context so if you forget all the duplexing in TCP and only rely on rack we have in our case we have retransmission that low earlier that may happen and that would have an impact on the depending on the size of the buffer of your reer doing window in your Metro cooling scheme you may have an impact on how a rack total weights disorder we are doing and if and well out of all the pockets another important thing is "
  },
  {
    "startTime": "00:33:32",
    "text": "it is a good thing to have real variability and to have more resiliency but the problem is that capacity is expensive in the satellite so there\u0027s a trade-off in how much residency you had and how much you can improve the quality of experience but how much does it costs in capacity because that\u0027s a big open question we have and then that is more related to another working group that is all the neutralization thing it\u0027s more because we have lots of CTE and gateways and data centers now we are moving toward this in satellite so basically we can ask easily these coding techniques end to end and between at least two endpoints which more how do we integrate this solution in and virtualized environment that is something that is maybe not a research challenge but at least something to do cuts debris because when you go deep into the details that way issues may commit and then interactions with DTN because that is something that came out in the discussions so basically how to network coding Interac who is against a current amount we have to open issues on the github because we have very happy to use github so if you have any comments of the document we are happy to welcome emails but issues on the github is way better because it\u0027s very easier way for us to explain to you how we assess your comments so we had a comment on virtualization and the research challenges were basically we proposed to close it because the question was because we are punting now our comments was that there were no ID on what the section means so do we want to be authorized antennas or virtualize reflector so that is not what we want to do but we try to make it clearer in the text and then another comment was on DTN and all these ccsd\u0027s stuff we don\u0027t want to mess with CCSD yes that\u0027s an also standard it has its specific use case in satellite industry and we don\u0027t want to consider that and so we just and we explained in this document that we are just using DVB as an example of what a satellite system is and not as a base line and we don\u0027t have a specific location trail even if rid of it so we published a closed issue as well yes just one comment you already sent an email to least mentioning those two open issues if I remember correctly we receive no feedback on it so I suggest you just "
  },
  {
    "startTime": "00:36:32",
    "text": "reply to this and say explicitly what you have said now okay we propose to close unless there is opposition okay but do that on the list and not on the github because I\u0027m not sure that it\u0027ll be so much below it as far as I\u0027m concerned I\u0027m Network easier for us we just copy paste it what we received by emails in the github to the end changing the pre quest anything it\u0027s clearer but then ok so send it to the list make it clear that you want to close those two commands open questions and yes so what\u0027s next step so we received comments from Scott recently yesterday thank you very much I suggest you answer those commands during a date and then I see no reason not to start a new working group a result group it\u0027s not a working group research group Lascaux on this dating documents okay no opinion no it\u0027s okay thank you so this is a technical presentation of what we have done for this coding for quick document we change a lot of things I as I will explain so this is joint work with Francois my shoe and onion so just a summary of what we the situation at previous ITF there were two proposals for adding quick earth adding FEC within quick the one that I mentioned here is the the one what was implemented in previous revision of this document the idea was to do that within a stream you know stream notion of trim from quick with good properties meaning that some of the streams have more requirements in terms of reliability and others so it makes sense to protect more new streams than the rest there was also a good property that it was possible to do that without changing at all at all the quick sauce packet you\u0027re in your packets so that\u0027s great to do that but of course there are consequences side effects one of those side effect is the fact that okay this is a stream concept so being a stream concept there is no "
  },
  {
    "startTime": "00:39:34",
    "text": "separate there\u0027s no boundary no notion of boundaries and it\u0027s doesn\u0027t it\u0027s not something that could be easily applicated to data graham approach another way to transport data transport build within quick so that\u0027s not very good from this point of view there\u0027s also another side effect that was a bit annoying this notion of stream makes it in post it makes it possible for a symbol to straddle several packets and that\u0027s something that we don\u0027t want so much so the second proposal from Francois was doing it totally differently the idea was to protect packets to consider packets consider the payload of this packet and to segment this payload into symbols so as to do a protection for all those frames within these packets within those packets so it\u0027s another way to do that it preserves packet boundaries that\u0027s a good point when you recover something you know that it fits inside a given quick packets you also had this good property that saucy motion ever straddles they were quick packets so that\u0027s also something nice with some additional one side effects that\u0027s okay we need to change which will be the original quick packets but something that can accommodate and it\u0027s also bit more difficult to try to protect a subset of a packet so do that think that we will elaborate a little bit more in this presentation too much into details at the moment so we add discussion so together and we decided to change totally the way we propose to do efficient quick and to follow what more or less what consol was proposing namely doing that inside packet cross packet friends so that\u0027s what is now implementing in this every revision of this document we added a few additional features as I will explain so many things are still the same several key architectural concepts remain one of them being that we apply FEC encoding and decoding before doing encryption which means that middle boxes will not be able to do anything from this data flow it will be an encrypting data flow no way to distinguish between source and repair packets there\u0027s no way to do that that\u0027s the first aspect another aspect is that as before we try to provide a generic picture which is compatible Morris with any fax scheme that we may want to use within quick and we have moved we move all the facts keep specific considerations our to do that with such or such cut for instance within a separate dedicated internet drafts so that\u0027s the case with this existing with the existing I\u0027ll see for quick internet draft the third point "
  },
  {
    "startTime": "00:42:35",
    "text": "that we kept is that we absolutely want to be congestion control compatible we do not want to interfere with the way a congestion control may happen within quick so we use dedicated recovered friends to inform the sender that some packet has been lost but has been recovered by a fish decoding at the receiver so so that the sender can take it into account do whatever you need to do from a congestion control point of view notion from this point of view and of course avoid reasoning retransmitting this packet that has been recorded so that\u0027s something which i think is also important for acceptance of efficient quick yes different tell me you go away if you\u0027re gonna cover this in minute so two questions came up and put this down number one is do you have a sense as to whether this scheme is more friendly to multipath than the old scheme my intuition says it is more friendly to multipath but I\u0027m not sure yes maybe because there is this way yes so similar straddle several packets quick packets and if you send one on one side and you\u0027re the one on the other side maybe it will reduce the probability of having a packet loss that\u0027s involved so simple roses yeah especially if multipath has done not on a stream basis itself but on a packet basis huh the second thing is this recovery frame thinks is very nice have you thought about whether this also could be used to change the level of coding so that you get recovered frames in there\u0027s very few of them based on your current coding you might want to reduce the coding or increase it if the covered frames are showing a lot of recovered frames yes maybe it could be used to piggyback some statistics thus under more it could be done for in yes for help in the center setting the right cadre the right amount of repaired data that he wants to send maybe maybe that\u0027s something we work on but thanks yeah but anyway the goal was a bit different but yes we could take advantage of this for doing additional things yeah thank you [Music] so the the key point in all those in this work is the question I\u0027ll doing not quick packets to source symbols that\u0027s really the key aspects and there are several things to consider first of all of course the quick sauce packet is of variable size but we absolutely want to keep the symbol size fixed for the world ration of a quick connection because next things much simpler to manage within the encoder and decoder if we have this fixed property fixed size property so now the question that arises "
  },
  {
    "startTime": "00:45:36",
    "text": "is what is the appropriate size for those symbols should we keep a perimeter and the big e perimeter is this so single size so should we keep a small symbol size should we use a larger civil size of course if we use larger assimil size that will be perhaps the opportunity to fit all the quick packet payload within a single so symbol mu so that makes things easier to manage but at the same time if we have variable size bluntly viable size sauce packets a lot of small sauce packets and from x times bigger sauce packets then it\u0027s a waste it will include it will generate more overhead transmission over it so there is a waste of efficiency from this point of view so we need to find balance there are small aspects to take into account to find the appropriate balance this is there is no single magic value for this symbol size will depends on the use case so we need to to have a better understanding of what type of data will be carried within this quick connection most probably so that\u0027s something that will not be fixed inside these documents into a generic framework that\u0027s something that remains to be adjusted based on the use case based on deployment considerations so it will be so but we have this flexibility to manage at the same time small or larger size since symbol size in this document that\u0027s what simple is most important so let me explain how we do this quick packets to source symbol mapping so that two steps the first step is the one that is now on his right it consists in segmenting quick packets quick packet payload in fact into chunks so the way we do that is the following we add first of all we add padding to packet payload in order to be a multiple of e minus one plus this a minus v initial chunk so we need to add this to have a multiple number of chunks well no sorry the the the padded sorry the padded length must be a multiple of e minus one and E minus five why does the difference between a minus 5 and E minus 1 will be explained later the way we do that is by prepending packing frames to the payload so this the quic protocol has this nice feature that we can add padding and 1 byte 0 1 0 bytes padding is itself a padding frame so this is a result value so by doing by putting this padding at the beginning rather than the end of the packet payload it makes it possible for decoder "
  },
  {
    "startTime": "00:48:36",
    "text": "to skip all those padding frames even if the size of the frame is not specified on the other friend is not specified which is something which may happen so this is a bit complex but by that at the beginning of the parrot instead of at the end of the period removes this requirement to have an additional signalling film that will tell you how long it is how long the payload is so that - for the receiver to skip the final padding if we are doing that this way so it\u0027s something that is a quite efficient so we do that that padding and we then segment this padded packet payload into chunks so in this example we have three packets wick wick packets and as you can see there are four chunks for the first one three for the second and front ones so that\u0027s the first step we have chunks now so what do we do with chunks now we need to we need to do a mapping between chunks and source symbols and the way we do that is by prepending one bytes of metadata I will explain you what is inside this one byte metadata and then for the first chunk we have this additional packet number which is a quick packet number which is protected explicitly in the first row symbol of a quick packet so the association of this metadata press packet number press packet trunk is constitute this awesome so that\u0027s for the first chunk of a quick packet and the remaining chunks of sauce packets only this metadata there is no need to repeat the packets and number that will be anywhere protected by the previous awesome so in that case we simple is this method that I went back metadata press packet choke and all of these constitute disassemble so that\u0027s the way it works so now what we put inside this metadata byte well it\u0027s pretty simple there are three bytes sorry there are three bits that are used the first one is just to indicate the N field is just to indicate that there is a packet number that will follow four bytes packet number the s and E bits are there to seen all that okay this is the first chunk of a quick packets for the father√≠s s start needs or the last chunk of a quick packet for the e bits and with this we can inform the decoder we can infer the receiver after decoding back okay that\u0027s the first chunk that\u0027s the last chunk those chunks are in the middle or maybe there\u0027s a single chunk for a given packet payload that\u0027s the only chunk because there will be at the same time the first and last bits that will be set so that\u0027s an easy way to do that and as I said I said number this is also important to add this quick packet number inside some of the chunks because "
  },
  {
    "startTime": "00:51:38",
    "text": "no sorry not the tracks but the source symbols because it\u0027s something important for decoder to indicate what packets has been recovered by the FEC decoding process I remember that I is this recovered frame that will go to the sender to indicate to the sender that this frame has this packet has been decoded as been lost but decoded so we need to indicate to the receiver which packet it is and since the quick header is not protected by FEC itself we need to carry this information in some other way and we do that by including this quick packet number inside the first symbol of our packets so that\u0027s a trick to inform the decoder we went from the sender that this this packet and not another one has been recovered so that\u0027s why it\u0027s important so the big picture now which way so that we have this quick packet we do padding initial padding we split the contents of this packet payload plus padding into chunks in this example we have four tracks and then we create with this additional metadata and potentially for the first chunk for the first sample the packet number we create those source symbols and this way it\u0027s working it\u0027s working I just want to convince you that it\u0027s working that\u0027s a an example so let\u0027s imagine that in orange we received or read accordion or maybe something is missing several soft symbols at the beginning and for the for the for the last part and in the middle at some point of time the decoder can decode those for source signals so by looking at the first pie at the first bite of each source symbol it will determine that for the first one this is the first drink or the packet for the last so simple it really determined at this last one and was to in the middle just in window so it will determine all of this and you will be able to construct by removing those additional bytes M meta data bytes remove that but you will reconstruct the original quick packets and be able to do what he has to do with this recovered sauce packet quick sauce packets so it explains why we need to add two additional metadata stuff then we change just a little bit the the original quick packets with this approach we need to carry this additional fact sauce FBI fact payload information so that\u0027s signaling information that we need to put inside the original quick packets but carries sauce packets the source data or a journal data to the send to the receiver we need to do that just to "
  },
  {
    "startTime": "00:54:39",
    "text": "the receiver decoder okay that\u0027s that quick packet carries this do so symbols we have this awesome or identifier that is typically inside this additional frame if we are dealing with block codes maybe we will also have an indication of an identification of the block it corresponds to for the few things like that that we need to be that needs to be carried inside quick packets original should quick packets and concerning the repair frames we can transmit them in additional quick packets we can perhaps put several with their frames together inside the same quick packet it\u0027s not a big deal it is small enough if E is small enough to be able to let it\u0027s not a big deal and those a repair friends will be identified as such I added catchy repair frame identified so it\u0027s backward-compatible both of them and backward compatible but because a receiver that does not know anything about offici will skip those frames and that\u0027s that\u0027s it so there are few open points one of them being the possibility perhaps to ignore some of the friends in this process because these frames are not that important from the we can avoid protecting them with the fishing techniques that\u0027s the case of perhaps acknowledgement frames so and it also be the case for non real-time non the less sensitive streams maybe so we may want to do that I\u0027m not totally sure it\u0027s important in any case if we want to do that it means that we need to inform the receiver we need to keep both encoder and decoder synchronized so it means additional signalling and at the moment we don\u0027t really know how to do this additional signal and so there are point questions yeah this is something that needs to be experimenting implementing we need to have more background more information more thoughts on those or techniques if we really want to do that otherwise we protect the full payload quick packet so it\u0027s say always possible there\u0027s also this choice of this symbol size parameter that\u0027s I already mentioned next next things to be done well we need to add 8 the IOC for quick documents we need not have time to do that presently switched you\u0027re compatible with its general France in the previous version of this framework document so that\u0027s something neatly done and of course we need to experiment and from this point of view from this point "
  },
  {
    "startTime": "00:57:39",
    "text": "we do Swift connect will be quite useful that\u0027s all drift attorneys talk there\u0027s a Francois will discuss about neon progress in plantation reference implementation for these yes sir again be a little bit cautious about not protecting acts I think if you look at the net impact on performance it may be more so than you imagined okay yeah this is something that we discussed quickly with a young sweat trio Jeff there was some belief that could make sense to avoid protecting them but well that\u0027s another point for Jess so I\u0027m scratching my head about one thing the presentation is seems to be it seems to be oriented toward systemic codes and so it\u0027s actually you do or replaying support nonsense systemic codes and if so what happens just all the packets or repair packets by default we have in mind this systematic approach works and both the source and the Republicans but if we want to avoid sending sauce packets it\u0027s not a big deal it\u0027s just a matter of producing more repair targets and sending more about that gets so yeah it seems straightforward just because some of the description basically said well you know I don\u0027t need to worry about the repair packets right but if it\u0027s a yeah yeah everything\u0027s in a repair okay I always mentioning thank you yeah intuitively it seems like everything was okay but I just want to check I think the assumption it is that it is a systematic code it\u0027s because it helps so much of the decoding so true so that I think it\u0027s not a bad assumption but I agree with you it should be much it should be generic it\u0027s just nice if we check and make sure we haven\u0027t done something you know like silly that makes non-systematic hose not work when it doesn\u0027t you know when you could have done something just as easy and they both yeah okay Thank You Brandon Williams aye I don\u0027t get a clear indication of whether you\u0027ve looked really carefully at how well this approach aligns with the API approach in any other any other document does it did you do you see any challenges presented from the API should be able to be Bafa separates documents "
  },
  {
    "startTime": "01:00:39",
    "text": "for different aspects or the same big picture I don\u0027t see I don\u0027t think there is a much dependency on that if you need to just know what wasn\u0027t clear whether any anything fell out of sort of the quick specific discussions that might drive drive any change I don t think so at the moment I saw some that\u0027s not like a validation of the API yes but the idea to to ever to use this API and switch connect inside existing C implementations of quick and John Porter quick observation that at least as we presented it N equals s so it\u0027s redundant there\u0027s a systematic a non systematic code would that help in this context idea was brought earlier of being able to adapt how much code extra coding you\u0027re putting in because I\u0027m definitely interested in that because of my latency over satellite that has the error if I go into rain fade can I increase the coding on the fly if I can detect I have a higher loss rate etc the it I\u0027m assuming it\u0027s gonna depend somewhat on which code you pick on how easy it is hard to do that it depends on the nature and the code with a sweet fun slanging window codes it\u0027s pretty easy to add more repair packets it\u0027s just a matter of creating if you new linear combination of what is at the moment inside the training coding window and send it so it\u0027s pretty easy with also code star constraints okay but yes we have this Plex ability to use whatever we want in terms of code inside the this quick protocol so at least this is the way we want to design it so so this we just want to make sure there\u0027s some flexibility what kind of information you could pass back okay this looks like it probably constrains us to if we\u0027re doing hybrid air q2 doing type 1 doesn\u0027t look like it would support a type 2 or am I missing something and thanked 1 and type 2 what do you refer to type 2 would be an incremental redundancy hybrid a RQ where additional repair packets are sent in response to an ack as opposed to repair packets are you just pick a priori how many you\u0027re going to send and perhaps adapt at least by the number in that case if I remember and I understand correctly those additional repair kits are referring to the ones that have been "
  },
  {
    "startTime": "01:03:39",
    "text": "identified as being lost no try to figuring out what it means well so there\u0027s no actual retransmission so perhaps a RQ becomes a misnomer in this case it\u0027s just a matter of sending additional repair packets in sufficient numbers to allow for essentially increasing dynamically the error correcting capacity of the code yeah the only constraints in that case is to manage this lining window in an appropriate way because once this all packets have been removed from the sliding window and then there\u0027s nowhere for the encoder to produce repair CMOS really protecting news packets so it\u0027s not more a matter of using correctly those FEC codes if we are discussing that signing window cuts than anything else it\u0027s a matter of choosing it in the right way compared to what we what are your requirements yeah so they\u0027ve written somebody\u0027s made a nice comment and it\u0027s just sort of flew by which is um the way you\u0027ve described the encoding s and n bits are redundant because you can only put set the N bit if the S bit is set and it\u0027s invalid to have a packet with the S bits that and not the end bit set what I mean is there\u0027s some kind of activity there that you meant to describe and didn\u0027t yes the N bit which which means that okay there will be this I get another identifier inside this or symbol is something for which I don\u0027t have a clear idea at the moment is it option or not I\u0027m in the slides I mentioned optional that\u0027s something we need to discuss and figure out saying the the the packet number is always in the first packet which is so yeah yeah yeah and it\u0027s an error yeah some other chunk have I mentioned yeah it\u0027s it\u0027s optional but this is something we need to yes at the moment we have this in mind but maybe it\u0027s a mistake that\u0027s something we need to discuss and evaluate is it really all the time is it all the time required to have it all that you know that\u0027s only point but I should have mentioned this in this yeah good good yeah yeah no okay but yeah that\u0027s the point an additional point point that I should mention is yes sure we don\u0027t claim to we have fixed all the problems "
  },
  {
    "startTime": "01:06:44",
    "text": "especially when we see how many discussions life description dying the quick show is a working group so you know we are in between us I will say but once we go to a quick working group there will be many many more comments on the specific aspects so we need to clarify all of them as much as possible and we\u0027ll see after and surely the number is one of them yes okay thank you so now I will if the floor to Francois will talk about is interpretation of all of this can you hear me yes okay great wait wait wait I need to show this light it\u0027s not a big deal okay so they\u0027re coding for quick current working progress reference implementation so next slide so compared to the promised version the draft has changed quite a lot and at the same time we had a no made version of an implementation of a fake extension or quick that we made but that was based on no version of of a quick implementation and it was also in the multipath extension so it was quite complicated to maintain and complicated to make evolve so we decided to propose a new fermentation from scratch and whose goal is to be simple easy to learn and to play with and the goal is also to stay up to date with the draft specification and also with the the base quick indentation which is quick googly so next time and so if you want to check the source codes it\u0027s available on github the slide are also on the NW c RG github so you will be able to get the link there currently the implementation only supports a block code it\u0027s easier and the RSC specification is still evolving we currently provide a simple kisara and we already use the recovered frame as I explained and so currently what we are doing is that we are not protecting add frames so we can discuss about that you are stepping out of the or the packet payload we protect the packet payload and the implementation is closely tied the design of the draft "
  },
  {
    "startTime": "01:09:48",
    "text": "frame with you you can fight them to have a block that has a different format deeper frame and fixity it is the same for the recalls next so if you want a simple example say that you can see green onion type implement read functions and you should be able to to make it work so for example you can decide to implement a block-based already currently and you can also decide to implement convolution of skins and stuff but it\u0027s a little bit more complicated and excite so what do we do next so first to add a sliding window fix scheme and also wire the code with the swift codec what\u0027s it done we would like to add a proper test shoot so currently the the quick go test shoot is still working but we would like to add new unit - to test the fag extension and we would also like to move forward in a general way to have a more clever simple scheduling because currently it works but it\u0027s not really efficient because we do not do things very cleverly and we can also try to run wire new applications about the implementation because we chose a quick go because it\u0027s an implementation that provides the rich API which is easy to use and play with so that\u0027s something we already try to do next slide and so finally there is a list of other interesting implementations to look at so there is first a quick which will be presented in less than five minutes and finally we will also present another quick implementation at signal 19 which is done with the paper which basically revisits the way on how we can deploy in a complex extension such as effect so the the source code of this implementation will also be publicly available so you can stay tuned and you can get access to it after your sitcom so next slide so thank you very much and feel free to ask your questions if you are also just 100 mean name to me oh we have the old one we have this new one and we have the the one for for sitcom so three bands but the old one I think will get rid of it okay you you always to continue with the quick go implementation to maintain it as the main reference implementation yes this one and the second one the the destroyer and that it is one and the cecum so the quick go and the seeker go though okay "
  },
  {
    "startTime": "01:12:54",
    "text": "no comment no question so no okay so Thank You Francois and keep it in touch and if you have a new resource experimental results on excite here you will be welcome of course okay so next presentation is for our quick and was a quick and fake approach so me I can you hear me can you go on the night we are waiting for you or Josue or somebody can you click the button so you start talking to us okay in the news you\u0027re on the lists we can see you on meta group but without the action from you we won\u0027t be able to give you the flow so go ask the mic on mythical okay so we are going to swap the last two presentations so now managers they will talk about relationship with other initiatives and then we will come back to you nice okay I don\u0027t know if you can hear me but let\u0027s do that okay so like I said at the beginning there was a strong I think need and a strong opinion about starting to link a lot of groups together and you know we\u0027re essentially a service for in the network so we obviously have links to other people and there\u0027s other groups who are looking at ways of implementing the coding so obviously they also have implement well issues or they actually have related issues so they are gonna get so we\u0027ve had it\u0027s sad that they\u0027ve just left but we\u0027ve had a long-running relationship with ICN RG which dates back to a paper I wrote about ten years ago and this led to this idea of network "
  },
  {
    "startTime": "01:15:55",
    "text": "coding for content centric networking requirements and challenges there\u0027s the draft that was discussed at the beginning and it is going to be a joint that we\u0027re coding and I see NRG RFC when it comes to that and it\u0027s it\u0027s been reviewed as they saw mentioned but this is has been I think one example of a relationship that has worked really well between the two groups and there was a bit of a win-win because it showed that you could implement and that were coding inside a information centric network so that was very nice coin this is really new coin we had a coin with my other co-chair group and we had a hackathon on Saturday where we started looking at things that could be done with p4 which is this language allows you to program low level switching and there\u0027s actually a group with Salvatori Signorelli and his team and Lisbon are actually low looking at an implementation of network coding in p4 which was one of the projects that I had on my list actually it\u0027s fun that they\u0027re doing it and this also is interesting for another reason that it will prove that the ideas of doing re-encoding in switches inside the network can be done really fast so that could be interesting results they were not ready for this IETF they are going to upload their paper and they want to write a draft on it and it\u0027s going to be a joint coin network coding draft so it will be submitted in both groups and we hope that it\u0027s going to be presented in Singapore in both groups so that\u0027s going to be fun and really show the present the relationship so this is actually something that I\u0027ve been involved since Monday and a few of us have been involved since Monday there was a non forming buff on Monday about something called loops which is some kind of hop by hop performance optimization and with FEC on selected paths there was a mention of Swift in the presentation there was no mention of the other potential codecs but obviously soif is really the work of Swift is related there was you know we know from the work that we\u0027ve done here that congestion control will be an issue you saw from the quick presentation that we now signal that the packet has been recovered so that we don\u0027t start messing up with the congestion control they have there\u0027s been a lot of work in this group on this and it\u0027s going to be important I think for it for the loops if it ever becomes and yes you have Kirsten you have a question yeah gasps mom and I\u0027m one of "
  },
  {
    "startTime": "01:18:56",
    "text": "the proponents of this both this is actually not top I hope this is meant to be used on path segments which of course may be single ops but in many cases actually for me the hop-by-hop was Pat segment so it\u0027s me not writing it right but I I understood it was different segments so basically the the point is that within a path that generally is okay there may be a challenged subset and you may want to install something at the ingress and egress of that challenge subset through to fix things and mainly right now we\u0027re looking at retransmission and FEC is just another option that has been implemented by the people who are building property prototypes of this and the main point is this is don\u0027t look don\u0027t touch things so we don\u0027t care what we transpose long as it is a package so if it\u0027s quick great if it\u0027s something else also wait no but I mean I mean that the the reason I mentioned quick on the slide is that there was a question from John particular about how quick would work but there was a presentation on quick with work so that\u0027s why I said there\u0027s a quick the presentation that we just skipped and that\u0027s sad actually it does some kind of a network coding tunnel and that could be another solution that you guys could look at so yeah I yeah don\u0027t look don\u0027t touch also includes that we don\u0027t talk to the host so whatever the host does is it\u0027s completely opaque of course the ingress or the egress might actually be the host in the end yeah so that\u0027s an interesting special case but the things supposed to be really simple and get by without talking to the host yeah and actually if you saw the presentations from Nicholas though some of his architectures looked a lot like some of the slides I saw on Monday so I think there\u0027s so the message here is that you know there is collaboration we\u0027re all in them saying mailing lists and you know again historically we ended up being a research group because the IETF was not ready five six years ago for a working group that dealt with the type of architectures that would discuss in here so we ended up being a research group but in the meantime a lot of the people involved have actually worked on real-world implementation and that could be if your group gets chartered that could be a way for some of the work that "
  },
  {
    "startTime": "01:21:57",
    "text": "was done here to move into the IETF because there\u0027s people in this room who know that the type of architecture you\u0027re discussing with loops including FEC is actually running code and a lot of different implementations may be more proprietary maybe a little bit more less known there\u0027s probably ways that some of these things may end up being you know in the public domain so it\u0027s just this I made you know and again I\u0027m talking about collaboration and this one is not between a two research groups but between a research group and a potential so what the idea is that most of us have been working on something for a while so for me this would be twenty years ago and we did the first thing of this kind and this is something that can be standardized but of course the the fec part is the the more interesting part and there we definitely hope to get very good input from this reciprocal thank you there\u0027s a question I think I make that depends on you know is connected okay so that\u0027s it yeah that\u0027s it we are also looking at links to other groups and but those were the ones that right now we\u0027re the ones that were the most likely candidate so if there\u0027s no other questions I\u0027ll we\u0027ll go we\u0027ll move to the presentation that was supposed to be before me thank you wait yes we can wait a few seconds I\u0027m okay these are the consequences of submitting my room sorry okay it\u0027s working so tell me when you want me to change slides okay okay thank you part of the day good morning to the personal attendees my name is Mihai I\u0027m a PhD student from University of Montana and Caroline Research Center we don\u0027t have any patents nothing dangerous here so and all the participants that are mentioned here this slider are okay me is presenting publicly the contents of this presentation I\u0027m going to present a robust week or our week which is another implementation of fact week are a lot to the work that was presented in construction next I kiss thank you so as I mention we were developing it in parallel so we follow the different "
  },
  {
    "startTime": "01:24:57",
    "text": "approach use different results which could be good review later which one is going to be better in which cases if there will be in a different book we will consider in the future you have a link to the github where we have this project as I will mention later these include more features next I have a question says Marshall say without the chair Harry the chair at your last statement says which quick fec is better and in which cases and is it worth merging I think I have an answer to this I think we don\u0027t know which quick fec is best because we\u0027re still testing these things and the worth merging my experience in network coding would say that merging them is probably not a good idea I think a decision that we made when we started working with Google on on the quicken FEC was that we were going to give operators a choice of the code that we\u0027re going to use in our case it\u0027s inside and in your case it could be that they also decide to use your approach but I don\u0027t think both together would work because then you would have a lot of issues with repair packets which ones are repairs we are above the encryption you\u0027re below I don\u0027t think there\u0027s a way that we could make a work so I think that\u0027s the answer to your to your last light I think I was referring more to today good practice for these cases that\u0027s all I was thinking yes okay next one okay according to code with badness encoded version we didn\u0027t know so much document exam we mean codes after Egyptian for two reasons the first one is because it seems more simpler limitation and the second reason is because this way we can evolve towards quick with network coding in a more easier and easier way this is Mary Jo say again question the fact that you\u0027re coding after the encryption but also puts kind of zeep encoded packets and in the clear how are you going to deal with the fact that people would know that this is an encoded packet like if I\u0027m on the line and I\u0027m looking at things going through I will probably be able to see that it\u0027s an encoded packets how do you plan to deal with the security issues of that well well the security issues I do adopt directly by tweet so that\u0027s "
  },
  {
    "startTime": "01:27:57",
    "text": "our idea there is an encryption of I and you don\u0027t really see the difference Oh even if you see the difference we need to review that so far over that week has enough mechanisms to to avoid the split issues okay the packet our budget so we will not expecting anything interview here I\u0027m trying to depict this off well I would week we never couldn\u0027t look like before and after routing before and after decoding so in sent over in emergent a minute if you encode before encryption is impossible or very very hard to record it in mediate notes however if you in encode after detection the product is much easier apart from being possible next time please some technical details here we took we are basing our code on we go budget by estimate not assuming we took the coffee after the release division Oh simple we want to be that we have implemented only one coding scheme with every second call it packet how because it depends on where loss is observe so far we have a four byte header four by four big packet right well this will show you change in the next future much the parts that we have added or we have changed in the original Greek decoder encoded the adaptive polling rate of I mean so it will be the station retina hard to buffer the packets that will need to be coded okay next looks like this our adaptive coding rate of this is number of technicians I have significant with with with Michel but Francois he was speaking so clearly that I didn\u0027t company so adaptive algorithm just in the last end coalition "
  },
  {
    "startTime": "01:30:58",
    "text": "periods nasty transmissions and retransmissions and then based on some promises that is that we configure which we can define as aggressiveness parameters we decide if we need to increase or decrease the ratio is according ratio and how much on the graphic little check that shows or even for losses little burden should define a more constant win rate one detail we threaten said we try to not to go beyond to congestion control window so we can recover any moment is there a more like eat chicken that\u0027s fine okay but could you hear more or less okay the previous parts please somebody answer on the chat or we can leave the dose above the previous part for later for the question okay for the question next I\u0027d kiss okay yeah it\u0027s our code what we simulations and physical setup which other art week isn\u0027t in pairing them up each session so we have considered for simulations three cases wireless network no no more typical war fine solar network and satellite communications in physical setup we had solar Network parents Wi-Fi we had two kinds of traffic both transfer and we\u0027re browsing as the output attic see the main output is the completion ratio that is the time in which our quick sense the necessary information divided by the time that normally could do that as you can see in both transfer we had of significant improvements in the in all cases however in web browsing the improvement is not that that big we believe that it\u0027s because our adaptive preto algorithm is not optimized for the slow start phase in the congestion control window we are working on it and the summary which is the next slide "
  },
  {
    "startTime": "01:34:01",
    "text": "thank you so as a summary we have a different approach to the FAQ which is easy to evolve into network coding the work is as I said the work is not over we are going to clean it more each more features more coding schemes random linear coding result we want to update our base coat and also include multi packs and network coding so if you have any questions I won\u0027t very fast sure and show you have questions hello it\u0027s Nicaraguan on the satellite axis you can consider 500 milliseconds OGG 20 Meg\u0027s downstream and 5 megabits upstream that\u0027s basically what you have in SATCOM accesses you can change the simulation parameters to 20 megabits down streams for satellite link and 500 millisecond okay thank you thank you we have it\u0027s I was curious about the relationship between what you\u0027re doing and congestion control maybe well can you also go back even one more slide I think that is dislike that as it isn\u0027t it so if I understand this correctly you\u0027re not changing the congestion control or like you working with the congestion all inside quick because it\u0027s supposed to be transparent to that so then we bring only the losses that don\u0027t play a role however is that this is preferred to congestion control okay so how do you ensure that you\u0027re not hiding losses that affect the congestion for response well if if there is a loss normally congestion troll should respond to that right so if you repair all losses then you\u0027re ruining congestion control okay where we are delaying the control losses so if you cannot recover that we don\u0027t pour that loss so we we have one loss we are waiting for the equity packet if we start to receive packets from the new generation we report that loss if not request as received packet okay okay okay I\u0027d have to read the details I guess if you you\u0027re probably working on a paper on this there okay thank you "
  },
  {
    "startTime": "01:37:03",
    "text": "Brandon Williams the the specific difference between this mechanism and the the other one that sits above the encryption layer that I\u0027m curious whether you have thoughts about is the it seems to me that the parameters you want or the desirable characteristics that you want from the network differ distinctly between a bowl between a bulk data transfer that wants to be reliable and say video-streaming that doesn\u0027t put as high a priority and reliability how do you see being able to make the necessary trade-offs there if you\u0027re sitting beneath the encryption layer and can\u0027t tell the difference between the packets that are associated with reliable and unreliable transport use cases okay we can actually detect I mean we should be or not observing them in the session module so this is not this algorithm this implementation is embedded into peak so we can see which packets are a priority answered so the do you mean that I didn\u0027t get the sense from the talk and maybe I need to read the document to get a better better idea I didn\u0027t get the sense that you were selectively applying the the FEC or that you have the capability to have any kind of differences applied between between different streams are you selectively applying the no right no we don\u0027t we don\u0027t we just our fact we transfer and the browser but so far we are not different do you have a do you have a plan to look into that and develop a more a more clear mechanism for being able to selectively apply a fact at the layer where you\u0027re applying it hmm we can\u0027t not host feature okay and then that that seems like something that\u0027s going to be something that\u0027s going to be important for you to for you to look into that certainly is one of one of the things that has come up in discussions about applying fact for quick that some "
  },
  {
    "startTime": "01:40:04",
    "text": "streams will benefit in some streams won\u0027t benefit much and and you know there\u0027s a desire to be selective about it as well as selective about the parameters that are applied based on the nature of the individual stream okay I\u0027m taking over this is immersion say again I go back to what Michael was saying you know I\u0027ve done a lot of this coding with congestion control maybe too much and I have the impression you really need to look into how you will interact with congestion control because right now you\u0027re correcting all the losses but the congestion control does not know the nature of the recovery that you\u0027re doing and maybe the thing that we\u0027re lost were things that should be lost and should not be recovered because there was something that was needed in order to prevent you know buffer overflows and a ton of things so you need to really I think look at your implementation in terms of how it works especially in the congested network where the losses will not be due to physical layer read you know residual errors but obviously because it was needed to drop the packets to maintain Network integrity and I think what you proposed here I think it works when there\u0027s no congestion and it\u0027s great but if you get into a more like the I would say the architecture that Carsten was mentioning when you have more than one path segments who have very different characteristics maybe on your wireless path segment there is very little law very little congestion and all your losses are due to physical layer residual error but once you get on the wired part of the network it may be a very different very something very different happening and I\u0027m speaking from experience here and you may not want to be very as aggressive as correcting everything and since you do not know what these packets are I think you need to really look at how you\u0027re going to make sure that you\u0027re not creating actually making things worse for the network and even you know sending things into congestion collapse okay thank you I think we\u0027re done thank you thank you very much okay okay so I guess we\u0027re we finished early which is always good so thank you for coming and I guess everybody\u0027s going home in the next few hours few days and "
  },
  {
    "startTime": "01:43:05",
    "text": "have a safe trip back and next time for people who came from far we\u0027re going to be the ones the people on the east coast of the US are going to be the one doing the long trek so we\u0027ll see you in Singapore hopefully not too jetlag thank you "
  }
]