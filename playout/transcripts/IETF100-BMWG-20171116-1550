[
  {
    "startTime": "00:05:26",
    "text": "this is working all right so we\u0027ll kick off with this while we meet Eko meet Eko meet Eko it\u0027s like Beetlejuice Beetlejuice beetlejuice all right so we have to we can we can make do so we\u0027re a few minutes late starting I had to install an HDMI adapter and a new driver and reset my whole system so everything I queued up to show you I\u0027m now gonna have to open during the session isn\u0027t that fun so i\u0027m al morton co-chair of the benchmarking methodology working group and this is sarah banks co-chair of thank you so welcome welcome to our our session at IETF 100 this this this group is we were overlooked in the mentioning last night but this group is as old chartered wise as the THC dynamic host control working group I think they\u0027ve met one more time than BMW G but but they were both chartered at the same time so so we have that honor and that\u0027s why I didn\u0027t want to miss this one for sure okay so we\u0027ve done the introductions you\u0027ve all moved relatively close to the front thank you for doing that and if you you\u0027re not subscribed to the BMW G mailing list that\u0027s how you do it so unknown it\u0027s now Thursday afternoon you should have seen this about 40 times but IPR is important here you have to disclose it I don\u0027t have the most up-to-date slide unfortunately but there is an update 253 78 I think that basically changes a few things IPR wise so please take a look at that I mean you\u0027ve you\u0027ve basically had the chance to do that and your registration and everything okay so here\u0027s our proposed agenda we we have a note taker Sarah it\u0027s Neville oh we might very well yes yes so so welcome to the work group "
  },
  {
    "startTime": "00:08:28",
    "text": "and your yes okay good thank you so before we get going here we circulated the blue sheets and I think almost everyone has signed it anyone not signed the blue sheets now okay Sarah is gonna monitor Jabbar so if there\u0027s any Jabbar activity we\u0027ll pick it up there we\u0027ve talked about IPR we should also mention meet echo we have one of our presenters Sean woo on on meet echo there and one other participant mister ding I think it is it\u0027s a little hard to see for me at least so we\u0027ll be watching for participants to queue up and in any case so this is the agenda will quickly do working group status and talk about our Charter and milestones we\u0027ve got one draft still in actually two drafts on Sdn controller performance they\u0027re in working group last call finishing up and one draft that we\u0027ve sudo adopted on evpn and Pb Pb be evpn benchmarking there that\u0027s actually two topics that were combined and I guess we\u0027ll get a status a little discussion about that today mostly from us though right the chairs yes yeah so then we have a series of new proposals our remote presenter Sean Wu will be talking about the network service layer abstract model we have updates for the back to back frame of benchmark which is part of RFC 2544 please find and sign the blue sheet sir thank you and then we\u0027ll have a fairly brief discussion of the updated benchmarking for modern firewalls kind of proposal which which really was just described for the first time on the list today we known it was coming but it came a little slower than we thought so at least we have at least we have something to what to look at there but then after looking at these new proposals and reviewing the old ones briefly we\u0027ll look at the the reach are during text will consider what would we would might want to modify additionally and then we may look at a few milestones if if we\u0027ve got the wherewithal to do that and I actually think Warren will join us today Sarah our ad advisor you said he had another meeting but I think that other meeting was cancelled I think it was DNS SEC yeah so he even so he may well be able to join us any any changes or bashes to the agenda seeing none that\u0027s "
  },
  {
    "startTime": "00:11:31",
    "text": "good sir please please grab the blue sheet there and sign in you\u0027ll see I\u0027m recruiting blue sheet signers because we\u0027re we\u0027re we\u0027re late on Thursday afternoon and that usually that usually affects attendance the only thing that will be worse would be to be after lunch tomorrow I think so in any case I\u0027m sorry good question Sarah asks how many newcomers do we have in the room please raise your hands why five very good so what I always say when newcomers join us and we\u0027re and you\u0027re very welcome to join us this is a very easy group to join if you have a testing background you\u0027ll you\u0027ll fit right in here and we have a supplemental web page which Sarah was nice enough to restore to the interwebs which which in a few paragraphs tells you how to get involved here very quickly so that\u0027s on our you know our data tracker charter page so you guys will see at the end we\u0027re talking about proposals and retar during discussion what that really means is as we\u0027re looking at taking on new work you guys are joining at a perfect time because if there\u0027s something you guys are interested in and you wanted to bring in now is a great time so I realize you\u0027re new or maybe on a Thursday you\u0027re four days into your first IETF so if you have questions about that let us know but now please don\u0027t be shy at the end when we get to that make sure if you have ideas let\u0027s hear about them and Al and I can help you even after the meeting on what next steps are and how to bring that work in and what have you I knew or tend to use join us please grab the blue sheets er which is uh and pass it back there perfect thank you so much okay so on so other than this about on no bashing of the agenda seeing none let\u0027s move on all right so here\u0027s our quick working group status folks I\u0027ll bet this thing is supposed to be turned on we went through we went through a whole I am meeting and that I mean that\u0027s that\u0027s gotta be it right Wow okay right right usually you can turn them on so meet echo meet echo meet echo we we\u0027ve got a microphone out and we\u0027ve got a speaker monitor which is not turned on they\u0027re supposed to be monitoring audio to pick this up I mean I mean I mean that we "
  },
  {
    "startTime": "00:14:32",
    "text": "could do that too but I can\u0027t so here\u0027s the quick working group status as I said we\u0027re in group last call is just about to end for the SDN controller drafts we\u0027re tracking many proposals here\u0027s a list of some of the proposals which we\u0027ve just I talked about in the agenda but we\u0027ve got more status some really good news here look at the list of for RFC\u0027s that we\u0027ve completed in the last interim period but we\u0027ve I mean the the reason we\u0027re reach our turing is fairly obvious we\u0027ve actually been really productive in the last couple of years or so and and and believe me this is a group that that works long and hard on its RFC\u0027s to push out for like this is is pretty amazing I can\u0027t remember this ever happening in a long time right so discussion on the agenda we\u0027re gonna be talking about the Charter we mentioned that oh and here\u0027s the here\u0027s the link to the supplementary BMW G page I knew it was in here someplace this is on you know encrypted dotnet and Sarah was kind enough to provide this after one of the cable providers discontinued my residential web pages so no problem for that here\u0027s our current milestones just one left on the current Charter and that\u0027s that\u0027s also a good state to be and it means that we should be considering proposals and looking at retiring so a little bit late with that one but we\u0027re not going to worry about it not not your fault so when we when our drafts are reviewed by other areas and it\u0027s a good chance to mention our our scope and charter here we do all of our testing in an isolated test environment packets that we use frames that we use they all have addresses in an address space that\u0027s been assigned to the benchmarking methodology work and what that means is that if you see these packets on the live network you can discard them we don\u0027t want our packets to get out and the live network and we prefer the testing to be isolated so that\u0027s one way to you know to try to ensure that that kind of isolation have our own address space and so forth but the the main point I\u0027m making here is that what we want is for the security folks to understand if they pick our draft up cold and they haven\u0027t read our Charter they may look at this and scream what do you mean you\u0027re doing you know look at all this traffic you\u0027re sending them to the network that\u0027s got to be some kind of problem well it really isn\u0027t it\u0027s not going into the network it\u0027s a laboratory isolated testified so we we remind them of that in general and that this should be part of all our graphs let\u0027s see I think this may be this goes too far here "
  },
  {
    "startTime": "00:17:32",
    "text": "yeah yeah I think that\u0027s let me check yeah yeah so we\u0027ll look at the proposal summaries so we we\u0027ve adopted and in in some way shape or form this evpn benchmarking proposal so we\u0027ve got that all in green there and you can see the kinds of things that we evaluate whether there\u0027s a proposal written on you know written up for it whether it\u0027s in the scope of the Charter we you know we make the call on that ourselves and then get feedback from our ad whether there\u0027s a draft that supports the proposal whether we\u0027ve seen significant support at meetings and on the list and whether there\u0027s any dependencies and other notes so everything here we have covered for that and we\u0027ve had the adoption column on the list and I believe that was successful and so the last the last thing we need there is is a version of it that actually takes on the working group file name but but that\u0027s something where I won\u0027t be working toward okay so it\u0027s there\u0027s other proposals here that I\u0027ll just briefly mention this virtual benchmarking as a service we haven\u0027t seen much on that in a while and we kind of alerted one of the authors to it and at the last meeting and he said oh yeah I\u0027m gonna bring something in well nothing so that may well be dead the virtualized platforms testing but this was discussed quite a bit in Chicago but we haven\u0027t seen any activity on it since nevertheless we\u0027ve got a draft dated this year so I think we\u0027ll keep that on the matrix for a while here for service function chaining we did see something on that in July at the last meeting and for virtualized Network which sort of went on hiatus for a while and then came back we\u0027ve seen a new draft of that in July but it continues to have the issues that have been raised on the list and at meetings and so they they really haven\u0027t solved the problems just by keeping the draft up to date so that\u0027s that\u0027s kind of a liability there I\u0027ll mention that we\u0027ve got the new proposal from Sean woo going to talk a little bit later about the servus abstract model and then a new proposal from me on back-to-back frame benchmarking and then this other one on modern firewalls next generation firewalls so but that came in so late it didn\u0027t end up in the matrix all right so that\u0027s what we\u0027ll get to later with the retiring discussion any questions about the working group status okay all right so then let\u0027s let\u0027s proceed let\u0027s proceed "
  },
  {
    "startTime": "00:20:34",
    "text": "to our I guess the best thing to do is proceed to our web page here this is gonna be horrible Wow okay so which which one would you like me to bring up that\u0027s what I mean it\u0027sit\u0027s meth okay so as al mentioned the SDN controller draft is in the hopefully last group last call comments welcome we were just and I\u0027ve done and now I saw feedback from you I think yesterday where you caught a snafu on the editing side with a cut-and-paste error and then an additional comment that I need to work through with my co-author so we\u0027ll we\u0027ll do that and revise and resubmit but again it is working for class call you guys are new so please if you have comments on it now now is the time now is the only time you\u0027re going to get the comment on that particular draft we got a dead mic there as well as alright great where did you press the button thank you great thank you thank you any questions on the SDN controller draft alrighty then we move on to the EVP n yeah so the author there is a student Jake ax he\u0027s been coming to the IETF meetings he\u0027s based out of India and couldn\u0027t make it to this meeting this time I don\u0027t see him logged into the meet echo either so he brought the draft in last meeting there was a fair amount of I would say spirited discussion in the room about the technical and the editorial content of the draft we do too quickly I would say we we almost always ask that we have discussions on the list but because there\u0027s been a huge outreach I think with the IETF India community and making sure that folks are comfortable I did discuss with students offline and pointed him back to the "
  },
  {
    "startTime": "00:23:35",
    "text": "minutes from IETF 99 where the content some technical things for example his test bed wasn\u0027t very clear what he was testing at all and while he could verbally or I think he was verbally trying to explain it the document needs to typically read if he\u0027s not here so what I\u0027ve asked him to do as a co-chair is to go back and review the IETF 99 minutes and addressed the technical commentary and if you can do that and I will help him as an edit or as an from an editorial function I will help him with the English or just the editing sometimes doing your first draft can be daunting so we we are here to help we\u0027ve all been in this position but well I don\u0027t know if you ever were I feel like you might have come in knowing how to do it all but I certainly did not know how to do it all when I first joined and I was a huge help so we\u0027re we\u0027re here to help especially when you\u0027re new doing it the first time we realize it can be a challenge actly Mike my first draft looked like the dog\u0027s dinner I was using a word template and I ran a special thing on on the template which you were supposed to some little script supposed to fix the carriage return line feeds into something else and it actually deleted all the whitespace ran the whole thing together and I looked at it and said well I guess there must be some additional processing at IETF where they fix it up so I submitted it that way and and then and then I asked Matt Mathis about it and and he said oh no they don\u0027t do anything so the first one was a true nightmare and and it was it didn\u0027t take me too long to ditch the word template but yeah that\u0027s actually a good advice so anyway I mean but that\u0027s an old story you know like like 19 eight or something don\u0027t be ascared of the word templates as the non engineer at IETF I know it\u0027s not common to say that out loud but I live and die by the word template so well it\u0027s very good work joe-joe touch put that together and I guess it keeps it up to date so that\u0027s that\u0027s great so from here I\u0027m expecting I will ping Soudan if you want to assign me that action after IETF 100 to make sure that he understands that we\u0027ve adopted the draft that we do see the value not to be discouraged by the amount of feedback that he got because it was a fair amount of feedback but I think the draft will be much better for it and then once that comes in I\u0027ll ask him to post that explicitly on the BMW G list and if you\u0027re interested if you have experience here please read the draft and then likewise I\u0027ll preempt al before he gets to say it when you read somebody else\u0027s draft well the con onus is there that they\u0027ll read yours and that\u0027s a good thing getting multiple eyes on a draft is a good thing so that\u0027s right and that\u0027s how you join the group really is by reading a few drafts that we\u0027re working on and providing your expertise in form of comments where\u0027s the blue "
  },
  {
    "startTime": "00:26:37",
    "text": "sheets all the way in the back there\u0027s a there\u0027s a blue sheet coming toward you sir please we sign it thank you great thank you alright one further point on this Sarah and and that is some I seem to remember that Sue Dean was looking for additional editor help I think you\u0027ve you\u0027ve volunteered to do that if there\u0027s anyone else who has evpn expertise we should also consider maybe another author as well to provide real the the technical background that might help out here yeah I think that\u0027s ultimately a question for sued in because at the end of the day he needs to either take on that help but I think the feedback he got from your colleague they might forget Jim Utara Jim thank you me too yeah was very valid I also think it might not have been received as well but as long as we captured it and and someone can implement it with expertise that that\u0027s that\u0027s needed then and and and really now that we\u0027ve adopted this as a working group draft we\u0027re sort of in charge of the editor list yeah for sure so I think doing something that I\u0027ve seen us do and BMW g1 drew you even before I was chair getting that cross working group feedback it\u0027s probably going to be key here yeah because we aren\u0027t going to get unless we have Jim in here every single time I think we\u0027re gonna have to take it to the routing area to get a review oh yeah which is good so we\u0027ll try that as well or do that early alright so you get some time to turn around the feedback yeah yeah that\u0027s will will will work this at a pace that everybody is comfortable with very good okay so it\u0027s fairly easy to find our drafts on this is the tools page by the way which I\u0027ve I mean this has been around a lot longer than the data tracker and I\u0027m kind of more comfortable using this but there there is of course the the data track of version of this and you can go there alright so let\u0027s see where are we in the agenda all right we\u0027re racing along here okay so Shawn can you hear us and can we can we get you in the queue for speaking yes hi okay hear me okay yes we can hear you perfectly Shawn that\u0027s fantastic great well I didn\u0027t well I\u0027m not no we move us so fast it\u0027s almost my turn yeah yeah well uh I guess "
  },
  {
    "startTime": "00:29:40",
    "text": "that\u0027s a good thing because we lose our note taker at five o\u0027clock local time oh goodness all right so hang on a second here I\u0027m I\u0027m finding you\u0027re finding your slides on my greatly reduced screen all right so I\u0027ve I\u0027ve got your slides up Shawn I suppose you\u0027ve got a remote display there yes I do great okay well first off welcome to the working group and and this is Shawn is yet another new participant but he\u0027s come to join us with a some knowledge of what we\u0027re doing and also a pretty good proposal in hand so let\u0027s let\u0027s have a look what just happened there no signal okay now we\u0027re back that\u0027s obviously pretty pretty hinky okay you can go ahead any time Shawn I thank you hello everyone I\u0027m Sean from the Juniper Networks I try the previous authoress Adeem it also from a Draper and I sure worked with him in the past on the EDP end as well so let\u0027s move on to the next slide or yet I\u0027m doing it right I just got to watch out what I touch here all right thank you so the network services layer abstract model is really a reference model there provide a converse Kelton of how we would define at the document the benchmarking methodology based on the EM data structure so I have read a quite a few our past our FCS and a draft from BMW G and the first question is do we need another modelling or do we need another methodology in general since we have already many existing standards out there so let\u0027s take a step back and consider our traditional methodology you for the benchmarking I think I\u0027ll mention it before is that we typically looking at the black box level testing and we\u0027re looking for the external characteristics of a device or a system so there\u0027s a few challenges as we the networking technologies have evolved over the years for example we\u0027re looking at the black network testing instead of giving testing folks on a single device or a set of advice in many cases that the user will be presented it was a "
  },
  {
    "startTime": "00:32:40",
    "text": "private vertical how do we do it so we\u0027re looking at external characteristics of a network rather than a device or set of devices the ear model has made a significant progress over the last couple years and the direction of the year model and what we are doing here is complement but on two different directions what your model has been typically doing is trying to define almost every aspect of a technology or protocol how the controller can use a vendor agnostic way to configure a device using a setter the very detailed commands but here the abstract model is trying to use a similar scene set of the scene taxes but I only retain the high level which is relevant from a service outlook perspective so that will leave a lot of details out only folks were the external characteristics another kind of hub buzzword is intent-based networking and I\u0027m not sure how you already are familiar with the intent based work networking so traditionally a user interact with the device via a set of configuration and the Yamato it\u0027s just a vendor agnostic way to do it but we have evolved a using the Sdn controller that it will only require user to provided a very small subset of within this necessary intention so that are based on a lot of the machine learning and telemetry later the Sdn controller will automatically provision the servers using a set of the growing number of the underlying devices so we no longer have a static asset of the configuration instead we were actually benchmarking the intent rather than a set of the devices where the concrete configuration another challenge is the scale and dimension the unit dimension those scaling and unit dimensional benchmarking is often the primary focus of testing and typically it works great when is in the unit dimension and the ones adding the additional dimensions which the motif services edge in many different cases we that\u0027s where we start to seeing a problem so when you have the ability to abstract the multi-dimensional Network and into a "
  },
  {
    "startTime": "00:35:40",
    "text": "simpler file model that we can really test it out in the lab and finally the converge your services and there has really blurred the boundaries between the different layers today like if we want to send a layer of free traffic we know not necessarily require a layer 3 interconnect or layer 3 based the product comes in many different cases for example the evpn with type 5 route it can actually not only exchange the layer 2 mac database or mac route but also has agreed to exchange the layer 3 the ipv4 ipv6 routes so the boundary of related to an array of 3 is kind of intertwined these days so we\u0027re using this service model we\u0027re trying to come up with separate the underlying technology and the service profile which basically is a set of the customer requirements if I\u0027m a business perspective so this is why we are trying to propose a simplified a year model to for the model network services for the benchmarking purpose next slide please so a little bit busy slider here or I should have a put a box in the middle this is the count there\u0027s a four key components in this model some of the old existing that we have been using for decades some of the top the component is the relatively new so let\u0027s start from the bottom if you look at in the middle column so the bottom is the inventory the inventory refers to a set of the notes or hardware software resources and eating a bunch of the connections wide or Wireless they form a physical topology that is the underlying hardware layer that we are dealing with and moving up a bit I separated the logical topology from the physical topology the reason being eating the same set of the physical topology in a lot of the benchmark testing you know we can easily create the tunnels to form a they\u0027re completely different view of the topology and you have the a protocol adjacency where the device is the far apart from a physical perspective but they are really next to each other in the logical perspective we can use some of the tunnel technology like a V X LAN and POS tunnels USPS the gie tunnel that those are the technology can really change the perception of the higher application how "
  },
  {
    "startTime": "00:38:43",
    "text": "they view the underlying physical topology the service provision which is the dark blue bars those really the static configuration of a testbed if you\u0027re looking of the infrastructure this is the focusing on IGP bgp the MPS transport and the potentially the bridging those define a set of the communication protocols between the networking devices provide the baseline connectivity and finally on the top on the left side that which is a service layer this is the fund a set of the ultimately services received by the user perspective we have the internet exchanger provider we have a data center Metro Ethernet and so on forth so on the left side of the five different layers those are not new and we have been using for decades the trying to capture that eating the image or in a service provisioning but what\u0027s new here is to use a set of the e/m based data modeling to describe or document those key elements and to provide the baseline support when we if we try to zoom in a particular service benchmark so next to our boxes wanted in a dark green it\u0027s a service profile I think a lot of times that in the game model we typically define the configuration which is a static is scale static configuration the service profile is a more referring to a setup with a dynamic elements of the network there\u0027s a four subcategories the traffic emulation those are not new and typically a test vendor that will come of the traffic profile the protocol emanation emulation to exchange the control Briony of data with the network and the test what\u0027s news in addition that a to current subcategory was introduced the one we have to have a certain set of the SLA or how to describe the resiliency of a network using a set of the timers like how quickly the network will respond to a failure scenario and finally we need to a set of other events that we\u0027ll need to define a common event like no link of failure the control protocol churns and some of the mobility the mobile could be a station moving from one location to another or VM motion that aware we quickly provisioning a virtual machine from one data center to another so those "
  },
  {
    "startTime": "00:41:44",
    "text": "are the four category that we are looking to define what service provider so this profile really owned by a customer versus a service provision is owned by the provider an ISP or cloud provider and finally on the top of the resource utilization the resources described how much it\u0027s basically it\u0027s a health indicator of the network and the particular provision which is a set of the static configuration and a particular set up with a loader which is described in the service profile and how busy the network is do they have enough capacity to handle additional load of those things okay let\u0027s move on to next slide but if any question from the room and feel free to stop me and definitely want to answer if we you have acquired doubts or questions to eat more clarifications so here\u0027s the okay sure thanks Ron okay here\u0027s the set of the design principles that are we trying to come up with this is service model one is we trying to leverage the existing MO I took a lot of the tools IT efforts were all daily tracker there are tons of the efforts ongoing or past there are 2500 yen related RFC\u0027s and more than a hundred the internet draft is being actively worked on so we did not want to reinvent the wheel we want to take it existing what all the work has been done in various protocol areas but that we don\u0027t want to take or that\u0027s what we want making sure only provide a sufficient set of the keywords to this abstract model but not exhaustive we will leave a lot of additives out for example the IP addressing and roundest Englisher and those are necessary for a real production network provisioning but not needed here we were trying to look at the aggregator view from a network of high-level and unnecessary zooming in down to the device level an additional set of the rules we had to introduce is the distribution model we\u0027re not trying to mirror the exact how the network is operating but instead we\u0027re trying to look for a abstract the distribution model to use a very few parameters to model the existing set of the routing entries or map database or even a tracker profile and the service model also need to provide a view from different perspective the Cosmo the provider at a manufacturer they have different folks about how they "
  },
  {
    "startTime": "00:44:44",
    "text": "need to benchmark for example the customer is only looking at the network capability not necessary care about the underlying technology that they provide the service profile meaning that I just want to move the traffic from place a to place B they don\u0027t necessary care about which we ended up the equipment what technology use EDP and avi POS they probably don\u0027t care the MVP on or just vanilla IP multicast those are just a choice or if I\u0027m going to provide a perspective it\u0027s not necessary from customer so the service model is really focusing on the a external characteristics which is the from a set of the surface profiles and a finally not but not least as we want to make sure those servicemen were calm rated the new requirements from the vnf there\u0027s a lot of the discussions as al mentioning the agenda data the sta and the D the virtualized the platform and of those in need to be taking into consideration not only the virtualized platform but also virtualized network so ok well let\u0027s take a look at an example in the next slide again there\u0027s a lot of the content data and I\u0027m not sure if you can see the clearly from the behind so there\u0027s only this is not a complete a profile it\u0027s a subset of the the model that is it broke into four different categories on the top the three one is the service definition here is example of the layer two services in the middle is the traffic profiles traffic profiles are really you can consider it as a service profile what really the customer is a program to put a load what kind of a load that is prolonged to network that is going to be handled by the underlying service and on the right side is the resource because when we do them benchmarking and we have to look at the not only the final throughput but also looking at the health indication about a network and again this table is not the black network black box testing every we will have to look at the performance in indication that we\u0027re looking at those KPIs of the devices and on the bottom the bottom is the resiliency the residency is really defined a set of the timers define how quickly the network or the device will recover function this is some of the common events for example the failover in a motor homing scenario some of the know the link of failures the ISSC or the in-service software "
  },
  {
    "startTime": "00:47:44",
    "text": "upgrade and how much time that would be allowed to the device to recover without breaking the control sessions so by a small set of the data we expect the user or the tester will take the high-level parameters and generate the configuration depending on the underlying device type and all that we always care about is get a set of the validation from both the resource it basically a setter of the KPI and the performance in the term of the forwarding or the scale of the control plane it can handle as well as making sure they have in demonstrate enough resiliency and me those threshold for various types of the events so this is a there\u0027s a lot of work underway to make that really useful and making it more complete so that it can be used to profile various types of networks so I think that the decision is really hard when we trying to distill a large number of the existing yen data model into a very small subset and only keeping what\u0027s necessary that\u0027s the hardest part of this proposal okay the expert yeah come here here\u0027s a question Shawn from Al um it looks like looks like most of the most of the things we\u0027re looking at here the elements of the yang model so to speak many of them are provisioning or configuration values like for example we\u0027ve got the we\u0027ve got the traffic profile here which would be it would both be input to the device under test but also the input to the traffic generator to to to use these specific frame sizes it would be good to distinguish between what appear to be the measured values over here on the right under forwarding as sort of less about I guess all of these are potentially measurements here under resources aren\u0027t they yes the the resources snapshot of the current kind of load indication and also the final outcome of the I guess the results of the test yes good um and it and it\u0027s it may be worthwhile just as a you know as a quick feedback that occurs to me here that that we\u0027ve got we\u0027ve got these what "
  },
  {
    "startTime": "00:50:45",
    "text": "we call sort of secondary or auxiliary metrics like the CPU utilization and the memory footprint and so forth those are those are good to know but we we always set them aside from the benchmarks that we that we try to measure the benchmarks of course like like throughput being the primary things that we\u0027re after CPU utilization at the measured throughput is a there\u0027s a good thing to know and probably the kind of information that will will particularly want to supplement our benchmarks with so that we\u0027ve got a better chance of improving how our benchmarks are used in network engineering in the future yeah absolutely I think there\u0027s different level the importance of the resources sections and also this is just showing one snapshot of the steady-state and also showing we probably will be interesting hood is a PQ tradition and utilization in event of those failure scenarios how the network will respond because in a like say 10 in 10 based networking those in tradition will matter and dynamically change the configuration and back to the service provisioning meaning they will dynamically move the component of a certain function into different elements within the network so that\u0027s why I think it becomes more important to over the time that both the forwarding and the snapshot of the resource transportation need to be captured as a single set good Sean I have a question so I\u0027m not sure if I\u0027m clear based on what L asked are there under the resources profile are you looking to set the values are you looking to say this is what you would expect as maximums what is the intent of the resources configuration here resource is not a configuration resource it is a measurement as a snapshot and but also we can provide some of the references threshold meaning that typically under this is scenario that we expected the device to reach certain performance so then just to clarify you\u0027re saying that this would be populated at the end of a test or a test case run and it should most of the value there should be captured and as a result of the test while but in some cases the reefs also have a predefined a threshold that can be a more kind of a benchmarking a common part for them but we expect that as the nine rated at 100% but it may not reach to it but most "
  },
  {
    "startTime": "00:53:48",
    "text": "likely the original intention yes I do mention its capture the results not necessarily prior to the tester it\u0027s a configuration it\u0027s more kind of a dynamic snapshot all right then not to beat this up so I see under your traffic mix you\u0027re showing sort of classic pics from 25:44 are you accounting or allowing for I mix and so you would just specify your non-standard your I\u0027m excretion here in some way I guess so the frame size the traffic or file is a way to provide a user to either pick a predefined like RFC year two five four four and a profile or they can construct their own distribution based on the real network measurement to mimic the real environment here not necessary to tell which one the user how to what valley it is it just provided a way that if they want to have a customized the profile those are the very they can provide it and the underlying processor of this model can generate the real traffic on the test emulator based on the in limited instead of the parameter from the user thank you sure very good okay all right next slide moving right along okay so here\u0027s a few use cases that I can think of how we can if we develop spend time developing those abstract model how can we use first of all is to have a formal way to document in the benchmarking methodology and the results in a more into exchange but data form act and once a library of the source model or network deployment scenario is been developed or captured so here\u0027s how we can I can see that the being used first war is an a map between the real network production network to the abstract model it can we can have a set of a tool to discover the existing network in tradition exist network baseline and convert those at your configuration probably is gonna be a Java set of the data into a simplified abstract model once we have the model then we can feed back into the test lab for the benchmarking for the design choices and do the F what if scenarios in a finally we have the test results in a feedback to the the model to document and to store the data for the further "
  },
  {
    "startTime": "00:56:49",
    "text": "analysis and those are results the results are from those analysis can be further fed backing to the network to improve the design to optimize the resource assignment to those things but what I here on the lower right corner is really kind of a nutrition facts for a network and this is to provide an extra it\u0027s a really hard decision to which element is more it\u0027s important that we should be included and those in the network effects sheet I know there\u0027s a lot of data sheets out there typically that we have follow the the benchmarking RFC\u0027s and we already have a set of those but I think when we move it on and how we can define those that elem information in the yen data model and provide a more English interchangeable format so that a user can use the same set of a syntax that generate the report they like okay I think that\u0027s premature next slide so here\u0027s next step you know I definitely need some help from the work collaboration and provided the import various type areas especially for the SDN area how we can make this more compatible model to work with the virtualized Network and we need to validate to the end keywords and making sure that we have to run the linked for the year and the created sample detail the for complete profile for layer 2 network or could be layer 3 it\u0027s just picking a sample and then all these feedback once we hear more and the world updated the internet draft that\u0027s all I have thank you well thank you Shawn that was a great and very interesting presentation it was our our first exposure to yang models here in the benchmarking methodology working group and I think now we can probably say that the net confiscation of the IETF is complete that\u0027s the the term that people are thrown around for how how the reason that everybody in the IETF seems to be working on Anna yang model somewhere so we we have a we have a question at the microphone and please identify yourself CERN and escalade Pedro Martinez from any city and my question is that how do you think to deal with data and actually the benchmarking stuff you know you have some kind of four men smoking you have you must have some kind of algorithm and also some data to input in to the to the protocol or whatever and then some reference output to compare that where "
  },
  {
    "startTime": "00:59:50",
    "text": "do you plan to fire and this data and what in that sense how do you think that it would be done with your model yeah I think the model thanks for the question by the way and I think a year definitely right I\u0027ll point out the difference between the model itself and the data to be captured and how the data can be used analyzed for the further improvement of the network or benchmarking so if I understand your question correctly is that the how can the data being used for to reference maybe reference the what expectation or how the data is gonna be huge due to fed into this model maybe you can elaborate a little bit sorry no sorry more than that is which kind of data are you planning to use are you proposing to use okay so like the real tracing data from the network or something so so it\u0027s the question in the context of this slide here yeah you have in the law in this slide in the lower left you have this design immense marketing is provided to a test lab where there\u0027s you also need some kind of data to input today to the whatever protocol software or whatever you are trying to are testing where is that data coming from I mean okay yeah so so the question is that where this data is coming from to be fed into the test lab so that the test lab can do their test right now yeah okay so this is the trying to use a set of the a subset of the gear model take it for example layer 3 deep here layer 3 VPN has so many arguments it you completely define a layer 3 VPN offering what this model does is to extract a subset of the key elements for example we only tell the test lab I need have a hundred sites say I did a total of the hundred thousand routes but not necessary tell the test lab the which router has how many routes or which route I had how many VPN instances what the data you provide is an aggregated view so that a test generator will use "
  },
  {
    "startTime": "01:02:51",
    "text": "this high-level data from basically is describing a customer requirements for network and then distributed into the individual devices based on the definition if we go back to the one slide example probably that can be explained better yeah ok so in this particular case is that we this model defines what the key elements is needed to describe a network sufficient number of the elements and the the actual value is not set by this data instead it should be set by it\u0027s a the test engineer and say hey this is a target I have a bigger router I need to increase the number of the global Mac count instead the model only defines what to define but it doesn\u0027t define the actual value I\u0027m not sure if that answers your question answer it if it doesn\u0027t define the actual value I think one of the sort of core tenants that we have in BMW I feel like I\u0027m great repeatability if it doesn\u0027t define the actual value then how if I run the same test ten times in a row for example how do I know that I\u0027ve run the same test ten times in a row or how do I know I\u0027ve run the same with the same input values each time so that I can compare apples to apples the results do you see what I mean well yes but I think the value when we do a report a test say this is the describe the profile the profile will have a list of the elements end of the value yourself but our proposal here is just to define the skeleton of the profile but the tested repeated test it will have used the set of parameters there were you the same set up the number the pass on the test generator so out of the 10 attempts they will hear the same number so I think there\u0027s a question is there\u0027s a profile contain the value yes it does does our proposal define the value it doesn\u0027t our proposals only to find the key elements and but certainly we can provide the values but as vadi will change over the time depending on the capacity never underlying network can offer so I don\u0027t think I answer your question maybe so Shawn I think what you\u0027re saying is for the slide that al has up right now yeah the profile itself is in essence the methodology you just happen to provide in the example sample test data that the tests are filled in but I think what you\u0027re saying is it "
  },
  {
    "startTime": "01:05:51",
    "text": "would be up to me to take the skeleton without the values and then as the test case or the engineer fill in the values and record exactly what I tested and then of course I could repeat with those same values 10 times in a row for example that\u0027s correct yes that\u0027s correct okay thank you very good good clarification yeah so um there\u0027s no one else at the microphone well um I think we\u0027ve got a a decent idea of what you plan here Shawn and I think I think it will be I\u0027ve got your next step slide up we should have the call for collaborators on the on the mailing list yeah absolutely and I think looking for additional help and if anyone is interested a the really goal is to provide a simplified thermal profile on the network so that make our benchmarking easier anymore interchangeable right right and and I encourage you to continue to to flush this out in terms of the where to network benchmarking example okay sure alright anything else folks okay very good I think well well thank yes thanks for your thanks for your your proposal and your presentation both both very good and informative here we\u0027ll we\u0027ll see ya where the work working group wants to go okay okay all right so so next on the agenda here is the back to back frame a benchmark proposal that\u0027s it\u0027s obviously going to update our se 25:44 there\u0027s just one section of RFC 25:44 which would be updated here and [Music] so here we go um so that so the draft was prepared and and circulated on the list made a little announcement of it and as a as a little background for the for this proposal RFC 25:44 subspecialize this measurement measures the back to back frame benchmark that\u0027s what it\u0027s called but it requires a "
  },
  {
    "startTime": "01:08:53",
    "text": "little more really the back to back frames is more a description of the methodology than it is what\u0027s actually being measured it\u0027s it\u0027s defined in RFC 1242 as the longest burst of frames a device under test can process without loss and they go on to explain the tests of this parameter are intended to determine the extent of data buffering in the device so in 25:44 today there is in fact a very concise objectives expressed a very concise procedure and also a very concise reporting for this benchmark it\u0027s about five paragraphs so when when I when I looked at this testing in the context of testing these switches in the OPN of the V switch performance project we made some measurements of this of this benchmark and the results are basically shown in these two links here to references the reason I included the links was because in the printout of the RFC something went wrong with the formatting and the URLs went away so it wasn\u0027t what wasn\u0027t much help well it was it looked to me like it was in a place where they would be displayed but apparently you got to just append it in the title or something and that makes it show up in the reference so um so I\u0027ve got that straightened out here for at least for a temporary basis and as I said we I I circulated and discussed the are our results from the V switch performance benchmarking at some length at the last meeting I\u0027ll talk about that a little bit now but you\u0027re welcome to take a look at the at the slides which is which are the this first link and and actually you can see even more detail spelled out in the this wiki page where we were working on on lots of traffic generator testing and comparisons there but looking at the back to back frame testing in particular so when I ran the tests and this is a as I said this is a test where you\u0027ve got the traffic generator sending traffic to a device under test and it passes through the device under test so it\u0027s either routed or forwarded or encapsulated or transcoded or you know whatever else whatever else the device under test does to the traffic it does it and then it passes that traffic back "
  },
  {
    "startTime": "01:11:53",
    "text": "out the other side for a reception so the there it had been noted in the past that the back to back frame benchmark had some problems with consistency but we were able to test this over a series of months and actually over a series of two different hardware platforms and we saw a very consistent results of between the two for fixed frame sizes and it was it was somewhat variable and a few of them but we came up with an explanation for that but the sort of the surprising results were for large frame sizes you saw the range of frame sizes that Sean just showed us now all the way up to a fairly high values 64 all the way up to you know 15 1,500 approximately white frames but there so the the frame length reported for a large frame sizes was unexpectedly long in other words it was on the order of 30 seconds of storage in the under test we knew that wasn\u0027t true and so it required us to investigate that and the test equipment we were using didn\u0027t report any kind of error when it when it said I just produced a burst of 30 packets and that\u0027s as far as I\u0027m gonna go and so that\u0027s the longest burst this couldn\u0027t handle that\u0027s it turns out that that that that was erroneous data the the test generator was reporting I\u0027ll explain that a little bit later the calculation of the extent of buffer time in the device under test helped explain the results with all frame sizes it turns out that some frame sizes like the the highest frames the device under test was able to process them at full back-to-back frame line rate so in fact while the processing is bleeding off the buffer as fast as the frames arrive you don\u0027t get the buffering that you\u0027re trying to measure in this test now that\u0027s a problem if you don\u0027t report it that way so that was one of the things we want to change I think about the procedure and it was observed that the actual buffer time and the device under test could be estimated using the results of the throughput tests previously conducted based on RFC 2544 so so that the final conclusion there is that the throughput test results actually if they\u0027re if they\u0027re paired up with the back-to-back frame tests they can they can also be used to reduce the number of frame sizes tested because only when only or only when we have a frame size which is faster than the the device under test can handle do we generate a queue length and eventually a tail drop or a queue overflow where the burst of packets that was submitted causes some lost and then we can conclude that the burst was too long so "
  },
  {
    "startTime": "01:14:55",
    "text": "we have to reduce the burst size and and then continue with the trials of the test so you really want to distinguish those two cases where the the packets sending rate with extremely large frames is too slow to create a queue and and those which will create loss so we begin by expanding the the back-to-back frames test method here and and so we have identified that the 2544 throughput test needs to be a prerequisite test now absolutely conducted before him so the test setup and configuration much math must match between the two tests the record we\u0027re going to use the same recommended frame sizes and we must be using the zero loss condition which is what 2544 mandates or throughput and then we can reduce the frame size set for back-to-back if we if we compare our delivered frames per second with the theoretical maximum which is a the green bar here in this case so on this graph and this comes from the OPN efi testing we ran tests at 64 byte frames with the open V switch we saw I guess it was about 24 million frames per second with a VPP it was a little bit less in this particular test but they were both less than the maximum theoretical throughput so this is a frame size that we can we can test well to see if the device under test is going to be doing it well it\u0027s it\u0027s certainly doing some buffering it can\u0027t keep up the device under test can\u0027t keep up with the the maximum throughput at 64 bytes per second so at 128 it\u0027s a little bit ambiguous it\u0027s actually very close to the maximum theoretical throughput and we\u0027ll actually see that in in the results but then at 256 or 512 there there we we get in in in both cases both for VPP and OBS they lined up exactly with the maximum theoretical throughput for frames at the mini minimum inner frame back gap as but back-to-back stands for so so what we can conclude from this graph is that most of our testing would be conducted using the 64 and the 128 byte frames and there\u0027s no point really for this particular configuration to go on and to do 256 and the higher frame sizes we\u0027re never going to see queuing and so we\u0027re not really going to be able to measure the buffer size so in the procedure we would list the frame sizes selected for "
  },
  {
    "startTime": "01:17:56",
    "text": "the throughput tests they\u0027re composed the tests are composed of repeated trials for each frame size a trial requires sending a burst length counting the fort first line counting the forwarded frames and the trials seek to they the trials seek the longest burst length that can be sent with zero loss measured or same same number of frames sent to the same to the number received and the test outcome is every time it\u0027s the burst length and we are only going to count the ones where we see zero loss so the tests are repeated n times and actually for the after you after you seeked and found the largest burst that you can send without loss then you record that and then you go on and repeat the searching again and so you do that end times and the reversed lengths are then averaged and the average length from n repeated tests is the benchmark value so that\u0027s a lot more detail than is currently in RFC 2544 but I think that that\u0027s the that\u0027s the set of things that we are looking for now so for clarifications so I I grabbed this right out of the read out of the draft so for each frame size we\u0027re going to calculate the following Maree statistics for the back-to-back frames over the end tests the average is the benchmark but we\u0027re also going to report the maximum burst length that we saw in the end trials the minimum and the standard deviation and further we\u0027re going to calculate the implied device under test buffer time and the corrected device under test buffer time as follows so the the average buffer time is the average number of back-to-back frames divided by the theoretical frame rate so what we\u0027ve got here is a calculation of the time that that is represented by the burst and that time is it turns out it\u0027s both taken up in buffering and frames that were served by the processing because the the device is attempting to keep up with the maximum frame rate but in the in the in the low packet sizes it\u0027s not able to so what we we calculate this total time but then we\u0027re able to correct this buffer time by figuring out the proportion of frames which were in the burst which will actually served and processed and and basically sent out of "
  },
  {
    "startTime": "01:20:57",
    "text": "the device on their test while the burst was running so in fact you can think of it as a a buffer which in the in the implied buffer time it\u0027s the it\u0027s the complete burst that buffer is the time is represented by all the packets sent in the burst in this corrected buffer time we we use the maximum theoretical foot throughput to figure out how many packets were bled off the buffer before one packet overflowed and this gives us an estimate of the the actual buffering time inside the device so we would report the results as follows for a given frame size like 64 frame octets we would report our average back-to-back frame length at the first here it\u0027s here it\u0027s only 26,000 so that\u0027s a good point a problem I\u0027ll probably want to boost that up so that it matches more the kind of millions of packets we\u0027ve seen in typical testing but so we\u0027ve got the average at 26,000 we\u0027ve got the the min and the max and the standard deviation here reported at at 25 527 thousand and and 20 packets and then the corrected buffer time which is let\u0027s see here it looks like that\u0027s about it\u0027s small it\u0027s a 40 microseconds yeah so not very much so that would typically report it in a table like this and in addition we\u0027d want to report the the standard the static and configuration parameters that are associated with the test so that\u0027s the number of repetitions obviously and the minimum step size that the device the tester uses to try to determine the burst length in other words it may not be it may not be incrementing the burst length by one packet that might take a very long time so that might be configured at at in a test with where we\u0027re trying to test millions of packets we might have a step size of a hundred packets let\u0027s say something along those lines and that would improve our ability to complete this test quickly so this is so a lot of this other than the average this is a lot of new information that we\u0027re requesting now we\u0027ve we\u0027ve kept the traditional average benchmark but we\u0027re asking to add this additional collateral information please sign the blue sheet sir you\u0027ve been here for 10 milliseconds too late so um so that that\u0027ll give you a feeling for the oh I think I think the "
  },
  {
    "startTime": "01:23:57",
    "text": "blue sheets are very good thank you Steve and and welcome to BMW Jane so so next steps know what as far as I can tell no one\u0027s actually reviewed read and reviewed the draft yet and that would be essential before we adopted it I think you know I I have to hold myself up to the same standard that anyone else would as a participant bringing a proposal here and then so once we get some readership and review and feedback we we could possibly consider I guess I didn\u0027t ask the room has anyone read the draft almost like a real light turn out who will read the draft yeah whose willing it was willing to do some do some work here great that\u0027s that\u0027s the kind of commitment we\u0027re looking to see so thank you thank you for that great in fact you can start reading it now well we I know I know so what we could we could agree to create a milestone for this work on the basis of this description today that we think this is worthwhile I\u0027ve actually proposed one there and then obviously sometime in the future after we\u0027ve done some readership and review but we\u0027ll hold off on asking that today we\u0027d ask her working group that this whole list of authors not me and and actually my my colleagues from OPM if the vSwitch performance project may may join me on this author list as well but but I wrote this in like two days over the weekend so I did get a chance to ask them they wanted to join it but in any case there\u0027s no guarantee even if we take up a milestone there\u0027s no guarantee that this draft would be the one that satisfies it other ideas are welcome so that\u0027s the way we play here so Sarah so I ask please that we read the draft and I think we\u0027ll come back to your suggestions they\u0027re out in London very good i we should ask if there\u0027s any questions or comments in any case and III want to do that because I I saw you coming to the mic may ask please say your name to mask what is the thing that you are looking to test using this methodology so when we do these kind of tests usually we are looking to test some particular you know component within the switch architecture such as queuing such as packet processing such "
  },
  {
    "startTime": "01:26:58",
    "text": "as buffering after processing or before purchasing might take away from what you described is in a way you try to check what is the capacity to buffer buckets before hosting events am I correct or can you I stay right stay right there there you may have a follow-up question what what I anticipate is that I\u0027ve in my mind and and the way I described it I modeled this as as one buffer and one processing stage that bleeds off the buffer the reality is there are many more than one buffer and there are many processing stages but at least one of them is the bottleneck so what we might see is the sum of all buffers up to the up to the processing bottleneck and and then queuing beat bleeds up or or grows out to the ingress interface before that so my word so you\u0027re trying to check how much buffering can happen before pocket cross is seeing cause these issues before the before the limiting packet processing that\u0027s right thank you for that good because just as a note usually we use these type of things also to detect how much worse absorption in terms of congestion a buffer can absorb which may result in you know totally different results in places within the switches that they I\u0027ve been thinking that the reason to have this correction factor to actually try to assess the actual buffer time or space that\u0027s available is that well actually one of the background things is that you know real traffic that doesn\u0027t necessarily arrive smoothly or continuously it it arrives in bursts and it may be valuable to know when a device that\u0027s doing forwarding or routing when that device pauses for a moment or two and and and the processing stops then how much real buffer is inside that we can count on to be able to smooth out these bursts I said so so so that\u0027s that\u0027s that\u0027s I think we\u0027re in sync on that thank you for their yeah good good okay please yeah um my name is Juan Gauri from PRI at tree so I asked you welcome yeah it\u0027s um what professor so my battery\u0027s about previous previous slide I mean the props are so many metrics there is um so what area six or seven things but this is currently work "
  },
  {
    "startTime": "01:30:00",
    "text": "area right are you looking at the oh yes yeah you\u0027re going back to that you\u0027re going back to the Chairman slides do you want me to put that up so everyone else can see it here while you\u0027re asking the question okay yeah oh sure sure no problem yeah there it is okay yes please some what about em the virtualized performing these and I understand that but what about the virtual light virtualization platforms is it is it the scope of each other no no no it but that\u0027s a it\u0027s a different draft that was prepared by Samuel Camus and Jacob wrap Jacob wrap one that we discussed in our meeting in Chicago it\u0027s it\u0027s it\u0027s sort of data center focused it\u0027s a follow on piece of work to the sort of the physical device data center benchmarking that we completed just in the interim period but they they are now beginning to look at the data center with virtualized networking as well so that\u0027s the plat work platform that they\u0027re talking about I\u0027m sorry for the shortness of the name there but but I can give you a link to that draft if you\u0027re interested in taking a look yes I make sure that I am interested in just like xxo packet accelerating technique such as DP decay oh yes so I just Kosar to the microphone there I think otherwise benchmarking benchmarking mass knowledge about those happen technologies I just want to create the new proposal over the next in this in this working group okay so I would be very interested in fact I\u0027ve been looking at potentially doing something down this path as well so if you have that draft as soon as you have that ready a with my chair hat on I think we very much encourage that it\u0027s very relevant to what we see in the industry and and how to benchmark that I think is a good thing and then with my chair hat off just as a participant I\u0027m very excited to read that so if you\u0027re going to take that on thank you we\u0027ll see you in London and please submit draft before London so we have a chance to read it and then we we can talk about it in the next IETF yeah you know I through email very very good and and be sure that you take a look at RFC 80204 which is where the the open platform for NF e V switched project provided some "
  },
  {
    "startTime": "01:33:02",
    "text": "considerations for doing exactly this work I mean that\u0027s the project that\u0027s the project that also contributed the test results that we just discussed and so we\u0027ve been you know we\u0027ve been testing V switches and and and now vite the cisco VPP virtual packet process are there as well so there\u0027s some possibilities for you know cross insemination of ideas and testing in this virtual switch and DP DK accelerated space in fact we\u0027re basically testing the plain vanilla OVS the DP DK accelerated one and VPP and DPP uses DP DK as well so thanks for your proposal that\u0027s interesting in fact um in general the RFC 81 72 talks about considerations for benchmarking in general in the in this virtual space and we just we expanded on that here for virtual switches in this one so that and that\u0027s a another RC that was published really just before this interim period so it\u0027s it\u0027s actually been five very recent ones that we\u0027ve completed okay [Music] okay so I think now we want to go to its the the next generation firewalls in fact that\u0027s what we right look at this yeah this is yeah this is really annoying oh wait I mean I can get rid of this at least okay all right so um I\u0027ve been asked to represent this proposal on benchmarking next-generation firewalls by the the proponents who happened to be a couple of a couple of good guys who worked with us here in in the past carsten or us and hovel and balla balla raja both from the european advanced network test center and they\u0027re currently working with a not profile not-for-profit initiative called net sec open informed to innovate network security test methodologies and they\u0027ve been looking at this for quite a while they want to strongly improve the applicability and reproducibility and transparency of benchmarks for next generation firewalls but also intrusion "
  },
  {
    "startTime": "01:36:05",
    "text": "detection and prevention systems unified threat management and and oh I guess it\u0027s and unified threat management solutions so this is very opportune that we have such an esteemed security area colleague here with us as we\u0027re discussing this yes yes he has to wake up now yes [Laughter] so they\u0027re currently developing test terminology and traffic profiles and they\u0027re focusing on the next generation of firewalls first and and that\u0027s the work that they would like to begin to contribute here in BMW G so they plan to put this you know these other things on the on the back burner for now and see how it goes with benchmarking methodology working group but they they tell me personally that they looked over many different standards bodies to consider where to take this work and to standardize it and they ended up choosing us for our ability to take up work quickly here also the you know the good timing with our charter reach our during efforts and so forth and and the fact that you know we have the attention of the industry here in in having done this work before RFC 35 11 is our previous effort in this area so well they they plan to submit their first draft sometime next week and they hope to proceed quickly through November in December and and so depending on on how quickly we we want to review this work we may take up an interim meeting perhaps in December we actually tried to have a nighttime meeting scheduled here when some of the folks from the US who are part of net sec open could join us but that didn\u0027t work out it turns out if that\u0027s actually not very easy to do so so we will investigate the possibility of an interim meeting it will be a virtual meeting - to hear more from the net sec open folks and what they\u0027ve got here is a table of contents which mostly is composed of the scope so it\u0027s focused on test methodology for network security device benchmarking tests in terms of performance metrics describes the test methodology to obtain repeatable results independently using different vendor test equipment by defining the full set of test configuration parameters this document will allow users to reproduce network performance and compare measurements benchmarking tests focus a set of key performance indicators we\u0027re all familiar with those devices such as firewalls next-generation firewalls intrusion detection and prevention devices well see this here they seem to go beyond the next-generation firewall "
  },
  {
    "startTime": "01:39:06",
    "text": "scope so that\u0027s something I would feedback I mean I think I think they should probably attack next-generation firewalls first see how that goes which is actually what they said in the message and then worry about this this other interesting stuff like deep packet inspection devices web application firewalls and and so forth but but I think you know we might consider adding a sentence in our Charter to be sure that everyone knows that we\u0027re we\u0027re we\u0027re willing to take on devices in this of this ilk if in fact the working group is so how let me let me ask the room now that we\u0027ve described this how is is there is there any interest in helping net SEC open here with benchmarking modern firewalls if so you can sort of raise your hands okay nobody here today personally a lot of my work stems from the company that I work for them we don\u0027t do we don\u0027t manufacture modern firewall those but certainly I think it\u0027s of interest very interest very relevant excuse me to the industry today absolutely and and when you when you look at the fact that in fact RC 3511 was one of the first ones I helped to finish up as a co-chair and and so that\u0027s a long time ago 20 2003 so yeah a lot has been learned in the meantime and if you remember we had Mike Hamilton\u0027s content-aware work yes yes well he was the original proposer that\u0027s why I always I always think of it think of him there but if there but if there\u0027s anything we learned from that work we need to bring that forward as well to that that\u0027s still relevant of course that that\u0027s been retired for a few years so and then the rest of this is fairly usual the test setup testbed calibration that\u0027s a good thing though and reporting and benchmarking tests and so forth and and they want to define traffic mixes here both know the stateful and and stateless stuff you know that\u0027s going to be interesting but that\u0027s that\u0027s something they they feel very strongly about it has to be reproduced and used by all the vendors the same mix I think that\u0027s if you wanted an apples to apples comparison that\u0027s the key and I think it\u0027s one of the places where at least for me you know 25:44 is great but the average packet size has evolved on the internet from Warmack started out in twenty five forty four times so for them to at least take a stab at defining traffic mixes that make sense to them so you can have an apples apples comparison across vendors isn\u0027t that what we all want yeah well that and and I think we "
  },
  {
    "startTime": "01:42:07",
    "text": "want to continue with the fixed size testing as well yes not discount all right but I think we have that covered yeah and I\u0027ve seen a couple of data sheets recently for devices in the next-generation firewall class and they are basically testing whatever they want at the moment so so that\u0027s the I mean that\u0027s that\u0027s the goal here is to get everybody testing the same thing so that we can have the apples to apples comparison without the speck mint chip yeah that\u0027s our that\u0027s our original goal okay so any further questions about that I encourage you to visit the next step the net sec open site and see what else they\u0027ve got going but I think that\u0027s a it\u0027s a timely proposal and one we should consider further especially after we\u0027ve seen the first draft of their draft okay well thanks for participating in that review and so back to the agenda so we so we\u0027ve covered everything here that we planned today except for the the sort of the discussion of any new proposals and the reach are during discussion so I would like to now open the microphone to any new proposals that folks would like to make although we did hear one along the way and since I don\u0027t see anyone rushing to the microphone I thought that I would make one myself in fact during the IRT F open session mr. Paul Emmerich from a Technical University of moongeun talked about the moon gen traffic generator and also some results that we\u0027ve some of us have seen in the industry where if you use a different traffic generator and there\u0027s quite a few choices out there today there\u0027s the hardware ones from Lexy Inspiron and of course several software generator generators like like moon gen and and also t-rex which has its own platform but can be run on on general-purpose hardware as well and there\u0027s a few others I won\u0027t try to mention them all but the the point is that we should we\u0027ve seen some sensitivity of the results to sensitivity is is to the generator itself and we suspect that that\u0027s due to the characteristics of the packet streams that the generators are in fact generating but they may be "
  },
  {
    "startTime": "01:45:07",
    "text": "generating bursts when they say that they\u0027re intending to generate a constant bit rate stream also we might recognize that more of the traffic in the network today is bursty than CBR so so maybe of maybe some of our streams that we generate should have some burst characteristics as well but the idea that that that came to me as as Paul was making his presentation showing the the stream generator characteristics was that if we have ideal characteristics that we\u0027re trying to match that a measurement of the stream itself would be very valuable and we could compare that with a tolerance template around the let\u0027s say the inner packet arrival times that have been generated compare that across you know a stream that\u0027s long enough to characterize a device under test and then for every generator that we\u0027re considering using in the various circumstances and so forth take a look at how well it conforms to this template of Tolerance kind of as a calibration of the the generators themselves and I think that we if we if we wanted to take up this work that we would need to add at least one sentence to our Charter to say that we will also look into this calibration so what do you think Sara I think the idea of having a test apology where your traditional D UT in the middle is not actually the D UT but rather the test tool itself is the D UT is a fantastically wild idea I\u0027m not entirely sure we\u0027ll make friends with some folks who have visited us in the past but particularly as we take on virtual I think as we take on more of the virtual testing and how do we particularly with some of the results that I was presented from the Opie nfe work that we\u0027ve done as you start testing there\u0027s a lot of push for not just physical testers where you have a Pina convolve but virtual testers where the traffic stays inside of the virtual machine and and I know there\u0027s a lot of controversy around that and how do we make sure it\u0027s a blackbox test but the idea of having the ability to test the test tools I think is something that we\u0027ve seeing or I\u0027ve seen as a equipment manufacturer coming in for my customer so has anybody else had experience with this no answers you\u0027re gonna be buying beer tonight at Pecha Kucha just letting you know so yeah Paulette Mike to Munich "
  },
  {
    "startTime": "01:48:12",
    "text": "so yes obviously I\u0027ve had experiences that since I gave the talk earlier today and it\u0027s really difficult to measure so this is like everything is moving to software package you know at us and now we are seeing that that they are not accurate but again to validate them validate the software package generator is another software tool doesn\u0027t really work because you get the same in your measurement device the same position problems as with your generation device so you then really need hardware to precisely calibrate it then the next question is what is an important or what\u0027s the right metric to or what do I tell events what is even acceptable may be some small bursts are acceptable maybe gave even what we want so I don\u0027t have all Anton antis I just did some work there and it was very very challenging and also yeah the results were kind of unexpected I thought we might find some some small deviation but then we found that the latency differs by 400% just because we changed the birth size was like Oh what is going on so could I then I agree I think it\u0027s hard I do think sometimes when we take on a draft we take it in and it doesn\u0027t have to necessarily publish out so if we get to the end of the exercise maybe we decide this is too difficult to do but at least we tried for me I think it\u0027s valid I wouldn\u0027t mind I had a class today and couldn\u0027t see your presentation and I\u0027m wondering if I could potentially convince you if we have time on the agenda in London presented here and then we could maybe ask a second time do we do we want to contribute or would we want to look into this sure this sounds like a great idea thank you and in fact um I\u0027m sure your slides will be available in the IRT F open yes they so we can we can take a look at those but yes absolutely I think it if we if we if we can pursue this then that would be great I\u0027d be very interested in following up on this as well also yeah great there I think and I think I think the minute the minute anyone in the test generator world gets wind of us thinking about doing this well will suddenly have lots of collaboration that\u0027s right something that I wanted to look into as but I do you have a package analysis I actually as precise as they came and this I didn\u0027t have any on hand so maybe that\u0027s and so maybe that\u0027s it maybe the first draft that we take on focuses on hardware and if we can get collaborators "
  },
  {
    "startTime": "01:51:12",
    "text": "from the other vendors who have traditionally come in to BMW G I think this becomes a little easier we can donate a WebEx and then talk through and run our tests bring results here that\u0027s really nice um so how I did these tests another time we used an FPGA but that was like well it\u0027s it\u0027s great hardware but it can be very cumbersome to workers if you need to change something but at least you know how to ourselves so you know it works and and if we have a actually there\u0027s no reason to wait all the way from London we you\u0027ve got the slides and if we have an interim meeting this could be one of the topics that we take up sure but but you could still potentially get a trip to London out of this that\u0027d be good so okay well I I\u0027m glad I brought that one up and it was well timed with Paul\u0027s earlier presentation I think that\u0027s that\u0027s a potential thing that we would want to add at least one sentence in our draft charter so there at least there seems to be interest in it right sir okay I wonder if I can I\u0027m just gonna pray oh yeah I\u0027ve got it right here alright so I wanted to I wanted to mention that we\u0027ve we\u0027ve got this we\u0027ve got this charter that I shared on the list for discussion Sarah and I worked on this a bit before it was republished and this this paragraph here the scope of BMW G has been extended to develop methods for virtual network functions and their unique supporting infrastructure such as Sdn controllers and V switches so we\u0027re actually where we had this as a kind of like a bullet item before for a specific area of work we\u0027ve actually completed the considerations draft which was the first homework item there and we\u0027re just about to complete the SDN controller stuff and then and go on and do some other things so we\u0027ve got all sorts of things here mentioned platform capacity and performance characteristics or virtual routers firewalls signaling control gateways other forms of gateways are included benchmarks will foster comparison between physical and virtual network functions and also cover unique features of the network function virtualization systems like migration or life cycle operations and so forth there\u0027s a lot but there\u0027s plenty of things that we we we could be doing which are not data plane things lots of "
  },
  {
    "startTime": "01:54:16",
    "text": "stuff so I think just as a note to self actually I actually think we\u0027ve got enough here to support the well maybe not quite enough here to support the security related things that came up for the security and the second was specifically adding a sentence for the calibration right devices so make sure we mad that him all right what happened there all right social security devices and calibration yeah that\u0027s a test release okay so the so we\u0027ll flush the wording of those sentences out and circulate it on the list and then I guess we\u0027ll propose after we\u0027ve had some some time for a review and some of the other documents well will propose milestones related to evpn and whatever else we decide to to take up out of the the set of new proposals we\u0027ve heard we\u0027ve heard about three brand-new proposals today we\u0027ve got some other ones which we\u0027ve shown in the matrix they\u0027re lurking around and and hopefully the proponents will be more active and then then we should have a good set of milestones that we can put together with our Charter text and go to the iesg and say please let us continue as one of the longest-running working groups in the Haight yet it shouldn\u0027t be too much problem all right so with that we\u0027ve got a plan to continue with our reach are during activities will will let Warren know about that as soon as we can and then I think we\u0027ve now reached the any other business topic so if you have questions in general ideas about benchmarking now\u0027s the time to come to the microphone and talk about it okay looks like a pretty satisfied group all right folks well thank you all for your attendance and your participation in particular those who did I think that we were very glad to have that here today and there will be even more of us and in future meetings I can guarantee you that where we\u0027ve really started to work out our details for new things in particular "
  },
  {
    "startTime": "01:57:18",
    "text": "we\u0027d like to thank Sean Wu who participated at a very early hour in in the east coast of North America Thank You Sean thank you folks and joy yeah it worked it worked very well and we\u0027re very thankful to meet Eko for that so thank you meet Eko guys and and so there we there we are I think we\u0027re done folks so thank you again and we\u0027ll see you in most likely in a virtual meeting interim meeting but also for sure in London thanks again "
  }
]