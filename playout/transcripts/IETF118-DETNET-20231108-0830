[
  {
    "startTime": "00:00:09",
    "text": "Okay. Good morning, everyone. It's a time to get started. Welcome to this session of the debt networking group. Co chaired by Luburger and my Satyaanush Farkash. And, Manny, thanks, to give sugar to our secretary for her efforts, especially in this, stage time for her and taking care of the minutes. As this is, This our second session, we are not, it's the same, very same deck, but, we don't go to the, slides. Neutral is very important to highlight, though, so as a reminder, If you're not familiar with the notes, please check. And, participating the IITF, you actually agreed to follow the IITF processes and policies which are captured by the note And as part of it, that, you acknowledge that everything you you say and contribute becomes a part of our permanent records. Also would like to mention that the police act respectfully to our colleagues as, this have in detail in our contact guidelines. And, please join the Mitacle, on-site as well. Maybe the on-site tool is more convenient. For the blue sheet. And we also would like to ask you to join the queue if you would like to speak up on-site as well. Makes the key management a lot easier for everyone. Also, a note taking is a joint note taking. So please, join us in the note taking tool the direct link is already in the chat window. For that."
  },
  {
    "startTime": "00:02:00",
    "text": "We have this is the 2nd session we one on Monday, which, primarily focused on the role. This cussions and, uh-uh, documents and we also got an intro from David Black or a summary about the open meetings at the end of the Monday session. And today, in the second session, is mainly about well, the first thing is the requirements draft that is already a working group document and the, the rest are the all kinds of, solution proposals being discussed in the open meeting as individual contributions, so far. We'll not say more about the agenda. You can check, at your own, And, the first, presentation is about the working doc document And, for the non working group documents, like the individual contributions, please focus on but you are addressing out of your our charter and what is the change compared to the previous version. I would like to mention also that and we introduce, or reapply the same idea we did on Monday that, we will set a timer a bit shorter than your, time on the agenda. For the presentation time to allocate and enable time for questions and, discussion. No need to repeat this one. This one either, and we have not as we discussed have the charter and my milestone discussion on Monday. And, It's always good to remind, I think, everyone, about the IPR policy is we follow. So please Keep that in mind. And, To progress our work, it's not just the sessions, The mailing list is, really essential So please use that one. And, we can have,"
  },
  {
    "startTime": "00:04:01",
    "text": "entering meetings or additional meetings, we already have the open meeting serious as, we heard And we mentioned, one thing about the raw architecture, on a Monday, that we try, to, contact the discussion on the list hopefully come to sorting out the outstanding items, soon this year. But if they don't manage to do that, maybe we set up an interim meeting, and Lou and Harvard checking the calendar possibilities if we need to do that. And it looks like that the week of January 15 is the 1 That would make sense because this this year is gone, practically speaking, given the holidays. And before that, it's not meaningful. Other after that, it's getting busy. So that's state June for that, but it would be really good to conclude it on the list if you can. So that's the intro part. And, with that, let's move on to Performance for the requirements. Okay. Yes. If you, yes, please. And you you you tell me when to it. Switch slide Okay. Hello, everyone. Polycom. It's a requirement for security standards. Excize, please. So, the document was update from, there are, 3, 2, 0, 4 according to the discussion, and thanks to choose, open meeting. We got a lot of use 4 comments from Kieran from David and the from others. And we add some text to enhance the Ranishanov. Requirements, and some section has been rated named a little, but we didn't add any new requirements or changing the structure. Exactly. Slides, please."
  },
  {
    "startTime": "00:06:00",
    "text": "So here's the main updates, we renamed the section as a resection and, the main change are happens to a section 0.6 3.7 and 3.8. And for the section 4, we also added the reference to the, controller plan dropped. So next dot. Sometimes, please. So here's the main change of the name of the 3 sections or subsections of the requirements. First of the way changed provide mechanisms not requiring, full time synchronization to strict time synchronization. And we changed, name of ground 4, to add the of bandwidth to demonstrate that tolerates the high utilization, what it focus on. And, for requirement 8, we just change to support provisioning of multiple mechanisms. Next slide, please. So here's, for the requirement for we try to make the clear of the requirement of high utilization of bandwidth. And, It is to say that for the case, the bandwidth utilization is more than, 7th 8, 5% or and all up to near 100%. And we also consider in the results quite for the. You already is reserved, and it's not sure if there's any space for the queuing solutions that can improve the bandwidth's authorization based on the current method but accept the sticker app. According to the existing work. So we would like to make this, items, be on option option. Yeah. Yeah. So next size, please. And 4 comments 6."
  },
  {
    "startTime": "00:08:01",
    "text": "We add a paragraph to expands that's a flow, fluctuation is focused on the data flows, So we, here's nothing that the non debtflow also can be massive and may have potential impact on this capability. Of the tunnel flows. The instance is that it caused a high utilization of the bandwidth and the surprising possibility of more results with reservation and the traffic steering of data flows. But we assume that there will be the strategy in the ingress to deal with unknown that flows a prevent, the real time influence on the data flows. So, it's just to see that we, have the strategy to control what, will be sent from the, ingress to the middle network and also to the egress. Next size, please. Okay. So, for requirement 7, we're ready, had the problems to refine the requirements. Several open meetings with discussion and several, emails in the middle east because, the name is basically available to a large number of hubs with complex topology. But the one we try to evaluate if the if they're seeing solutions by this requirement, we got some problems because, if it relates, degrees. But not not only yes or no to support this requirements. So, During our discussion of valid, it's different understanding of how to evaluate this method and the way proposed some criteria for the latency jitter and the routing cogulation and resource scheduling in the cont control panel. Which didn't trace the consoles."
  },
  {
    "startTime": "00:10:01",
    "text": "So for the current version of, 4, we just add a really little, sentence in the existing versus. But, next slide, please. But just after the cutoff, we also had good discussion in the open meeting. And thanks to David for providing the new tax. And we think that we, by adding the 3 paragraphs. We solve the problems So, the 3rd paragraph is to see that from the deliver delivering of the queues of the we explain the complex complex city. Of the, latency and the jitters requirements. So for instance, the data queues is bombarded by a constant, fixed, constant constant per hole. So the and the and the and the latency bounds are a linear function. And the the fixed consent and to indicate her bumps also, expected. And for the, maybe the control plan, For instance, to ask BP to, for the real resource allocation, maybe range from linear to, potentially, x ex, financial. It's, depends on what's the case it is used for. For example, we just to to, to reserve One flows along the path is we'll be the linear. Function. But if we, just to, reserve all the flows it may be changed to a graph based questions. So it will be the potential, exponential. Yeah. Complexity. So the different queuing mechanisms,"
  },
  {
    "startTime": "00:12:04",
    "text": "has a different properties because but we just focus on the and and Jeter Pounds, Jay Bo, latency, farms, and just and others. And and all the three of these areas, consideration in evaluation and selection of the scalable standard securing mechanisms. But we didn't really give, special criteria. Point. So for, requirement 8, we just change some words, or it's it's related to the description changing the heart to a strict. And, it's just to say we may have 2 kinds of damage, scenarios in the barrier beginning of the requirements of this section. So next size. Please. So we will, find the document according to the last open meetings some, maybe within, 1 week, we, have no other comments on it. And, for the next version of the draft, the course are things that we, it may be stable and major not to, to request for the last call. Yeah. Thanks and any comments. Nobody is in the queue. Okay. Well, thank you very much. For the update. We look forward to trying to wrap this document, up So thank you. Accreditation and work. Shaku? Hi. Hello? Are we, parking hasn't created this, session remotely. I'm sorry for that. To give me this opportunity again, to"
  },
  {
    "startTime": "00:14:00",
    "text": "and take the the one post so that the live based, green organism next please. So This question mainly contains the following updates. Are the more co authors who are interested in this program and and recommend the option that's available for that are more suitable for not just screening requirements. With the relationship between the as well as so supposed to get into on the we recommend the anti mold scheduling mode and the the corresponding scalability consideration they will automatically create a location lure for RFP. And the server that the include and the for each option. Other data that you wanna shoot people and the settlement, the security considerations, Next, please. I gave you control, so you can flip, yourself. Okay. I will see that Okay. I got it. So, according to the Unity, the public, while for need to reach analysis in the industry, Yeah. We know that the the challenges of the existing cooling mechanism. For example, The reductive is the recognition site here, the TS, and ATS, the CBS, how overestimated the propositions and the CVS cannot even work independently due to busage needs to cascade and the PS and TS has a scouting scalpinity issues, GSL operations. And the TSN is okay for at over provision issues. And the the polarity, basically, creating scheme where you need for server network. May have an I expected the worst case letters due to plus the accumulation and the positive risk cascade So"
  },
  {
    "startTime": "00:16:01",
    "text": "we introduce the EDF for scaling into the the data plane to uniformly provide the bulk of the deleted by in time or under anti remote you'd be learning the full he has some mechanism category, not the local shaping. That's what we just discussed most substantially, it is a delayed based discussion and describe the another couple of spoke So in this page, we use the tools wonderful whether you could talk also to understand the proposal In the first example, we are gonna need 100 of flows issue, we supply the sites, see multiple, 1 micros, 7 to per repeated the server's capacity into over 100 microseconds. That means each role will your concern or one person to bundle by of the service we need to see and the society has been consumed by war balloons So the worst case of hope latency is 100 microseconds in the case of eligible arrivals In the second example, we estimate the term flows issue with a public search is C, MARPOL, Megaoseconds I'll repeat the server supposed to enter over 1 milliseconds That means each floor will be a consumer 1% of bandwidth of the service with the but the was able to see how the load has been consumed by to see a good, the worst case of the horrible reasons 100 and backward a second Of course, more fruits can be automated. But there will be some larger popup latency for example, 1 millisecond, According to the power examples, we learned So, hopefully, Tennessee is generally determined by the admitted eligible bus that I'm gonna be seeing under the servicing of the sea. The two resource types, one is the puzzle, and the other is an important aspect of the cooling mechanism is to issue or pick out eligible arrivals of vulnerable water congolanda arrives."
  },
  {
    "startTime": "00:18:03",
    "text": "So what is the probability considered by EDF EDFO companies said the multiple proposals with some of the delay levels, tell me that the driver can use the functions to offer valid levels for me that the getting you need a condition. The arrival contribute to the foundation may generally be need a bucket for easily lower for example, for the dealer with d I the BI Ally is the faster provider solution. And it can be allocated by flows that it belongs to the the data lower. Based on the choose a bit of strategy of a queue such as sworted the crew and the rotation crew there are the 4 insignificant conditions with by the differences. But I I will note I will note the describe within detail. So this is the option of ready controlled pluses sorted team It is the classical idea of with the recipient states maintained in the call. This is the overseeing of already controlled plus a rotation crew. With course, narrative, 13 rules, then option 1 it will also made 10 receive stays in the call. This is to of latency conversation plus the and the the latency conversation is based they translate the you did a the requirement is the option suitable for a large scale and requirement workflows arrive at the area for scheduler. This single issue that is and eligibility, origin, a community based on the can set that where she So this is the overseeing open latency conversation for us and rotation crew the data science conversation is also based on David said Dawasi,"
  },
  {
    "startTime": "00:20:03",
    "text": "it is worth of the requirement data option suitable for not spending requirement. So this is a not important update for this version. To this on time scaling mode the pump options we and the 4 described is a working concern motor. Behalf of it. Make the Under to under latency, less than t multiple hubs they may have a large cheater. Animal model will be based on plumbing resistance on the latency to get a low cheater animal modem. They alumni the but the accumulation making buffer design more simple. The animal model within multiple week could contribute the function of flow. We can further implement the animal model using tools message. The first one is the target is scheduled by Dpluse. In the schedule configured with animal In this case, the end to end lateness may be in the range of room, the multiple hub to the multiple horrible supplies the bees you may even see the targets of 39, but are the exceeding 1 or use list and deliver 1 deceiving most of these, the public, these the in the scheduler 1 configured with animal diversity 10 scheduled by Dintheschedule2 configured with in time a motor. In this case, the under- to- underlayance may be in the range of romody and variable hopes Minus TIA 2 d multiple hubs. So we can see both messages, may provide one tier. Please come to the end of your presentation part, few seconds left. To have some time for discussion? Sorry. Answer. So I will just okay."
  },
  {
    "startTime": "00:22:01",
    "text": "No. I didn't write. You didn't you didn't have to end immediately. So, I'm not sure if food for next step, we, try to, request to double your double digit for this one to do to the contender. It's until we get some, interested in our cooperation for this document. 7 any questions on the comments. Yes. One comment on the adoption part that, as we did cast, at the end, on Monday session, it is the subject or or a goal of the open, meeting series to come to convergence on which queuing solutions to be selected by the working group Right. Based on what criteria. So we are not just starting adopting yet. Yeah. Okay. And Understood. One of the pieces of work we're really hoping for that those discussions, to provide us is an understanding of which of the solutions are competing and which are complimentary or hitting solving different column spaces. And that I I think that's a really important thing for that those discussions to bring to the rest of the Ah, Thomas Eckard. So I I start to feel that I would really like to have one example topology with a set of flows, a maximum set of flows, kind of the the example. And then from each of the proposals that we have, description, how the calculation for the latency guarantees that can be"
  },
  {
    "startTime": "00:24:00",
    "text": "given by the mechanisms have to be done. So otherwise, it's really hard to to follow everybody's presenting it somewhat differently. Everybody is assuming a different amount of background that you have. So maybe that's one of the things we could discuss, in in in in the site meetings kind of the standard reference example and then the description for each of of the mechanisms because I had And this one just was the first one here. On the slides, travel to follow. Thank you. Okay. And next one, again, you are the presenter, so I'm giving a going to lower to you. Okay. Thank you. I will, go right there for this select so this is the, ticker mechanism. In this way, she will have the following updates, supplement the Python based, the time slot is good. Simplify the premise for the modern relationship or the to reduce and retaining on that advertisement, the cost and, can identify the 4 states and the network entry. Fix the latency equation of a pope at the end to end so when the income is scheduled, updated the evaluation paper, and the civil and the security considerations Again, this proposal is a enhancement of the TS and TS, which has the scar scalapidity issues of GCRO operations. This proposal where you introduce a time slot, the type of resource to LSB and, related to the Thomas world that based the screening and mechanisms and doesn't know the display. You did launched 2 TSN mechanism category, here with data study. So key graph, we are constructed at the time slot, the type of of only source of the phoitioning for supposed to get orchestration PR with the instance. And the with the cap, the ultrasound period, the form of the skirt, I mean, period"
  },
  {
    "startTime": "00:26:00",
    "text": "the later much is out of your hardware capacity over the device requiring only a few random I feel a lot longer move being accused of a single peppercase for one lumpiness because they have a equipment in the bank Finally, Sumat Higa. Open clothes and no other stomachaches. The policy recognition is based on time slot resource and reservation. I use an ink and obtain a flexible market release could be between the income terms with an outgoing terms with the agent node. So for demand load, we may detect a single time slot and market relationship the outgoing thermostat will offer local mode to the outgoing port. Put the ongoing center time slot of a downstream removal income report as the figure on the left side, although we may integrated the the ultra prison period of serving relationship between adjacent the notes as the figure on the website. This relationship is the independent of its flows. But in what and you're hearing the attributes of the topology it can't be advertised in the network based on this relationship he will you. He will PTM can be deduced to the other use for the thermostat and resource and reservation. Oh, soon. Just the closer that privacy please give me the control. K. You stopped, you stopped the presentation. Let me keep the control and tell me when to flip to next one. Okay. Something I'm sorry I did. So is it a good side, or should we move to another one? Yeah. It is immediate the the previous one. Previous"
  },
  {
    "startTime": "00:28:03",
    "text": "Yeah. Yes. So at another work entry for each locally, the supervisor of possible flow the result outgoing, absolute offer, an iPad is based on the idea it comes comes with the UI port. For example, there are end stage for ends of a bus for possibly interval of the specific flow. The another and she should take the colloted the idea in comes through the based on the actual income and time slot of the regulated packet. Next freeze, So, we introduced a pifu based scheduling and pifu can convenience support the 2 screening modes, the antenna mode, and the timer mode. Anthemomotor needs to use the full low cheetah propose in this case, park rates should only be permitted to send the other the beginning time of the mature the calling comes with the day. This is actually similar to the loading booking key based on scanning. So the rank of the pocket that you're close to the beginning time of the outgoing premise with the city which is the one closest to the lifetime list. So in normal mode, it attempts to obtain lower end of end of latency tender guarantee the, worst case and the 2 and the latency. Some applications may have this requirement. In this case, Parkinson may have been sent before the beginning time of the outgoing times fluidity. So the rank of the packet equals to the begin time of the outgoing Thomas would say would say is the one closer to the arrive time pluse. What he should be card in the pocket. Next please. So gift card shows the latency"
  },
  {
    "startTime": "00:30:00",
    "text": "vision of a ticket according to the reservation of a time slot in each hub. The end of the end latency is invalid with the hubs under the key date is a constant negotiates, to meet the requirement of both of the service fluids, how different the service policy interval we design, multiple instance of opportunity in period. A ticket for Nincol can be configured with multiple kig of instant stability corresponding to us they go to the field interworking people in different than notes, it's based on the same hotel billing period instance. Next please. So this type is the urination of particular much into larger scanning requirements. First of all, no time synchronization is needed in the network. For the items with the full natural number of flows ticker for never assume that the world computing flaws arrive with a simultaneous as a sum Adam Magna need to know soon with but they're not internally was based on Thomas World Association. So people can provide the best evaluation score to support a large number of criminals for the items, we put the sword. Logic number of hopes that you wanna see to also years due to under to end the latency that is around with hubs and the constant return to Jitter. The exploits. again, this propose the contender is, basically mentioned. I would okay, are we, according to the deciding of the open group qualifying the comments Okay. Thank you. We have told us in the queue. Oh, yeah. So, wanted to repeat my comment from from last time because this hasn't changed here either in the new ref of"
  },
  {
    "startTime": "00:32:00",
    "text": "the document and that's it. I think, if we would go forward with this, this is a single draft describing TCP IP. So two layers, that should be separated from each other, right, and that's basically what, my my proposal is about that this orchestration thingy is something that we should put on the edge. And consider a different layer from the Hopper help forwarding. Thanks. Okay. Thank you. I think we may, discuss it in the various, in detail Okay. And we discussed the adoption part. So I suggest to move on to the next presentation. Gino, please. Hello, everyone. I'm. I will describe about the c score. Next slide, please. So this, presentation material is 3 part the overview of the c score and the email discussions and the updates on the draft. The first part overview will be skipped. Next slide, please. Next, maybe go to the page 6. Thank you. Yeah. I will start from here. And this is about the email you change and discussion through the emails. We have quite a lot of email exchanges. For the ceasefire Thank you, everyone. Join, for joining the email exchanges. There are quite a lot of topics, but I, I I just picked 4 of them. The first topic was a lot the validation of the papers to only one's property. Which is enjoyed by many rate based queuing schemes. Such as ATS, Fifty round robin. Fair queuing and the cisco herself. So if you look at the"
  },
  {
    "startTime": "00:34:00",
    "text": "The metrical expression and the second bullet. Yeah. Where the b, large b is the maximum bird size of flow under observation. And the large eight is the number of hook count. So if you look at it very closely, the b appears only once. So, that's why it is called papers only once. On the other hand, there are terms that are proportional to the a number of hook count. So, basically, it is linear to the hook count. But the first side itself, is paid only once. However, this nice property is not applied to any scheme that tries to allocate per hub latency. Okay? That's because the latency bound in a single hole If you, if you ask, what is the latent, shebound, experienced in a single home. Then the burst appears again. So to sum up the bound in each hope. Is larger than the end to end latency bound. So there's the key property. Here. We have been trying to verify that property for a throughout the long, email is changed. So I hope everybody understand that. The second one was about the cscores latency bound expiration is self. As you can see there, we had a discussion based on the original paper how to prove that. And with a specific network design, who provide by turtleists. So Yeah. It is validated. Another one was about the time difference compensation mechanism. Should be appeared in the next few pages. The effectiveness. So that, compensation mechanism"
  },
  {
    "startTime": "00:36:02",
    "text": "And the finish time, the as a metadata, for this time, can have range precision. And how many fees are required? Those are discussed as well. Yeah. Thank you. Left. The first one is the addition of the total reserved service rate estimation. With the metadata given. So there is a long history behind But, I will skip it. Anyway, the The scaling requirements draft, which Pang has been has just presented now include the to resource or location complexity So it is in that data plan requirement, but anyway, a new when a new flow joins, or leave the resource allocation, can be a, limiting factor. For automating that flow. So it is very important And As you can see in the bottom, or the last bullet. We added the metadata carried for Cisco in package can be used for estimating the total reserve service rate in a core node, as in the following, the detail mechanism is described in append but either thing I have time to introduce that. Next slide, please. Thank you. So this is the second, updates of the dressed. Which is about the time difference compensation mechanism. The time difference is defined like that. For a single packet, you measure the departure time of each own clocked at the deeper helps from note. And then the downstream node measured the arrival time of, that packet. With its own cloud. There is a difference, and this difference is called time difference."
  },
  {
    "startTime": "00:38:00",
    "text": "And it can be updated and compensating throughout the node. And we have been discussing with the email with especially with Andrea. And he gave the very essence of what it is. So I appreciate Andrea, and I put those sentences in the draft. Thank you. Next slide, please. And there is a edit reference, which is recently published, you know, a tripoli access the title or weird is scalableflow isolation. So, in some sense, in determining the token, we are persuading the scalable flow isolation, and they did the title a bit paper. And it includes, extensive on that validates C score. The paper has 2 topologies with the simulations the first stone is about nine of those and maximum 7 hope net tops. And second one is, a t knows who is, 16 Nextiva home counts with lots of flows. And throughout the topology, we tried various dual effect promotions, We compared with the ATS 54 FSC roundrobin@virtualcloakself. And with the no no conserving cost favored fail queuing, which was suggested by a long time ago. And he never set up. Cisco performs almost the same as the stateful virtual clock. And as much as superior to anything else, and it needs the theoretical and to test the latency bound. Okay. I have about 1 minutes left, but I will stop here. The appendix may be too long to explain. You can take a look. Thank you very much. Questions?"
  },
  {
    "startTime": "00:40:02",
    "text": "Yeah. 12 a second. I just wanted to rent again the IETF that I would love. A lot of these wonderful pictures to show up in an RFC maybe you actually can and kind of convert the SVG. So think there's there's good, explanation checks. Yeah. If you have something else you wanna you have It's okay. Thank you very much. Yeah. You actually had couple of minutes more, but for a question if you wanna anything else? So, again, we're is is is is setting the timer to leave a couple of minutes of discussion. If there's No discussion. The speaker can use this the time. Next slide. Right. So the goal here is to, pick up again on what I introduced last time with a very quickly hatched up slides. And so the whole idea is to think about how we can achieve a high utilization, with, Bounded latency traffic in networks, with tightly bounded jitter forwarding mechanisms. And so this time, we we only updated the slides, and and not the presentation. And in general, I think, when when people start to think about it, what's being presented here is this time division multiplexing yet. It is but primarily in the control plane. Right? So it doesn't, make anything in the forwarding plane. Of the mechanisms, TCQF, CSQF that we're proposing any more difficult. And, it's also becoming quite popular as mechanism to increase utilization, other domains So, if you click on that, picture. I'm not sure if it actually works during the presentation, but this is in the PDF as well, then then you'll see this wonderful, nice, autonomous car intersections where all the cars are crazily driving through each others and not colliding And that effectively happens when we do have"
  },
  {
    "startTime": "00:42:04",
    "text": "slotted forwarding of packets because, all these packets can go through with each other not build up queues, which we normally also have, on these intersect Next slide. So here is, hopefully, a much better work through example and, maybe it's not, that easy to understand it all the way through, uh-uh, run here. But, typical, large metro aggregation network maybe, 30 routers, each of them aggregation for a 100 notes and independent of what particular, advanced scheduling algorithm we're using, still have the problem that from each of the incoming interface, there can be a packet, competing on the outgoing queue arriving at the very same time and none of the queuing mechanisms can basically compensate for that. So what we're having is that We're building up on every hub. A latency, just because of the large scale topology that is, in this case, for example, worst case 1400 packet and then the serialization time for that. And, if we do wanna support large bursts, like back to back, 10 or 20 packets, then, of course, this problem, scales up with a number of packets we have and if we do, do, forwardings, like, wait for queuing and other so called in time mechanisms where packet aren't delayed on a per hop basis, then, the jitter also increases by X10. So this is basically, the problem we're trying to solve that we do, create ever larger jitter. And, because of the the jitter also the, aggregate end to end latency. Next slide. So How would TSN avoid this? What TSN does if we have, CQF for example, in TSN is that on the ingress side,"
  },
  {
    "startTime": "00:44:01",
    "text": "on the centers, we have a gate through which you can exactly control at which point in time a packet is being sent and therefore, in which cycle it comes, and then basically the admission controller can calculate which of the flows admitted to the network is going to go into which cycle. So that's when they're kind of entering the the ring. They're all nicely coming after each other because they're only delayed on the sender. Actually, we do have that on the highway in the US right before you're entering a highway there, you're queuing up, so that you're not having to queue up on the following, intersection, highway intersection, points, but, only on the ingress side, and that keeps the overall network up by how forwarding very simple. CQFTCIC and cycle based. Right? Now, The way that TSN does this is, still with a, per flow, based forwarding And the flow, and and they also kind of to to support their scheme, have the option of need to do this to do this delay within the topology. Right? And that's exactly the complexity that we do want to avoid. Right? We do wanna have this additional complexity, this layer of explicit delay to get into a certain cycle only on, the sender, but not within the topology. Right? Next slide. Right. So, when we go beyond cyclic queuing, which CQF, TCQF, CSQF, where this is, very simple. We have proposed mechanisms like GLBF, which is damper based and, GLBF being the generic damper algorithm for one particular calculus and namely the t s n a t s calculus because that makes the queuing and the, algebra very simple, but This scheme here applies to any of the dampers. Right? The dampers, like the cycling queueing, have the benefit that"
  },
  {
    "startTime": "00:46:00",
    "text": "the time that a packet will be on every hop. So you're just creating yourself cycles logically in the controller Now it becomes just a control plane solution, and you have eliminated the need for her hop clock synchronization within the ring. You, of course, still need clock synchronization across that layer of, timed gates on the senders, but that's now only on the edge nodes, those edge nodes could be radio towers or the routers associated with it, those nodes do need clock synchronization, anyhow, whereas the core routers here in a a metropolitan backhaul network may not have it now and wouldn't need in the future if we would go for this more advanced but again, these more advanced damper solutions, I haven't seen high speed, you know, validations yet. So next slide. So summary, right? So those in time queuing things, dampers or cycling queuing, They do enable flow interleaving. And that's, I think, why they're a great thing, but the gates on the edge, that, this flow interleaving mechanism proposes they're equally valuable for in time queuing, just not for interleaving the flows, but anywhere in the network, but you can still use it as a great way to interleave flows when you aggregate them. Right? So all the flows from 1 ingress to 1 ingress they can still, use these timed gates so that you're interleaving them on the ingress and you have one big aggregated flow going through the network that is nicely shaped out and has a minimum burst size. Right? So that's why I'm thinking that these time gates and this concept of, you know, point to point aggregation for any q mechanism or the interleaving for, the cycling queuing and the dampers I think this should be a different layer, different functionality in the dead net architecture. And, hopefully, we can get to the point of seeing how much we can clone from TSN for that, which obviously has this function. Alright. That's it. Thank you. Questions?"
  },
  {
    "startTime": "00:48:10",
    "text": "Good time. Oh, okay. I'm Juveen Shahram, CEICT. I will present, the chapter about the enhanced use cases for the gating, guitar mistakes, Snapbook, next please. Okay. He has agendas a growth in source rep, the four parts introdedication. Summary, some, discussed the enhanced use cases and the natural requirements. And, summary is the clarification of different resource application. And the next step, okay, next slide. Okay. Introduction. As we know, IETF, issues, RFC 8 said, 8578, which covered the variety of the IIT of the, Pro, of course, a professional's audio radio, electrical, cellular radio, my mining industry and so on, but for this chapters, we try to discuss the use cases and network requirements out of after of the existing RFC. Okay. Next class. Yeah. It's a in it's in crow in rodents, machine vision, radio controls for industrial, and, crowd AR, we are games and the living streams for, high experience videos and is a computing, a wireless, application as well. And analyzers, SLS requirements and the design was behaviors in enhanced that natural standards for the"
  },
  {
    "startTime": "00:50:00",
    "text": "3 type of use cases and application. That's more of the use cases, what is motion vision, for industrial, machine reasons to use this AI Technologies as a machine to replace human us to the per production a qualities inspection, which involves images captures at the end, and the intelligent detections at HNSA AI training at private and public crowded. In this, those processes, industry cameras, images are required a high definition and with little or the new compression, and high bandwidths is acquired us. On the other hand, the real times, related monetary function, is required high speed connectivities. So the requirements of the, Machine Vision is a delay sensitive and high reliability. For example, the is delayed last time. The 10 is 10 milliseconds. Yeah. Okay. Next class. Okay. Use courses too is remote control industrial Chill. In Internet. Oh, okay. The path, the technical application of remote call is crowd business PRC. The PRC stands for the programming that programming and control function is trans is transmitted to the cloud basis, centralized management in future. And in deterministic is forwarding. It's a re required So the requirements of net of networks for A remote control is delayed and jitter sensitive on a high reliability. For example, as a jitter less than 100 May 2nd. And, and, delay is less than 10 milliseconds, for for control, for financial command. Okay. Next class."
  },
  {
    "startTime": "00:52:02",
    "text": "Use cases 3 is cloud ARAR for a high experience review. Okay. So for, for good performance and experience, the, the rendering and a string control one of the histories control consists of a crowd processing network transmission and the terminal, processing. So the the requirements of cloud AR and PRs depend on the the different tools, the level of of the, experience, in the strong as scenario of us. That network's performance is desired. For example, the delay less than 15 milliseconds. But for comfortable experience, the delay at the list, at the list, 15 milliseconds. Next slide. Okay. In your cases, for a crowd game, for high experience radio The online games, the technology space is a crowd complete, excrowders comp companies that enables the lightweight to the devices to the round, high qualities game. The games experienced that depends on the high quality and the low latency network environment. So the requirements of, cloud games, it depends on the level of experience for example, for level of the usual part, is a part, means, makes the online games competition. The delay is to the delay, less than the 16 millisecond, But a fortunate level is delayed, less than 100 and a 50 millisecond in as fast paced Okay. Next, next, the use cases file and the crowd live streaming for the high experience. Were you, for scenarios such as a consent,"
  },
  {
    "startTime": "00:54:00",
    "text": "a press conference and support events, the cloud links streams use 5 cheaper high bandwidth to transmitters. We are radios the requirement of it is a is a It's a bandwidth and a disease sensitive like, delay less than to hand your millisecond and the bandwidth are the latest, one Nextwest, okay. Summary. Pieces are about as a analysis or network requirements where summary 7, topic was a scenario, the remote, the public, the productions, control in park, remote control with your AI in production products, monetary, production, connection, we are, and we are radio and and show up, as a figure shows, different to levels, education, health, diversity, SRS requirements, overall, the main character character rust of, he he has dead net debt net focused use cases, is the crowd basis applications and the remote control. In terms of the industrial industry deployment for smart grid, and high isolation, low latency, jitter, and the synchronization is demand it, for industrialslowlatencyjitter and high affinity and high panel lasers is desired, as choose the customers in in entertainment, the high bandwidth and the low latency, is demanded, for computing, wild applications, and, by the way, and low latency jitter, and there's a high reliability demand Okay. Next slide. Next slide. Our next steps, any, feedback, suggestion, and commerce, and discuss platform. Any questions? Okay. Uh-uh, oh, sir,"
  },
  {
    "startTime": "00:56:01",
    "text": "of the salon. Yes. Regarding We lost you. Okay. Sorry. Okay. Yeah. Yeah. Regarding the data or the the the bandwidths, And, the delays, mentioned are they, really, experienced figures or numbers, as a you mentioned 20 mil less than 20 milliseconds or 15. I need to be I just need to be sure because usually we in my country. We didn't test it, but will be nice to to know, was this, these figures tested? Already, or it's a a statistical, you know, has I had some contacts. I I asked for some of engineers in UK, but some say that not 100%. We can get these, figures. I need, some answer from the author, and thank you very much. Coralis, at Libira, Next up. Yeah. I think I've seen, so thank you very much. This is very nice. Actually, again, slides are not nicer than the, that the, text and HTML. So maybe if you if you want, we can tell you how you get these nice graphics into the draft, but only useful when we do it. I think enough on that point. Yeah. Sorry. Now, I think I've seen similar, sources from other references So you probably didn't collect this in in one evening yourself. So maybe you add also for the prior comment, the references where you had this from, and I think we can I think also find more more references there might be differences in what some of these are saying, but I think the"
  },
  {
    "startTime": "00:58:01",
    "text": "certainly a very good set of applications that we didn't all considered in in the original dead net use cases? Thank you. Secure secure. So all of the I think the data and the indicators may reference some pharmacies that switch your PP and maybe some send this, reference, reference to the maybe some research, report, yeah, thank you for this. That I view this as a addition or an expansion on the use case RFC. Yeah. That use case RFC has a section, which sort of summarizes common themes. I think that I I went to look it up. I was either chapter 11 or 12. Yeah. Have you seen any impacts to that section based on these new cases. The It's now installed yet. Maybe we were maybe 80 8 of this part for for next version, I think. That that would be, I think, a really very helpful because That summary helped us Yeah. Yeah. understand all the different use cases need to be supported by our mechanisms. Yeah. Yeah. Yeah. There's no impact Okay. This is interesting. It's great to document. Okay. Good. But there's no impact. Yeah. Yeah. There is impact that's really important Yeah. Yeah. Yeah. I mean, you may be added as part for next week. Yeah. That'd be great. Thank you. Yeah. Yeah. Thank you. Yeah. Of this one? No more. Yes. So I understood from your answer that, it's, the the data is, referenced by the 3 GPP. That's I hope I can get some of the reference or pointer to the references you use thank you very much. Okay. Thank you. Thank you. Next up, we have"
  },
  {
    "startTime": "01:00:13",
    "text": "Hello, everyone. This is from. The topic is the differentiating the data queues. Next slide, please. So, as we just presented by Junfeng. We have another, a defense uh-uh, enhanced use cases. And so we master consider what's enhance the goals for the client. And so as we were along, that's the primary goal for that lab queues is, their, pending the latency packet loss ratio and the the out of order packet. So, if they're in cancer use cases will bring a new girls for that land. So we provide some too many, lugers for the lead first one, it's, we must provide various the domestic services with their differentiated SLA in scaling networks, for example, different application, applications will be co existed in, use in a use case. For example, the, electrical utilities they will have many, applications with different SLA will, pendulatency requirements and there are different applications will differ in network topologies and the the SLA requirements. And there are different flows with within an application. We all demand, differentiated, a different, different mislegal SLA. This may be a such there may be such different use cases younger,"
  },
  {
    "startTime": "01:02:04",
    "text": "from the the enhanced use cases. And The second one is that, to achieve this goal for different levels of applications. We lead to consider to support hired utilization of the lateral work resources. For example, make reasonable use of resources and carry more traffic in deployments and the to make more money for our operation operators, and their their, service providers. So this is, new girls, new goals for the Detlet So let's slide. So as discussed just now from the new, use case, use cases, we, we can we lead to consider the new goals for that led. And then it will bring, bring up some new requirements. For example, And this has been mentioned in their scaling requirement, example, we need to support different levels of applications with different SLAs requirement. And then we were, this different levels over applications will demand different the data technologies. For example, the different queuing back evidence. And so we need to consider if we should or if we lead to, enhance our the threat queues, for example, their, that's like queues. Their primary data queues may be classified into several, classes. And then different classes will be matched to, different behaviors and technologies, ness of mad grace. So this is our"
  },
  {
    "startTime": "01:04:05",
    "text": "consideration about their enhanced, the lab cues for a from the left table. We can see that different different applications we are half different s SLA requirements And from the right table, we we can see that we, maybe their cues can be class find and divided into several traffic classes And each class may be divided, in you several subclasses and each class may demand, diff the different different, deterministic or for wording behavior for example, we may have a a teacher guarantee delay guarantee or low detail, low, delay guarantee or auto a load, a delayed, low, digital guarantee. So this is just this is just an an example. So let's slide quiz. So we, we we would like to start some discussions about this requirements for the data queues and their comments and discussions very, very like Thank you. K. Yeah. Questions, comments, Hi. I'm Kieran. Related to my work Do you have any requirement about interface from and systems to dotnet, or is it something would you like to consider So, do you mean that, there there use case, a word that queues can cover your your that their interface you proposed? Yes. I mean, I'm not forcing for it, but I'm asking that is it something worth considering? Actually, it's a question for the group that"
  },
  {
    "startTime": "01:06:04",
    "text": "how applications or end systems will interface with that net. Yet we we we didn't cover that yet, but I think there, the use case you proposed has been covered and the and you proposed in the mailing list, their applications, differ, in their top largest and their SLA requirements. I think this is Coleman. Between and their their your use case is pro you you have mentioned. And there, you have also mentioned that the flows and single application. Also, will, have different Fendi latency requirement. Yes. I mentioned advancing. Oh, I also mentioned in the this, data queues requirement. So I send the date these two, aspects has has been covered in the past interface we didn't. Okay. Thanks. Yeah. Thank thank you. In in looking at this and looking at the document, I read it as your trying to come up with specific classes for use in Detman. Yeah. And that's quite different. From you know, a class based, service is very different from what's in the debt net architecture. Where we have per flow service, which can then be aggregated. Yes. Looks like you're you're moving away from that. Is that your intent? Yes. So I think that they really have to talk about, the impact to the architecture, and this is a fundamental change. Yeah. So Nestor sleigh less slides is about the solution. It will impact to return their flow Yeah. But I'm not sure it's that net. Yeah. So Okay. Yes. Thank you. We we can discuss That would be great. That'd be great. And,"
  },
  {
    "startTime": "01:08:03",
    "text": "for me, I'd like to better understand the the motivation You know, you could have a solution that's at the queuing you know, virtual output queues and virtual virtual queuing is is something that's been in industry for many, many years and it's gotten us to you know, you know, you know, you know, you know, 64 k queues per interface on some implementations, but So it underneath being able to break, you know, to to go from individual flows into some hierarchy queuing, that all makes sense in an implementation. But what I'm reading here is a fundamental change in our service architecture. Yeah. No. I think the the main, the main motivation Dero has to to 2, 2 aspects for has the first one is we want to resolve their scalability issues. Because I've, we think that there are aggregates, flow also has a scalability issues And the second one is that we we, want to provide the fine grained traffic scheduling and the results, management. Fine grain. How how are you doing fine grain when you're doing class space. Yeah. This is a judicial solution for for me, and I'm speaking as contributor, not chair, I think it would be very useful to understand where you're seeing things breakdown and aggregation. And where the model the service model meets the to change. That would be helpful. And then I don't recall see the fine grain concept. So maybe I'll look look for that in the next version. Okay. Thank you. Nice. Nice. Thank you. We have one more. Thank you. By the way, it gets to the Yeah. Mike was here, some, use case, to answer the chair's question regarding, like, I'll try to give to find green things. The things are that was a contributor comment."
  },
  {
    "startTime": "01:10:02",
    "text": "It's not sharing. This is like, some people mentioned the sweet GDP, actually, you know, in the sweet GPU community, It's already got a project down. It's called, to 5gs as a logical than a node. So it's like a black box, but within, there are so many flows. That is having that is requiring the different material aspects. Like the the per hop behaviors. Basically called, like, the Bandwidth, are jitter or condensing. Actually, they are Lea then between 3 GPP and this group. I think enough, last year and then got something there already. So that is re I create a requiring behavior and plus the fine grings things as you mission. Okay. It's, to me, it sounds like you just said that you're doing using the virtual node concept Not just the so the That we've had for a long time also in the IETF. note is a pop behavior, but the granularity actually is per flow. Cut, in the 5 g system, it got at the video session. So it's like a flow. Okay. If you could send more to the list so that everyone can understand be great. Thank you. Okay. This is, their other solution consideration for that for mentioned that that queues. So we proposed the the traffic engineering sessions for the enhanced the net Nest libraries. So let's first discuss about the traffic and gearing for that land. As, as I noticed that for, as further RFC 3272 bs. The the slats can be seen as a pressure branch over it traffic and engineering because data uses their the existing traffic engineer and technicals. For example, the explicit, passes and the there are a reduce all locations. And then"
  },
  {
    "startTime": "01:12:01",
    "text": "but they they're the the deadline also has the scalability considers, for example, the it's a demand, should uh-uh maintain, a last number of their station information and it will be challenging for operators to to for the network events, such as the force. And then even, that's led supports the aggregation, creating flows it's a sphere requires a large number of the control signaling. So, this is, there there are many concerns for the existing, that's that. Technologies. Last slide, please. So, what's the new traffic engineering requirements first, we just, mentioned that that's their their their lieu goes for the last queues that we're, maybe class find and may demand different, queues behaviors. And, their characteristics over their scaling networks where have 2, main problems including the scaling flows and the scaling networks. So it will bring, lewd traffic engineering requirements for that. For example, we need to provide past during to forward a package and, provide differential behaviors for data plane to achieve their their, differentiated data queues. And the way, leads you redraw the scalability issues. And for the resource management, we may consider the 10 base that LSL SLA requirements because we have a new term based queuing mechanisms. And we need to consider the, the reasonable use of, resources because operators want to make more money. And we also lead to, consider their"
  },
  {
    "startTime": "01:14:03",
    "text": "end to end the roads establishment, because they're not scaling, the scaling networks where your we are a multi domain or a cross domain. And, there are past computations will, will be considered the multiple metrics And the the past planning with the resource renovation will be iterate biter than CUi Macaridans. So this is this is the we, try to list all the possible, requirements for traffic engineering. So let's slide, please. So we also, try to, provide the solution, consideration from the three key elements for the police for for their policy. They're routing, may be, I, may include the manual maintenance country based routing, including Marty, domain, roles, into 2 main roles or distribute routes. So, and for the past during, as we just discussed, we, we proposed per class traffic and, scheduling. And then there is her mystical latency information, may be provided for the encapsulation. This has been discussed in the fact And the last one, the resource management, because we have the new 10 base to queue in mycaditance, with, and their DRAM manning queuing mac evidence. So we should to provide the generic resource man management example, the 10 based results aware control and the forwarding. And then this is the the, solution consideration from the swing key arguments So let's do that, please."
  },
  {
    "startTime": "01:16:01",
    "text": "So the main, proposal for for their TE extension, we we, elish order the differentiates the dead net aware of traffic engineering. This is the extensions. And, we compare it a comparator flat? Under the ATA extensions, for example, as just discussed, maybe that led, is of proposed to the peripheral or act flow aggregates based queues, and we then, if we did to consider the differentiated data queues and the the existing TE, which has been using definite is peripheral aggregates t and maybe we can consider the per class And there are what what the the motivation and the benefits we think there are two aspects, for example, the capabilities, problems, to support the different levels over applications and achieved the fine grained time based resource and the traffic scheduling. So to, to meet the ventilate latency requirements and the 2 rational utilize achieve the rational utilization of our resources and to improve the network performance this is the main benefits. So, we assure this the work, we think that a it's It's a main, it's not just for that. The solution, other requirements may be common for other technology technologies for, the working group. So we may seek feedback in tease working group and their initial the discussion for the, requirements, enter the extensions for for TE. Comments and the discussion of our"
  },
  {
    "startTime": "01:18:00",
    "text": "Thank you. Hold a second. So I I think it it'll be hard to to not not not invest a lot of effort. To validate or invalidate many of the claims that you're making as opposed to that this is different than you from debt net given that debt net already has a wide variety of mechanisms that it can do. So for example, all the past work that that we've been presenting here has been around all of this bounded latency, but you don't have to have bounded latency to call a dead net. Right? Your jail may just have pre auth and band with guarantee or even pre off without band with guarantee, and you're doing over provisioning and all these things. Right? So we have various subsets, and many of the things may just be subsets of what we already have in dead net. So I'm maybe just to counter Lou, I'm I'm not even sure if there is more than dead net. There may be just, you know, new names that you're giving to subsets of that that that were already having. So but, yeah, the the full analysis takes more time. I think I'm gonna agree with your disagreement with Lou. So So I'm gonna disagree with myself. You know, the comment that was made earlier about 3 GPP I, triggered a thought is is that we could also look at this just as a form of ag we have many ways of doing aggregation of services, and you're just saying Instead of doing full 6 tuples classification, you wanna do 1 tuples class education. We're the one who pulls on DSCB. That and I I think you were to our list, you're saying it's already supported and think maybe you are, and you're saying and from your drafts, it becomes this is a applicability of debt net as opposed to a change of debt I'm gonna disagree with my earlier comments. So thank you to for coming up with a 3 gppone because that changed that my perspective. So that's and by the blue is individual. And and by the way, there was this this site meeting of our traffic engineers, or there were the one thing"
  },
  {
    "startTime": "01:20:00",
    "text": "which I was jumping up to was this traffic engineering. If you do all the complex things together, which we can also do in Detmet, but we don't have to do. So I do think there would be value for marketing purposes of Detnet to kind of have better understanding about the fact that you know, different type of applications and use cases, would only need to use different subsets of what that net has to offer and maybe even simple examples of that. Right? And so that might be in between these different classes of new use cases or old use cases. And this type of classification. But the underlying mechanisms would all be, I think, hopefully already all be dead net plus what we wanna do for large scale dead net. Up to Salam. Okay. Welcome to. Hi. Yes. I think in the this presentation also, maybe in the the the the previous one. And is the difference between, service class or, traffic flow. So when we are using the the traffic engineering, we are usually focused on the flow, not the class, but, I've seen in the presentation mentioned, the class other service class, not the flu, So I hope, we get the explanation for that Sorry. I didn't quite catch, the the the. I think he's just looking for more information the description of the class usage versus the per flow usage. And, you know, for you, if if based on the comments, if we look at that as a form of aggregation, x describe that in the context, that would be helpful. Okay. Thank you. So We have our last the last slot now? Okay. Thank you. Thank you."
  },
  {
    "startTime": "01:22:01",
    "text": "While you're coming up, I'm gonna just wanna make a comment about that we've been having, a side discussion on when the next meeting on the queuing is going to be. David has a suggestion on how to get us to some taxonomy and wants to, solicit some help, some help, will probably have a meeting in December about it in 2nd week of December. And, we may or may not call that a formal interim. We'll figure that out this week or But stay tuned to the list for that. Hello, everyone. My name is I'm from our introduced the program of the top the of key to redacting magnesium, enter while the the results are while the casing in our late. Next key the draft have been modified in 1 we have had, the correct person method for very distant delay process and on how the regulating contributing enhancement network to botanist. The highlight is that you be implemented Next, next time. There's a simple instancer So how it should work? What's the we're collecting the transmission delay between the torque and the the listening Second we add the ratio of the delay. On the transmission delay of the blanket to the past. Ref as a past reference delay. Sata. We calculate the upper limit of the composite delay for each costs. Force. Reclacting the actually transmitting delay of the bid packet Do you, like, dealer and the transmitting process"
  },
  {
    "startTime": "01:24:01",
    "text": "exclude the effects dental domain, transmitting delay. 5th, add to the comp, it is not calculating the regular competent delay based on the actually treatment delay. Of the package and the the updating of the complexity delay. And finally, we're performing your comp processing at the constant node which close to a listing Why is the confusing, to the last note? The factor rating is to edge reduce the data caused by worries with him. Which encouraged network deploy to flag both in different opinion mechanism, and the network con considering the message The second, though, is minimize it and the and the each composition requires a reference value And compressor redone things must be considered if, did package undergoing more people round off with delayed compensation. It will increase the overload delay. So competition showed that ideally only be performing the west. Closer to the listing. That's what the reading is. Many days to achieve the best route with the mineralized costs for the and the result cuts train. No matter, you know, no matter what the delay comes in, take place that it's always possible that multi transpiling deep to be coined. Resulting the radio cleaning delay that reduce the effective need to transmit the of of the compass. So come up with anything. I talked very much of the network So the"
  },
  {
    "startTime": "01:26:01",
    "text": "should best approach to reduce in the data. And, to achieve the best result with the smallest cost Next slide here. The finger. WAN is the network you have a label we add additional transmit and delay for 50 milliseconds on the uplink And the 46 milliseconds, on the lower lower link use the super internet device. So We can't get the next pass relay. And the state of the the the the the past reference to delete as 51 milliseconds. We we're constructing 50 business flow with total bandwidth of 1 gigabit per second. And, with the package size on 1300 and 80 80 byte has with the back around the flow of 100 gigabit per second. With rental random package side, from sitting 64 to 9000 6300 Bikers. The task to operate is performing link link, Fort simulating. On past 1 and all past 2. That has the result here. Be caught here. All data value on the test almost I lost the day in terrible microseconds with the compass. While the next, the"
  },
  {
    "startTime": "01:28:00",
    "text": "etcetera exceed the 2 22,000,000 seconds without the compensation. Next slide, please. So We can see the draft, they have a lot of benefit that can be applied to you're a single domain multidomain time synchronized is naturally only between the ingress gathering and the egress gateway within the same development not tall, not all the know the in the single domain. Time synchronize is the only required within each synchronize domain. Not between Thomas. The egress and the egress node like the truly transmitting delay in each domain. Competition in the transmission delay at the competition law. Clicked to the leasing. Next, So feedback and the clapper racing. A highly welcome we are looking for how some how your what can we ask to to completed the traffic. Thank you. Thank you for your attention. Are you assuming time is a the latency is accumulated in the control plane or in the data packets themselves. Yes. We the we use the control plane. To take the delay the delay the daily pass. Okay. Do you see that we need to change anything then to make it work? Other than to make this solution work. Other than ensure that the control plan can provide that information. Yes. We we the next slide, I the backup slide to have the we have add the the the ad is a what you clerical reference to tool plane to the to the control plan. To the that that that that that that that that that they pass."
  },
  {
    "startTime": "01:30:04",
    "text": "Okay. So you, in this document, you'd like to see a control plane solution to calculate latency the network or to propagate latency across the network. Okay. Alright. Thank you. Thinking for, otherwise, about the things here while, based on your explanation since they're going to accumulate the delay until the the edge edge node to do all in one work here. But still, back to the the previous discussion about the for the for a logical dynamic node from the 5 gs site. It is going to join the IP domain as a than that node. So it's looking for behavior. And if that behavior has already exceeded, it's, SLA. Will you still put the the that this the discarding work toward the end of the edge, all you prefer, or we prefer to do the work. On the dead nano itself. Sorry. I can't. So this is like a If one, one node has already exceeded its SLA cannot, basically, the the cannot satisfy its SLA based on your proposal, you say, okay. Was you're still going to accumulate until the the large end note. Action old. So so what is the, you know, pros and cons? Like, where are you going to jump? You're you're at the packet. So, Okay. We we are over time. It seems, maybe let's continue offline on the list on the list, please. Yeah. Maybe better to understand than money. Thanks for everybody for the Yes. Thank you so much. Thank you. Many thanks for everybody for the contribution."
  },
  {
    "startTime": "01:32:03",
    "text": "And, let's keep continuing our work and the state June, discussions on the list and contribute on the list. Any other See see you in person. So, next time. Thank you. My my well. That's Island"
  }
]
