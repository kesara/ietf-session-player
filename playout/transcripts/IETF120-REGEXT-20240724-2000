[
  {
    "startTime": "00:00:10",
    "text": "Sounds good I thank you All right, well, my clock says one minute after a topic of the hour, so I think we will get started. I think we're going to have plenty of time today to get through our topics. But, well, we'll just see where the discussion takes us. So this is the second of our two meetings, I believe this is the first time this group has had two meetings during an IETF meeting but we certainly filled up most of our hour the last time and all the administrative topics And so today we're just going to walk through a number of more specific technical topics and hopefully we'll get enough technical discussion in there to feel good about that, although we are going to have a bit of process to go with it too So, okay all right, well, I'm trying"
  },
  {
    "startTime": "00:02:01",
    "text": "out this cool thing over here, which doesn't seem to want to actually allow doesn't want to do things. That's okay. I'll go back to my other window over here, and I will manage the slides manually so that works too. All right, this is the note well. This is a reminder, please, to everyone about the policies and procedures with which the IETF operates and and how we work and the things that we believe are important in terms of how we get our work done It really is important that you understand and take the time to read through the various policies that are all highlighted down there at the bottom and understand that if you make a contribution or participate here that all of these rules and policies apply to you. And it's important that you take the time to understand them and look at them As one particular item, we do like to call out and remind everyone that you know, we are a respectful environment. We are focused on the substance here not on people. And if anyone feels that you know, they have in any way been intruded upon, that we do have a process for all of that. We have an ombuds team for to whom you can approach if you have a particular concern and confidentiality is important to you. You're also welcome to reach out to your working group chair or area director about any particular issue that you might have But a reminder, please, let's keep our discussions and and discourse focused on technical issues. And this applies in all IETF related activities Okay, IETF code of conduct guidelines. I've pretty much covered this quite directly, but, you know, reminder, treat each other with respect, speaking slowly and without slang you know, sort of things that hopefully you have heard many times This is day three of the IETF, and this is a"
  },
  {
    "startTime": "00:04:01",
    "text": "pretty standard set of slides, which should have been in front of you for each and every working group meeting Okay, this is agenda bashing. This is the agenda that we had set up for today, so this is just a quick run for people here Do you have any questions or concerns? You want to reorder this? There were some slides that have been up updated quite recently this morning for some of these things. So if you, I do believe that there is a slide here for everything that's on this list now. So if you feel like you haven't seen a slide for a topic, you might want to go look at it. All of the detailed extensive slides have been previously distributed but there are some last minute one or two slides for three or four of these topics here And I guess I'm the one who's pretty much guilty of those. I've put them up this morning for the last three topics on this list. But hopefully people are familiar with the topics. And so that's just to guide the discussion that we're going to have here. I'm not seeing any hands or comments coming up. So we'll jump right into our welcome introductions. We've already done the note well usual kind of note scribe, look around and I see Rick raising his hand again. So thank you very much, Rick. He does that a lot for us and so we owe him a significant vote of thanks for putting our actions and gathering our decisions in our notes area Okay moving on, so into existing work So there's one item we're going to cover under this. Existing work is one of our, you know, pro forma agenda items But the issue that here, and this is the one slide to cover this particular topic, is about internationalized email addresses Now, this topic has been around actually for a number of years in this working group You know, it took us quite a while to get"
  },
  {
    "startTime": "00:06:01",
    "text": "to the version that we had that we had sent around, which is the link which is there This existed in the IESG's Q. It's itself, or I think even a year or by itself, it certainly predates ORI by quite some time, and I'm pretty sure predate him by a year, as well as all the time that he's been here. So what we did was we ran into some problems. We had quite some extensive decisions on our mailing list about this document but, you know, we gained some consensus. We submitted it and then it hit IETF last call, and it ran into significant problems. Again, we had some real concerns coming out of the email contingency in the IETF. And we spent quite some time going through this. And trying to deal with it. I know that I myself invested a great deal of energy and effort in trying to find a path through the concerns that came out of IETF last call. The end result of all of this was, you know, ORI as area director in the end, they decided to hand this back to us and remand it back to the working group, thinking that, you know, this was really, something the working group should revisit and reconsider. And I guess having it invoked your name, Lori, please, jump in the queue here. Thanks. So I want to apologize first for, you know, having to send this back to the working group. I know you have all spend a lot of time discussing this document I'm here to support continued progression on the document. I'm happy to provide reviews to the process The main sort of point I wanted to raise here is that when the document comes through to me, I want to make sure that you're all comfortable with it and that we're not running into these at the latest stage. And so you know, I apologize for having to"
  },
  {
    "startTime": "00:08:01",
    "text": "hand the document back to you all, but I'm here to help you work through any any of the challenges with it, including coordinating with other working groups, other areas. So I stand ready to assist you and thank you to the chairs and to the authors for your patience and processing the document Yes, thank you. Appreciate that very much. You know, it has been a challenge to deal with some of the issues. But I think that we've also where we are right now is you know, I along with art well, I'm just going to butcher's his last name, so I'm just not even going to go there Aren't. Yeah, aren't. Aren't. So but we had been focused on trying to find edits to the original proposal that would ideally you know get past the concerns that were raised during IETF last call. In addition, there is another set of people and there is another draft which has been pulled together after this document was removed back to the working group. In the background, there was another set of people that have now also created a draft and it's a much simplified draft and to have it had it set of people that have now also created a draft. And it's a much simplified draft and to how to deal with this issue and where to go with it. So in a way, it's kind of a rewrite essentially of the work altogether So I was also reminded by one of our working group members here that there is another option here that's not on this slide So it was remanded back to the working group and we essentially have three options for what we want to do, although only two of them are mentioned on the slide here. You know, one option is we could just decide to walk away from this work and say, okay, well, since we could get consensus, we couldn't get consensus in the IETF you know, maybe we should just be done and walk away from this work And it is fair to, uh, you know, bring to the work group to understand that that is an option You know, speaking personally, I just"
  },
  {
    "startTime": "00:10:01",
    "text": "I don't accept that that's an option because I think that we really do need a solution to being able to carry internationalized email addresses in EPP. I just don't think that that's something that we can escape. You know, the world needs this, and I think that it is an obligation that that work happen. If this work group wants to put it aside, then that just means that you know, those among us who really want this done will have to reach out to our area director and find a different way to get it done. My feeling is, he'll probably end up tossing it back to us anyway and saying, why don't you guys want to work on it? That's just my opinion speculation. I don't know So what I really think is it brings us down to these two choices here. One is rewriting the document or um continuing to try to find an edit of the existing proposal. My personal point of view, being as on the team of people who was working towards rewriting, actually the two sets of us for these two documents, you know, kind of found each other early on in this week. So we kind of got ourselves together and exchanged our work on And, you know, we're now working together to pull together a document. And in fact, I'm inclined to work with the simplified proposal as is, aren't. The guy, that who was working with me to do the edit And so we're working with the other set of authors and we do fully expect to reconcile all of the things that we think need to be there that should have and that that document then will come out in the very near future within, you know, just a few weeks here. And having seen that, simplified proposal, at least from my own personal point of view, I think it's good I'm hopeful that it will pass the working group and I'm equally hopeful that it will get passed the IETF last call concerns that were raised before Of course, those are both processes we're going to have to go through"
  },
  {
    "startTime": "00:12:01",
    "text": "but you know, it is what it is, and here we are So I'm, my now as chair, my advice to the working group is that wait for a new dog document to come and then we will revisit the technical discussion and we'll do the normal working group review and we'll move forward from there But actually, this is now an open discussion if anyone has a different idea, different preference you want to object altogether, you know, given that this slide, does not talk about, you know, abandoning the work, certainly open to hearing any opinions or comments about any of that, but also any votes of support or competence for the path that we're going down And I see Jim Gould has joined the queue. So please, Jim Gould ahead Yeah, as co-editor of this draft, I've seen both, I guess, versions of the draft that are up for consideration. And I do agree that the simplified one is probably the most likely version that we'll be able to get through. So I'm supportive of that. Thank you Thank you, Jim. Very good to hear that Appreciate it. Scott, you're up next Thank you, Jim. scott hollenbeck I don't mind admitting that I'm one of the guilty parties associated with that group that Jim described I do think it's important, though, to maybe go into a just a little bit of detail of what the simplification entails I noticed that john klensin is not with us so I don't want to speak for him, but I should note that one of the ways I kind of came to the end point where I did with this simplified proposal was by having a direct conversation with John about the concerns that he had shared earlier, which kind of focus on two areas. One was the fact that the current draft in"
  },
  {
    "startTime": "00:14:01",
    "text": "implicitly updates both RFC 5733 and other extensions that include email addresses. So now he had some concerns about what was described on the mailing list as a functional extension which does not exist in our BCP describing how to extend DPP So one goal of this simple approach was to not go there The other goal of the simplified approach was so leave the base 5733 contact object alone meaning it continues to be allowed to carry only an all ASCII email address and simplify the extension part such that it can carry one additional email address that is either All Askey or SMTPUTFA all right there's also an indication there for if that address should be considered the primary address to be associated with the contact, because much like in the way DNS works with mail servers, if you have a little of them, well, the question becomes one of, well, which one? do I try to use first, right? Anyway, so that's the basic idea behind the simplification. As Jim said, I this is a very drafty draft. I think we still have a lot of things to do talk about before it's ready to really see the light of day. But if anyone has concerns about us following, that kind of a path of simplification I do think it would be good to kind of get those out there now before we invest a whole lot of energy and publishing a draft only to have it be DOA Thank you, Scott. I'll just add that, you know, like Scott, you know, Art and I were actually talking with John Clinton also about our draft and our work and trying to address his concerns of what we proposed The big fundamental difference, which Scott has just highlighted here between the two paths that we took was scott rose comment that the simplified version seeks to make sure that nothing"
  },
  {
    "startTime": "00:16:01",
    "text": "would be considered an update to 5733 It is true that the path that we were headed to down, because it was the same as the original core there was an argument that could be made. We didn't actually we never made that argument here in this working group but after some other additional discussion you know, I realized that when Scott had focused on that particular issue of not wanting to risk updating 5733, one could argue that even the original proposal, there was a path which suggested it might be considered an update to 5733 And, you know, so we're all in agreement now. We don't want that to happen And so doing something and doing a rewrite, that's a critical reason why and we're all in agreement there so just wanted to highlight that point. Edmund, you're up next Yeah, Edmund here. I put on my hand actually to ask the question of what are we simplifying so thank you, Scott, for clarifying that But then, so just to lend my support, I think this is an important piece of feature for EPP. So glad to see it move forward Thank you, Edmund. Appreciate that And Missile? Q Mycel, MPI, Enth, fan of simplification and internationalization. I think in general, a simplified process is always better. There should be good reason to do something more complicated However, in this case, I know you've just given an overview wherever you're sitting Scott, but I have concerns about what if the only email address available is a UTF8 email address I'm not going to go tell my customer, hi you need to register and ask email address in addition like their email address is their email address I can't just tell them, no, your email address is wrong,"
  },
  {
    "startTime": "00:18:01",
    "text": "because that's false. That is their email address So I'm not objecting to the way the simplification is being done but it may still require an update to 5733 to say, oh, this field can be blank or something similar. That might still be a neat way of doing it the what has been thrown back to us but i don't think we should simplify at the expense of proper internationalization So thank you for that. And that question actually is in front of us. We're very aware of that question and do plan to deal with it and address that That is a question that, you know, I've had all along too about all of this. And that was actually one of the last questions comments that came around is making sure that you didn't obligate people to have both addresses So, and with that, I also want to add that, to be sure, the document that does come out it will get a full and complete airing in the working group It can be considered new text, and so you will have plenty of opportunity to make sure that your issues are covered They've been addressed and to comment on anything that you think is incomplete. So thank you Pete. pete resnick, just to reassure you a little on this point, remember that if you only have an EAI address, you can't use standard SMT mechanisms to get a piece of email You have to have all of the SMTP extensions that go with it So even the simplified document I think, at some levels, is going to have to say, okay, if you want to use standard mechanisms to receive email, you're going to have to provide NASA email address, and if you don't have one of those, you have to understand that you're only getting it through this other path. And, you know people who implement DPP can"
  },
  {
    "startTime": "00:20:01",
    "text": "either have implemented one path or you know say no sorry you need to at least give us some way to get through to you that doesn't involve these extensions. I think that's fine Okay thank you, Pete. And I think with that, I will close this by saying out loud that at least the sense of the room is, you know, people would like to see the rewrite and then we'll go from there So we'll just consider this an open action item as it has been unfortunately, for quite a long time But hopefully we can move this along relatively quickly once a new document is there And, ORI, please so i'm i'm deli document is there. And, ORI, please. So I'm delighted with the energy in the room to proceed with that. Just make sure you confirm it on the list so that, you know, folks who aren't here can't be in the room. Have a chance. Thanks Yes, thank you for the reminder always um okay so we now have six topics to walk through. We are a little bit behind where I had thought we would be, but I think we'll be okay. So we're going to walk through these presentations and we'll take the time that we have and see where we are So Powell, you are up first. You can come on up while I get your slides going here Unfortunately, it seems you can control the slides because that won't work All right, so thank you for having me. I'm public colleague from Dini, cover this presentation, this part of the me. I'm a colleague from Dini, however this presentation, this part of work will be. It's okay, it's not catching This part of work is not true related to my application, so I'm presenting this individual. You really need to eat the mic especially with the background noise in this room. All right"
  },
  {
    "startTime": "00:22:01",
    "text": "really need to eat the mic. Especially with the background noise in this room. It's good? All right. So a bit of history about this work work so it has been presented by this group already a few years ago so I think as some of the folks who are long enough here may remember it in Berlin 2016 so it has been continued the work at IETF until 2018, there's some updates, but after that the original authors moved away to other areas areas but the protocol itself evolved and that why I want to present you some update how it goes next slide please So, reminder what is is. So it's an application level protocol of provisioning the DNS records to the mainly to the second level zones basically allowing the zone owners to provision these records without really too much deep technical knowledge, what is in these records because this is defined by the service providers so basically this allows the integration between service providers and DNS operators in this sense It makes much less complicated for the end user It's based on the templates which define what kind of set of records is provisioned which also allows for very dedicated authorization of this process and in the end it has the operational benefit for both the service provider and DNS provider because the process is similar and involves less of the moving benefit for both the service provider and the NS provider, because the process is seamless and involves less of the, let's say, moving parts of copy pasting of the content. Next slide, please provider because the process is seamless and involves less of the moving parts of copy pasting of the content. Next slide. So in simple flow how it works. So the end user would come to the service provided where let's say"
  },
  {
    "startTime": "00:24:01",
    "text": "a web interface or a user interface and will express the wish to connect this service with a domain Behind the scenes, the domain will be looked up over the a user interface and will express the wish to connect the service with a domain. Behind the scenes, the domain will be looked up over DNS, who is the operator of this zone. And when did it discovery would be successful the service provider would, let's say, compose URL link which basically tells how to provision this service. And in the next step that the user will be redirected to the DNS provider after authentication authorization of this process the DNS records will be provisioned to the zone and after that the service would be properly connected to the domain. Next slide So the protocol has also some additional features so the templates are already mentioned They define how the record structure looks like. They have also built in variables, so basically the template doesn't have to be fully static so reverse for example a verification code to approve the ownership of the domain name, which is very often the use case I don't know for SS provisioning or all this stuff, it can be provided as a variable to the template and basically provision with the flow. It has two variants One is, let's say, for simple cases of one off-provision where basically, the flow closes when the records are provisioned and there is the second flow with Oaf layer which basically authorizes the updates to the template also at the later stage There is also a conflict resolution built into the protocols of basically a new template would conflict with something that is already existing"
  },
  {
    "startTime": "00:26:01",
    "text": "in the zone, the user will be very informed. Okay this email service that I'm provisioning right now will remove the setup that I have already for other emails service, so there will be no surprises When an email is concerned, there is also a small issue of SPP which basically can be composed of different providers wanting to send emails under the domain. So domain connect also addresses this issue that basically this composing of SPF can happen, let's say, seamless There is also support for temporary DNS records, which are only important for, let's say, short period of time like this verification records and there are also some security measures not to, let's say, spoof this URL, which is let's say, being authorized. And this is also some security measures not to let's say spoof this URL which is let's say being authorized and basically that there's a typo and there's a signature in this URL, right? All right, next slide, please. So this is the interesting part because back when 2016 it was presented as a proposal from one of the DNS programs providers and after this period there was not that much visibility what's going on, but actually I was one of the people working with other DNS providers and service providers basically to improve the standards, to add, let's say, DNS service and service providers to improve the standards, to improve the standards, to add, let's say, the necessary features and to make it let's say, workable across the ecosystem, so there are like 20 DNS providers right now implementing it what we know of at least the so there are like 20 DNS providers right now implementing it what we know of at least on the service provider side it's much right adoption like it's 120 providers which are publicly known implementing it with even more services"
  },
  {
    "startTime": "00:28:01",
    "text": "So the specification is quite stable why I'm here because the community feels that this actually requires standardization to let's say, enable also some other entities to integrate it, which are right now a bit reluctant looking at that it doesn't have a, let's say, formal better as a standard next slide please Yeah, so the way forward so where is a draft? Let's say the report recent version of the specification has been published and I would love to hear some feedback from this group because I think at least many of the stakeholders on the registrar side and on the service side are sitting in the room. Also, if you have any feedback which other groups may be interested in this work or can contribute, give feedback I would love to hear about this And also the let's say, looking for some guidance, how to proceed with this work in the towards standardization especially that it's right now is not fitting well any charter of any group. So it's one aspect now is not fitting well any charter of any group so it's one on one aspect is DNS part but on the application level so not really the protocol itself and on the other side it's not particular EPP or other but I think this is a the right audience here. All right, so thank you. And just to be clear, for all here, it's not on the slide here, but Howell and I have actually talked I mean, I think there is a question here before the working group that will be clear for all here, it's not on the slide here, but Howell and I have actually talked. I mean, I think there is a question here before the working group that will come out eventually, which is if we would like this working group to take on this work, he does not that he can send a message to the mailing list and ask for the working group to adopt it, and then the chairs will"
  },
  {
    "startTime": "00:30:01",
    "text": "you know, do the part that needs to happen. But that's really what's behind here in this work The other questions about whether or not it fits into our charter I have to talk to Ori and we have to see what's going on and see how he wants to handle that but that we can all do separately. With that, we have a bit of a cue here, so let's go ahead, Scott, please Thank you Jim. scott hollenbeck. Pavel, I very much like this very much. But both you and Jim, have already talked about the one question in my head where is the right place, right? This isn't he EPP, it isn't our DAP. Right now our charter is kind of limited to extensions to EPP and our DAP, having said that, I don't think there's a better place in the IETF for it either. So is it rejects? Is it a new working group? I don't know, but as you said, Jim, this is something we're going to talk about. I think this is definitely a discussion worth having. Okay, good. Thank you very much. Q Q, myself speaking with my domain, DNS provider hat on this time I agree. This is a difficult one to place in the IETF, but I think this might be the best place because it technically it is an extension to DNS and DNS configuration, so that would put it in the DNS operations working group but the type of person who is going to be using this is the type of person who is using their registrar's DNS server. So it probably makes more sense here We should tell the DNS operations work group about this work if it gets adopted here and make a sure that they are informed on this but i have no objections to putting it in this working group and if necessary rechartering the second point I have is more technical, and that is from a quick skim"
  },
  {
    "startTime": "00:32:01",
    "text": "of the draft. Everything seems to be based in the simple case, at least on HTT get requests. I would advise that you make an update to allow HTTP post requests because if I have say, 5D Kim signatures, I want to provision, that's going to be longer than ERR URL is allowed to be So come up with a better way to deal with. I have a lot of data I would like to put in DNS that's not to say I don't do dislike the standard. I quite like the standard. It seems quite neat but that's one small technical issue I noticed Thank you. If I can just directly respond to it, so very sound like the standard, it seems quite neat, but that's one small technical issue I noticed. Thank you. If I can just directly respond to it, so there's some practical, practical, let's say, better of using get requests. However, I take your points so it may be useful addition right now the standards allows for this in the OAW flow because the one is happening let's say server to server but thank you for a video Thank you. Hans, you up next. Yeah, this is Hans here from Odriga. Email migration and data portability enthusiast And yeah, I just want to say that a very important work, especially for people you want to move their, you know, services and thus, you know records between providers. So I very much like and appreciate the work of keeping this going on and hopefully having it finished as a draft. Thank you Thank you. Jim, next Pavel, I think this is great work. I think it's a good idea to do it here around, try to shove it across to dns hop we can just let them know that this activity is going on here. The fairing from the DNS op team feels that they have to contribute, they can come to this particular working group. Because the fact is this is a relatively straightforward self-contained problem, I think it's better dealt with in the registry context. And of course, bear in mind of course if it's touching on dns it will end up coming to the DNS direct route one way or another. Says me making a sh- shameless plug. Thank you"
  },
  {
    "startTime": "00:34:01",
    "text": "jim reid. Jim Gould, you're next Yeah, I wanted to say that I was first off impressed with the liberal adoption of Domain Connect since it's in many years since I reviewed it So hats off to the team doing the work on it. I'm really not sure whether that Red Jax is since it's in many years since I reviewed it. So hats off to the team doing the work on it. I'm really not sure whether that Red Jacks is the right place before Domain Connect since I believe there would be the need for more D&S providers to be involved, since I'm not I don't believe registries are involved with Domain Connect correct me if I'm wrong That's correct, uh, Jim, but um, you know, we have, we often have a bit participation problems nonetheless but i'm sure we can can a way to make sure that we get some DNS review and activity over our work here. Certainly the DNS Director, it is accessible to us and we can always submit documents to them for active review in advance of any submission to the IESG So we'll see. Thank you, Rick. Go ahead richard wilhelm, PIR, I'll pick a chunk of what Scott said and a chunk of what jim reid said and plus one both of those. I think this is a good thing to support and better here than anywhere else and what Jim reid said and that the DNS director would get a look at it regardless in the DNS office folks can come on in. I also point that I don't think anyone's made there's some other proposals about how DNS operators can be doing updates to DNS config configurations that have been going on inside of DNS opt that a number of us have been watching. They're exciting extraordinarily, and this is just my opinion clunky with polling and CDNS and I see that with, you know, all kind of loved anybody within your show"
  },
  {
    "startTime": "00:36:01",
    "text": "that is like been pushing on this stuff And I know people have been working on these multi-DNS provider things and switching them and stuff like that. But those things are just awfully clunky. Domain connect since the folks at GoDaddy put it out there years ago has been, it works And like Jim Gould, I was surprised at how many people have actually adopted So I think that this is actually pretty good, Pablo, that you're bringing up up and saying, hey, so many people have adopted it. Let's make it a standard that would actually encourage it more and encourage more kind of good behavior like this And so I think it's kind of great. So in like here why not here as good as any other place? Thank you Thank you, Rick. And thank you, Pel If I may, direct feedback. So yes, I was having also conversations about whether the domain connection as any other place? Thank you. Thank you, Rick. And thank you, Powell. If I may direct feedback. So, yes, I was having also conversations about whether domain connect can be used to provision D DISA records, for example. Yes, it can be used It requires some extension, but this kind of work, which I would love to be putting forward Okay, thank you. One more speaker, Suzanne yeah sorry about uh jumping your cue but all i'll claim privilege of having been called out as DNSOP co-chair We can ask people to take a look at the draft We actually have at least one other draft also that we're supposed to be calling to people's attention in tomorrow's meeting, so we can certainly do that Just, you know, here this is, here's why it might be interesting to people on D&S up, after that usually the way if you're not sure which of two groups a draft belongs in, the chairs will discuss with ADs and so on and so forth, and there'll be something worked out, but there's no, reason to worry about cross-group review because that we can do Thank you, Suzanne. And yeah, so thank you Powell. And I'll just add, as my own summary yeah no it's okay um you know my personal view about this is, is I do think that this work is better placed here than DNSOP, but ultimately that"
  },
  {
    "startTime": "00:38:02",
    "text": "decision will be made by the area directors and the chairs of the two groups We'll chat and we'll figure out what we think so work best. So what I'm taking away from this discussion, is a couple of questions, but the sense of at least this room in the moment is that this particular working group is a reasonable home for this work. And, you know, we'll continue to go down that path. As with all things, we'll certainly make this known on the working group mailing list And we'll check in with our area directors here about what really is the best place. So, okay With that, let's go to our next item on our list I should go over here and put that slide up over here for myself, so I don't have to keep going back to this one. Restfully, he even knows You don't have to wait for me to bring it up. Okay And here we are, please, go ahead Yeah, next slide, please So this is a Resto EPP For those of you who are new, to Restful EPP, a short recap it's basically a mapping of the existing functionality and data model for EPP on a Restful API And doing this, results in some added value as in improved scalability and performance options better usability for developers and end users and security-wise you would be able to use all the existing HTTP security schemes that are available and also importantly it may help avoid"
  },
  {
    "startTime": "00:40:01",
    "text": "fragmentation in the EPP ecosystem because we see right now that there are multiple registries that are already developing or already have developed rest-like interfaces for domain provisioning another item is that next to XML, there is also JSON support for EPP and there are two documents one describing the API itself together with the XML data model and one where the JSON data model is being described. Next place So since presenting last meeting, we have been busy working with where the JSON data model is being described next place so since presenting last meeting we have been busy working on the open APIs spec for the API for the rest of our API. We actually worked on it during the hackathon last weekend Currently, we implemented some JSON support already by automatically generating or converting the existing EPP into JSON schema and using the Open API spec where we're able to generate client and server stops for multiple language bindings, and there was we also already have a working proof of concept that includes extensions support. For example, the DNSAC And so we are in continue to be working on running code for it reference implementation And we also talked or actually presented this during the last center chamber meeting and for those of you don't know, Center is an association for European registries and we got a personal feedback from this community as in, okay, that's something we are very interested in"
  },
  {
    "startTime": "00:42:01",
    "text": "we would like to be able to use or are actually already using in some film Next slide, please So, a little time A little bit less. Little less. You have an impressively face baseball. Okay, okay. Let me try this. Let me try this This is better? Better? Okay, sorry No drilling, so yeah Sorry So, sorry. I have to go back to Prague, where we first presented this And the consensus there was that, okay, this is useful and potentially important work and the feedback was that well maybe it's good idea to create a split between the existing XML and the evolution to JSON That's why we created two different documents And then during the meeting, in Brisbane, earlier this year, again, support, but also concerned that it may not be fully compliant with RFC 5730 and concerns about how to move forward with regards to the Charter for Rehext as it does this work may not be covered by the current Charter. And on the mailing list, there are similar consensus okay this is something we should be able to work on, but does it fit the Charter? do we need to re-charter so something we should be able to work on, but does it fit the charter? Do we need to re-charter? So, a lot of questions there. Next slide So that's why we're here again to ask this group, okay, what is the best path forward from here? So how do we fit this work into the IETF process? Can we"
  },
  {
    "startTime": "00:44:01",
    "text": "adopt this as a work for this group? Even there are questions about, okay, what it actually for this group even there are there are questions about okay what what what it actually is is the extension is it more than extension does it fit in the working group charter or not? We would prefer to be able to work on it further within this working group because we think it does fit very well even though there might be a need for a recharter and if so then we would like to do that in parallel or another option would be create a new working group If the group things okay this doesn't really fit here or if there are other reasons to create a new working group So I would really, yeah start the discussion now just to see, okay, what are your opinions? in this room, what is the best option to go for or are there other options, not listed here? so please let us know I have one more slide. Did you want to go to that or? Sorry, that was the act. No, no. Okay Thank you, Mysel, again I don't think this can be class and extension. I think this is a entire re re-implementation of EPP. I don't think that's a bad thing and I think it is in this working group that it should be. I quite like the idea of making EPP rest because in its current state it is a bit it's a bit weird to deal with sometimes and it would be much nicer to just it maps quite well to restful semantics anyway, so I see this is a good thing to do I have opinions"
  },
  {
    "startTime": "00:46:01",
    "text": "on doing it once an XML and then doing it again in Jason My possibly spicy take is that XML is actually better than Jason for this and we should not do it in Jason at all. I recognize that people will disagree with me and sure, but if we're re-implementing EPP in its entirety anyway, then we should just skip straight to Jason If we go, well, let's define it in XML and then let's define it in Jason later, we'll end up with three implementations of EPP, not two and that will be even more annoying to deal with and it's like, well, which one do I have to implement? And sure, some of them share similar semantics, but it is in effect still three completely separate implementations I personally would quite like to just see a mapping of XML to restfully EPP and forget about Jason because I think Jason has problems about extensibility and the extensible part of EPP is quite important I'm happy to elaborate further on that, not at the microphone Yeah, thanks So the idea is not to re-implement everything in Jason again, but try to convert the existing data model used in EPP, like all the object mappings and extensions to JSON schema and to prevent any issue in the JSON part from impacting the like the development of the A to prevent any issues in the JSON part from impacting the development of the API with XML, there's a split between like the basic API and XML and the JSON part so we could have a API with XML and not yet have the JSON support and work continue working on that and have it later on OK, before we continue back to the queue, I want to take a moment to"
  },
  {
    "startTime": "00:48:01",
    "text": "frame this discussion from a chair's perspective on what is and is not in scope here. So there is the question of asking for this to be work taking on by us And much like Domain Connect, you know, I mean, the working group certainly has its own opinion about that, but ultimately, whether or not something is new work or that the more that something becomes something different than who we claim to be, it becomes a decision of the area director and chairs of other working as to where work lands In the case of this particular work, I wanna tease something apart here. In my mind, as chair as long as this does not change the EPP data model, then it represents EPP. And in that context it belongs in this working group, nowhere else And to the extent that that's true, I look at this and I say, this is just suggesting a different transport for EPP. So that's sort of one path as a way to think about this. On the other hand, if you think of EPP as just the ex-em- XML-based thing, and if this is going to go down the path of a JSON representation, is that a not EPP path, which means it's not EPP anymore because it's something entirely different for provisioning. And to the extent that that's the bio that people have, as you think about it, that means that tells me I'm less inclined for it to be in this group, okay, and it would need to be somewhere else So this is just something to think about. And then a third path that comes to my mind in all of that is if this is, which one of those paths this goes down, if this is compared to EPP, right? So if you go down the second path this ends up being competitive EPP will be that becomes a problem all by itself. Because E.P and RDAP, as they are currently defined are the core protocols that run the registration system"
  },
  {
    "startTime": "00:50:01",
    "text": "They are standards. Okay. And so that automatically means that this thing, if it is something, entirely different and it's changing the data model, okay? then it's no longer EPP. It's now competitive to it And now we have a different set of questions to answer about this work which is it should probably be experimental not a standard, right? Because you can't put something, you don't want to have two standards to do the same thing. And if you are going to bring up another standard to compete with EPP, the question we need to ask ourselves is what is the motivation for that? And is there sufficient support? for moving aside or getting ahead of EPP where we are today? So very quickly, the question I think that we have to think about in whether or not to absorb this work is whether or not it is EPP or not And, you know, how much do we want to keep it being EPP? Because if it's not, we have a different set of questions to answer and a different way to look at it I hope all of that made sense. Just wanted to frame that of people have questions about what I said, you can bring those up to We now have a long queue here. And about eight minutes left in this session. So just a time check for folks And Jim Gould, please, you're up next Yeah, I'll be brief I'll mirror what I said in the past this is a new provisioning protocol I believe Jim it's more than the data model. I've been thinking creatively related to how to comply with ours 5730 with the various things that are in there, but it simply does It's a different provisioning protocol. My recommendation is to create a new working group define the requirements for what needs to be worked on, and then work on it. It's probably the same folks in this working group, but it would warrant a separate working group Thank you. Thank you, Jim. Appreciate that. jim reid you're up next. Yeah, thanks, Jim"
  },
  {
    "startTime": "00:52:01",
    "text": "I think there's enough wiggle room in the current spec of the charter for the working group that any activity in this year is still going to be within scope. I don't think it's makes sense to talk about even talk about re-charter usually the sign that a working group needs to recharter is usually a sign indication the working groups are some kind of trouble and that's certainly not the case we've got here so i think we can say this is in scope provided we've got the blessing of the area directors and should just carry on get the work done if we have to go through some kind of rechartered exercise, it's going to take far too long to get anywhere and we'll probably end up with the same result with the same people and the same co-chairs in the same place. So why bother doing? it? Right. Thank you, Jim Powell, you're next I'll call it Denick supporting of this work, so I think this is a very important work and I still continue to think that there is no better place in IETF than this group So basically this may be defined as experimental in the first place. I think this suggests is quite good, but this work should come be defined as experimental in the first place. I think this suggestion is quite good, but this work should continue and should take place here because the defined as experimental in the first place. I think this suggestion is quite good, but this work should continue and should take place here, because as the team sets, that the group will constitute from the new working group will be probably the same people more less like like here so why why should we should we form a new group for this Thank you, Powell. pete resnick, you're next um just to disagree with Jim and Pavel a little. I think people should worry about the idea of chartering a new working group or rechartering this one, assuming the rest of the work is done, which I'm not convinced it is Chartering a new working group gives you the ability to sort of open up things. What you don't want to end up with is getting into arguments about how a proposal on the table for this"
  },
  {
    "startTime": "00:54:01",
    "text": "doesn't fit into the current charter And oh, well, you know, that's too big a change that's too small a change if you start with a clean slate, yes, it's going to be the same people. You guys already have two sessions this week Having a third with the same people or one of each of, we're working on this and we're working on the old EPP stuff, I don't think it logistically makes a difference for this group, but I think it opens up the possibility that you're not as constrained and worried about where in the charter you are it's not that hard to write a good, easy chart that will allow you to do this stuff and you'll just do it at a separate time than you're doing the rest of this So I would really recommend thinking about writing up a new charter and coming up with a new group Thank you, Pete I want to add a comment. Just you, started by talking about not being concerned about whether you re-charter this or not And yeah, I mean, speaking as chair, in this particular group and for the work that we do here, I will tell you that, you know, my little bit of bias is I like to try and steer people away from talking about whether or not something is in our charter or not in our charter. The question is whether or not the work fits into the kind of work that the group of people in this room do, whether or not to charter it, that's for a discussion with the area director when you come right down to it. I worry because in this working group as we all well know, there's really only about six of us, you know, who really are engaged in every discussion with the area director when you come right down to it. I worry because in this working group, as we all well know, there's really only about six of us, you know, who really are engaged in everything. We're a very small group You know, I mean, in my view, if it is just going to be the same people, I just to soon find a way to keep it in this group. And that's just something to negotiate with the area director you know, as opposed to a whole new group But, you know, that's why I said the question here really for me as, as chair is i want to understand what people think about whether or not this is EPP"
  },
  {
    "startTime": "00:56:01",
    "text": "or something different. I'm hearing a couple of different views on that. I'm not not hearing myself a consensus view on that, which is fine. Just want to take in whatever we can get here. But, you know, I want to understand whether or not people think this is EPP or if it is doing something different than EPP and then we'll figure out the administrative side from that So thank you. Andy, you're up next Yes. So I want to agree with everyone pete resnick said about trying to start a new working group that's um that that can be a kitchen sink exercise That can be an exercise in trying to figure out what is it out of scope. So I think rechartering would be better I do think this is work that should come in the IETF because we do need to, we do need to the market. We also need new people to come into the IETF as well I think the formulation that Jim you have about the data model, I think that is a good, way to think about it and to see if the rest will EPP proponents can constrain themselves and I think that would work probably pretty well the I do have a quibble with something that was said like, we can't have two provisioning protocols. We currently have many provisioning protocols. And the internet is not going to break. So I don't think we want to go down this path of saying, you know, you guys have to go someplace else but and I hope that's not what we're saying. But I don't think, I don't think if we ended up having to get a new working group, I don't think that's a good idea, but in creating a completely new thing the internet's not going to quit working Yeah, and I still think that still is EPP, it may be different but it's reusing the existing data model all the mappings or the objects and support for the extensions So it's a different way of using EPP but it's still EPP"
  },
  {
    "startTime": "00:58:01",
    "text": "Thank you. Rick. richard wilhelm, PIR I'll, I did not do a super close reading of the draft as apparently Jim Gould did. I, it seems to me that there should be a way to do an implementation of EPP that minimally changes things such that essentially all that's happening is swapping out TLS and putting in HD and as if one was taking out TCP and putting in TLS. And when I heard the comment that Google comments that Gould made who said, it's not EPP, then I TLS. And when I heard the comments that Gould made who said, it's not EPP, then I'm going to read the draft. I'll just being clear I haven't. Like, I'm not sure what's in there that would cause us to say that this is such a big change because it seems to me that it should be possible to write a draft that is only touching the transport and not doing anything else and and only as as Q said is leaving everything else alone just doing it because really, I think the key goal for a lot of implementers is the hardest thing that a lot of folks are facing, right? now is finding engineers that can hand the TLS handshake and that level of program because you want to do the HTTPS deployments via AWS and things like that. Yeah, it'd be nice to be able to do some of this stuff in JSON, but once you've gotten the XML code written, it's done and dusted and you kind of leave it and you don't touch it until the spec changes. But the DevOps work and the TLS stuff and things like that and debugging that is a thing that, a problem that we face a lot, right? And so I think that this is a case where you lot of times you say, I think there's a case where the perfect is the enemy the good and I would offer that"
  },
  {
    "startTime": "01:00:01",
    "text": "the group that's interested in this stuff might be interested in taking half a lot That's a maybe that's an international saying, but it's at least an American saying And like just sort of, as Q was saying, like, keep the XML, get rid of T TLS, take HDPS, get the cloud deployments, avoid Yeah having to do that difficult TLS handshake and kind of take the win it's a suggestion you know, as far as like going kind of, and then then you don't have to get into this whole thing because a lot of most of the code is in the ground for a lot of people, that kind of code, whereas the DevOps code and that kind of stuff is much more, I'll stay saying the same thing, loud and slower thing Yeah, no, you're totally right. So there are a lot of running EPP implementations that work perfectly fine with XML No need to update them at this point, but at some point you need to. But I think for new registrar, smaller registrars, of new registries, start fresh again, it makes life a lot easier for developers and end users to just be able to use it restful API. Thank you, Rick Powell, you're next. Just a reminder, time check folks. We all over time and it seems clear to me at this point we're going to continue this discussion on the mailing list So please keep that in mind and try to be brief here. Thanks Paul Covaldick Denig question, whether it's list. So please keep that in mind and try to be brief here. Thanks. Pao Kvalikdenik. Yeah, so I think the question, whether it is EPP or not, so I think this important definition of keeping the data model. So if this group would, or the new group would be charged, I think one of the questions is to answer what are the design principles for the new thing and one of the thing that I would like to have a be charted. I think one of the questions to answer what are the design principles for the new thing. And one of the thing I would like to have is like that the data model will be same or let's say compatible with EVP so the all this ontologies and everything"
  },
  {
    "startTime": "01:02:01",
    "text": "can be basically reused as is even if the representation in Jason and the restful structure will be basically changed and maybe some redundancies which are encoded in the paths and and the headers will be removed from the from the representations but the representation is for me less important than the basically, the data structures, which are let's say, deeply encoded into different implementations thank you pal, and I believe Scott, you're jumping over, uh, Ori, please Right. Thank you, scott hollenbeck. One of the ways I'd like to be able to measure the data model conform right? So my company operates an EPP server Let's imagine for a moment we have a way of doing this whole transport swap thing, right? But ultimately, if I can take the XML in encoded data that comes in via whatever this is called, pump it through my existence XML parser and backend server, and if it can do that and process it all without error this is a good thing, right? That in my mind is data model preservation If I, if there is something happening here that causes my server to break, we have something that's incompatible right so Martin, I actually read the draft, okay actually read the draft, okay? Thank you. And I was encouraged to see that you're taking steps in that direction right and I know you said in the draft there's a couple of things where it's not quite there yet, right? For example, you described it still as, you know, stateless. However, let me ask you to think about stateful and statefulness in a different way. Who's maintaining the state? Yeah, we've had that discussion. You can keep state at the clients for instance right yeah right so I think what you've got in the draft right now, you say it's stateless but the truth is the client is maintaining the state, right? So I think that's a way we can deal with that particular"
  },
  {
    "startTime": "01:04:01",
    "text": "problem but again data model preservation that's priority number one, I think, for me. Yeah, so that's the idea. Keep the data model make the other stuff easier to use And yeah, so there are questions about where keep state and stuff like that So, but the draft is still early and we just want to know if the is this something we can invest more time in and work on it, make it better? without ending up in a situation where we spend a lot of time in it on it and that the group says, okay nice try, but this is not something we're going to include in our working group Thank you, Scott, and Ori. All right steele, responsible area director director So, you know, we're talking about rechartering. We're talking about rechartering group. I think in like you folks have mentioned there's a lot of interest in this work and in the previous work item as well With my AD hat on, these don't seem like they fit in your current charter. So I think, I don't a minimum, you know, we're talking about rechartering And I think, don't be afraid to widen your sort of mind around a new working group that can separate the maintenance work that you're going to continue to engage in for EPP and ARDAP from the new work. I liked what Pete said around being concerned about that, you know work and the old work, you know, potentially interacting with each other in a way that makes it difficult for either to progress without interruption. So these are just my thoughts as I sit in the room with you all. We're going to work with the chairs and other area directors as needed to to work on this issue, but for now I think what we've seen here today is it's not EPP. It's something that's"
  },
  {
    "startTime": "01:06:01",
    "text": "you know, inspired by similar almost compatible with but there's there's enough difference here that I think we really have to be careful about that and we have tom strickx to the charter Good news. I'm young and I'm energy and I'm potentially naive and how quickly I think I can get this done for us working together with you all I'm willing to do that work So I think main thing I want to say is like I like the excitement I see here. Let's make it sure we're continuing the conversation on the list, and I'll be working with the chairs Thanks. Thank you, all. I appreciate that And thank you, Powell. We'll bring this to the mailing list I'm sorry, Martin, and we'll bring this to the mailing list, and we'll see certainly figure it out from there. Okay And now we have a discussion. It's obviously been quite some discussion on the mailing list about RFC 9537, which is our redaction document but over to Andy to walk us through some summary of that. And then we have to check on our path forward so thanks okay so RC 9537, so I have a draft out there discussing how limitations on RFC 9537 that have been developed after we tried to do a client several client implementations. Can you next slide? So just some background here 9537 is a new RFC and what it does is it tries to specifically our explanation identify parts of an ARDAP response that can be redacted using JSONPath. This is the abstract of the RFC. Next slide please All right, so for just some background on how it works there's a redacted array that gets put into a JSON, the ARDF response, and in that redacted array, there's these data structure which specifies what type of redaction method you have There's redaction by removal, redaction by empty value"
  },
  {
    "startTime": "01:08:01",
    "text": "redaction by partial value and reduction by replacement value, depending on which method you have you can have these different these different JSON path expressions that go in there. It's either zero 1, or 2, but that's how it works. So, next slide All right, so at the time, that this became an RFC, we only had one implementation of a server. It was an alpha implementation and there were no known client implementations of the RFC So this is experience from trying to develop a client. Next slide What we did to get this what we did in trying to develop this is we actually developed two clients. One is a web client, and that's the lookup lookup.Ican.org. That was done by an internal team and then we have a command line client, which is an open source client, there's the GitHub URL, and we had a contract to do that. This contractor is experienced in doing, taking RFCs and develop code from that. They're experienced RPCA and DNSSEC. We also created a test server, and we had to do this because there were no production servers out there that we can query that have the redaction stuff in there So we took the same code, so the, in that same code base that has the command line client, there's also a test server and uh cobinion took that and they also extended the test server, so it could emit the redacted arrays And then we also created a 21 test cases and we have a Docker file in this other GitHub repository which actually spin up the server for you and allow you to query it. And anyone can do that You can just go in there and look at the code and run the Docker file We'll spin it up. Next slide All right, so we quickly ran into what I would call limitations in the RFC, things we thought the RFC could do that it's it can't do first off the first one is the redaction by removal, and this is the default redaction method in 9537"
  },
  {
    "startTime": "01:10:01",
    "text": "And this JSON path expression is optional, it's given in the pre-path string. And even if it was, given, so it's optional, but even if it was given, it should always evaluate to a zero set so there is no way for a client to actually be able to identify the parts of the response that were removed because they were removed so and that may sense, but there's still no way for the client to do that The RFC has this non-normative text that says, hey, just you the name in order to figure out your display logic That guidance is actually very ambiguous because the name is not a string, it's either a type or a description so it's either a registered value or not a registered value And because you can't identify what being removed, this actually is not so you can't explicitly look at what the what you have removed. So it's very hard for the client to be able to see signal to the user what's going on. What does kind of reduce? redaction by removal to is what I'm trying to get conceptually call redaction by notice. So, and I'll talk about that in a minute later. Oh, sorry, next um redaction by empty value so that the other one. And this is a, this is a talk about that in a minute later. Oh, sorry, next. Redaction by empty value, so that's the other one. And this is another place where the RFC is very ambiguous. So the text talks about empty strings and setting other things to null So the text talks about empty strings and setting everything to, or setting other things to null. Well, so first off, an empty array or an empty object are not null in JSON. They're just empty bracketed things. But the other thing is, is you can't go see setting arbitrary values in an ARDAF response to null That's just not something that's doable. It's not allowable in the spec, and you will break things if you do that There was an argument, or sorry, a discussion on the list that said, hey, well, 9083, talks about no, but it really is something that's informative text. Nowhere in the RC does it say you can just go insert null. The same is true for RFC 70 with the J-Card RFC. It talks about null in exactly one place and it's informative text describing what the primitives are in JSON. It doesn't say you can go sit"
  },
  {
    "startTime": "01:12:01",
    "text": "with the J-Card RFC. It talks about null in exactly one place and it's informative text describing what the primitives are in JSON. It doesn't say you can go insert it anywhere. All right. So for all practical purpose, redaction by MP value is only applicable to strings. Next slide slide so redaction by partial value um also kind of ambiguous in what the RFC says it has to be for a format value. So that's kind of you know, what does that mean? I think we can we can say, well, we know what a formatted value in as a string is, but what's a formatted value for a null or a Boolean or whatever so that that's that's somewhat ambiguous as to what it means. The other part with Redacta, by partial value is it can't actually identify, like in a string, or even if he could use it against an object or array, it doesn't identify the part that was redacted. It just points to it and says, something over here was redacted. So there's no way for the client to actually signal to the user what was redacted The part in, so this is very important for ARDAP because in ARDA you have a lot of redaction for things like postal addresses or parts of postal addresses and not every postal address is a structured postal address J-Card allows for unstructured postal addresses which are just strings I know it's I didn't create J-card okay the but it's still it's still just strings separate by carriage returns and those when you pull out something from that string, there's no way for the client to understand what part was pulled out because it's not tagged. The other thing is that there are things in ARDAP where you have remarks and notices and there's other data in there that could constitute personal data which is something that would be subject to a lot of redaction policies themselves Next slide. Scott, you have a clarifying question I'll wait for the end. Okay, thanks is something that would be subject to a lot of redaction policies themselves next line um first scott you have a clarifying question okay thanks and then finally there's redaction by replacement value and"
  },
  {
    "startTime": "01:14:01",
    "text": "because this kind of plays off of the redaction by removal by using the prepath string, which is a, optional, redaction by replace value can't actually understand what was being replaced if it was removed So next slide Another thing that we ran into, and this was like running into like a buzz saw, was Jason Path itself jason path is inappropriate for this use case. I'm not going to say Jason Path is inappropriate for all use cases, but for this use case it is I have that link up there. This is an excellent website that someone has put together where they took dozens and dozens of Jason Path implementations and all the things you can do with JSONPath and tried to find the compatibility and it's just a, it's Jason Path is just not interoperable at all So our experience was we never found a single Jason Path library that implemented everything faithfully we found something faithfully we found some that came close but we never could find anyone that did everything that we were supposed to do What that meant was our developers were constantly trying to do workarounds and fix ups and they're parsing Jason Path on their own blah, blah, blah. So it's very fraught with the frustration from a client's perspective Yeah, next slide The other thing about the way RFC 9537 is put together is it is quite complex for the client itself. And so, you know, I had these two developments teams, I was doing code reviews for them and they were bouncing ideas off of me they had some choice quotes about RFC 9537, which you know, I thought I would put up here, but I decided to redact them so I'm glad that joke landed Anyway, the, but here the thing. So in ARDAP to do RFC 9 to 537, the client has to go annotate every bit of the ARDAP model, and that's quite a big for any client to have to do. And depending"
  },
  {
    "startTime": "01:16:01",
    "text": "on how they do the representation internally, their data model is especially if they're using JSON itself, they have to go through this two-step parsing process, or at least some sort of annotation process, and that is quite a significant change to how most of the ARDAP clients work today Next slide So since I put the draft on the mailing list and we started talking about this on the mailing list, the authors, the RFC authors have said, no, no, no Jason Path is completely optional, and they've filed, two or atas about that the we started talking about this on the mailing list. The authors, the RFC authors have said, no, no, no, Jason Path is completely optional, and they've filed two erratas about that. That may have been an intent, but that's not how the RFC reads. Okay, so the RFC abstract does say, using JSONPath, there are several places in the RFC that says we explicitly, identify or explicitly specify art apps values. There are 22 examples of redaction in the draft. Not a single one of them has Jason Path as being optional And also there's a section 5 in there, which is quite lengthy which is all about Jason Path so you cannot hand this R one of them has Jason Path as being optional so and also there's a section 5 in there which is quite lengthy which is all about Jason Path so you cannot hand this RFC to someone who didn't have the benefit of reading the mailing list and have them come away saying, oh, Jason Path is optional. Next slide The other thing, and I've mentioned this earlier, if Jason Path is optional, this reduces 9537 to just redaction by notice. And if we had intended to do that, there are already a notice mechanism in ARDAP called notice which we could have used, and it's actually a little more flexible in the fact that you can repeat them and you can repeat them in multiple languages and there are links they can have to redaction policies. You can't do that with the redaction draft or the redaction RFC. Next slide redaction by notice is also not very good UI. So, one of the things you end up doing, so a lot of ARDAP clients, because this is structured data, they tend to take the data and they tend to visually separate certain parts"
  },
  {
    "startTime": "01:18:02",
    "text": "of the like entities from the other parts of the, of the response to make it more vision appealing, make it more readable and so forth Well, a notice gets mixed in with all the things like terms and conditions and you know here's the status codes and stuff like that that's often displayed at the bottom of an ARDAP response. So what it does is, from a UI perspective, this separates the redact notice from where the redaction takes place and we already have a mechanism. If we wanted to do that, there's already a mechanism called Remarks and Artap that could have done this anyway. Next slide This is also when you think about that, this is actually worse than what you get with who is. So in who is today, when people do redaction, they just put redacted next to the thing that they're redacted If you have a redaction by notice and you're taking that notice and you're putting it, you're separating it from where the thing has been redacted, you're actually, it's not as good of a UI experience. Next slide Thanks to Mario he brought this up on the mailing list so you can kind of tweak the redaction by notice and get this thing called to conceptually put a name on it, redacted by registered notice, and this is where you actually have the register value in the redacted array. And so that's in an IAN array registry. The problem with that is you can have conflicting IANA registry values Some may be used for removal, some may be used for empty value. That's not actually in the registry that's in the redaction notice itself. So there are all sorts of problems with this. It also turns the INA registry in a pseudo specification which I think is kind of not what we want for IANA registries And it's not as precise or of flexible as an algorithmic or programmatic method So this is not very flexible, especially for smaller registries like CCTV or so forth. If they want to get"
  },
  {
    "startTime": "01:20:01",
    "text": "something that's redacted, they would have to go put something into the registry and then hope that the client implementers come along at some point and notice it. And I think a lot of implementers when they implement 9537, if they implement it they're only going to look at that registry once. They're not going to come back and constantly look at it and constantly update it. Next slide The other thing is, even in the GTLD space, this is this ideal. If you look at . . . . . they have this thing called the nexus contact and there's a nexus policy. So they have redaction requirements that go above and beyond or they go further than what the standard DTLD redaction policies are anyway They would have to, or any other GTLD that comes along that has to do this kind of thing they would have to hope that the ARD client implementers are paying attention to that IAN or registry so they could put that business logic in there Next slide And then there was a comment about, hey, we just need to wait and see I don't know what the wait and see is going to be about. I don't think Jason Path is going to get any better. It's been around for 10 years, I think, or something like that. I know it's a new RFC, but it's been around for a while and you have these wildly varying implementations. The other thing is, wait and see does not address the actual problems that are inherent with 9530 itself. So, next line All right. I just want to everyone to remember that the TOW of the Internet is rough consensus and running code And that protocols even though they're a proposed standard, part of the process is once implementers get a hold of them if we find problems we're supposed to try to address those problems Yeah, and I also want to point out that this working group, unlike, like, if you go into DNS, or if you go into SiderOps or something like that, you'll see a lot of implementers getting feedback and getting their stuff into the protocols This work group doesn't have a lot of clients implementers"
  },
  {
    "startTime": "01:22:01",
    "text": "giving us feedback this is one of the rare occasions and so I don't think we should dismiss it. And that's it okay thank you um before you walk away I'm hopeful that you want to ask you one question, and then I know that you want to sit down and just let the conversation take place, and I'll manage all that unless, right? Or wait I can stand here and take questions. Oh, you want to, okay. Well, then I'm going to, chairs para prerogative I'm going to ask the first question you did you see Jody's note on the mailing list about him doing a client implementation and his reaction to that? And he posted some data about that. Do you have any? kind of response to that or comment to make about what he? did versus what you've done with two different? sets of implementer teams? So I don't think it was on the register mailing list. If it was, I didn't see it Yeah, it was okay yeah I'm getting some other nod so yeah okay so I'm not crazy okay well that's my fine. Can you describe what he said? His, his, kolker, GoDaddy, so he gave it to his team to do and uh his team put together a client implementation in two hours. That's really the nut of what he said um and didn't have any issue And I, you know, I, just reporting what was there. It's okay. You don't, you don't have to have a comment, but tom i thought maybe might have had said it was that he did he do the Jason path as optional thing or don't know I Yeah, so we'll just comment but tom i thought maybe might have had said it was did he do the jason path as optional thing or don't know i yeah so uh we'll uh just uh run the cue at this point so that's fine okay uh Scott, you're up first Thank you, Jim, scott hollenbeck. Andy, a lot of what you just described here clarifications required ambiguity, et cetera I mean, there is a reason that this document is a proposed standard, and that's the, we know we probably didn't get it right, right, out of the gate, right? And we have processes to deal with ambiguities error corrections required What about the possibility of developing a BIS draft that a"
  },
  {
    "startTime": "01:24:01",
    "text": "attempts to deal with the issue? that you've identified? Is that something that might be helpful, even if it ends up being a fairly significant rewrite? I mean, yeah we can do abyss. I'm not standing up here to say not to do a bit Actually, I don't really know what the way forward is The, yeah, so if the working group wants to do abyss, I'm up here trying to identify the problems Next. Okay, thank you. tom harrison I think I generally support the comments that are in favor of letting this run for a bit not jumping straight into some sort of BIS process I think there are a couple of things. Riper relying on this already, so have Robert returning out of responses in reliance on this document I think even just pathless use of redacted is still better than with notices because you know that it's about redaction and there's extra metadata and stuff like that It seems premature to say that there'll never be good implementation of JSON path per 9535 I have spent some time looking at JSONPath implementations and it's pretty it is pretty all that there'll never be a good implementation of JSON path per 9535. I have spent some time looking at JSON path implementations and it's pretty, it is pretty awful, but that's what 9535 is kind of pointed out. So I think, which goes towards letting that run for a bit longer And whatever replaces this it can't just be string replaced of values with placeholder things like redacted or whatever, because then that just breaks existing clients. It's got to whatever it does it's going to have to omit fields from the responses and as soon as it has to omit fields it's going to have to identify that in some way. And that goes to either some sort of JSON expression language like JSON part or some sort of registry"
  },
  {
    "startTime": "01:26:01",
    "text": "which describes what's being omitted so you end up in basically the same problem spaces as Redacted as Redacted ends up in, it seems to me Yep No, okay Thank you, Tom. Jim Gould, you're next Yeah, I'll second to scott rose comments related to following the process in creating a biz draft would make a lot of sense, but I do agree with the comments that jody kolker put on the mailing list that we need more implementation experience There will be implementations coming up there very soon, and it would be great if we got that experience incorporated into a biz draft So I would wait a little bit before starting on the biz draft, but pretty much I believe it can be implemented by a client by using the required name and method fields in the draft And I want to point out that we spent two and a half years on this draft. We made many updates, including making the path expressions optional and make the name member required. So the working group did consider these elements and we can learn from the implementation experience and make updates based on those Thanks. Well, the path experience are not optional in the current RFC and if you read it that way, if that's what you want to do, then you're basically turning this into redaction by notice. And that is a worse user experience overall We've disagreed on the mailing list related to this but I did go ahead and create your Rata to hopefully clarify this and we could also add a Rata related to the examples"
  },
  {
    "startTime": "01:28:01",
    "text": "because those examples just weren't updated because originally the path expressions were required, so therefore all the examples had them so i could understand the confusion on that so when we made them optional the examples should have been updated to make a mix So that could be certainly updated in the biz draft Thanks Okay. Thank you. Oh, and Jody is out there Jody, please. Hi. Can you guys hear me? okay? This is jody kolker. Absolutely there. Jody, please. Hi. Can you guys hear me? Okay, this is Jody Coulter. Yeah, so I want to just do a point of clarification We did the server implementation here. We did not do a client implementation for ARDAP So I just wanted to clear that up Basically, GoDaddy's server implementation is rather simple. Most everything is redacted due to GDPR, et cetera You know, and the other thing that I want to add, is, yes, the examples are a little strange They do not, you know, have the type in there because those types didn't exist in the Iranian registry yet. And I think it would be clarifying it great deal if we had, if we could redo this without the type and without having the JSON path in there being required, which is what the errata does The other thing that I have that I'm curious about is that it seems like we're making this very easy for clients to do You know, when you're parsing things like this you kind of already know where the registrant name is I understand the whole JSON path that needed to get to that, but it seems like clients are trying to make this into basically a text version that they can display nicely to people. I'm going to say in a nice way instead of displaying JSON, correct? So they're going to have to put in like registrant name, registrant street, registrant city, all of that stuff And there's really not a JSON path to that People just, programmers are reading that and saying, here's the registrant and here's the address information"
  },
  {
    "startTime": "01:30:01",
    "text": "When you put in the registrant name, saying that that is redacted, I mean, I think from my perspective, I'm going to know where that's at I don't necessarily need a JSON path to get to that Thanks. Let's, I mean, what you're describing is the redacted by registered notice where each client has to implement separate business laws in order, what we call business logic, in order to know what was redacted And that is doable. I mean, that's what would happen what would happen if you got rid of the Jason Pathbooks anyway, but it's not very, flexible for, especially for, smaller registries who need to go put something in or they need to respond to some sort of policy that might only apply to them because then it requires the client implement to constantly look at that IAN registry Yeah. Is that it? couple more Jody any additional reaction or sure um a register. Yeah, that it? No, a couple more, Jody, any additional reaction or? Sure, my reaction to that is that if you're doing it client that's supposed to display all this information, you're going to have to look at your code again and redo it because you don't want to have the client displaying jason to the end user. My experience or what I'm assuming, Andy, is that this client is supposed to parse everything out of here and display it to the customer in the same way that who is is doing right? So, but it's different, though, right? Because then who is? who is all of the tags and everything? that's just straight text that comes directly from the server whereas in Jason, in our ARDAP, you can have these things in multiple places and you have to be able to go, the, if you're doing it by registered notice, you can have overlaps and it does have to know, like there's business logic to say, I know that thing is embedded in this part of the JSON and there's this whole you know a whole bunch of nested arrays so our nested uh structures. So it is, it is much different when it comes in JSON. You are correct that a"
  },
  {
    "startTime": "01:32:02",
    "text": "good ARDAP client, well, a generalized ARDAP client, because there are specialized ones, does have to take that JSON and parse it and display it. But just saying I'm doing a registrant name, that could be I mean, there are multiple entities that could be in there, or if you just say, I'm just doing an entity name, that's really an ambiguous. And that's actually how it would be, how it's represented in the JSON. It doesn't say registrant name, the thing is a name in the J-card, right? So I understand. So if a small CCTV is going to update their ARD app to include more information in it, then it's going to have to be reprogrammed by the clients also so having to look into the INA registry, I don't think it's going to be a hardship for that when they're going to have to be re-looking at the code anyway to be able to display the new information Well, the registries aren't the ones writing the clients. It's just different client implementers that are I understand, but the registries are the ones that are writing the server and they're changing their ARAP, which is causing an issue for the clients, and they're going to have to update the client Okay Okay, well, so thank you Thank you, Jody. I think all of that was a good discussion we have two more people in the queue here jazip Hi, interesting discussion I think I have just a couple of points And we at Aaron haven't done it reduction right now First is, I really appreciate the generic client's viewpoint And that probably as a way of working for this this group is pretty important when we talk about interoperability of a standard, just generally it's between a client and a server and there are a few generic clients out there meaning they need to what Andy was saying a more programmatic way That's first point I wanted to say that"
  },
  {
    "startTime": "01:34:01",
    "text": "please, let's not ignore client-centric input. Second, interesting thing is, and I think we all kind of very proudly said that this can pinpoint equity ignore client-centric input. Second, interesting thing is, and I think we all kind of very proudly said that this can pinpoint accurately the redacted values And we all know what redaction looks like if you have ever looked at it document with some blackened out stuff, right? And clear it is generally in situ. It's like what that means is it's in place. So from a human friendliness, point of view, you can actually see it. Oh, this is something I'm not allowed to see. But from the client perspective, again, that's where this visualization happens. I think clients would desire that accuracy pinpointing And now the debate is, okay start ignoring JSON path expressions, for instance right, as we are trying to say here but i just want to remind the group that making JSON path options does not absolve us of the identified issues. I mean, we can discuss these identified issues on their technical merit, right? And just making it them optional doesn't sort of remove the problem so i don't know so i doesn't sort of remove the problem. So, I don't know. So I, in summary, client viewpoint, I think is very important, and frankly, we should think that carefully pinpointing is important for redaction and especially for more complex generalized clients and any expression language we pick right to Tom's point earlier, if there are, issues, making it a May does not make them go away. Thanks Thank you, jessie lowell I just wanted to comment on the Jason path issue. So we made this"
  },
  {
    "startTime": "01:36:01",
    "text": "optional out of the reason that you mentioned that the object is not there, it's kind of pointless to put a path to something that is not existing there. Well, maybe if you have a generalized model in the client out of the rough specification, you can think of, okay, this path should be pointing to this object with it not very, but it's not that reliable. I think it's highly useful for data which has been redacted in place, so you can pin pinpoint exactly to the place where the data is is changing I think there is a value in it if the JSON path was the best tool, well, it's a standard it's now published So, well, we should we consider that the implementation are not yet there for this standard? when putting the standard on top of it? Yes, no, there's an open question, but I don't think it's was that much of better approach to base on it I suggest that you go to the website I put up on Jason Path. That will probably change your mind about its interoperability I mean we ran into things with Jason Pass where it didn't even support the bracket notation, and that's that's like an obvious thing I'm not not not claiming that it is, it's the question whether if something is put as a fresh standard here at IETF should we consider this yet or no to base our let's say our work on it because it may influence also other areas in this sense Okay I'm going to let Rick jump in here, a quick minute. Thanks I'm richard wilhelm, PIR. I want to destroy extraordinarily gently disagree with something that judges have said because Jez Deep is a gentle soul himself and he's rarely wrong he talked about redacting institution because Jezdeep is a gentle soul himself, and he's rarely wrong. He talked about redacting in situ, and kudos for the Latin With this response, they're really"
  },
  {
    "startTime": "01:38:01",
    "text": "is no in situ because there not a, in my perspective, having worked on this art app redaction stuff since it was first brought up years ago, there is no place where this stuff is redacted There's not a, there's not a sequence of these. There's not sequence and so so that's kind of the only point of that like there's not a spot where it's like being blacked out or, or, or, sequence. And so that's kind of the only point of that, like, there's not a spot where it's like being blacked out or sharpied out or something like that. And so it's it's kind of, we're used to seeing old school 853 or whatever the RFC, who is responses where they're kind of, Andy had an example of there but there really isn't like that in RDAB and so there isn't a place where there's not a sequence of these responses So I just kind of offer to that folks that when they're thinking about these things, that there's not really a sequence of these things Thank you. So in current ARDAP today, you will see some servers responding the very same way you see some of the who is servers. They just say if there's a name or something redacted for privacy, and that's very, very common Okay, thank you, Andy Here's my takeaway from all of this as as, chair. You know, we've had a very substantial implementers experience documented and provided to us I think that as a working group, you know, we have a responsibility to consider, you know, how to respond to that You know, one suggestion that was certainly put out here in the room was to attempt a biz version of the document and incorporating all the things that I think needs to be there You know, I want to remind us that another option is just, you know, explicit suggestions on G gee, if this little bit of text was this, that would help a lot kind of thing. And then we can figure out, you know, the original document authors can still have ownership of writing a biz document and what to do with it. But in any case, I think this discussion moves to the mailing list as we continue"
  },
  {
    "startTime": "01:40:01",
    "text": "to evaluate what's here and what we want to do with it. And that's the right thing to do. That is process from my point of view. Okay We are way behind schedule at this point. However, I've only been squeezing myself. The last three presentations are actually mine and I'm at the end and I'm hopeful that we can still get them in in the 2020 minutes that's remaining. So that's the time check here And so we're just going to quickly jump into each of these and see where that takes us. These slides are actually loaded These were all loaded this morning but I think you'll be able to read them here and see what's here. I really was just trying to put some data points up here to spark our discussion in the contact objects just like the versioning and signaling discussion in the next one, these discussions start earlier this year and i think at the time you know, there was certainly some interest in doing something with these things like oh this this sort of felt interesting In the case of the contact objects, I mean, yes, contact objects are well defined broadly deployed the EPP specification, 5733 in particular clearly defines a contact object and there's really no question about that. And, you know, it's a standard. So it is where we are, and that's the baseline. Part of what motivated some of this was J.S Contact coming along, and it kind of proposed a new specification if you will, dream being a little loose with that phrasing there for a contact object, moving it from XML to Jay a new specification if you will dream being a little loose with that phrasing there for for a contact object moving it from xml to jason and you know because they had a community of people that sort of wanted to do that And that's a reasonable thing. But it did raise the question of gee is this a new thing you know is it a competitive thing? You know, and what does all of that mean, and what are the consequences of it? And then- simple contact became something that was just sort of tossed out in discussion, which was interesting you know, the realization that at least in our registration"
  },
  {
    "startTime": "01:42:01",
    "text": "system, yes, we, inherited the J-Card idea of a contract object, but bottom line, when you think about it in registration systems in our domain, registration system, we don't need most of what's in J-Card And it does sort of beg the question of, why did we adopt all of that? Why didn't we start with something simple? So the whole notion of simple contact was sort of attractive and interesting at the time, but it never really moved any anywhere. So the question is what to do with this discussion I mean, is there a problem to be solved here? You know, what do we think we're doing? You know I mean, is there a competitive content? object definition that we really want to consider? And do we? really have some particular motivation for doing that? I think it's fair to say that the simple contact idea has kind of been shelved. So, I mean, it really kind of isn't out there and a real consideration JS contact does seem to have a community you know, do we want to think of it as competitive to? EPP or do we want to let the J.S Contact stuff move forward, finally? and, you know, be experimental instead and let it go on its own path and see what happens to it in the market, that kind of thing So that's kind of where we are to make it concrete i would say that we should consider this, we should take JS contact, let it go to experimental, with the exception of dealing with the signaling issue, which we'll get to in the next section And, you know, consider this closed and we're done with this discussion. So, uh, interested in comments, Andy, you're up, please uh yeah as the author of simple conduct I kind of disagree with the, it does not have wide available what was I can't I can remember actually what you had on that slide anyway the I do think what happened with Simple Contact was, marc blanchet made a very interesting statement. I think it was on the mailing list that we really only need if we're going to replace J-card, we only need one solution going forward"
  },
  {
    "startTime": "01:44:01",
    "text": "And so Mario, who was doing the J-S contact, paired down, some of the things in JS contact that made it, I mean, it don't think it's as good as simple contact, but at certain point, we're talking about style issues here And so that's why we, we, shelved simple contact because Mario did pair down with some of those stuff in the JS contact draft now I read JS contact just recently and there's some other things that I think need clarifications I think JS Contact would be a lot more powerful if it removed is signaling and trans sections in there Also, I think it was offered that we take J.S. Contact to experiment maybe because again marc blanchet made another statement, we've already got the sunk cost of J-Card I'm not a big fan of J-Card, but I've written that code several times, both for clients and servers, and it's not it's not hard it's just a little confusing So. Thank you, Powell Yeah, Paolkovaik Denig I think the problem to solve was actually had its origin at the discussion of the reduction because Andy presented this ugly expression let's say, and actually it had this the reason why this expression was like this, of the adjacent path was because how the contact structure is expressed and aired up and everyone had a feeling okay, we can do it, do it better and i think jess contact has the other issue, but it's generalized for other purposes and probably it's too much. So if just contact would be the answer, I would be very positive to profile it, to just narrow it down to the features that we really have in the registry context rather than just taking the"
  },
  {
    "startTime": "01:46:01",
    "text": "generic specification as this and to live with all the let's say downs and highs of it yeah so this this would be I take that, but this problem with the reduction of the current representation is existing and it won't go away. So maybe we should we should put holistic view Okay, thank you for that Before I try to summarize and suggest a concrete action, let me get through these next couple of slides on this topic Again, you know, similar to the contact discussion it partly was born out of JS contact because it has that transition signaling mechanism built into it into the space And Andy kind of just made reference to that in his intervention in the last section And we along the way, you know, had these other things you know, I don't know, semi-related documents, right? I mean, versioning, extensions, etc media type. We took them on board Originally, we accepted them as a working group item because we felt like, oh, there's actually a problem to solve here, although we didn't clearly define at the time that we took them on what that problem was I think we kind of had a sense that, gee, we should say something about versioning and signaling and we should figure out what that really needs to look like and solve those problems. And one or more of these documents might be the right baseline you know, or an opportunity to integrate some features. And so that was kind of what we had intended to do. From my point of view as, as chair, when I went back and I was trying to look at all this and look at some of the old discussion about this I've had a couple of people come up to me privately in separately suggest, well, gee, you know, I mean, I thought we knew what problem we were solving, and I would just observe that, well yeah, we sort of had an idea what we wanted to do but I ever felt like we actually stated in so many words on"
  },
  {
    "startTime": "01:48:01",
    "text": "the mailing list that this is what we're doing And additionally, no one actually stepped up and said, okay, I'm going to lead the process of moving this forward in this way. You know, and as we all know, work doesn't progress unless somebody is going to actually move it forward and volunteers for it, right? So you need someone who's going to do that. Or we never actually, you know, had that kind of traction. So, um progress unless somebody is going to actually move it forward and volunteers for it, right? So you need someone who's going to do that. We never actually, you know, had that kind of traction. So, you know, I think that frankly, for me, consensus is really still not apparent. I sense some ambiguity. I mean, I think there's still some interest in, you know, trying to deal with providing some guidance for our ARDAP extensions, at least, you know, a few people have indicated they like that topic. You know, the notion of being able to version extensions seem like something there's at least a couple of people interested in You know, working consensus is always a hard thing for me to judge and my co-chair, Antoine, although he's not with us, would agree with me on that point. He and I often have interesting debates about whether we have consensus on something or not which is always helpful, though he's good to have another voice in these things. So, you know, I mean, it is really kind of a question to us here. You know, is there, is there a problem? or is there no problem? I, frankly, my leaning, I'm just going to put it out there right up front here and see what discussion we get from folks. My leaning is that, yes, there actually is interest and I think we can get enough people together to do with this notion of providing guidance to extension development and addressing this versioning issue. I think that the ADAP extensions document is the right baseline document to take that from, but that doesn't have to be taken as gospel here. We can go to one of the others you know, once the working group decides that they're clearly want to solve this problem, if we want to start somewhere else, that's fine with me I'm certainly not going to make this happen in a certain way"
  },
  {
    "startTime": "01:50:02",
    "text": "I do want to, you know, take note of Jim Gould's recent message on the mailing list which I think was Monday. You know, I mean, I think he had very articulate and really good message in talking about these three documents here and distinguished them and at the same time, you know, indicating where they could be moved together and maybe they should be combined and and turned into something So I think there's work to be done here I really do. I, I think there's at least a leaning on a set of people to do it And so I'll end with this point and then we'll take some discussion here Ultimately, for this stuff to move forward, somebody has to step up and say, hey, I'm going to take, you know, pen to paper, be the editor for this, and we'll hope to move the discussion along in the mailing list. And that's kind of where I am. So I want to, we need to get to a clear articulation of what we're doing, perhaps what I I've said on the, on the slide here and we'll finish that decision, obviously, on the mailing list and somebody has to volunteer to move it forward. And I think that's where we are. So with that, Andy please, your first step in the queue What do you mean by someone has to take? the pen? I don't know, I'm not clear on what you're actually asking. I mean, because we have draft authors for these, sorry, drafts Are you trying to say we need to put together a I forget what you call those things? a design group or something? design team that's design team the way that our group has worked, I mean, this actually in my experience here, this is a unique circumstance for us in this working group. Okay, I know what other working groups have done but in our working group, usually we only have one document that comes forward and then we all work around that document So there's already a document editor or author, whatever you, you know, however you want to do that where it's coming from, and we move forward. This really isn't a new unusual situation for us. So"
  },
  {
    "startTime": "01:52:01",
    "text": "I kind of picked one but honestly, we have three documents. Any one of the set of authors for any one of those three can stand up and say, I want my document to be the starting point Here it is. Now let's talk about whether it solves the problem that we've decided we're trying to solve or not So I think the, those three documents, I mean, they're all doing something different The ARDFX media type is about client signaling to the server, about what extensions it wants The versioning is about the server being able to say what versions of extensions it has. And the extensions document is really all about best practice, well, not this best practice but taking care of a lot of the ambiguities that exist in the current RFCs and we have current extensions that are in the ARDF registry, which violate some of the things that people think are what the are the the are supposed to do so the extensions draft is really about how to take care of all those ambiguities. And it was really about, let's try to take all those discussions, those high level conceptual discussions where everyone was like kind of talking past each other on the mailing list for the last four years and let's let's get that solved and that's what that is the yeah, so I mean, in my opinion that should that should be something we do the other stuff I could see how we could we could maybe prioritize it or something, I don't know. Okay, so just to be clear, my takeaway from that is all three of these documents deserve the opportunity to go forward independently And you just want that particular option to be on the table here. So just to get to Jim Gould's comment, I saw the mail he sent I didn't, it was a lot, so I didn't quite digest everything he was saying. I do think that the versioning and the media type,"
  },
  {
    "startTime": "01:54:01",
    "text": "I don't know if they can be merged, they do have to be compatible, and I think that's true So yeah, we can take both of those forward. I've read the last, actually he just published a new version of the version I haven't read that. But I think they are compatible but we could, we could maybe. And I don't know, make sure that they work together I think is what we need to do, so. Okay thank you. I am going to lock the queue. Time check. We got six minutes here, people. roland schott, no, Andy, you're up. Oh, you're up big. Scott, you're up next scott allan back uh let me just build on an echo what Andy just said here, right? I see value in all three of these. I definitely think we need an R-DAP equipment of RFC 3735, which was, you know, guidelines for extending EPP. I like the idea of taking a really good close look at these and seeing, you know, which pieces need to be consistent with each other and maybe which pieces of the versioning draft and the ex ex-media draft need to find their way into the extension draft. I mean, if they're describing best practice for extension So let me stop talking Do someone else some time to all, thank you. Thank you, Scott Jim Gould, you're next Yeah, I see a path for all three drafts And I could even see the extension drafts going broader. It's all three drafts. And I could even see the extensions drafts going broader. Scott brought up a good point related to RFC 3735 for EPP. So there was a lot of ambiguity within RDA that we could help address in the extension draft. It's related to the versioning and the X Media. I just thought that they could be merged. They don't need to be merged. They saw draft. And it's related to the versioning and the X Media, I just thought that they could be merged. They don't need to be merged. They solve different problems, but the versioning draft itself does have a normative reference to the ex Media draft related to how to signal from the client what extensions are desired from the server So I see them all being a"
  },
  {
    "startTime": "01:56:01",
    "text": "a... Thank you, Jim Powell Pell Pell So I slightly disagree that there is no overlap between the specs So the versioning specification has also specified the weight of signaling for the client of the server, which also the media type there so I would rather like to have these two concepts match into one which is dealing with, let's say, signaling between servers and the clients of the versioning and the supported extensions I think this will be of benefit Okay, thank you, Powell. And Jim, you want to add something? Yeah, I do. An up update was made to the versioning draft to include support for signaling via query parameter as well as X Media So, and it provided the requirement that the server supports both. So that's the way we're able to solve, I guess, or use both mechanisms Thank you Okay, thank you everyone. Wow, very, very engaged in quick discussion. All this, I love it. My take a from this is that each of these documents deserves an opportunity to move forward To the extent there's a relationship between them, we need to find that in our discussions so that we can make sure the document are compatible and we don't do anything against each other. And then to get back to the question that Andy asked me way up front, that just means that as always, you know, the document authors for each of the documents need to press on moving their individual documents forward on the mailing list, and that's the way that would happen So this notion that these things are on hold because we're trying to figure out what to do with them is the issue that we've closed at this point. And or you put yourself in the queue. Please go ahead. We've got three minutes to do my left"
  },
  {
    "startTime": "01:58:01",
    "text": "topic, but I think I can handle it. Go ahead. Oh, you have one more time I'll let you go Okay. I probably should have just put these up right away. All right I can do this quickly. I believe because, oh, this is not going to should have just put these up right away. All right. I can do this quickly, I believe, because, oh, this is not the right set of slides Gee yeah, I have to talk to the chair about the fact that those are not the right set of slides. Okay, well, here the real point in all of this um i there's another slide. I'll put up, revise slide deck up because it has much more information It's got a couple of links in it too. We had the joint meeting between ICAN TechOps and REJX back in May and the purpose of that meeting was really to expose to a broader set of actual registries and registrars because we really only have a few here in this group, in the IETF side. But on the ICAN side, you know, I hit a fora. The tech ops group is a great place to hit a broader set of GTLD registries and registries So kind of brought this topic there And what it was was it was myself and Arndt in particular who kind of presented to the group at large and exposed this proposal that we had for how to deal with ID and variance. ID and variance, there's a pilot work that's been under development for a couple of years than I can about how to deal with IDN variance, at least for a policy level, and what we need to understand here is there is very clearly some technical work to be done. EPP and its current form, and RDAP in its current form, you know, just don't support ID and variance. And so as GTLD registries and registrars, we need to be able to do something. So there's work that has to happen We actually, Arndt and I do have a draft. Some others have joined us on the draft I see admin is back here now too. We actually had a meeting earlier yesterday, I guess it was"
  },
  {
    "startTime": "02:00:01",
    "text": "We kind of dug in on this thing too, and there's been a few other people in the ICAN community, technical people I've been working with very closely. So we actually have a internally to ourselves we have a working document. And what we expect to do, what we will do in the coming weeks is we will eventually publish an internet draft and it'll be an individual draft and at that point then the work will become fully featured and exposed for everybody and then we'll be asking for this working group to adopt looking at the extensions that we're proposing for EPP and for ARAP to support IDN variants. The ability to meet the needs of this proposal that is going to come out of ICAN. And that's where that be. So there'll be plenty of time. I had thought about actually what I had done in the slide deck in the revised slide deck, as I put a couple of slides in there to talk about the technical principles and guiding principles for the work that we're about, actually, what I had done in the slide deck, and the revised slide deck, as I put a couple of slides in there to talk about the technical principles and guiding principles for the work that we were doing, figured I was going to expose that to this group here. We don't really have time anyway but I'll get the new slides up there So you'll be able to see that and we'll be in good shape as far Folks will be able to look at that. And then when you see the draft, we can consider this working group adopting the work, and then we'll go from there It'll be fully open here to the IETF So jim reid, you're in the queue, please. Quick question, Jim, just a question with cloud clarification. Will this promised draft have a clear? indication of the problem statement? I'm not sure about what the difference is going to be to support these IDN barriers and maybe other people in the civil position to me Yes, it will. In fact, I can succinctly tell you what the problem statement is. The problem statement is with IDN variance you have to deal with domain names as a set And that's a fundamental shift in obviously or overall architecture, which is individual names. That would have been in the revised slides if I had gotten them posted there, you would have seen that, actually. But that's the fundamental technical"
  },
  {
    "startTime": "02:02:01",
    "text": "principle that changes everything and why there's some things that are needed. So, and I apologize for the quickness of that. We're actually already two minutes over cue the fundamental technical principle that changes everything and why there's some things that are needed. So, and I apologize for the quickness of that. We're actually already two minutes over queue, but please, ORI, and if anybody has any other business, think about whether you want to raise your hand in a minute and we'll do that too. Go ahead, Lord to thank you for a wonderful meeting, all the engagement a very active list discussion, and a bunch of open work. I look forward to talking with you about the opportunity to recharter or contribute to the charter for potentially a new group with some narrow focus and clear milestones on some of these issues perhaps feel free to come grab me in the whole narrow focus and clear milestones on some of these issues perhaps. Feel free to come grab me in the hallway if you want to have a discussion. Thanks again to our chairs for running successful meetings at this IETF. Thank you Thank you very much. All right. Appreciate that anyone have any any other business that want to jump up and allow them? This really has been a great meeting this particular two hours. Vary engaging. Really appreciate all of discussion all the comments, and look forward to moving forward. We've got a lot of good stuff and opportunity in front of us So thanks again. Thanks to Rick for making some notes for us. We're adjourned, folks"
  }
]
