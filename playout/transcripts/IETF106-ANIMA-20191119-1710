[
  {
    "startTime": "00:00:04",
    "text": "thank you and we should be another one careful Reeves taker you Oh I said we did a mistake and you want here but okay anybody else also enter sure thank you and speaking also supposed to the unit content and all the slides already uploaded interior of a PSP this is publicly shared polishing and Harris this is a meeting at Inga we have the 720 key trade and first the SAT of Monaco and to plan that\u0027s the working with token image update the second is grasp it I also the working of cooking the young church will be added for the new chatter town square and then that\u0027s the information dissipation in augmentation and ASA environment and you know what we what we need and I have your size oh sorry yeah okay good okay thank you yeah and then we have the issue for the agenda today once right okay and that\u0027s the cleaned up at the world I will mark and Rashad and played for the working group now stories we have a after copy but three "
  },
  {
    "startTime": "00:03:05",
    "text": "for the they s a p-trap to already submit or ISP homes and we still have one single discard and also brass key is already on the circus where she and still have to discuss hopefully we could you know fish that onyx neatness Oh because eternally for press key we actually has to finish that before we can really process the lots following up work and then we have the cross a guy about twitter twitter we article then that one is I believe which state impurity a working group stage and we have a constraint virtual adopt last year and all these tapes which we could ship okay okay so we are into the first which these folks "
  },
  {
    "startTime": "00:06:15",
    "text": "no the case is this never cannot turn out the what we were uploaded that\u0027s a pro week Pete all right welcome to the neverending ACP token so in ITF 105 basically we updated the ACP document to version 20 and at that point in time there was the video from the security Directorate outstanding and the the Jen art was also not closed so that was an oversight by Alicia so that was closed and then I try to work with the remaining discusses from Bankhead book and he also taken over the review of I referred all her the other security AE but I hadn\u0027t received any any response after I hear from him so there were some delay on his side pin I had in 20 in the feedback set there were 2 discussion points left open from my side that I had to do I try to answer them in 21 which I posted before the deadline for IKEA on 6 didn\u0027t so the first one is one that we discuss also in IKEA 105 and that was the use of RCA 22 address as the object to encode ACP information in the ACP certificate and basically after the discussion in 105 the conclusion from the working with C 2 has been met with one stick with this because it had shown all the benefits now I\u0027ll get back to that point at the little bit later and then I try to close all the open encryption detail gaps and "
  },
  {
    "startTime": "00:09:16",
    "text": "that\u0027s basically what\u0027s in SS 21 I wanted to quickly go through those so basically in the ACP certificates there were a lot of updates me reading through a lot of documents trying to ensure that we have the right requirement about RSA and EC BH support in these certificates and ultimately the high-level gist of the requirements is as little as possible but also that we can leverage the new technology so we must do RSA because it\u0027s still more widely used and the latest standards security track RFC\u0027s are referred to also are asking for RSA as a mess ec th would be better because it achieves you know with shorter key links the same security but we would reasonably only be able to do it in networks where the certificates are only used within the ACP so that you know that all the devices would be able to support it so it\u0027s not widely enough spread if we wanted you to use these certificates for other authentication like applications running within the ACP so and that\u0027s basically what the text says in so many words and all these magical details likely elliptic curve sizes and all that stuff was hopefully correctly stolen from other RFC\u0027s that are at upcountry and the feedback from them in verbally when I mention here seem that this is fine 6:7 security associations simply added that we must have a perfect forward security and also everyone know about the fact that we made for go actually encryption in the secure channel protocol is a secure channel is defined to leverage underlying layer 2 security Association like for example mexic and then the secure channel itself might only be required for the authentication and the derivation of the underlying layer 2 encryption function so in that of course would avoid us to duplicate encryption efforts that were already doing it air 2 and so now I have a two person I think so so then also um TLS for brat so that was not specified in before and then being the expert on TLS suggested some specific profiles of which I selected also the minimum hopefully equally a sufficient subset in support of also AES and then our RSA and EC DHA GCM wala counter mode also is known to be better "
  },
  {
    "startTime": "00:12:16",
    "text": "so basically because we don\u0027t have backward compatibility needs for graphs with all the new it\u0027s it\u0027s hopefully sufficient to have the very small things other details also stolen from other typical security documents so but kind of to me sounded good but then when I looked at the process I kind of woke up to learning something new that I didn\u0027t like so the ihe reviewers we had since I - 13 is are listed here right so originally the document was own factor in Anderson and then we had all these survey used from the iesg members listed there and the problem is that the process I didn\u0027t understand and that seemingly all - nobody else you know was actively working on is that when an isg member leaves the isg his vote for the count turns into a pumpkin so it\u0027s uncounted anymore so the total number of reviews we need is not reached anymore and besides we would have also needed a new owner beside karim anderson or kind of casting the guest vote and taking the process to the next step like you\u0027re not moving it in the end so all that kind of turn up when i brace the question with the is g and the reason why we don\u0027t have an owner by the way is that the logical owner would be the AG of the group Ignace but he had to recuse himself from the document and so the new owner to be selected would also have to define the process so what\u0027s the current status so the security review needs to be closed Benjamin said that he pretty much likes all the things except for IPSec parameters seem to be missing one or two pieces he is not an expert on that but he\u0027s given me the specific name of a person I should work with for whatever IPSec parameters may be missing I hope not much and then he wanted to actually discuss with the working group the RFC 822 address and I told him that I think this this would be so important that we\u0027ll make a slot for him but he doesn\u0027t have time right now but he\u0027ll have time tomorrow so that\u0027s basically a slot that we need to discuss the ACP domain information element with him so the proposed new ad owner of the document is going to be Erik Venky I was talking yesterday with him he can only finish his review in January but in December to prepare for that and he would then be submitted to the IHG hopefully he could already start getting two additional reviewers beyond him that we need right now and I\u0027ll also push out another revision right now this week just to summarize the changes since we entered the is G in - 13 because there is a lot of textual change but it\u0027s you know 95% of that is a lot more explanation but in a very few small limited technical changes I think for other stuff in those were refinements so really no major technical change but if "
  },
  {
    "startTime": "00:15:18",
    "text": "you do add if obviously there\u0027s a lot of texture change so and then of course I started to bitch about the process right so talk to Felicia and raise the case and data tractor that you know somebody gets alerted because seemingly you know people like me not aware of the process and isg also not following up on basically already in time reassigning additional videos all right any questions okay looking forward to it this is for a ticket so by next two years oh yeah yeah we\u0027ll have a big celebration I know you ate everybody for that it\u0027s crazy and we then we could have full rfcs at the same time education okay well I saw for the first ideas okay this should be fairly short thank you so just a quick reminder for people to reread that draft recently it talks about a model in which there is a functional library called by autonomic service agents that communicates by some inter process communication magic with the core functions of the grasp implementation and underneath those core functions there is going to be one or multiple demons it could depending on the implementation model and those demons do things like listening for X unexpected unicast communications and listening for multi costs and so on and there are going to be some various caches so that\u0027s the model in which we are working the function library is the what the user would see just a little bit so the recent changes to the document that we have improved the discussion of layering to make it more correspond to what was on the picture than it did before mentioned the necessity for a demon or multiple demons which is an implementation detail improved the description of asynchronous operations in particular adding some discussion of callbacks which were not mentioned before "
  },
  {
    "startTime": "00:18:20",
    "text": "one of the reasons for that is my skill set doesn\u0027t include event loop programming or callbacks it includes my skills that includes threading which I personally use a computer scientists find much more satisfying than event loops and callbacks but hopefully now the document covers both ways of implementing the asynchronous operations we were asked for more explanation of the two nonces that appear in the API when that explanation is in the text basically the aasa\u0027 nonce is a way of saying yes I am the same autonomic service agent that caught called you 10 minutes ago and the session nonce is a way of tracking a session when there are multiple sessions going on in parallel which is fairly standard in fact in in an event loop environment at Michael\u0027s request we added an age limit parameter to the discover primitive because in fact he\u0027s absolutely right it\u0027s useful to be able to say I don\u0027t want to hear about the result that was discovered 10 minutes ago I only I want a fresh one and we clarified a bit of the text about the dry run feature of off grasp not the feature itself but how the feature is represented in the API so next steps this is an informational document it says it\u0027s a conceptual outline of an API for a grasp it\u0027s not meant to be a tight spec you can\u0027t code directly from it at least I can\u0027t and it\u0027s not at all clear to me that this stage in the life of our software that it would be even be a good idea to define anything like a definitive spec for an API which in any case isn\u0027t something the IETF is very good at so our belief is that as an informational document this is pretty much as good as it gets and it\u0027s ready for a working group law school well maybe there isn\u0027t a victim that\u0027s the last one yeah so that\u0027s really all I wanted to say and it\u0027s the chairs decision whether we start that discussion now or on the list or what can I see a show of hands with who has read the document so who thinks this is ready for last call so I believe the okay yeah I registered there was a "
  },
  {
    "startTime": "00:21:30",
    "text": "reviewer from wampum but you know most of his comes addressed I believe so yeah I mean bingo we got good comments from Michael and from Guangdong and I think we addressed both of them that was the intention yeah so if the people who thought they read it and thought and didn\u0027t put their hands up for ready for Law School I would like to hear the reasons why email is better okay yeah we should ask this question does anybody hear your hands sinks this document is not really for working group must go okay so we\u0027ll confirm that meninist and there will be two weeks period for the working for Vasco whether that\u0027s you know next week or the week after yeah okay that\u0027s great thank you steer you yes or is it that\u0027s a chair yeah but we should fun today given how this is working group stuff I didn\u0027t allow to sit yes okay so a couple years back we started the new charter process as well and that actually finished in September sixth when the second Charter was approved so I wanted to talk a little bit about what that means for us so first just a quick rundown over the Charter I it\u0027s actually three slides so I I think I don\u0027t want to necessarily read the first two slides because they\u0027re mostly the explanation for people who are kind of not engaged in the working group so let me skip to basically the third slide which is pretty much defining the scope of the second Charter and I think we should read through that one as a reminder for us so the scope of possible work items are as follows additional work are subject to extra approval from the responsible ad so first extensions to the a and I including all variations of a II and I deployment such in virtualized environments information distribution within an autonomic network a and I OMP operations administration management provisioning interaction with yang based mechanism defining the domain boundary and membership management of the domain second one support for autonomic service agent so that\u0027s basically beyond the a and I so that\u0027s why we can adopt this now including design and implementation guidelines for a say lifecycle "
  },
  {
    "startTime": "00:24:31",
    "text": "management authorization coordination of ASI oops and I think there is missing here in this slide a new section brueski features including proxies enrollment at a adaptions over various network protocols variation of ultra formats generic use of autonomic network and new grasp extensions options for them including bulk transfer an SSD interworking autonomic resource management autonomic SLA assurance autonomic multi-tenant management autonomic network measurement and finally integration with network operations entries including autonomic discovery connectivity to knock yung based Ani or a SA management and reporting autonomic functions from notes to Knox so that\u0027s basically a really good set of areas where we can explore work so let\u0027s try to see where we stand with the work so as a reminder of where we stand with at least working group adopted work right now it\u0027s we\u0027ve got two RFC\u0027s we\u0027ve got these three documents that are waiting for the next two documents the ACP and brewski and we have two of these working group documents right now we just heard the grasp API and there\u0027s also the constraint ultra document that we already adopted because they already fit into charter round one so um we also have milestones and I think they\u0027re Ignace there there was something miserably bad happening in transferring before 105 I put milestones in and when I was looking them up right now a lot of them look like there is a mixture between dates that were meant for call for adoption and the actual submission to the iesg which was always meant to be about a year after adoption for the working group so somehow would be good if we can sit down and try to fix these ones because the red ones are kind of seemingly not correct so this appears just to be a technical thing you decide what dates you realistically expect those to have and and that can be fixed but I thought to remember that we we always had the milestones for adoption and they\u0027re completely missing if we want to give up on adoption and just saying because you know if we don\u0027t adopt then this admission to is G is kind of milestones I had the discretion or a discretion of the working group okay so this is for you to decide what do you want to achieve right and then I did put all the milestones for adoption and then kind of about a year later for each of them from my understanding talking to the authors for submission to isg so there is a lot of missing and the dates of these so in any case right I just wanted to let the working group know that this is these milestones are I think not correct right now so we\u0027ll kind of need to fix them okay so now what are the target draft "
  },
  {
    "startTime": "00:27:33",
    "text": "for working through the adoption so the ones that we did mention in in the discussion for the Charter are exactly the information distribution over grasp that\u0027s going to be presented here the guidelines for developing autonomic service agents and the constraint adjoined proxies so basically we\u0027re going to you know ask for their adoption as well for the joint proxy I haven\u0027t seen Peter yet and I sent an email out to him figure out because there was not even a presentation scheduled but well he is registered to be here in person but he hasn\u0027t arrived that\u0027s what I read from the attendance list so we\u0027ll see but otherwise we\u0027ll just take it to the list that\u0027s fine of course so that would result with the two ones that we\u0027re having right now in a first round of follow-up documents in fund five drafts for the working group but of course there is more so here is basically the documents that are currently not expired and associated with the animal working groups so for the ones being presented here obviously you know express your opinion about how much you think they\u0027re already in state ask for adoption if you think that\u0027s appropriate right now and as the working group member please you know consider when you know we have a list of more documents to be adopted which ones you think would be highest priority so that we also make sure that we work on the things and you provide the feedback to that is most important for you there are more expired documents so for the authors of those are please refresh and then if you if you want to have them taken up now with the new charter if you have any I think that all the documents that we had reasonably discussed in the past and that expired because they were out of charter I think 90% of them would be within the Charter I think there are several from the same author so the author should pick what they would like to work on first but I think certainly what we didn\u0027t do in the Charter was put together priority lists of what we would like to work in brewski and I think that would be a good discussion to have tomorrow when we\u0027re talking more about the different brewski drafts and where they are but actory um before we doing too much for the brewski discuss I would ask the question toward Michael how long do you think the Persky document will take to be ready for public I mean out of the is t4 RFC with the luster to discuss okay yeah if if "
  },
  {
    "startTime": "00:30:39",
    "text": "that\u0027s the case I don\u0027t have any problem but you know given the history we have the non process with the frisky and ASAP I\u0027m not really confident unless by myself I mean I think maybe to rephrase your question is there even a risk in adopting brewski enhancements as long as brewski isn\u0027t done right I think we can make a bet whether any change that could still happen through the ice to review of brewski would have an impact on this other documents but I would think in many in most cases of my understanding about these follow-on documents that wouldn\u0027t even be the case I sincerely believe that there will be no significant technical bits on the wire changes that the only possible risk is that there may be some significant technical operation no comment about dr. it hurts when I don\u0027t do when I lift my arm please don\u0027t lift your arm right so that\u0027s the only thing someone will come up with a this doesn\u0027t work it since we don\u0027t like this blah blah blah I says we\u0027ll just don\u0027t do that right no can\u0027t we\u0027ll cross and text out or something I don\u0027t know that\u0027s the only thing I can see at this point and I think that after August and September \u0027s endless threads that we\u0027re done with that ok so I think there\u0027s no risk of adopting new things that way ok thank you ok I guess we can move to the next distribution so that\u0027s all sir so my name is Archer I can presenting for the audience so we have this document around for quite a while and this document essentially describes the way how grass can be extended such that we can do information distribution or let\u0027s say it is some kind of publish/subscribe service within a and I so what we actually did we defined two specific modules inside there so in in the other you would have essentially an information distribution sub module let\u0027s say which has three sub modules additionally and all that is then broken down to past Isis who usage of synchronization messages across all through extensions of trust so this is what is described in the draft now specifically in the latest version to version 12 that we uploaded recently we have extended some classes "
  },
  {
    "startTime": "00:33:40",
    "text": "in the queue management sub module which is probably not very important to discuss right now what\u0027s more important I guess is the question of the relevance to the rich heart ring so that what Turrell is presented before you have seen information distribution as one of the key points in the reach out at aneema and this document actually addresses this information distribution in a specific way so while we can discuss the quality of the document certainly rewrite it improves the language and all the things the toriel things can be done a lot to this document it\u0027s by far not finished I would say that we need this document to become a working group document and this is the major point essentially so we can we can refine many technical things we can even see you know where whether we are using grasp as we should whether there are alternatives to this but we have a requirement session which identifies why we needed at all how it can be done so all the things somehow I think are relevant to the information distribution question in general and therefore we would like to actually ask the group and the audience whether this document could be adopted as the working group document as opposed to the personal contribution as now any more questions no Chava I haven\u0027t read the draft recently but in what you mention as updates is it that you consider our information type to be relevant to events only or no the point is that we have some kind of understanding of Raza either instantaneous transfer but let\u0027s say you already know to whom you want to send information okay then essentially the node can directly say these are my recipient notes and then essentially it can go this can be implemented with grass without many changes today okay music synchronization messages then again you can have a completely different model where you can say okay I have some information that is somehow of relevance to all notes but I don\u0027t know which notes because I don\u0027t know where which AFS will be essentially interested in that and maybe even though it\u0027s joining later I could be interested in this information still did not expire and then we have some kind of a publish/subscribe model and for this different types of events we have different cues and the events actually more account for the second time because we need some kind of motif right and just clarification again the question again is it necessarily by need to grasp or we can have order sonication mechanism so there is information that\u0027s a good question so the point is I think the answer is probably no okay this document does the following we first discuss what needs to be done and why we actually need the information distribution as you know supported service from the other and not just on some kind of random thing because right now it\u0027s undefined and we clearly have it as a need you know just for intend distribution for example we always discussing this but now it\u0027s in the "
  },
  {
    "startTime": "00:36:40",
    "text": "Charter so we then went on to define also a specific implementation but this is probably a specific implementation which I guess we can discuss later but we need some kind of document like that to start this discussion and to have people contributing agree I think at some point we will have to make a decision in the working group about whether we stick the two aspect together but needs to be distributed and how versus the specific implementation or link to grasp so cross has of course a maintenance - yeah symmetry we may decide that it\u0027s better to take both together exact so in principle yes but grasp has of course obvious advantage of already being there and somehow being natural is suitable for some things and we do not you know it\u0027s it\u0027s kind of signaling protocol very generic and we do not mean to use it for bulk transfer of data but we certainly mean to use it so to say as notification that oh there is a new information element available right or you know download it there something like you yep my comment on that last point is that what I discovered of the various toys I\u0027ve been building with grasp is that the discovery mechanism is actually pretty good when you want to actually do something which isn\u0027t it in grasp terms of negotiation or a synchronization it gets a bit clumsy which is why I recently added a trick to my implementation where you could hand the session over with just send receive calls as if it was normal TCP or TLS and I think that is the way we could play this to say protocols that don\u0027t need gross don\u0027t use grasp but they can use the discovery features both with the hats of the working group participant and as as an energy member now it is particularly about API and extensions of the API given that the base EPA document is informational and it talks about topics which are much closer to the implementation details than the protocol specification details but certainly will raise questions in energy of why we are trying to document something like that there is for several years there have been discussions coming from either side on documents which specify use cases applicability and things like that and while there is no strict single answer to that in general such documents they are not seen to positively and not with this I\u0027m not saying what you\u0027re doing is plain wrong the question that I\u0027m raising is what is the value of specifying implementation details of the "
  },
  {
    "startTime": "00:39:41",
    "text": "API IDF certainly is not a place to standardize implementations and for that the vendor that that wants to do that they don\u0027t need ATF they they need a market for that and market will decide whether that API is applicable or not trying to specify the protocol mechanics and the functionality of that certainly is within the scope now there the way how I see the CPI document and extensions to that they are going find deeper into the implementation domain again I\u0027m not saying that this is wrong but I\u0027m just saying that this will raise questions so what benefits you see going this path is this really needed what is not why it is not enough just to standardize the basically protocol mechanics and the recommendation guidelines why do you really need to specify you can ask you a question are you talking about the API guidelines or are you talking about the information distribution it within this context I\u0027m talking about the both aha I can obviously not answer both but I can only answer for that part for that part I\u0027m not sure about the information will be bit that we need to see but what we actually specify is part of the functionality of the Ani which we believe is required for information distribution so we have grasped there which is required to set out the Ani and it\u0027s working already right and if we want to have some kind of pub/sub service or this information distribution in general then we need some additional bits and flags within grasp which are absolutely not api relevant but which are relevant to the protocol on the wire that is what is being specified then again again in this document we do firstly analysis of requirements we say yes that\u0027s why we need it and then we specify a solution as we just said we could discuss probably the you know details of the solution but certainly it\u0027s about the protocol on the wire because we need to enable an additional functionality completely I would say orthogonal to what is so far in there it\u0027s not only about opening communication channels or secure communication channels right but it\u0027s about storing some data within the autonomous network infrastructure for some short while or for longer while and so on it\u0027s about the pops-up integration inside of it so it\u0027s not only about ApS that part I so I think we both understand that but if if we read the document without this prior understanding this question naturally arises and if you look from a perspective of ayesha review there are those who are not following what is happening here certainly will raise that question so maybe this needs to be explained rather detailed in in the scope of the document what it is trying to define and what it doesn\u0027t try to define okay understood in any case the "
  },
  {
    "startTime": "00:42:42",
    "text": "document for me from my perspective the co-author is not yet ready for any kind of a house calls so we absolutely need to revise it several times several rounds because this is obviously probably this is true if this is the impression that the reader is getting then we need to get rid of this indeed yeah with my working groups chair Adam actually has opening impose document they stand on along API document is informational document which provides some you know extra information and - how may may you know implement the grasper and how that may help the you know Apple a year asa to use it so that\u0027s useful but for this document I\u0027m with you I I think this document shouldn\u0027t depends on the you know grasp API document or all the API I just look at through your document there\u0027s a not part machine you know in the cross a P I and how to integrate with grasp api which i think is we shouldn\u0027t do that okay yeah understood you are doing a standard document and to reference a lot to our informational document which which is not right so I say that part of information is still useful but move that from the main document maybe into the appendix what are the degree so how precisely that is done is for working group to decide but what should happen is that it very clearly states the scope of what it tries to define and what it doesn\u0027t try to define clear comment taking yeah understood so to answer Ignace a question about the api starting first um i think one of these principles that I always you know expected a anima and a and I to help with but which I think we haven\u0027t really well spoken out is the ability to actually decompose the so far very oft monolithic software in a network device to be composed of interoperating components from different vendors so one way for example to think about the API document in a term that I think would make it a lot more amenable to you know this resistance force against api\u0027s is if you know the API was specified in something like a rest specification as opposed to the more "
  },
  {
    "startTime": "00:45:42",
    "text": "informal approach that we have chosen in the document and then I think it would become very clear that just because the two components the provider and the consumer of the API are sitting on the same system it\u0027s still an interoperability issue that we want to solve right so that\u0027s my answer the the second is for for your document I think that I\u0027ve only superficially read it so I\u0027ll need to spend more cycles on that but it seems to me that it also only gives very coarse guidelines as there are some extensions right so that\u0027s basically a real specification part but there is not even a single let\u0027s say example interoperable solution you could build out of that right not always right not notwithstanding the fact that obviously the idea of this document is to allow multiple different independent you know information distribution solutions to be built it might be helpful to have let\u0027s say the minimum single reference one included in the document to basically you know make it clear that we\u0027re really talking about integration at two levels generic things to be applied to multiple solution and then one example maybe that\u0027s that\u0027s a solution yes so to the second comment I guess we wanted to do something like that that\u0027s why we adopted grasp because by by essentially saying grasp can do this in extending Ross we are going for something quite standard as at least as some kind of minimum you know denominator which is common then to an Ani then there could be other like maybe out-of-band ways for information distribution as well where grasp could be just setting up the channels okay so this is also possible but the indeed I understand and I fully agree that this document is not ready for publication we need more contributions to this that\u0027s exactly the point so fight somehow you know a personal draft which is more or less evolving with the authors we never received any kind of review or comments from the community okay so please do not be surprised obviously we do not know how the community understands what we are trying to write and yes the language has to be improved in this 4k that\u0027s for sure so maybe maybe one suggestion for the API document in and we can take it offline it\u0027s just brainstorming right I mean we have some successful work about api\u0027s and taps right and they also don\u0027t have you know a concrete API but they\u0027re all abstract api\u0027s and I think that was also the goal of what Bryan\u0027s document is trying to achieve so as not to you know forego different intentions like rest being a possible one but shouldn\u0027t be constrained to that so I was only giving rest as an argue example but maybe we can you know seek the help of taps to basically ask them what minimum formalism they you know think is necessary to basically achieve that level of standard that we currently have there is that with that I know I mean as I said we can take it offline but if "
  },
  {
    "startTime": "00:48:42",
    "text": "there is expertise maybe we can use it right so just the the standard one who has read this document one two three doesn\u0027t count two three four okay who thinks it\u0027s ready for adoption okay thank you we\u0027ll take it to the list so what\u0027s the next you see okay this is supposed to be tied to a particular draft but I won\u0027t really be talking about it very much and it will come back to the question that Ignis raised a little while ago but explicitly recent changes to the document none we\u0027ve had quite a small amount of feedback except at the very beginning and that in my opinion is why we need to discuss the more abstract question of an anima ecosystem so why do we need one we in a very general sense deployable autonomic network needs more than an ACP and grasp it needs to achieve management goals that the network operation center cannot achieve manually otherwise why are we here my opinion that requires a library of autonomic service agents and if we\u0027re using the grasp model and our library of grasp objective definitions and it requires tools to deploy and oversee the ASA\u0027s we have some documentation it\u0027s sort of addressed some of these questions including the one I\u0027m Thea reticle II talking about I won\u0027t read out the list um but we got no clear working group goals in that area in my opinion and then we have the question of what ecosystem issues can the IETF tackle missing standards operational guidance implementation guidance and "
  },
  {
    "startTime": "00:51:42",
    "text": "what he what issues are out of scope for the IDF and who should be encouraged to deal with them so I think this is a generalization of Ignis if we just stop you know at the on the word protocol we in the sense of the industry then nothing will happen so someone has to make this ecosystem stuff happen but there\u0027s a limit to what we can do in the IETF and that means in practice is a limit to what the isg will will will let through the ballot there\u0027s other IETF work we might want to consider that conference in an autonomic Network net confer over ACP that conf over grasp I just added this line this week use of muds for authorization in an autonomic network so the concrete examples of things probably need to play nicely with an autonomic network which are going on to to efforts that are going on in the ops area working group that\u0027s all I want to say I want a little bit guidance from the working groups to where we should take any of this topic and both the chairs want to go to the microphone Michael Michael Richardson so I had a question I guess you\u0027re working along Apple days ago and someone wants to know about the animo stuff what\u0027s that all about right and you know I realized I didn\u0027t have a really good elevator pitch at the moment um but the question that they asked was is this going to permit permissionless ipv6 network extensions in in the same way that we typically an ugly Lee you know plug not for forced into v4 networks and just extend them without permission right because it\u0027s gonna let us do this with v6 and look I said gosh that would be really good it\u0027s a good result wouldn\u0027t it right isn\u0027t that what homeless were trying to do yes exactly so the the part of the and whether we succeeded or not is a good question but maybe the permission lessness of the of that not for for scenario that it was completely permissionless and also unmanageable was a bad thing okay but maybe we need to find some intermediate point and so I go back and I was sitting there looking your list of slides and so what happened with our address assignment AAS a spec it\u0027s it\u0027s in mr. FL that\u0027s where it is "
  },
  {
    "startTime": "00:54:46",
    "text": "okay it\u0027s in miss Roth okay right okay so for a long time I was in limbo but how it\u0027s going to Hill right so so my take on the stuff and in sort of not so terrible that reach are during took so long and I guess in the end I actually think we need to take a brick a breath we need to let our queue empty also that our mine you know our collective minds kind of empty with some of the issues and we also need to let some of the running code catch up to the whole scenario and so I would ask our area directors and ASG to please not take our lack of activity is a sign that we have no work to do but rather that we\u0027re too busy working to bother talking about it for a while fair enough that\u0027s my opinion okay you agree it\u0027s the topic matters yes I think the topic matters I also want a point that I think that that the many of the participants in this working group have have gone through forcible job changes or employer train jizz with the result that there\u0027s at least a couple major vendors that are essentially not in this room anymore mm-hmm okay so that\u0027s a pretty significant thing and the argument for why we need standardization if we only don\u0027t have any as many large vendors in the room is maybe a good one but I don\u0027t think it\u0027s I mean I think we still important so as soon as ACP is in your name sir Tallis yeah so I\u0027m not doing anything right now and until basically the ACP document is out of the iesg queue but then the answer would be that I\u0027m still coming from what I known to be working from pre standard implementations and what I think is fundamental and that\u0027s pretty much the DNS SD for service discovery of important you know services in existing network so really the pragmatic stuff I think that allows you know people with existing networks to see the biggest value as opposed to the things that I find cool like all these you know how do i structure Asin these things which are more researchy which I love but I don\u0027t think that they necessarily give us the you know shortest term extraction you know with the industry which unfortunately is very backward facing well that\u0027s just my personal opinion that\u0027s one of the reasons why I did the experiment with interfacing respected Iain SSDs you know not even hard to do no no but I think you raised a much longer set of things and all I was saying is my preference is to you know work on the things that hopefully give us a more immediate affection to you "
  },
  {
    "startTime": "00:57:46",
    "text": "know not the most forward-looking networks but the ones that one in here the incremental think you know what the last document on my slide was the diaphragm Vict because you shall mention that the animal is a guillotine so I\u0027ve got two questions one continues because animal is lost I killed him then I think the implementation and obligation scenarios are very important then can you give some examples for the application scenarios and implementations another quality is because animal is legacy demon and if they want to be lazy shield between the animal and at a i/o anniversary learning then my question that my talk religion example scenario was already mentioned which was the address assignment mechanism where here where the RFC is stuck waiting to be published but you know we we did that right at the beginning because it was one of the use cases that emerged in the original buff that led to the formation of the working group and and the idea there would be that there will be no more need for manual address assignment within an enterprise network because the anima stuff would just go away and do it so you you could find that draft which is sitting in the RFC editors queue and you could find some code which I wrote to implement it a couple of years ago and we just you know it\u0027s all part of the queue that we\u0027ve been talking about for forgetting our work finished in terms of use of AI and machine learning as far as I\u0027m concerned that\u0027s still a research topic which the NMR G is looking at I don\u0027t know how we\u0027d integrate it I feel that we should do right but I don\u0027t know yet how we would do it yeah I agree with you that it should be should be there the idea there would clearly be that you would have an autonomic service agent that would be connected to the AI system and could talk to other autonomic service agents that were not connected to the AI system so you have to have almost certainly a central resource for the AI which is used by distributed systems and we can easily do that if we only knew what we would be doing with the AI I would like to comment on that when we did our reach other way actually leaves the AI out of scope intentionally and actually as brown also explained 80s possible "
  },
  {
    "startTime": "01:00:48",
    "text": "you know we here\u0027s the machine learning or AI mechanism with sit in the some certain autonomic service agent but that\u0027s nothing to do with the protocol or the signaling we are standardized here so basically that just means some logic for favoured by the machine learning or AI use the anima infrastructure if that\u0027s the case of waste spotted but we\u0027re not going to you know really discuss how the algorithm algorithm or machine learning algorithm to be applied you know through through the signaling or the autonomic Network distributary Brian can you go back one or two slides up please no slide three please at the point when you say requires a library of a size I will say I agree with that I think we\u0027re on e ma he\u0027s right now we have developed some protocols framework different things that are useful now we need to have a bit more like the guy before but examples use cases application areas so I think this is important to understand what what could be then the require the summarization requirement or the sanitation needs to address different areas so maybe we need some kind of use case document so a phase where we try to see what are the application of what could be the types of Aiza I\u0027ll just finish on that is also because but on that thing that we need to have use cases for me this is where we reach a bit the limit of what I ATF is used to do with respect to your question and in ecosystem because then aisa for the security space Oryza in IOT or is it and then this is not anymore a NEMA or even anymore it\u0027s a bit like cross cross area or even application space that can be copied outside IETF so for me this is we need to investigate that this could be channeled in the ayah in the working group through a set of documents or discussion points but I am Not sure the IETF I mean to develop an ecosystem understood the IHF is the right place for that and I\u0027m saying it\u0027s not feasible but I don\u0027t have good example is in mind we have I think we talked some years ago some couple of IETF ago about having also more implementation which may be participation to the ATF a cation or open source projects which can be also a way to make an ecosystem live and an "
  },
  {
    "startTime": "01:03:51",
    "text": "final point final comment I think for this discussion I\u0027m not sure we have yet a good description or a good understanding of what Asia is or could be because it\u0027s essentially functionally oriented and to bring back to the question of the use of AI or machine learning inside this essence it\u0027s valid question and then it opens all bunch of discussion about this kind of how to describe an essay in terms of capabilities to analyze feelings to take decisions so this aspect of cognition intelligence which is really not the place for IETF I mean maybe more iron chef but so this a bit not it\u0027s a bit blurred that\u0027s exactly why I have this question about what can we do yes I probably for this note should be sitting up front but I think just a general note to you know all the co-authors of the current drafts or drafts to be looking into this problem right I mean they\u0027re there a lot of other working groups where there could be you know help and interest in in what we specifically are doing so when I started the DNS stuff of course also went to the DNS working group as I said maybe you know for API things something taps could be helpful right I think there is nothing stopping us from proposing to talk about the subjects that were interested in in what we think is the best working group to you know create more feedback or also you know in these other examples that were showing that that may have the use cases and create you know more advancement through that so that\u0027s definitely also some additional work for authors not simply thinking that we can operate in a silo but you know create contacts elsewhere in the idea a remark more it\u0027s a about what aces are or could be I usually take the comparison with a virtual network function or network function I could see a parallel between an ASA and network function but typically network function this is not really IETF which is developing network functions you go to there are many other places where people are building or proposing those functions and also the require the standardization needs on these network functions it\u0027s a I mean needs to be clearly understood and defined and this is part of I mean one point I will have in my presentation on what could be some somatization nodes for that now I think that\u0027s a very interesting comparison because the reason why things like vnfs are so managed to to the largest X tends to be you know something the ITF can ignore is because it didn\u0027t really change you know the api\u0027s and the protocols use but it just changed the shape of the individual notes right from hardware to software whereas what we\u0027re trying to do is decompose you know the "
  },
  {
    "startTime": "01:06:51",
    "text": "the monolithic system and create you know it would be between the aasa\u0027 interoperating interfaces and being able to compose that right so that in the end something for example what what you\u0027ve been doing in terms of defining dependencies right and and and these complex management operation that we can\u0027t solve right now that they can be done easier for example right so from that perspective I think is the explanation why what we\u0027re doing might have a lot more need and opportunity to be done in the ITF as an you know new interoperating extend routes things then what traditional Vee have done so far big-nose McDonough\u0027s now main thing is I\u0027m really happy that this type of a discussion is happening and this is clearly needed now let me expand a little bit on that with with a few say rules for assumptions first this is ITF working group not IRT F working group and therefore the deliverables should be say tangible engineering components now IETF is good at working on components now and that that is what the individual working groups produce IDF is not that good and working on combining those components together and then building something like a system that\u0027s one second thing my impression from from from especially reading the slide that is in front is that it is at this point of time it\u0027s a question more about the requirements and understanding the problem space and where that problem lies and only then trying to address the components which can be addressed here in some other working group right now it sounds like we are trying to find the so we\u0027re trying to use the solutions that we already have the fragments and then try to find out the problem for that this doesn\u0027t seem to be practical in my view there needs to be an outreach into the user community to understand what the problems are the way how ACP started it started with a very narrow but a very specific problem right and therefore it resulted in in a tangible and employable solution if we are trying to look into broader scope overall into into say all these autonomic nodes now without having a detailed understanding of a problem space I think this belongs or not belongs but turns much more into IRT of type of work than ITF type of work so this is something that in my view is the first step to end the stand what is the problem space then so I said problem space into the components which can be worked either here an animal or maybe somewhere else so it "
  },
  {
    "startTime": "01:09:52",
    "text": "appears that some some dispatch style mechanism well some areas have dispatch style groups which bring in the new incoming work and all sorts of other things and they try to distribute and find the home for that maybe something like that is needed there were similar discussions in here this meeting to about the IOT IOT systems or work more on a more broader scope than just an individual product the protocols and components in IOT domain I think this has a lot of binding together and maybe that could be one place where both the anima and I which he related topics are being discussed and and and of sliced for the further work but the starting point at least in my view appears that we need to reach out to the potential user base of of these deliverables potential deliverables to understand whether what we are trying to do is a problem for them and whether we understand what is a problem for them now this is definitely not ITF community now we have severe problems of operator participation in 90f and that will not get better anytime soon therefore this is an outreach question the question to what what organization of what venue do we need to outreach and again I think this is one of the topics that needs to be addressed first before trying to do something on a protocol work yes we are engineers and dealing with protocols it\u0027s fun and easy but the fundamental question is what do we need to do from a problem perspective okay we\u0027re now reaching the point of catching up with the end of the slot time for this last so if I may the answer is they need a tangible demo okay and and may say that sends you the ietf but the point is that that\u0027s the next step for the work and we can\u0027t come back to the rest of the stuff until we get those guys excited and that requires work that that is of a different kind right so that\u0027s all so that\u0027s why I\u0027m saying please don\u0027t shut us down if we doesn\u0027t look like we\u0027re actually doing something at the IETF because it\u0027s just not happening here it can\u0027t happen here for a little while until we have as you say the operator has come in and get excited alright so now I\u0027m joking I will not shut down the working group while it is meeting because it was already a precedent and that would be a clone but what I\u0027m saying we might not need to meet but that doesn\u0027t mean we\u0027re not gonna meet we\u0027re inactive is what I\u0027m trying to say okay we might not need "
  },
  {
    "startTime": "01:12:53",
    "text": "face time as much for a little while but but we have a lot of documents that are it that are still processing and we probably might need face time for that but we might not be adding new documents because we just it\u0027s it\u0027s just not it\u0027s just not ready yet right you are the working group you have reach at it you have your milestones now it is for you to work on those milestones well if if you are looking at an ad who will guide you for all of that I think I can help but this is for you to do that once we are six years old with you the milestones dates then probably the question of shutting this might be raised but there are no such intentions at this point of time so this was a great philosophical discussion we need to come to the close of this I wanted to remind that the starting point of all of this was the draft that is talking about the guidelines for ASAS and I think as much as we understand that this is at the fringes of you know the actual ability to create interoperating running code but really at the starting point of that well we want to make a call for adoption after this meeting so just for the people in the room who has read the document on two six seven the ASI guidelines okay who think it\u0027s ready for adoption two three four okay thank you yeah of course like all the time right whatever we do in the room this will take over okay thank you so I would like to present work that is being done in a another group in Etsy some not representing this group I\u0027m participating in this HC group but it\u0027s real individual view so don\u0027t take this as an official communication but I think it\u0027s related to the discussion as initiated by Brian on this a cycle system and I mean how to approach this and maybe the fact that other groups are doing something could could help us in this process so just very quickly I have a lot of slide but I will not present all of them this is in the slides for your reference if you want to look a bit more but to give you some context so it\u0027s either SM it\u0027s an industry standardization group in at C stands for zero touch network and service management so you can see with the relationship with anima it was created roughly two years ago it has been renewed for second two years terms recently so we trillion again for two "
  },
  {
    "startTime": "01:15:55",
    "text": "years the main objectives and to end automated network and service management architecture that has been already provided to be supporting both with the Greenfield and broomfield environments doesn\u0027t need to reinvent everything but to try to collaborate a lot with open source projects especially for instance onap which is the main contour part of this is G and also other standardization for the ietf EGP PSMA everything that is irrelevant for that I\u0027m so created foundation for diverse open such groups to produce interoperable solutions the idea is really to have something workable after links if you want to have more documentation so this may look a bit complex but again the idea is not to go into the data market texture but just to explain a few aspect of that so the group has been developing a framework architecture one of the some of the key elements it\u0027s a service based architecture we are more used to see a functional based architecture so there are some good advantages to that and especially if we think about a Z as agents or services we could see a good fit with some potential reuse of these aces in this architecture so you have management services this is the atomic entity by providing a management service that is offered service based approach and the management function is a implementation that is providing the user role to consume or produce a service so this is quite also software we hunted approach integration fabric is in fact a bus to connect all these services on the management functions together and so to provide also some utility services to discover to register to connect different forms of communication patterns can also be provided by the integration fabric so the idea is really to provide a lot of Independence between the components and not to have each of the companies to win and then to implement different communication interfaces or discover interfaces but to rely on the shared components cross domain that has services this is to be able to collect data of course if you want to have automation and close the loops you need to know what\u0027s happening so to collect data collect data from multiple sources but also share those data between the different consumer of those data this relates well to the work that I was mentioning and so this to make this available through this bus website typically or whatever form you would like to support management domain this is since as LSM aims to be applicable end to end I mean typically different network segment so administrative network so there is this notion of domain this is where arbitrarily whatever deployment you will group your services and functions together so if you say I have a mobile run a type of domain and it connects with the core domain and transport and "
  },
  {
    "startTime": "01:18:55",
    "text": "cetera so but each of the functions will be handle at the scale of the domain and then you have this end-to-end service management domain which is to provide the entrant service view where you will point to the different domains in order to realized or your service deployments and service management this is just I will not go through these three slides highlighting a bit more the different components of the management domain the entering service management domain some typical services that have been also specified in the architecture so you can see for the different domains data collection analytics intelligence orchestration control integration fabric services also for registration discovery data services type of of services storage persistent services so this is typical type of services one link I would like to make now this can be partially seen as a component of aces so we can also borrow from that if needed infant aggression fabric details so now a bit relationship to the Ada and closed groups aspects so there have been so this notion when if this is an automation framework to rely not mandatory but at least to use a closed loop operation we are not binding to any form of closed loop model this is just to illustrate with that type of hope it will work with map K where whatever number of steps you would like to implement in your closed loop but it\u0027s just to show that the essential steps you need to observe you need to get information from the environment from your managed entity then to analyze this information to end up with different types of insights run some reasoning to derive decisions decision plans what to do with the current situation and then to make an action selection decision of this on this on these plans to actuate on the resources or to reconfigure some some different aspects and you have in the middle and knowledge component that is used to I mean be a repository of different knowledge that can be read read or written from so the architecture have been published in August this year it\u0027s available publicly on the on this link what more recently has happen also in June the the group has adopted three documents on closed loop automation so one document is called enablers this is typically what are the generic components that compose a a closed loop and how these components needs to interact together in order to be I mean very flexible and fulfill different types of deployment use cases so this is where I see the most relationship with Asia in anima the second document on solution this is to take the generic enablers on specific use cases and then to try to say if I need to deploy a network slice and to enlarge cycle of network slice over different domains "
  },
  {
    "startTime": "01:21:56",
    "text": "what are the typical protocol that exist today to fulfill this dis this use case and to reuse the enabler specified and see if there are things existing in Fiji PP in HC in ITF in BBF to realize these solutions if there are some gaps this will be pointed out could be developed in the less mo could be sent back to the different SEO s2 to make the necessary changes and the last documents is so the first two documents are specification so equivalent of external tracked documents the last one is a informationally to report it\u0027s more to a study like next-generation types of closed group so to open the door to more use of artificial intelligence and different levels of autonomy but also everything that could not fit in the two other documents that will be a bit too immature will fit into these advanced topics current state use of activity so they are made mainly to two drivers in the design work ultra naval multi-vendor closed-loop design so you can translate that how to enable multi-vendor Aiza is a AAS a design and specification and closed loop spanning multiple domains so this is typically if you have a some processes management processes assurance loop or optimization loops that spans through a different domains operating domains or technology domains and so the interactions among the domains to realize this closed loop operation the same one we are targeting some I mean working on some requirements and also the design modeling of the closed loops what\u0027s important here these are great advise I mean that\u0027s usually we have this also in animal view of asa or close to being a kind of integrated components what we are pushing in the rest time is also to say now this needs to be a bit more disaggregated they constructed so that you can have the different components and how to compose this component will be a key a key aspect of these enablers enabling a synchronous operation between the components and also enabling multiple input and outputs between the closed loop stages on function this is not the kind of single path in the closed loop you can really see the service based approach that if you have a data collection service that can be used by multiple analysis functions for multiple closed loops so this is to address the the key challenges of interoperability and composition of closed loop in a region rich even though environment there isn\u0027t true so progressing on the list of scenarios exchange between the closed loop stages for different use case provisioning of new resources and sensation of backup resources dynamic monitoring cetera there are also two typical models that we try to use as for our fault process so a kind of black box closed loop this is typically what we see most of the time and as we say it correctly in Asia is a bit seen like this you interface with this closed loop "
  },
  {
    "startTime": "01:24:57",
    "text": "through an agent process but still you have to convey a certain type of semantics through these interfaces for governance information how to set the goals your permitting condition of the scope of this closed loop coordination between the closed loop means also to go through this agent in exchange of knowledge information the output interface convey the other way cover governance information such as exposure of capabilities constraints and requirements different actions that were taken or the status reports again also providing the knowledge that has been discovered or produced and reactions this closed-loop manager closed-loop agent is a logical function responsible for managing the closed-loop external interaction so this is how to interface with something that is not the closed-loop but we have also which is more the the focus of the activity this white box closed-loop model so this is still represented as a single component but in fact we you can remove this this Square this dotted square to imagine that the different stages are really independent functions and we need to connect them to compose them so this is why we have in that case the same interfaces as the black box was do but we want also to support way to compose the different stages the steps of the closed-loop and also to have a capability description and pairwise characteristic information between acquisition analysis decision and implementation now making a bit the link between this work of closed loop in zsm and animal on the Aces can you come to an end after the last Latin so roughly my understanding is that the closed loops that are being investigated in the Risa equivalent of the autonomic service agents in in in anima the resin will develop specification for closed loop automation so how these different stages can interact using different forms of mechanism and what needs to be specified for that so on your neighbors generic components of the closed-loop interaction patterns and composition means for the solutions so applying on different use case those enablers and we using standard based components or protocols and for the alvin\u0027s topic this is more to investigate next generation close to design and operations and in identify potential area for future sterilization so that\u0027s it any questions all right thank you very much thank you last speaker of the evening please that\u0027s not the right slide right this "
  },
  {
    "startTime": "01:27:59",
    "text": "would be very quick so I think we talked about this is the last meeting briefly yep we\u0027ll skip the topics list anyway can you line it up so just reminder that the scenarios were talking about ones not direct competition with the traditional ACP the theory is that a simpler layer-2 solution to the ACP could be used on a very small enterprise or in a large enterprise that actually wants to chop its network up anyway and then therefore would be willing to use over to ACP in each segment of the network the other thing which is different from the real ACP is that at least for a small network some degree of pre configuration of the ACP nodes would be acceptable because of that that\u0027s something that doesn\u0027t scale to a large network but would be okay in a smaller network so we have a list of requirements for the layer 2 technology and the draft must support v6 must support letter multicast MTU size it must be able to isolate a set of nodes in other words in a CPG LAN in practice and there must be some secure authorization mechanism for access to that VLAN which most VLANs will provide one way or another and a few other requirements all of this was in the document before I just wanted to mention the updates since last time we added a discussion of Mexico which is got an a I Triple E magic number it\u0027s the good news is that it supports multicast including group authentication the point of our group authentication is some trust one trust also there know that there is a single trust model that covers all the multi casting nodes I had it applies across all VLANs but the ACP VLAN of kind of crispy isolated from the data plane VLAN independently of maxixe although it\u0027s they\u0027re both protected by mexic they\u0027re also separate VLANs so they remain separate we noted in the draft that you could actually use some security on a Wi-Fi segment as well by using a dedicated ESS for the lair to ACP that wouldn\u0027t be very elegant and it provides an interesting problem of how you would do bridging between the written word and wireless networks so basically that\u0027s all I have to say I\u0027m not asking for working rip adoption at this time I just like to know if people are interested or if we should simply whether this document expire personally I\u0027m quite interested in this work but as "
  },
  {
    "startTime": "01:31:01",
    "text": "working groups here I\u0027m not sure that\u0027s because that\u0027s layer 2 is not technically idea for scope so I would like to get yes also I\u0027m worried a little bit whether we have enough expertise in our working group to handle such work I\u0027m pretty sure we don\u0027t and we have to go outside for the expertise Mark Smith some for the Indian society for this ITF um I work in the v6 ops and there are six main groups and one of the thoughts I\u0027ve had about RV v6 is in addition to solving lots of addresses problems potentially in the future people will actually build much bigger VLANs because there\u0027s there\u0027s it\u0027s been traditional do slash 24s which implies a limit of 255 nodes obviously v6 with such 64\u0027s can support much bigger than that so I think the constraint on size of VLANs will really just be multicast traffic so potentially you know subnets with 5,000 nodes on them won\u0027t be that unusual in the future I\u0027ve in the past seen VLANs with 4,000 ipv4 hosts on them so maybe that this sort of fits in with that deploying 400 switches that sort of solution a Remora for Mehari I think the your scenario is quite interesting so in your mind how big campus is defined I spake well I\u0027m no expert in this at all but I do notice that you the ants won\u0027t answer your question is the network and the Swiss hotel is too big the network in the Swiss hotel is too big all right it is why they\u0027ve had to switch off ipv6 so I think the the limit might be you much lower than you might want okay so here you have said that it should support ipv6 packets yeah and this package should be like I don\u0027t know from the aisle two perspective it is just one half from for every ipv6 packets so for ipv6 is just adding local well we could work with linked local actually yeah I\u0027ve been the grasp is designed to work with with link local if it has to and ipv6 is a mandatory option or not all right that was sort of a starting point for anima there\u0027s probably no reason you couldn\u0027t distort this and make it work over v4 but it\u0027s never been you know designed board for us I mean pure out was signaling ways that IP yeah I don\u0027t "
  },
  {
    "startTime": "01:34:03",
    "text": "know any real reason why I couldn\u0027t be remapped to ipv4 but it\u0027s you know it\u0027s not written that way in any of the specs I mean does not mean I don\u0027t mean to ask you before I mean only layer two messages I don\u0027t know so here I\u0027m asking that if IP is it is optional oh it is meant for uh I don\u0027t quite see any benefit in running directly over letter packets but I mean I suppose it could be done what do you have to do is give me the API so here and so here you mean that we should have for example the i/o to hire and then we have the ipv6 header and I\u0027ll show you and then you can like transport some grass for signaling okay okay we\u0027re already five minutes over time for the social yeah so just just quick comment to repeat especially in the context of what you were saying the one thing I\u0027d like to make sure if we continue this work is to you know make sure that readers understand that the ACP today already supports managing a layer 2 network in terms of if the service you want to bring is not routed network by the Metropolitan where X\u0027s network for example where all the devices are meant to do layer 2 switching you can run the ACP and only the ACP will be hop-by-hop routed and I think that\u0027s a very good starting point to support you know let\u0027s say I Triple E technologies you know it so I think I would want to make it clear that just because you want to support networks where the services are let\u0027s say I Triple E technologies large switch networks we don\u0027t need to change absolutely and and and these things that you\u0027re doing here basically need to be viewed I think and discussed more in that context in terms of what are we gaining if the ACP itself isn\u0027t layer 3 but also there - and I think that goes into the depth of different type of product limitations and we understand that but I think that that is a lot more explanation required ok five minutes it will go into the next next version so a quick quick information update there is a less we are working group link state vector routing they\u0027re working on what called layer free discovery and liveness and that is a mechanism for bootstrapping latch fabric based apologies I would recommend to take a look into that you might find a lot of good ideas there thank you lsv our link state vector routing okay that\u0027s in a minute so I will do so okay yeah that\u0027s "
  },
  {
    "startTime": "01:37:05",
    "text": "very short session today seven minutes overtime I\u0027m sincerely sorry for that so enjoying your social events tonight hopefully see you tomorrow also afternoon session breaks Brisky session okay thank you thank you guys [Music] "
  }
]