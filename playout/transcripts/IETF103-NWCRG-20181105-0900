[
  {
    "startTime": "00:00:23",
    "text": "well son you are messy what\u0027s up Ramon hello everybody this is the coding for efficient network communications research group in order to accommodate somebody who\u0027s on a very short schedule in Hong Kong we\u0027re just going to go through mineral introduction and we\u0027re going to go directly into the first presentation and then we will finish whatever administrivia and other presentations we have I\u0027d like to thank Nicolas for having nicely accepted to become the volunteer to take some notes it\u0027s greatly appreciated and without any further delay again this is the group that does research into network and application layer coding to improve network performance we\u0027ve been going on for a number of years and for those of you were there at the beginning you can see that we have a major move from just looking at codes and coding library but also for protocols that facilitate the use of coding and existing systems that all the research around this as well as the researcher is going on in many other fields that originally didn\u0027t have anything to do with coding but I recognising the use of coding is something that improves performance although from network virtualization to video transmission to 3d visualization and everything everything that needs to have some form of reliability provided by coding so this is the note well something that we always have to present to make sure that everybody recognizes issues of IPR and everything we have 50 new people who have never been that idea and this is IRT F follows the same rules as the IETF in terms of recognition of the processes recognition that the IPR "
  },
  {
    "startTime": "00:03:24",
    "text": "recognition of how to behave in a meeting like I said we\u0027re just going to go directly to the presentation from Raymond because he has a very tight teaching schedule today Bremen I\u0027m going to give you the speaking part now okay thank you very much chairman and okay my name is Raymond young from the Chinese University of Hong Kong the title of my talk is DTS pets for smart lamppost four and five cheese mix please our next slide please okay okay smart lamppost is a key infrastructure of small cities and typically they\u0027re equipped with network interfaces cameras and sensors and they promote small city innovations on a city scale including intelligent transportation of homeless driving real-time surveillance high-speed Wi-Fi coverage etc etc and it is estimated that over seven million small lamp posts will be installed worldwide by 2027 2027 and that creates a global market of eight point three billion US dollars next please okay one thing is that smart lamppost must be connected to the Internet backbone before they could become smart and then nowadays which is optical fiber - you know this next piece for optical fiber the pros are it has very high data rate and it also is highly reliable although occasionally sometimes the fiber can be dug up by people accidentally now the the cons are it has a high installation cost and very long set of time and the process is very disrupting and sometimes is that it not possible to lay fiber in in some areas and for example I was told that in Hong Kong I can take up to two to three years to get all the permits for taking up the road too late the fiber if you\u0027re doing it in a sense either percent in the center of the city now reso realistically only a small number of them phones can be connected by optical fiber directly and while the rest do need to be connected to the Internet by some means next please okay how about 40 now the idea is very simple you just put a 4G card at each "
  },
  {
    "startTime": "00:06:24",
    "text": "lamppost converting it into something like like a cell phone now the pros is that using a 4G card is that it\u0027s very easy to deploy and it\u0027s relatively inexpensive because the cons are it has a pretty high recurrent cost you mentioned that you have a HD webcam generating like 5 megabits per second of data and for the whole month you\u0027re talking about over 10 terabytes per month so it\u0027s a relatively high cost to transmit all all these data through therefore through a seller network and another thing which make the 4G solution not very viable is that the bandwidth can drop drastically during rush hours next please in this talk I\u0027m introducing the multi-hop solution in this picture we have a sequence of lampost for the first one on the left being connected to the optical fiber directly and for the rest of the lamppost they are connected through a wireless multi-hop networks and which is enabled by bypass code which is an acronym that we developed throughout the last year last few years okay why why do we consider paths now we know that multi-hop is long standing following wireless communication in industry and transmission can sustain no more than a few hops if you go to a few a few more hops than the the at the throughput basic risks are quite negligible and sometimes in industry people refer to this as the multi-hop curse best code is a as advanced Nemacolin technology that can sustain tens or even hundreds of hops and this is done by recoding as the intermediate nodes and with that\u0027s a very long multi heart never can be realized thanks please the last year my collaborator Shin ha Gyung and myself are published a monograph on pass codes in the synthesis lecture on communication networks edited by a three-count next please here\u0027s this group comparison between bets and routing now here we are talking about a lying network with 20% loss on each 20% take a loss on each each link so that after one heart you you lose 20% and a new maximum rate that you can ever get is 0.8 okay the the red curve shows the throughput of routing versus the number of hops and if we see that is "
  },
  {
    "startTime": "00:09:24",
    "text": "decreasing exponentially fast so for example after 10 hops you only get about 10% of the of the of the rate okay and with pass code it is the true who is decreasing with respect to the number of hops but it is decreasing very slowly specifically after 50 Hobbs you still get about 0.7 which is around 87% of the of the channel capacity of the network capacity thanks please so essentially one can think of a pass code converting a lying that multi-hop line network into a into a single hop Network the advantages of best code are the following in as high throughput low latency low coding complexity and low storage requirement for the last aspect I\u0027m talking about that you need to store only a in to keep a very small buffer at each intermediate node and for all existing solutions they fall shot in at least one of these aspects next please okay of Tabasco D the benefits instant in terms of operations are it has low installation costs easy to deploy and that\u0027s low recurring cost unlike 40 which you can you need to pay paid a monthly fee and because it\u0027s not a public network you also have guaranteed bandwidth for essential data for example post health check video surveillance etc and it can also cover rural areas not reachable by fiber or 4G next please okay here\u0027s a quick comparison with 4G both of them have the advantage of the low installation cost an easy to deploy but advanced core has three other advantages not processed by 14 in the local procurement costs guaranteed bandwidth and rule reach rural areas next please okay next I\u0027m going to talk about other applications of pass codes next please one of them is wireless ad-hoc networks next please satellite networks next please be 2x next place underwater acoustic communication next place our line communication networks makes place and "
  },
  {
    "startTime": "00:12:28",
    "text": "5g next please there is actually a very close relation between 50 and multi-hop because in 5g millimeter wave is used for transmission which is very directional and therefore the receiver needs to be almost between the line of sight of the transmitter and because of this many base stations need to be deployed and relays probably also needed in many occasions and the naturally many of these survey stations and relays will be put on the spot lamppost then it bows down to the to the same question for how to connect lampposts to the Internet and for this best hope is a very natural solution and in fact 3gpp has announced that multi-hop will be supported in 5g next please finally I would like to talk about the Hong Kong smile and post project that our group has been engaged in so it in this project is at the pilot project which has the consist of the first phase of about 70 and then post which is due in mid 20 to 19 and with for the second phase another about 330 lamp post would be installed totalling to about 409 posts in the pilot project and if everything goes well then the they were planning for a massive deployment of about 70,000 then post drama city and our group has been engaged in this pilot project to apply read scope okay I also liked Nick\u0027s place I also would like to mention that we have just submitted an internet draft entitled rats coding scheme for multi-hop data transplant transport and this is this was prepared by my collaborators in the chinese university of hong kong sunjin and also national childhood University in Taiwan makes these okay so and is talking with this picture as the take-home thank you very much thank you I think Wishman Rick Tina Airbus first off thank you very much for this presentation this is really interesting technology I totally agree with your use cases that just sticking 4G or fiber optic to every lamppost is madness I have a question about I\u0027m afraid I haven\u0027t read all this in depth and I need to go away and do it but the picture you have on the on the on the slide shown at the moment shows a single linear topology for your multi-hop have you done much research into how the topology so we obviously know lampposts "
  },
  {
    "startTime": "00:15:28",
    "text": "although down one Street are in a single line but when you come to intersections you start to get start upon a G\u0027s if you\u0027re one lamppost with a fiber optic you know backhaul is that the is at the center of that star how does that scale to look at that and have you done that research yet well actually if if the optical fiber is at the junction burrow is even better because you can then radiate out into more than one line networks then actually Kenton can mark a multi so you\u0027re it so there\u0027s no sort of congestion on the waveform at that\u0027s that central node that\u0027s that\u0027s handling all the communications from all the the bats connected lampposts but all you need is a more powerful computer or you can install more than one computer at that lamppost okay and I think to go away and read this in more detail and I might come back to one on the mailing list thank you I float in Bible School Broadcom few questions what is the distance between the lampposts that you do take into consideration typically it is less than 50 meters but but the application of the best and now she has nothing to do with the physical layer if they are further away just you need a bigger antenna that\u0027s what it is not quite like this because the overall incapacity may be dependent on the distance especially if you consider a wireless medium so you have widely Wasat gigahertz have you considered this one is a possible link I\u0027m sorry once that consideration I was saying for the interconnectivity between notes you may consider my gig which is a Wi-Fi technology operated in the 60 gigahertz band oh okay we haven\u0027t done that yet but we are actually looking closely into this possibility also you mentioned to the Phi G related work currently there is a integrated access M back hole that is going on into the Grand Tour and free groups is there any relation of this work to the IAB work in 3gpp probably not at this point we just begin look we\u0027ve just begun looking into this and so I later on we may find some more connections then how can you put the correlation to 5g as long as early since the release 15 and 16 there is nothing to be done with this type of coding oh because the the no coding I mean the application of male coding has nothing to do with the the physical layer for example you can also use it for underwater acoustic communication it is just a something implemented at the transport layer high Devoran no "
  },
  {
    "startTime": "00:18:29",
    "text": "existence research and design on to related questions about your performance graph curve could you put it back up okay well I can answer it while you\u0027re getting it up um does that graph include or not include hop-by-hop retransmission retransmission no it does not include hop-by-hop retransmission because if you do hop-by-hop retransmission then it is very hard to support real time real time applications so it would be useful to show a few curves there which relate to loss versus delay of the of the coding solution versus a hop-by-hop scheme right because there are applications that you know particularly with it with with these very short distances you know the delay incurred by a single hop retransmission isn\u0027t actually that high and then you also have to build in the slight delay incurred by the coding computation and each hop one thing is that if the if you use a like some end-to-end TCP then about using and then TCP I\u0027m talking about hop by hop retransmission yeah I know the actually the it will consume the in I can say something about our implementation in our implementation in it actually turned off the link bilingual transmission otherwise the it actually will decrease it the stupid so does the paper have all this in it because I mean it\u0027s useful you know you\u0027ve sort of set up an AR you know best case comparison right which is you know high loss with no hop by hop recovery of course this is going to do a lot better it would be nice to show it also does a lot better when you use a more conventional layer 2 protocol scheme I\u0027m not I\u0027m not necessarily saying that doesn\u0027t do a lot better it would be really nice if you could show that yeah ok we\u0027ve done like some experiment but we haven\u0027t so we didn\u0027t in this slider okay so for lack of time in any way else here no more people at the microphone are there any people online on meet echo who had some questions if not we\u0027re going to send the rim into oh just a comment just a comment from myself and Vincent Raymond you have always been very clear on iti aspects for all the patient\u0027s you\u0027ve made so far don\u0027t forget to also deny no disclosure for your internet draft just a reminder thank you thank you very much okay so "
  },
  {
    "startTime": "00:21:29",
    "text": "we\u0027ll send Raymond back to his class thank you very much Raymond thank you for accommodating this presentation with your schedule okay Foundation and we will go back to the print of the previously scheduled programming thank you so much okay so back to you with the chair slides so you want you wanted to talk a little bit about github so yeah I wanted to say a few words about it so you\u0027ve noticed that we switch to Gita for all the research material so I mention already mention you in the mailing lists this so do not hesitate you are looking this github repo you will find many different things so first of all as I said all the recent good metal will be posted there for the various meetings but as well as interim meeting so you will find whatever we\u0027re talking about in this repo but you also have additional repositories in this ayah TF n w mg organization you will find the suite correct so I will talk a little bit buddies later on for the Akutan project but you will also find two additional repo for the moments for the two results could be item documents so this is the place where you can find the latest version whether it has been committed or not and uploaded or not to the data tracker so if you want to have a look at the current version ongoing Russian have a look at this this is the best place for that and as new Richard group eaten documents are accepting we will create new repository for each of them with a team composed of the offers we will have full access to their own repository so as to be able to update and the work from their documents so unity state this is best place to know what\u0027s going on his group in addition to the data tracker that of course remains something important for our such group like working groups of fight yet but we are both and we\u0027re working with [Music] otherwise there\u0027s nothing new about a mistress EDI information so this is the agenda so we already in the next few minutes and everything and then there\u0027s much like to talk about the hackathon he\u0027s been doing Nicolas talk about satellites we\u0027re going to have a CCN and and en and we\u0027re cooking draft that I saw as put actually it is on that\u0027s we "
  },
  {
    "startTime": "00:24:30",
    "text": "forget to say this about the github thanks I put a number of I we called it FEC for dummies but I don\u0027t think it\u0027s dummies I think it\u0027s for more for newcomers but anyway I don\u0027t think people are done because I don\u0027t know about it but anyway and there\u0027s a lot of things that explains with network coding is and with network coding can do for you and I thank all the people who commented on this and sent us like comments and improvements to this performance evaluation is something that we\u0027ve talked about in the past and thanks was going to mention it we have to talk about the milestones like I said for people who have not been in this meeting before this group has been on for a while we have gone through a number of iterations through things and we want to make sure that all the milestones are updated and we are going of course to ask the list to comment on this after the meeting and I\u0027m going to talk about something that\u0027s new that we have a side meeting on on Friday which is in network computing for extended reality but actually I think the presentation that think that Raymond just did where he had in network Rhian coding was also showing the improvement that you can have by putting some computing in between endpoints inside a network and I\u0027m going to be talking about this and then we\u0027re going to talk about obviously closing this and see what we are going to do in the future Thanks so we have the items right now the ideas that are the research group items we have the network coding and satellite that again Nicholas is going to do an update on and the network coding for content centric which is also a r2 document and we are also sharing some of the approval of this document with our colleagues in the IC NRG we have a individual ideas we have a new idea on facts coding we have the generic API we have the coding for quick coding for quick has no progress because the quick guys are so busy putting things together what we intend to update it so that you won\u0027t disappear and detectors in RL NC who straight enough where the drafts that started this group have now expired and this is something that we have we would like the teams that were behind that to really consider restarting it as we had docked and bidding to have the beginning of this to have one draft per type of code that was going to be able to be used next our future meeting are we intend to meet in Prague in actually after the winter I guess it\u0027s "
  },
  {
    "startTime": "00:27:30",
    "text": "early spring and we intend to have the market on and I think we\u0027re this is the next step the next step presentation but I think we encourage people to show up at the hackathon I couldn\u0027t be there on Saturday but I think the next hackathon one of the goals that I would have for Prague is starting to write use cases to test the codec and so people who know about Python and Python use cases please show up and then you\u0027re going to talk about the yep okay so this is a quick updates on this quick feedback can be a curtain that we add during the weekend over Saturday and Sunday that\u0027s much better like that so a quick update so the goals of this Acton was to design Swift correct switch but explaining window fec correct in order to facilitate tests and experiments by anybody with potentially interested in this technology and operated easy to facilitate the adoption technology itself as well as being a reference open source implementation free open source plantation of these of those solutions so that\u0027s the first to go of this accattone the second goal is to challenge our API dynamic API in turn draft and I will talk about it later later on and also it was a good opportunity for me because there was a newcomer at this Acton project in fact I was wrong but I was I met quasi who was dressed yeah sitting here and we worked together on this project and since these you bring new people to ITF it was a good opportunity for us to for me to test and this fe CN n c for the means or new comers call it whatever you want and see if it\u0027s appropriate and the feedback is positive I would say on this if you disagree do not hesitate to interrupt me and shop but I think okay so those are the goals we of course we didn\u0027t finish it\u0027s just the beginning of this project for sure but we already fixed a few issues within this generic Fe C API intern draft and I\u0027m updating the document yesterday evening just after the accident take these into account so if you have a look at this new version you will see many different things I\u0027ve "
  },
  {
    "startTime": "00:30:32",
    "text": "reorganized the thing good some functions in different way in order to facilitate the completion of the full staff fixed a few people\u0027s removed one or two functions and I did another one so those are things that you find quite useful and necessary when you\u0027re working with code at the same time as working on the documents so that that was a very good opportunity to do this work and to add something back on this interactive even if this is something I wrote myself and I was the one doing the most of the correct stuff also at the same time even that case was useful so that\u0027s the first tremendous common one is - okay we now have this repository for this suite correct and we started to put many different things inside so we reuse some existing code either from open factors or project that I used to work on in the past but also come we also reuse some odd existing code from the garden it\u0027s from Cedric I\u0027m sitting here my colleague sera congi so you you already you can really find some interesting not working code but some interesting one inside this github repository we\u0027ve been fucking we focused on the encoder but first of all for two reasons first of all it\u0027s necessary in order to be able to test the full scheme full solution you need to first welcome me and coda and also because it\u0027s a little bit simpler you just have to compute linear combinations of packets to be able to do encoding so it\u0027s something which is quite simpler than the decoder which has to deal with this linear systems resolution all the stuff so that was the first goal it still does not work but we are not that far from having a solution of course we focused on some the most simplest assumptions one single encoder for the moment we will extend to any network recording operations later on in this project we also focused on well something that is relatively close to algae because this is something I know the best and it was the easiest way to start project but later on we\u0027ll try to do something more general but we didn\u0027t map for the next action so I do insist on this and you are all invited to join this project and hopefully during next next right here I will be there will be more people than just myself and quasi if you have C programming skills because we are focusing on C correct "
  },
  {
    "startTime": "00:33:33",
    "text": "do not hesitate good opportunity also to practice remote participation is also feasible even if it is a bit more complex particularly when you were this time difference but it\u0027s feasible we have the tools for doing that ok so let\u0027s focus on this generic FEC API and documents so this is version offer that I updated yesterday evening as I mentioned I moved a few things in within this intern draft I already went through this those modifications but you can have a look at the document itself on the dish with the first version you will see that many things moved now I think that we reach a point where this document is not stable but in a good shape well good enough shape to be accepted as a result group item if you believe this is something useful for this result group so I would like to formally ask for recent reproduction for these documents so that can make progress and in fact we will add the two activities in parallel at the same time this academic project which is a good opportunity to check and challenge this inside draft and the of course the generic API instant draft that will explain how to interact with this correct so if you have an opinion on this do not hesitate we\u0027ll go through the list of course after the meeting to confirm or to gather opinions yes they um I don\u0027t see any objection to adopting as a working group as a research group item what one of the things I think is a precondition to really getting it to move significantly forward is that there be at least two different FEC codecs supported by that API otherwise you can\u0027t tell whether you have a generic API or not or whether they have an API that only works with one codec so we need to somehow get in the work plan the implementation of at least two yeah FEC codecs with this API before we can really decide whether this API meets the first referral this is another wasn\u0027t holding it I wasn\u0027t gonna hold I\u0027m not saying hold it back from our G adoption but just make sure that the RG has the expectation that it\u0027s really not gonna get all that much farther and so we have the last two codecs yes so a quick answer yes of course this is one of the goals of this document to have something generic that can be used by several different types of physicals I have said during previous meetings we are focusing on sliding window codes but not only one solution but hopefully all potential sliding window solutions with end to end Kareem but also with in-network recording as in networking systems like in bad schools so we are really we really want to address all those the use cases all those different cuts Ric Taylor follow-up to that absolute plus one and can I recommend I "
  },
  {
    "startTime": "00:36:34",
    "text": "give you sort of answered this already but that you pick to make sure your API is generic enough you pick two contrasting if you see income so a sliding window and maybe you\u0027re trying to pick something else random but at the other end of the spectrum to make sure that your API is is good enough just sure now it\u0027s just a matter of manpower to be able to bright those critics and make sure that they are working and that they are working so they don\u0027t think this is fine I\u0027ll see what I can come and give you a hand okay great thank you no other opinion okay anyway we will ask the question formally on the least [Music] common denominator and put rappers on run it yeah for all those situations and requirements yes social okay so we will go to the list and ask the question and you want to add some more you noticed it thank you [Music] so Nicola since you I will take notes while you\u0027re presenting hello everyone and that would be a very short update on the networking for satellites draft I hope you have read it otherwise this presentation will be complicated because it\u0027s just a diff basically we were in IDE version 5 document and now it had been adopted so we are in the first version we just didn\u0027t change the name why going through the working group documents we adoption founders lots of comments there were lots of harmonization issues in the figures so we try to polish all these presentations figures and also had lots of grammar mistakes and that\u0027s something we hope we have improved also the way from wasn\u0027t clear from the Willing what is a crew infectious agents at comm systems so we just try to make it clearer by adding one or two sentences we hope it\u0027s clear enough but don\u0027t not agitate let us note it is not we can point to more dvb-s to solids for example but basically we try to make it clear also once opposite of text for the multicast sections we have "
  },
  {
    "startTime": "00:39:34",
    "text": "tried to include all that and thank Universal such as proposed by evensong we added research challenge section so we somehow cheated because we moved the conclusion to we change the conclusion to a research research science section basically we have identified two main research challenge that are specifically related to succumb and network coning first one being how do you make it deployable today in the systems we have because that is one of the goal we had in the document we identified use cases and where we could have agreed that were coding in satellites but there\u0027s always a question how you get it deployed so we think that this should be could be doable in TCP proxies we have because then we split TCP connections we are at the user space that also you can do lots of funny things and we have fun geology same thing at the terminal side there\u0027s also a challenge that is already inherent to satellite systems in how efficient we are as opposed to a much with gradual resource we use that\u0027s eternal debate and trade-off that is going on in SATCOM industry and this is even more relevant for network coding in high layers because we don\u0027t because wider resource is cast so we have to save it so that is something that really always be open and we kind of tackle it in generic way and just depending on the systems you have and the objective of in terms of latency and loss tolerance of the applications you have different solutions another thing and now that energy working group is over and I think one of the thing that we had discussed and I think in Alps also the API document if we have to make sure that basically using all of the tradition concepts make it easier because we are not speaking about clouds aggregation functions in SATCOM industry and then we have all these service function training working groups so if Network coding turns to be vnf you could easily deploy that would be very useful for us and that would define meant of the network audience attempted systems something also that we did we I think we kept me may had some content to it is a Security section because basically and there are lots of SATCOM specific security aspects but I think the goal of document is not to tacko satellite system security issues more death Network coding has any specific issues with security in certain systems so we precise that in the draft I mean we can make some we have had some since the document "
  },
  {
    "startTime": "00:42:34",
    "text": "was released as working up item we had some feedbacks from the internal from people from our own company so we may want to add some more details on sat-comm system security if you want but I think the scope here is more to focus on networking but though we we may want to we work a little bit this section and also if anyone wants to jump in and has research challenge we think of we would be open and we are looking for volunteers to review the document hi Rick Tyler this is with my I\u0027m the one of the co-chairs of the DTN working group which is now IETF oK you\u0027ve got a really good DTN section in this document I had a quick look it\u0027s it\u0027s really good could I ask you to update some of your references to the IETF RFC somehow that draft still that are going forwards rather than the IRT F stuff and if you need some volunteers can we\u0027re meeting on Thursday morning put a copy of this onto the mailing list I\u0027m sure there are people there you know we all work in satellites in DTM as well so I\u0027m sure there are people with lots of industrial experience who\u0027d be happy to review this I think it\u0027s a good opportunity for some crossover so okay so we all send the copy of the draft to the lists and come to such the morning\u0027s meeting either or conflict yeah yeah thanks thank you okay so thank you very much I don\u0027t know before you leave okay so I think we may be close to the end for this document so we encourage people to read and review this and maybe we can also start research group last call soon in order to install reviews hopefully on this document so do not hesitate to to have a look and to recommend to put on the manual on this I can I can promise we mainly made it short it consists on xt time is for MC for C and then C N and the N once again which is a research "
  },
  {
    "startTime": "00:45:36",
    "text": "group written document so please Kazu from an IC k so let me talk about quick status the tracker is our network coding for shishun Indian requirement and challenges so the main objective of this route is to provide a sufficient equation and the clarification requirements and challenges regarding foreign genetic coding into Chien and any CNN Vienna so in order to you know that provider establish common common understanding and hopefully to provide useful insights to develop a through a pry and she in decision so well year ago we presented our initial draft both network holding research group and I shine research group and the in the previous meeting it was discussed regarding the the adoption draft as a research study group draft so then thanks to the chairs and already had the balls Network coding misogyny panda energy this draft has now become so here\u0027s a current structure of this draft so this is a group so we I think we need to I think it\u0027s important to introduce context and semantics of Chien in the section one and the two so in section one we introduced both network coding and decision over B and in Section C we provide the incision equivalent so so the current way in this part we we provide in section 3 we provide the advantage given by NEC on decision in Vienna and after that we describe why the requirement and we describe the research potential research challenges so we we now cover the requirement for offering energy into CM so one is the naming and the others are transport in networking and seamless mobility and security and the privacy so in this section we we\u0027ve already modified based on the obtained comment so far so for instance we add the relationship between "
  },
  {
    "startTime": "00:48:38",
    "text": "the coding information head down the security envelope and then we add design choice who determines the encoding vector and we describe its impact on ratings here and we were already updated regarding some editorial updates so as a potential research challenge we will now cover these four points other thing compulsion coding region and congestion control and the security and privacy and the rating is rooting scared of it here so in this draft there\u0027s no description about a specific protocol solution because it\u0027s out of the scope of this net so actual protocol proposal will be indicated indicated in another draft so as a next step we consider heater update is if there are other other requirements to be considered we\u0027ll add in section 3 and we we plan to refine the potential challenge especially about a cigarette gear looting in section 3 and if any we had important potential changes so welcome comments further comments and suggestion for this improvement and so we are as I mentioned we are now implementing [Music] according with decision and she she Anna so to in order to initiate a proposal so we we and also we are planning to experiment our implementation for instance considering the CMAs same with mobility scenario thank you ok thank you just a quick comment since you are mentioning it you are you have started implementing this so that\u0027s great we also have the second project that\u0027s great that is a perfect match between the two No what do you think would you like to be part of the Akutan team on swift code okay we will talk about it later but you are more than welcome and I would be more than happy to have you the acting team if you if you have some manpower and time for that yeah so but so now we just starting to just at first "
  },
  {
    "startTime": "00:51:45",
    "text": "we want to use we want to first we make a prototype implantation with the simple [Music] people just arrived and please make sure that you signed them please make sure you sign the blue sheet I don\u0027t know where the new sheets are but please sign the sheets Dave so this is an IC energy chair Hat comment not a personal comment which is that we\u0027re about to get the CCN drafts published as experimental RFC\u0027s um it would be really helpful as you do this work if you discover changes you think ought to be made in the CCN protocols in order to make this work better um just remember you don\u0027t need to treat the CCN protocols as cast in stone right we can change them [Music] mr. sidearm so commentary I think we should not ask to modify any CC NX format which is already in a stage for the just before the LOC so but Observatory we need to add some packet format change or we need to change something but that one is can be categorized as something like a extension of the basic packet former so I say notice doesn\u0027t need to care so much at this moment for the formalizing the CNX message Walmart or semantics but in your future if we have some solution to provide network coding into CCN we may need to add or modify some part of the defined CCX Walmart and so on but this can be done satellite three okay something else okay thank you can anyway we will have a milestone description at the end of this meeting so we\u0027ll have more questions for you thank you so a few words about this document "
  },
  {
    "startTime": "00:54:46",
    "text": "efficiency for all newcomers will say but I I like dummies also because this is a good theory anyway so just to remember you okay we mentioned during previous I kept meeting the fact that was important you have some quick and easy introduction into networking FEC to make people believe that they understand what is behind so that they can more easily accept the technology and the very important force for everybody I would say so it was very good comment so we started thinking about it and trying to put a few IDs kept as simple as possible but at least the goal put together some ideas simple ideas on what we want to address what is the background the minimum knowledge you need to have you know that to be able to understand more or less what we\u0027re talking about so that\u0027s an attempt i sent on the email only mainly sorry an email two weeks ago on the topic with draft of IDs so what i\u0027m presenting now is in line with what i sent only lists with a few modifications based on comments that I receive I received two comments to the comments people were in tracing this topic but I received two suggestion for modifications improvements so it\u0027s in line is that it\u0027s small that\u0027s a requirement so I have eight IDs so the first one is to stress the fact that we are working on packet loss networks so networks where packet will be lost perhaps or if they arrived to the destination this packet is does not contain any which arrow it\u0027s correct on this point we\u0027re not working in the physical layer so what whenever we are we add package this package is is good so that\u0027s definitely the first time the second ID is consent to explain what encoding means and what decoding means so when coding means adding redundancy in the packet flow I mean one or more repair packets and decoding means using this redundancy those additional repair kits to be able to recover from packet losses I think it\u0027s quite easy to understand the third idea is okay is to tell people that they don\u0027t necessarily need to understand what is behind the technology what is mathematical aspects of course we are working on finish fields so we if you want to perfectly understand what we are talking about we also need to know what is a finite field or with the multiplication of all these mathematical paths but if you just want to have a row idea general idea of what FEC and networking means you don\u0027t necessarily "
  },
  {
    "startTime": "00:57:46",
    "text": "need to add this knowledge it\u0027s not required at all just know that you have a linear system it\u0027s just mad the coding is just matter of solving a linear system and economy is just matter of computing a linear combination so that\u0027s those are two basic aspects that everybody can understand Paraiso the fourth ID is about a physical store roughly roughly speaking there are two categories of a physical one of them is block codes the other one is sliding window cuts so block codes with block codes you had this flow of data packets you cut this rule into among these packet flow into blocks and you do efficient coding on each block independently so that\u0027s for block codes and forth landing window codes you have a continuous flow of packets and you have this lining and Kooning window that will slide over this set of packets and whenever you need to produce to compute a new repair packet you just do a linear combination of what packets are at that moment within this entering window once again if you have comments about those ie if you believe that they are not put in the right way if we can add something that is simpler more easily constable or if you have suggestions do not hesitate the goal here is not to tell you what we are what if not to teach you what is networking and 50 it\u0027s just to get essentially to get your feedback so Rick Taylor again sorry I\u0027m talking a lot just can you go back to idea to slide well I completely agree with you apart from you use the word repair which if you go to idea one you said you know we\u0027re not a filer we don\u0027t care about bit error you know we\u0027re assuming our packets like that arrived or don\u0027t the word repair implies that you are fixing broken packets rather than I think use the word recover correctly can you call them recover packets you know it\u0027s you\u0027re not fixing a broken packet you are recovering from analysis it is just an English thing sorry okay okay we also need to make sure that we are in line with the MGM energy okay man cause we published I think we are talking about rip advocates energy documents but yes that\u0027s a good point I will I will try to find something maybe better it\u0027s not fully in line with this token okay thank you because I am coding okay so the fifth ID is okay so what type of code for what type of use case so basically very basically speaking records I create for "
  },
  {
    "startTime": "01:00:47",
    "text": "all situations when you don\u0027t have so much real time requirements so five transfer that kind of this case is great in for those kind of use cases using broken is not an issue usually and slagging we look at some much better for real-time traffic that\u0027s the general idea of course you can find exceptions you will you can tell me that okay - flute uses block codes but this is for real-time traffic yes the exceptions for sure but we speaking I would say you can put it this way date so this gives me heartburn first of all a block code with very small blocks is going to work way better than a sliding window code with very small blocks so if you have lots of small objects that are independent and you\u0027re spraying them out on the network a sliding window code is actually going to enforce certain types of ordering properties on the data and actually slow things down so we have to find another way to say this I think I know what you\u0027re getting at right which is if you have large bulk data block codes are win yeah right yes you and if you have streams of real-time data that have time correlation sliding window codes win those are both the true statements but this is going a whole lot further so I just want to throw a little bit of caution in here that people are gonna reach wrong conclusions from that yes yes we don\u0027t well okay I agree okay no no conclusion that\u0027s not the goal just give IDs general right yes so yes we can maybe change a little bit the wording on this side yes okay good point next ID ID six is about yes there are two situations basically if you see a net working with the GC we had a single encoder and civil decora and with networking the way we understand it we have the possibility to do we incur in within the intermediate nodes so basically you have multiple encoders next ID is seven well okay there are situations where network coding can help improving network usage and this is a very simple example with Alice and Bob both of them want to send packet to the other one and you have this intermediate routing equipment the Wi-Fi water this Wi-Fi widow is if first packet p1 from a listeners like @pq from Bob and instead of sending p1 to Barb and p2 to Alice this Wi-Fi water just sent the combination of the two packets so Alice remembers having "
  },
  {
    "startTime": "01:03:47",
    "text": "sent p1 can easily recover t2 by computing peacocks or p1 or p2 so the result will be one and the same calculation can be done by Bob will recover p1 so that\u0027s a very trivial example we already talked about this a little bit for SATCOM networks but there are more complex butterfly or there are more complex configuration but this is an idea that is quite easy to understand yes as a self-professed dummy that example doesn\u0027t show me any improved network usage because from a naive look your eggs or is the same size as p1 p2 where\u0027s the improvement yeah yes but in that case the Wi-Fi router will send a single packet instead of two blankets so it\u0027s just the Wi-Fi broaches multicast is much slower than unicast now yeah yeah I think yeah yeah I\u0027m sure it\u0027s a good example it just needs fleshing out in a lot more detail I can change Wi-Fi water with a mistake because it\u0027s Wi-Fi multicast Wi-Fi is not good at all yes that\u0027s a good point ok I will change this thank you and finally with congestion friendly transmissions this is an objection that sometimes arise ok you add some more traffic to the data flow it will make congestion even worse yes but we don\u0027t do that this way of course you guys congestion which is a separate program then we address this in a separate way by reducing the sauce flow rates of course and so that even inject some more traffic with with recover packets it does not make situation even worse but that\u0027s a sight problem that can be addressed and if you do that correctly there\u0027s no reason to say that took a FEC and then she is not congestion front so that\u0027s the just to avoid this kind this type of objection and that\u0027s all so we don\u0027t want to have an intern draft on this topic or we may I but there\u0027s no strict requirement for that what I\u0027ve done so far is I\u0027ve extended the github readme documents well fine in the github repository in order to add those simple ideas in this with me and make people mostly understand what we\u0027re talking about so it\u0027s already in the github in - we - in "
  },
  {
    "startTime": "01:06:47",
    "text": "the coop material with me fine and in the Swift correct readme file as well okay so do not hesitate if you have some more feedback to tell us we will continuously improve those ideas if you have new ideas that you think be within this quick introduction to fenc notice date as well she find that the where they are organized is not to create once again send us send us a comment that\u0027s more than way without my chair head as somebody who\u0027s implemented some of these things before I think one thing that you could add to this is the type of packet losses that are experimented that are experienced so that so there\u0027s codes that are better if the areas are truly random and what happens when the errors are there is the losses start being correlated and that I think could be something that you could add as maybe not an idea but I don\u0027t know if it\u0027s an idea but yes I think your your slide about the sliding window is not only for the real-time and the non real-time I think the sliding windows or the flexible window or variable size windows have shown better performance when the losses are correlated so that that could maybe I\u0027m suggesting it I\u0027m not saying you should do it but I think a lot of people think that they have a very wrong or a very bad view of what their their loss profiles are and it\u0027s not that you know I have losses I\u0027m going to put the coat over it and everything\u0027s got to go well well depends a little bit of what this looks like as a profile so that\u0027s my comment and here\u0027s Dave with another comment so I think that\u0027s exactly right the the the and I don\u0027t think this belongs in the document but you know if the reason you have correlated losses is because somebody is using tail drop cues this is not the best way to solve the problem right just get rid of your tail drop cues right so you have to have a process that\u0027s producing correlated losses it\u0027s not utter stupidity and the implementers of the network devices okay nobody else no okay so there are any questions from people on VTech oh just a quick comment on nos pattern we may have some satellite choices that we could made available to the group we\u0027re trying to work on that for specific use cases to have different loss patterns but are "
  },
  {
    "startTime": "01:09:47",
    "text": "only due to physical layer impairments not buffering issues trying to see what we can do on that I\u0027m actually also working with the with a start-up that may want some of their millimeter-wave losses which are not due to stupid they\u0027re due to really millimeter-wave so yeah okay which I do like yep okay that will be perfect for the next presentation because in this presentation we are talking about performance simulation and personal salvation requires to have lost models so if you have indeed satellite driven loss models then that\u0027s very great because we I don\u0027t have any as far as I\u0027m concerned we have different roles models but yes that\u0027s quickly appreciated so you want to speed my comments and my question in this presentation that\u0027s fine thank you Nikolas okay so this presentation is about efficiency performance simulation we initiated this IDE and discussion in the interim in September so that\u0027s next talk about that\u0027s the only date he took the presentation after this interim meeting okay it\u0027s just mentioned that this is not the first time we are mentioning the possibility of doing consideration for efficiency the at least boost two references one from Morton if I remember in IGF eighty-ninth some time ago and another one I made introduce work on a fake frame and I see last year anyway so there are several aspects to the program the first of all the question of how do you manage your correct what are the correct parameters how do you initialize those parameters so you what are good values to give them to provide them so that\u0027s the first point the second mention is about performance metrics the different performance metrics so you have to select what you want to do the right metrics so there is some discussion about this there is also a methodology discussion that\u0027s something very important how do you conduct your performance variation and the fourth item is bad fourth dimension is about the communication channel so this is what I mentioned just before after suggestion and proposal to share satellites loss models so that\u0027s "
  },
  {
    "startTime": "01:12:47",
    "text": "something very important because you want to test your solution your fe co NC solution for a given news case so you need to have lost model that is representative of this first case so that\u0027s something very important and of course it\u0027s a fifth I\u0027d mentioned you need to use tools so this Acton project which focuses for the moment on writing designing Nephi and NC solution so next step could be to design tools to evaluate this performance of this is incorrect solution so it could be one it could be a new academic project after so that\u0027s not right that\u0027s not number one the first priority but it could be something that we know second step okay so I will go through the first four items four dimensions now when details so the first topic is about the correct parameters so what are the parameters and how do you derive these parameters so it of course depends on the features of the sauce flow so there are several possible parameters so I mentioned some of them now this slide is about how do you manage these parameters do you consider the parameters in terms of for instance their window size in terms of number of symbols or do you express this window size in terms of time seconds number of seconds so whatever fits inside this time frame will be part of this including window so that those are the two possibilities I can imagine and depending on the situation whether you have a fixed great sauce flow viable rate sauce flow real time constraints or not you will do one we will select one of those indepence so you have to be quite flexible so you immediately understand that can be quite complex to the performance relation in this situation especially if you are considering windows in terms of time in terms of how long it will it can last itself so that\u0027s not sure still for those correct parameters so you the uncoated side we had this anchoring window size parameter which is one of the key input parameters you have the code rate the amount of energy that you put within this data flow and you also have in case of real time flows this F is related latency budget so that\u0027s the amount of time that can "
  },
  {
    "startTime": "01:15:47",
    "text": "accommodate for encoding and decoding operations so this latency budget accounts for this time it does not include the consummation time the propagation time all the types of delays that you made parents understand or disfavor on using the network it\u0027s just for FEC encoding and decoding operations that\u0027s something very important in case of real-time flow because this is one of the first parameter that will be used to in that can be used to initialize for instance the and canoeing window size so at the B color size were this Nino system maximum size and you also have in case of red and blue this is the way I understand it the way I manage to initialize my parameters this decoding window maximum size that can be once again expressed either in terms of similar time this deepening max window maximum size is the maximum number of packets lost or receive that you can put inside your in our systems while being sure that if you can so listen our system those lost packets will be recovered on time within the time frame what I\u0027m saying but you won\u0027t decode those packets too late to be useful to the application so this is forward time flows so those are the main two parameters that I can imagine for the current there\u0027s a relationship between the two once again I don\u0027t have time to go into all the details but something we can discuss offline and we try to explain how to derive those parameters depending on the situation in this document so this is the oil CFX scheme document that I\u0027m working on in the context of in the context of the GS v working group I\u0027m not free satisfied by this those guidelines maybe we can improve this description we can find better ways to initialize or clearly I have the feeling we need to work together on this topic because it\u0027s not easy it\u0027s not trivial and perhaps we can go and find something or a better way to express this mid Rho G parameter duration stuff together so that\u0027s for the first step the second topic is more classic I would say it\u0027s about balance matrix many different types of performance metrics the average over n can\u0027t do the coding the to recover from packet losses that can vary probability with respective packets that have been "
  },
  {
    "startTime": "01:18:48",
    "text": "wasted all those metrics are quite classic but you can also find more practical conic oriented metrics like en Coningsby in the decoding speed maximum above memory and the maximum amount of memory required during decoding the number of field operations you want to abstract to bits instead of working on speeds and column upon each page can also consider the number of physical operation that\u0027s something that can be quite useful in some situations to compare different decoding algorithms for instance so lose art was a classic performance metric residual residual losses yeah yes that\u0027s the the next one last bullets and it\u0027s more less related to this which is so last bullet is the required could rate to achieve a certain quality in terms of packet loss okay for given threshold very good way of comparing different solution to one another yes yes exactly that\u0027s something that we every agree with you know Josie we connected some research from this topic in section static what is the required could rate in order to be able to achieve a certain quality in terms of transmission and since we are considering real-time data flows this quality is not perfect but you have an objective this objective expressed in terms of residual packet erasers after doing whatever FEC and coding the canoe you may want so what is the required rate to achieve this objective quality objective for given to maximum returns so that there is a methodology to carry out this kind of experiments it\u0027s well I\u0027ve three ideas on how to do that but you I would be happy to share with you also may different methodologies different IDs so but yes that\u0027s something extremely important to consider that we are not always targeting a full reliability but having a reasonable packet loss rate can be unavoidable in some circumstances especially if you have real time constraints [Music] next whenever we have to consider time makes a variation quite complex so that\u0027s abuse but there\u0027s no way to avoid it if you are considering where time flows and so we have to accumulate this so the first dimension is but the metallurgy or do you do that you can "
  },
  {
    "startTime": "01:21:48",
    "text": "carry out a thorough analysis that\u0027s quite useful we never say the opposite but this document is not about this we can also carry out real world experiments that\u0027s once again very important but the metallurgy is quite used case by use case at specific oh you can also try to do simulations where with this idea of fully controlled and reproducible experiments that\u0027s extremely useful and accurate but once again we need to do that in a careful way because we can make mistakes quite easily so that\u0027s the main focus of this presentation there are two following that we have our own tools make some work in this domain I would like I will be happy to share with the group it\u0027s already available in pots but I\u0027m pretty sure that you guys have your own tools holding that we can exchange and share knowledge from this aspect can be quite useful when we are doing simulations we need to be very careful in the way we carry out those simulations because can we must take into account the correct specificities and the way it\u0027s implemented can change totally in the conclusion if you don\u0027t take them if you don\u0027t take that into consideration can take you can easily go into wrong conclusions just because you only get to think that okay if you implement that feature with one puts Q or two out to choose that\u0027s the example I\u0027m vining and the bottom of this slide this is for blood cuts but depending on the way you implement efficient cleaning and blood cuts you can either consider one output out sorry I forgot to say something we want to have a constant bitrate output so in order to achieve this constant bitrate output you can either use a single output Q or two alkyd use each of them betrayed so it depends how you assign source and repair packets to this output Q or to use to output Q\u0027s the result will be completely different in terms of packet ordering in the link in the connection link between the sender and the receiver and which will lead to completely different conclusions so when we are talking about evolution metrology when we want to simulate things we need to be very careful on assumptions that were making that\u0027s an example it\u0027s a bit easier with flaming window watching Scott satisfy them well as far as I know outside but anyway forth yeah you\u0027re "
  },
  {
    "startTime": "01:24:54",
    "text": "right right with non-systematic codes you only add Ripper traffic so it makes things easier but non-systematic is not that use is not that popular and I\u0027m not aware of real-time systems using non-systematic codes maybe I\u0027m not I miss something but I\u0027m not oh well yeah this is a framework the fourth topic is about the communication channels that we need to consider so when you want to assess the performance of a given solution forgiven use case so you need to have a model for your channel loss model and that\u0027s typically what we already mentioned to the morning discuss to this morning so it\u0027s very important to have traces that are representative of your target use case so as far as I\u0027m concerned and so far I was only aware of this 3gpp essay for mobility traces which is quite a school that I\u0027ve been using quite a lot in the past it\u0027s convenient because instead of having this to state in that model where you have two parameters two probabilities and you have to find appropriate values for those two parameters which means that you need to explore a two-dimensional space infinite space and you end up with some values that are not necessarily able to detective with your case instead of that you have those traces that will tell you ok if you are a pedestrian what working in the street at that speed then you may experience either a 1% average lost rate or 5 percent or 10 or 20 but in that case those are the four loss finds they provide for lost files that explain you what are the packet that will be received and what are the packets that will be lost on the network so this is the figure on the right each - sign indicates a packet loss so you can follow this fine and see if this packet that has been sent by the sender will arrive the receiver or not so depending on the average loss rate will have more or less packet losses and since you\u0027re a pedestrian when you live via an obstacle will stay on this obstacle for quite a long time and therefore you will see burst of packet losses on the opposite when you are in a vehicle at 120 kilometer per hour well that\u0027s the target of this different "
  },
  {
    "startTime": "01:27:57",
    "text": "model and once again they provide four different files with an average one person packet loss 5,000 10 and 20 and you have to slice very convenient use files that will tell you what packets are received on what packet that we must so that\u0027s something it is available on the web you can go to this website and we treat them and use them for your own equations but it\u0027s just for free PPSA for every Asians for a specific frequency bound to get something like that it\u0027s not necessarily representative of all the use cases so this is why I mentioned earlier when we grab propose to share saturate lost models I was very happy because it\u0027s exactly the kind of thing that we need in order to do tough conservation for satellite communications we need to benchmark our solutions with loss models that are representative for this use case and if you are aware of similar loss models for different use cases do not hesitate to share we\u0027d like to get as many loss models as we can representative loss models so that you can now because models are usually generated with an equation and models are actually and profiles or measures so I\u0027m sorry I\u0027m doing on words here so I think I think we need both yes we need both in case of three bikini season every theoretical model so it\u0027s a loss model yes its loss model the result for us model but yes the probably also lost price under if we have access to some of them are publicly available then that\u0027s great to share that would be great so the idea is to might get some feedback and if you are well something then thank you are there any question questions okay through my best light Valentine to wrap it okay so that\u0027s that consideration something very important for the group I would say we need to be careful but of course we are talking together on we try to do our best most probably in the case we need to write in you into the draft on this topic I think it\u0027s useful I cut off of course I need to shake hands directly I need sharing and trying to find good ways to "
  },
  {
    "startTime": "01:30:58",
    "text": "initialize products find good ways to run performance relations on Otis yes questions comments just a comment because I tell you agree about do we need lost models or because it depends a lot on where you are in the oscillator because if would you take layer two oscillators measurements from silver networks you have all these fake and things already going on so you have to be sure about where packet size if it is measured what also there you are in because twice you have to make it clear when you I will try to be clear about when we provide traces on where we are otherwise we can scan it to misleading conclusions okay so I have anything about the codec is number one I think a lot of us again chair chair hat away a lot of us have done n F Street and NS to simulation models and what I think is missing a lot of time in these model is actually good simulation of the codec itself there\u0027s not a lot of very good ns-two or NS tree code simulator however there is a lot of I think again us who have done incredible amount of work in simulation and maybe that could be a hackathon is actually maybe not a hackathon in terms of writing new code but in terms of getting all the NS two ns three contributions that so many people have done into some kind of an organized an organized way so that when somebody wants to do some simulation of a certain loss profile with a certain code that they don\u0027t have to start from zero and as to R and s 3 depending on what they want to do so I would actually again head off suggest that maybe in your slides you could actually add that so maybe there is some kind of a NS 2 NS three hackathon because both are very different ID there no yes cool questions questions on meek psycho no that\u0027s all listen to you ok that\u0027s known updates for for those of you who again were there at the beginning I may I recall that did know where the blue sheets are by the way and whoever didn\u0027t sign the blue sheet should actually sign blue sheets blue sheets sign the blue sheets yeah now it\u0027s in the back ok okay so whoever hasn\u0027t signed the blue sheet should "
  },
  {
    "startTime": "01:33:58",
    "text": "actually sign it okay thank you so anyway like I said we\u0027ve gone through a number of iterations of these milestones and I think it\u0027s time to review where we are and also we will like I said at the beginning send these to the list also to make sure that everybody agrees with potential changes so we had all of this that were there we have some that I think are in pretty good shape there are things in red that we need to either review change or delete and that\u0027s what I\u0027m going to talk about in the next few minutes so the first one was the existing solutions we mentioned that both teams are Lindsay and Tetris have let their drafts expire so they currently have are not existent there\u0027s actually the bats which is the new ID so now we have an ID on that we would like to frankly rekindle the work on RL and C and Tetris and so I knew that km is on meet echo so take that as a nation and based on says he can actually oh we would also like the tetris team to update their their draft and we would like to adopt both of those as as our G item we will also have dragon cast to update and and adopt as a RG and so we still waiting for these inputs and and now with bats it would be really nice if all these things were updated and be part now of the real milestone and the research group ideas so that we can actually have this nice set of codes they are relevant to the community the other one is the NC and quick that I\u0027ve been editing with Ian\u0027s sweat from Google actually it this turned out to be more way more complex than than we expected because it really has specifications and quick sources and experiment that or a vote that evolved at the same time as we\u0027re trying to put them them down and put a coat over it so that is currently still on however there\u0027s no way we could finish that this year and we plan to reschedule it for next year as quick probably in another room right now are really busy issuing there one and obviously the code will be part of the next version the draft and "
  },
  {
    "startTime": "01:36:59",
    "text": "satellite what this is is almost done Thank You Nicholas and so the proposal is probably to be done by December 1st and time for Christmas shopping and so if the authors can address that it would be really great the common API we also want to reschedule it because essentially as I think they sound really showed is that it was one thing writing about the API and it\u0027s another thing about putting it in the code and so we we plan to reschedule it as it\u0027s heavily dependent on the hackathon so yesterday we were discussing about this we figured out if there is a really good hackathon in Prague and there\u0027s also from my own group of collaborators are some people who may collaborate to this remotely and so I think that by july 2019 we could have like almost a convergence of both the codec and the hackathon and the draft so this is an interesting thing we had at the beginning when we bit retarted the group said ok so we should look at some of the adoption challenges and in effect it\u0027s been done but not in a draft it\u0027s been done in all the drafts that have been issued about applications via the satellite B and the CC and they have addressed in there the challenges to adoption that the adopt the challenges to implementation so we think that actually we can give it up but we shouldn\u0027t we\u0027re not giving up the idea we\u0027re still thinking that applications of network coding should have something every time you write a draft about you know what are the adoption challenges but in it would be like and over it would be just doing cut and paste from existing documents to create another draft so we would plan to think that this is not very useful anymore now this is the that the rabbit that comes out of the hat and they saw mentioned this ID that you can actually do network coding or FEC coding that is going to have good performance even within a using protocols that have congestion control the status of this is uncertain because of other work I had no time frankly to to do this so the surgeon that the status is in surgeon I got in a discussion yesterday with a bunch of people who were interested but they I don\u0027t think they also have time the exact goal may have to be reformulated I think you missed a line "
  },
  {
    "startTime": "01:39:59",
    "text": "here no yeah we are looking for a champion we\u0027re looking for people who would collaborate to this especially people who have done it and the big thing is always how does how do you deal with essentially all the time Network coding with TCP so I think we\u0027ll put that on the list we need to have more discussions and decide what we want to do with this again there\u0027s been a lot of work there\u0027s been new flavors of TCP that have it there\u0027s been all kinds of tunneling solutions that have been proposed so what do we want to do with this and maybe we just wanna have something simple just to say okay frankly we can\u0027t do anything more than what people have done already we may discover that there\u0027s more research and we didn\u0027t know so maybe again this is going to the list the DNC and ICN will obviously thank you guys this is on track this is perfect it will be a small reschedule to make sure that it goes to the the last call and actually you can again converge to the final version so the questions is to with the author\u0027s what do you think how much time do you think you need or how long do you think it will take you because I think this is all Stan so I\u0027m Cassie Sampson there still remain I tend to be to be with you so so maybe we perfectly made major we\u0027ll make complete draft to pass on up to the next [Music] spring 2019 well I don\u0027t know it\u0027s too late well but how when we should why should we complete well I think the question is back to you is when can you do it and then we will accommodate the wind you can do it so if you think that by POG you will be ready for this last call and then we put it last call and we\u0027re fine so do we do we do that yeah okay I\u0027m good the also that we had talked about looking at that we\u0027re coding and robust tunneling a bunch of people were interested in this I think we we have ended it and the proposal is to take it out as a milestone because again this is now part of specific implementations to end every code that has been proposed and I think even Nikolas you address it into the satellite so maybe it is something that has now been embedded like the other ideas some of the either "
  },
  {
    "startTime": "01:43:00",
    "text": "ideas have been embedded in to other people\u0027s work so we think that we could remove it it\u0027s not a real milestone anymore and the good then the question is do we still want to do telling well probably yes so new milestone we have the swift codec which is the hackathon project and I think that should be part of it I mentioned that it\u0027s also related to the API document and we seem that we think that july 2019 would be a good time to have a first at least a very good first version assuming that all C programmers in this room show up in pod and Python we want to do other things the new milestones may be that we want to add this forward or correction that were performance evaluation performance evaluation if Morton and company are interested in the draft and if other people are ready to collaborate and this has to deal again with loss profiles and everything there\u0027s this idea of the computer and the network for net for network coding actually there\u0027s some people on the list who have said that they had started working on implementations of network coding and p4 for example so that they would be inside switches and they\u0027ve you have a question no I think this is great but I there\u0027s a possible confusion in the wording which is you can mean one of two things one is how do you use in network computing to implement NC and reek and potentially recoding for NC yeah and the other is how could and C help a computing in the network well I would I think those are sufficiently different that you don\u0027t people will get really confused if you make try to make one thing that\u0027s doing both again I\u0027m saying two separate things it\u0027s two separate things there\u0027s yeah there\u0027s the the P for network coding which is how do we re encode stuff inside the network and then there\u0027s what I\u0027m presenting in two minutes which is what can network coding do to help things that are computed in the network or the application so I yeah that\u0027s two things there\u0027s there\u0027s there\u0027s one is helping and the other one is actually you doing it so we\u0027ll see the idea is that we wait some more and we\u0027ll see what happens and I would say for me personally I would say probably the performance evaluation could be actually a very valid milestone because of what is needed and because also of your of the coding for dummies which has defined what things are and then having this thing is how do you evaluate the performance could be really well the computer in the network computing in the network the reason I\u0027m not pushing that much in this group it\u0027s because we\u0027re trying to start a new group which is not what I\u0027m going to talk a little bit about questions I\u0027d "
  },
  {
    "startTime": "01:46:07",
    "text": "like to suggest you to add one milestone it\u0027s related to network coding with ICN as a solution because currently it\u0027s just defined a requirement that our challenges and the most important I don\u0027t say most but one of the most important point is that how we express that network earning function within IC or CCM network so this is really important issue to find formalize the packet form and again me we may have some collaboration with site energy but anyway it\u0027s good so if this research could initiate this kind of work it\u0027s great thank you very much well taken ok um so I\u0027m still long I guess if you\u0027re on the other I\u0027ll be faster next ok so for those of you were at the ICN RG interim yesterday this will mean like it will sound like stuff that you\u0027ve seen before but that\u0027s going to do it and by the way this is the picture is from magic leap who actually made their name by showing this picture it\u0027s actually with goggles of a whale that jumps out of a basketball court so there\u0027s a draft that I wrote about the review of what I call the requirements for what I call extended reality for me extended reality is the Cromwell is actually trying to find the commonalities between augmented reality virtual reality 360 degree video experiences and stuff and the ID because we are suggestion we\u0027ll suggesting the creation of a new research group on in network computing whether the idea was actually to see once you have networked X our experiences what are the challenges and what is needed in terms of adding computing in the network to to be able to meet these requirements and also to look at some of the open issues and the research aspects and a lot of them have not been resolved yet so the idea and you see that I\u0027ve put like packet loss and loss and use delay here because this is this research group but a lot of other things are there I thought it\u0027s the multi-source multi destination problem but you have a lot of sources for your experience being part of an IOT some video some overlaying graphics a lot of things that are bringing together and they come from different sources and they\u0027re going to different destinations and especially if you do it in a multi-party and that everybody is participating into that "
  },
  {
    "startTime": "01:49:08",
    "text": "experience then you get a lot of interesting networking challenge so it\u0027s this shared experience it\u0027s interconnected it\u0027s distributed you need some Federation and so you\u0027re creating this global immersive experience and so some of the principles is allowed joint collaborating and X are when the best one I saw was actually joint surgery joint manufacturing IKEA actually has a very cool augmented reality things where people are building no tables and chairs in na R so the multi-view also like when you start looking at it for a different point of view and all the extra streams and also that becomes also another issue is that some of these streams are very very large streams with very large bandwidth requirements and some of them are very small but they\u0027re the ones who actually are driving the experience so the challenges and thank you take your day for suggesting to take the word that was there so it\u0027s actually the Andres is on time delivery of all these multiple streams and their rendering across multiple participants so you have you want these things to happen at the same time because if these people are sharing they have to share together I will tell you that I have experience of something that we used to call social television which was also either thing about having people were sharing the same video experience and it was a big thing of having them having at the same time and actually network coding helped in that obviously a lot of these streams that are coming have a lot of sensitivity to packet loss and lots induced delay especially strangely enough for the non video components if you\u0027re going to have something that\u0027s overlaid and is graphics if these things are delayed then the whole experience falls apart or if their loss is even worse so at low end-to-end delay and delay variations it is very well known that when things in immersive experiences are delayed and that you move your head to try to see them you get seasick because your brain expects the experience to move with you and it doesn\u0027t and obviously this is this idea of optimizing the cache and the rendering this is actually inheritance from gaming the gamers have started doing that you start putting elements in the network that will not change non variant elements and then whatever is the activity the dynamic stuff goes over it but all of this is part of the experience so what would we\u0027d like to have this is actually I\u0027m just figuring out this is extremely busy so you would like to optimize the location that type of resources that you want to have you would like to distribute the functionalities between data center and edge this actually requires functional decomposition of some of the elements again I said that some things are really well done in the in the core in the in "
  },
  {
    "startTime": "01:52:09",
    "text": "the cloud there are things that cannot be done there which are the things that really happen now you may want to have Federation\u0027s of these edge nodes that goes back to the idea of how do you distribute the functionality and how do you disagree the load across all these things and then the evaluation again that\u0027s actually from the gaming world the local caching to make micro data centers with some of the pre-rendering that is needed to for the experience you may want to have multicast distribution another way that is in bold anyway you and again one of these things I think is interesting here if you have this idea that you\u0027re going to put things in the network to help these things to help these experiences is that there are it\u0027s not about just putting it in the cloud which was what people thought in the beginning it\u0027s not just putting it in the edge because this is also not the thing and it\u0027s not just putting it in the middle it\u0027s everywhere and so you can actually also think of trend and machine learning based congestion control there was actually presentations at the IC NRG ICC RG in London well baton was very interesting you want to have dynamic allocation of all the functionality as people move I speak as the group changes as the experience evolves and you may want to have performance optimization and then we go back and some of the things that we talked here on tunneling sufficient virtualization and loss protection and so I will not go into this because we will not have time but this is essentially the architecture or one of the architectures and I made it very complex to actually highlight that a lot of these things although there is ICN and there or CCN there is in the network computing that helps some of the fake functionality coined by the ways for computing in the network there are things that come from the cloud and interact with the cloud and go back to the cloud I think a lot of time that I think one of the mistakes of all these architectures is you have the cloud you have the transit network and you have the destination not thinking half way that there\u0027s interactions between things come to the cloud or process go back to a cloud go to the network and when they come to the edge they have to actually net synchronize with incoming streams that are coming from other parts of the network so I think this is what I wanted to highlight in that what\u0027s the link to this network XR is obviously very delay and lost sensitive we want to use a racial coding to provide this packet the racial coding to maximize things like related to peer to peer and multipath efficiency and reduce the need for format for retransmissions actually you want to prevent as much as you want as you can to have three transmission of the lost information you "
  },
  {
    "startTime": "01:55:10",
    "text": "would like to recreate it and it has to have it really has a we were mentioning this right now the link to current in network computing and programmable network elements once you can actually program the in the network elements to facilitate the the streams that that facilitate the fact that the streams need to have very low loss and very low delay you\u0027re going to be very happy with this so there is a strong link to this group however there is going to be a request actually I request comments from both the computing and the network which does not exist and the network research group community and I would like to have co-authors from the X our community have actually reach out to people actually develop some of these things we intend to generate a v2 and that\u0027s what this is a typo actually I was I wrote this when I was at v-0 figured out that the XML compiler that agent half of my draft so I had to for the new one and eventually have it adopted as a coin RG if coin RG ever happens because join us for coin on Friday corn is actually a it\u0027s not even a proposed research group right now coin is a proposal for a proposal research group who that corn well it\u0027s like the pre pre pre proposal anyway so it\u0027s a proposal for a proposed research group we\u0027re meeting on Friday my co-chair is in the back there Jeffery from Huawei and the idea is to look at the whole research that is happening right now in computing in the network both in the data center at the edge and again like I said in the middle a lot of the work is research of what you called things that heart in the network in terms of how they reprogram but because of my own interest I also think that we will look at some of the applications that are enabled once you can do that and with then can justify all the other implementation so again join us Friday and for this group I think there is a strong possibility for for FEC and network coding to basically be part of one of the great XOR solutions thank you thank you Mary did any comment quick comments questions one time well two three minutes left well thank you everyone merci beaucoup the question from Phil meeting of Jose we you should you should have known this is for people who came in late for the first five minutes of this meeting everybody was here about it\u0027s almost everybody spoke French so thank you very much we will see you in Prague we will "
  },
  {
    "startTime": "01:58:11",
    "text": "see you on the list and I can see that there was a lot of new people here and this for us is absolutely fantastic please collaborate this is a great topic I which I think maybe that\u0027s taken some time to take off but I think that it\u0027s right on for so many of the new network applications thank you very much thank you everybody see you in Frank [Music] [Music] thank you to everybody on the Medeco by the way thank you so much for your participation and I know that a lot of you are at in the middle of the night so thank you for so very much "
  }
]