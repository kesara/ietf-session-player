[
  {
    "startTime": "00:00:08",
    "text": "okay let\u0027s start with the big crowd welcome to the ITF DTN working group thank you all discussions everything that we write say or anything on is under denote well proposed agenda hopefully the last presentation about TCP CL so that we can afford it to the right people upstairs VP SEC updates bundled in bundle and custody transfers who were kind of move out of the VP base base document and then management any agenda bashing or changes suggested okay Edie would you take notes as usual thank you very much jabber oh yeah anyone who wants to relay on the jabber then watching my stones we\u0027ve working group last calls on those two documents we wanted to send both through the ISD at the same time given that we did this by itself requires you know the convergence layer of some sort we\u0027ve been discussing TCP CL since then and hopefully it will be final and sent to the Ihde very soon this is the milestones for the working group and the chartered current charter I can remove from the previous presentations all the you know small stuff but essentially we do have security protocol addressing architecture naming no discovery so a lot of stuff to do with that yes there\u0027s other comments let\u0027s move - yes carp early and was there there were going to be three documents taken together at the same time right TCP CL and bps and also security did we not go through last call on BP SEC we I\u0027ve been kind of saying let\u0027s push TCP CL and BP this first to the is okay cool because if "
  },
  {
    "startTime": "00:03:08",
    "text": "there\u0027s any changes you know kind of as substantial changes then they may impact BP sick right sure so yeah my my impression had been that that that the area director wanted those all three of those to go for at the same time but if that\u0027s but if we\u0027re good with with BP dissing TCP CL then I\u0027m I\u0027m fine with that I just want to bring it up well we could do like you know one after the other right after the other right but you know we\u0027re we\u0027re not really successful in sending stuff to the is fast but so Brian yeah I know if you were here cool we are not hearing you not sure why oh okay now now it\u0027s better great okay so there\u0027s very few slides here it\u0027s just really a delta from the earlier versions so this is only discussing roughly in what is in the the seal itself and focusing more on what are the last changes since the last IETF and the feedback after that idea so next slide please sorry Brian is there any chance you could turn your microphone up a little bit you\u0027re very quiet to this end Oh giving it a try no it\u0027s still very quiet yeah could you try bring the mic on your headphone cord up closer to your mouth sorry it\u0027s yes okay all right so this is just a summary of really the changes since the last IETF and the feedback received since then with a little bit of boilerplate still left in the presentation so I figured in the next slide this is really what I just talked about and also there\u0027s a little bit of discussion about the prototype that was made at the end of the current state of "
  },
  {
    "startTime": "00:06:10",
    "text": "the draft next slide please so all the motivations for the converters layer update are still the same as they were I did add a another item here just for people\u0027s reference that 1 to 4 had been the same throughout but the last set of changes to the spec were to add extension capability for both the connection the session itself and the individual transfers although right now there aren\u0027t any actual extension uses defined but the capability and the mechanism is there and it still roughly follows the nomenclature and the workflow of TCP CL v3 and even these last changes were made to simplify and to avoid variations in the protocol workflow next slide please the the overall what the CL is doing is still the same since v3 although there have been a lot of fiddling with the mechanisms of how to do this the second sub bullet item about the still using contact negotiation and the existing headers and type codes that applies less now than it it did because we have set aside separate inr registries for the v4 type codes from the v3 but some of these familiar with the v3 should be able to pick up v4 and understand what\u0027s happening relatively quickly the one thing that has changed in the last draft that I\u0027ll talk about in a second is there still is a single phase contact negotiation but it actually is split between a free security and a post security negotiation so if you go to the next slide discuss this so the zero nine revision of the drafts didn\u0027t make it in before at the IETF although it had been a bit late in coming the the major changes to the document itself are to try to simplify understanding in the earlier sections of what the draft is defining and what the protocol is doing so it adds some state definitions it adds names to the roles of the entities involved in the protocol it defines an active a passive side of a session it defines some terminology about the states of an individual session the states of a transfer and "
  },
  {
    "startTime": "00:09:10",
    "text": "some diagrams to make it hopefully easier to understand how the both ends of the roughly symmetric session operate the workflow really is the same rough workload from v3 but these are more intended for somebody who\u0027s not familiar with how the CL operates the third item here is a change to the protocol encoding definition actually there was a lot of feedback about the security implications of how it was structured before it was really a holdover from from v3 in v3 there was no concept of a secured session so there was no distinction between pre security and post security exchange of data this last edit does split the - it\u0027s still uni-directional in the sense that once you progress past the negotiation stage you can\u0027t renegotiate it still only goes one direction but at this point in the 0-9 version of the draft the only unsecured data that\u0027s transferred is the can TLS flag and all of the magic magic octet that establish that you are talking to a TCP CL node so what this does is it guarantees that an implementation simply can\u0027t provide any unsecured data as if they don\u0027t want to provide any and secure data it\u0027s not possible to leak the negotiated contact information and the fourth item here is a simplification in terms of workflow from the in terms of sequencing from the last version of the draft and v3 which is that the connecting entity always sends the contact information first and receiving the list in there always waits for a contact message so that makes the sequencing of things a bit easier of it\u0027s simpler and it avoids the possibility of some kinds of not leaks of information but leaks of resources if there was a bad actor on a TCP CL Network the transfer extension capability was added which is really just a identical encoding to what had been specified for the the session extensions there\u0027s a different "
  },
  {
    "startTime": "00:12:11",
    "text": "registries so there\u0027s a whole set of types of assessing extension items from transfer extension items right now there are no actual item types defined by the spec but the capabilities there and there was some clean have done about failed TLS handshakes and failed connection attempts just again to avoid the the avoid sending any date on the wire that really doesn\u0027t provide any information and is something that could be a vector for unnecessarily wasting resources if there\u0027s a misconfigured or a bad actor trying to connect next slide please so all that being said had been said supposed to fire a revision that we lost you for a second I Brian I\u0027m back okay out again so this had been said before but is being said again that the current draft of the spec is all there in the sense of defining everything that needs to be defined to implement a protocol and there is now in the in the drafts back with an editor\u0027s note to take it out a reference to the prototyping implementation to be used that could be used for interoperability testing or or just establishing that yes this protocol is implementable it follows a single path through the workflow for a lot of these things so it does do a minimal amount of error handling but it doesn\u0027t really allow you to exercise weird situations of messaging it\u0027s just really supposed to be proof of concept for the normal path of a session to start with since I have transfers and it doesn\u0027t have anything to do with DP itself it\u0027s purely chunks of data going from one end of the session so the other end of the session over TCP so that\u0027s where things stand right now and and all of this was changed to address the last comments that were received against the earlier draft of the seal okay thank you Brian um this is good stuff I I need to reiterate to the working group again that this this work is vital really we we have to get this done we have to get "
  },
  {
    "startTime": "00:15:11",
    "text": "this pushed the isg as fast as possible it\u0027s been resting in working group last call and brian has done lots of good work on this but he is working pretty much solo at the moment so we need more feedback for comments as fast as possible so please have a look at the latest draft I know chair hat off I\u0027ve noted it I think it\u0027s in a very good place now but we need to make sure that the working group is happy and the clock is ticking on this because you said two week window and we push the button I\u0027m trying yeah of course go with the questions first I do card just one question I didn\u0027t find anything in the draft and I hope there is nothing in the draft that would prohibit my using various TCP options the reason I ask is in the same kinds of environments where the bundle protocol would be very handy having an extremely robust TCP would be very handy and I\u0027ve made extensive use in the past of skips TP up to 20x I just want to make sure there\u0027s nothing in there that would say I can\u0027t do that sure I should have looking back I should have included the new diagrams in the presentation but I didn\u0027t but the very first state on the TCP CL diagram is you already have a TCP connection so that\u0027s really the starting point of the CL and it really leaves up to the network the implementation where and how that that TCP connection comes about so I believe that there shouldn\u0027t be anything in there preventing the underlying TCP socket interaction from being whatever it needs to be as a Rick here\u0027s a follow-on to that if you feel there needs to be clarifying text can you just review the document just check it it does cover this I agree with Brian I think you\u0027re fine if you feel it needs text can you can you suggest some more or give us a +1 on the list for this so to reiterate the desire of the chairs if everyone is happy is to make this a two-week last last call and then press the button and one thing I will say is Brian has done sterling work on this I know there were lots of original authors from TCP CL v3 and guys involved with the early days of the v4 documentation I\u0027m sort of trying to reach out to them to say can you assist Brian and Brian can you amber ate a little bit this isn\u0027t this is meant to be a constructive request not a criticism because as soon as we "
  },
  {
    "startTime": "00:18:11",
    "text": "get into the IAS G pipeline there will be ad reviews that will need addressing promptly there will be editorial nits that need to be addressed and it\u0027s important for the working group that we\u0027ve all got day jobs you know just to make sure that it\u0027s not we\u0027re not all just standing looking at Brian waiting for him to do so if people want to assist I\u0027m looking at your for example please step up and Brian please use them the onus on the rest of us is please review this and check this is good because otherwise it\u0027s happening silence is ascent one left area that would be useful to get some feedback on is there was some comments earlier about discussion within the spec within the draft of the should and optional behaviour and I really have not gone through and scrubbed all of the cases of should in may to see if there\u0027s guidance on when or when it\u0027s not appropriate so if anybody who does browse through it has particular shoulds our maze in there that it\u0027s not clear when that should or may applies and what the implications are to them that would be a useful piece of feedback to have I mean a lot of those will be picked up by DHG but it would be better if it left here correct it\u0027s just a bit embarrassing when the ADEs turn around and say you\u0027ve got this sort of stuff wrong but from Brian\u0027s perspective and I agree with him having written these drafts it\u0027s hard to get this bit right so I think that\u0027s an action for the rest of us in this room and online to go have a look at it just double check the required mandatory wording okay thanks Brian I think we\u0027ll move on to the next straight item so a protocol to the security area come out yeah "
  },
  {
    "startTime": "00:21:13",
    "text": "there\u0027s too much playbook no no it wasn\u0027t is that better yes even I can hear me now so so uh so to repeat briefly again we made a decision as the working group to submit the standard for post standard to the security area for an early review we did get comments back from that early review additionally we had sent the spec out to other standard body security review of areas and we got some minor comments back from them as well so I want to explain what those comments were I want to walk section by section the changes that were made to the standard between be piece echo 6 and o7 there were a couple of small questions that I wanted to bring up to the working group and then to move over into the interoperability cipher suites and then finally just talk about a discussion on how we choose to represent extension block type specific fields in in VP which may be overcome by events from the mailing list so starting with the IETF security area review the review early disposition was almost ready so as I understand it there are three rough dispositions ready almost ready and not ready almost ready means that it\u0027s almost ready the three comments that came back I think that\u0027s what it means so tautologies aside there were three comments that came back one was there was some confusion on the point of view of the of the reviewer as to what we meant when we said integrity as it relates to encryption this did not necessarily turn into a change in the format of the specification or how the protocol handles things but we did have to clarify some text additionally we clarified and and at the reviewers request put in a stronger statement that when you are using encryption in BP SEC you must use an AE ad cipher suite which really means a cipher suite that generates an authenticated encryption and perhaps other additional data associated with it too to Rick\u0027s point from before there are RC 2119 wording questions sometimes we used all capital maize sometimes use lowercase maize and I tried to clean that up as best as I could and then the last was just a comment on the security considerations so I want to walk through these briefly one by one but the the full comments are available at the link below so so the first comment that came up was essentially and I\u0027ve emphasises mine it mandates authenticated encryption the security ad feels strongly that if you were to not have authenticated encryption how do you understand if your decryption has failed how do you understand if something else has been substituted along the way it was certainly something that that we had "
  },
  {
    "startTime": "00:24:13",
    "text": "always envisioned would be part of any operational cipher suite but it in our opinion it makes no it\u0027s not harmful because of that - to say that any BCP ciphers you "
  },
  {
    "startTime": "00:51:40",
    "text": "could say we understand some format of the plaintext meaning it is a see a byte string and it has some sort of a length designation followed by the data we could take the length away feed the data as the plaintext understand that if our cipher text is the same size as the plaintext the length won\u0027t change and now our encrypted data is of the same size and we now have the length and the overall thing has not grown in size but we can\u0027t do that if we have an array if we have an array then we need to take that entire thing as plain text we will generate cipher text but then we have to have to put some length on top of it which can be one two three or four bytes depending on how long that plaintext a cipher text is so what do we do in in that case right so if if we choose to represent extension blocks with things like arrays or really anything other than byte strings every time we encrypt we\u0027re going to result in ciphertext that is larger because it has to be encoded so the question is can be Phoebus always represent block type specific fields as byte strings because it certainly makes things easier for us and it probably doesn\u0027t hamper other things but then the other is even if we were to do that is it seen as a violation to somehow meaningfully parse the context of plaintext to say well we are assuming that the beginning of the plaintext is the Seaboard length and and are going to you know sort of use it or views it as such my recommendation of course is that we should represent things as byte strings and that it is not an abuse to do this but it\u0027s an open question to the working group scholarly and I\u0027m I\u0027m for option a there I think it is the simplest thing just the block type static fields just always make them byte strings always precede them little lengths no I mean they\u0027re preceded automatically will link by being seaport byte strings the simplicity of that is very appealing and I can see cases where it also would be more video fishing so I think it\u0027s the best way to go Rick with my without a chair hat on how does this I\u0027m just trying to quickly checking my mailing this mail logs how does this interact with the block length field discussion that was going on I seems to be this is another manifestation of the same is here it is yeah well and what the the original had discussion had been was well the original discussion had been that the block type specific stuff is gonna be see bore encoded anyway why have a length field in front of it because all the elements of type specific stuff are our self delimiting which is true right would and and so you arguably you can save a little bit of byte of data by by "
  },
  {
    "startTime": "00:54:44",
    "text": "leaving that that length off and and then that was we visited on mailing list in the context of simplicity question and I think the sense on the mailing list has been that this is the best way to go so that is all I have the are you aware of any muck ear are you any aware of any implementation so there is a I\u0027m not aware of a full implementation of this there was a partial implementation that had gone into ion which dealt solely with applying these blocks to the payload block without the security target but I think we need a BP biz v7 implementation to how the blocks represented at is first which I think we may have now and then the next thing would be a BP second fermentation right there are two at least partial BP distance plantations so you could conceivably do a BP second fermentation integrated with with those probably the more complete one is the one from the guys in Dresden the the one that is in ion is really sort of a the interim streamlined bubble security protocol specification which can\u0027t be the entire BP SEC because it\u0027s based on RFC 5050 which lacks block identifiers which is required for the the new iteration of bibs and PCBs market again I\u0027m asking the question because I wonder if we got reviewers and reviews of this spec because it\u0027s a pretty complex thing from the point of view and a Dementor which you know may not ever happen you know I\u0027m not sure how much we have exercised in the actual spec really as a implementer point of view you know ITF standards are not do not require implementations for the first level of the standards proposed standards but at the same time you know it\u0027s kind of reassuring because you know you have a different eye when you want to implement something especially for complex spec like this which actually depend on other another you know not so simple implement a respect to so well so agreed I I will say though that a lot of the "
  },
  {
    "startTime": "00:57:44",
    "text": "participative been in ITF became VP sack was the lessons learned we have of trying to implement ESP and so we we certainly had things from there and most of the most of the work that we\u0027ve done here is to actually remove features and functionalities from from BP sack but I would say that the Seabourn coding of this data is new and and is something that probably could be prototype really quickly and and maybe by the next meeting right do it it\u0027s clear that we\u0027re not starting from zero but at the same time you know when you read a spec from there you know I didn\u0027t limitation you know you you go into all the details of oh there\u0027s a big ol layer because when you start coding you actually oh sure I\u0027m one thing I\u0027ll add is this specification is I think is complete and comprehensive with regard to the protocol what I\u0027m working on right now is policy and that\u0027s something that we haven\u0027t addressed yet that was going to be in a separate book and it\u0027s going to introduce a whole other layer of complexity unavoidably but from the point of view of implementation complexity is for keeping in mind so Scott Rick with chat on do you feel that and I know that\u0027s future work and it\u0027s difficult to judge but do you feel that policy documentation is gonna have impact on VP sector as it currently stands no I don\u0027t think there\u0027s any I don\u0027t think I\u0027ve not yet seen any need for any sort of impact on the BT SEC protocol specification to make the policy work I\u0027m seeing opinion there is a section of BP SEC called security policy considerations it\u0027s not normative and but if as you\u0027re going through this giving and we believe it\u0027s the minimum set of policy that you need to provide but if you see any issues there please let us know right I\u0027m the there was a section like that in the original BSP specification which which I\u0027m sort of using as a as a checklist to make sure that that\u0027s all covered so my next question with chair hat on these I\u0027m looking in the data tracker and this is marked as in working group last call and it\u0027s been lingering there for a bit how many people have read this latest draft I\u0027m looking in the room obviously it\u0027s a bit harder to do over meet echo but no okay so it is iing someone has a printed out in front of them so I\u0027m as "
  },
  {
    "startTime": "01:00:49",
    "text": "mark alluded to in our intro slides TCP CL and BP base are we\u0027re gonna push them really hard probably let BP SEC follow that doesn\u0027t mean BP SEC is not important and it needs good review and can I again request people just take them at a time and try and digest it it\u0027s complicated just try and rough out how you\u0027d implement it just check all those ifs and else\u0027s a way you need them but other than that applies to everything of course but if you could just spare some cycles on this I think it it would be a mistake to realize we\u0027ve got a Fault in a security document after we\u0027ve pushed it out of the working group otherwise thank you with followers about this I\u0027ve got nothing this is a talk that I gave at a workshop on intelligent space and networking in Nanjing a couple weeks ago and that\u0027s me in yes sir we need a shepherd for the BP sick document any volunteer for shepherding the document we should be pointing somewhere following the process so you have a report essentially that says you know answer all the questions that\u0027s the documenting review you\u0027re working with last call implementation it\u0027s a it\u0027s an administrative thing but you follow the document as it goes through oh yeah so this this came out of drafting the the latest edition of the bundle bundle of capsulation internet draft m\u0027as working on it it occurred to me that there were potentially of maybe more depths to what we could do with the ibe then had previously been explored so I thought I\u0027d try to list some of those and and encourage people to think more broadly about what would be implied by this capability so I will have a short history of a bundle bundle encapsulation I\u0027ll talk a little bit about something called aggregate custody signaling and "
  },
  {
    "startTime": "01:03:49",
    "text": "go over the current design of the ibe and then spend a little time on why I think some the applications are ok short history of bundle bundle encapsulation the original Bible spec this is from 2009 Susan Symington Bob Durst and Keith Scott at mitre drafted this as it was conceived as a bility an application essentially they don\u0027t have a on the protocol application a capability of the application agent the motivations listed in the introduction to that document were a support for content centric networking way back then and the idea there was was forwarding of bundles they\u0027ve been cached if you if you\u0027ve spread bundles through the system and you\u0027re caching them because you\u0027re being content centric how do you take that data and send it to something some node that was other than its original original destination so you need a way to do that and bi B he was seen as as as their mechanism a mechanism for [Music] specifically targeted custodial we transmission from multicast bundles or reliable multicast and as a mechanism for security tunneling and in particular traffic analysis right because it\u0027s the only way to to send a bundle with the primary block encrypted so that it can\u0027t be analyzed by hostile Network interpreter scepters the the original bi b e spec never got used very much as near as I can tell maybe somebody\u0027s using it and not advertising that fact but we didn\u0027t forget a lot of interest or traction in in CC SDS or or in ITF really until 2013 [Music] where we started looking at security the same kinds of things that that that Ed\u0027s been talking about that motivated Abuse Act a big problem in the original bundle security protocol specification was that there was a conflation between routing and security there was implicit in the concept of having both security sources and security destinations in security blocks that were distinct from the bundle secure source and the bundle destination so that that conflation could result in bundles being routed to some place without reaching a spot at "
  },
  {
    "startTime": "01:06:53",
    "text": "which they could be decrypted for example as of limited utility so a way to get around that would be to not allow security destinations other than the final bundle destination and and if you needed to do that if you needed that capability of a an interior source and destination you could do that by encapsulating the bundle inside or another bundle and the encapsulating bundles destination would then be the essentially the security destination and you do it in a very clean way that regular routing could handle without without any problems so so I I wrote a draft in March 2013 that essentially resurrected vib Ian in that simplified form but as a as a convergence layer protocol underneath vp in 2015 2016 there was a lot of discussion of custody transfer and and problems that sort of inevitably come from the original definition of custody transference however see 50 52 of those were in to some degree showstoppers one was that because not all nodes are required to take custody when a custodian forwarded a bundle it really had no in the general case had no way of knowing when to expect a custody exception signal because the next node receiving that that bundle might or might not take custody and then it would forward it to some other node that knows who it is and there\u0027s the the point at which custody would finally be taken would be completely unknown to the original custodian to the sender worse than that is possible because not all nodes are required to take custody as possible for a node that receives a custodial bundle not to take custody but instead to fragment the bundle and now there are two fragments going through the system with the custody request signal set when they reach a node that can take custody the custody signal goes back but it goes to nowhere because nobody is taking custody of those fragments and there\u0027s and there\u0027s never a custodial acceptance signal coming back to the custodian for the original bundle so there were these certain Felicity\u0027s in the custody transfer system in general but that didn\u0027t remove the the fact that in some "
  },
  {
    "startTime": "01:09:56",
    "text": "deployments you really have to have custodial retransmission in the sense of using the bundle protocol itself as a way of sending acknowledgments back to the to whoever is in a position to we send the bundle because in some cases the the return path from a receiving node to the sending node would not be the same as the sending path and it might in fact be a a separate no path that that is subject to delay in disruption so last year I think we talked about extracting custody transfer from bundle protocol to simplified on the protocol and to localize all of the the complexity of custody transfer in a new document and and and in general the the conclusion there that we were working with was the bundle protocol transition reliability useful thing do it between neighboring VP nodes and and that would mean essentially at the convergence layer so custody transfer convergence there used under protocol as a convergence there protocol reliable convergence their protocol and then a moment of clarity bundle bundle encapsulation was already doing that so the simplest thing looked like simply building custody transfer into bundle and bundle of capsulation and use that the IBE protocol for both purposes independently or together that is use it for cross domain security including traffic analysis and use it for reliable convergence their transmission over asymmetric paths separately from all this and in in parallel to it back in 2012 there were some guys that University of Colorado in Boulder who were working on the use of DTN on the international space station which had highly asymmetrical links the downlink was thousands of times higher bandwidth in the uplink and so for reliable transmission between the space station and the ground custom transfer which is what they wanted to use was not going to work because the number of custody signals required going back up to the spacecraft to acknowledge receipt of data would have completely flooded the the very meager up length bandwidth so sebastien Kosminski and Andrew Jenkins developed a mechanism for aggregate custody signaling where the custody signals would go back as bundles just as "
  },
  {
    "startTime": "01:12:57",
    "text": "they as in RFC 5050 but the custody signals would not be one for one with the acknowledged bundles there would be a an aggregation of custodial acknowledgments into a single bundle that was originally conceived as a as an additional administrative record and an additional extension block it was implemented in ion in 2012 2013 and and it worked actually really well it was highly successful in operation of the ISS and the people using it are just big fans so as we look at migrating custody transfer into a bundle bundle encapsulation a natural adaptation there would be to look at in fact putting aggregate custody of signaling into bundle and bundle of capsulation originally as an option alongside the original one for one custody signaling system in our 5050 but as I started looking at it a little bit longer I could not see any advantage in retaining the old you know on the per bundle custody signaling mechanism the aggregate signaling did not impose enough overhead to argue against using it all the time so that that\u0027s what is is written into the bundle and bundle custodial transfer draft posted in May that that well aggregate custody signaling is supported as an optionally reliable convergence layer mechanism under bundle protocol the encapsulated bundle may be encrypted it may be signed it may be reliably transmitted or any combination of those and so that gives us a reliable convergence there protocol that is based on using bundle protocol as the as the transfer mechanism analogous to LTP or or TCP the way this works is that the payload of the encapsulating bundle includes a transmission ID which is what\u0027s used as the mechanism for aggregation which is set to zero if there\u0027s no request for custody transfer an expected time of acknowledgement which the sender computes based on its "
  },
  {
    "startTime": "01:15:59",
    "text": "expectation of the round trip between itself and the and the neighbor the Tawaf topologically adjacent node that its send me into because it\u0027s convergence layer and then the encapsulated bundle the acknowledgement of the encapsulating bundle is aggregated into an administrative record that comes back in a responding bundle there\u0027s a yeah there are our aggregation thresholds in time and size the same sort of thing that you do with the aggregation of LTP there\u0027s a custody transfer disposition code that is in the the the signal that comes back and that applies to all of the the encapsulating bundles that are covered by the the custody signal and then there are sequences of of consecutive transmission IDs and that\u0027s that\u0027s all there is in the in this return record if the acknowledgement is not received by the expected time then transmission of the encapsulated is assumed to failed and the encapsulated bundle can be queued for reporting same as in old-style custody transfer so so given this mechanism there are some things that that you can sort of obviously do with it here\u0027s custodial reliability is an elegant diagram showing how considerably overall I ability works the wheel the the the source bundle is shown in red the the encapsulating bundle is shown in green and the custody signal coming back is this crosshatch thing and so the what\u0027s shown here is an asymmetric data path where no one - no - it goes it\u0027s unidirectional perhaps and from node two back to node one the the acknowledgement or customer refusal signal comes back by some entirely different paths and through other other nodes altogether and here\u0027s the other original motivation for bundle and bundle decapsulation here we were showing cross domain security and the the the original source bundle gets encapsulated in in a encapsulating B IDE bundle and the the source bundle is signed that that\u0027s what the sort of little brick cross-hatching shows and "
  },
  {
    "startTime": "01:19:01",
    "text": "traffic analysis is basically the same thing where instead of just being signed the encapsulated bundle is encrypted and that encryption is is terminated and the original plaintext source bundle emerges at node two and makes its way across the safe part of the network to the destination but because one of the protocol is being used as the convergence their protocol that means that all of the features of bundle protocol can be applied to the convergence layer transmission of bundle so for example suppose you\u0027ve got a bundle that is in a private network it\u0027s extremely important but once it gets into a trunk line for example or some sort of wide area network in that you know in that big pool is this much smaller fish and so while it\u0027s expedited in in the local networks that produce and consume it in the over the trunk line it\u0027s just standard priority and the the encapsulating bundle can have an entirely different quality of service than the original source bundle and quality service that\u0027s better matched to the network itself as an elaboration of that there\u0027s this notion of critical forwarding in the extended class of service and and so you can imagine that the the original bundle is is just sent from from the source node to the destination node but once it reaches the edge of some unstable network the entry into that network recognizes that the you know the network is is it\u0027s a mess and yet this data has got to get through so so it forwards it with the critical foreign flag set which will cause the bundle to travel over not just the the one path from node 1 to node 2 but over all possible paths from node 1 to node 2 and so multiple copies of the bundle may arrive No - but the chance of mmm no of the bundle not making it to the - no - at all our minimized and and and from node2 onward to the destination it reversed - just being the original source bundle another variation on the same thing would be it may be that that rather than "
  },
  {
    "startTime": "01:22:03",
    "text": "wanting to send from node 1 to node 2 across this network over multiple paths it may be that node 2 itself is not necessarily reliable so rather than focus on sending the bundle over multiple paths to one exit from the unstable part of the network you might multicast it and multicast it to multiple possible exits from the network to make sure that at least one of them gets a copy and forwards it and and and at the at the end at the at the end of the unstable part of the path multiple nodes may have received each of them received one copy of the encapsulating bundle and forwarded one one copy of the source bundle the destination node may again receive possibly multiple copies of the source bundle but it\u0027s got a good chance of getting at least one of them source path routing this is something that that Lloyd wood pointed out on the mailing list that that bundle bundle encapsulation gives us and I think we can certainly discuss whether or not that\u0027s that advantageous but but it in any case it does work and and it does provide a a way of doing source path routing that doesn\u0027t require any additional protocol design it\u0027s it just just comes naturally out of a bundle and bundle encapsulation and you can imagine combinations of these things you when the bundle reaches the edge some unstable unsafe part of the network the that entry node may determine that it\u0027s it needs to be sent to multiple receivers but it needs to be signed by the bye-bye note one to make sure that those receivers don\u0027t drop it and so it it may be uh that the the source bundle is is not only multicast but it\u0027s also signed or it could be multi multi cast and encrypted and then decrypted at each of these points so in general the what I think we have here with bundle and bundle capsulation is a wide variety of processing options that are rooted in the fact that we\u0027re using the bundle protocol as a convergence there are protocols so all the features that are provided by the protocol or are available at the convergence there and that I think gives us a lot of options maybe an increasing number of options as as as the bundle protocol ecosystem grows and we had more supporting protocols bundle bundle encapsulation is "
  },
  {
    "startTime": "01:25:04",
    "text": "being considered for adoption in the working group it\u0027s actually sort of deceptively simple specification there\u0027s really not very much to it it\u0027s you know fairly fairly straightforward implementation should be pretty easy and it\u0027s very powerful and the applications I think are just a matter of imagining what you can do with it and that\u0027s all I have questions from the floor questions from mythical don\u0027t go away yet this functionality is actually was in 5050 and then in VV this got removed so essentially we\u0027re having multiple documents for the same functionality so I it\u0027s really thin the Charter do people feel we should adopt this document as a working good document yes no maybe only one or both musica college I feel that there should be fun to the working group written document Rick Taylor without my chair hat on I think this is important working should be adopted and brain I think they should be adopted anybody opposed or have any issue okay so let\u0027s conserve possibly adopted I\u0027ll we\u0027ll send an email to the mailing list to confirm great and then thank you we could then the next step we would have for you to reshoot the document under draft idea DTM exactly so next off I believe is ad who\u0027s gonna talk about the async rest management just as it comes up I believe at IETF 101 IDI requested this be accepted as a working group document I believe it\u0027s on the Charter I\u0027m looking for mark to correct me at this point I think I thought the architecture okay right I\u0027ll shut up so trip also so to start with that when we talk about network management in a DTM we\u0027ve broken up the drafts that we\u0027ve proposed into three areas the first is an architecture document which talks about the required processing and the desirable properties and the workflows "
  },
  {
    "startTime": "01:28:06",
    "text": "associated with network management in this space separate from any kind of data model suffered from any kind of protocol and that\u0027s called the asynchronous management architecture that was the document that we had requested the adopted I believe at 100 and 101 for minutes that was that was approved and the others were separate where the data model associated with that and the protocol for exchanging that data model and I wanted to talk through some of these briefly so if we if we start oh this is that\u0027s right give me a second I\u0027m gonna see whether this fullscreen button does what it says it does haha yeah so uh there was a hot RFC meeting on Sunday and we were able to present some of this work there as well the the motivation for why we are trying to do something different for network management in DT NS is to try and address the fact that if we have very remote nodes that are not always part of the network and are not always part of high availability access to operators and managers in the network then some of the operational constructs that we currently use to manage networks no longer work particularly pull requests for data or the idea that performance monitoring happens in a network operation center and network operators can then push things back we spent some amount of time some years of going through various approaches to this problem who looked at mobile code we looked at expert systems we looked at things like SNMP and Arman and early net comp and rest comp and so on and what we found was that no one thing answered or addressed the problem that we thought that that we had in this scenario but there were a couple of things that were close and if we could find a way to put them together usefully then we would have something that did what we needed to do we looked at spacecraft fault management systems in particular they don\u0027t have the security issues associated with mobile code or with flying script or scripting engines they had stimulus-response systems there were many heritage implementations they were they enabled deterministic processing if something came out from a period of delay or disruption you were able to forensic ly account for what happened during the times when you were not actively managing the device and you knew exactly how it would behave in those disconnected scenarios the difficulty was on the space side one there really was no network cannot this was a fault management system to the there was very little infrastructure for how to do it it was very mission specific or space agency specific so many people do this job and about the same way but they all do it a little bit differently and there were no standards if we looked at network management we saw lots of standards but not too many and we saw some open-source tools we saw large investments not just dollar investments but intellectual investments "
  },
  {
    "startTime": "01:31:07",
    "text": "in trying to understand operational workflows but what we didn\u0027t see were the things that made the space systems work very well when you were disconnected which were what we call mature autonomy models and when I say inefficient implementations we mean binary implementations and also compressing the protocol stack because on very embedded devices and not just spacecraft but small energy harvesting nodes would be another good example having 10 15 layers of stack and processing associated as is perhaps not the best way to use your battery time so the question that we came up with in the AMA was how do you usefully reason about putting these kinds of things together to manage nodes in an autonomous way and in a networking way and what would that overlap look like so we came up with something called the asynchronous management architecture data model template and protocol encoding I have it passed IETF presented some of this before so I\u0027m not repeating that information here I just want to go over changes to those documents but I do urge and recommend people read at least the architecture document which we think lays out what needs to be done in this area the AMA is essentially an aspirational document the ADM is a template document for talking about how to how to build the autonomy models for individual applications and protocols and then a MP is the C boring coding of those structures so that they can be exchanged efficiently on the wire in all of that there is a set of drafts that have been published sort of in an ear of this working group and we talk through we talk through again that AMA architecture followed by an application data model which is the autonomy model and then just like we have yang modules or just like we used to have libs we would have some statement on how we apply instances of those models to various applications to manage them such as how we would autonomously a bundle protocol agent or how we would autonomously manage a BP sac agent and then again the protocol side where we have a couple of reference implementations I guess is just another view of what those are again am a ADM and a MP or sort of the higher order ones ama is the document that we\u0027re currently asking and believe we\u0027re proof for adoption ADM was sort of our adjacent encodings and the model and then the Seaboard and here for for those who are interested in going back and reviewing these top three are those a series of management documents and and some other ways of reasoning about it using a database in general if we talk about the asynchronous management architecture we were on version 7 of this the the past several versions five six seven have been very very small revisions if you look through the difference is some "
  },
  {
    "startTime": "01:34:08",
    "text": "minor spelling and grammar some moves of items into a scope subsection updating the logical data model to make sure that it has all of the items that have come in as we have worked with both the network community and some of the autonomy communities add a little bit of background on command versus control and talking about you know some some notional differences between keying off of time and keying off of state in a system but again the request here is if you haven\u0027t had you\u0027re interested in the topic and you haven\u0027t had a chance to read through it take a look through the AMA specification the system model is familiar we didn\u0027t see need to change the basic system model of having agents and managers and there can be multiple agents and managers and we talked in the AMA document as to how they can be multiplexed with shared definitions again much like gang modules and MIBs we proposed something called the application data model because it just needs more things in it and that operate slightly differently than a yang module would operate or a mid would operate and then if we look at the application data model itself this talks about the go one more head the autonomy model that we believe satisfy the requirements and the desirable properties that we lay out in the management architecture and that data model has things that we call externally defined data which are things that are computed outside of the network management system such as in firmware a 2d conversions and so on literals which are just that numbers in the system operators that can be defined plus minus sliding average controls which are essentially command op codes in the system tables and reports which should again be familiar for a network management perspective the ability to define strongly-typed variables without tipping in to making this a scripting language which we don\u0027t want to do macros which are collections of controls and then time and state-based rules which bring together the ability to generate expressions and then call command op codes together and all of that we sort of propose that some of these things are atomic meaning they really don\u0027t change once things are deployed because changing them would mean updates to firmware things like externally collected data the operations that are coded into the agent that they can run the command op codes obviously if you had command op codes in a system that typically means you\u0027ve updated the firmware in the system to actually implement new commands and then there are things that can be dynamic and generate as part of network operators active in the system adding additional variables defining macros defining new reports that can be generated over time and and giving and configuring behavior as to how things should act over based on a function of time or based on state changes in the system so going back one slide the ADM template takes that "
  },
  {
    "startTime": "01:37:09",
    "text": "autonomy model says we believe that that is the smallest necessary autonomy model to do the kind of expressive things that we think need to be done we probably don\u0027t need more but we probably don\u0027t need less and then we walk through a JSON encoding of that so that if you wanted to then build out something that says these are the externally defined data and reports and so on for a BP agent or B piece a cajun we now have a J\u0027s coding for doing that which is what the ADM document lays out and the overall operational concept here again which is not tremendously different from a workflow perspective than what Restaurant network management does is to say we have a management model and this is our autonomy model and we have a template for representing that in a standard way so that you can build code generators and and verifiers and so on and that individual to applications and protocols you would populate those templates per and then that along with network specific dynamic configuration can comprises the overall state of management information in your network so for a few examples to this and about eight or nine of the documents that were proposed were looking at the Bumba protocol VP sex some of the I and administration utilities an LTP and coming back and saying if we look at what has previously been published on how to manage those things or in some cases creating that set for the first time this is what it would look like syntactically expressed in Jason in this template so that we could Co generate it and use it for management so we have a relatively familiar and not very our opinion very verbose expressions for things like externally defined data there are some bits of syntactic sugar in the system where you can parameterize externally defined data and give you an a sense of associative arrays which are things that are missing sometimes ruefully missing from network management systems we have today we have examples of defining tables and we have examples of specifying controls and for example if we look through the I and administrating I on administrative utilities we were able to generate an ADM JSON file for each of those in just a few hours and then auto generate the code to do that in an ion and what that sort of rolls up to is once you have a model and a con op and a JSON template and the ability to express these things with certain bits of useful syntax then generating software to do this management and to run the autonomy engines can actually be reasonably straightforward so there are there\u0027s there is one and a second one coming reference implementation of the a MP which is the asynchronous management protocol which is a binary see boring "
  },
  {
    "startTime": "01:40:10",
    "text": "coding of how to exchange these models than how to implement the autonomy on the agent side and and that work is happening there\u0027s some other work to create a Wireshark plugin for a MP that was done to a MP version o3 which was a hand coded binary and that\u0027s being updated I imagine over the next three to six months to update to the new C Boer encoding and then there are some Python scripts that we wrote just to show how you could take in these JSON files and then auto generate for example C code that does most of the implementation particularly it could generate function prototypes and the calls for the functions and someone if they were inclined could then go in and just implement the small bits here which are if you need to sample a base of external data this is how you sample the piece of external data or you need to call the function here is the body of the function that you would call but really everything else the autonomy the generation of the reports and tables and the calculation of variables and the time and state base evaluations you would get for free in these cases so that is where we are in terms of the network management piece again just to come back to this document for a moment the AMA we claim is a is a useful way of describing how asynchronous management works and why we need it in a DTM and then the templates and the protocols we just have as internet drafts to capture the reasoning the reference implementations the performance measurements as we go off and and do the kind of reference implementations that we need to make sure that we have the specifications correct that\u0027s what I have mark ear as you probably know we don\u0027t have that recurrent charter doesn\u0027t you know doesn\u0027t have any real management milestone except you know collecting requirements I think Michael Chow was trying to be to find home or you know directions from Oprah upper layer of the management ear the the people the ITF management or what to do with this work and we actually sent an email to the IG trying to find that answer hopefully some if the doctrine being we continue here therefore that would require a charter change or somewhere else or you know we\u0027re looking for guidance on on this so I guess news later wrong in felt what was the reaction when this was presented in the whole tour of seen was "
  },
  {
    "startTime": "01:43:11",
    "text": "where any feedback yeah I mean I\u0027ll let ed answer if he wants to but we received positive feedback I mean people were interested in it whether they were interested in it because it was cool and what to do with space or whether they actually had some interest because it sold some use cases was harder to judge following from what Mark was saying I mean I with Ed\u0027s assistants we\u0027ve been sort of wandering around as many of the ops area and the network management groups to see what overlap there is what advice and so on they can bring their is intellectual interest but people are busy doing what they\u0027re doing in ops which is why we\u0027ve gone back to the 80s and said in our opinion this work has broader reach than just DTN I personally think and this is hat off I personally think tienes is the right anchor working group for the moment and we should probably look at revising the Charter because I believe the Charter says we should look at network management use cases not go as far as architectures and further on into it but I think the expertise is currently in this room so why not keep the work in this room but I see huge benefit in reaching out to the wider ops area and saying come and help us do this right because you have experienced not directly in in this use case but been network management and Yang and all that kind of stuff there\u0027s what I what I would push strongly back and it knows this is the the little snippets you saw in the in the presentation there about the EVPs and defining it at the various atomic items that are available there are something like eight and a half thousand yang models out there which handled the vast majority of terrestrial equipments and if I with my corporate hat on I\u0027m interested in using this not in a space environment but as in the terrestrial environment and I don\u0027t think it\u0027s a good time for this working group to spend coming up with parallel specifications to all those eight and a half thousand yang models so we need to work out how we can reuse that work in a way that works for us and isn\u0027t entirely disruptive so there\u0027s a lot of politics and a lot of communication that needs to happen but we are trying to do it and but for now I personally believe we should anchor this in this working group and not try and shove it elsewhere because I think the people involved will just have to change seats and go and sit in another working group so so this is ed brain at this microphone so the I I would agree with that Rick and I have gone and talked to a couple of people from ops areas in a few ways absolutely there\u0027s a lot of existing work in Yang and Netcom right now and one of the issues that we have found is that there is a difference between how some of that static data is represented and can be "
  },
  {
    "startTime": "01:46:13",
    "text": "mechanically translated back and forth between representations and the actual state models and protocols for what you do with it and how you up and and the difficulty that is happening right now in in the ops areas right yes is that that static representation which has the bits that are reusable for us are tightly coupled with the workflows and the protocols which do not work in the DTN scenarios and what we have found is there are others with different non DTN use cases that also can\u0027t run net count for a particular reason or want to run yang over G RPC or yang over something else and we\u0027re trying and there is some general groundswell but this is breaking new ground and none of that goes to autonomy which is simply to say there are static parts of the autonomy model and dynamic parts of the autonomy model and if we have a data modeling language to use them that is good but we still fall back on something that\u0027s specifically a DTN type use case which is and this is the autonomy model for nodes to follow when they don\u0027t have a connection back so when we look at anima and some of the other working groups they start with here\u0027s our flooding message here\u0027s our synchronization message here is our discovery message and the amount of exchange that we go to learn about each other and that could be fine in some circumstances but not in others and so we run into those walls in terms of understanding and agreeing on the problem space so that\u0027s a lot of comments but but generally data model versus CONOPS and and trying to keep some of it in here while we get other review may be helpful because I think we in the room understand the problem space as a counter-argument to keeping it that\u0027s not a counter argument if we keep it in this working group we still have to get BP this.gc PCL and probably be p6 slightly behind those two done so there this will not be primary work this will have to wait for it it\u0027s like charter update and so on but at least we know the interest is here second point this is still Rick speaking for those on meet echo I was speaking to some of the ops IDs and following on from Ed\u0027s point about yang being a very tightly coupled with net cult despite their best efforts there I started to hear conversations about yang net and about trying to get a design team or buffs together to try and look at where yang has got to over the last 10 years and say okay how do we need to revisit this so there may be some scope for input from us to say we like 80% of what you\u0027re doing but this 20% is though is a no deal for us so there\u0027s an ongoing conversation if you are interested in assisting if you have opinions take to the list come and see ed or myself and and let us know what you think Thanks any other business before we close the meeting just a quick question "
  },
  {
    "startTime": "01:49:21",
    "text": "where are we on your own re Stuttgart who are we on other convergence layers like the experimental norm convergence layer we\u0027re happy to receive the sophistication in documents I\u0027m not sure it\u0027s the right answer you were looking for but Scott burly yeah I know there\u0027s there\u0027s a norm convergence layer prototype implementation for DTM - but anything about a specification for it yeah a Rick Taylor on a similar time get a coffee can I\u0027m sorry I have a prototype convergence layer using HTTP which is unusual reading pointers for the space community but quite fun to think in terms of mobile phones what I wanted to reiterate is TCP CL is not the convergence layer from the IETF it\u0027s it\u0027s the first convergence layer we\u0027re getting through the door so people have convergence layer drafts bring them along absolutely other comments before my co-chair died thank you very much enjoy Quebec "
  }
]