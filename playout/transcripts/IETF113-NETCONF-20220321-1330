[
  {
    "startTime": "00:00:07",
    "text": "can't"
  },
  {
    "startTime": "00:04:32",
    "text": "yes thank you um so ieee uh 802.1 reached out to netconf working group about half a year ago with regards to the keystore draft and in particular some language with regards to promoting or copying private keys from a built-in or system data store to running datastore and just a couple weeks ago rob wilton and myself attended the youngsters meeting on march the 10th which is during the ieee 802.1 plenary and we had a a good discussion i thought it lasted for about 10 minutes or so and which action items that came from that was one first for rob to send a liaison response um with regards to general conformance when dealing with multiple standards or standard spanning multiple sdos there's three items for myself one to ensure the keystore keystore draft adequately indicates what kind of key is being referred to on a case-by-case basis second to amend the keysword draft to indicate that built-in keys should not be clear text and lastly to ensure that"
  },
  {
    "startTime": "00:06:02",
    "text": "the crypto types draft adequately defines what is meant as a hidden key and then lastly mick seaman from ieee would ensure that those draft updates addressed his concerns so the actual impact would be of course the updating of the keystore draft and potentially also the crypto types draft so that's all i wanted to say about this uh but i know that scott mansfield who's part of the ieee group is in the room and maybe would like to say something as well or yes go ahead scott i don't want to bust in line uh rob has something to say first and then i can close off sorry i didn't see the queue order you're right go ahead rob perfect scott did you want to say or add something yes scott mansfield erickson uh also works on liaison and such the uh first off wanted to really uh thank rob and ken for reaching out and trying to get this issue resolved the ietf ieee liaison officer i believe is russ housely so we should include him to make sure that it goes through the right proper channels if you need any help from me since it is an 802.1 specific thing i can also help with the wording or help get it to the right people but other than that it was a great discussion the next youngsters"
  },
  {
    "startTime": "00:08:01",
    "text": "meeting for those that care will be on the 29th of march so if you if there's any follow-up or questions please feel free to join that meeting thank you"
  },
  {
    "startTime": "00:10:36",
    "text": "uh scots in the queue go ahead scott hi it's uh maybe it's just me because i am remote but mahesh you sound it sounds like he's underwater or something i don't know if i just need to turn up my volume but i have no trouble hearing kent or rob or anyone else so just wanted to raise that thanks yes it is better when you face the microphone okay all right um i'm going to revoke yours oh you did it yourself fine let me start sharing the next slides okay so my name is kent i'm presenting the client service suite of drafts um this has been a long project for the working group and we're almost to the to the end of it this is actually the first time that the client service we draft has been presented since itf 110 though they were touched on as chair slides amendment or you know notes during the chair slides in previous ietf sessions so uh on this time i'll just do a little bit recap going back to 110 it's not much actually because we've just been doing uh fit and finish for the most"
  },
  {
    "startTime": "00:12:00",
    "text": "part um but for the crypto types draft we did accommodate some sector review comments from valerie simslove and we added the hidden keys feature uh i mean so the hidden concept of hidden keys existed before just the the feature statement hidden keys didn't exist before in the trust anchors draft we added prefixes to the path statements on a per trust anchor issue regarding that issue and we renamed the trustor supported uh feature to central trustor supported that was from jurgen i believe we removed two unnecessary slash unwanted min element 1 statements and added a present statement and we added an informative reference to the mos netmod with system draft so with regards to built-in keys at the time that we wrote the text for built-in keys and trust anchors we only had operational data store but now there's this introduction of a system data store so those things could show up there as well and so an informative reference made sense for the keystore draft we also the same note about adding prefixes to path statements and again we renamed the feature from keystore supported to central keystore supported and we added feature statements for asymmetric keys and symmetric keys and lastly an informative reference to the with system draft you'll notice that on the right hand side it does mention that the key store is the liaison we just discussed and so next slide we have a tcp client server draft we removed the tcp connection grouping grouping um and so now we just use the tcp common grouping directly that was actually done quite a while that was back in the 110 time frame it was done a while ago we added a securities consideration section for the local"
  },
  {
    "startTime": "00:14:01",
    "text": "binding supported feature and then for ssh client server draft we removed the supported authentication methods from the client authentication grouping and we moved algorithms away from the ietf ssh common module to a more general iana maintain modules and this is kind of a big thing we also did it in the tls client server draft but essentially the same update where we're going to the iana maintained registries for algorithms once for ssh and then separately again for tls and converting those registries into yang modules that can be henceforth maintained by ayanna so that's what that item there is we also added a config false list for the algorithm supported so while they're in iana registry defines hundreds of algorithms a particular server may only support a subset of them so this config false list enables them to identify the server to identify which subset they support and we also added to be discussed in this slide presentation a generate public key rpc and so we'll be discussing that in a moment for the tls client server draft we again moved algorithms and we have now the iana maintained modules and again we added a config false list for the algorithm supported by the server and then lastly we made a major update to this draft and specifically to the yang modules to support tos 1 3 mostly in reaction to comments made by tom patch over of course the last year with regards to how tls one three was quite different and uh shortly uh we'll be presenting that as well"
  },
  {
    "startTime": "00:16:01",
    "text": "so moving on uh there were really no updates to the http client server draft in these past a year just nits in the netconf client server draft we did augment in a mapping required flag into the client identity mappings only for the ssh transport and so just locking things down making the the validation more correct and then lastly we removed appendix a which was having before fully expanded tree diagrams but those tree diagrams were enormous i mean literally the tree diagram itself spanned uh five pages i think and so we just removed those foliage and once they fully expanded i mean all the groups have been expanded so the uses statements have been expanded uh so now only both the netcomp server netconf and rescon client server drafts have just the unexpanded uh where the grouping are displayed as users and that's what so those are the updates of sense 110. i did mention a couple items that we're going to circle back on the first is this generate public key rpc which is an open issue and i'm hoping to get some discussion uh so about three years ago folks may remember that the crypto types draft attempted to define actions for generating private keys and after much discussion we abandoned these action statements when it became not possible to define a set of algorithm identifiers that span protocol stacks so for instance ssh and tls each of these protocols are their own crypto silos if you will having their own iana maintained registries and trying to get the security directorate or area to unify to come with a unified set of algorithm identifiers that spanned these protocols proved difficult to say the least"
  },
  {
    "startTime": "00:18:02",
    "text": "so we did abandon that idea about three years ago but uh since then um as mentioned earlier both the client the ssh client server and tl's client server drafts now have their own iana maintained algorithm identifiers that are being pulled from iana maintained registries and so it becomes possible again to maybe define an rpc but this time make it be protocol-specific rpcs in each draft so i've already made this update to the ssh draft which i'll on the next slide i'll show and the slide after is regarding the tls draft which is where the discussion comes into play so for the ssh draft you can see it's just an rpc it's very straightforward their input but notice that the algorithm at the very top on the right hand side in yellow it's a it's an algorithm identifier identity reference so that is a reference to and you can see it ssh of course is the protocol ssh pka stands for public key algorithm so in ssh there's four different kinds of algorithm identities based classes pka is one of the four and is the only one that really matters when it comes to generating private keys so it's a reference to that public key identifier as basically what is the kind of algorithm or what kind of key do you want to generate there is a bit so how long of a key and then and then there's a little bit of how do you want to be encoded do you want the key to be returned as clear text or should it be encrypted by another key or would you like in fact the system to hide the key like it becomes a built-in key not ever visible to the outside outside the server and the response is effectively exactly the same as what you'd find inside keystore but in the form of output for rpc response so the format of the key how's it been encoded"
  },
  {
    "startTime": "00:20:03",
    "text": "and then of course if it's different kinds of key if it's clear text you just get the key if it's hidden then it's just an empty you don't really get the key it just says it's empty and if it's encrypted you get back the encrypted data but also a reference to the other key that it was encrypted by so that's all very straightforward and it's easy i mean doing this rpc took me no more than 45 minutes probably to put together very straightforward then i moved on to tls to try to do the same there and discovered some complication the issue is that with tls there's only one registry and that registry defines what's called cipher suites so these cipher suites are you know they're not standalone private key algorithm like ssh it's it's more of a combination of a private key algorithm an encryption algorithm blocking padding and so an example would be for instance tls-rsa-with aes1256 cbc sha-256 so you can just see how many different algorithms have been encoded in there but the main thing is rsa so this is in fact an rsa key and if you were to ask the system to generate a key for that cypher suite it would be expected that the system could say oh what you want me to do is inherit an rsa key anyway but it's a little bit it's not perfect right it's not like with ssh so the question and and again i'm hoping for some discussion is should we move forward should we continue and and and define this rpc passing in a cipher suite algorithm uh assuming that the server can identify which private key and generate the appropriate key from there or should we just back out of i mean i'm kind of adding in this generating a private key at the last uh at the last hour um again it was removed about three years ago at that time it was uh author's preference and i thought i decided i prefer not to move forward with it is kind of what i was thinking at that time but now it's been it's so easy because"
  },
  {
    "startTime": "00:22:00",
    "text": "the iron had defined registry so i'm willing to give it another small go if people um can help me get past this one issue any comments on this yes joe's on thecube go ahead joe yes it's gener yeah okay well it's generating the private key but in doing so it also generates the public key and in the key store itself it stores both uh and since this was a mimic of what is stored in the key store then also the output the contains both the public key and the private key but the main thing that's coming back is the private key um possibly i i the actual name of this rpc generate public key i think i stole from open ssh and uh it mimicked their language and remember mean i mentioned the ssh has four different kinds of key elements sorry algorithm identifiers so this is the public key algorithm it's actually called quote public key so um i was trying to leverage that but you make a good point we don't have to necessarily we would just say generate key pair asymmetric keypair that would be an option yes"
  },
  {
    "startTime": "00:24:03",
    "text": "okay anyone else any other comments are crypto experts in the room well how about this is anyone feel like we should not pursue this again is sort of being added should we just close down the idea of i mean it's best practice for a server to generate private key okay okay thank you we can confirm with the tls chairs as well okay moving forward thank you everyone for those comments um i'm going to transition now to slides for the update to the tls and um i have a co-presenter jeff hartley who's joining me and uh jeff yeah perfect i see he's joined the microphone queue and so jeff i'm going to let actually if you'd like i'm going to pass slide control to you which you now have if you hit your right left mouse button you should be able to increment the slides"
  },
  {
    "startTime": "00:26:00",
    "text": "gotcha just checking the audio there i see the graph showing up in the interface just want to make sure it's audible over the session you sound perfect to me okay so just a quick summary try not to take too much time here um some feedback had arrived via previous chatter parts by joining the team uh think of me as an informal liaison from bbf we have a lot of client server type applications that we're looking at uh rolling out in the next year or two in some of our own standards and uh having a standards-based framework for integrating those would be perfect things like grpc kafka https transport things like that so some of the chatter that had been active at the time that uh i threw some time over the wall here was that uh tls one two and tls one three's usage of the term psk uh are vastly different and that proved to be the case so in the uh original specifications there of course was already a psk in place uh and it sort of had the assumptions of tls 1.2 and going before that so it was quickly deemed necessary to split that out designate which one was one two which one was one three in fact this notion of an external psk is prevalent throughout the tls 1.3 rfc so in fact i would dare say it's not really a tls v 1.3 psk it's a tlsv 1.3 epsk one noteworthy change uh is this notion of zero round trip time as they call it and it's that the entire handshake once the client has authenticated itself and the server's accepted that and they they effectively agree upon the parameters embedded in the external psk"
  },
  {
    "startTime": "00:28:01",
    "text": "they can immediately start sending data the server can immediately start fulfilling requests and while that's a gross oversimplification of the full description which you can of course find in one three it it really did need some attention and call out here so the the action items as described uh just split 1.2 and 1.3 psks apart from each other uh a few additional identities and features of course so we could use a feature statements uh to just apply some constraints to them but uh nothing too earth-shattering beyond that uh hopefully the font is legible but i i kept only sort of the the main body you can see the full text of these drafts uh via kent's github and that sort of thing so all the all the descriptions and references i assure you are there uh in fact a couple of the uh the notes are are pretty handy reading i would say so in the case of the tls one two psk that was the original structure it really is unchanged it's just renamed uh the the original psk there and you'll notice that you're going to see the the concept of identity hints and things like that which don't exist in one three when we get into the one three e p s k right and again the those of us who are our sticklers for syntax and notice that the e p s k is different than the psk above it i assure you that's consistent with the rfcs and it helps really point out the difference that there's no parity between these things and how they're used um the uh the actual cryptography underneath it was was really not the the big challenge here in order in other words we could still reuse this notion of keystore as canton companies draft cesari had already defined it so that part wasn't so bad but you're going to notice that there's some leaves in here that are dissimilar to what had come before"
  },
  {
    "startTime": "00:30:01",
    "text": "the actual hash itself you can see right there there's a new type for that like what hash algorithm you're going to use there's a limit of exactly two that are currently defined uh that being an identity could be extended pretty easily in the future should tls13 add additional types of hashes supported and a lot of this is sort of context specific there's the the actual leaf for context uh target protocol for example if you had say an https client right or if you had some other form of client that is effectively manipulating this then that information can be populated uh and the key derivation function is another mandatory piece in here again the descriptive text had to be trimmed to fit on the slides but uh but this is the structure of what was added and differentiated from the tls12 and prior psks the server of course when we're looking at the client the server is is the inverse of the clients and it simply specifies hey which of these if features are you going to support when you're talking to a particular server if you look at the server it's of course the inverse of the client the exact same structures right with uh opposite positioning so the tls server grouping contains the case statements that we're just speaking of and the container specifying what client altercation authentication it will support in terms of psk's is there and i believe kent did i have the i did i did include the additional uh identities here there was a bit of a nomenclature clean up there we went for the most simplistic structure of just tls12 tls13 that got cleaned up throughout the files and we talked about the new the new type def for epsk supported hashes that's easily extensible i had"
  },
  {
    "startTime": "00:32:01",
    "text": "said identity earlier but uh typedef for that and that's about it the references it's really the same three references in most of the fields we talked about there and you can see those listed here i'll pause here and see if folks want to line up with any questions there might be a couple of folks in on the chat or in the room whose previous comments were directly addressed by this or at least i hope we're directly addressed by this i do not see tom patch on meet echo so if we're waiting for him to respond i don't think we're gonna get that okay well then i'll end my section by just stating that if folks do have time to look at these later and they like to make comments uh i do participate in the netcoff mailer so thanks oh oh i think i killed slides sorry about that um oh hold on no no because we're not supposed to be we're sharing these slides just yet ah okay here we go sorry about that zooming ahead to the end thank you jeff and by the way um jeff was just absolutely awesome we worked together i think over the course of maybe three months and possibly meeting every other week on all this so a really huge contribution thank you jeff last slide for me uh next steps uh we mentioned uh so jeff just talked about updates to the tls we you know we need we should definitely be validating"
  },
  {
    "startTime": "00:34:01",
    "text": "the correctness of these updates um significant uh security you know related update it would be good for sector to take a look at it i do know that that sector takes a look at all drafts as they're being published so perhaps we do it just as a part of the normal ietf publication process or if rob ad would like to have a proactive you know sector review beforehand before doing that we could discuss that as well as mentioned also there's the ieee liaison some minor updates need to be made there and lastly resolving the generatekey rpc action issue that we just discussed and then we're done i i mean amazingly uh working group chairs can publish the entire set to ad at this point in just a few weeks and i'll be noting here we started this work in 2014 so eight years ago this has been a large long effort and uh happy to be near the end and that's it for this presentation thank you oh i do see rob in the queue go ahead rob like you up the next thing i don't actually think otherwise i think it'd be okay to push it you know do as part of the normal process i wha what i would do rob is uh in your write-up just bring note to it so some extra attention is brought to that section just i think it's reasonable to just have people take an extra careful look at the way the tls-13 is supported okay thank you okay and now we're um moving to the next presentation this"
  },
  {
    "startTime": "00:36:01",
    "text": "is udp based uh transport for configured subscriptions yes thank you alex please go ahead oh let me pass you control over the key of the slides as well if i can i'm not able to so uh just tell me when you want to see next slide oh i hear it i can't do it sorry about that okay you can increment your own slides now hit right button left button yes it's working yes thank you um so this is alex wang from instagram and i am presenting today the few changes we did on the dash o5 of udp native draft on the agenda i will explain shortly the div we made on this new draft and we would like to start a discussion on uh how to configure dtls from the young module which we got a little feedback on the mailing list so the few changes during the last ietf we got feedback from rob i think that we should specify the rfcs of the encoding types of json and cyborg because they they they had multiple uh rfcs uh we at the end uh decided uh that instead of just specifying the rfc we could just referencing the media type instead so the registry would reference directly to the already standardized"
  },
  {
    "startTime": "00:38:01",
    "text": "of the jana media types after that we modified a little young model the module we added a feature in code seabord leaf in the young module and then also change all the encoding type references to be aligned with the whole draft um we also uh have been talking with the chairs uh for the dtls encryption part of this draft we got feedback that it should be [Music] it should make it good for the security review having the dtls part in in this draft and then lastly uh some days ago i would say uh that we got some feedback uh that if we uh would add the dtls part in the young module to be configured configurable from the router directly so we would like to start actually a discussion on this meeting that if it is something that it is expected for for from the community i would guess yes but and then if just importing the i we saw that in the draft net conf tls client server there are some young modules implemented and if just importing them it's it would be enough or"
  },
  {
    "startTime": "00:40:00",
    "text": "but what starting the discussion on on this meeting and [Music] i would say that would be all uh just uh a quick quick presentation too about the distributed native draft we changed a little so we we did some minor changes on the young model and we also uh think that uh the draft is already pretty stable and that we would like to last called when when this udp notifies last called so that would that would be from from my part and we we could start this discussion so can't thank you um sorry so yes it is a good idea to modify the configuration model so that the actual tls part of dtls can be configured i mean so we're asking the server to in some cases initiate the outbound tls connection to a remote tls server and you know how does it authenticate that server certificate does it need to authenticate itself to the server uh you know where is the configuration for these things uh specified it is uh necessary it's not it cannot i don't believe be just a flag like dtls is on and there's a configuration that has to be specified and i think that's the request so uh yes exactly what it would come down to is the yang module that is in this draft would import the tls uh client"
  },
  {
    "startTime": "00:42:01",
    "text": "um module and maybe also the tls server module if it turns out that it needs to actually listen to uh connections as well and then um that should be most of it you would want to also add examples that illustrate those configurations being uh set and i think that's the ask does it make sense yeah i think so yes okay thank you so um sorry can you repeat the last question i did not get oh yes this"
  },
  {
    "startTime": "00:44:01",
    "text": "yeah the subscription id maybe yes maybe thomas or pf could touch or that says okay is it now better okay so the domain subscription id is basically the identifier which identifies the export process on the router if more than one process is there and this is needed for the segmentation so in a nutshell that's what distributed native is and sits its uh transport agnostic we need to describe that in a separate draft okay which is uh basically where we can implement that it is not implemented in the https but for future drafts that's"
  },
  {
    "startTime": "00:46:03",
    "text": "and this concept is not something which is coming from that country this is actually also being applied the same way in ipv6 sure [Music] should we move on to the next presentation now okay and um mash why don't you uh or just i mean let people okay with there's a small agenda bashing while we were uh between slides here and we've moved the adaptive subscription presentation to the end everything else will be the same so next is per node capabilities for optimal data collection i think benoit is in the room we'll be presenting perfect"
  },
  {
    "startTime": "00:56:56",
    "text": "yeah there's a couple on the queue yeah maybe tim you want to go first hello yep hear you good uh so i will say uh meanwhile that um we have seen in the past uh similar uh problems that you're that you're um talking about with like the mibo id uh but actually for other protocols as well like for uh ipfix for example the the ie number there that would be assigned to the node so um you know we do see some usefulness for for those features to be able to have the source correlate it back with other uh identifiers for other protocols um but when you do that if you could if we could somehow make that kind of a list uh and allow for you know um you know the the identities uh to be done for uh for for you know one or more types of things you can do"
  },
  {
    "startTime": "00:58:01",
    "text": "you know ipfix or snmp or both right you know where you're giving annoyed or or the ip fixed number for for whatever purposes that the system needs yeah but it's for the same the same problem right that you're trying to do in it yeah yeah so i think we if we can address that i know that there's needs in the market for that"
  },
  {
    "startTime": "01:02:22",
    "text": "charles is next in queue all right thank you charles and joe's in the queue next question joe yes um"
  },
  {
    "startTime": "01:04:29",
    "text": "um"
  },
  {
    "startTime": "01:06:46",
    "text": "actually just quickly before blood starts speaking uh that was uh diego lopez who was at the mic just last time he didn't introduce himself so yeah go ahead blush do you hear me yes okay so besides oh ids and ipfix references we also deal with 3gbp management systems using distinguished names so that could be another reference that would be very good map to yank sometimes thank you all right next presentation will be the um transaction id jan lim blood let me get the slides cued up"
  },
  {
    "startTime": "01:08:00",
    "text": "and yawn i'm gonna make you the uh controller so left right mouse button should do it for you go ahead thank you so this is a update what's going on with the transaction id that some of you may have followed earlier so i wanted to go do a quick problem and solution recap and then talk about the simulated results that we have since earlier and then mentioned a few words about what's in the works right now so this work is trying to address three problems one is the get config it's a slow and costly operation and if you want to use it for change detection on the server if it's clients wants to know if the server has changed this is an expensive way to do that so you do get config and you get a response and then you do get copy clear and check get a response and see if it looks the same but it's consuming both cpu on both sides and a lot of network bandwidth to find out that nothing happened uh the second problem is with jan kush so if a client is subscribing to updates on some parts of the server configuration and then getting updates after that when something happens in the server that's of course great but what happens is that if the client is configuring the server he will get updates about his own change as well and kind of unnecessary and it takes a lot of computations to figure out oh actually this i i already knew this because i said it so if there was a way to identify those updates as being well what you already know that would be good and the third thing uh well actually more more than cpu consumption and the network bandwidth consumption a problem is uh that's important for in many cases is that we want to detect"
  },
  {
    "startTime": "01:10:01",
    "text": "when multiple clients are making changes uh at the same time and to the same server so that if they are clobbering each other they would want to know and the the current method of using getconfig is both costly and it has a hole right you can do a getconfig but before you are able to send the editconfig as follows to make your change there's a window of vulnerability if somebody else is doing an edit config in that window you would still be clobbering uh you can of course take the lock but since getconfig can take several minutes you don't want to take locks that are so so prolonged so a lot of people have talked about yeah let's introduce a sort of simplistic top level transaction id where every server keeps track of for example the timestamp when it was last changed or some sort of global number at the top that reflects the contents so that didn't get comfy you can ask what's your transaction id and when you get the content forget config you'll also get that number like 4 7 11. many servers have implemented this already but not in a standard way but in each vendor in a proprietary way and then that could reduce the amount of traffic in cpu considerably for some use cases but what we have found is that many of the use cases that are interesting are not like that you would actually have more applications more clients that are interested in certain subparts of the configuration of servers let's say we have a vpn client a security client and an underlay client that care mostly about different parts of the config of the server and if you all you get is this top level etag number 471 there and the changes these clients they don't know if something that affects them or they"
  },
  {
    "startTime": "01:12:00",
    "text": "care about has changed or not and in many cases that e-tag number is changing so frequently because of changes that are going on on this device that there's no point in trying to track that at all so we have found that many of our customers are turning off that feature even for the devices that support this top level thing so that's why we think a transaction id or e-tag mechanism that goes deeper into the tree is very valuable so that you can synchronize the part of the configuration or track changes to the partial configuration that your that you actually care about and the the draft is also talking about the edit conflict mechanism that is lock free and uh detects clobbering without any sort of vulnerable wind vulnerability windows so this is something that you might have already known because we talked about it before is nothing new here but just to remind you what we are talking about here in order to measure what we what this draft would give you we did a measurement on a real world application that was running in one of our labs for an hour uh and this application was then doing a lot of management of devices in the network and it was uh doing 569 round trips that means get configs and edit configs and all sorts of messages that they were sending to the server and it was sending about one megabyte of net conf traffic during that time but if we implemented the sort of mechanism that we talked about in this draft those 569 would go down to 378 round trips so about one third would be gone and that of course removes both network load and delay in applications because round trips take a lot of time and reducing the amount of traffic from one megabyte to just a little bit more than"
  },
  {
    "startTime": "01:14:00",
    "text": "a half megabyte which again reduces network load and processing time on both sides and this is now then a mechanism that doesn't require any sort of locking and it removes this window of vulnerability so if you think this is interesting we can continue working on this together to look at how we implement things and there are a few open questions in this work the thing that we are looking at right now is to uh add text for how yang push should integrate into this it's uh something that is not mentioned in the current dash one version at all and we are looking at in-house doing prototype implementations of this just to verify this with a broader class of use cases than this simulation that we did that's all i had to say any comments or questions that could be a good idea yeah if you can arrange that please mahesh before the poll maybe some questions at least i have a question um jan okay great um jan so um i i'm highly supportive of this work but first can you just clarify you didn't use the word rest conf in your presentation but this by and large in my mind is um enabling that conf to have feature parody with rescue at least in terms of uh the e-tag and maybe also the modification time on a uh you know within the tree uh deep in the tree um is it is that a fair characterization it's a as a effectively enabling that contact feature parity to rest conf in that regard yes and if you read the the draft you will actually see rest confirmation in"
  },
  {
    "startTime": "01:16:01",
    "text": "there and exactly how it would work and it is i would definitely say it's feature parody but it also goes beyond that yeah and that's that's that's uh going beyond is also applicable to rest conf okay and then my second question is uh your first bullet point in this slide you talk about integration to yang push it doesn't even occur to me what can you just say a few words more about what is the uh nature of that integration that might be needed yeah i mean we have this uh let's see i can actually go back here in the slides you know i have this pole in front of me so i can't really see the slide very well but okay so when you subscribe to uh configuration updates using young push for a part of the tree that you're interested in whatever you the client itself is pushing to that part of the tree will be echoed back to him but it's uh difficult to understand if this is another update from some other transaction that happened on this server or if it is my own thing since there's there's no way of knowing you have to actually parse this whole thing and see yeah actually it matches exactly what i already had so i can throw it away yeah this may be an echo of your problem number one i forget if it was or not but you mentioned uh the server getting back a notification for something that it had already it knows it did it so why would it need to get a notification for it um and as you were saying that i was thinking to myself that maybe it's not so bad i mean if i in if if the bandwidth and you know processing isn't huge it's still probably valuable to have a record of the thing having occurred and so in that regard i probably would say it's not a big deal so if it's the same issue then maybe it's not a big deal i think that actually if you look into how we could do this with the transaction id you could do exactly that but much more efficient than getting the full data back and having to process it and compare and all"
  },
  {
    "startTime": "01:18:01",
    "text": "that so getting the the update is great but if you have the young push mechanism integrated with transaction ids you could do that okay thank you that was just and that was and again this is kent as a contributor thank you that's it for me i think those numbers are quite impressive oh i see them now okay very good so i think we can move into an adoption call shortly excellent thank you any other comments or questions thank you changing the order just a little bit so next is going to be uh jamming as i understand it this draft actually pretend presents the use cases for the adaptive subscription uh presentation which is after this one is xiaomin here"
  },
  {
    "startTime": "01:20:00",
    "text": "who's presenting this um i think i can't represent him to present this work i didn't get that was that yes or no no sorry i can't really represent him okay it's fine um all right well then i guess we'll just skip this presentation if he's no one's here to present it so we will kill these slides i shouldn't use that word but bring out the next slides adaptive subscription uh yeah i i think i can drive this slide okay i'll pass the control to you as soon as they come up okay there you go thank you thanks so uh [Music] okay on behalf the authors and contributors i would like to give a presentation about the adaptive subscription to young notification so for people who are not familiar with this work um usually a high frequency debt collection leads to more resource consumption while low frequency debt collection is insufficient for for photonucleation and people sometimes may find it hard to balance the need between expensive data management cost and better fidelity for troubleshooting so"
  },
  {
    "startTime": "01:22:01",
    "text": "this is exactly what we want to do and our main idea is to install the adaptive subscription policy which is built on top of young push mechanism and allow the servers to switch to different update intervals based on the network condition chains so about the document status this work was first proposed about two years ago and we have received a lot of comments over the past two years about two months ago the working group adoption call was initiated and we have received different opinions i think we got a lot of support and also received concerns and objections from andy and the poor and some of the objections are about the problem statement while others is about the evaluation of the x-path expression like the usage of the watermark evaluation of expat external evaluation etc so the authors investigate these concerns very carefully and update the draft accordingly which includes the the following chance like we have defined new rpc errors in last itf meeting i think it's rob rob has suggested us to define a new rpc error to report when a server cannot pass the expat syntax defined in the x path evaluation expression which is more complicated than it can handle and andy asked us what if multiple expats criteria conflict so we have defined three rpc errors so far to show adaptive subscription unsupported and exposed syntax defined in the x-pass external evaluation unsupported"
  },
  {
    "startTime": "01:24:01",
    "text": "and the multiple expat criteria conflict respectively and we admit that the watermark leaf defined in the module is confusing so we have removed this parameter and there are also some other questions asked by andy like how to evaluate the x-path expression how to compare a targeted data object in a specific list entry uh how often does the server check if the period should change clarifications in the updated draft has been met and i will also explain some of the later in my slide and another progress we have met is that we have proposed a hacksaw project in this itf meeting to provide some implementation results we monitor the kpi chains at different frequencies of data collection and also evaluated the performance of adaptive subscription so i i will introduce the hacksaw project briefly and then clarify the open issues so this is about the our hacksaw text environment setup we use the jrpc based telemetry to collect data from different access points the network devices in our campus and we have evaluated the following different data collection methods uh high frequency periodic telometry a low frequency periodic telometry and an adaptive frequency telemetry and for each debt collection method two cases are evaluated one is to report the rssi values so as to detect the real time whether roaming events across different aps and the other is to stream the bytes sent from the ap uplink so as to detect the potential congestion"
  },
  {
    "startTime": "01:26:00",
    "text": "and we also use the elk to collect analyze filter and visualize the data so in in this case uh we tried to we have collected and aggregated the rssi signal data from different aps and the usually the issi is a measurement of how well the terminal devices can receive a signal from an ap or a router so usually the default roaming rssi thread hold is the negative 65 and if the actual signal stress is length is less than the threshold the then the terminal devices will search another ap to attempt roaming so in this case we try to figure out when a with a roaming event happens during the movement of the terminal devices and also identify try to identify continuous signal degeneration so we tried different methods to collect the same metric and the results show that a very high frequency debt collection at a two second interval is easy to identify when a roaming event happens and signal degeneration but also but it also at the cost app at the cost of a greater volume of data and unsurprisingly a low frequency collection at the 13 second interval can greatly reduce the data volume but it's hard to detect the important events and data and we also tried adaptive subscription which is on the right side of the slide if the rssi value is less than the negative 65 we set the period to be every 2 seconds otherwise switch to 13 seconds at the interval so since the condition can also be evaluated at the subscriber side the"
  },
  {
    "startTime": "01:28:01",
    "text": "subscriber evaluated the received rssi value and manage the decision whether it needs to modify the period so while our proposal is to configure the adaptive policy into the server and allow the server to switch to different intervals automatically so we have compared these two different ways and the results show that for the first way for the condition evaluated by the subscriber uh the low frequency at a 30 second interval debt collection prevents the subscriber from capturing roaming events which lasts only two to four seconds because the subscriber can only use the data collected every 13 seconds as the input of the condition evaluation and it will realize to increase the frequency only when it happens to receive or as as i value which is less than the threshold but for the the second adaptive way the server will evaluate the condition at the end of each high frequency interval which is two seconds in this case so it will check whether it needs to switch to another frequency every two seconds even it's during the low frequency streaming now so any there is no no important events and the data will be missed in our proposed way another case we have tried is to stream the bytes sent from the ap uplink so as to detect the possible uplink congestion and similarly adaptive frequency debt collection is able to capture as many traffic but as possible while when the monitored operational data is normal the frequency can also be decreased the the light chart at the bottom right side of the slide we can see that the adaptive subscription can greatly reduce"
  },
  {
    "startTime": "01:30:01",
    "text": "the amount of transmitted data compared with high frequency debt collection so this is about the the hacksaw projects and regarding the issues clarification i i think that the very first one is that um young push supports the adaptive subscription already uh yes i think it's true it's true that the subscriber can monitor the targeted that object change and modify the period for an existing subscription but we think that it takes time and resources for the subscriber to to analyze the network status and send the modification request and it also takes time and resources for the server to receive the modification and react to it and sending modification requests to switch to from the low frequency to high frequency streaming cannot capture all important events and data due to the low frequency debt collection interval as i showed in the rssi signal use case use case with when it is low in low frequency debt collection the subscriber can only use the debt collected every 13 seconds as the basis input for the condition evaluation and such a time interval is very likely to cause the loss of important data and also the third point is that when tens of thousands network devices need need to be managed the frequent frequent modifications are prone to errors then people may ask about uh how about the proposed server driven method how often does the server check if the period should change um i think it sounds more like an implementation decision because the more from the condition evaluations are performed the faster the server can"
  },
  {
    "startTime": "01:32:02",
    "text": "react to the network condition change but it's recommended that it's recommended to be at the end of each high frequency streaming update period and which means that the data is reported at a high frequency only when the network suffers but the server should periodically detect the condition change at this high frequency even it's reporting data to the collector in a low low frequency currently and this to reduce the frequency of the evaluation the server can also choose to check the targeted object change at every multiple update periods so that's also fine i think okay then it's about the and another issue is about the expat instance information uh yes it's it we think that the the question how to select no more than when entry if there are at least an instance to handle we think that xpath itself can be used to identify a particular instance and it's true that there may be a desire to select an object inside a list and but the the expats itself supposed to identify a particular instance inside a list already which is defined as a abbreviated syntax in xpath1.0 w3c specification so we don't really think this is a problem and the last issue is still about the expat capability the problem statement seems to be limited to absolute values of specific leaf or leaf list and usually at least a rate is needed"
  },
  {
    "startTime": "01:34:00",
    "text": "well in maybe in itf 111 i can't really really remember it but maybe there is there used to be a concern about arbitrary xpath complexity so we think in order to reduce the complexity we have recommended the implementers to use the comparison of the specific that object value and the threshold but for the server with more powerful capabilities to handle a complex expat syntax we think that it's okay to use the mathematic operations in the expression so it so i think the x path syntax supports it to use a red we did not really limit that capability but our current focus on the smart field cases which means like the monitor data object exists a specific threshold it this is the recommended way but we do not really limit that capability okay so any comments and the questions about this yeah go ahead and job"
  },
  {
    "startTime": "01:36:58",
    "text": "okay well for your your first question um i think i have the slide to yeah for the adaptive subscription the condition can evaluated at the subscriber side and also at the server side and if we want to leave the complexity with the subscriber then we is maybe we have some issues to collect the enough data to identify the important events and and data and and for the the second where the adaptive subscription evaluated the condition at the server side we can collect enough data but yes we did add some complexity to the server we don't really have a uh performance statistics about the network devices load to implement this adaptive subscription but the results show that"
  },
  {
    "startTime": "01:38:00",
    "text": "it's it seems okay because it the server only adds some some if then logical programming codes on the adaptive subscription and there don't really have so much load than we expected and also about the the stream data in this case with the evaluation data is the issi signal data which is defined as a leaf better node in our module in the draft appendix section so the rssi is the the stream data and and it's also the evaluated data so this is the the filtered about the this and i i think that for adaptive subscription uh the rssi signal data streaming to identify the terminal devices roaming events maybe is the most uh solid use case for for for for this draft and i also know that there is another draft for a dedicated discussion about the use case and the problem statement about adaptive subscription but i uh we can we we can see that uh i i think that it seems more like to focus on the data collection the traffic debt collection but our focus is about the the young push mechanism which is to stream data from a particular young data store so but we can see that whether the use cases dropped can fit in some use cases in this in this one we can see that"
  },
  {
    "startTime": "01:40:48",
    "text": "okay thank you i i i will look into that and and try to give some more implementation results about their mission use cases actually my house i'm sorry um i did receive a private chat message from xinwu who says that uh the presenter xiaomin will be presenting or joining uh shortly to present imminently i'm hoping so this may still happen um i don't know how long we should wait okay shin says he's online i know i want to hold off and doing a poll until after we have this other"
  },
  {
    "startTime": "01:42:02",
    "text": "presentation if possible because it may it may answer some questions um but i don't see shin yet i'm probably saying the wrong shell i'm saying hello hello yeah can you hear me i hear you jim yeah this is actually i do see uh online and i did talk with him and he will present is he in the neck conf yes okay i'm gonna cancel this presentation and bring up the next presentation then yes hi we hear you i'm gonna oh i'm going to pass control slide control to you you can increment uh the slides between the red or left right mouse buttons okay let me uh let me introduce the this factor oh problem statement and the use cases of adaptive traffic that con collections um next one let's"
  },
  {
    "startTime": "01:44:03",
    "text": "you should be able to hit your right mouse button or right keyboard button and increment it okay please please turn to the left kg okay i'm going to take back slide control and just tell me when you need to have the slides incremented sorry about that okay next slide go ahead oh okay okay motivation and objective motivation ig curry network leads to providing real-time traffic visibility to have network operates quickly and accurately look at network congestion and impact loss make timeline pass adjustment for deterministic services to avoid congestion as this trend stand assembling it means second intervals will generate generate a constant variable amount of data which might claim too much transport by the way's resource will be load the service for date collection storage storage and elect release objective explore the adaptive traffic data collection mechanism so as to capture real-time network state at meaning minimal resource consumption please next page okay problem statement if network use of"
  },
  {
    "startTime": "01:46:02",
    "text": "traffic-based calculators tickets after a long time operates have obtained obtained traffic vicinity from ms which cannot reflect this kind of base calculations first to observe it observe the evolution network traffic my skills the calculations tickets are for traffic based game direct smt is widely employed to collect network traffic at five minutes intervals second in spite of low links usage such as setting to 14 percent final base utilization mailing billing time plans have still been received about four kilo yielding delivery you know application based there since same sensitivity of the delay and the pack loss large quality of laboratory data and evolutionary date need to care diet and make the best with phenomenal because frequently he operates calorie little workers such as ip brain antimatter measuring quality little work actually backbone little work and in the data centers families of television television indicates we can capture their company tax packages for macro traffic however it is um impractical to gain the real-time traffic visibility at cost of persistence time same thing at milliseconds in the wales please the next page scenarios of effective traffic that"
  },
  {
    "startTime": "01:48:03",
    "text": "use case one dimensional real-time portrait of interface traffic characteristic the real-time traffic visibility can help operate but understand network performance so as to achieve sla guarantees for latest and low and losing sensitive sensitive applications i'm telling the hardship and genuine characteristic of interface traffic is also basic requirement for the statistical multiplexing model of iit network which is of great significance for traffic prediction network planning to work habit capacity expansion and the network optimization and so on it is essential to expand the adaptive traffic data collection techniques to detect not multi dimensional real-time portrait of interface traffic calculations at a minimum resource consumption next page please and this gets to make the best traffic detectors not the best traffic as a intense instantaneous congestion phenomena occurring frequently identical network will cause political detail and impact laws which will stimulate the effect at qe of late 10th century sentence applications the ability of detecting market-based traffic of inter interface where network operates quickly and equally equitably"
  },
  {
    "startTime": "01:50:02",
    "text": "located network fundraising and effective loss and make timely plus adjustment for deterministic delay services in order to avoid the congested load and links triggered by the events such as packet loss cure depends beyond the threshold which is the detective families assembly sector must be timing turning to milliseconds to capture a magnifier of interface the next page please use cases list congestion event for deterministic and their ministry services real-time check visibility is based on the adaptive traffic that collection techniques can accurately predict the long time congestion and quickly capture the instantaneous congestion of inter interface and means of delivery time travel visibility the automatic of optimization tool when java ai can make timely pass adjustment for case type flows the next page please this case four parts can imagine based on adaptive traffic assemblies adaptive approach can be used based on the network condition to analytically adjust the sampling threat in low mail network stated a low sampling rate is enough to develop"
  },
  {
    "startTime": "01:52:00",
    "text": "reflect network performance in case of network congestion timely adjust their practice something reacted at a very high level so as to acquire real-time measurement data such as latency jitter and packed loss the next page please next steps solid state conveys and refine the draft accordingly population will overcome possible implementation the verification as well thank you thank you does anybody have comments no i was saying the same thing that's perfect yes benoit please yes"
  },
  {
    "startTime": "01:54:00",
    "text": "all right thank you um i don't believe there are any other comments so just uh so we did have to take these last two presentations out of order the idea was that this presentation was going to provide the use cases that would help justify the potential adoption of the adaptive subscription draft which was the the previous presentation um but now that we have had this presentation i know uh so it required i know there were some objections that were raised previously on list by andy and also per with regards to [Music] concerns with the adapter's description draft and andy's not online i don't know i think i see per if um if the use case or other um oh yan is joining the queue perfect go ahead and john yes jan please go ahead uh yeah perry is not able to speak at this moment but we are working together so i think it's perhaps better to discuss the details on the list if possible but uh i think many of the concerns we have are still still relevant okay all right thank you uh so i do want to put a show of hands pull to the working group it's on screen now"
  },
  {
    "startTime": "01:56:26",
    "text": "okay i think we've gotten i don't see any new oh one more participant all right i'm gonna end the poll now because it's pretty pretty much good enough um so we did we just got 24 participants in that poll um it's about half half in terms of whether or not the working group should you know continue um looking at adopting this as a proposed standard versus um an experimental message uh sorry experimental um draft and uh so so again this is not an adoption call on either on either front but uh it looks like we'll hold the door open uh longer for the possibility of it being proposed standard i think as jan just mentioned more discussion on list needs to occur to try to resolve the concerns of those that have raised them and i think that's it for for that presentation so thank you very much everyone and also i believe that's the end of the meeting we're at the end of our agenda now lash with three minutes to spare yes thank you everyone for joining the netcaf uh 113 session"
  },
  {
    "startTime": "01:58:00",
    "text": "wish i could be there in person see you in philadelphia right okay marriage true you"
  }
]
