[
  {
    "startTime": "00:00:11",
    "text": "yes ah actually yes oh we should stop now right to their stuff yes let me do this part my automatic good morning that wasn\u0027t me good afternoon I hope you are in the right place this is going to be gripped a forum research group and we have a pretty full agenda so let\u0027s get started so I\u0027m Alexei and Kenny the other co-chair is sitting next to me so I hope you know us we\u0027re going to start blue sheets shortly we have a note-taker thank you let\u0027s do this so I hope you\u0027ve seen note well rules about participation apply to this session so same to ITF and I RTF we have a jabber so people will can relay stuff from jabber right I\u0027ll quickly start with the document status we finally have one more document in our Fe editors queue since last time we also have actually four documents just about to be done so basically Canyon I need to divide them and Shepherd them through the rest of the process and so we have a couple of active documents verifiable random functions will present it next time in Manero a couple of pack documents and we have a new document from both hoffman about transition to post quantum cryptography so as far as this one is concerned we agreed to work on the topic but I think the research group will decide whether this document is going to be published "
  },
  {
    "startTime": "00:03:12",
    "text": "and what exactly will end up with being in a document yeah we also have a couple of expired document but you know to be fair we we have quite a lot of things documents to process anyway so I don\u0027t think this is a big deal so actually I know I should have asked about this earlier any agenda bashing so this is our agenda any requests to move stuff around all right in this case let\u0027s start with all right thank you my name is Karthik Karthikeyan bhargavan and I\u0027m going to be talking about a new initiative called hack spec which stands for high assurance cryptographic software assurance cryptographic specifications for which I need your help so I\u0027m going to describe a little bit of this this is an initiative that came out of a group of researchers who matter the sidelines of the elbe all crypto this year and this is kind of a problem that we identified and we have a proposed solution that you want your help them so most of us will agree that implementing crypto software which meets implementations of crypto primitives crypto constructions correctly is hard ok so if you go look at the last two or three years of OpenSSL series you\u0027ll see about half of them are memory safety bugs like buffer overflows about a quarter or side channel bugs like branching on secrets and about a quarter of functional correctness bugs like carry propagation bugs the thing about these kind of bugs is that they\u0027re low probability which means if you test and test and test the code it\u0027s still unlikely that you might hit the case where this bug might be trigger but an attacker who knows that the bug exists might be able to drive the implementation towards about so testing doesn\u0027t work what works better is formal verification but formal verification requires a lot of effort and expertise so the group came up with this idea that maybe we can try to make the effort required for verifying modern crypto primitives lower the good news is that a whole bunch of research groups are right now be able to use existing research tools to verify fairly sophisticated cryptographic implementations so there are a bunch of tools that will verify see implementations of your primitives including all the ones that you can imagine there\u0027s also a few tools that will verify optimized assembly implementations and these tools have now reached a level of maturity that they\u0027re being included in production software like boarding SSL NSS s2 N and so on actually using formal verification techniques so so the question is well "
  },
  {
    "startTime": "00:06:16",
    "text": "what is the problem the problem is that it takes a lot of effort so how do you how do you actually verify a crypto implementation well the first thing you have to do is to write a specification that captures our desired goals it could be like functional correctness memory safety some specific kinds of side channel resistance that you need even your cryptographic security goals and then we write your implementation and prove that in this implementation meets the spec that you set out first okay so this both of these steps actually require work the if you go look at the various tools that are available right now most of us agree on what the implementation language should be you usually see your assembly but there is a wide variety of specification languages so some people write specifications in general-purpose logical languages like cork and F star other people write it in domain-specific languages like easy crypt and crypto and the reason we write it in these languages is that these languages which see specification languages are particularly geared towards a specific verification method that these tools are using however what it means is that the first step any of us has to do when verifying code is to take the beautiful pseudocode or text written in your other C\u0027s and encode it in the specific very specification language that you have this step is quite error-prone quite painful but actually is needed because this is what we need in order to get the verification tool to work on the other hand the negative is that the resulting spec actually looks quite different from the RSC so it\u0027s difficult to understand what exactly we are proving right so this is the kind of problems that came up and a whole bunch of us met with crypto developers in the series of workshops called hacks which is on the side of real world crypto and the developers essentially said well you guys have lots and lots of proofs but we don\u0027t we don\u0027t understand what you\u0027re proving ok because the proofs are relying on the specification written in some obscure language that we don\u0027t understand and we don\u0027t have the time to learn so this is where the idea for hack spec came from which is the idea that we need a language which can be which has a well understood syntax and semantics that both developers and crypto designers and people are writing specs like the I like the CFR G and so on can understand and read and write as well as can be used as a basis for formal verification so the design goals for hack spec which is a new high assurance crypto specification language are the following you want the specs that we write to be really set synched and readable so that you can actually the people in this room can read and write these specs and that they can be integrated as pseudocode in to RFC\u0027s we want the this X to be executable so they can actually be treated as reference implementations and they will pass test vectors and so on and we actually want them to have a clean syntax and compact formal semantics so we all can understand them and they can be used as a basis for formal verification by a variety of tools ok so that\u0027s the goal that you\u0027re going for so we have a first design it\u0027s a very preliminary design and looking for feedback you\u0027re all looking for feedback on this and we went around and looked at various RFC\u0027s that have been standardized recently and we found that most symmetric crypto Hirsi seem to be "
  },
  {
    "startTime": "00:09:17",
    "text": "using pseudocode + c reference implementations but anything that uses field arithmetic seems to be using Python reference implementations so we said okay maybe Python is a language to start with it seems to be used by quite a few developers and designers as prototype for prototyping and testing so we pick a subset of Python 3.6 extended with type annotations what is the subset well it\u0027s a really really minimal subset we have like machine integers we have big numbers and we have arrays and not much else okay we might add things as we need them but you really want to keep this minimal because you want this to be a really compact and minimal domain-specific language the types are useful in two ways they allow us to catch very simple in silly errors like writing into an array out of bounds or or forgetting to add one or my subtract one and so on but they also help us to do very precise translations into various other formal languages which are usually typed so in particular we have compilers right now to F star there\u0027re already one working to Easy Clip that is on the way and other compilers that we are developing for languages like crypto land so if you write one speck in hacks pack which looks like Python with a few more type annotations you will be able to get for free formal specifications in all of these different languages we also have a building a library of common constructions and specifications we have written quite a few examples but we need help to write more because you want to basically exercise this language quite a bit more what does it look like well here\u0027s an example this is the matic of poli one 3:05 it\u0027s a very small sort of fragment of the speck as you can expect it\u0027s Python there\u0027s nothing special happening here there\u0027s a prime there\u0027s addition and subtraction and multiplication on this on this field which is modulo the prime but the interesting thing there is we\u0027re defining a type called FLM which is a refinement type it says this is a type of element set up between zero and prime minus one this means that everywhere in the spec where we use the type FLM we will be implicitly asking the verification tool to prove that at this point the value that we are dealing with is in the field is between zero and a P minus one and we can put many other such constraints here\u0027s a fragment of the charger 20 spec that we wrote again looks just like Python it\u0027s nothing very surprising except it as a few more type annotations in particular we are asking that all the array indexes that you use are between 0 and 15 which means that you will never accidentally access the state array outside these bonds ok again this is just a sanity check but it\u0027s useful to kind of put this in and we need them for our formal models later on anyway so once you write specs in this language what you get is for free you get compiled a compilation into models like this which is a model in a star of charge at many and then you\u0027ll be able to prove that C code that looks like this implements the spec that we started off with so you just write the spec and then we that be various tools that will be able to prove that assembly in C and Java and LLVM or whatever meets this high-level spec and yes we can verify code that uses highly optimized "
  },
  {
    "startTime": "00:12:17",
    "text": "instructions including vectorization and so on there are tools that will do that for you so coming to the end of my talk what we need here what I am here is that we need some help we want your help in promoting high assurance implementations for the standards that are coming out of this body in particular if any of you is writing a new crypto primitive or has just recently standardized something maybe you want to write your pseudo code and hack spec maybe in addition to your pseudo code you want to write a reference implementation hack spec so come look at our specs read them comment on them add more specs if you can give us feedback on the language what are the kinds of features that you might need to write specs for your new crypto committee in this in this language we are we are happy to kind of evolve our design as depending on what people say and help us kind of test out our various compilers to various languages and our various specs so the code is down there there\u0027s a mailing list which is very light right now and you can initiate and and participate in discussions there on what this language should look like and that\u0027s all I have to say thank you hello I\u0027m Daniel Kahn Gilmore I thank you for this this is really great and I\u0027m pleased to see it one of the things that maybe you don\u0027t have an example of in your slides is how to express the formal cryptographic properties that you want from the code right so the examples that you showed made it really clear how to express numeric constraints and things like that can you just explain a little bit about how you use hex back to express those things right so right now the way we write crypto security guarantees in these various tools they\u0027re different tools have different ways of doing so and we haven\u0027t really resolved how we would do that in a language like hack spec what do you want - a classic way to do that is to define two specs one which represents the ideal functionality and one we should present the complete functionality and kind of show that that is the ideal functionality we want this to achieve and the ideal functionality would not be actually executable you can\u0027t test it but the concrete one will be testable and we have to show that the two of them actually achieved the same thing and that is the goal of the crypto proof between Washee we love some help to kind of make that more formalized scarf lower sister systems are - question two questions first one is about side channels you mentioned that as someone important how would is there a way to specify that this code doesn\u0027t have any secret dependent branches or two dependent accesses yes so for for example for our charge mining spec and for any symmetric spec like that what we do is we restrict because we because you have a type system we can restrict the uses of all the integers machine in this world to be secret independent "
  },
  {
    "startTime": "00:15:19",
    "text": "in the sense that you cannot for example compare to win to machine integers you can only compare array indices and so on but you cannot compare the data which is represented by you into eight you cannot compare it you cannot crunch on it you cannot use it as an index to an array you can write these kinds of things but it\u0027ll make things like AES with s box impossible to write in the language so you have to relax it at some places so you might say ok for the S box I\u0027ll relax it for the bignum arithmetic because you\u0027re using big numbs there is no side channel guarantee there but once you once you exit that world and you come down into the world where you actually have concrete bytes and concrete integers yes we can express this requirement that you cannot you have to have this constant time coding discipline which we call secret independence another map properly for us to be questioned I look at the your github or there I couldn\u0027t see any formal description of the language do something well there\u0027s a markdown file which is extremely low content right now called language toward MD it\u0027s trying to describe the language but we are still like looking for feedback and we will we will formalize it all but you first want to kind of settle on what features we actually need Thank You Phil hamburger yeah I like this lockers you know we\u0027ve used Python in a couple of specs yes and I\u0027ve spent a lot of time trying to convert them into c-sharp or C because it\u0027d be nice if you had compilers to executable languages and if you can get C and C sharp and maybe Java that basically covers all the things you need to cover because everything else can cook into those that\u0027s a that\u0027s a good point Thanks okay any more questions comments okay I\u0027m from the chairs perspective we\u0027d like to thank you for bringing this to C FRG so early and giving us a chance to to see it and get some exposure to the ideas yeah please keep telling us about it as it as it develops thank you very much thanks okay yeah I have to find the oh there we go I didn\u0027t why does that oops it\u0027s the wrong one but your pardon come on alright hello everyone my name is Chris Wood from Apple here to talk about something some work we\u0027re doing with Katz Kramer\u0027s Luke Garrett son Esau not gonna try to pronounce your last name so butcher apologize and Nick from CloudFlare this is something we talked about a sec dispatch at the last ITF and "
  },
  {
    "startTime": "00:18:20",
    "text": "we were encouraged to come over here to present it to you so without further ado the motivation for this work is that while pseudo random number generation is fairly easy in principle and in theory and should be in practice there are cases where they can break and or I guess worse they can contain more systemic design flaws point to just two we consider relevant examples first one being the Debian bug where some developer tried to silence some warnings that were brought up by Bell grind and mistakenly removed some critical seeding processes from the or in some critical seeding step in the random number generation step which basically you know hosed everyone and made the output be sort of predictable which is not so great and then there\u0027s the dual you see bug or design flaw or whatever you want to call it which could have been actively exploited by TL server implementations that happen implement this particular spec and that is not so great so we\u0027re trying to bake in sort of an insurance policy or some kind of defense mechanism such that if we don\u0027t ultimately trust our pseudo-random number generator we can still you know get some guarantees about the indistinguishability of the output of the RNG and to do so we build on what we call the Naxos trick which is a sense every time we want to sample some raw entropy called X you mix in a secret key or private key that you have available to you and then out pops the ultimate randomness that would you you would use and this is sort of a defense-in-depth mentality because if the random temperature is ultimately flawed used the security essentially or the distinguishability essentially reduces to the secrecy of your secret key here sk also if you have sort of a you know systemic kind of implementation flaw or deployment flaw for some pseudo-random number generator this technique ensures that the failures themselves are kind of localized to each individual you know a secret key instance so for example the randomness that you might get from one particular server would be different from the randomness that you would get for a different server they happen to be running the same the exact same rng you see our PMG with the same state so not everyone is hos just a small fraction however in today\u0027s deployments private keys are not readily accessible you know if you\u0027re a server you typically store them in some HSM for good reason and if you\u0027re a client you might keep them in an enclave and depending on what api\u0027s are using to actually interface with the private keys they might not be readily available to you the keys themselves might be of varying types you could have RSA or elliptic curve or whatever meaning that the output size or whatever\u0027s fed into this mixing step it\u0027s not always the same so analyzing the randomness that comes out might not be that easy but the commonality here is that at some point during the execution of some security protocol they are used to compute a private key operation be it a digital signature or you know encrypting something or decrypting "
  },
  {
    "startTime": "00:21:20",
    "text": "something and we exploit that to sort of build what we call randomness wrapper which essentially works as follows assume we have some algorithm G of X that you know produces X random bytes of entropy give a simple PRF signature algorithm in a key derivation function which which simply can be defined as HK DF extract with a empty info string and the wrapper works sort of as written so you would sign some fixed tag tag one with your C key which you can call it your HSN which you\u0027re whatever your your API that happens to manage your private key access for you hash the output and then anytime you wanted to extract some randomness you would actually call it to the PRNG you get the randomness append it to this hashed the hash with the signature and you would extract from that a key the KDF step and then you expand using the PRF our much randomness you need I you know I guess the KDF I we use KDF and PRF notation here but really it\u0027s just an extract and expand kind of design you could probably swap them whatever expander you want of course subject to analysis and everything to be sure that\u0027s safe so some details about the particular parameters so tag one is a fixed intended to be a fixed string that\u0027s used across you know a particular deployment of this technique so a server that starts up starts you know pumping out randomness would only compute one signature with the secret key over a fixed tag and it can just cash that you know value or catch the hash of that value and then never do anything with that ever again except append it to whatever randomness is generated tag two is a dynamic string it changes every single notification so that you\u0027re not you don\u0027t have colliding randomness output and that\u0027s critically important in fairly simple to implement as well a comment that the signature absolutely must not be exposed otherwise all bets are off because the point here is that or that the trick or the secret behind an access trick is that the secrecy of the or the or the security the technique relies in keeping the secret key hidden where is the secrecy here just realizing keeping the signature computed with the secret key or that private key hidden and we recommend that the signature scheme should be deterministic although if you\u0027re only doing the signature once ain\u0027t not anything else that may perhaps that\u0027s not necessary but again like we\u0027re trying to make no assumptions about what type of operation operational environment you\u0027re deploying this technique in so you could be in an extremely hostile environment where side channels are prevalent everywhere and perhaps computing one signature is enough to leak information so just use a deterministic one if possible so some obvious criticism for this technique there was you know flurry of comments on Twitter first one being why bother with this at all you know your "
  },
  {
    "startTime": "00:24:21",
    "text": "energies are very easy to get right but just point back to the previous slide yes in principle they should be easy to get right however things do go wrong and this gives us an extra insurance policy to kind of protect against those particular instances second major one is why would you ever use your private key for something that\u0027s you know not intended use for coming here is that or my response to that is simply here we\u0027re not it\u0027s not an unintended use of the private key you\u0027re still computing a signature with a signing key it\u0027s just not used in the same way that you would use it in the protocol originally so for example you\u0027re not signing the key sheriff until s1 or or whatever and I\u0027m sure other people would come up with other criticisms I\u0027d be very happy to hear them on here or here at the Lister however you know however you like so some open issues in the draft right now with the retinas wrapper as presented it\u0027s not an easy drop-in replacement for something like that random where you just expand however much random as you want so we\u0027re looking at various other alternatives or Jarius extraction alternatives to make it so that it\u0027s very easy to do so I don\u0027t mind we had to draft a while ago that has since expired basically specifying a C Mac based expander instead of hmx based expander and you could probably do the same thing here or use the KDF that\u0027s derive - you know seed a key stream and that should start pumping randomness from there we have a very trivial implementation of this technique if you\u0027re interested go check it out then just comment that we could probably experiment with other implementations or with this technique in popular - OS libraries like popular there SSL and then SS in among others that have user space PRNG implementations that you could easily amend or rap to make this happen so that\u0027s it very simple idea I\u0027d love to hear any comments and criticisms you have thank you let\u0027s go to CUNY hi ya venire so I got to question can you go back to the for me for this yeah so um how bad can your PRF you\u0027re a random generator B and suppose G few effects returns all zeros all the time does this still work and yes and the second question is well if your random number generator is hosed how did you ever generate the secret key ah so we\u0027re assuming that the secret key is not generated locally and like that\u0027s my answer to that particular question like some magical oracle says because usually to generate gets locally I\u0027m gonna defer to the server operators on this one I\u0027m a client so no yeah thank you oh yeah Nick was saying that deals keys need to be signed and distributed so so making tom\u0027s lid that you don\u0027t "
  },
  {
    "startTime": "00:27:22",
    "text": "just necessarily have to distribute private keys so a couple of comments why did you choose concatenation rather than pass G to the X to the salt I guess no particular reason other than it was this simplest it seemed you say Plus at the time certainly welcome to a PR that changes it and your assertion that this is secure in in light of the xkcd random number generator that always returns for is not true in the case where you have the same secret key on multiple machines and they can\u0027t coordinate the yes generation of tags everything in that case would be the same across those two machines yes of course I don\u0027t know that that\u0027s that\u0027s properly addressed but I think you should probably like that is a very good point to make very clear yeah so while we do try to spell out that tag one here would be different across those two instances that one is like specific to the deployment or the of this particulars it\u0027s like maybe the MAC address and the protocol and what you\u0027re using this something that but that leads me to the conclusion that perhaps this this leads to assigning Oracle that I I\u0027m not sure than them so perhaps we I was thinking this would be a fixed fixed tag based on you know this this is I\u0027m using this for HTTP server authentication so I just pick a string that that is constant across all over that particular application and then then I deal with the the problem of making tag to unique across all of the uses of the same yeah that seems reasonable at one point I think that maybe that was discussed so we could certainly revisit that yeah for sure right and the final thing was if you want to work with NSS come talk to me we happen to have a kind of crappy random number seed that we have tried our best to remove we just used a few random on most of the builds that we have but yeah I mean we I will come down we can do this all right yeah for that so my question is you mentioned that it\u0027s not a drop-in replacement for death /you random do you have any results on how many random bytes you can safely use from this Oh some limit no not yet not that I not that the security else is like how much we can actually pump out with this particular technique if you\u0027re interested if you\u0027re more like talking about performance metrics for this particular technique okay so there that is the pending issue that we need to address there certainly less for animus that you can pump out with this particular with this particular technique the short answer is as many as you like if you have secured a secure PRF and you model the hash function as a random Oracle I mean there\u0027s really no boned okay but you don\u0027t have forward security though I mean once X is compromised yes but we just haven\u0027t "
  },
  {
    "startTime": "00:30:23",
    "text": "specified it like the tightness of the bound position thank you yeah I have a couple of questions too if I mean yes and I start you used dual ec as part of your motivation for this yeah I\u0027m not sure that motivation really works because it\u0027s known by now that a back door generator in that way is actually equivalent to public key encryption which means you can spot it in source code if you have access to store could it stands out a mile because it\u0027s basically a public key encryption scheme on the other hand if you don\u0027t have access to source code you can\u0027t see it and you can\u0027t detect it okay fair point so that might be something you want to look at in your you know section and zero of your draft or something yeah our motivation I\u0027m the other question I had is if you go back to the equation just from aluminum suppose we use this process to generate randomness for a signature scheme which is already the signature scheme that\u0027s being used to generate the randomness yeah what can you say about security in that case I I don\u0027t have a good answer for that right now but that is again something we see we just need to kind of specify yeah hello / Mishler descriptor pro one command for kenneth question yes this is very important question that\u0027s why in the new version of the draft at least should appear about this monistic signature algorithms and I think we should discuss that she\u0027s this shoot can be switched to must in the future so it was a usage of non-deterministic signature algorithm can be used only once for these exact usage and not for any other means and about the question of Martin about Sun Oracle of course we should continue improving the draft about as a form of tag 1 and take 2 about the possible forms such that no obvious attacks place I mean Oracle can be possible so these two ways must be taken into account while we improve out draft so thank you very much questions we are cynical about it already but maybe for now our steps were not too much but we tried to start to keep it into account yeah thank you yeah thanks thank you one one more question from the chairs I got it from Alexia and me is you know what was your intention here what are you hoping to do so we were originally appointed to come here from sec dispatch and here we are so I guess that happens a lot of people get sent to see FRG is like a kind of punishment thing you know so it depends on whatever the work or the the group feels is best I I think it\u0027s useful technique we can certainly do it without anything written down but you know if it "
  },
  {
    "startTime": "00:33:26",
    "text": "can be written down why not yeah so Martin Thompson let\u0027s let\u0027s let\u0027s be frank you wrote something down in an internet draft with some intent that you would have it published is your intent to ask these guys and this group to publish that um yeah I I think so if people deem it useful and we\u0027re the excellent thank you I think you\u0027re sort of getting to this point but thank Thank You Martin for accelerating the process so maybe we can just take a hum in the room are people in favor of the research group adopting this as a research group draft with the intention of starting as a starting point yeah potentially other techniques will come forward and other people want to get involved and that\u0027s how it always is with with an internet draft in a research group yep so we could take a home so I guess on three hum if you are in favor of this of the work of the research group adopting this as a starting point for an RFC okay thank you and um if you are against you know yeah you did it was one of what okay but I think much lower volume than the hum and favor thank you very much it\u0027s really helpful thank you everyone for participating yeah thanks good just a quick point of order the the draft is on github at the link at the bottom that\u0027s just a pointer to some code that\u0027s there but if you have comments or you want to file requests please go ahead and you can find the slides on the agenda Thanks yep alright so the next one is about hashing to elliptic curves this is work that Nik and I I did not intend to do that put together there has been some work especially with relation to the vrf graph that was recently adopted - you know nail down exactly how you might want to hash arbitrary things strings to elliptic curves and there are a variety of different ways to go about doing this if you just look in the literature so we wanted to write down what we thought were reasonable mechanisms for doing so exactly how you do them and hopefully depending on how those hacks back stuff going goes maybe produce some maybe use that as kind of a vehicle to drive that particular work forward as well so kartik I\u0027m kind of well sync up later talk about it so for some background hashing two curves is not uncommon it\u0027s used in a wide variety of protocols Pakes use it quite often to hash for example of the private key or the secret password onto the curve itself BLS signatures used it quite frequently or used it as well as I mentioned the vrf Draft has a placeholder for the elliptic curve variant of the vrf that uses this particular technique and the privacy "
  },
  {
    "startTime": "00:36:27",
    "text": "perhaps work from CloudFlare and others also has this baked into at one step of the protocol so the common approach to going about doing this and the one that\u0027s written down in the vrf draft and I think the one that\u0027s maybe implemented in privacy is they try an increment approach where you simply um iterate essentially until you have something under the curve so you have some spring hash it up with some you know kid hat and a would some counter and check to see if the output can be decoded to a point on the curve and if so return it otherwise keep going indefinitely the problem with this particular approach is that it\u0027s obviously not constant time the number of iterations that you do depends on or will distinctly reveal what the actual arm reveal something about the input so that\u0027s not always necessary but when we can make it constant time it might as well so some of the requirements we kind of set out for this particular draft are number one we want to be constant time number two whatever else you people want in this particular work so question mark there we were happy to extend that non requirements are that the hash function itself is not invertible and I realize that\u0027s kind of misleading because we typically you know model these as random Oracle\u0027s which we consider to be one way but certain implementations or certain algorithms rather are invertible elliegator to for example which point to later is invertible and that has some useful properties for example if you want to do some steganography type things where you\u0027re sending random bytes which also happen to be a point on a curve and you want to try and get away with it that has a potential application there but some particular protocols privacy paths for example requires that the mapping not be invertible so we just want to call out and it\u0027s not yet written down the draft but we want to call it which of these algorithms are invertible and which are not but it\u0027s not a requirement for the ones that we write down right now so the methods that we chose and we started with four are the aircard the SW I forget their names the simplified has to be you and alligator two and each of them has this particular requirement on the curve itself for example i-car requires that the prime or the order of the prime subfield is congruent to 2 months 3 SW has no requirements so it works for any particular curve elliegator 2 has some interesting requirement Q is large I forget what the actual technical definition of large here is in this case has a point of order 2 and J and very not equal to 1 7 to 8 so I be more interesting for judge appoint you to papers for you know the particular details of these algorithms and why the requirements are necessary then describe them here so that\u0027s what I\u0027m doing in the draft we focus on one particular interface for this function simply a hash function which I shortened that to H you see here which takes some input alpha maps which is at least "
  },
  {
    "startTime": "00:39:27",
    "text": "nonzero and maps to some point and the curve so alpha can be arbitrary in point we q to denote the prime order the base field u is a point of order 2 we went specifically in the case of alligator 2 which is my one that has this lovely little criteria f of X is the curve equation and then H of X Rho alpha is something that we use to hash a string into the prime order subgroup of the curve not hash to the curve which are two distinct things so the heart method is fairly simple you can you know write some sage go fairly quickly to compute this in fact one of the appendices in the draft has this some modest number of exponentiation some scalar multiplications and additions and subtractions the exact cost we still need to do in the draft there\u0027s a big to-do at the end just to compare the different you know the computation will come the you know at arithmetic complexity of each of the algorithms but you can you know just take a glance at it and see what it\u0027s like alligator - sort of similar but a little bit simpler compute this value D and compute the Legendre symbol and then just depending what the output of that is negative one or not choose one value the other so there\u0027s some constant time this you need to worry about with the implementing this particular technique but it\u0027s not too hard to accomplish so our current recommendations based on the widely used curves that are in use in ITF protocols are P 256 stick with simplified SW 384 use a cart in four to five or nine four four eight use alligator two simple because those were or that particular algorithm was sort of tailored to that you know Bernstein like world so and and it seems to work so um I say current because those are free to change depending on what the actual cost complexity turns out to be and if there\u0027s a new algorithm that comes out so of course I\u0027m happy to discuss these particular recommendations going forward like I said there\u0027s a lot of open tasks to do we just wanted to get something written down and something that people could talk about need to complete the cost analysis there\u0027s a huge empty section on the SW algorithm particularly details of an implementation which are empty we\u0027ll get to eventually simply that draft unlike him up on this mighty quick so next time around we\u0027ll get to it Sharon Goldberg who we collaborated with on this particular document pointed out that it would be useful if there were security reductions in this particular work where possible so of course that\u0027s something we should consider and integrate the interface details are sort of skimmed over in particular how you convert you know octave strings to integer points so we just need to look at the vrf graph where she\u0027s done a she and her co-authors did a great job laying out the foundations there and maybe apply that here and also kind of work alongside with her to see if there\u0027s something like in that draft "
  },
  {
    "startTime": "00:42:27",
    "text": "that or if she can point her VC vrf stuff over to this particular document so we don\u0027t duplicate work and then I was alluding to earlier it\u0027d be really nice if we could use this as a driver for hacks back to produce some verifiable implantations and you know test out the miss emerging language and the last thing is so I want to clarify that not all mappings are reversible and specifically you know layout in potentially in the security consideration section what happens if you are using a hash function that is invertible so some open issues particular the language around hashing to a prime order subgroup of the curve is not it there\u0027s much to be desired there certainly we flushed out in particular many of the techniques that we see always multiply the output by the cofactor of the curve so that you make sure that you\u0027re always belong to the primer order subgroup that\u0027s something we\u0027ve not actually written down but it seems like a reasonable technique and there are others that I\u0027m not overly familiar with that we could use as well so maybe you just stick with this particular recommendation and go from there but of course I\u0027m happy to hear alternatives the other point raised by Mike amber goes that you don\u0027t get pure indistinguishability from random from a random point in the curve for each algorithm that\u0027s not always needed for every single protocol so we just need to spell it very clearly you know with this much technical precision as possible um what the indistinguishability guarantees are and potentially list some algorithm are some protocols in which this is and is not needed so that\u0027s still sort of an open task and it\u0027d be interesting to hear what people have to say or think about that and so that\u0027s it so I encourage you if you\u0027re interested go take a gander at the graft it simply lists the different algorithms has some implementations and has some - dues that we need to fill in and yep that\u0027s it questions comments feedback - people think this is useful desirable please come to the mic and give you a reasons why will be really helpful or not someone\u0027s coming Thanks we should so actually have a question Richard Barnes question about variants so whether this is related to different problems I\u0027ve got in different contexts so in the MLS that I\u0027ll be discussing the buff on Thursday we have a need to map from a random string to a curve point but also know with a known discrete log so you know me up to an easy keep hair instead of just a point now that draft has something in it that I just sort of made up and I think looks kind of okay but do you think there are like learnings here "
  },
  {
    "startTime": "00:45:27",
    "text": "that could apply to validating something I\u0027m mapping of that type as well as in that big - two points itself so I would need to look at it and it sounds like yeah sure maybe that\u0027s good as anyone out there yeah so well we\u0027ll talk and then let\u0027s see if there\u0027s some way we can kind of expand the interface here to accommodate that particular use case or or something yeah it could it could be a little bit dangerous though because in here you\u0027re trying to kind of get some kind of random Oracle functionality on to the curb right from strings to curve points and you\u0027re doing something that\u0027s manifestly not a random Oracle so the that may actually be an interesting question for MLS whether we actually need that property out of the derivation we go yeah I don\u0027t think we okay it is also interesting in the vrf draft the interface is not exactly equivalent to this they take in a public key and a string and they use both in hashing to a point in the curve so the question of what exactly is the right interface here is still of course up for discussion we just chose you know one input the arbitrary input because as Kenny said we kind of want that to be the thing that we hashed onto the Garba nothing else but of course we can talk about it if we need to change it okay so here\u0027s grilling one so I would like to know did you have some comparison with your proposal with other existing solutions we impose expects over security in the efficiency we don\u0027t have a proposal this is simply a coalition of all of the existing techniques and algorithms that have been already published into a single document in an attempt to kind of nail down exactly how you would do this if you were to do this in an IETF protocol because it\u0027s used quite often and as you point to the CRF draft there\u0027s one particular use case so that I\u0027m sure somewhere in like for example in the alligator paper and in the they simplified us interview paper where they presented that particular algorithm they do offer comparisons between you know their work and all those published previously yeah so maybe there\u0027s we can yank those in with proper citations and okay quickly yeah just a would like to know this yeah yeah hi I\u0027m Ella berners-lee and I was just wondering where any of the curves that you just mentioned pairing friendly not that I\u0027m aware of no okay because I know there is a publication out there about implementing hashing on 2bn curves so is there any interest in adding that into the draft or so I\u0027m not opposed to it Nick might go out there is shaking his head yes so I yes there is interest okay and and one more question when you talk about not being strictly indistinguishable from random what kind of language does that look like is that sort of just losing a couple of bits security or Dewey and a completely different way now so to give you an example of the extreme elliegator to "
  },
  {
    "startTime": "00:48:28",
    "text": "only ashes on to half of the points on the curve so that\u0027s likely in distinguished are that\u0027s lightly distinguishable we don\u0027t sorry we\u0027re not more precise than that we would certainly like to be though and it if you have suggestions love to Europe thanks Dan Harkins yeah I think this is a really good idea it\u0027s very important as you mentioned it is used in vrf it\u0027s used in Pakes I got beaten up pretty severely for using a really simple and lame moy of hashing philippa curve and had this been around I wouldn\u0027t have gotten beaten up so badly good I\u0027d probably get beaten up anyway South fluorisis four systems I\u0027d like to emphasize if if you have a method which misses half the points on the curve that is very critical that you emphasize it it will completely break most pigs yes absolutely and we do not go into strong language that we simply actually I don\u0027t think we write down that it only maybe we do maybe we don\u0027t I don\u0027t recall but if we do not is certainly an omission and it should be added okay my attendant chairs would like to ask if there are any objections to adopting this document as as a research group document with the assumptions that you know more changes will be done and you know more curves will be added as discussed yes and stuff are they people who are willing to work on this document review document alright that sounds good thank you thanks Ron hi I\u0027m Nick Sullivan from CloudFlare this is sort of the Nick and Chris show right now but um right now I\u0027d like to introduce this draft that we wrote that introduces a new construction called verifiable oblivious pseudo-random functions now it builds on the intuition from two very well-known constructions one is V RF switch is a public key out analog to "
  },
  {
    "startTime": "00:51:30",
    "text": "hashing so you can compute a v RF and then someone can verify that with your public key that this was done correctly this has several applications including heat transparency and the N SEC v draft as well so that this is a this is a very useful technique in a lot of different areas of cryptography another basic construction is that of OPRS which is similar to the idea of blind signatures which was rooted in the idea from ecash schemes generally how this works is someone will take a message that they want to have signed by a signer and blind it in some way send the blind message to the signer who then signs it and it can be returned and then unblinded and then any person with the public key of the signer can invalidate that this signature and message were signed but this has the additional property of obliviousness where the signer does not know at the time of signature anything about the message that was signed just that it had signed a specific blind blind object now the intuition for vo PRS is to kind of combine the best of both of these you lose some properties but essentially if you go through what a vrf or what a PRF is supposed to be is that it\u0027s a function that given F X it\u0027s infeasible to compute this function without knowing a secret key okay and this F is also supposed to be indistinguishable from from random and this has the technique that we want to incorporate from VRS here is that this should also be verifiable so the verify somebody who requests this vo PRF to be computed can verify that it was actually used it was computed using a specific private key that\u0027s associated with a unknown public key we would also like this to be oblivious in that the signer does not know if review if the value Y that is revealed to them cannot identify which X was actually used or which computation was actually used to to compute Y so yes if X is revealed to the signer they can\u0027t actually identify which signature or which of these computations is is the one that was used to compute it so this is very similar to the vrf and the O PRF but what you do lose to verifiable and oblivious properties are used together but you lose the ability to have this publicly verifiable so if you do actually expose this as a publicly as a as a public value then the signer can then recover "
  },
  {
    "startTime": "00:54:33",
    "text": "the obliviousness so it the way that it kind of will work fit into a protocol is is as such is the verifier will construct a message M will blind that message send it to the prover which will then compute a signature s a signature which is the o PRF computation of VO PRF computation the verifier can then take this and verify that this is associated with the provers public key and then they can remove the blind and if they want to that can confirm the the output here this signature is associated with the original message M send that back to the approver they can verify the same thing and this original vo PRF computation versus the confirmation these are unlikable there\u0027s no way to associate m Prime with M without actually seeing the Associated proof so this can actually be instantiated with elliptic curves this is very similar to the work in the VR vrf draft that we that was discussed in the previous presentation so you can construct it with an elliptic curve a one-way function that as was described in the previous presentation a one-way hash to curve that takes a value of string and puts it onto the curve and if you also have a way to do a non-interactive zero knowledge discrete log equality proof so that\u0027s a very long phrase but essentially what it means is that given two pairs of points you know that they were both exponentiated with the same scalar so we have we have a warning eduroam authentication failed great ok let\u0027s let\u0027s go forward so I\u0027m this instantiation was that actually came from a paper from a few years ago from jirachi khaosan kochak and this describes the algorithm which lets you compute a discrete logarithm equivalence so if you have Y modulo point G and Z modulo point M you can show that there actually have been exponentiated with the same scalars K and this is these are the details the algorithm and in the protocol some intuition you can get around this is you take your string which is your sort of secret value you hash this into a curve and you apply a blinding factor which is just an exponent which is just a multiplicative value here so your message that you\u0027re sending to the server or to the approver in this case is the hash of the input X onto the curve so you have a curve point "
  },
  {
    "startTime": "00:57:35",
    "text": "and you multiply it by a blinding value arm on the prover side you take that value and you multiply it by the secret key in in the case of hash curve this is just another secret scalar and then you generate discrete log equivalence proof between this multiplication of the point and the a public pair that represents a a base point and the base point multiplied by again K which is the the secret value in the prover you can send this back and the the verifier can verify this discrete logarithm sort of divide out its multiplicative factor R by multiplying by the inverse and you end up with the original point hash to a curve multiplied by the provers private key now the the second phase of this ins in some protocols is that you can take this pair and send it to the prover who can then compute a hash of the value X and multiply by its private key and that should be equal to the original value Y and if it is equal then it knows that its private key was used in the computation of Y but it does not know exactly which which value you originally compute it because it doesn\u0027t know the discrete logarithm modulo the blinding factor so the blinding factor is is what keeps this from being known to the server so this adds the obliviousness so if these match then you can confirm yes this was actually used in a previous interaction alternatively you don\u0027t have to send the value why you can send a value that can only be computed with the knowledge of Y and the prover can compute that same y as well I\u0027m multiplying that x hash to the curve okay and and then you can validate that both parties share this Y over a specific mount a bound to a specific message so that\u0027s that\u0027s generally how these this construction works and as as was mentioned before this is we have an application to this called privacy pass which is in an upcoming Pets paper with myself and Alex Davidson and few other folks the way that this works this is for reducing the amount of CAPTCHAs seen on the Internet in a privacy-preserving way so the way it would work is that you would compute a token and or a set of tokens and win "
  },
  {
    "startTime": "01:00:35",
    "text": "solving a CAPTCHA the CAPTCHA server will compute the vo PRF over your blinded tokens and send them back to you and then the next time you see a CAPTCHA on a completely different site on a completely different origin you can submit the unblinded the unblinded token and then the server has no way to actually associate whether or not which-which site was the one that actually issued these tokens so it allows you to send data to to prove that you have solved a CAPTCHA on a another site without revealing which origin that site was originally presented it so this allows a sort of bypass of the same origin policy due to the blinding ability of the vo PRF and this is implemented in a browser extension for Chrome and Firefox as well as on CloudFlare servers another potential application of this that we\u0027ve looked into is privacy-preserving password leak checks so if a service has a lot of passwords that have been leaked what they can do is they can hash these to a curve and exponentiate by a private value and and if you want to check whether your password is part of that list you can submit it to the server to compute a vo PRF and have it come back and then compare it with the the entire database and what this lets you do as a server that that has access to all all of these um the private keys for all the these passwords is to do rate limiting so it allows you to check to see which password you\u0027re looking for and the server doesn\u0027t get to know which password you\u0027re actually looking for so if you have a unique password it can\u0027t identify you as well as it stops people from being able to do a kind of a brute-force crack of all the all these websites because it\u0027s it requires this vo PRF computation and these are some of the the foundations for this is several different papers and as well as this relies on the previous presentation which which is about hashing to elliptic curves this is one of the major mode of motivating factors for writing that document and that\u0027s it questions stunned silence more like it is this your knowledge christening yak Zakia people have returned you forever Oh something comes on thank you this isn\u0027t when dureena from MSR I\u0027m kind of "
  },
  {
    "startTime": "01:03:37",
    "text": "struggling to understand what is the actual contents of your drafts that you\u0027re proposing I didn\u0027t read it so I\u0027m trying to understand because you you dr. words several kind of cryptographic primitives as many of which are kind of fancy but from my understanding of these primitives they have kind of different security models so I want to understand what what exactly you are trying to propose as a sundog right so what this draft contains is a general definition of EOP ahrefs how they work in a specific instantiation that you can do given an elliptic curve as well as a hash to curve so if you have a specific curve that you like and you have an algorithm to hash to it that is one way this tells you how to construct a protocol of this sort and to which extent is your craft specific to whence particular conscription of vopa in particular this draft is about this elliptic curve instantiation we we don\u0027t go into opening it up to more generalized vo PRF second it can be instantiated in different ways but this draft is about EC vo PRF okay and this thing about those are kind of vrf no there\u0027s nothing about that it\u0027s just that the specific definition of of this instant instantiation it thank you very much okay do you want to ask anything about this what are we gonna do what are you gonna do this thing what do you want us you\u0027re doing for research group adoption of this dress yes presumably yes I mean based on whether or not the hash to curve is is adopted I think this is a I find follow-on to that work and dependent on it okay do you see them progressing in parallel or in in sequence I think they can progress in parallel and I also think that things like privacy pass as a protocol um could be proposed for say the HTTP working group or something like this that would rely on this draft being adopted mm-hmm so other people in the room who would in addition to the authors of the draft who would be interested in working on this maybe OH what hi Daniel con Gilmore ACLU sorry I was really loud I am really grateful to see this work happening one of the concerns is about how you ensure that "
  },
  {
    "startTime": "01:06:37",
    "text": "the the key for privacy pass particularly the Vikki remains constant right or else the person doing this on you can keep a single key I believe you\u0027ve solved that for the tour arrangement do you have suggestions for what we had to solve it for III I think in general making sure that the server does not yes oh so we\u0027re you\u0027re mentioning is the tagging attack where the server could potentially provide a proof to a different public key that is unique to you which sort of defeats the privacy properties of this and the general suggestions for this are to make sure that the server\u0027s public key or the signers public key is has some sort of public verifiability whether it\u0027s put in some sort of consensus protocol or part certificate transparency or some sort of transparency log and the hope is that every signer inter every every verifier interacting with this system would also have access to this but I think that\u0027s outside of the scope of this particular document okay that\u0027s that\u0027s what I was looking for was whether you see that as being independent of this I think it\u0027s independent in the way that certificates are independent of TLS okay that\u0027s fine I just want to make sure that if we do end up working on a document like this there needs to be a big caveat even if it says to use this scheme safely in public you need something like so that that\u0027s not yep noted and we should definitely add that text to the draft okay we\u0027ll take it to the mailing list and we\u0027ll we\u0027ll have full of discussion with you thank you okay so hello everyone my name is grilling one from hobby so my talk is about Pig so PA ke password authenticated the key exchange so in the first part I was introduced paraquad about fake then we will introduce our proposals I mean our protocols yeah then we will consider whether it\u0027s a good candidate the proposal for the IFC eight one two five because it gives some requirements about the pig so here is the terminology or some main concepts about to take increase you are not so familiar with this one Pig basically means it allows two parties to establish a secure key in the cuiprit or sense by using a common shared a secret between two parties "
  },
  {
    "startTime": "01:09:38",
    "text": "because the secret is assumed is a very short so it is easy to memorize but on the other hand it also means it just that has a low entropy is a it could be very easy for attacker to guess the password so the main thing we need to think about about the security of the pig is about the dictionary attack actually two versions one called the unlike dictionary attack this is err can be prevented quite easily by supposing the server side can do some check just allow you twice a password for a few times in a given period now this can be done very good in practice so the really difficult one is about the offline cache we attack it means that actually attacker can leasing your messages for your protocol yeah for several protocol or running instance after that as you can according to this message and I\u0027ll try to do offline calculation to fund your password this is a bigger problem yeah because the part of what it is a shot and many people use a pass or according to some petty information like your your your name or some your birthday something like this so I think I can create a dictionary for possible puzzle world and try this one by doing offline calculations or flies that have computers even super super powerful computers can do it very quickly so the sage Dictionary size can be very big actually yeah another security requirements you called the forward the security it is also important basically it means we were likely to have such a protocol such that even the password is leaked sometime later even in this case the parallel parallels share the secret King the session King yeah agreed by using the password could still be secure this is important one one more thing is that actually original version about the pig is that both post parties just share the drawer secret that the password but in this case especially if the server is a compromised by attacker so the server can get the password for all the users this will be very bad so we would like to have something else because there how to prevent the server come corruption or compromised this means even if the attacker could compromise the server that can only get a summary information part of the password but not the password is itself yeah so to do this one we have a variant of a pact accorded a verifier Peck so we can cause of APA k yeah use these keys we can prevent the server complete corruption yeah so these the terminology and these are complex but if you\u0027ll notice quite well it is actually yeah but interesting okay so the main challenger for the peg "
  },
  {
    "startTime": "01:12:39",
    "text": "is that we would need to design PA ke secure against the off like extra attack it\u0027s not challenged apart yeah so the main limitations is the most obvious existing package solutions are to expect the first one is most of our quite a number of them actually don\u0027t know the support the form of the security but this one is actually important and another one is that for some schemes they\u0027ll have provable security but only in the multiplicative group sort of a find the fuse basically means it does not work for Olympic Africa Liberty curve lot of work for you see see this is actually important one especially if you\u0027re needed contained efficiency because it is a can use the short elements and can get a very tighter security key yeah so it is more efficient for post computation and that communication yeah so we have a two protocols they are paper protocols which meet both forward the security and it can works in any group so including ECC which means so the paper actually published in 2000 hmm HSE says a nice conference just a one year go and a public evasion is actually available from the professor David upon the Chivas website from yes so you can get a version as well so this coupon code will call them tbp ke to base to basis possible the explanation case change so to base just a term we use how to construct a protocol and is a verifier version called the VAE PPP e ke so this can be used to prevent the server corruption yeah suppose protocol approval can be proved the secure understand the complexity assumption so this means we have a cryptographic security guarantee for this protocols and the most important one is that the ECC can be used that to implement is the protocols so in this case post computation and communication can be hard efficient okay so here using some a very quick summary about the existing solutions as there is a lot actually here I just mentioned two most ephemeris war and also call it related to our research work the first protocol called a de ke encrypted key exchange this is the first epic protocol yeah I guess they so actually it basically is that DF ami exchange but the tff I\u0027m exchanging is not secure but due to the Magnum attack so here is AC protocol we used password just used possible as there as a symmetric key and a to encrypt the temper temporary public key for the D H protocol yeah in this way we can get a secure protocol one secure protocol about the security actually it can be proved secure under the random on Komodo "
  },
  {
    "startTime": "01:15:41",
    "text": "yeah but we need to assume that the symmetric key we use the for encryption here is an idea cipher so it is has no flaws like an idea cipher yeah just a idea cipher a second one called the SPE ke simple parts of other explanation K is change with just the patient\u0027s is work at our new protocols and then this protocol is do editing another way so do based on th but here we just used maybe not what things mean sorry for getting so in this protocol basic idea that idea generates the generator for our yeah multiplication group G from the password use a hash function actually this is also related to the previous presentation about the hash and opponent hash and some value to a point in ECC yeah it\u0027s related so that was all from my point is also increasing there are such things for that Joseph for this one so this basically means the attacker can actually things do get is the temporary public key for the th but they don\u0027t know what is the generator because I don\u0027t know the password yeah so from this point it\u0027s quite simple but the proof is actually is not so simple especially saying is that the the available security proof only works for multiplication subgroup of a finder fields not for the history cooks so this means if you use a UCC you can see do use this protocol but it is risky because no security proof guarantee for this protocol yeah and also because of the usual reason so actually the real efficiency for a proviso is not so good ok so here we introduce our protocol our bottle coding is something quite similar to the PE ke due to this reason we called to base PE k so in our protocol with just a general get the generator G from two bases you multiply the right to PW PW the password you and P you and they are other other two pieces this is our protocol yeah and the next one to prevent the server corruption so we need to do it another way just the based on the first protocol so what we do is that the client signs do need to hold the password but but for the server side the server only need to store another value it is called the way to the h SP w SS here you know just a random sort yeah for ye for each user it\u0027s the difference "
  },
  {
    "startTime": "01:18:42",
    "text": "and the H here is a hash value yeah so this means it\u0027s the server side the server data into two daughter the the password yeah and in the implementation are you how to design the protocol two basic ideas the first idea is that yeah the user need to prove his knowledge sgw is the hash value of the of the password together with a random sort yeah he needed to prove this one and the to prove this one basically the well used as their knowledge skill so also just the previous slides introduced the idea here we don\u0027t mention video and the next part is that because their own knowledge like removal there\u0027s a challenge commitment challenge and response and again this one we master need to encrypt the response otherwise the protocol is not secure again against the offline attack yeah so detail use a little bit of complex but the basic idea is can it okay can I just interrupt you so there are four minutes left you can either keep going through your slides and have no time for questions or okay yeah yeah yeah so hey the policy could you prove we actually gave us a guarantee in the cases yeah like a website is supported security and we also consider the possible so that we can get a little bit more tighter security results yeah there\u0027s some examples of it on you can go into detail here is the comparison so in the second part the last line is about our Chester PA ke protocol hardly sufficient from here you can see it is supportable so for the security and also work seeing the ECC group and the last one lots of the parts in the last align to our verify version of the our protocol it also supported secure forward the security and also works the following sec here is our preliminary inflammation implement this is the recommendation on parameters so in different security levels what\u0027s the password we can we can use how long the password and the corresponding ECC element size and as i see is the our preliminary implementation results basically you know a quite normal server so each patrol can be wrong I mean mainly for the computation can be done in 10 milliseconds this is the requirements from I say eight one four five it is about the requirements of a paper protocols so any requirements here so we can say our protocol satisfy almost all the requirements there are some we need a little bit more work so we always think it could be a Canadian proposal for these requirements so they think it all right we have any questions please and uh fill van Baker I would just like ITF to pick exactly one "
  },
  {
    "startTime": "01:21:44",
    "text": "I don\u0027t care what it is so long as you pick warm and his patenting unencumbered which is the reason that we\u0027re not doing any of this today because there were patents and they got in the way Ann Harkins again so related to what Phil said requirement 8 is you have to say whether your company has any IPR in this scheme so does your company have any IPR in this scheme I\u0027ll wait I\u0027ll have okay so on the comparison you say that\u0027s spake to speak and SAE do not provide for secrecy but that\u0027s not true that\u0027s for compromised speak to speak and SAE they all perfect all right yes they\u0027ll provide for secrecy and I don\u0027t think that there\u0027s a limitation for a multi-link of subgroup of finite field for SAE okay we take a leg done maybe okay yeah discuss with you Stanislas mesh laughs crypto pro I would like to add a few words to the dance I commend in fact spec 2 is as for secrecy moreover dance protocol KX has it and as I understand has all positive features that you enumerated in your slides so it will be very good if you may be in the Middle East we could have a deeper analysis of comparison of your protocol to all existing ones because you have a lot of package and I think that at least three of them are quite similar in the sense of security these for secrecy with support of elliptic curves and maybe the difference is about as a complexity as additional security properties and also I will dead that your conditional there file will take a same very similar to augmented Peggy and in fact this doesn\u0027t prevent as a password to be leaked if the server is compromised it\u0027s just another line of defense if the adversary wants to put force all passwords but if you want to attack one single password and he knows this verification value it\u0027s not a big problem so and they would like to it to continue this discussion in the main list because it can be very long okay yes I\u0027m gonna cheat yes sorry we\u0027re a bit short on time so yes let\u0027s take it to the mailing list and move follow up privately all right thank you hello "
  },
  {
    "startTime": "01:24:56",
    "text": "everyone I\u0027m the Nova gear I\u0027m from the University the Netherlands I will be presenting the truck for counter 12 so first of all what\u0027s kangaroo 12 so let\u0027s have a look at check 128 psych 128 use a sponsor insertion so basically you have your spawns on your right which is divided into part two parts the earth part and the inner parts the inner part is what guarantees the security of the scheme and in this pond construction you\u0027re going to spit your message into small blocks that you will absorb and between each absorption you will apply a ROM function which is mixing up the inner part and the other parts and then once you\u0027ve mixed up everything you want to extract your hash basically so basically you extract all parts and then you mix again and extract the point of this is you can extract as many bits as you want so that\u0027s why we call it an excellent able output function because they are lengths is arbitrary as long as you take a long enough in the case of Shake 128 you use a Kajaki function which permutation that has been defined in 250 Oh Jo so while sec 128 is quite nice by design it does not allow the possibility of terrorism which makes it a bit slow so we want to add some sir it into that using congroo 12 so basically convert 12 is the same idea but we apply a tree structure with the sponge so you split your message into block off 8192 bytes so that you see in blue there and you will hash this small blocks into what we call a chaining values that you see in green there that will be 256 bytes and then you will hash the full thing again so we use the same sponsor construction so we\u0027re also pretty nice in term of design and we reduce the number of fronds of Ketchikan to 24 to 12 giving us already a bit more speed and as you can see that the longer the message the more paracin you gain so and it also if you have short message you don\u0027t need to actually hash the other part so you actually don\u0027t have penalties for short message so once you see that you start sinking what\u0027s the security of it so Congress wealth is claimed as secure as check 128 in all the words 128 bits of security it has because it\u0027s used as pawns construction you also relies on the generic security of a sponge that has been provided by the attractive the pearl mode is based on secretory hashing so it\u0027s also proven secure bicycle check Jim once again and on top of it we have the same run function as defined in "
  },
  {
    "startTime": "01:27:57",
    "text": "Phipps your choice okay check P but only weeds the 12 last roams this mean that the crypt analysis that has been applied to it it\u0027s still valid since like the last ten years and we moved on from safety margin which is rock-solid to quite comfortable still as a matter of fact if we have a look at the 24 runs of shari here we still are in the middle of it we have collision are over 5 roams but we also have collision over 6 runs but with a smaller capacity so this gives more degrees of freedom the difficulty of having the creation of over capacity of 160 bit is estimated if you take a birthday paradox as super 80 we also have stream prediction over 8 runs but we have 12 so it\u0027s fine with the difficulty up to 2 per 128 time it\u0027s also possible of the nine rooms but the difficulty is 125 1 to 2 per 256 time so that\u0027s already above the security claims that\u0027s very fine and there have been lots of so the particular is is being done on kachuck so that\u0027s very nice we\u0027ve seen that conclude roll this pretty seeker let\u0027s see how fast it is we have the number of Thrones so it will logically take half the time so it\u0027s twice faster as checks 128 and then once you take longer inputs and the latest skylake x processors only using a VX instruction then you can get down to 0.55 cycles per byte at that point the bottleneck is not the hashing anymore but more the network connection and so on so why I think it\u0027s an interesting I see that we could have it\u0027s because it\u0027s on the same basis as the NIST it\u0027s public design completely open it has been the result of the Shah three international competition it survived ten years of cryptography and cryptanalysis and still will I hope survive more it provides a really nice speed up with respect to sha-3 without wasting any cryptanalysis resource because what have been done is a path still applies today to get Chuck and come go 12 and the pair isms just scales with the implementation so you don\u0027t have to provide partner initial parameters like I want to have convert well with 8 parallelism computing at the same time and so on so very nice for more details I can invite you to have a look at the current draft also I will add that there is a version "
  },
  {
    "startTime": "01:30:58",
    "text": "two that will be published online or a short leash thank you for your attention thank you questions comments from in wah so I\u0027ll start off maybe until people can get to the mic and so you\u0027ve half the number of rounds in yes so what percentage of your performance gain comes from having the number of rounds we are at least was twice faster than check two so and then we have the cycle to the bytes yeah counts okay so it seems like something like 70 or 80 percent of your performance gain comes from just having the number of rows no it also comes from the fact that we are actually hashing in perils of blocks and I\u0027m just using the fact that we are have to process every blocks one by one and one by one this as a in check three or yeah shy quantity eight okay this question from the floor oh yes so here is grilling so I would like to know concrete or is basically like primitive to construct the prototype for hash function or just a complete algorithm it\u0027s a complete hash function a complete extendible or third function so you provide the message you can provide an optional level but that\u0027s if it\u0027s not provided then it\u0027s considered as empty and you provide the output link that you wants okay Nick Johnson Foundation it seems like you\u0027re combining two different trade-offs here one is oh sorry to two innovations I guess one that improves speed with parallelism it with no cost and security yeah and a second trade-off which gives you more speed at the cost of additional security why combine these together why not just offer a parallel construction that uses the existing number of rounds well if we want to have a very nice speed-up it\u0027s even better if we can actually do the number of runs like the current Tkaczyk implementation with 24 ohms is like really really conservative and there is no lots of going down to 12 roms is there a reason that you believe that your users will be less will need less conservatism than general consumers the secretary claim is the same so there is not really less conservatism in that case like we still have 128 bits of security that\u0027s under an assumption that reducing the number of reigns doesn\u0027t weaken security yeah okay so it\u0027s not and it\u0027s not an unconditional assumption well until proven contradict you able to go back to the slide with the performance measurements for a moment that one yeah so so it looks like you\u0027re getting comparing lis the shorter looks "
  },
  {
    "startTime": "01:33:58",
    "text": "longer but you\u0027re getting at least 100 percent speed-up yeah from parallelism as well yes I yeah I guess I I still don\u0027t understand the justification for the two changes together it seems to me like it\u0027d be a very useful construction with standard gear check well the standard code check would you would have the same speed at check 128 for input that would be shorter than 8,000 bytes basically and we actually want to try to make everything faster for whatever the possibilities so that\u0027s kind of a trade-off thank you okay we\u0027re kind of over time actually we\u0027re already eating into people\u0027s break so I think we\u0027ll need to leave it there and we can maybe take further discussion of the draft to the list that\u0027s okay um thank you from the chairs for attending this session stay here if you want to attend the next session which is TOS working group starting in about 15 minutes and could we please have the blue sheets back to the front police would somebody bring them down thank you thank you everyone thank you luckily unluckily I have a fun place so you can be elsewhere I\u0027m good I\u0027m gonna stay here ya know so are you here thank you all we know there\u0027s a lot of other stuff going on at all because we\u0027ve been in strike weeks yes Acker was asking me you know do you know what this strike thing is that I said well I\u0027m not sure you do but yeah thank you start about this about the ancients the ones Noah "
  }
]