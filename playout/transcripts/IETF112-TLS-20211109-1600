[
  {
    "startTime": "00:00:06",
    "text": "okay i think we'll get started in just a minute uh just to make sure we're here for uh tls alrighty let's get started um you all are probably familiar with the notewell which is uh with respect to ipr in the ietf um so please take a quick look at this if you're not familiar you know also find it on pretty much every uh thing that you get from the iepf when you're signing up the next thing we'd like to mention here is uh the ietf code of conduct so this is something we'd like to emphasize that we always want to treat our colleagues with respect try to make sure you speak so people can understand using reasoned arguments better than um you know trying to attack somebody's uh person um using your best engineering judgment to find solutions for the internet uh as a whole and we all want to keep that in mind and that people often have different points of view on on"
  },
  {
    "startTime": "00:02:01",
    "text": "coming from different experiences and backgrounds so keep these in mind when uh coming to the mic speaking on jabber or on the mailing list thanks all right do we have minute tankers i didn't notice if we had i don't think we had requested is there somebody who's willing to take minutes yeah rich i'll do it in the hedge dock thing perfect thank you thank you um and i think probably we'll have a number of people in jabber but if somebody wants to speak and doesn't have uh audio access we can relay that to the mic um and again uh state your name when you're speaking and then keep it professional all right so we have a agenda we'll have a couple discussion a couple of working group jazz looks like we've had a revision uh here already um and then we'll have a discussion of of some new work uh that people have brought to the tls working group is there any agenda bashing that we'd like to do at this point any additions alrighty i think the next thing is just a quick uh check on document status um we have a number of things coming up into the rfc editor queue uh there are some drafts that have been in this state in their various"
  },
  {
    "startTime": "00:04:01",
    "text": "states for some significant amounts of time uh usually waiting on uh author action in in oauth 48 or waiting for some revisions the document shepherds will be following up with you to strong arm you into getting some of these things to move forward some of them may rely lying on the chairs too but uh these are things that we want to try to push forward other than that i think you know we have a number of things uh in flight so it's you know good work by the working group good to see that we're making progress in a lot of areas so without further ado i think we will start on our first topic which is exported authenticators you did uh who's presenting that that's going to be me do you want me to run to you yeah could you run the slides there's only there's only two of them so or three types okay let me just uh find them sorry here we go hi so this is nick's draft but i think he's out on vacation um but basically i'm here as document shepard to try to get this document to the finish line because it's been through isg review and we have one loan comment remaining from ben kadek and i want to make sure that we get it reviewed next slide so again we got one comment from ben and uh could basically be summarized um that he noted the are there any security issues um caused by the fact that the exported authenticators is based on the exporter secret which is not incorporate the entire transcript and this issue kind of arose during the uh tls 1.3"
  },
  {
    "startTime": "00:06:01",
    "text": "discussions that were on the mailing list and um nick basically said hey it'd be great if jonathan could look at this jonathan did take a look um he did an analysis and proposed two ways forward uh there's links there's to the emails and the proposal uh the response basically was like hey we could have security considerations to address this or we can change uh how the um exporter works and what he proposed was the security consideration and that's what we're going to review next um and so we've basically taken the approach that since no one has suggested the other option that we're gonna go with this so we we uh um he proposed some text i guess rich commented on it and so i'm we're curious to see that um is this done does anybody want to add anything is there anything new that we need to add or can we just call this closed going once going twice um i did note that martin thompson suggested in the draft that the short answer is that this is fine and that tls 1.4 or whatever the next version will be numbered um might want to include the entire transcript under the exporter secret watson also suggested that it was ready to go so with that i think we're going to go ahead and um go ahead and uh get this merged and get this draft done and get it in the rc utter skew so thank you for your time ecker were you waiting to speak on this issue yeah i'm sorry i'm having trouble understanding what it says so um i'm trying to understand what this says because um"
  },
  {
    "startTime": "00:08:02",
    "text": "like why what what how does how does the service any application data do anything useful here the client the client's final flight is not included in the traffic keys so if i can jump in then kdek i think that the application data is going to trigger the server to reject the connection or close the connection if it doesn't like the client certificate but the ea doesn't involve the client i don't understand this the the severe requests are sent in the channel after the entire time the hinging is completed right the ea certificate request yeah uh can i jump in please the ea request is can be done out of band so it is not necessarily sent after the connection is complete it can be sent for example by the server [Music] as long as it's computed the server finished so if the client then sends back a malformed finished message or something then you're not guaranteed like the server at the time it computes the request doesn't know that the client will successfully complete the handshake okay but how does any application get help um so the only thing that includes the client finished is the resumption master secret so producing a message that uses the resumption master secret first"
  },
  {
    "startTime": "00:10:01",
    "text": "before you make this request guarantees that the client and server already agree on the client finished okay how does any application need to do that um because it's a implicit versus explicit authentication thing once you send your first thing of application data uh the server has to agree if sorry if the servers received it it has to agree on the client finished or it will abort the connection uh i i don't understand this is the server's instant application data we're sending us to request the client and the server is application data as soon as as soon as it receives the client's first flight so the circus application application have i ever even seen the client's second flight right and i think there is a difference between a new session ticket and application data and reading and writing application data thanks dkg in the chat but also but also the nst but the nst also doesn't like guarantee agreement on the resume master secret because you have to resume to get that information what the if i have the for the server to have complete for the server to compute the resumption master secret to produce an nst for the server to manufacture an nst it must have received the client finished no no not i'm not if you're not doing client authentication the servers are supposed to impact on to do that i'm looking at the key schedule now resumption master uh yeah but you can predict the client's final flight if a client is not authenticating correct like i don't understand like this like the server like why aren't you telling the server room don't do it don't do this like like"
  },
  {
    "startTime": "00:12:01",
    "text": "like don't do anything i mean like as you understand like if we want the server not to do anything before receiving the clients finished don't do that like this isn't clear enough for me to like agree it's just like ready to move forward so like i think like like i guess i mean we have to go read the read the issue but like i don't think this text like like i don't think like i guess what i would say is i don't think this text is clear enough to put this specification like we're going to properly explain the issue in a way in a way that one can understand it and that's like that's the condition so i'm happy to go read that issue and try to understand what it's actually saying but whether this class has those in there or not on the specification okay so we'll go back and clarify the text i'd be a place to start i mean i guess i'll try if you issue it to understand it i i tagged you as a review actor thanks that'll work all right thanks dude uh flags are next you up are you here yes sam can you request the share slides you want share i can share if you want what can you request to share oh um i thought you were doing that um where is that right next to the joint cue button there's a request to share a preloaded slides button"
  },
  {
    "startTime": "00:14:01",
    "text": "[Music] yeah perfect okay uh so hi talking about the tls flags draft and so what's happened since the last itf well that's a bad font for 111 so we've gone through uh what we would last call we added the requirement to drop malformed packets and published version 07 that includes this requirement so are we done not necessarily there's three issues that maybe are open so the first one is about the guidance for ayana experts so section 4.1 contains guidance and how to assign numbers to the flags and it's kind of a complicated thing so 0 to 7 is for things that are like everybody has to implement them and i was thinking of uh ri or a new thing like our eye and then we have number 8231 that's uh for um things coming out of this working group or specific requests said to have a small number and then from there on it's uh things that are maybe standards tracks but uh not um are more specialized and then there's experimental it's kind of a complicated thing so martin thompson opened issue number 11 and suggested to remove all advice and leave it just to the discretion of the expert and i think that giving the expert some rationale is important given uh if it's at some point in the future when i'm no longer the expert uh so so far i haven't made any changes to the draft if the working wants to make the chain time we can do it"
  },
  {
    "startTime": "00:16:01",
    "text": "yes martin i don't think i made that specific suggestion what i was concerned with was the very specific set of rules specific boundaries that you'd set so you had no no i'm just running off memory i'm gonna have to go and look at the draft again but there were specific points that you had that you said i have to follow particular rules now flags 0 to 7 have to be out of the working group 8 to 31 have to be standard track documents with very specific conditions on that and 32 to 63 are experimental and and that sort of thing and i think that what you want to provide is general guidance to experts and maybe reserve the top few flags because they're super super important or something but the level of specificity here is far in excess of what i think is reasonable you can see that practically and the ayana people always ask about every assignment they don't just say oh well we figure out through the um the rules and we think you should do that one they always ask so yes eric i i basically agree with martin's guidance which is like if we think that we i mean so obvious obviously like just we're all on the same page um to restate the obvious um you know the resources being conserved is a big pile of zeros at the front of the front of the flags for the fly's word um and so um i grew them t like and first of all i guess like this is already a relatively small idea so that's a better shape than that as long as you don't start like reserving like you know out like wait wait but um the um i mean so i think like my sense would be like let's reserve like"
  },
  {
    "startTime": "00:18:01",
    "text": "zero to seven or zero zero to fifteen like um you know fuel that's appropriate for like working group discretion everything else should be allocated in sequence right after that and if this turns out to be like a nightmare and we have like a usually sparse thing then we can event like a new flags thing with like romantic coding for zeros or something but um but like i just like you know trying to spend a lot of effort trying to like optimize down that last night or two i mean that's the kind of thing ctls tries to do i don't think it's particularly helpful in class i mean the handy is already quite large so i'd be happy with the suggested text to replace where what there is right now in 4.1 there and empty do you want to take that or you don't need to take it i think you had some strong you probably thought it was more than i have because like i thought about it for like all i've been american okay so can we go on to the next issue okay so the next issue about is about the recommended um flag well flag in the uh yana registry so the recommended flag is in the new registry the relative flags is uh what it says right now is uh recommended which is either wire or y or n value determined in the document defining the optional feature and doesn't say really anything about when we should when it should be recommended when the flag should be recommended when it should not the assumption was that it's the same thing as in all the other registries and specified in rfc 8447. so do we need an extra line of text that says so explicitly the meaning is like in rfc 8447 yes joe hi uh hi this is honest yeah i thought"
  },
  {
    "startTime": "00:20:02",
    "text": "it would be good to have some extra text as i mentioned on the mailing list like this is everything but clear like just have something meaningful there um what recommended here actually means like i don't care about it but it really is but but not saying anything i think is not a good idea so we're saying this is the same as what it says in section 5 of rfc 8447 which defines the recommended column for all the other registries well um in in this case it's a little bit different uh because like you are defining flags um which by its own nature already different from um in the general purpose uh extensions like the flags refer to some the need for having something optimized right that's why the flags are defined um right semantically they're just like an empty extension well um i went through the through the the list of extensions and even with uh what with the language from the r from the tls rfc like many of them don't make any sense like recommend it for what so that's what section 5 of 8447 is for means that um oh yeah yeah i can propose some text as uh dkg proposes but uh i i i'm in general against like just putting some columns there and populating with values nobody knows what they mean like and these type of things second i guess uh i'm sorry i guess at least they mean that we expect"
  },
  {
    "startTime": "00:22:00",
    "text": "all or most uh implementations to implement this flag because it's recommended but that's the informal way of expressing it yeah and i think maybe this is something we would touch on with rfc 8447 this discussion later on but i think some of this may be around ambiguity about what recommended means in general or the yes and no i think those there's things that need to be clarified there and i would hesitate to put something too specific in here um when that should be really be clarified in the 447. so that tells that it's a good idea to just refer to 8447 or or maybe quote a line from there and wait for an update to come and update every registry including this one yes john yeah if it's updated in eight four four seven that's enough i think we should not introduce more of this confusing one bit recommended which i think in people outside of the tls working group does not understand what that recommended means but fixing it in general would be even better okay i'm still not getting guidance on what to do with the draft i think this column should look exactly like the column for other extensions and so we should defer this discussion 84 47. and we want to just go especially if we're saying this like whatever the heck we decide like the um you know what it'll be what's applied here because these are as you say just like regular"
  },
  {
    "startTime": "00:24:00",
    "text": "extensions the purpose of the the purpose of this field is not to cons not to say space is to indicate to people what like what things what things itf has confidence in one thing it does not have confidence in and um and you know it's certainly possible to have a one bit extension which you have no confidence in there's everyone essentially says like don't cook anything like we have like very little confidence and that would actually have very high confidence it was bad so like i i don't really think it's possible to have one bit extensions which like we have an opinion on positive or not so um um so um so i don't think that like i don't think that the the encoding really is relevant to this question of what the meaning of the columns is so like my vote is that this column this merely is exactly the same as as the other one and then we can debate like about 20 minutes what the other one means okay sounds good hey john i wasn't sure are you still in the queue um hey i think the easiest thing to do is just reference 8447 um because then you don't have to worry about updating it uh this document if you end up deciding to change the other values because then that document has to update two things so it's probably best just to point and then move on and just kind of deal with it this thing will go in the rfc editor's queue and it can wait for the best document which hopefully shouldn't take all that long to catch up okay right so i'll go to the last issue probably the more controversial one so about dtls 1.2 so i can cross sorry i'm from butchering your name opened issue number 13 asking for the flag extension to be defined in dtls 1.2 as well it's already relevant for tls 1.3 and dtls 1.3 they want it for dtls 1.2 as well this will be useful for dtls rrc return rule to ability check which does address dtls 1.2 as well as dtls 1.3"
  },
  {
    "startTime": "00:26:01",
    "text": "so currently the tls flags is only for the 1.3 versions so up to the working group if we want this to also somehow apply to dtls 1.2 the backstory here is for the working group is that typically when we start working on new extensions the default is that they apply to d to 1.3 and later um and not backwards and then we have to kind of make an explicit decision to go back and try to support something that essentially back port it to 1.2 yeah so one thing the think is that if we do this for one if we add this to dtls 1.2 then we have to have another column that says does this apply to dtls 1.2 or do everything or rather is this flag only 1.3 or well or only 1.2 or both yeah ben i think he sort of started to touch on the point i got you to make which is sort of the scope at which the protocol version applicability is applied over and so you know right now we're saying tls flags extension is 1.3 only and there's there is the conclusion the corollary is that all of the individual flags are also 1.3 only so if we start saying that okay the flags extension itself can now be used in 1.2 um like is the scope of that literally just the flags extension and then we have to say something else about each individual flag or is the implication that all of the flags contained within it are also applicable to tla to tls and dtls 1.2 as well because if that's the case then there's a really severe implementation burden as david benjamin noted where now if you're a dual stack and you want to implement a"
  },
  {
    "startTime": "00:28:02",
    "text": "new flag you have to implement it for both protocol versions at the same time and having recently gone through this exercise for raw public key it's kind of tedious to have to do both protocol versions it can be a fair bit simpler to only work on the telephone 3 version and i also don't think that there's a very strong argument for adding the extra granularity and having each individual flag say is this valid for pls 1.2 or not but i also don't have a great argument against it honest yeah this for me this is really a very practical issue like i was working on the update uh of our implementation for the cid and uh and also this um our this return routability check is is part of that story and we have uh the 1.2 and the 1.3 and the question for me was like i have to provide features for both because both um provide this cid for dtls what what should i do do i have to write a different extension for 1.2 and have and again use the flux extension in 1.3 or what's the story and that's why i was asking for that on the mailing list and in general of course it raises the question of like what happens um with the details or with dls and details 1.2 in general like if someone wants to sort of define an extension and probably this is less uh fewer people want to do that but uh it it will be out in the field for a while because there's it's still a fine brother code like this it's not broken if you use it with the right uh algorithms in the right settings and we have already decided that uh"
  },
  {
    "startTime": "00:30:02",
    "text": "rc does apply to dtls 1.2 it's not just the latest version i guess we could work around the complexity of having the same extension by making this two extensions one flags for 1.2 and one flags for 1.3 and if you want a certain flag to apply to both then you just update both registries and to add the flag to each extension it's a bit more complex but the complexity then dies with 1.2 i guess i kind of think this is a this is a set of paramedic questions um um because no answer seems ideal um uh you know basically it is a is as ben's as a hassle to have half like been maybe been support like this for 1.2 1.3 um i i think if we were going to do that we would have to say whether it's two cup points or one that the flags are valid from one point two and not knowledge one point three and vice versa right um and probably we shouldn't define any that are right home but two only um um you know uh like it's not i think like i guess the question i would have is like you know like is like the people the people who the people would like to have this from 1.2 like how inconvenient is it to like not have it if the answer is like really inconvenient then we should do it and at the end unless the end because because i already heard from david ben and ben and benjamin kadek that's like not that inconvenient to like implement it's just kind of inconvenient and so i don't feel that strongly about it so i guess like you know i like to hear from honest and uh and other people who sort of like like that this is valuable like like this is getting a real pain in your ass if we don't do it if the answer is the"
  },
  {
    "startTime": "00:32:00",
    "text": "answer is yes though you shouldn't like do it um even though like kind of this might um and i guess i guess i would observe like you know you could just not do it echo to your point and that that's where i was going to go is that you know apparently this could be useful well like useful like how useful like you're going to use it every time you you send a dtls 1.2 um you know set up details 1.2 and handshake or not so that's kind of where i'm i'm i'm kind of thinking about this i don't know i mean you actually i mean i guess i guess oh i see honestly to talk about it but i think i i want to appreciate it at home at this point because i guess honestly but most house is about to make a very impassioned case yeah i think it's not for me it's not terribly inconvenient it's just i need to define an um a separate extension for 1.2 and then that means a few more bites over the wire extra coat but only a little bit um so so it's not uh it's it's definitely not the end of the world so i wouldn't uh die for this so i guess we should do do we need to do a hum if the person that was asking the question uh isn't willing to fall on a sword um i'm thinking that we should basically just leave it as is it definitely works for me okay let's go ahead and note that thank you and thanks honest for uh being pragmatic okay so that's the third and last issue that i know about which leaves us with the question if there are any other issues"
  },
  {
    "startTime": "00:34:11",
    "text": "um so in the interest of time i think we should move forward to the next presentation uh which is details 1.3 okay so i'll stop the slideshow what to present which button is that again is that it says presentation paper button the paper button right next to joining the queue oh okay how did i not recognize that um okay uh okay why can't i just talk multiples no i can only share one okay um that would have been awesome um so yeah but uh obviously um i i'm too clear i've heard like temporary bankruptcy any four forty six ps um i just wanted to um i still plan to work on it um but um um i i prefer this meeting i went through a bunch of comments david mentioned had and realized that i was not able to like like produce useful discussion in the time i had available and so i'm planning to do that but like i didn't see any point in requiring us to discuss it um when i wasn't here does anything meaningful um next slide please no it's me isn't it that's right um okay yeah i just did that um it's not used to being i used to have net control so um uh the status of g203 is um that we're all 48 but we've had two celsium issues raised that we thought we had to deal with um and so um this is hoping to get this issues out as fast as possible and then get this out the door um so the first subset of issue um was raised by i'm john matson um uh which is that because gtls has much tighter record limits than tls for asgcm um due to the the um the fact that forgery that that um mass failure does not cause um"
  },
  {
    "startTime": "00:36:02",
    "text": "protection tear down um then um as a practical matter um you have to you have to rekey very often in order to um deal with uh the key extraction but the xbox are only 16 bits which means that the total number of records you can actually send is only about to the 40th which is really quite a small number and like concerning um so um that seems like not um it's worth noting that like um that this is also a problem with details 1.2 it's just that we didn't actually write anything about about the key record limits in dlc 1.2 um so um we're trying to be more rigid about 1.3 um so um we have two poles in front of us um that both kind of are relatively similar um one by uh chris wood one myself though i don't think chris and i are fighting about this we just decided to um to try to like flash both of those people to see them um so um the um first is to expand the outbox to 64 bits which you have to do in any case so that you can re-key more than 16 times um and so the question is what to do with the um with the uh the key formatting for the aead so one option is to just encode the lower 16 bits in the um in the knots so the nods would be um you know to still be 16 bits of epoch and 48 bits of of record identifier um so um this obviously requires you to spend the act 112 bits to incorporate the entire epoch um but it's still the same um it's still the same underlying formatting for the details records um so that's more consistent with gl's 1.2 um the other option is to um expand the sequence number 64 bits use the entire sequence number and the knots um and just remove the epoch entirely um so um i think the argument that i think to try to argue for like what one or the other um the argument i think for um the uh 235 um is it's a simple change um uh and and and you still have the app on"
  },
  {
    "startTime": "00:38:00",
    "text": "the not you know the lower 1650 at back of the knots but when you go to look at the analysis um about um the situation you say what is the epoch doing the knots anyway and um to be honest like this like really really old it was done when we first did gtls i'm not sure we had a good reason um but um the essential which you're thinking about this problem anyway if you're worried about the epoch allowing you to distinguish between different um different key phases well now you have to worry about cycling around 2016. and so it's not going to actually helps and so what you're really saying is and so we went to the analysis we actually said each outback has to have separate keys and that's what's giving you separation between the epochs not having that block bit in the nonce um so the argument for 257 is once we had to accept the keys had to be separate anyway which they already are and we were depending on that property then it didn't matter what that was what was in the knots um and um so uh um and and so and this allows you to be to a um have uh 264 um you know possible sequence numbers if you had a cipher permitted that um and b it looks more like t tl's from point three so it harmonizes the tail some point three instead of being a special dcls um so that's um so that's what we were thinking about when we did um uh uh we when i post this um i think um you know in either case i'm gonna want to run this by um a couple um uh uh on some uh uh um some photographers but we can do that quite quickly once it's written down and we already did run by um the um 255 by karthik um so um uh um i i think i'm seeing scott flores comments um my my impression is because we're also randomizing um we because we randomized the sequence numbers uh we have the xor against the epoch um as martin was saying yeah i don't think that actually as much difference you think so i guess um i think i prefer 2d7 i think that being closer to sales 1.3 is better um than being closer to details 1.2 in this case um"
  },
  {
    "startTime": "00:40:01",
    "text": "and um i did it leaves us with this like this sort of weird work we have like half of it there and we have to reason about it so i guess um what other people think i saw i said mt was suggesting um uh that he thinks 257 is better okay okay anybody wanna argue for 255. okay um then i will find 287 i will um run it quickly by um some of the usual suspects and we will call soup um okay uh next um so this is saying this thing dave benjamin raised um that the um um because the dc so gtl's handshake um structure is different from the dlc structure and it has these three uh fields which are used for reconstruction um uh of the handshake of the firing hand tape messages um and so the question becomes like and so like if you like ordinarily you would say the transcript like consists and so even when you reconstruct the messages what you do um is uh you instead of instead of basically saying we didn't need this framing what you do is you basically set the message question to be what it's supposed to be and then use the fragment offset and the fragment length to be like zero and length and the length of the message right um and so uh um so so these are these are fixed values but they still go in the transcript currently um and they eventually pointed out that this like is a little weird in the message hash um that we use that we use for um you know for hr um and he also pointed out that in this case um it's not entirely clear you convince yourself the tl 0.3 and details 1.3 transcripts like don't overlap in some way because this sequence number and stuff is overlapping with message contents um so um i think david sort of said like well this is just annoying and grumpy but we should like live with it um but i actually am wondering if in line with a previous thing we should just bite the bullet and like say that that the dtls message transcript does not include"
  },
  {
    "startTime": "00:42:00",
    "text": "these um whatever uh uh uh six eight octets um and then it would look the same as the tails with the message transcript um and um so i i think you know um like i don't think it's much harder i think this would not be harder for us in any meaningful way um i don't think hard for anybody else um i know it's like breaking change but i guess like because we had to do some david points out we did something here because we have to specify what goes in message hash and so once we're doing that maybe we should just like live with it and make the change um people are probably getting the impression i'm like trying to eliminate any distinction between one point in detail loss and tails and point three when i count i will say like the reconstruction code has to like it's not like just just the people on the same page like the reconstruction code like has to assemble messages anyway so it's not like it's like it's not like you're like not having to screw up these fields david mt chris yeah that sounds pretty um i don't have any concerns um given especially the point that martin points out in the chat so um uh perhaps i can work with david to prepare pr and here he is [Music] sorry it's been a while since i've used this thing so i forgot which buttons to press um yeah so i guess i i think when i filed the issue i thought it would be kind of annoying to change it around i originally found it just because it was like ambiguously specified it wasn't sure which one was supposed to be um but i guess it's true that the only like by the time the only mess is only the first client hello that ever is in this like ambiguous stage so uh and at that point you haven't even"
  },
  {
    "startTime": "00:44:00",
    "text": "picked the hash yet so you could just like keep the clientele around and just sort of like erase the extra bites as needed maybe it's okay um it also like like we also don't strictly need them to be separable if like well i'm not sure i suspect we don't strictly need them to be separable if all the labels say dtls rather than tls but it is like kind of annoying to have to remember to do that like every time so okay so i'll prepare for this and if someone given there's gonna take a couple weeks to like you know to like finish the other thing like um you know someone could try implementing this make sure it doesn't like vaping explode that'd be great i i don't think by the way you keep the client around very long um just to contact honesty's comment i mean like you did you do the you do the version negotiation immediately so like um so you already know what you're doing it um okay uh i am done the um in the repo there's also this uh uh pull request to address uh sorry to reference rfc 7457 which is the utah draft um i think that the you know i definitely think it's not needed i think you didn't either does there anyone want to speak to adding that as a reference because otherwise i think you should just go ahead and close the close the pr um i was playing close to pr okay uh"
  },
  {
    "startTime": "00:46:04",
    "text": "implementation report who is going to be giving the ech implementation report okay i think we're all set uh echo i'll take the slides away and then pop up vch um [Music] sean i'm going to meet you as well that's okay oops sorry no worries um okay this is a fairly quick update um hello um uh just i guess a quick primer for those of you who are not familiar uh with the protocol imagine you had a normal tls 1.3 connection in which you're connecting to a server revealing um in the sni extension um potentially sensitive information uh about what you're doing specifically what server you're connecting to um uh ech's name suggests is just some mechanism for encrypting that information to the the target server that you're eventually trying to connect to um such that you know passive ease droppers on the on the wire between client server can't figure out any of that potentially sensitive information beyond the sni other extensions in the future might be sensitive um aopn for example might be something you'd like to hide um psk identities that sort of thing um since the last itf uh we sort of declared drop 13 as the interop and deployment target to get some initial experience um to avoid sort of circling on issues that we had open particularly around you"
  },
  {
    "startTime": "00:48:01",
    "text": "know what is the right mechanism for signaling acceptance versus rejection how do you deal with hrr in greece um practically speaking how you would implement server-side padding for the purposes of hiding you know which certificate was actually chosen for the particular connection and there's also been other questions around extensibility in the ech configuration that's published in the https record we've parked all of those open issues and labeled them as such in github uh with the the plan being to effectively get some experimentation um you know experience under our belts and then revisit these based on that experience um to have you know a more informed decision about how complicated this thing is to actually do in practice uh how feasible it is and so on there are a number of implementations uh out there right now um bring us open ssl forks nss um [Music] and so on um some of these are interoperable than others uh others are you know working their way up towards draft their team which is good um if you know of other implementations uh request that you please add it to the wiki you can find the wiki page under the um the esni or ech repository on github um if you can't find it just drop me or the the list of a message asking for and we can point in the right direction but the link in the slides also should work as well um during the course of uh bringing up the different implementations and other people have um sort of been taking notes in terms of you know what are some of the pain points um in the protocol right now uh thanks to note going forward to potentially revisit uh depending on [Music] uh you know how how uh severe the or how how painful these sharp edges happen to be um you know for example uh configuring um"
  },
  {
    "startTime": "00:50:00",
    "text": "uh your stack such that things from dns are plumbed uh into the the tl stack accordingly and parsed and validated in the right way uh has been somewhat annoying there's a there's the required text for checking um the public name in the ech config inside the tls stack which requires you know an ip address parser which typically was or previously was not a requirement for um for most tls stacks uh so the i mean what's currently in the draft right now is is not the best um in terms of uh the technical procedure for validating that particular ech config so it's no surprise that this became somewhat of a pain point uh when implementing things um perhaps we can do something uh in the future to fix it but um you know uh something to be mindful of if you're gonna spit up an implementation of your own um also been noted uh by several people that uh split mode is kind of challenging to deal with as well um not aware of any uh experiments or deployments that are planning on using split loan right now um uh but uh if there are folks who uh do specifically try to implement this use case uh it'd be very good to know um what sort of obstacles you run into specifically around coordination between the front end and the uh the client-facing server and the back-end server um similar to the implementation uh interrupt uh wiki there's a there's a there's a wiki page for sort of tracking these uh these red flags with these sharp edges it would be useful i think it would be useful for posterity's sake if we started accumulating these collectively just so we you know can be mindful of potentially ways to simplify the specification going forward or you know areas we might expand upon and you know the draft and appendix or what have you um for the purposes of helping"
  },
  {
    "startTime": "00:52:00",
    "text": "implementers similar to what's in the rfc 8446 um steven did you have a question or did you want to elaborate on anything yeah just on the on the split board thing um split mode itself was was pretty straightforward um you just required a new api but it was it was easy enough it's split node plus hr that was the problem and the issue was with in particular with h a proxy you either operate as a kind of a tls endpoint in non-split mode or in what they call basically a tran you know tcp mode is what they call it where they're trying to do go faster stripes essentially and in that mode they only look at the first packet so i don't know there's any way to fix the issue that with hr you have to change the second packet as well as the first one um but on the other hand it's presumably when hr might happen more often so it might indicate that what we're doing with hrr is less likely to be of real interest in the real world i don't know but it was with her that was problematic the the basic split mode was pretty straightforward okay yeah thanks for clarifying um no surprise that hr is problematic i guess um uh i think you also raised an interesting point in that um this was particular to particular or to a specific server implementation aj proxy um the interesting thing to know is people are integrating ech as it exists in various tls stacks like boeing ssr what have you into different server implementations um uh what what pain points uh come up along the way similarly for clients you know how challenging is it or not uh to you know plumb this into curl if you're gonna if you're gonna if you were to extend curl to add support for this uh or to browsers or what have you um yeah so you remind me of something i meant to say there which is the it's not on the list i think it's on the wiki page though um with coral one of the big issues is going to be supporting svcp it's not ech"
  },
  {
    "startTime": "00:54:01",
    "text": "per se that's tricky it's all the dns handling and caching that might go around that that i think would be a giant piece of work for carl yeah thank you then hey uh so ssl stacks uh generally general purpose ssl stacks have to have ip address parsing to be able to uh to be able to do certificate validation for ip certificates uh is my audio incomprehensible it's a little bit choppy but so i'm i'm just trying to piece it together i i believe i heard you though okay uh so yeah why i guess i'm i was curious if you had more insight into why all the ip address parsing code for ip certificate validation wasn't didn't make this easy well we mean we recommend a particular parser the the what wg parser um in the draft if i recall correctly um and i don't i don't know um often if that matches the existing parsers that are present and you know uh existing dls stacks or elsewhere in host stacks so it's mainly i guess a problem of you know ensuring parity between what's available and what's expected from the perspective of vch and as you may recall trying to carve out specifically in language what is considered to be a valid or not uh public name um [Music] the world would be i guess a lot simpler if we did not have to deal with this ipv4 nonsense but last year we are i don't remember any more particular details beyond that"
  },
  {
    "startTime": "00:56:01",
    "text": "okay uh go ahead david so the the web with parser did also recently change in a way that's actually probably useful to us uh because uh we realized that uh if the the that you really want dns names to be closed under a subset of other under suffixes um and so we can instead simplify our rule to if the last component is all numeric or looks like hex then reject it which should be a lot simpler than the like go check for like four components or three components insanity that we previously had to deal with right uh yeah i didn't know that thanks for flagging that um uh might be good uh it might be useful to track that um um i guess i don't think that would require a spec change provided that you just implement the latest version of the the wg parser but um but anyways good to know steven yeah i mean i just i only just noticed that the title of the slide here um i think we should there's some really reasonably good news too i think actually because although eh is a lot more complicated internally than the s i externally for all the web servers we've integrated with it it was really really easy to to upgrade him from vs9 to ech um so and we got a drop with with with i think mozilla for about 10 and with boring for 13 without too much hassle uh i'm a cloud player as well i'm not sure what on 13. so you know i think there's quite a bit good news as well as red flags more good news um yeah sorry i didn't mean to uh to cast out on sort of the the future of ech but um mostly just to point out that the few implementation uh sharp edges that have come up um it is good news indeed that it's been relatively easy to upgrade existing servers to support ech as you say um it'd be great if this list was empty but uh you know"
  },
  {
    "startTime": "00:58:00",
    "text": "i can't have it all i guess all right um that's pretty much it um i i you know between now and i guess ihf 113. um i guess the expectation is still still targeting draft 13 for interoperative deployment um and uh as you know client stack server stacks uh you know proceed in adding more support for this we should have a better uh better picture in terms of you know how deployable ech is on the internet at that meeting any questions if not uh i will yield the floor and we can turn it over i think steven your next no sorry joe you're next for a47 no stop okay here we are again so this is going to be a little bit of a re hash of the some of the discussion we had in uh the flags spec so in rfc 8447 we have this uh recommended column uh which is supposed to indicate okay if it's yes then this is an extension or a parameter that's generally recommended for an implementation to support and if it's no it means it's not generally recommended for an implementation support uh to support so on the surface this seems seemed like a a good idea so that you know there were certain ciphers that we we thought were good and then others which we hadn't evaluated or we might think were bad uh"
  },
  {
    "startTime": "01:00:02",
    "text": "that we didn't recommend or were useful only in particular uh circumstances or could only be thought of as secure in particular circumstances um the feedback that we got from here is that well this isn't really perhaps enough information um you know n could mean a number of different things from what hey we didn't it was not evaluated by us it was not recommended in any circumstances this cypher is not safe at any speed can't you know you should should not use it um or could mean that it's only recommended in specific cases um so as we're working on rfc 8447 this uh we we'd like to try to address this issue and make it a bit clearer which probably means um adding uh some additional states in here i guess you'd say so we have a we have a draft out and we have a proposal in that draft that we'd like to to run by the working group here and get some feedback on the proposal is parameters you know if it's yes and we can argue about what the uh what the character here is but yet why right now would mean parameters are recommended for general religious as it is today and then n would mean that they're discouraged um and then we would also include a reference there that to the to the document that says why uh this parameter is limited and then if if the area was blank if there was a space there then parameters would be unevaluated so they would in general be not recommended uh but we wouldn't have any specific thing to say about why other than it's just we haven't gone through the work uh"
  },
  {
    "startTime": "01:02:00",
    "text": "so martin so i was looking at this and it sort of occurred to me that this column is really what does the ietf think about this code point and if if you frame it that way then then maybe the title of the column is you know its status and the values are recommended discouraged or you know no opinion and that gives you the opportunity to to have some statements there about other things if you if the ietf wants to say something else like um limited applicability or something else i don't know can we just say what we mean yeah that's that's a good suggestion uh next stephen yeah i gotta maybe argue the opposite i think the semantics of no can't be defined precisely and therefore has to be vague and i think we can't do any better really because sometimes no means maybe it'll be good in future and sometimes no means we absolutely hate this sometimes no means this is something that somebody else thinks is good but we have no opinion on if we try and get any more fine grained i think we're on a slippery slope and i don't think it'll work so i i would argue for the status quo even if some people find it difficult sometimes life is difficult eckerd yeah i guess i guess i'm persuaded i think that we need to have something more fancy than we have now um i think that like what we have now is innovation and that like it you know it it it avoided us having to like spend a lot of time evaluating things we didn't care about um but um i think it's also clear people are confused um i i think martin's suggestion is actually pretty pretty solid um i don't care what things are called but i think that like the like i think the minimum things we need to be able to say"
  },
  {
    "startTime": "01:04:01",
    "text": "are we're in favor of this we think this is bad and we have no opinion about it and there's many things we have to say and i think there's like room for here were some nuanced opinion like that maybe is only good for iot or something um so i think you know and i think it's clear that the why end thing didn't really work out that well um specifically um so um i think i think empty swirls will be fine um uh you know um i i i think i but i think we probably should just strike the y in the end um okay uh stephen yeah sorry for getting back into again honestly i think no opinion versus bad involves almost as many debates that are pointless as the previous situation and so i i don't think that's going to solve it for us and i don't think it really makes it much clearer for somebody who's going to be confused anyway so you know i think that's confused a little bit yola um right so uh these kind of values make sense for um cypher suites or for i don't know uh different helmet groups like uh yeah we really like uh the 512 bit from one edd sa but this is a yes and the 512 bit rsa is no and we're not saying anything about the brain pool curves that that makes sense but uh for extensions what possible extension are you going to say no don't use that testing standardize that we just added this so it might be a change that we make later to this extension but i don't see how we're making new extensions and making them not recommended with this with these semantics"
  },
  {
    "startTime": "01:06:05",
    "text": "answer that question the the ones that have come up before typically do not get adopted by the working group and then they go to the ise um to get published um but what i got on the queue to say was that instead of having an open-ended um section where we could put it in this column we could also just put notes in the in the actual registry and point so that there's less ascii art problems okay rich uh yeah i think i thought i heard steven say he was against having a no um and i think we need that or when we have yet another die die die rfc that says don't use you know these ciphers okay it wasn't steven if somebody else i thought said no um i think notes as a one of the designated experts is a slippery slope where do we get the note text from um i wouldn't want to write it and i also wouldn't want to copy it blindly from some ise's ise draft that's it turn for any standards draft i think it would be good with a text column to complement this yes no reference that could for example like explain what any limitations would be or for example a specific use case this is recommended for iot and so on that's similar to what ipsec"
  },
  {
    "startTime": "01:08:01",
    "text": "is doing today at least in their drafts but i think that should only be used for standards track not for any individual registrations okay rich sorry i meant to take my hand down um but in the chat i think was watson proposed having a d for you know deprecated and maybe that's a finer grain than n don't know then hi so uh yeah then the concept of freeform notes seems pretty strange because it seems like we a lot of the places where we want these notes are on ise submissions and so we i guess be in the position of writing an ietf standards track rfc that adds a comment to an entry created by an isd commission it seems uh at best hostile and also uh pretty complicated uh i think that uh oh in terms of deprecated uh remember that we can also remove coke from the register um we not that they be free again they just get marked as as reserved due to collision or uh we have various ways that we could potentially notate that independent of this i think what might be most straightforward and clear would be to simply note the status of the mining document in the registry so if we're allowing"
  },
  {
    "startTime": "01:10:01",
    "text": "code points to be registered from documents that are independent stream or standards track or experimental let's just have a column that tells you the status of the accompanying document so speaking just for myself joe what i like about this is that it doesn't take a lot of itf arcane process interpretation to parse those words even if we want to put a little more nuance in it so i think we may need some finesse but top line i like the starting point of just the clarity of of what that might mean to someone that's not steep in in an itf process and back to kind of uh your comment been pre that you previously made to list kind of status i i think that's helpful for inside baseball for ietf but the nuance of what's in isc versus kind of someplace else that's not so well appreciated that's just for us yeah okay great this is a good feedback i think we're also going to present this at sag we may do a little revision of of this based on some of the feedback we got here because this something that may be of interest in general to other groups that face similar challenges there are a couple other things in this draft that i want to quickly uh go through here um the other thing we had added was a a way to reserve uh experimental uh code point range uh that we kind of set aside a temporary uh space where we could assign values that were valid for only a year uh for for kind of larger scale experience experiments um i think you know after some discussion this really probably is is"
  },
  {
    "startTime": "01:12:02",
    "text": "would be better not trying to manage a space separately from ayana but kind of go through the existing iona process and maybe see if we can streamline that a bit i don't know if anybody has any feedback on that particular area go ahead martin so i think this is this is a good direction the the idea that we give someone a con experiment within the experiment turns into success and then they have to pick a different code point and deal with the deployment come from that is is kind of annoying at the same time having the entire space available for experimentation perhaps with a a process that streamlines the registration would be would be a good thing i think we want to encourage people to register the code points that they're going to use and keep that as simple as possible this seems right rich so you got to see my face um i don't think the registration is overly complex i mean sometimes you have to wait you know the email delay for one of the experts to respond but you know it's only like a week or two in general and no experiment that lasts a year is really going to be offset by a week you can always pre-allocate ask for a pre-allocation um i'm just mainly concerned about the you know two places to go for things um and the minute you have to write down information in two places you're almost guaranteed somewhere it's gonna be out of sync right the old comment about code"
  },
  {
    "startTime": "01:14:00",
    "text": "and comments disagreeing um expiration date yeah you know make it renewable a couple years all right so i think for for this draft we would like to do an adoption call after this meeting there will still be some things probably to work out in some of these details but that's it thanks uh yeah thanks joe um [Music] that that that sounds reasonable to me i know there's been um some discussion about this on the list there's been interest in doing this for sort of a while um so uh i guess the the question that we'll ask the list is is it you know what's in the document right now uh pending the changes that were discussed um uh in the last 15 minutes um is it a reasonable starting point for um uh updating april for seven um so i'll work with uh joe and sean to get the document updated and then we can start an adoption call on the list all right um i believe now then this uh unless anyone had any questions or concerns about that i believe now we're uh we're over to stephen um [Music] so stephen you can uh request a share of slides and then i will if you have that so i'm just pulling that there was two drafts i had um back when eth was esi and uh i i'm just this is kind of a heads up and to get some feedback i'm gonna i'm proposing to maybe refresh these with a general substitution of the smi for ech um and then i think last time we talked about this a couple years ago people"
  },
  {
    "startTime": "01:16:00",
    "text": "seemed like okay with maybe adopting them but we didn't do an adoption call so i'd hope to get back to that state pretty quick the text could go into ech as an appendix or something that'd be fine the first one basically just defines a pem format for a private key and an ach config and that's really useful for loading into a server when you want to have multiple key keys supported so you load one file for ech config plus private key pair and then you can load a whole directory of them or do various things um and it's just just a pen file format the second one is a well-known uri and last time i did it i found it very useful to be able to have a web server publish its ech config so that a dns process could pick it up and then publish it if you're refreshing keys and so that was the well known uh the well-known uri one um so that's what i propose doing i'd love to get any feedback i'm happy to do that the next uh little while and then see if the work group want to adopt them or not but if people think this is really not a good idea anymore then i'd like to know that now before i do anything that's all i have here pam thing seems seems harmless but i don't think it needs to be specified here um it's pen file um so um so no i don't think we should adopt that the other thing um i i guess i um i don't know yet until i know whether or not anybody who deploys dns would be interested in it um if they do then i think we could then i think the question would be i'd ask your ids where the appropriate places because that could it's not like a team like a tls thing in particular so um it's not clear to me it belongs here if that's the case um but i guess the question would be like i mean i mean no particular is like epp or something right it's like you know um so um so so i guess you know i guess i i would defer i guess like the answer i try to give is like is if people are interested then i think someone should do it and i would refer to the is where it should go sure i mean but i guess i i think the performance"
  },
  {
    "startTime": "01:18:02",
    "text": "would make more sense here because we're defining ech config it's fair point about the other one i think um you know i think if you have dda dynamic dns you wouldn't need that well not eso thing at all if you don't have dynamic dns and you have some other zone production mechanism that feeds into its own file that gets dns excited or whatever then in our experience it was kind of handy but i guess you could you could argue it could be to find somewhere else for sure yeah like itself or whatever right that's what i'm suggesting i mean just to be clear i'm opposing taking the pen thing um so um um yes i don't think we should take it okay so i don't understand why because i don't think we need to specify here i think it's fine it's internet draft okay i don't follow but i mean we don't it's not it's simply not let's go for this right here okay i still don't follow but we can probably that's enough time for this item probably we can talk about the list i guess okay all i had on this and chairs wanted to devote more time to this uh yeah thanks steven um so yeah uh i mean you went away but uh quickly um if if you can come back how uh how much work do you think it would be to update to ech for either of these uh not much it's just just it's just a case of getting around to it so i could probably get done next couple weeks um yeah i think uh if if you're able to spend some cycles on it just updating it then we we can uh talk with the the chairs um or the other i can talk with the other chairs to see you know um whether or not this is something we want to you know actively pursue here or elsewhere um it does seem like there's some interest in uh at least the the well-known draft um whether that's tls or not i i i don't think it's a a big concern"
  },
  {
    "startTime": "01:20:01",
    "text": "um and um i guess same for the fan format as well i don't know specifically where they used to be but um it does seem that there's uh at least some interest in it so um all that is to say uh we'll chat offline um and come back um with uh proposal for how to move it forward i'll respect the drafts and talk to the chairs as we go from there thanks all right yep thank you stephen okay uh next up on the agenda is i believe um uh the pseudorandom ctos extension out of ben is that that's you okay and i will let you take it away hi i don't see the slides in the in the slide collection oh they're not there um so i'll take another i see export authenticators chair slides e c h zero knowledge proofs it's uh okay so i will try to present for my own screen instead oh uh sorry um i must have skipped over this one when i was importing things hold on it's processing right now oh okay that's that's my bad one moment um okay can you is my audio still crummy no no no it might have been just me um you you sound fine now okay um"
  },
  {
    "startTime": "01:22:02",
    "text": "okay great sorry about that take it away so hi all this is a uh a zero zero draft this is the first time we're talking about this draft the authors are myself and chris patton who's also here and this is intended status experimental so this is new stuff weird stuff so what are we talking about we are talking about an experimental extension for ctls so ctls that's the also relatively new still an underdevelopment version of tls that has a pre-shared template that the client and server somehow agree on out of band before they attempt the connection an extension to that that makes the wire image purely pseudorandom in other words it makes all of the transport contents pure pseudorandom bytes so this is possible because we have a template and because ctls already has essentially an unpredictable wire format where the wire format varies in arbitrary ways depending on the contents of the template that's very different of course from mainline tls 1.2 or 1.3 that has a very deliberately carefully structured wire image this extension sits between ctlx and the transport so the transport like tcp or udp is not modified and ctls is also not modified this is layered between them with the goal basically of simplifying security analysis right all the security analysis that holds for tls or ctls should for the most part continue to hold why might you want such a thing there's a security benefit here so there"
  },
  {
    "startTime": "01:24:01",
    "text": "are these attacks called the nat nat slipstream attacks and also various other protocol confusion or middlebox confusion attacks where where one party causes the other party to emit text on the mid bytes on the wire that are confusing to a badly written parser in the middle so that's uh that's one for concern there's also a privacy benefit here because because each ctls template results in a different wire image ctls reveals which template is in use normally but this extension causes all ctls templates that use this extension to be indistinguishable on the wire there's a protocol agility benefit because if the wire format is fully encrypted then only authorized parties or at least only parties with specific knowledge of this protocol will be parsing it so the current model that we've that we've specced out in our draft is based on something called a strong tweakable pseudo-random permutation or uh sometimes in the literature this is called a tweakable super pseudorandom permutation or a wide block cipher or variable input length block cipher there's a lot of different terminology around this but it's fundamentally just a slightly trickier cipher mode like the usual block cipher modes like aes cbc but more complicated and it gives you one one really big block cipher our extension takes that and applies it to any tls messages that are plain text that aren't already ciphertext and also then to segments that contain"
  },
  {
    "startTime": "01:26:02",
    "text": "both the headers which are clear text and at least 16 bytes of the ciphertext uh this is we chose this setup because it has no ciphertext expansion has zero space overhead so the output and the input are exactly the same size and we believe and and hope to be able to prove that it is still very highly secure in particular it relies on tls's integrity checks so any modification to any part of the bitstream will cause tls's integrity checks to fail so this is just a a quick outline of what we're talking about here this is a typical seat a diagram of a typical ctls stream so you've got a handset handshake message like a client hello that can be fragmented especially in a dtls style situation into multiple fragments handshake fragments which are then prefixed with headers and sent to the other party and then eventually when the handshake is over the the bytes that follow those handshake messages are aad ciphertext output so they're they're already pseudorandom so in our extension we take two steps first we use this this stprp the cipher to render the handshake message itself pseudorandom before it's fragmented i'll note that this cipher this sdprp takes a key and a tweak tweak is a little bit like a nonce but we don't actually require it to be non-repeating it's a it's a key diversification input so first we we insider the handshake message rendering it pseudorandom and only decipherable to"
  },
  {
    "startTime": "01:28:01",
    "text": "and then as a second step we do the same thing to a block containing each bit of the subsequent ciphertext we rely on the fact that every and every message includes at least 16 bytes of ciphertext payload because that's the smallest aead output so the resulting the resulting stream here at the bottom is composed of lots of different kinds of output but all of the outputs are pseudorandom so this is very early days we are seeking working group input most importantly i think on the cryptographic construction here so we've we've chosen stprp for this draft but there are a lot of other options here with different trade-offs in terms of simplicity of description and and also how complicated the analysis is especially under active attack assumptions and we're also looking for input on how to integrate this with ctls in the way that it's cleanest in the way that enables broadest use we do have some requested changes to ctls itself so i sent an email a few weeks ago with a bunch of input based on based on this work things that could change in ctls that would make it clearer in general or that would make this extension easier and we do hope to pursue working group adoption at some point but i think right now really the question is what would you like to see in a version of this that was ready for adoption so that's that's all i have for slides and welcome many thoughts from the working group"
  },
  {
    "startTime": "01:30:06",
    "text": "uh jonathan lex i assume you're in yes i just i was just gonna say i don't think this prevents that slipstream because um the you know the uh so far as the server can force you know the server obviously knows the key stream and can insofar as they can should get a you know select what the client sends as plain text they can therefore select what could set a cipher text which is what you need for for that substrate uh that's interesting i uh i'm going to discuss we had a discussion earlier today in uh transport where we have this might be a problem you know for all of quick too so this might be but yeah so basically you know because you know the key you know you know the key stream in advance um you can just say okay send me this you know take the the cipher text you want xor it with the key stream tell the client to send that and that's you know that's your native stream attack that's uh that's a very interesting observation um i think that we have been thinking about this principally in the handshake messages where there's clear client provided or rather you know source provided entropy each side is providing their own entropy there uh you're right that gets harder in the in the body of the stream so we'll have to give that some more thought thanks for thanks for noting that ecker this is uh quite fancy um and interesting um um those are independent observations not one um so um um i mean i'm not sure i think of the not split screening um i guess um um you know obviously if we're going to expand the data then it's to remember about that this ring um um depending on how this construction actually works um"
  },
  {
    "startTime": "01:32:02",
    "text": "it may be it may it may be quite inconvenient to um uh to to construct the appropriate appropriate cipher text um because i recall you you're probably depending on the um because the aad because because the authentication tag is random authentication tag then becomes input to the the prp then it may be the case that you have to essentially iterate through a large number of plaintext in order to get in order to get advertisers of choice but i wouldn't be able to guarantee that because i don't understand construction well enough um so i guess one thing i should a question about that i'm not sure i understand um is does this mean that a server um that uh uh if a server supports multiple profiles it is then required to trial to correct in order for which profile the client is using that's um so mostly no if all of the profiles share the same key then you can have distinct profiles and still multiplex them right although uh they'll take this check and then the jabber that the uh that the key material should depend on the profile as well that will no longer work that's right the key material deliberately the decryption process deliberately is is profile independent okay after that okay right oh well sorry i think so i think that the question would then be is it required to is it required to is a security reason to have the uh the the so i mean you just see the java paul grabs is saying sharing keys it makes it makes analysis difficult i don't know but like that i'm not sure it's in disaster to have a travel but i just wanted to like to flush that a little bit yeah this is actually the the thing that worries me more is it's not clear that trial decryption is possible because there's no mac um specifically on handshake messages um the handshake doesn't contain its own mac we haven't added a mac so how do you trial decrypt yeah fair enough uh that's one of the open fashions here at the excellent point right right and since details are trying to make it smaller right um max is unfortunate um yeah um anyway i"
  },
  {
    "startTime": "01:34:03",
    "text": "think this is like pretty interesting um you know we've been discussing exactly what we needed to get ctos are aligned to so um i think like you know uh um you know i i guess well i'd like you guys to see before we think about adopting is to make is enough harmonization with ctls which may mean the changes you propose because i i i'll just not even reviewed that we like have confidence that we're not like we're not fighting with you know not fighting each other right yeah obviously this is early days we don't have anything look we haven't attempted an implementation so right well the thing i want to see is um um i would surprise not see this in the specification but i may use that around time is at least one concrete puzzle for for the stdrp um uh because like when i would specification i was kind of like we just don't define one thanks i think like i'd like to see a definition for one even if it wasn't great i'm gonna now be honest i don't want to see but maybe i think imagine you run out of time right um uh so i see my co-author in the queue maybe i'll let him um maybe i'll let chris chime in on that topic right uh chris were you responding to ecker's point there i can go away from chris uh well i don't hear uh i don't hear anything from chris so stephen go ahead okay oh my microsoft go ahead go ahead stephen i was i was just saying uh you're first in the queue so go ahead okay so i i i would encourage further work on this i think it's uh it's interesting i really like how many people this will annoy um um i would encourage you to maybe think about this as a way of kind of pushing the envelope and breaking things for a while at least um and you know see if you did all this and succeeded even ignoring some of the security goals what would you break it would be interesting to learn that um and then last comment is i think"
  },
  {
    "startTime": "01:36:00",
    "text": "as this if you assume this kind of eventually reaches maturity maybe the stage we wanted to be mature is not to have one fixed way of doing it but many many ways that are malleable even after the standard has been produced in an rfc um because the yeah the anniversary in this kind of context is probably pretty uh good at changing themselves as well uh so maybe think about you know the eventual outcome not being just a fixed single interoperable way of doing it but more of a way that you can keep changing what you do and and i like it's a good good work thank you thanks stephen um yeah so about the st prp construction so we were we were going back and forth about this because like uh it doesn't it like we were wondering if this is something that the scfrg is supposed to do or like could we specify our own construction there are like there's lots of options in the literature that i think work really well um and all you really need is aes so um i think i mean i'd be happy to stick a uh construction in in the document um but yeah i guess the question is like where where where should that live um yeah so before i guess uh talking about particular constructions and what now it might be useful to try to identify what are the requirements of the thing that you need um i had been mentioned that you know you you need non-malleability um but now cca security is that necessarily true i don't know um an answer to the requirements question could be useful in helping shape what the actual construction you end up with at the end i think that's true um i think um i think that we it's i mean the the the very informal"
  },
  {
    "startTime": "01:38:01",
    "text": "idea is by tampering with the the bits on the wire you can't predict an adversary can't predict how it impacts what is deciphered and how the server like interprets the handshake so the idea is that like that should cause there with you know you can you can you can probably talk about the probability that the it leads to a handshake failure but you're right like we haven't really worked this out um like like ben said this is super early ecker yeah so i i i would think um uh like for the moment it sounds like it sounds expression's pretty simple so i would just like pick one you like and kind of like set a reference and stuff and stuff and stuff in appendix or like or something i mean there's just like they need to complete then you have a complete specification right um um it's like that i put and then like i could just you know hold up loosely yeah i think we'll do that pretty soon um maybe after the next ctls iteration scott um i would i if you're talking about which stprp you want to use well once you it's up to you to to decide what are the security properties you need from it but once you do it really really that's what the cfrg is there for you really should go to them and saying gee here's what we need what do you recommend i agree uh i think that we ultimately we we would not really progress to publication without a probably a cfrg approved underlying construction okay thank you all right uh thanks ben um paul you're up uh if you guys"
  },
  {
    "startTime": "01:40:00",
    "text": "request to share slides yeah so okay i'm i'm sharing my we discussed this already yeah hi everyone can you see my uh my desktop here can see the desktop i'll let you know when we see the full screen slides all right we can see him now take it away okay great okay uh thanks chris so today i'm going to be talking about uh uh zero knowledge proofs meets tls uh so i'd like to well sorry at first i'd like to say that this is based on joint work with uh urasu arun joe bonneau zach de stefano mike wallfish and yes and i'd like to start by um just saying that i think tls is pretty awesome i'm a newcomer to this uh working group um but i've always been a big fan of the work that everyone here does um and uh i think uh i'd like to congratulate everyone here for uh getting a bunch of awesome um crypto deployed on the internet most notably tls 1.3 um which is an amazing protocol and uh um this i think is a great accomplishment for the working group to get this pushed into more and more places um however i'd like to talk about um the challenges that the increasing deployment of tls is causing and these challenges um are so-called visibility challenges um for for network operators because network operators uh who are used to enforcing network policies by scanning plaintext traffic directly so an example of these policies would be like dns filtering data loss prevention and enterprise networks uh malware scanning and the list goes on and on there's a ton of these um security network security policies um so obviously though by design tls prevents the network from scanning the traffic and enforcing these policies uh so this this this causes a challenge for uh for network operators and so um these visibility challenges are are are pretty"
  },
  {
    "startTime": "01:42:01",
    "text": "old and um even in the in the development of pls 1.3 as far back as 2016 there is this famous well maybe some people consider infamous thread on the tls mailing list um in which a representative from the financial services industry uh came and requested that tls 1.3 retain rsa key transport cipher suites because it makes the kind of like monitoring and policy enforcement that they need to do on their own traffic easier and so this this challenge uh still persists today and there's lots of companies that have kind of sprung up to address these challenges with tls 1.3 so i googled last week and i found this extra hop company um that is talking about security operations visibility for tls 1.3 and interestingly also nist now has a some kind of working group that specifically is is focused on finding solutions to these kind of visibility problems with tls 1.3 um so the solution to these problems that exists in most systems today uh is to just not use tls at all or to terminate the connection in the network uh and uh just enforce scanning on plaintext directly um so there have been some more fine-grained solutions proposed to these visibility problems probably the most mature is multi-context tls uh which changes the tls record layer to a lot of different kind of contexts to have different keys which some of which can be shared with the network or or a middle box to allow them to kind of enforce policies in a more fine-grained way but directly on plain text um other proposals are like enterprise tls which is or like ets which is a protocol that's kind of a variant of tls um that retains some like some some properties of older tls versions that make monitoring easier and there are lots of um proposals based on like trusted heart like sgx on the client or or in the network um but all these solutions basically focus on keeping uh scanning and other kinds of network functionality in the network uh by weakening or modifying uh tls uh so today i'm just gonna talk to you"
  },
  {
    "startTime": "01:44:01",
    "text": "about zero knowledge proofs uh because i think zero knowledge proofs are a really interesting set of tools for addressing these visibility challenges in a different way importantly that doesn't require kind of weakening the security guarantees of tls nor does it require like modifying tls the protocol itself so uh uh this discussion will mostly be centered on a recent paper that my co-authors and i wrote called xero knowledge and middle boxes and i'll focus on a key contribution of this paper which is an efficiency or knowledge protocol for decrypting tls 1.3 records uh then i'll just speak kind of in general about future directions i see for uh zero knowledge proofs and tls um and suggest some other open problems from our work and then finally i'll finish by soliciting some feedback and criticism um and hopefully some maybe some suggestions for interesting applications of xero knowledge proofs to tls so first i'll talk about this this recent work but first i'll give just a very quick primer on zero knowledge proofs uh so zero knowledge proof is a cryptographic primitive that's focused on allowing approver to convince a verifier that a public statement like for example an arithmetic or a boolean circuit uh is true so in the circuit sense this would be that the this circuit has a satisfying assignment so the approver wants to convince the verifier that the statement is true uh without revealing why it knows that it's it's true so zero knowledge proof um is is a is a string like a bit string that the prover generates and it will send to the verifier and the verifier can check this bit string along with this public statement and by checking this bit string it can it can gain an assurance that the approver knows why this public statement is true but but not not why so so the zero knowledge proof um kind of guarantees the verifier that the statement is true but but prevents the verifier from learning um why the prover knows it's true so for example in the circuit case um this this the provers knowledge could be something like a satisfying assignment to this to the circuit um so zero knowledge middle boxes uh"
  },
  {
    "startTime": "01:46:01",
    "text": "use zero knowledge proofs to allow network operators to enforce security policies on traffic without decrypting it um so this is this addresses a lot of these visibility challenges especially with things like like filtering and scanning um in in traffic um so the way zero knowledge middle box works is as follows so when a client first joins the network the the middle box uh gives a description of the security policy to the client then the client when it wants to make an outbound connection to a server uh can just perform a normal handshake and establish a session key with that server then when the client wants to send some traffic the client enforces the policy the security policy locally on its own traffic and additionally uh creates a zero-knowledge proof that it enforced this policy correctly on its traffic and so it sends the the encrypted traffic as well as zero knowledge proof that the underlying plaintext is compliant with this policy and finally the middlebucks can verify this proof uh and block the traffic if the proof verification fails so just to make this setting a little bit more concrete i'll explain a use case from the paper that my co-authors and i wrote so the use case is filtering dns queries that are sent using either dns over tls or dns or https which are too increasingly deployed ways to encrypt dns traffic so in this case the the the security policy would be basically a block list of websites that the the client can't visit on the network and so the client would when they join the network get a list of these these websites and then they would perform a normal tls 1.3 handshake as in the regular dot or doh protocol and then when they want to send a a dns query encrypted what they do is they they encrypt the dns query and send it and then they include as your knowledge proof that the underlying domain name in this dns query is not on the block list and so i want to reiterate here an important point which is that this zero knowledge proof reveals nothing at all"
  },
  {
    "startTime": "01:48:01",
    "text": "about the client's dns query except that the underlying domain name is not not in the block list and so finally the middle box can block the dns query if the proof doesn't verify it that the domain name is not in the block list so how do we build these your knowledge proofs um in the paper we describe a three-step pipeline and in my talk i really don't have time to go into it in too much detail uh but the this three-step pipeline the first step is basically a zero-knowledge like a circuit that can decrypt the tls 1.3 records in in zero knowledge and then in the paper we describe how this these circuits can be composed with other circuits that are kind of responsible for checking policy um so and by composing these circuits you can kind of do an end-to-end policy enforcement on encrypted traffic so i won't talk about that um the latter steps of this pipeline but i will talk about um this zero knowledge circuit for decrypting tls connections uh so the question is how do we decrypt uh tls 1.3 records in in zero knowledge proof um the most obvious way to tackle this is to just re-run the record layer decryption uh in this in the xero north group so basically express record layer decryption as a circuit and just decrypt the encrypted traffic uh in the in the in the circuit so the problem with doing this is that uh tls 1.3 records are not binding commitments to the underlying plaintext because uh tls 1.3 really only supports either gcm or cha cha 20 poly 1305 um and both of these uh aads have the property that you can create craft a single cipher text that has multiple possible decryptions so this means that a malicious client could lie about what it's putting in the proof basically craft a cipher text that has multiple decryptions and then issue a zero-knowledge proof about one of these decryptions but actually send a different one to the to the server so so this this problem of kind of lying in the proof about the key that is used is uh one we need to tackle um so to fix this in the paper we observe that you can use the handshake information um to act as a"
  },
  {
    "startTime": "01:50:00",
    "text": "kind of consistency check with the key that the client gives as input to the zero knowledge decryption um so in the in the circuit in addition to doing record layer decryption the circuit also checks that the key that is given is consistent with the handshake information that was sent on the wire so the question really boils down to how do we build an efficient zero-knowledge key consistency check for zeal for tls 1.3 um and so because uh tls 1.3 key schedule and the handshake are are quite complicated i i could get into the fine details here and i'm sure everybody here would understand them but it would take a lot of time that i really don't have um so i uh would i'll i'll just skip most of the details here uh but i first would like to thank um the dowling at all tls 1.3 analysis paper of like cryptographic analysis of the tls 1.3 handshake for this incredible diagram of the tls key schedule which i think is like this is like maybe the best diagram i've ever seen in a crypto paper but anyway so we don't really have time to get into the details here but uh what i'll say is that the the simple and efficient way to design this key consistency check is to just rerun most of the client's key derivation in the circuit and so in the paper what we what we observe is that this the server finished value basically the mac of the server computes over the transcript acts as a commitment to some the intermediate steps of this key derivation process and so by checking these uh in the circuit we can shortcut most of the expensive operations of the client's key derivation and get like a key consistency check whose cost and the size of the circuit doesn't depend on the size of the tls transcript so i'll just talk very very briefly about the results of our prototype implementation um we talked uh we used uh the xj smart development environment uh and the graph 16 zero knowledge proof system and so the cost of this key consistency check the proof generation um is about 15 seconds and so in the paper we explained that this consistency check really only has to be done once per tls session um which um ameliorates the high cost of doing this somewhat but it still is quite a high cost this is this is pretty impractical"
  },
  {
    "startTime": "01:52:00",
    "text": "at this point however once you do this key consistency check um actually you're doing like per like for the dn the dot filtering um use case i described before the per packet cost of this is only about three seconds per per dns query if you want to prove that your dns query is not for a is for a domain not on a block list um and finally the proof verification cost here is the best um of the three uh it we inherit the fast proof verification of grout 16 so proof verification for the middle box only takes about five milliseconds so the tldr here is that these techniques are not practical yet but they're they're really really close um and there are a lot of interesting optimizations that are possible here so like for example ongoing work uh we're using a different zero-knowledge proof system that reduces the client cost here by about 70x um but there are some some caveats here which i can get into if people are curious and i encourage you if you're interested in more of these numbers or more context to see the paper online um so finally i'll just conclude with some general thoughts about zero knowledge proofs and and tls um so whatever people think of of this this particular research that my co-authors and i have done i hope you'll agree that zero knowledge proofs are a really really interesting tool for lots of of practical uh network security and privacy problems um so zero knowledge proofs are in a really really interesting um place right now as a technology they're they're really on the cusp of becoming unpractical uh practical enough to use real applications so one other interesting application specifically tls could be um in other s in other network security settings it's important to see uh sni values in plain text um so one possible application could be doing like zero knowledge proofs about the contents of of an encrypted client hello um in in um in a tls handshake um and there are lots of other problems here which for time reasons i won't um go over them but there are a lot of other parts of tls that we didn't really uh approach in this work on zero knowledge proof so figuring out how to do things like client authentication in azure knowledge proof would be pretty interesting um and another very outlandish suggestion which i'll i'll just suggest and i expect people to"
  },
  {
    "startTime": "01:54:00",
    "text": "to push back on this but i it would be interesting to me to imagine zero knowledge friendliness as a design consideration for future versions of tls and indeed for other future secure channel uh protocols um so with that uh i'll just conclude and uh take some questions so thanks everybody hi ben schwartz uh so you you mentioned the idea of yeah sorry to see to see the the screen i have to like end the presentation here so oh well that's fine okay uh so you you mentioned zero knowledge proof friendly version of tls can you imagine a zkp hostile version of tls what would that look like um well um the the glib answer to your question is that tls 1.3 is already the zkp hostile version of cls um and that sounds like a criticism and it's honestly it's not a criticism um tls 1.3 is extremely well designed for the the use cases that the designers envisioned um but the the like some some of the reasons why tls 1.3 excuse me is well designed are also reasons why it's it's quite quite hostile to zero knowledge so for example the the kind of extreme precision and detail of the key schedule um is something that uh makes it quite hard to do efficiency or knowledge proofs about because in the key schedule not only do you need to do a lot of kind of hkdf operations uh hk you know you're using hkdf on a primitive like like hmac shot 56 which"
  },
  {
    "startTime": "01:56:01",
    "text": "shot 56 is extremely expensive to evaluate and zero knowledge proof um so the key schedule having this you know there are lots of context hashes and like like label inputs and everything there's lots of like the there's kind of a hierarchy of keys uh this is this is quite quite hard to do efficiently in zero knowledge and zero knowledge proof yeah um yeah i guess another thing well yeah yeah okay thank you but i i can i'd be i'd be willing to i'll stop my head i can't quick question is how lengthy is the zero knowledge proof that you need to send to the middle box yeah great question so um this depends a lot on the specific zero knowledge proof back end that that um you use so for our system the proofs are quite short so grass 16 uh which is the proof system that we use is really designed to produce extremely succinct small proofs so the proofs are only only going to be about 128 bytes um in in our in our prototype um and so the trade-off here is that gross 16 the the the work of proof generation is relatively high that this is kind of a trade-off in all existing um zero enough proof systems is that there's a kind of trade-off between the succinctness of the proof and the work that the proverb has to produce it um so we're exploring like kind of different trade-offs here um like maybe if you were if you were able to accept like a one kilobyte proof you could get a much faster proverb but currently our prototype is 128 bytes per proof i just had a a comment i think the um the proposition that visibility is a reasonable thing to want for tls is"
  },
  {
    "startTime": "01:58:00",
    "text": "contested uh i wouldn't accept it at all myself and i would encourage you to maybe do more research on on trying to make this harder rather than easier and slower rather than faster in other words it would be good research to try and figure out how to improve tls to make these methods work less well uh in my opinion um and it seems like as as good a research goal perhaps not as popular with certain people um so well it's probably hard to publish a paper like that right but sometimes protecting the security of the internet as well i don't know i understand sorry yeah so but my question is so you you you said that uh you have like a 15 second overhead and maybe a 70 x speed up how realistic is the 70x speed up in what time frame can you can you can i give a feel for that um so the 70x speed up relies on a different set of trade-offs for the the zero knowledge per system um so it's you but in terms of time frame do you mean like when could this be deployable or yeah yeah but yeah when might get feasible to be 70 times quicker than 15 seconds overhead per trs session um well the the back end the zero knowledge backing that we're using i mean exists today i mean we're using code that was written by actually like like a researcher at northwestern um xiao wang um so the the 70x speed up um is is the caveat here is that there are other trade-offs so the the middle boxes verification cost is also quite a bit higher in this in in the 70x speed up so you think that you can imagine that like both the the client and the middle box in in this proof system would need to pay about like a 200 milliseconds overhead of proof generation and also verification um so so 200 milliseconds is you know quite a bit faster than 15 seconds of course but to be doing this on every packet on every network packet is probably still impractical so there are"
  },
  {
    "startTime": "02:00:00",
    "text": "um there's a lot of research um ongoing in like these zero-knowledge proof systems um and i think like in the next five years i expect that people will develop techniques that kind of achieve the best of both worlds where you have kind of more succinct proofs but that are also faster to generate okay thanks so my takeaway is that if the tds working group is is looking at trying to make these techniques less effective then we have a couple of years to do it right and we'd welcome your help of course well thank you i appreciate that although i would i if if i can i would just kind of like to push back a little bit on on the the first thing you said about visibility um i think it's it's it's very very natural to um oppose like like efforts towards the kind of network visibility but i think it's important to remember that the starting point like if you are taking a very pro privacy standpoint i think it's important to remember that the starting point here is not tls 1.3 security guarantees the starting point here is really networks where tls is not used at all because it conflicts with these visibility requirements so to me the reason why i think this is an interesting research question and a very challenging one admittedly is that by doing these kinds of like like you know these visibility um by doing this kind of visibility research i think we can improve the privacy of a lot of networks um and improve the privacy of end users who today don't get to encrypt their communications because the network operators can't have this visibility into the traffic uh okay thank you paul ecker um since we're one minute over is it is it quick uh yes um thank you paul um interesting talk i'm looking forward to waiting 15 seconds to uh to download thanks um um"
  },
  {
    "startTime": "02:02:01",
    "text": "so can you say what would what would make um what would make those more friendly to this is it just having committing ciphers or something more fancy yeah yeah that's a good question so um having committing ciphers would help however committing ciphers they actually aren't the best way to solve this problem um they are the way that like kind of in the past people have approached this and like the kind of receiver wisdom in the crypto community about doing verifiable decryption is that you know as long as your encryption is committing then you can just kind of verify the commitment and everything's fine however in this paper one of the interesting things we found is that it's actually if if your sessions are long-lived it's actually much more efficient to do a one-time key consistency check uh and then rather than having to kind of check the commitment in every ciphertext every time you do a proof so one thing that tls could do is send as part of the handshake a commitment to the session keys um even even just as an extension like if if you if you sent this and had both both parties kind of check these commitments um then this whole key consistency check this 15 second cost that i described would go away pretty much immediately because the handshake would actually to have a like like a correctly set up tls connection you would need to check a commitment to the session key and if the middle box can extract this then they can just check subsequent proofs against this commitment that is sent by the client does that make sense uh not for the purposes thank you all right um so we're three minutes over thank you paul for uh you know talking about this you know interesting uh a new take on uh tls and uh privacy and security um sorry for going over time that's our fault this chairs for not managing the time better um uh as discussed in the chat the the paper was shared on the list so if you're curious please check it out be interesting to see how things can be improved or or not one way the other"
  },
  {
    "startTime": "02:04:00",
    "text": "and unless anyone else has any burning questions i think we can wrap up here okay bye thanks thanks folks thanks for our notetaker"
  }
]
