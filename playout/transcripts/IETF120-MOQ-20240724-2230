[
  {
    "startTime": "00:00:03",
    "text": "Thank you very much to say you got it media OverQuick. If you're not here for Media Over Quick, you have lucked out because this is way better than the working group you were trying to find We're here, of course, in Vancouver BC and our continuing our little local sports mascot series the hockey is of course sort of the national pastime of Canada and the local hockey team here is the Vancouver Canucks Canuck is a slang term for Canadian. And they're mascot is Finn the Whale. It's an orker whale, which is a species that's named to the waters around Vancouver And we remind you, the session is being recorded This is the note well. It says that any ideas you ever come up with related to the internet or the property of the IETF And if you believe that, you should probably read the note well We've also been asked to note really well that we should treat each other with respect please address each other as you might if you're going after dinner not as if you were on Twitter Also, you know, harassment is sometimes a problem with the IETF if you are being harassed or if you witness harassment, feel free there's an ombuds team that's here to address your anonymous concerns And of course, there are also nominal authority figures here us, the chairs and our area directors Zahead. Raise your hand, please, Zahead can certainly take any of the, in your concern about any sort of harassment that you experience or witness Okay meeting tips. Again, this is being recorded. You, uh, a good opportunity for you to scan that QR code that is on the screen and be admitted to automatically sign the blue sheet so we know you're here and also participate in the online polls that we conduct and enter the queue also"
  },
  {
    "startTime": "00:02:00",
    "text": "a very important thing please if you're you using the full client turn off your audio and video This is the agenda If you saw it more than 15 minutes ago, it's changed We've done a lot of shuffling between part one and part two or session one and session two of this meeting This is what we're planning to do today It's a packed schedule, and we're going to move briskly This is what we're going to do tomorrow i'm going to go back to the other slide and get anyone an opportunity to bash the agenda if they would like We've been bashing all day. It's not too late to bash them more Alan, I did make a conscious decision a few days ago to focus on sort of higher level discussions As many of you know, we have virtual interims on a very very frequently between meetings that address a lot of low level, you know, draft issues and GitHub things. We will do some of that this week but that is not the emphasis of these meetings Okay, hearing no about know, draft issues and GitHub things. We will do some of that this week, but that is not the emphasis of these meetings. Okay, hearing no bashes, I move on You need to scribe. Who wants chocolate? You watch that things fall off the edge of that agenda as we sit here and stare uncomfortably at each other And as a reminder, we do have a transcript and a video so you do not need to record the play-by-play mostly just recording major decisions or outcomes We can also get you a backup note taker to help This is the only working group that offers chocolate as a reward, so if you're going to get tapped for one at least get paid for it"
  },
  {
    "startTime": "00:04:00",
    "text": "All right, Watson, thank you Can we have a backup here in the room? Can somebody back up? Watson in the room? Thank you, Daniel All right, so you can work out who gets a chocolate there. You can deliver to Watson All right. That would also be painless. All right so now we're going to take a moment to talk about the interrupt that happened this week you want to talk to it no you do it yeah that's why i said me You put me on the right side All right, so we have the draft five was published right at the draft deadline And so our various implementations were hard at work implementing draft five. Right now, at my count we have eight different implementations including a couple of new ones. They were not participating in the inter-op just yet, but welcome to new people who are implementing. I think it's a very healthy ecosystem and most everybody is up on draft four or draft five If you flip to the next slide I tried to throw together a quick matrix where people are achieving interop This is not as organized as it has been in the past, but you can see it people are achieving interop. This is not as organized as it has been in the past, but you can see that there's definitely some amount of five and draft five interop and draft four interop happening across the ecosystem So next slide but i'd like to put out a call uh see if anybody's interested in becoming a new sort of MOQ interop czar where the goal would be to try to get the people who have various sample apps to document their behaviors in drafts. MOQ chat does have a draft but for example, there are three different clock or date sample applications that are all different"
  },
  {
    "startTime": "00:06:00",
    "text": "So getting some of that behavior documented would be helpful, defining an interrupt use cases, so what various parts of the standard do we want to demonstrate interop on not just basic publish and subscribe, but some of the far-flung reaches of the spec that maybe aren't seeing as much love maintaining that spreadsheet or matrix instead of me having to throw it together hastily at the last minute, and then you talking here at these meetings instead of me So we could really use some help. So think about it. It's a great way you can help if you're not, you're looking to contribute to MOQ more and looking for a place to jump in, especially if you like in rob and we can offer chocolate for the scribes benefit Watson he was talking about the mock chat MOQ chat draft that's the one he's referring to um Just out of curiosity, do we have someone who's instantly willing to volunteer to be interrupt czar Okay. Our ancillary request is even in the absence of a czar if you have an interop application, if you could like write a draft i don't think we've any intent to make that go to RC or anything, but just writing down in some fashion how the thing works and like how catalogs are and what the track theme conventions are, et cetera, would really make interop work a lot better because we have, it's hard for us to get these implications to talk to each other without those Okay, so next, as you may have noticed, on the Zulip, we have a, we are actually live stream this via MOQ So I think Jordi is going to say a few words about that Yes Yep, Martin Mennon mentioned, so we are live streaming this event using MOQ is the, as far as I know, the first public live stream in MOQ is quite exciting. It was working 30"
  },
  {
    "startTime": "00:08:00",
    "text": "seconds ago when I was sitting there, so I hope it's still up and working So we are planning to stream this session and the next session on Thursday. Lower your expectations, it's an alpha stage and if you're trying here in this Wi-Fi yeah, you're probably not getting the best experience And please provide feedback. It's just an experiment then we want to get feedback and make it better better so if you are curious about the setup this is the hardware setup so it's a just a webcam, USBC connected to my laptop we are getting the audio from the audio and video crew. It's just the mix of the whole of the whole meeting it's also captured in my laptop and it's running. Then my laptop is wired to an IETF so because we find we're trying to stream with Wi-Fi, with this Wi-Fi is not going to work at all. So it's wired to IETF net network. IETF network is connected as far as I know with two gig with Wi-Fi, with this Wi-Fi is not going to work at all. So it's wired to IETF network, IETF network is connected as far as I know with two gigabit links to Internet. Thanks to Akamai that we are running a MOQREL relay in Los Angeles. There is another note in Madrid but this is the one to serve the web pages. So the important part here is the blue one, there's the MOQ path So the relay is in Los Angeles and then if you connect to it, you will be connected to that relay in Los Angeles. So next slide pages. So the important part here is the blue one. There's the MOQ path. So the relay is in Los Angeles and then if you connect to it, you will be connecting to that relay in Los Angeles. So this is hardware. So this is software. We are running MOQ encoder player that it's an open source implementation from meta. You can find it in GitHub in Facebook Experimental or Metexperimental, I think it's called now The relay is Moxygen. It's also a meta relay open source by meta and then the player is the same code as encoded player. So next slide more interesting details for the MOQ fans here. So the encoder is just a JavaScript browse up that uses web codecs to manage media inside the browser and web transport API to the MOQ funds here. So the encoder is just a JavaScript Brows-up that uses web codecs to manage media inside the browser and web transport API that implements the MOQ implementation The stream that we are producing, it's a single stream, no AVR 8554 by 480 30 per second, encoded"
  },
  {
    "startTime": "00:10:00",
    "text": "in H264, 750 kilobits and audio it's opus we are using LOC content Not exactly the draft is a bit modified, but hopefully we will be able to just put some changes in the in the graph or clarify the draft and then that will be that will be the pure LOC and it's working on draft zero four and that's the encoder you if you're curious so the relay as i said moxygen c++ it's based on meta production battle tested production, open source also libraries like Proxygen, Mufus, Wongal Fies and Foley, DraftO4, obviously, and no priority is implemented yet. This is important. So if there is a network issue you will see video and audio failing Theoretically, when priority is implemented, you will be under network constraints, you will see video failing but not audio. So next slide And this is what you will see. If you open the link that i will that it's in the in the chat so you will see a player it's a JavaScript web codex also web transfer you will you will have uh you can see the lower right you can have different options to select for latency You can play with them and see how performs in different latencies This latency is basically the jitter buffer, the jitter buffer, sorry will have, you can see at the lower right, you can have different options to select for latency. You can play with them and see how performs in different latencies. This latency is basically the jitter buffer, and that's it. So, next slide this is the link it's also in the MOQ chat in Zulip. So and this is the QR code if you want and let me just thank the IETF, the NOC and METECON and Encore, the ABCrew, that help us to set it all up. So thank you Thank you, Jory. Any questions? Okay so we're delivering media ever quick. I guess we're done Yep. Good night, everybody. Going to last call and All righty. So next our area director, Oso Gently suggested that we should Friday sort of"
  },
  {
    "startTime": "00:12:00",
    "text": "check in on their overall status and the big picture of MOQ and our progress, and so Alan is now going to deliver that Uh, so thanks everyone. I'm just kind of a level up just reminding everybody like we're the progress we've made so far, where we are right now, and kind of a rough sketch maybe of where we're going to be spending our time that maybe the rest of the year And it's obviously an open discussion Next slide So where would we come from? I'm a QT. I know we've been working at this a long time, but draft zero zero is over one year old. So we've only published in adopted that draft one year ago. And since then we've been a lot of big improvements. We've gone through two iterations of how we're going to do subscribe parameters I think we're going to have another discussion today for what the third version will look like. But we spent a lot of time working on what the object model is and how that interacts with transport Object status, I want to say that we had a very successful interim in June where we came up with what I guess, the priorities, maybe call it V1 priorities, but people seem to be pretty happy with the outcome there, I think, and so excited about that and then there's been many many mechanical and editorial improvements to the draft in a year. So there's been a lot of progress even though sometimes we know that we like to argue with each other and it's kind of slow uh they're looking back i I'm so very proud of what we've gotten done. So next slide And then we think about the other higher level things this group is doing, like we've achieved consensus on how we're splitting up the transport the catalog, container, and streaming formats and agree on this sort of layering. We've adopted the catalog draft and we have these active IDs out there for both LOC and work Next slide So where we are right now, we're getting a lot of feedback from people who are trying to implement the draft and doing this"
  },
  {
    "startTime": "00:14:00",
    "text": "center-up testing, and that's resulting in a pretty high volume of issues coming through, which is good People are using it and finding the problems, and that's why the IETF runs on works on running code. So just the last 90 days we've got about the same number of issues coming in as going out, and given that we have a high number open um we'd like to we think that there are a lot of issues out there where there's been enough progress where we could get a PR and get consensus and we might need, there's already about eight or 10 that are marked needs PR there's probably another several, another set that could be so can I maybe get a show of hands people who are like would not mind being assigned to write a PR by an editor is that something people interested in? jon peterson is going to help us, two, three, okay, four. All right, sort of the was maybe hoping for a more enthusiastic uh risk what's that get the names i see Cullen and Mo and Suha Haas and Cota and did i see a hand over here christian hopps um saw Colin and Mo and Sue Haas and Kota and did I see a hand over here? Christian. So maybe there's some virtual hands too. So I appreciate that and hopefully that I think if we can nail down a few more corners of the tent, it'll be a little bit easier to make progress on some of the bigger things that are still outstanding So we'll work with the editor to sign out PRs to write and then we'll use the weekly interim time to review it those and hopefully make some progress mike english as raised the hand virtually. All right, that's all those good say editor to assign out PRs to write, and then we'll use the weekly interim time to review those and hopefully make some progress. mike english has raised the hand virtually. All right. That's all I was going to say. All right. Thank you So where are we going? So we've been spending a fair bit of time, though, since in the last couple of months talking about the partial reliability model things like cash duration and delivery timeouts I think we're getting close there. There's PR's up I don't know they're going to spend that much time resolving it here or not but hopefully soon we can we can land that we've talked about also that we need to talk about the semantics of stream re-"
  },
  {
    "startTime": "00:16:00",
    "text": "up. I don't know that we're going to spend that much time resolving it here or not, but hopefully soon we can land that. We've talked about also that we need to talk about the semantics of stream reset, which kind of also fits in this partial reliability aspect. So I think that's something that's probably more or shorter from thing we'll pick up. Earlier this year, we started this discussion about fetch versus subscribe and we didn't quite reach resolution on it. I think there was kind of an intentional choice to go after partial reliability and priorities first and then circle back because hopefully it would make it easier to see what we need. And there's other subscription related issues that we've hit, like, subscribe done is a big problem deduplication of tracks, how we're going to resolve track alias and subscribe ID. So it seems like maybe from our perspective, one of the bigger rocks that we're going to look at soon And then other sort of big issues that we think would probably consume our time going forward, and this is where they're certainly welcome working group feedback to publisher related issues things like make before break or how you discover multiple publishers like we've discovered through my Mach chat or other um meeting type applications we know there's a lot in the security and DDoS space, we see things in the issues about flow control, about limits, that kind of thing. And authentication is another area where we have not spent much time. So those seem like some things. I don't know, if anybody wants to jump up and mention something else, they'd really like us to see add to this like near-term rest of 2024 roadmap or send feedback to the list also Image of Ian And, oh, Colin, go ahead. Look, this is hard to say whether this is a small thing or a big thing but that look ahead parsed issue that, you know, I think that that's a very valid issue. I don't know if it's smaller a big thing, but that look-ahead parsing issue that, you know, I think that that's a very valid issue. I don't know if it's small or big, but I wish that that one got dealt with It was the PR, the issue that Christian raised on look-ahead parsing I would like to see that solved sooner rather than later because I think it'll be harder to solve later. I think that's good I think that's one of those issues that where it may be is ready for someone to write a PR"
  },
  {
    "startTime": "00:18:00",
    "text": "and maybe we can deal with it But like this class of, yes, I forgot to say my name, Colin Jake but whatever. Yeah, no, I know which one you're talking about anybody else want to comment on mopt things that want this group to tackle shortly? Okay, next slide And then higher levels, I know Will's going to talk later today about some of these things, but just catalog seems like we've adopted it it seems like it's in a pretty good place there's the issues being addressed there, but the next step there's probably some kind of basic interop. I don't know when would be a good time. People are interested in working on that. So I know MOK takes a lot of the oxygen, but that's probably the next step there LOC is out there. I just heard from Jordi that it's like part of the demo that we're using. So it's it's important work for this group, so we need out there. I just heard from Jordi that it's like part of the demo that we're using. So it's important work for this group. So we maybe should be thinking about the path to adoption and that it sounds like maybe it needs some updates Warp is our highest level thing we're looking forward to update today, but it still feels a little bit further away in terms of how much time we have and what people are going to be able to focus on but again curious if people see things differently along these lines All right, I think that's all hand have. Thanks, everyone everyone Oh, our esteemed AD 80 Jahed, thanks Alan for doing this. I actually request you, we are starting actually requested it, so you deliberate it so, and I loved it So I think this is a nice way of getting this work group to get in like in a course of like what we it so, and I loved it. So I think this is a nice way of like getting this working group to get in a course of like what we're doing right now, what you have done and where we are going and and i actually the intent my intention was to actually get us all agree on this. This is how we were working actually like there are not much like and where you are going. And I actually, the intent, my intention was to actually get us all agree on this. This is how we were working. Actually, like, there are not much dispute about that one, like how you, you should"
  },
  {
    "startTime": "00:20:00",
    "text": "you deliberated that one. So I think this is really good Thanks for doing it anyway, ma'am anyway ma'am. Next up, we have Ian, who's going to give a very brief run is really good. Thanks for doing it anyway, ma'am. Next up, we have Ian, who's going to give a very brief rundown of what has changed in our most active draft since our last meeting All right. Next slide uh so two updates uh has changed in our most active draft since our last meeting. All right. Next slide. So two updates, 04 and 05 work slide uh so two updates uh four and o five uh were uh done between the two drafts um And so the big we did subscribe V2, which makes the old subscribe, which people complain were scurundously complex into something slightly simpler but still meets the core use cases, such as, you know, starting at head and such We also added subscribe update, so that allows you to update now say the priority but originally kind of the range of objects that you're requested in a given subscribe So next slide So the big one here is the priority in group send order 470 which I'm going to go over in just a sec in a little more detail we also did some terminology updates. Thank you very much, Alan You know, so I had some errors and added object status. So object status isn't interesting one because that allows us to specify when an object or group is missing explicitly instead of it just having it be a gap and you don't know why it's there So this says it's missing but and it's you're not going to get it essentially We also added a track status and a track status request It's sort of like a head request in some sense It tells you what the most recent object ID that's been published is So next slide So, yes, the priority in group order The subscribe now has a priority"
  },
  {
    "startTime": "00:22:00",
    "text": "field between 0 and 255 The subscribe also has a group order field which can either be ascending, descending, or default So default indicates that the publisher kind of gets to choose Subscribe okay specifies the publisher's preferred group order, again, which is used if the subscribe specify as default. And the object headers had a priority field before. Now we have a well-defined use of that field and so the framing does not change, but we actually have text to look like to do with it and how to treat it. And as a general rule, the subscribers' preferences are considered as being more important than the publishers And under the theory that it knows what's viewport is and such, but if a subscriber wants to defer to the public, preferences, then it basically sets everything to the same priority. And you know, the group order to default and kind of what's the publisher do what it wants. Next slide I just wanted to since I fell into the trap of the priority field did not change in 05. It actually did. It's no longer a variant. It is down a bite so um yeah, that was an interrupt bug that I had. So it did change ever since slightly. And thank you for Victor for sending a priority of better than 62 Thank you, Ellen Okay, next slide so this is a kind of a short summary of text that we wrote up during actually on day two interim on day two. Cullen in particular was working hard on this, so, you know, we wrangled this quite a bit but approximately what happens is for all subscriptions with data to send you first select a subscription a first subscriber priority if they're equal, then look at the publisher priority at both of them are equal then the implementation kind of"
  },
  {
    "startTime": "00:24:00",
    "text": "chooses which ones a sentence So we didn't specify exact round rather than our anything like that. There are a number of other reasons why you might choose what to send but that's how you select which subscription to send on. But then the selected track slash subscription, you select the group if it's ascending, you pick the lowest group ID, if it's descending, you pick the highest group ID. And then within the selected group, you always send it increasing object ID order. So you select the spot smallest object ID And that's a quick summary of how kind of priority and the group send order feature that were added in that PR work And thank you to everyone who worked very hard to hash out an awful lot of detail and think through an awful lot of edge cases So, I mean, at least so far, I'm quite happy with the help you to everyone who worked very hard to hash out an awful lot of details and think through an awful lot of edge cases. So, I mean, at least so far, I'm quite happy with that sort of itself out Mike, uh, Chi Can you say, actually ask the same questions with Alan Mandi Mops? meeting? I rest through the draft and then for the object definition, it has payload and metadata here. And then I rest through the metadata field got like group ID object, the track, all kind of the good fields. Just wondering, why in the draft, does not define some extension field, like in the meta-data field, if you define some extension, that is just a live away later for like a VSE, for whatever to extend. Not going to a affect the MOQT itself but just leave some field as extension Just say, okay, this is like the field lens and then some bunch of, okay, whatever you want to define So have, has a group that, uh, our thought about"
  },
  {
    "startTime": "00:26:00",
    "text": "it. Talk about extensibility for things like object headers in particular? Yes there is a metadata in the object header. There is actually an open issue I believe, for I mean, I think the straw man proposal is to put the properties sort of chunk of data like we have in the handshake setup and the subscribe and put those into object I don't think we've had a use case that's so compelling that it's been worth doing yet, but you know, I can certainly am imagine it coming along and, you know, at my mind, a compelling use case would make that more complete Maybe after meeting, I can give you a very good use case that has been discussed right now in the 5G domain right now. Okay. Sounds good. Thanks I put the issue in the chat if you're curious. Thank you, Alan i have those are my five minutes Cullen and- Oh, sorry, nope, that's not all I have who still electrocated this thing uh Cullen jennings, just a slight tweak on your last line there. I think that in- have. Oh, just electricianity did this thing. cullen jennings, just a slight tweak on your last line there. I think that inside of the group, we actually prioritize by priority and then object ID is what we have in the draft I'm not sure that makes much different things, but I thought I might mention it because it becomes relevant tomorrow. I will fix the slide and re-upload. Thank you. No word much. No, no, you're right. I got the work mo zanaty, on the metadata, I think there's a very compelling use case that we've been struggling with in the low overhead container draft And that's whether to put things into payload headers or whether to migrate them up to the action object header and the biggest decision point there is whether or not we ever think a relay may need to operate on that data. And it's a double-edged sword because there's going to be some people in the community that don't want to expose any information don't want to make it visible to relays, and there's going to be people that say, well, this is essential for high performance you know, routing and decision-making"
  },
  {
    "startTime": "00:28:00",
    "text": "in a relay. So I think for the LOS draft, it would be very useful if we did start considering some sort of extensibility mechanism for the object header to allow metadata from the other drafts to poke in there Yep, thank you I just wanted, there's a note that the note takers that hedge talk may be down right now, and so if somebody can create a public Google document, There's a note that the note takers, that hedge doc may be down right now. And so if somebody can create a public Google Doc quick, so we don't lose notes until hedge- doc comes back up and just paste that in the chat So someone can, we have a place to go. There we go Watson's got it. Thank you thank you all right next up will be Will who is joining us remotely I find his slides remotely I find his slides. There we go. All yours, Will? Thank you very much Just brief audio test before I launch into the ether. Can you hear me? Yeah, the audio is not wonderful that. I'm not sure if that's your end or ours ours Your mic is overly hot, Will We had that pop in ADP also. I don't know if Meetecho Meetecho can help us What about now? Tasting, tasting, overly hot mic. Overly hot mic the PDP also, I don't know if Meetecho, Meetecho can help us. What about now? Tasting, tasting, overly hot mic. That's better. Thank you. Any better? Okay thanks for the advice okay if the audio gets problematic, just interrupt chairs and I will try to adjust things here So, as mentioned, we're going to start with two ancillary specs, which is the catalog format and also warp following that. These are a warm-up to the actual transport that's coming later, but I think we're going to start seeing the next layer of interoperals suggested at the catalog layer. This was purely a hypothetical format until a couple of weeks ago, and I see Luke started"
  },
  {
    "startTime": "00:30:00",
    "text": "implementing it, and it's now in quick talk video, so it's progressed beyond that stage. So it's great that people are using it and I think the more use we get, the more practical and functional it will become. Next slide, please so for the gender I've got a lot of trying to fit and I'm going to go quickly through these. I want to update you on all the change since IETF119, the PRZAT that have been merged then we've got two PRs for discussion and three issues for discussion. I didn't want to move back update you on all the changes since IETF-119, the PRs that have been merged, then we've got two PRs for discussion and three issues for discussion. I didn't want to move those issues to PR because it's not clear what direction we should go to be good to get some feedback So that's the agenda for the next 15 minutes Next slide, please So yeah, just a reminder, actually since last IETF, we did adopt catalogs so it's located in it moved from my repo into ID draft and we're on also on the standards path for this right now. Next slide So I did merge. We expanded the IMA registry of the catalog fields I used to have a big broad table. I had to reformatted down edict characters. So it's it's much longer now, but essentially we're putting all of the entries into an ionic table. This will allow for extensibility in the future We can add them without having to issue a new RFC I think it's a great move, and there was no contention on that. Next slide We also added a new field to indicate of Delta updates. So to be expected by a client if it needs to be able to pass them It's very simple. If Delta is expected, you pass it billion true. If it's omitted, then it's false. It's assumed to be false And this helps people write simpler players that can abandon playback if they know they have to part Delta updates. Next slide Yeah, I added a new real object to hold an inheritable track fields. It basically takes repeated information"
  },
  {
    "startTime": "00:32:00",
    "text": "and moves it to a header in the catalog Very interesting. This is going to come up later in another issue where there's a move to actually retract this But for now it's been merged and there's actually arguments as to why we may not want to merge this So we'll address that shortly. Next slide uh there's actually arguments as to why we may not want to merge this. So we'll address that shortly. Next slide. PR 64. This is one where I actually want to discuss it. So the current spec defines a fixed table of packaging formats So we've got a stream of data, a track. And in the track we have objects to carry payloads and we want to tell the client how these are packaged And we put an INA registry in with two for CMAP and LOD lock, which are two most commonly requested packaging formats however these are very media specific right they don't support gameplay or other data-centric users that will have packaging or formatting even that's got nothing to do with CMAP or lock. And there's more attributes to how you put stuff into the payload than simply the packaging. So the PR replaces the term packaging with the term for CMAP or lock. And there's more attributes to how you put stuff into the payload than simply the packaging. So this PR replaces the term packaging with the term format, which includes packaging, but can be broader if the implementation wants it to be And I'll show some examples on the side. You can you can the term format, which includes packaging, but can be broader if the implementation wants it to be. And I'll show some examples on the side. You can make up these strings and the strings are defined by the application format. The streaming application format if it's a media application or your game format if it's a gaming application So I don't believe we need to put these into a table but that would be an open question to the group. Should these be I on a registered? or can they be at the discretion of the application? My opinion is they can be at discretion. We already have a header field in the catalog that allows you to dictate a version of your application and that particular version can define the strings what's allowed, and what should be in there Victor, for comment. Uh, I sounds different the common thing is useful So, but it doesn't mean that"
  },
  {
    "startTime": "00:34:00",
    "text": "you cannot put like your own saying, but it should not conflict well defined ones That's typically what we do, since those are stream identifiers, you have a lot of flexibility in such regard. Okay just a quick answer to that, though, but we consider these much like we the version of the the application which is defined is much like a name space for the form just like we have a name space and name so I might call mine CMF, you might call your CMAC We mean entirely different things, but our namespace, the top of the formats, just like we have a namespace and name. So I might call mine CMF, you might call your CMAC. We mean entirely different things, but our name space, the topple of the namespace and the format then define the means That would be the only counter argument to that. I have no objection with creating an eye on a table. It's fine Lucas for Q yeah maybe um just something. But I'm sorry, why not you? media types? Like if you're going to do something on now, I know, doesn't it? entire thing already well would we define something we have a mind type, which is a separate selection parameter that's already defined so mind type is in a field called selection parameters and it's there with audio and video frame rate. It's also this is beyond mind type, right? Your mind type, you can still within a given mind type vary the format or or how you package it so this provides a little bit more flexibility than simply mind type alone, and my type's already included Suhas? Two comments I think packaging was fine name but I'm okay with the format. On the I and I think they should be something that should be in the I know we can we was fine name, but I'm okay with the format. On the I and I think there should be something that should be in the I know we can, the things that the applications want to they want to experiment with they don't have to register with Ianna but when I when I say I'm using lock i it would be nice to specify the"
  },
  {
    "startTime": "00:36:00",
    "text": "draft that defines lock not something that's on my GitHub, but that's an RFC. So having something with INA register that says lock means go refer to this draft would be used for entropy ability Okay, fair point Victor again Yeah, I was going to comment first on the application saying Just because there are a different application doesn't mean that like, they don't share the same thing So for instance, there are billions of web apps out there, but a lot of them just have like PNG images, and that's a common So it's kind of similar to my type. The reason I believe we should not reuse mine types is because mine types are defined for things that look like files It is there like solid sequences of bytes where MOQ is for things that structured, like MOQ tracks, they have groups and objects and those kind of bindings. So you cannot map a mime type to an MOQ track because they're just structured differently. So that's why I think we should generally avoid referencing those Thank you, Victor Collin Colin Colin Johnson, look, I'm sorry to be raising that this is sort of the knit on the format or something. So on your slide, you have code colon opus in the selecting parameters What do you call that? Because in Kodontopus, alternative have Kodak colon opus in the selecting parameters. What do you call that? What is it called opus or thirdic or selection? What do you call that field, that type field that there? Because the problem is, is RTP calls that a format, and you're using the INAF format registry for that value So there's certainly possibility, even mean, you're going to have, I think this term might introduce real possibility for confusion Maybe you want to use mock format or something instead of format because like on that same Deason structure, you have another thing that's going to be format. Okay, could we use?"
  },
  {
    "startTime": "00:38:00",
    "text": "track format? Sure, sure format or something instead of format because, like, on that same Deason structure, you have another thing that's called format. Okay, could we use track format? Sure. Because it's actually described as track format and then it's just the stringer's format, but when you read the PR, it says this is the track format Look, I'm just flagging the issue. I don't really care how you resolve it, including not resolving it at all. But it does seem like a potential for some confusion There you are. OK, I like that suggestion Thank you. Bernard Yeah, to Collins some confusion there you are okay i like that suggestion thank you uh bernard yeah um to to to colin's point i think this may be the codex string what we call in WebCodex the codex string, which wouldn't be just AV01, right? It would be the full code string indicating the profile tier and level and stuff like that that's yeah i the little dots ellipses mean i trunk and level and stuff like that. Yeah, the little dots for ellipses mean, I truncated it to make it fit on the slide. But it's meant to be the full code string same as we use for MSE, for example for example Mosenati, this is an area of a lot of confusion People that are implementing law, first question to me was, how do I know what codec it is? And I'm like, well, look, doesn't specify the code that's in the catalog. And I said, well, how do I map the? catalog, you know, codec to something? The reason why I don't think mine types are appropriate is because these aren't really mine types These are probably things that are never going to be specified by the IETF. These are most likely to be specified by other streaming bodies and there's not a need for an INA register to duplicate all of those strings WebCodex actually does try to enumerate inside of itself within W3C, some subsets that they think are relevant but I don't think that we need to duplicate that in any INA registry. We just need to be explicit about what are we referencing. If we're referencing some other normative specs, we need to say what they are Right now, that word codec is not the codex string from any body. That's just the word codec"
  },
  {
    "startTime": "00:40:00",
    "text": "as another tag in the catalog spec, right? Well, it doesn't actually reference the codex string in a body. Yeah it's in the catalog spec, it's a generic field where you can put information related to codec In a streaming draft such as warp, it's very explicit about what value you put in for codec And it references the external spec that's says defines the string that you're going to put in there. So, my idea is that the catalog is generic enough that it can suit a whole lot of applications. And so it's those applications that make the specific references as to the values that go inside these fields If we don't do that, we end up with a a... I think this is maybe worthy of having the relevant people form a little mini design team or meeting about all the things related to packaging, to formats, and descriptions of them, I think need to be fleshed out and agreed between the different streaming formats and the catalog itself. So I think it's probably good to have a little design team for that because it's not clear at this point especially implementers trying to implement it, have come back with a lot of questions about it. I'm going to close this queue soon, so come in if you want to get in in So, yes, I see think I have to agree with saying, don't use media types for the format that's probably because you have both the container kind of aspect here, I think, just in certain cases as well as, as well as saying, duplication of media types yeah RTP has had its problems over the year. I would actually suggest that you define this as a URN, and then you can define an IETF prefix, URN prefix for standardized formats if you have such And then anyone can ensure that it can create a unique ones themselves if there's external formats"
  },
  {
    "startTime": "00:42:03",
    "text": "Okay, thank you, Mattas Okay, I'd like to move a good with a lot more material here. I heard arguments for and against Diana and I heard the suggestion that we established a design group for this I think that's a good suggestion. There's been good comments raised and that's what I'll do after this meeting. Next slide please Right, TL 63, adding a type at attribute for tracks. Hopefully this is less contentious So there are a number of use cases where it's very useful to be able to specify the type of a track. For example, to declare it to be a data channel or a timeline track This is again within the scope of the streaming app application or the game application that is using the catalog to describe its mock content The idea here is that type is a stream. The field is optional. Any application using catalog would need to define the allowed contents of this string. And I showed some examples here on the right. And then the question is, do we want to set, firstly, do we want this? And secondly, do we want this? allowed contents of the string and I showed some examples here on the right and then the question is do we want to set firstly do we want this and secondly do we want to set a max length just to prevent abuse and help people parsing this? Important question are those types always application specific? Yes Yes, they're defined by an application So it can be Victor's special type for vectors special application and it has meaning within that. I assume this is actually really easy to solve. You don't need to define this. All you need to do is let applications put a I think this is actually really easy to solve. You don't need to define this. All you need to do is let applications put any fields they want because that just makes it sense and we can do that and then application can put type fields or if it doesn't want type, it can have like two types or it can make type an array if that's what it needs or whatever. But like as long as you let applications to add"
  },
  {
    "startTime": "00:44:00",
    "text": "their fields, there is no need for like standard field name type so just so i can repeat it back, you're saying that the catalog should be extensible by the application, we define a base catalog, but then the application is allowed to add jason compliant fields at any point, and it's up to the client which is understanding that application to know how to parse and use the information in those fields and that clients that don't understand that should ignore those fields is that correct uh yes and i kind of assumes that you can just put them already Okay thank you uh Luke yeah sorry if you can hear anything in the background, but yeah my use case for this is uh just type safety like implement parsing the pet catalog and we have like a video track and audio track right now any track can have any fields, like an audio track could have a width And it just makes it harder to actually implement if everything's on optional and everything's undefined. So I would like, you know, I understand what Victor's, you know, saying is like catalog should be generic but i guess within the street format or something, like we should define like what does it mean to be an audio track or be a video track? Like, you must have a sample rate or something like that Instead of just leaving it to be a big blob of Jason nothingness that we just barf every time there's a weird field in there The same for selection forams as well, Victor I would like to standardize like codex string will exist something you know like so I know that not everything is undefined But should they be defined in the application specific? or in the catalog specification? I mean, if you want interrupt somebody has to define it somewhere. I think if we just treat this like an opaque Jason blob, then interrupts impossible Right, but we're going to interrupt around War"
  },
  {
    "startTime": "00:46:00",
    "text": "works, say. We're not going to interrupt around necessarily around catalog for that is and maybe that's a statement or not a question but if we interrupt around a street format, then that streaming format defines all these fields what should be there and then you write your parser against that. You don't write it against the generic catch I'm going to close to you soon, so get up I keep one in. Mosinati, just like we talked about extensibility for the object header and the data plane, I think it will likely also be extensive needed for the catalog my only suggestion and i agree with victor that there'll probably be some app that want tom strickx their own JSON blobs in the I want to suggest them to be, let's make it very clear that the different namespaces. So if we have like an X dash pre or something like that for the application, you know custom extensions i'd like to not mean the IETF standard special fields with, you know, some vendor fields. So I like different namespaces for those if possible Good point Okay, let's move on Please, these are PRs, so feel free to add comments to the issues and we'll try to follow up based on the notes. Issue 46 add a new field to allow suggested relative track prioritization. We actually need this based upon what's been merged around priority. We had no means for a producer to suggest to the client what the relative track priority should be. So it's a simple numerical value lower numbers equal higher priority, catalog should indicate it. If they supply it for any track, then they should indicate it for all tracks. Otherwise you leave the client in an ambiguous state. You can apply equal priority if you so choose the absence of relative priority field should be interpreted by the client that all tracks"
  },
  {
    "startTime": "00:48:00",
    "text": "have equal priority to us i think this field is important, but I would say, uh, should be, it must be provided if not what's the default priority is not known I have two applications who are trying to try to pick try to pick the same thing for two different values for the same tracks it might not work so i would basically say have the priority if it's provided it's good if not it's an error Okay, just I think that the default priority could be that they're all equal is that an unacceptable default student right like we don't know what's the value of that one right But the value is relative, so it doesn't matter. You're going to make it all one or all four or all eight because it's, they just relative to one another within your subscription your connect your connection and your subscription. So if you apply the same number for all, of them, the absolute value of that priority doesn't matter Okay. I'm just trying to see if I send a subscribe for one of those tracks what value should I put in there? they're all same i know but what value should i put in there should it matter or should it not matter? If it's absent yeah I think your streaming format should suggest to you that, hey, put a value of five or one or three or bigger number okay i think in that case we should add that some note there if it's missing an application streaming format might define something if not like when I when I send a subscribe i have no idea what to say because this we use catalog or something the catalogs we will pass the catalog until my more clear saying subscribe with this priority for a given track the application can pick a default priority if it's not there but one way or the other way we need to make that clear i agree with you thank you"
  },
  {
    "startTime": "00:50:00",
    "text": "Okay, next slide So this came in pretty quickly. I mentioned we added a PR to add common track field. The idea was to compress the catalogs size by removing or referencing report information running once. Look made a comment that it complicates its parser, that if we really want to make catalog smaller, we should just shift to binary and away from Jason which is a good comment. And the request there is remove comment track fields and simply repeat the elements. So on the left-hand side, you see a simple implementation with only two tracks and on the right you see the information repeated. Obviously, the complete if you had 10 tracks or 1,000 tracks, would be a lot better but i buy the argument that if we're in the JSON realm, we're not too worried about the size here. So I'm actually in favor of this and I'm willing to make a PR to remove it as long as this some additional support for this Conjunct Jones. Yeah, I mean, I just think that this is the stuff, like, until we see that we need this, this is just sort of like, let's optimize this later, not now So I'm sort of in favor for me By the way, mic one camera for the online audience is now super blurry. It's like a single pixel Okay. So no objections. Watson, who just spoke? that was Colin based on voice because like oh it got clear now. Right, next slide, please Streaming format should be a string and not an inch. So this was common from jonathan hoyland Scott. Currently, so if you look at example number one a streaming format is an integer defined in a Niana table. And we've got notice we've got three fields. We've got the version of the catalog, we've got the stream format identifier, and then we got the streaming format version The proposal is converted to a string"
  },
  {
    "startTime": "00:52:00",
    "text": "which is fine, and then to limit it to ASCQ asking characters so which is version 2. I would prefer to keep it used to support non-Western character sets but otherwise going to a string I think is good Proposal three is, if one, we're doing this, we can coalesce streaming format and streaming version into one, right? Make a string that's got a number in it It's a contract between the application and the public and the player so you can put both version and format in there and that's example three and then proposal four is actually remove the catalog version field because again, that streaming format as defined there is going to tell you what catalog version you need to use so we don't need to repeat that information so the suggestion is to move to sample four here but the proposal is as was shown and probably is number two Thank you Escher from Apple. I was trying to log in the queue, but something that was going wrong I would strongly argue against option four, because this is not user interface This is a protocol identifier and numbers have the properties that somebody has to allocate them so you don't have a collusion Strings are a bit more wasteful with space but they can be mnemonic they can be convenient But as long as they are opaque protocol identifies their machine-to-machine communication engineers may look at them, but normal end users never do Supporting UTF8 and all the other arbitrary scripts, comes with a whole bunch of"
  },
  {
    "startTime": "00:54:00",
    "text": "problems and it's not worth it A similar example from my experiences with DNS service discovery service types they are US ASCII strings letters and digits cases insignificant They're expressive enough that they're usefully mnemonic but they don't have to be unlimited length and they don't have to be unlimited character set so I think that's a mistake. I fully support UTF8 in user interfaces, but not for on the wire protocol Great. Thank you You make a good point, and that was a vote for, I think, two with the constraint to asking Colin I was going to go the same direction of, like, the UTFA will just have bugs in interoperability bugs, subtle interoperability bugs forever because people won't test it with the hard cases So I would not want to do that. And I mean, as a general thumb, anything that can be separated into Samantha different things, I prefer them see them separate in semantically different fields. It just seems easier to reason about you know, you can ask if things are greater than are equal And I'm thinking about the cases where you're supporting more than one version at a time and you're trying to migrate from an old version to a new version. Those are the cases that I think may be easier I don't have a strong opinion, but I want to think about those very carefully I don't see the reason to embed the version into the string. Like, it just you know, if you can't separate, maybe you should. So Thank you. Moe. that is I specifically don't want to merge the catalog version with the streaming format version. I think it's semantically incorrect and you want to be able to parse the catalog by knowing what version it is But the streaming format version may be"
  },
  {
    "startTime": "00:56:00",
    "text": "different and it wouldn't affect your ability to parse the catalog So I don't think we should ever mix the catalog version with the streaming format version Okay. So I heard pretty strong consensus for option two here keeping the values separate and then having some type of ASC restriction on the contents of streaming format, but it will be a stream. If we can add that to the note Next slide, please That's the last slide. That should be the end of the deck. Yeah, I realize I got warnings about our time, but we still have a war to go to. Can I get a few minutes for that? You can have four minutes Thank you Do I have that slide? slide back? It has been uploaded yep Or maybe you have to approve it. It was uploaded about six hours ago If you don't want to burn time, we can go to someone who slides you've got and then I will just message you that directly Well, would you mind just bump? to Thursday? We have a little more space there for that discussion Yeah, that's fine by me. Okay, thank you Thank you Okay, next up, we'll be, uh Colin talking about secure objects I'm standing in the white box, not the pink box Okay, so this is really about sort of"
  },
  {
    "startTime": "00:58:00",
    "text": "our end-to-end encryption of how we encrypt this data. And if you want to logically think about this, I'm talking about the equivalent in the RT, you know, this is to SRT and RTP, you know, this is sort of the SRTP equivalent or a proposal for that here. So next slide, let me talk about this a little bit So, this is, what I want to get out of this today is not the details of whether this drafts the right way to do it or something else This is basically S-frame this draft, but is I want to get of like, you know, whether people are willing to be today is not the details of whether this draft's the right way to do it or something else. This is basically S-frame this draft, but is I want to get of like, you know, whether people are willing to move forward with something along these lines or not So first of all, I want to make sure it's very clear what this is not This is not common encryption or CMAF or anything like that Like all this is not trying to replace those or get rid of those For the people who are, you know, trying to do those types of things they'd keep doing exactly what they're doing in the first place. They'd never use it this. But for a lot of cases where we are trying to do more video conferencing type application, or some of the other applications, many of these might be using lock, in fact, they have some need for a more end-to-end encryption of our objects. And the reason why is this stuff flows through a lot of relays. We want to be able to use a lot of different relays, and all the relays have access to the unencrypted objects, okay? you know we we don't want to have them looking into them or anything but it does go flow through them. So there's a goal that how do we encrypt this end to end now the other thing that we want to do, and this is the same as SRTP, I mean, you could ask like, why don't we just take RTP packets and encrypt the with S-Mine and then send them across And the reason why is they would get a lot larger with S-Mine than they would if you use something like SRTP. And this is a simple proposal here. It's an argument that the existing mechanisms that we have floating around expand things enough that for small objects, particularly audio objects and things like this,"
  },
  {
    "startTime": "01:00:00",
    "text": "we probably want to do something a little specialized that keeps our band So the king, the is just a symmetric king mechanism, or just a symmetric encryption The keying and those types of things is a separate issue I'm not talking about that in this draft at all. That would be, you know, you'd use MLS or something else to set up your keys, but once you have a keys, this is how you do your data. Very similar model to to SRTP again. So next slide You know, the key thing that we're dealing with here is one way or another and how this done is, is use an AED encryption mechanism but use our existing information about the full track name and the object ideas in things to help not have duplicate counters in there and use those to generate the counter so that we don't expand our bandwidth usage substantially And that's roughly what SRTP does. Okay. And we could we could talk a little bit about how these are formed and make sure they're secure and stuff Obviously that would happen, but I just want to get to the big things. So, I'm going to know next slide for a second. I don't think I really want to talk about it. I mean, I just want to mention that when we talk about low bandwidth, I mean, audio code are dropping fast in, in how, low rate they're going at and this becomes particularly relevant for like satellite links to some of these other elatant links, long radio links, Laura, free links these types of things. So back a slide And with that, let me, let me open it up for questions here Hey, madameara, Apple. Uh, I'm not sure why not adapting as a frame? because this frame was implemented just for these use cases So go to the last slide on this deck OK Okay, so Richard, who's standing beside you will notice"
  },
  {
    "startTime": "01:02:00",
    "text": "doubt comment on this too, which is, you know, doing S frame So algorithmically, this is the same as S frame but we need to define somewhere, like go back to do more slides. So this is basically, oh, no, this is fine. Sorry I'll go that slide. Stop moving around. Okay, we need to have something that says how you take a group ID and an object and you put them into S frame or deal with those types of things Okay, like the S frame does not know what a group ID is or an object idea is. We have to have something to wrap up in there so as I said this is based on S frame and I'm totally open to how we do that and whatever. That's not what I'm trying to get to here And if somebody wants to propose something completely different than S frame, like we should go use something else. I, you know, sure, fine. But I'm more trying to get, do we do this concept? and do we move this forward, S frame or not? If it just header or just had a header extension of this frame, I don't want to like go through the same conversation with having S-frame again right? Yeah. So the short answer is that semantically like, this is S-like, you can do this with S-frame You want to end up computing the S frame key ID encounter based on some of the stuff that's already present in the mock headers So I've got a PR on Cullen's doc to basically replace the crypto innards with S-frame So there's no invention here So your intuition exactly right, this is S-frame, but there's a little bit of compression you want to do so that you can leverage stuff that you're already trying innards with S-frame, so there's no invention here. So your intuition exactly right, this is S-frame, but there's a little bit of compression you want to do so that you can leverage stuff that you're already transmitting as part of the mock headers And I wrote this draft by copying S frame. So, okay, but I'm mean, the only question is floating around is, by value or reference okay but that's like that's irrelevant towards the overall concept here. So, I mean, I just like to get some feedback, you know, do people see this useful? Can we move? forward with something like this or not? Oh, Victor. Oh, sorry sure where I would use it, but this is definitely seems like highly useful I'm not sure whether we need KAA or in every object or we can put it in the catalog, because it sounds like"
  },
  {
    "startTime": "01:04:00",
    "text": "we could make the same as simple and as minimalistic as possible And the only question that's hard is do we truncate the off tag? or not yes the off tags and look this is definitely i imagine this being optional in the sense that the catalog tells you whether you're using this or not, and certainly lots of people would never use it including probably everyone, probably every C. Matthews case Did you want to answer Victor first? so the short answer Victor you can't just use the track ID as the key ID because you are answer, Victor, you can't just use the track ID as the key ID because you will want to, in a situation where, you know, like with MLS where you might be having different receivers over, different sets of receivers over time, you probably want to use different keys over time to encrypt the same track Mosenny. So I took this as an instant of S-frame in the mock context because there are key context fields that you need for every, you know, end-end encryption scheme like S-R-TP and everything else. And so this defines what those key context things are you know, where the key, where the key, where the key derived, where the nonsense has come from, how are they derived? And so this binds them directly to the mock object model and on the wire fields So this to me makes perfect sense as an instantiation of S-frame, so I don't see it as competitive at all. On the on the way that it's laid out, this is something I struggle with also in the low overhead container And I think just like we said, that mock may need some extensibility for the header object header fields. I'm wondering whether we actually need a trade an object trailer as well just like you know just like a HTTP and other protocols, you often you"
  },
  {
    "startTime": "01:06:00",
    "text": "often have header body trailer header body trailer and in encryption is a typical example where you have exactly that header body trailer. You always want these off tags as trailers So wondering if we need to explicitly have these trailers instead of burying everything inside of opaque blobs of payload headers and payload trailers, should we actually just expose what the headers and trailers and trailer? trailers instead of burying everything inside of opaque blobs of payload headers and payload trailers, should we actually just expose what the headers and trailers are in the protocol? I mean, our experience in RTP would certainly suggest we did it the wrong way there and that we should deliberately expect it, yeah. I'm going to close the queue very soon. Suhast, please be brief. Yep Suhast, let's go. I think to the metacvah, question that colonel you're asking should we do something uh close the queue very soon. Suhas, please be brief. So, Haas, Cisco, I think to the meta question that Colonel you're asking, should we do something, a symmetric option encryption that does not work? Cisco, I think to the meta question that Colonel you're asking, should we do something, a symmetric option encryption that's out, that does not work for a real-time conferences like, WebEx I think we need to do something on those lines. How will we use as frame? i think that's once once we adopt this one we can figure that one out Okay, thank you Colin, can I ask what? you're, are you asking? for the working group to adopt this work? You want to iterate some more as an ID? What is your planar vision? here? I mean, what I'd really like to do is ask the working group to adopt it, but I think that there's probably some people that would like to see the details of how this is connected with S-frame resolve before that happens, and I'm certainly willing to go work on a revision of the draft that particularly address that issue. I hadn't thought at all about what Mo suggested, but I think that's a very positive idea that we go to and figure out how to deal that, and that's about general extensibility of Mott. So it might be figuring out both of those issues and then see if we're at the point where we're ready to adopt Okay. Mo, maybe I'll ask if you can file an MOQT issue, if you want to, so we can have a discussion there about whether we need trailers in the transport and then it sounds like we'll look for enough"
  },
  {
    "startTime": "01:08:00",
    "text": "update of the draft and discuss in upcoming meetings going forward. Thanks. Thank you for bringing the work Last stuff, we have Victor to talk about his experience trying to implement subscribe V2 yeah so um am Victor. I'm good, so subscribe v2 is uh uh one that's in draft 05 and the subscribe format itself is an improvement over what was it previously there, but there are lots of issues with how it's defined and specifically as a case that are underdefined And I'm going to talk about some of those. So next slide So currently a subscribe has the four modes of things that you didn't subscribe, you can subscribe to current group, which is all of six stars starting with object zero of the current group, the current object Absolute start to infinite and absolute start with absolute end, which is you specify the exact right of objects you're subscribing to So the easiest to understand and the one that I think we kind of got correctly is the current topic subscribing to. So the easiest to understand and the ones that I think we kind of got correctly is the current object, because the way you do it is you look at your track, you figure out what largest delivered top object is either because you're the original publisher or because you're subscribed in the original publisher told you what the largest delivered object is because it's a field and subscribe okay uh then uh original publisher or because you subscribed and the original publisher told you what's the largest delivered object is because it's a field and subscribe okay then you either do or do not say current object, it is unclear from me from this spec whether current subscribing the current object implies actually sending the current object or the object after it And then, like, you just forward both of the, you know, object that are after that object"
  },
  {
    "startTime": "01:10:00",
    "text": "So the next slide is the difficulty comes in when there are ranges, especially ranges of objects in the past. So right now it is possible to send subscribe to something like Group 1000 to Group 2000 and assume we have stream per group and assume that this track itself is like already far past Group 2000 but the original publisher actually can all of the thousand groups and it is not clear what's supposed to happen So if you're subscribed to the life objects, the life objects will arrive to you basically as long as the rate at which those objects are generated can be sustained by all links in the path between you and the original publisher and if it cannot be sustained, you're already it already doesn't work so that's fine Now, the problem with subscribing to a bunch of existing stuff is that if there are thousands objects, the most naive thing you can do is you can send all thousands of them at once, and that would be really bad because even not just it's unclear whether the link supports it. What will happen is you are blocked by quick flow control. So you will be able to send like 100 streams at best. And then you have 900 streams that are queued and they're taking up bandwidth and space from possible more important real-time data that actually even priorities don't fully solve it because priorities don't quite solve So that is like really naive solution of what you could do and doing that is a really bad Ian, do you want to"
  },
  {
    "startTime": "01:12:00",
    "text": "to finish the slide or do you want to speak now? I was just going to clarify on this particular slide. I think with the group order if you follow the algorithm, you would need to be able to send all the data on group like 1000 then all the good data on group 2001 1002, and so on and so forth. So I agree this is possible, but the, I mean, you'd have to have a huge congestion window unless these groups are enormously small I'm not saying the problem in general, like I think there's the shape of the problem you're spelling out is is true but I think the example is a little bit. There is nothing in the text that doesn't say that you cannot open a stream for Southern 1 if you have Southern Open Well, it says to write it first. Yes you'd have to open. That's why I intended to write whatever you have Southern open. Well, it says to write it first. Yes, but you'd have to... I don't know. That's why I intended to write when I wrote the text I guess if you're doing what you're doing here unless you have enough congestion window for all 1,000, streams and their payloads, I think you're doing it wrong is my personal opinion. Or based on what I tried to write you're doing it wrong Oh, so I'm going to jump this in Victor didn't have an immediate answer. I just noticed they've got a couple of people in the queue and please remember maybe we should try to keep the questions to clarifying questions so that Victor can get through all of his slides in the remaining 17 minutes Yeah, actually we have like a space for clarifying questions like in a couple of slides okay um mo and suehaus you want to keep it brief? Or Victor, would you prefer to just run through everything and then take questions? toward the end? You can go, Victor. Okay so one saying that want to keep it brief for Victor, would you prefer to just run through everything and then take questions toward the end? You can go, Victor. Okay, so one thing, so the problem here is that not only like, not only it's unclear whether you can"
  },
  {
    "startTime": "01:14:00",
    "text": "open those strings, but also you have to somehow fetch those from the back end. And when you're facing from the back end, the problem, like, is if your backend is a the strings, but also you have to somehow fetch those from the backend. And when you're fetching from the backend, the problem like is if your backend is in the cloud and very fast, that means that the backend will be able to send those streams to you faster than you can receive them. So now you have to do something clever about that And there are some solutions I tried, like I tried the things at the end mentions that where you like only write stream 1000 and do not open stream 1000 thousand one until you are done with stream 1000, but even that is complicated because that means like you you have to manage how you fetch all of those streams for backend and you really want to pre-fetch some of those in advance and it all becomes a huge mess and it would be much easier if we could solve it on a quick layer uh next slide So there is a bit of a related issue where there I'm not sure how to explain it but this happens when you try to subscribe to current group is that if you subscribe to current group and like right now you say it's a year current group as a stream one, it's like an object one 1000, what could happen is a your relay and you're like, well, I am supposed to send object zero to however big this group current group is. I don't know, it's not finished So I probably evicted like some of those beginning objects from cache So now since the subscribe, I have to subscribe to like Livehead, but I also have to try to backfill And the problem is that as I backfill, the head can move further and further. And the means for that single subscribe to current group, even so though it sounds simple, I can subscribe to current group, but I have to do this like"
  },
  {
    "startTime": "01:16:00",
    "text": "fetch loop of fetching more objects from backend in case they get evicted faster than I can send them Next slide slide And the third problem I have with subscribe is that it's like the semantics of what has And the third problem I have with Subscribe is that it's like the semantics of what happens on objects that do not exist are not clear. So for instance, if we're Group 1000 I request objects 100 to 9,100 and this group never had more than 10 objects, do I send nothing? Do I send 9,000? objects to say object do not exist or what happened? The second one is the if there is a bit of ambiguity between objects, that were will never exist and objects that do not exist yet but might be missing and if I'm doing stream per object mapping and I receive every odd object from the upstream, that means I'm missing like five objects and I have to have this really large data structure to track those in whereas what ideally was I would do is for objects in past I would ask fetch and fetch would tell me for every object definite status uh next slide so this is so those are the three big issues and I want to hear what people think whether those make sense or how do people do So this is, so those are the three big issues and I want to hear what people think, whether those make sense or how do people deal with those Thank you very much, Victor This implementation experience exactly matches my thought experiment of why the subscribe is doomed whenever we have anything other than what Mach was intended for, the Live Edge. So let me briefly explain what I mean. The live edge is coming at media rate The live edge is coming as the media is being produced. So that means it is not"
  },
  {
    "startTime": "01:18:00",
    "text": "Vod. You would never ever do this about if you're doing VOD those are fetches. Those are not those are not subscriptions. Those are fetches. So I think preserving subscribe only for the mock Live Edge use case removes these problems that Victor has. And for furthermore, when you do a fetch, more like an H get or something, there's an assumption that we're delivering all of that at line rate and fully in parallel. If you did fetch, 10 fetches, you'll get 10 parallel fetches. That is most likely not what the application wants. And then you're going to have to have some extension to mock to say, okay, deliver at media rate or something like that. And I think separating that from subscribe, it makes a lot more sense because I think there's different machine for fetch. It impacts the priorities. It impacts the delivery rate it impacts the congestion control between the catch-up streams and the like streams. It impacts the availability of the objects in the cache And what decision points does it really make? Do I go back and get? something or not so I think limit subscribe to only live edge not even current group not even saying go back to the beginning of the current group no the current object is all you can subscribe to or this beginning of the next stream. I think that would obviate these problems uh so how's this go thanks wicker uh i think this took me back to denver interim because this is this is this were the exact same problems why will myself and you and others we started talking about fetch versus subscribe? And this there's very clear semantics and rich semantics for fetch as more more was pointing out you can basically control the order you wanted to be delivered how it you want to be delivered, and those kind of semantics does not apply to sub- subscribe when you when for live data So anything that has absolute range or something in the past very well fits with the seminar and we can define what kind of behavior we want there But overloading the same thing with subscribe is the exact same problem"
  },
  {
    "startTime": "01:20:00",
    "text": "we are re-treating after implementation experience that proves that we have to solve this problem. Thank you Okay, Colin and maybe keep it brief, because Victor has some more slides Oh, okay, sorry. So I Okay, Cullen and maybe keep it brief because Victor has some more slides. Oh, okay, sorry. So I'm of the thought pattern that the best way to deal with this is for things in the past, they should come for each time you request things in the past you get one stream and all of the data comes over that for exactly what you requested and that it's prioritized in a way that makes sense relative to the stuff in the future and that we handle past and future fairly separately. I don't care whether the method is called So subscriber Fubar, but that we're the text of how we handle things in the past and how we handle things in the future are impossible to be the same Thanks, Luke Yeah, I was just going to say for the fetch suggestions, Fetch has to be pretty radically different like what Cullen's proposing. Otherwise, it's fair similar to subscribe. You're under the same flow control issues if you try and request more objects than flow control allows You know, you have the same cache problem like the cache being empty. So I do think that there's a world where we can make this easier, but I don't think just magically saying, like, we only support old objects is going to fix it. It's a little harder than that Okay, thanks martin duke, practicing for the Olympics martin duke is an individual so victor on your slide about um requesting tend with you know up to object 1,000, and the right edge goes to 500 current group will just give you the whole group, right? Or is the point that you won't? you want to stop after the group? Well, we're going to give you the whole group. The problem is like current group might be very long, and if you're back filling, you might be the group will give you the whole group. The problem is, like, current group might be very long, and if you're backfilling, you might have to, like, continuously backfill it from back end because if it's very long But the relay could just subscribe to the current group, so we'll just keep getting stuff"
  },
  {
    "startTime": "01:22:00",
    "text": "doesn't have to issue new subscribes uh yes okay if you're like have five clients and they're all up to date on object 1,000 of current group, and then a new client subscribes and says please give me current groups in subject zero Now it's possible that those objects zero to thousand of current group. And then a new client subscribes and says, please give me current groups in subject zero. Now it's possible that those objects here, 2000s are like out of your, any cache on your, relay because OK, thanks. So okay, so that strains the queue so go ahead and okay so the next slide is I'm trying to like go through the proposals and I'm mostly going to follow on what I think is like what started solving the life case and in life case what we usually do is we want to subscribe to new objects and sometimes we want to get some objects in past but usually not that much, sorry, not that many of those objects and next slide uh So our previous proposal was roughly, well, Next slide. So our previous proposal was roughly that, well, the ones that I think I was advocating for in Denver was that, well, we do subscribe and then we do fetch and then you do a thing called Atomic Subscribe and Fetch where the subscribe kind of the case in the subscribes are just delivered new things, and then fetch that delivers you old things, and that kind of both of those are well defined as this works and there's this kind of this kind of used to be worked theory however this has two drawbacks that were pointed out even back then so like slide The big drawback is that since in some delivery preferences, objects can be real reordered, you might have stuff that's like below the life head and that falls into fetch and that has weird semantics. And then you can have"
  },
  {
    "startTime": "01:24:00",
    "text": "stuff in few, and that means that like you're not really full solving the problem and there is also an observation that this kind of has weird property where your current group and always delivered on two streams one is like past the head at the moment of subscription and one is in the future Next slide So to fix, I that I said one is so before I define subscribe as delivering new things and by new things we mean things with increasing object number And my proposal is to redefine that to just mean that subscribe means that publisher for original publisher is the objects that are new generated. Unfortunately, really, it's the objects that are received from a subscribe from publisher And the reason this is good, it's a solves two issues, one issue is where you can write a group before it whilst a new group is a open, and the second it's also a reordering issue Next slide So the second component is to define fetch and I'm not even gone to delve into what fetch is supposed to mean But we define this. It's like you specify a well-defined range of what happens. And next slide is uh my actual proposals that I think I kind of solves what we were trying to do before And it's kind of a practical solution for doing backfill of like capital past groups without making it to conflict. So usually when you subscribe to our you will have some buffer of like and most recent groups because you're fanning out those groups to buy"
  },
  {
    "startTime": "01:26:00",
    "text": "bunch of clients and not all of those clients have stable connections So you have to buffer them. So you have to cache bunch of recent groups anyways my idea is that you can ask the relay, please send me N most recent groups, and the relay can look at that cache and if they're in cash it will give them to you and if they're not in cash, it will not give them to you And my observation is that this is roughly works most of the time and my second observation is this is really easy to implement. This does not have any edge cases since all of your objects are in RAM and none of them are stuff that you have to go back to the origin to do And that's why I like it and I kind of have looked at the way our code works and that would mean, yeah Victor, wrap it up last slide and we'll get some brief comments. Yeah, this is the roughly, like, what I propose is like we redirect fetch and replace absolute trenches with, like, subscribe to N most recent groups lovely thank you victor we have three minutes, so I would like to invite people to come to the mic to comment with a focus of would you like to see PR in this general direction? And let's not bike shed the details. It's like, do you want to go see PR? Is this like? completely the wrong way to go? So how's this go? I would definitely like to CPR and also help uh writing some of the peers thanks thank you sue hoss Luke. I said that the chat, but I'll say it again Backfill's Victor's proposal is based on the cash. That means it changes based on which relay you connect to, like two different users could get different backfill results just on a win Really should treat the cache as transparent Like the relay needs to put almost to the user, the cache doesn't exist So I really don't like that behavior of being part"
  },
  {
    "startTime": "01:28:00",
    "text": "you know, specified. Okay, so you would not like the CPR along these lines? I mean, I'd like to think it, rethought Like, I don't want a verb that says serve only lets in cash because they're, making cash part of the protocol. Okay, thanks thanks Go ahead Mosinati, I support something a lot these lines, not specifically these lines. I think we do need a re- revisit the fetch versus subscribe I don't specifically want the cashability aspect mentioned or the most recent group and groups, nothing in the past for subscribe Thank you Colin Chains, I mean, I agree with what. Will's next I'm really sorry, Will No, it's okay, Kyle. Why don't you finish and go right off to you? you? Okay, I'm going I just also want to support the notion that the caches are immaterial. As a cash implementer, it's a delivery optimization. It should have, it should not affect what is received or what is requested. So I would also not want a API that's somehow gives you different results based on what's the cash. The cash may not be there and it doesn't matter See it next. Look, I was going to say is I think this is the most problem direction we've seen. I really love to see this work continue I do agree with, like, Luke's comments on the cache Ian? Yeah I tend to agree that this is potentially encouraging. I think the observation that absolute start offsets the subscriber or sort of not dangerous, but problematic is it correct one. I will say from like writing the like feds, subscribe PR before if you actually create a whole new message with like all of its accoutrements it ends up being kind of a huge pain and a wall of text it might actually be easier just to add a mode to some subscribe and or make the current absolute"
  },
  {
    "startTime": "01:30:00",
    "text": "start and mode in subscribe and just say that is this verb or something, or that's the fetch verb or something It makes for a much smaller diff and you basically need all you need priority for fetch you need like basically all the stuff in there, I think. So just for my editorial perspective Does anyone want in the 10 seconds we have, does anyone, want to speak against Fetch? I hear a lot of pushback on backfill Okay, so Victor, I think you have marching instructions if you're willing to submit a PR, some sort of subscribe fetch that we know back marching instructions if you're willing to submit a PR, some sort of subscribe fetch that we know backfill. I mean, it's a pretty strong signal I think, from the room. If you want to argue about backfill on side conversations, that's great but at the moment I think that's where the group is Sound good to you, Victor? Okay, thank you Thanks everyone for attending. It is 5 o'clock. We will see you tomorrow for round two And thanks to our scribes you will get chocolate tomorrow, at least one of you Oh, can you deliver to Watson? Okay, we have that recorded, so don't like claim you didn't get All right, well, Alan will have it tomorrow. He didn't bring it today Thank you Yeah, the live screen"
  }
]
