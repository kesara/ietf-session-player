[
  {
    "startTime": "00:00:05",
    "text": "on a circuit commute we\u0027re starting in 30 seconds we have a food agenda once again so we don\u0027t want to take too much delay at the beginning of the Y\u0027s will run turbines at the end combien John so musical join us okay so I think we can start okay so um this is the coding for efficient network communications research group um again like I said we have a very full agenda inside actually um so for people who are new here um our goal is essentially to foster research and I would you know and emphasize the word research here in network and application layer coding to improve performance what does that research mean it means research in codes and coding libraries and you\u0027re going to hear about some of that in the early presentations here we also want to focus on protocols that will facilitate the use of coding in existing systems a lot of times the reason that coding is not used is because there\u0027s not an easy way to access this code from inside another protocol and we want to look into real-world use cases and also work work in progress in other working groups and in other research groups and outside or group also okay so now the usual not well slide in fact not exactly usual because it has it has changed recent but the underlying documents remain the same so I don\u0027t want to go through this slide just to highlight one points that is very important in our case if you are reasonably aware of IPR related to your work or work from somebody else then please you need to do nykeya disclosure rapidly you can have more details in BCP 79 again of this list BCP 29 best current practice is also a short name for another name for IFC 81 79 so have a look at that then concerning some administrative stuff if ever you are looking for any information any piece of information concerning our research group then you "
  },
  {
    "startTime": "00:03:06",
    "text": "need to go to the data tracker I got ITF dot all websites everything is there the documents the milestones the agent the the Charter everything is there okay we also have wiki but we are not using it so much for the moments main list the slides are all uploaded except maybe one of them but I hope that we\u0027ll get it this is the Yun presentation but you will sign it to us all the slides also wise are available online and of course from a pest station is fully usual mythical system the agenda as I said is pretty full we have zero time balance so if you intend to present something then make sure that you presentation is stay within the allocated time so we have except one exception of a quarter of our for each your first ten minutes presentation and five minute questions if you spend more time presentation means less time on prostate on discussion after you so a little bit of a a quick status about what is going on we have a document that is at is G review which means that it will be LRC very soon and it\u0027s the network coding taxonomy which describes the words that we are using and describes the functions of network coding there are currently individual ideas did this has one there\u0027s RL and C there\u0027s a presentation that\u0027s going to be here presented today that has both information about ONC and also about symbols there is a it\u0027s very it\u0027s not very good here anyway there is network coding and satellites and actually this is an update to work that was done before there\u0027s also an update to network coding in ICN which was also going to be presented today we have the work on the common coding API and again we\u0027re going to talk about that a lot today because we you know this is something that is needed to allow interoperability and something that we haven\u0027t really talked about much is the network network coding adoption challenges which we have not dropped yet that we are coding and congestion control well that we\u0027re going to have a presentation today there was not a real document submitted and this idea of network coding and robust tunneling I think this will going to be probably changed to network coding and quick because this is what I think the original idea of the robust tunneling was there so future meetings we plan "
  },
  {
    "startTime": "00:06:09",
    "text": "obviously to have a meeting in Montreal in July and we\u0027re also planning to have an interim meeting the tentative date is September 25th in Boston last year when we had a interim meeting in that timeframe it was extremely successful because again there is a critical mass of network coding companies and at were coding users and the Boston area remote participation will hopefully be possible but being there is always better yep well and it\u0027s lovely in Boston and yes okay so that\u0027s for the agenda so let\u0027s continue with the first presentation yes okay so we had a bunch of presentation concerning the various building blocks and then we\u0027ll continue with the second part of this meeting with use cases so we applauded the fourth version of the tetris draft so this presentation is not about the tetris protocol it\u0027s more about the internet draft itself so what do we do with this so next slide please so just you know 12 next slide so the objective of our work is to propose jarick transport protocol framework plus some building blocks and particularly the elastic encoding window next slide and today everything is inside the same document so we defined the protocol so we defined some packet formats and we also defined a set of building blocks so everything in each side is document and this is why I want to discuss so you will see at the end next slide so tetris is defined as an application layer Transfer Protocol so it\u0027s n to n and above UDP next slide so the use case are unicast and multicast communications with or without feedbacks so in the protocol part we like it simple so we have three packet formats so the first is the sauce packet so it\u0027s just to pay a lot with an ID the second is a credit packet so it\u0027s a runner combination of some sauce packets and including an ID plus an encoding vector so the information about the liner combination plus decoded packet payload the last one is the acknowledge pockets so you provide some feedback like packet loss read the missing pockets or and you want to want to go back from the "
  },
  {
    "startTime": "00:09:11",
    "text": "decoder to the encoder sonic slide ok so we proposed this encoding vector so this is it could be actually the first building block so this is the most important because it defines how we code the data ok so each coded packet contains an encoding vector so we wanted to create a generic encoding vectors that\u0027s why by using this format you could store the these IDs you including the credit packet you could store the coefficients but if you want you don\u0027t have to put the coefficients so in the next slide I will make an example so for example if you just want to use a sliding window so suppose you want to generate an encoding vector by using the fighting with of size 64 by using the finite field with 2 to power 8 elements so you want to code simple source 0 to 63 so you actually need egg bytes to store all the information about the liner combination ok well do you don\u0027t have to actually store all the coefficients because in the draft we defined some algorithms some deterministic methods to generate the coefficients so this encoding vector could be one of the building blocks next slide yes so another building block could be the generation of the coefficients so interest will propose one approach which is a deterministic way so basically you are inside a codec coded symbol I and you want to generate the coefficient to integrate this example G so you have defined in the draft a method to just to generate that directly so coefficient based on these two ideas so you don\u0027t have to generate all the coefficients for your full line of combination you just if you want just generate 1 5 change is possible so this is an approach we propose okay does not cover all the use case internet recording but this is what we propose all right okay so now as I said everything is inside the same document so now what do we do do we have to split the document bit between the protocol and a set of building blocks or do we have to continue with this Jerek framework or do we have to create something addressed by defining more precisely the building blocks layers including vector or the generation of coefficient so it\u0027s up to you to decide different network systems research incident just a clarifying question could could you explain to some of us that don\u0027t follow all the details what the inner overlap if any and field of applicability between this and the TSV "
  },
  {
    "startTime": "00:12:11",
    "text": "are encoding drift for sliding window RL and C that\u0027s that\u0027s happening in with the feck frame yes so basically this is another format exactly so so we defined a format I think perfect from aurelion T defined another format so we have some common information but it\u0027s another format so um what are to do we need to worry about the defining the meta problem to give sepal some guidance as to you know which which approach to use in what field of applicability no party without my chair hat I think we\u0027ve had some discussions with a lot of the people and actually also I\u0027m the co-author of another draft and I think which we would like to get as much as possible is a set of generic protocol locks that we would say we called them to call them the open source api\u0027s and then having a set of specific blocks that are codependent and actually could be more or less transparent than more or less open so I and I think there\u0027s a lot of overlap things between the applicability of each of these things but we would like also to allow them to be used both independently or to address the same problem but then you could choose whatever you want does that answer your question because it was not a question that much for him but I think for it for the generic group I think it answers a question I\u0027m not sure I like the answer very much um in the sense that we don\u0027t have a neither document seems to provide a guy any guidance as to which one might be more appropriate for any given thing and you know you mentioned api\u0027s this has nothing to do with api\u0027s this is protocol encoding right and you could provide a generic API that could do either of those these things but then who decides when you call that API which one gets used right so I just think there might be some metal work to be done to give the community some guidance and I don\u0027t have an opinion as to whether technically one\u0027s better than the other for this or the other but one of the things we can do in a research group since we\u0027re doing research is maybe some experimentation that later can provide some guidance to people as to what the right field of applicability for the for the different encoding might be yes as I saw without my charts but also as well main author of the fact frame stuff that\u0027s a very good point and you will see there is some overlap between this presentation the presentation that will appear just after on like it\u0027s either formats and also some "
  },
  {
    "startTime": "00:15:14",
    "text": "overlap with what I\u0027ve done with colleagues in the context of fake frame for freak frame is a bit special because it was focused on an already existing protocol with some specificities but yes there is some commonality and we need to have common understanding and guidance regarding how to format others in an appropriate way to fulfill the requirements of that on this and that protocol so yes this is work that we need to be done and I wanted to we want in with Nigel a to put that on the table after the second presentation yeah I\u0027m sure they\u0027re really good reasons to have these different things but somebody coming at it from the outside right it\u0027s not going to have a direct line into you know the brains of the people that did this thing so we intend to promote that type of work so after this meeting we intend to start a discussion on the list about how this is going to take shape and what contributions will be yes million about recoding how do you envision recording here so basically yeah as I said it\u0027s end to end so we wrote a part about recording in the draft but it will be removed in the next so basically we want only to focus about end to end without recording thank you welcome command questions okay so then that case let\u0027s continue with next presentation and then maybe we will come back on this question so to kordell\u0027s on all these aspects no nothing you have the floor yes and thank you for the other author summer who is with us remotely and surely from Chora and myself and hear me no can hear me now yes okay so and Vince from from inside so can you okay so the agenda is essentially a general motivation and the objective of this work and the design goals and we just that we support and then an example of the simple representation that we have proposed and some types and the relationship with the outer protocol and some limitations of this work so it\u0027s a related to the first presentation not so the sort of the out "
  },
  {
    "startTime": "00:18:14",
    "text": "the starting point of this work was that we wanted a general purpose very low overhead presentation of coded symbols so it\u0027s not a protocol it\u0027s just the symbols with some stuff on top so that you can interpret them at the receiver sorry okay maybe I need to be really close step better no the next pad please the next cut thank you very much so the motivation so we so the representation of the symbol is very small but it\u0027s an important part of any protocol using it for coding I don\u0027t even hear you okay so maybe I just no no we need to use it okay sorry sorry okay so maybe I just okay so try this one okay so yeah so the motivation is a representation of a coda symbol that because we need that in in multiple different protocols and if we can reuse that so we can build our protocols faster we don\u0027t need to redefine this every time like the last and and also the chest no and then we can give up some interval Otzi between implementations of the underlying code of the coding libraries and stuff like that and then this last one should maybe be in the next slide but at least was important for this work that was that we wanted to accommodate a varying frame size over the course of the transposition over the over the life the transportation because we\u0027re working on a network where that happens to be the case that the underlying frame size changes during the because of some changing link conditions so so we have the goals here they know we want to know era overhead you know we want to support recording because it\u0027s we think it\u0027s an important feature of network coding that we need and and we want to be able to generate symbols from blocks that are incomplete in case of a block code and we want to support both the block and a sliding window type of code so the features that we have included as a consequence of this is a variable number of symbols that are can be represented within each of these representations because we have a usually we have fixed simple size and that means that the only thing that we can vary is the number of symbols we put into each representation unlike unless we want a sort of a purpose every representation for each simple and if we have that then we have an overhead for each of the symbols we put in so that\u0027s seriously limits the sort of the flexibility we have we have three simple types so we have an uncoded and I code it and a recorded one so similar to the first work that was presented so in order so we need different things for these three different cases so in order to be efficient we should define some different ones and then we have a small small and a large encoding window which essentially limits "
  },
  {
    "startTime": "00:21:16",
    "text": "how big we can do how much data we can put in our blocks and in our windows and then we have a bunch of parameters that we actually don\u0027t have in this protocol that can be defined per stream or per packet or something else and if we want to be most efficient we cannot define those in this representation because if they have example the same during the whole life of the transmission then it\u0027s a waste of bits so here\u0027s a sort of a generic example which is just that type field we have these different types and then we have a field for some how many symbols we include and then we have the rank of at the encoder which is necessary if you want to encode symbols before you have a full block for example and then we have something like a seed or a coding vector that we include and the data that is encoded next I please and then we have the three different types so the first one is just the an uncoded symbol so they\u0027re the encoder rank is essentially an offset into the block or into the sliding window and then there\u0027s some data that is appended and if we have something that is coded then we also need a seed so that we can put that into the certain random generator that we typically use when we do encoding at a source and so the seed can be used for all of the symbols inside of the representation because we just keep on generating numbers so yeah we have a fixed overhead overhead the regardless of how many symbols we will put into the representation and then in the case of a recorded symbol we put in the coding coefficients or if we have some system where we don\u0027t have access to the random generator or something else you can essentially support anything you can generate an arbitrary coding weight so any way you want and put that into this representation but it also cost as a higher weight so it\u0027s not what you would usually do and the reason why we think that we need all of these three is we need to mix and that\u0027s the system right that could be that most of the traffic is uncoded and then there\u0027s a little bit that has coded or recode or something else so if we if we don\u0027t permit that we can change that they are interoperable then we will not be most efficient so in relationship to with the outer protocol maybe that\u0027s a there is some things that we support and we support that you can essentially put any number of representation into a single payload and then in each of these representations you can put in up to 15 symbols and then we have two different the window or block size is that we supported a small one up to a thousand approximately which is typically enough a block code and then there\u0027s a really pick one up to two hundred and sixty something if you want maybe a really big "
  },
  {
    "startTime": "00:24:16",
    "text": "sliding window so and then there\u0027s a bunch of things that the outer protocol needs to define for this to work so it\u0027s things like the field the symbol size it\u0027s the type of representation that we use here either small a large and typically you would use would choose one for your application and then use that\u0027s route and then you need to also provide the block ID or the window offset in the outer protocol and that\u0027s a some things that you could define if you need them or if they are useful and that would be things like for example the block size or the density of the code if you have something with a variable sparse code right adopt to how unit byte operates could also define the server random generator if you want to so yeah that was I think fixed slide that was it thank you for the attention advanced questions I have okay so thank you for for this initiative because it is something that was missing to this group having some document that describes even if you don\u0027t go into the details for the moment but that describes Ireland C is something that was considered as important we put that in the milestones so that\u0027s great it\u0027s also important to start discussions on protocol headers and from this point of view we need to work together well I have several technical commands on your proposal I don\u0027t think it\u0027s appropriate put in this way for various reasons so we can technically discuss that but well maybe it\u0027s not required to do that now in the in the meeting we\u0027ll do that after if you want but most importantly we we need to work together on these aspects between you your colleagues junetta also has something in in the document as we present it just before and my life in the context of fake frame I also have another type of formats so there are three different initiatives that converge on this idea of having some common and reusable protocol a dose or trails that matter so let\u0027s I would suggest to remove this part from this document having a document that focuses solely on Ireland see adding another document which is a building block on protocol headers likely to carry this encoding vector to identify the content of the sliding window if it is a sliding window card having something different and then for this second document I would suggest to collaborate with you is a janitor and ways of the people who also add their own IDs in order to find something that maybe could be usable reusable in some "
  },
  {
    "startTime": "00:27:18",
    "text": "way maybe not for all the use cases because for instance I was mentioning earlier that with fake frame we have some already existing mechanism so we need to be compliant with that so that require not specific to that but also otherwise we can extract some ideas that\u0027s are more or less aligned with what you present it with what Jonathan presented so working together in order to add this building block that could be reused in different context if possible as much as possible I would say do you think it\u0027s something that makes sense to you well we will discuss this also on the list and that\u0027s the meeting there will be minutes actually mentioned but our goal is to have a common decision on those topics not it\u0027s not my decision escucha for sure but that\u0027s an idea that I would like to put on the table now yes Renato Renato so do you want a single document with all the including vector formats to represent the begin block or do you want several documents or now we need to have a single document that is that takes the best of all three proposals in order to find something which makes sense in as many situations as possible with as many protocol verses so so at the end you want only one format no I don\u0027t necessarily want one format it depends I don\u0027t have the answer today it depends on protocol requirements in that case we maybe have to use that format because it makes sense you know the case we\u0027ll have another format but at least having a single document and see what alpha we can go into this direction having something common as much as possible I don\u0027t know if it is I don\u0027t have young so today we need to think about it together but let\u0027s try to work together I think it\u0027s better than having you document with all the stuff inside and Jonathan\u0027s document with all the stuff inside let\u0027s split things Noel first sort of asked my question so what you\u0027re looking for is you would like to have a general format document is that what you\u0027re suggesting general format is possible but at least what in this document for all different forms with this building like this of a building block okay okay okay so I think the goal is a good one but at the end of the day we need at least one form of global optimization which is that we have n formats and M codepal embeddings we have an in order n times n problem in terms of actually putting a system together so the caution I would give by splitting this out is that we don\u0027t run "
  },
  {
    "startTime": "00:30:18",
    "text": "two parallel efforts each of which is operating in its own degree of freedom right so so that we wind up with a cross product that\u0027s you know unimaginably large right so we can decide whether to constrain the number of protocol embeddings we have or constrain the number of format we have or both but if we don\u0027t constrain either one we\u0027re gonna you know I mean we\u0027ve seen this in the ITF in other places before you wind up with a gigantic mess so some global discipline is needed here yeah yeah good point so if we do that we means that okay we would have this iron see document this building block dedicated to formats and another like the killing one second I must have missed something because yeah I what in that document this format document was actually specific to oral and say no okay yes I should have mentioned that before and when we when we read this document we see that there is a lot of text describing in some way a general concept related to Island see and then we have format thought this is the way I understand the document so let\u0027s because a lot of description or arlynn see is the use case motivating the format I just want to do a test because I didn\u0027t see anything in the actual format that was specific to our LNC right or wrong Genesis if you don\u0027t want so yeah so for example you should it depends if you compare with I don\u0027t like at a normal block code usually you don\u0027t you wait until the block is feel full and then you start coding right so this encoding show you is a simple representation sure okay yeah yeah so so it\u0027s yeah you can use as a symbol representation you know all right I could be wrong I just didn\u0027t see anything specific to our LNC in in in in the in the coding this is the idea of conveying the coding and see you would never have a recoded net block representation but you know systematic code will have whether it\u0027s all and C or not will have one you know uncoated format you know symbols and coded format symbols right true but a notion dimensionally would only use coded symbols but you wouldn\u0027t wouldn\u0027t for example me to communicate the rank right at the encoder and then you know in a normal block code for example so so it\u0027s a superset yes okay yeah no yeah there\u0027s no Christian comments yes I completely agree with Dave you know that was a motivating example particularly for instance for recoding but nothing here is specific to Ireland see in terms of the format and conversely I just wanted to point out that they are they have been proposals and they did my group has had papers on "
  },
  {
    "startTime": "00:33:18",
    "text": "doing RL and C without conveying without conveying the coefficients because there are other ways of figuring out the coefficients and implicitly or predetermined I think what you would have called deterministic maybe in the previous in the previous presentation so it\u0027s a motivating example but it\u0027s it\u0027s for a particular it\u0027s it enables certain things that are effectively coding which are particularly nice with our NSC but but it is really just a generic format what happens to enable certain of your LMC cases that that we have found to be very effective so that that will place it it\u0027s not really a subset or or super set it it\u0027s just a set of encoding formats which we think are generally useful and and there are only sees just there as as as one of the cases for some of the implementations of Ireland see what this is useful does that make sense to everyone yeah thank you okay so it also means that you Janet on should produce a new version of his document going through some going to add something which is more generic in terms of protocol mechanisms with building blocks like other formats that are moved elsewhere and these documents instructs the Iraqi so the only difference between a recording and not recording is you just need the coefficients to be inserted in so inside the the packets right I think this is the only friends so I\u0027m pretty sure we could imagine a format generic format with an optional field you said okay I want the coefficients inside so all other other I don\u0027t want the coefficients so it should be pretty simple to convert yes million yes so the recording doesn\u0027t always require the yeah that does not always require the the conveyance of the new coefficients upon which there the recoating is is affected so you know on the other hand of course there\u0027s some really great spaces for it but again it\u0027s not a cynic one on condition I just wanted to make that clear and indeed some of the papers that for my group signed fairly on on on sensor networks which people generally call more iot right now indeed did not you know did use recoding without conveyance of the of the header with activating okay I "
  },
  {
    "startTime": "00:36:19",
    "text": "just went out yeah better okay thank you okay so I think we are almost done just one comment because we already mentioned we already had some discussion offline on this topic but if you believe there is an idea disclosure that should be done on this document please do that rapidly as rapidly as possible there is a an exact wording in the BCP 79 that says as rapidly as possible after document submission after contribution so please keep keep that in mind one more comment regarding IPR disclosure if the patent is not yet granted it\u0027s not a problem there is a checkbox why can\u0027t that can check to say okay this is an unpublished pending patent so I don\u0027t know what is the situation but if we can clarify this rapidly that would be great yeah Georgia market ask occurred on we\u0027re working on the IPR disclosure we understand that you know it should be disclosed as reasonably as possible not as rapidly as possible you should appreciate that you know the IP is owned by predominantly Hamilton Caltech but there are also other eight universities involved so we are discussing and agreeing the best licensing strategy and approach but you know we\u0027re working on it and you know as soon should be something but you confirmed that there will be a nightmare disclosure on this document that\u0027s one way yes cutter thank you that\u0027s one part of the answer thank you no more comments okay so let\u0027s continue this is my turn okay so I would like to talk about this document which is about a generic API for low-level FEC codes that could be used in this context so it is joint work with Jonathan with Morton with Cedric with Jung yes next and we well I updated this document only very recently yesterday in fact sorry for that we try to do better next time I was waiting for a third contribution so now this document the one you will find on the data tracker includes a free example api\u0027s for sliding window codes nine the one from jonathan and the one from Morton so those free api\u0027s "
  },
  {
    "startTime": "00:39:21",
    "text": "correspond to running codes there is something behind them there have been independently developed by the free first press colleagues of course we are not working all alone but they\u0027ve been indefinitely developed so that\u0027s something very precious and there is also a link to a fourth implantation of sliding window codes the one from Cedric which you can find it you are yeah this one does not include codec API it\u0027s developed in a different way there is no standalone codec so I mentioned it we can use it to get inspiration we can also discuss we said like with well aware of foul we can do that but was designed in different ways so there is no fourth doesn\u0027t the only free examples not for anyway so we have analyzed all of them and we came with a few preliminary conclusions on several questions that I would like now to introduce you they are not in the document so the first of all I would like to do a reminder before going into the details we need to understand that what while looking here is an API for a low-level correction low-level quake will include a certain number of mechanisms but certainly not all of them a lot of stuff will remain in the color in the application or in the protocol that will use this low-level correct so we are the correct API in between but a lot of stuff will be out of scope for this API so you will see in the future slides some of them some of the questions that we try to answer are really dedicated to where should we do that or that mechanism should it be inside the codec or should be outside of the correct it should be should the API be aware of this or not that\u0027s the key questions so the first question is what type of codec should we focus on so of course we need to have something which is as generic as possible that\u0027s the title that\u0027s goal but we add we need to take an important decision should we consider poof block cuts and sliding window cuts or not we discussed that together if we look at what has been done in those four implementations you will see that three of them concern only it sliding focus only on sliding window cuts there is only one of them that encompasses both block cuts and sliding window cuts and we discussed and for the moment we came to the conclusion that we should focus on sliding window cuts only so this API which should be an API for sliding will occurs if you disagree then please come "
  },
  {
    "startTime": "00:42:23",
    "text": "and explain us why we you have a concern because that\u0027s an important this even we need to take now before going further into details de Varenne so you\u0027re gonna have to excuse me this is probably a really stupid question oh no he which is can\u0027t you do a block code by using the API for a sliding window code and on every call um the disjoint window gets shifted yeah yeah we add that in mind some parts of time of course a block code is a sliding window that does not slide so there\u0027s some equivalence from this point of view but when you go into details of the API for the moments we didn\u0027t find any satisfying manner to manage both in this in a unified way that differences technical differences and when you try to to address them you you will quickly enter into problems and for the moment we have no solution maybe there is one but we I didn\u0027t find them I just wanted to echo Dave\u0027s point and maybe expand on it a little bit so as you know there is I said this point of treated large literature sort of bringing together block codes and sliding window codes oh one of them is of course the overlapping blocks where in effect the coding is done in a blocked fashion but these blocks overlap sometimes in sort of a constant step away from each other sometimes in a non-constant step so that is sort of very much a link between log coding and a sliding window the other aspect is that sometimes you get implementations which start out as a block code but then because of the way acknowledgments are managed really start looking very much like a sliding window so I think it\u0027s important to realize that there\u0027s really quite a continuum with again I think a considerable literature behind it that wouldn\u0027t want us to dismiss yes there is a continuum but as I said when you go into details and want to design an API it\u0027s not that easy to find a solution that encompasses both block and sliding-window codes that is attractive and simple that remains simple even for a particular case of block codes so it\u0027s a very practical question and we need to go into practical considerations yeah but yes "
  },
  {
    "startTime": "00:45:23",
    "text": "for sure there\u0027s a continuum of course we want this to be practical but yes if you have an example yes we would like to see this that\u0027s just something that we would want to look into end up in it for time actually I think I\u0027m going to cut the questions until your end of your presentation so that for the moment it\u0027s okay but sake of time because you still have a lot you haven\u0027t done the last night actually API come yes yes yes left line important of course we of course can and consider both and to end and situations when you have recording wins inside the network because it\u0027s pretty easy to address from the API point of view so let\u0027s do that for sure second question is now one of those questions where should you do that feature will it be inside the code actually be on top of the collection so should the API consider this or not so that\u0027s the first example should be ad you so the a view is the application that I need the message from the application let\u0027s say should this ad you to source symbols mapping be done inside the codec or on top of the codec should the API consider only source symbols Reaper symbols which is the conclusion if we do that only on top of the codec if you do this mapping on top of the collec since in that case the API will only see and consider symbols or should this be inside the codec the opposite solution we had some discussion there are impacts in terms of implementation complexity this mapping is not trivial there is some complexity associated to this mapping so it\u0027s once again an important question so we came for the conclusion for now after discussing that should be done by the color outside of the clique to keep this Killick as simple as possible the a consequence is of course comments no by outside the codec do you mean above the API or outside the codec but below the API yeah so this is the drawing so on top of the correct means outside of the API so yeah in this example if we do this mapping inside the protocol inside the the application let\u0027s say that uses the codec the codec will only consider symbols because this mapping will be done before entering so coming back to the format discussion just for a second yeah with the form the the symbol format people oh the API are above the API "
  },
  {
    "startTime": "00:48:25",
    "text": "the symbol formats if you mean by a symbol for max the ADA okay so this is the idea there is a specific question for that I will be on top of within the application that\u0027s the proposal so we also will just comment you have to demonstrate it you don\u0027t get multiple data copies when you do that yep so that\u0027s exactly this question that you mentioned where should we process create and prevent the task the packet Eddowes the symbol Edo\u0027s so yes yes in some way there are connections between due to any way but yes there does let\u0027s say so there are consequences this is once again a very important question because when you design effect scheme this is not only the correct part the encoding and decoding part is also the signaling part that is required to you this correct so this answer in this question will also answer the question does the codec input does the API implements a fact scheme or just a codec so we had some discussion and for the moment our position is that once again we keep the codec as simple as possible focusing only an encoding encoding and decoding sorry and leave this packet error manipulation creation processing passing inside the application on top of the API so that\u0027s our position for the moment fourth question asked you have five minutes should the codec once again same cat same type of question should the codec take into consideration timing aspects so if you are manipulating real-time flow there is a limited validity duration for each of the piece of information that you will send to the receiver so should the correct should be yes to the correct and the API where are those tiny aspects or not once again it\u0027s as implications on the API point of view because that typically with slamming window codes whereas this distinction between decoding window which is which needs to consider timing aspects and linear system size which does not consider tiny aspect so there are consequences once again I don\u0027t want to go too much into the details but the implications so we add once again our discussion and for the moment our position is that this should be done inside inside the application on top of the API so the API and the codec will also only focus on coding and decoding five fifth question this is especially a "
  },
  {
    "startTime": "00:51:26",
    "text": "question for you Dave and you you mentioned at previous ITF that it should be nice to take into consideration other constraints that\u0027s a very good point we but unfortunately none of us has any sufficient experience in the domain to see what it means what are the implications and therefore to design this in an appropriate way or avoid some mistakes that might be done if we don\u0027t keep that in mind so if anybody has an opinion on these examples ins then we would appreciate that we realize the question is that anyway look okay so let\u0027s continue yet one quick high-level car get you don\u0027t want to structure the API such that if you have a split implementation that you\u0027re forced to pass every symbol independently across the hardware software boundary and of course you\u0027ll blow the latency out so if you\u0027re doing the coding on an FPGA yet and the application is running on the CPU yeah if the API is passing individual symbols back and forth uncoded symbols decoded symbols over that API between the hardware and the software right it won\u0027t work well so you have to consider an API in which there\u0027s inherent ability to do batching I guess so that so that the interaction this is the control interaction with the hardware can operate over a reasonably large number of input symbols and output symbols okay okay that\u0027s the key points to keep in mind yeah okay I will probably get in touch with you to try fine more precisely this but yes yes thank you thank you very much so quick final slide to summarize we need to make choices those choices as have implications it\u0027s not obvious to see what are all the implications of each of those choices we need to do to have some practical experience for that but I think we we could do something nice from what I mentioned before it\u0027s clear for the moment that the codec will only focus on low level and cooling and Louisville decoding and therefore the fake scheme will be broader than just what is inside this codec and the API as a consequence will not be an API for effect scheme but an API for effect correct so now we next step is to come with first proposal for next IGF we\u0027ll see if we managed to do that but this is working progress any more comments comments thank you thank you everybody "
  },
  {
    "startTime": "00:54:29",
    "text": "questions Millie and you had a question and it disappeared you still have it okay good Oh quick questions because just on time that\u0027s okay or maybe later on the milanese because sorry emmanuel we cannot see anything can you repeat yes I said maybe on the mailing list because going to be okay ah back up for me match maybe now you don\u0027t you don\u0027t hear me hello back yes that\u0027s good okay I was sure it was working back back back again again again again move lit yeah Hey look you walk you walk you look yes yes much better okay sorry are we sure but we don\u0027t need to have time stamping and the time time feels inside the codec for the moment this is the our opinion but if you have good arguments then you can discuss this I thought simply about the time stamp inside TCP you sometimes you need just to be sure what kind of information you retrieve or maybe to estimate and 20 a or some stuff like that value is not a problem yes but you should do that in the application in the protocol not in the collection correct when whether you see when a new saw symbol has been decoded then the codec will give it back to the application and so the timing will be that the wrong timing when this happens but if you have a maybe you are running and let\u0027s go on list yeah yeah let\u0027s go on the list for that uh I it\u0027s 30 seconds it\u0027s good if it\u0027s more send it to the list okay great I just wanted to point out that the the this actually announcer I think to the question that was being asked about whether there are implementations there are FPGA implementations of that my lab did with the lab of Anantha Chandra Carson our current Dean of engineering on FPGA we also have done this in with a you know sponsored by the semiconductor Research Council we there is a chip implementation of network a lot of and by the way I asked answering him and you has a question there is no timing in any of those at the codec level okay if you have "
  },
  {
    "startTime": "00:57:29",
    "text": "references and person that we could contact to get more information and what it means to have a hardware and print edition of I think it would be better if you were sending that information to the list because I think we want to make sure that the whole piece the whole group gets the information so the list is the best way thank you thank you hello everyone this is a five-minute discussion slot for speaking a little bit about the interactions between network coding and cohesion control so I\u0027m presenting that on the behalf of a manual you couldn\u0027t make it it make it here and set me aside yesterday so I\u0027m doing my best basically the problem is that the thing is interactions between net recording and congestion control could be done in many working groups at the IETF so why could we start it here first T is that we have already Network coding and congestion control interaction solutions existing and also the discussion needs to start somewhere anyway then see where you go forward through the objective of these five-minute discussions that may be worth having on the list afterwards is to see whether we make a group document here or we just peek I know I think the main high-level discussions are whether can we and should we fight on Paul when you have a network cutting recovery and but if if the loss is not due to link layer or transmission layers issues losses but more on condition control losses do you actually consider that in the as a consistent signal and how they actually impact your your condition control scheme at the consequence and also depending on I will present after this catch a use case draft on network ligand satellites and the problem that we see that depending on the use case because network coding is a building block that you can deploy and depending on the use case and the traffic you\u0027re considering you have lots of different possibilities and the same happens here sometimes there\u0027s no point in actually having interactions between these two catch country control and intercutting so next slide please it\u0027s just example on what is it that\u0027s at the moment for example we have things that are at the user space and we already have quick with some sort of network coding we can do some middleware network coding as well and in the kernel these are examples of the what you can basically be below a transport layer and have no interactions at all with TCP you can have as well so basically there are "
  },
  {
    "startTime": "01:00:29",
    "text": "lots of things acting and lots of proposals with interactions between network coding and collision control and the thing is do we have material to make a draft in this group or not do we want to and so that\u0027s what Manuel wanted to ask to the group I think yes the question is what to do next should I enter into this work should we is there any critical mass for doing that what should we put in sign well all of them are open questions hello yes we Google I think it would be worth reading a document although I think it\u0027s important to get the scoping right because I can imagine you know you have things like coding for satellites that may be unaware at the application layer like quick and TCP now that might not actually see the coding but it might still interact with the congestion controller that\u0027s running and end because you know for example if you run in cubic like you don\u0027t see any loss you\u0027re like oh everything\u0027s going great and you\u0027d like get some huge window and suddenly it explodes and goes very poorly so it may almost be an interaction with like a QM as a secondary layer I guess trying to figure out what the scope is is it only you know end in coding or is it and then coding as well as like in network coding and doing both I think is useful but it\u0027s it\u0027s a bigger task certainly not something I would sign up for but I think is worth doing yeah they\u0027re always discussions but well Korean vessels congestion control and if this document called where I explained among other things that K we can do things in an intelligent way where coding will not negatively impact congestion control break everything then that could be also one of the goals so there\u0027s one additional complexity that probably ought to make it on somewhere in the slides which is some coding schemes attempt to dynamically adjust the level of coding based on what types of errors they\u0027re seeing and if you\u0027re not very very careful what you\u0027ll wind up doing is you\u0027ll increase the amount of coding when you get congestion which of course increases the number of packets that are sent which in which in turn increases the amount of congestion so if you have a static if you have a static coding you\u0027ll do different things that the congestion control is above the coding then below the coding but if you have a dynamic adjustment of the coding level based on a perception of loss things get really complicated and I don\u0027t know the answer but there\u0027s not enough expertise either in a classic congestion control transport group or in a coding group like your to deal with that so I think it\u0027s a really good research problem and we need expertise from both sides to deal with it I I sort of like to add the dynamic coding problem in there because it\u0027s gonna hit us through that among the proposals on the the other slide there are lot of "
  },
  {
    "startTime": "01:03:30",
    "text": "them that basically find of all you use ecn signals when you know that there has been a loss recovery for you since I saw the draft on the oneit on using easy and it\u0027s very nice but that\u0027s only part of the solution mr. Dawkins says responsible area director for the quick working group the those guys are encoding everything and then well anyway some of them are sitting in this room so there I know there is communication back and forth but you perhaps perhaps dropping a note to the quick chairs would be it would be a useful thing to do just to make sure so that they can make sure that the right people are involved from that side thank you thank you I mean that\u0027s what we meant that we wanted to do we don\u0027t know where we have to start a discussion whether here there that\u0027s special dorkin\u0027s member of the IRS G we will folk between the ITF and the IRT F we will find you a place to have that discussion if you need to have it quick commence I think this is a great idea because there are a lot of things that you can do without touching the congestion control there\u0027s really interesting interactions I think great thank you thank you thank you for the support okay a great introduction to the next talk Ian you\u0027re still there and while we\u0027re en is coming as everybody signed the blue sheets okay do you know where the blue sheets are we even do it after but anyway the meantime is everybody in the room assigned the blue sheets and where are the blue sheets thank you very much I think the one no sorry I\u0027m lost things are not going on as I expected okay we read the Commission follow sorry this is a Lakes late contribution and therefore it\u0027s not on my laptop it\u0027s on I chose a laptop because I receive this and then I need to go to the official website sorry for that yeah but "
  },
  {
    "startTime": "01:06:31",
    "text": "I need to open a window one day we\u0027re going to invent something that will know what we want to do and it will just fetch it no that\u0027s the wrong we\u0027re closed yes yes at least yes thank you okay sorry there\u0027s another kind of conversation now we\u0027re coding and quick we\u0027ve talked a little bit back and forth of both like how this could be done in a v2 I v1 was done and I Google quick a long time ago that didn\u0027t really work out for various reasons which I talked about in previous sessions so I I want to say that for the record you know I know a fair amount quick as a transport I\u0027m not a coding expert so as much as anything this is an effort to kind of design an architecture that would fit best with the quick transport next slide so the top level requirements number one we don\u0027t want to actually change quick p1 the current proposal is to use the extension mechanism where rude negotiate one or more you know forward error correction frames for use inside quick as additional frames talk about that later should be agnostic with respect to what\u0027s actually the code that\u0027s being negotiated so the current proposal is that you\u0027d be able to offer up multiple extensions ideally they would all have the same base frame but the actual order correction algorithm being used would be different depending on the extension tag and you know you potentially you could even negotiate like two or three if that was suitable so this design mostly focuses on coding taking place within the stream or across multiple streams so kind of focusing on the data actually being delivered as a few slides later about kind of why we\u0027re we\u0027re shifting in that direction but the key thing is not all streams actually need to be coded so you know doing it on a packet layer is less natural control frames usually are and is latency sensitive and it also may just fit with the quick extension mechanism a little more seamlessly and it\u0027s going to be and end is the design so quick has ended and pretty much everything else quick is encrypted and end and so doing coding engined is the most natural thing one could certainly implement a middle "
  },
  {
    "startTime": "01:09:32",
    "text": "box that you know shared the ephemeral keys and like did coding within the network that seems extraordinarily challenging and I can imagine it actually be worth the effort but you know this just fits into visit on principle so quick much more naturally and yeah coding happens before encryption because it\u0027s but then the encrypted he live next slide yeah so some streams may need to be coded some may not so we\u0027re gonna negotiate what kind of algorithms are available and the quick handshake the PRI mentioned is one way to do it and then the application it\u0027s a it\u0027s awful desired like this is very high priority or maybe I have extra bandwidth or something and try to provide some signal even in quit today we actually have what\u0027s called like a bandwidth probing mode where like DB are for example as a mode where it\u0027s trying to look for more bandwidth and there\u0027s been been as has been mentioned before when I was talking with Lars one could you know use extra bandwidth and you know throw FEC in there to see if you have more pennant a quick question on the encoding on top of encryption rather than below encryption within encryption but yes oh not doing that you\u0027re saying well there\u0027s a trade off I\u0027m just wondering about it and you could check something I may not understand in in the way quick does encryption do you have to reorder before you decrypt you no you do not okay so then my questions are relevant yeah it is to define a new quick base frame that all of these various coded approaches you could use the simple version would have a type assumed ID and offset into the stream of what you\u0027re trying to protect and recover from and then add a the length of the number of bytes of code and within it you know obviously you need the second layer of ramming up like whatever your coding system actually relied on and the extension would be to have a repeated stream ID and offset and that would allow you to to span multiple streams which could be particularly compelling for cases when you know your schemes are very small so you know that\u0027s kind of an issue of data mapping of like whether you\u0027re using a large number of small streams that can be easily canceled or whether using large streams and maybe using some other unreliable ability mechanism we haven\u0027t actually like to find it and quick next one so the original idea was that we were gonna code packets because that\u0027s what you lost and so therefore that\u0027s the easiest thing to recover sort of fits into the general quick Packer recovery scheme however we can\u0027t change the packet numbers or we don\u0027t want to in such a scheme but we do want to allow things like non-consecutive packet protection because you know maybe some packets are important and others are not for previous reasons we can you know have issues with things like path migration which caused you like huge jumps and packet number space and so in general like the interaction between the packet "
  },
  {
    "startTime": "01:12:33",
    "text": "numbering and the code and kind of could become a little messy in some edge cases that we thought we didn\u0027t really want to do one of the worst issues is actually that all of these schemes have overhead you know it\u0027s not necessarily huge but it is so amount of over in and in order to have kind of one coded packet that protects you know some number of other packets the natural thing is to just add the extra overhead to the one that has the coding frame however that would blow over your MTU if you\u0027re not careful so then you\u0027d have to under fill a huge number of other packets which also in turn reveals like the using coding to the path and is generally just kind of a little bit messy multipath makes this sort of worse not better so we\u0027re kind of getting away from that even though it seemed to originally like the the most obvious way to do things because that\u0027s how quick loss recovery works also quick loss recovery is moving away from being packet based and more oriented around like the data that\u0027s within it then TCP style loss recovery is anyway so the new idea is to use an extension frame that references one or more streams as I said only protects latency sensitive data the nice part about an approach like this is the quick RT has send and receive buffers that you can base this on and so to a large extent it\u0027s fairly easy to access the existing buffered memory kind of as part of your input to do the recovery so it flows pretty natural from like an architectural perspective worship that\u0027s the idea the newer idea which is suggested by christian Hakuba also an active participant in the quick working group was to you know at least for a prototype purposes just to find an extension frame that replaces a stream with you know some combination of actual data and coded data and you know define a to find a way on a algorithm basis to make that happen and just kind of do whatever you want nice part about this is it really allows you to use any type of code you could possibly imagine it avoids interacting with quick loss recovery because it\u0027s not a stream so clicks not going to actually retransmit it for you it\u0027s just going to declare it lost and you can do whatever you want and yeah it allows maximum experimentation because it sort of offers but it also you know means you have to kind of roll your own to the maximalist and so maximum flexibility and maximum work I think on the part of the experimenter next slide so first step is we need to kind of figure out how the extension mechanism a we have tool and the extension mechanism quick B we have to figure out how we\u0027re actually going to use it to negotiate multiple different coding schemes we need to choose one or more sample codes you know raptor is now the original version of raptor is not encumbered anymore is my understanding so that certainly could be an option Reeth Solomon has open source "
  },
  {
    "startTime": "01:15:34",
    "text": "implementations which are fairly good you know obviously those are two very different types of codes but so it would be sufficient for the purposes of a demo or something and then implement in Pico quick or one of the various other quick stats Pico quick is Christian portion stack and he you seemed interested in actually writing code which would be an extremely helpful part of this process because my extra time to writing code is great code is sort of limited these days next we\u0027d like to agree on an API that we\u0027re gonna use so we can allow multiple different types of for error correction algorithms to be used within quick I would ideally you know we defined kind of a basic infrastructure of this is approximately how you should do this and then we you know just different algorithms would negotiate I don\u0027t know if you know Vincent\u0027s proposed API is the right one it certainly does restrict some types of codes so it\u0027s not as expensive as it could be but it also may be fairly applicable if we\u0027re focusing on protecting stream data so I think that\u0027s something we kind of need to work out through some combination of experimentation and you know feedback from this group and the quick working group of others and next steps is this a research group item is this something we eventually want to migrate to quick or last option is maybe we should just run some more experiments and come back in you know for eight months and tell you what we\u0027ve done oh yeah and thank you for your help bring the document on the cutting aspects i yeah thank you any comments any suggestion there\u0027s three questions here so who thinks they\u0027re actually I\u0027d like some feedback also on the transition from a packet based to a stream based kind of direction and whether there are any reasons people believe that\u0027s a bad direction as well as suggestions on the API question I think if we\u0027re gonna have a very flexible API for plugging this and these algorithms into quick do you think something weapons its document is the right direction if not should we be considering something else or two different documents or two different frames like some some feedback there would be great um I don\u0027t have opinion on the packet versus stream I mean quick as a screen protocol most aspect so you know and we better it had better work well in at modeling the the i/o is streams the the comment I wanted to make is we things may work out a lot better if we try to do this at the same time and in coordination with the way we do multipath if those two things start happening in parallel without sort of tight cooperation you know there\u0027s all kinds of interesting questions if we decide to do the coding on a stream "
  },
  {
    "startTime": "01:18:35",
    "text": "basis and multipath is not binding streams to paths but trying to split streams across paths the vision is it because again there\u0027s a there\u0027s a there\u0027s a sort of like a quadratic complexity around how you choose you know the the level of coding you use so it might be real nice if these two things the multipath and the and the coding um weren\u0027t so modularly separated that they didn\u0027t know about each other yeah that\u0027s true I think they\u0027re going to be most of the development will probably coexist in terms of time frame I think these are I\u0027m just saying this is you as this this is a good moment to move forward because we\u0027re once quick v1 is out the door there\u0027s going to I think a sort of burst of effort on multipath and there should be a burst of effort on this the same time I would agree yeah las a good idea quicken and so if you want to do anything with this this year quick the work quick working group is not the place right and I think even fully Greece as an editor in the sense that so we were a contribution from Mike oh yeah we\u0027re trying to ship quick version one which is single path HTTP only and and we are trying to push everything away um Dave makes a good point right so there\u0027s synergies here so if there\u0027s a lot of activity on quick that will sort of begin to happen once v1 is sort of stabilized that doesn\u0027t mean you know I\u0027ve sees out it made probably is going to happen before my personal so I don\u0027t really know if we\u0027re gonna make the November deadline but my guess is sort of within the three months window around at that time when we\u0027re gonna ship it finally to D is GU people will already start to think about multipath I\u0027m probably already started think now all right they\u0027re still Ivanka is for example um but the working group has no mind chair for any of this at the moment there doesn\u0027t that shouldn\u0027t stop you guys from thinking about this right but but don\u0027t even think of sending his email time before you have all jobs don\u0027t take mine chair nobody reads them if they\u0027re not related to the to the actual so um but alignment with multiplayer if they\u0027ve seems to make sense or at least sort of not making sure that they are not like fighting all the time but I think bit of all this part but yes not not this year and probably not even in the first half and that\u0027s why we\u0027re talking about it here which i think is the right choice hopefully yeah and I good money so Cedric to know from experience so I\u0027m working for I\u0027m coming from a different world from free GBP world and we\u0027re using righto code and we\u0027re using righto code for RTP and we are doing a different stream so differently the approach where you got one IP one stream which is just for the coded data makes sense especially if you want to keep kind of compatibility with a RTP so this is something that we experiment in 3gpp so maybe that\u0027s that\u0027s another thing - "
  },
  {
    "startTime": "01:21:42",
    "text": "okay thank you very much let\u0027s move to next talk we have six minutes we are six minutes late hello again this is just tattoos on what we have been doing internet recording and satellite draft since the last IETF we have six minutes left so I will be quick and next slide please basically what I wanted to show in this slide is that we had initial objectives with this document and we have been doing something different in fact we wanted to contribute to a generic document in Aceh textual where you can actually place intro coding and so on based on an example on satellite communications but the fact is that are too many possibilities that what we have been doing is at the moment is prison different use cases where network coding are interesting for satellite communications and also having a great discussion on how we could actually further deploy these mechanisms at a wider scale so next slide please we have had one good review from Tommaso and also we have these different use cases and that we go through these use cases now and we have been there wasn\u0027t much invidious cases before and now we have lots of lots more context and there are some missing points here so next slide please we don\u0027t have much time and I think I will just show you here what we have in the document but mostly focus for the end of the presentation where we may have some discussions but basically this is the use case when you have two satellite terminals which are under the same beam and that King to each other and basically that I terminal earthen faith and a beef and B and then the satellite combines o2 and send the combinations of the two signals on each of them basically that can results in huge bandwidth savings and that has been demonstrated in a SMS 2010 2010 this is another use case that we have in Auntie fight where basically you have multicast server and because satellites and business for satellite industry still on using virtual huge capacities I have with one satellite you have large beans that you can cover lots of terminals but the problem is that when you want to have a reliable transmission this is the type of mechanism that you can use and basically we have two terminals that are on listening to the same multicast server and both terminal can send what packets "
  },
  {
    "startTime": "01:24:42",
    "text": "haven\u0027t been receiving and then on the musical server you have some network coding mechanisms that resends what have not been acknowledged by everyone if you\u0027ve already implemented in norm but actually it\u0027s not the same coding technique that can be used in norm another one refers to what has been presented in TCP M couple of days ago where basically you have this sort of concentrator that lets you have a real axis of multiple technologies so there have been lots of research activities on how you can actually use network coding for that when you have packets that are lost on one path or the other you can actually recover them by using you don\u0027t have to wait for the packets to be actually which it starts to be actually acknowledged on the path actually we found it so basically you can have lots of high-level gains on the end-to-end this is something that is missing in the current version of the draft but we have been discussed discussing wizards cut earlier this week radically this is the use case of delete or events networking for those who don\u0027t know these network architecture is might be somehow different to what you may know basically to make it quickly we have the bundle protocol and underneath we have these conventions layer and we have different possibilities of including networking in this type of architecture either we do it on on the blue boxes below which is underneath the convergence layer or you you replace the actual convergence layer and you include networking within that layer so that is that makes a pointer to the discussion we just had before on the impact of the contract and control mechanisms because in the convergence layer we may have some conditional a congestion controls and so if you include natural coding in these layers that may have impact on the ribbon relevance of the mechanism and if you look at more the layer 2 transmissions the problem that when you have air currents and a retransmission Network coding may that\u0027s the same trade-off that we have what basically use an initial redundancy not knowing the actual channel capacity and so you use capacity you don\u0027t have or with too much redundancy so that\u0027s the kind of discussions we plan on having in these use cases in the document and then I think you can go next and that\u0027s another use case we have and that is one for which we actually already use network coding in satellite systems today when you have 35 basically we have a satellite terminals or satellite the physical gateway access gateway and then from network functions networking can be applied at lots of different levels for this use case and for what you have "
  },
  {
    "startTime": "01:27:42",
    "text": "today deployed when you have moving users you go on the final poll in maths at that systems when you have your moving and you hope you you your signal is interrupted because there is a tree or whatever then you have burst losses that can be recovered by using network coding schemes at higher layer than the physical layer and also there was interesting presentation in the plenary on satellite communication and basically we are actually targeting for very high bandwidth optical links in satellite systems and that\u0027s what the future is envisioned at the moment and in these bandwidth we have huge valuations so introducing network coding as a physical layer may not be enough in the near future so that is actually interesting for even fixed tell you that comm telecommunications tomorrow that\u0027s also another use case I think the best one that we have basically you have when you typically have an an internet satellite access over the Europe you actually have thousands of Gateway and sometimes where you have channel conditions are bad you want to switch from one way to another and if your gateways are not actually properly synchronized that may results in packet losses and network coding could be applied at different layers here as well to actually improve and cop from the losses that may happen when the Gateway they are not synchronized this is an illustration of what we have been doing with the manual Lucia ink Ness we have an open platform for Austin whatever that con experiments if you want it reads a variable we have lots of different access and this is a SATCOM internet fixed access and we have been comparing the suit put of TCP communication with and without network coding and basically what we can see on the right if the TCP good put over the time and with the TCP with tetris you have actually a better usage of the channel capacity we had it was we were lucky because when we were doing the experiments it was a rainy day that\u0027s when we actually have firing cap at the hang capacity and so we had losses and was not actually perfectly working and so we show that with network coding you have a better good put that being said we don\u0027t speak about the fairness of the collision control because it\u0027s clear that when you send more data you have a better good boot but you know we didn\u0027t has impact on the whole other users that only enable collision control and I think that\u0027s more interesting for the congestion control potential soon-to-be document and I think that that\u0027s it we have had a discussion also in the document on the deployability of network coding schemes format sacrum systems so basically we have present in high-level architecture "
  },
  {
    "startTime": "01:30:42",
    "text": "of a multi gateway that come system and what we try to discuss is a basically depending on where you are on the LC level the network coding scheme that you would deploy is not the same the and radically what I wanted to say mostly is about the virtualization infrastructure we have been what we are doing in SATCOM at the moment is the same as what is acting in the I forgot the name of the draft that is pointed out here radically we have virtualized infrastructure where you can actually deploy network calling functions easily so that is where I think there are interactions between what is happening in other working groups working with virtualization that\u0027s it the what we we have not actually fulfilled the initial objectives that we had on the document what we actually doing is show lots of use cases where networking is important and interesting for satellite communications we also have some discussions on how we could easily deploy these schemes and we think that we don\u0027t we are actually not sure at the moment how to progress further on this document should we detail the use cases and go much more into the details on what network coding schemes is relevant or not I think it\u0027s not the case maybe what we could do is look at the network coding proposals in the group and see which one are relevant and could be used for the use cases we proposed and we have been trying to find some industry or interest because we are not industry and we are we are interacting with some equipment providers or psycho operators to see they are interesting in collaborating this draft okay yes a quick question no yeah-oh comments oh yes no thank you that is a very very good presentation that I really like taxonomy of the different problems um I just wanted to say I might go ahead and share a white paper that we have written regarding one of the points that you brought up around dealing with failures that are not manageable by the physical layer growth I\u0027ll be putting that away also might want to share with the chairs permission we we have a paper with decent cloud was now adobe labs and also with Doug leaf of Trinity College Dublin on network coding for SATCOM lessons learned and I think that that paper which sent a couple years ago just go into a lot of these things and I also wanted to point out some of the some of the testing that we\u0027ve been doing with ocean wolf and also with ISPs in the Pacific to provide to provide for "
  },
  {
    "startTime": "01:33:47",
    "text": "bandwidth starved cities towns and islands in the Pacific a network coding based satellite internet connectivity so you know I don\u0027t want to deluge the group but I\u0027d be happy to share those they may be I think they they\u0027re listed to the many of the the problems that were so nicely prevented in this in this presentation okay thanks if you can share data great thank you thank you thank you thank you next yeah okay thank you I thought there was no comment no question so we yeah we can switch next presentation hello I\u0027m Acosta\u0027s Amazon from when I shake it so now hi dragons talk about the status of this document I threw the net recording for CGM and nvm so at the previous meeting at the networking research group and Sen research group we introduced our initial draft regarding the its background and content so then we got some comments regarding a relationship between the kanji information ahead and the security and over and comment about the design choice regarding food determines a encoding vector to generate the Kalinda packet and its impact on latency and the comments about the clarification of the objective and the scope of this document so according to this feedback we\u0027ve made a quick update which increase the editorial update and adding the clarification regarding a pair of encryption with or without coding information and we added a case where a producers that call it aside and Kotick vector and we also describes a potential challengeable adopting the convolutional coding so this objective the objective of this draft aids to consider research challenges other whether we want to gather under the research results to establish the common understanding about network coding for CCM and we want to clarify the requirements for networking for Chien and for hope free we want to provide a useful insights to network orders in order to make it easier to apply and implement network honing in to shishya and EMM so now actual protocol proposal to satisfy the requirement is out of the scope of this document but we will we will propose a actual protocol based based on our propelled in as a draft so here the table table of content "
  },
  {
    "startTime": "01:36:48",
    "text": "current content so in Section two we introduced incision and knee and background and its basis and thus accessory we which show the existing prominent researcher desert and clarify the benefits of using initiation using network calling in shisha and we we modify the section for content naming and publish up additional code uses a feedback from previous meeting and we also added a new description regarding the adopting commercial column as a research challenges so there was no discussion about network coding Prospero the encryption in the previous documents so we added the case of we we added the kitten we\u0027re coding information is specified at the meta field not to engine name and the the information is anchor puted together with they wrote and the way discovery it feature the trees this may make it more difficult to lay anchored at mean intermediate or not in terms of the competent computational overhead for description the coefficient okay and we clarify the scenario where producer statically decides a ankeny vector to generate a collet packet and we describe its feature in this case latency can be reduced compared to the case where a consumer determines included encoding vector to be used and better in this case canta to register need to obtain the name that will get clear to the request it\u0027s a drawbacks and we are we added we modify the challenge for adopting commercial coding we added an example and the benefit of adopting confusional coding approach in the end basis and we we consider research challenges such as how to fry eight into she in terms of the signaling aspect and how to exploit a she and she Sheehan and the end of feature to enhance performance gain and we need to discuss the feasibility and the practicality so now we are going to we are going to design the commercial Corning and to apply to apply into a shisha so next step we we need to enhance the content of the security and the privacy under looting security monetary and Mary we need to identify identify the potential research challenge if we use for and then we we were starting introducing actual protocol proposal and we we hope free "
  },
  {
    "startTime": "01:39:50",
    "text": "shows a experimental result and the next an extra meeting thank you okay thank you okay I have a comment regarding security and privacy those two items are with respect to the use of network Corinne this is not in general for icn\u0027s if I understand correctly no confirm otherwise that\u0027s a big big topic so this is specific to the use of point was similar by the way a great presentation I and I enjoyed it um yeah I think it\u0027d be interesting separately from this to look at the convolutional net were coding I mean the original paper on randomly new network coding by howa table did actually consider the more general case of convolutional coding but there was a lot of recent work actually witness I and others that we have done on decreasing the kernel size for these convolutional codes and I just wanted to basically just echo that I think you\u0027d be interesting to look at convolutional coding by itself and you know of course I think it\u0027s my task look at it I see in the CCN context but maybe doing that separately and then be happy to participate in that I just wanted to mention it basically just echoing okay thank you just before you leave one more question or comment last time we said okay it was great to have this shared work between our group and the other group is its how does it work in practice you still present this in both you didn\u0027t mention and it seems to be working fine okay that was to have your feeling okay thanks okay so now we on time last presentation this is also a shot watch okay yeah so this is it\u0027s a bit different perspective of network coding and this first attempt to share this work between the this research group and the network function virtualization research group so the others are Romano who is a protocol expert Luis Contreras from network "
  },
  {
    "startTime": "01:42:50",
    "text": "operator and then me I\u0027m in the system and encoding so it\u0027s a bit interdisciplinary so okay I will go quickly so the motivation of doing this perspective of software ization and visualization is because we will now discuss that the network coding can be seen as a as a function a network infection and convincing as a function provided as an operator service possibly on demand so then we will show we will provide our arguments for this then example use cases the usefulness and then our proposal for software ization visualization for which we propose some architecture and then also we would like to discuss the links to these other working groups and other trusts on next steps so motivation so what we have our basis is that the network coding can be seen as function and CF so the point is that under the network software each station point of view we have network functions which are basically pieces of software we should be efficiently designed deploying and executed so so far network functions were just as small set of functions and black box oriented way where it was not clear how they were they could be implemented but now they are being great has a great development by different vendors for many types of applications and well beyond traditional networking functionalities so then this is our point network coding can also be designed as a network cutting function so there I will explain now and how it will be the rest of slides so why so there can be many explanations our preferred foundation is that there are two distinguishing features in network coding that explain why seeing them as a function makes sense so first the transversal application which we are witness here in this research group which it means that the neural coding can be applied applied over a packet flows at different layers and many network scenarios with different degrees of distributed are centralized coding operation hence with this transversal application if we see that were calling as a network in function this would allow us implementing network coding in a lot of cases just thinking of them as software pieces that murabba could be reused so then we could have a versatile network coding okay way of applying which can be also modular understand provide scalability and second also a distinguishing feature "
  },
  {
    "startTime": "01:45:50",
    "text": "of neural coding is that we can think of it as doing a mathematical flow engineering what do we mean we mean that with network coding we can sit like a packet flows interpreted as mathematical objects as we know here you look at it in the symbol perspective micro symbol perspective we can also see it as in the flow sense so then you can see this that the network coding will transfer mathematically the flow and induces properties in this flow so if we have this person take this perspective and if we design networking functions with allowed to interpret to interpret the network according function as a flow engineering service which then can be given by network operators and possibly on demand so this is why then in our case we do have use cases so this and as use cases we we have two very different use cases that also proves our case no our arguments for example we have this european space agency funded project which is called submit code in this case we do a very typical application of network coding for improving the reliability of multicast we use rate encoding and we assume overlay hybrid networks so then you can see that on the left you can you we have just the satellite as a as a physical bent pipe so it\u0027s almost as if it doesn\u0027t exist from networking point of view and it may happen that for this case we have very very few logical nodes that need to re-encode then on the right you have that the the network the satellite is also a encoder but what is in in interest here is that you see that we need to control the operation of network coding all along that the topology and the topology itself needs to be demise so all these controlling thing is what we can address with softer ization visualization next then you can see we have yet another completely different use case which is the use of networking for efficient caching in this case while in the other case it was another relay network we have here a broadcast also hybrid network where the satellite is and in this case the use of network coding is for the efficient multicast so you can locate that they they populate that the caching efficiently so it\u0027s very two very different use cases where our ideas can apply can be applied ok so then this was just 2 argument why what "
  },
  {
    "startTime": "01:48:53",
    "text": "we are saying might be useful and then we do have a proposal for the software ization visualization of network coding so prepping for our proposal for summarization is to have visible internal logic as opposite to legacy blackbox network functions meaning that we can have a well-defined functional software architecture that this software architecture Maps directly to solarized network architectures and this implies centralized controller which is a little bit opposite to very distribute packet networking now even if we propose this visible internal logic an agreed functional software architecture this approach also enables internal interoperability between different networking functions because you can still have blocks that are proprietary so but if we do so we can prevent the stagnation of networking ecosystems doing in this authorized networking due to that everything becomes proprietary so what we do is is like we have a I\u0027m a protector that we all agree and then there might be common blocks and proprietary blocks that for the software I session for the virtualization we we focus on on integrating they do do this all the software architectures of that you can easily integrate in a virtual network functions architectures that by doing these of course you can take advantage of a unified computation approach to computational network sources ok so then this disciplinary ideas are already in this in this draft that was we proposed to have to present here and the other network a research group so then what we have proposed is that as you can see this presentation is different to the previous one why because here we we also need two pi system thinking not only protocol thinking for this reason is important to distinguish in which domain we are because we also need to to see when we are in the coding domain meaning design of code books and coding the coding schemes in too difficult or which performance has the codes then we have the functional domain which is the the one we\u0027re talking about here for the architecture and finally finally also the protocol domain because at some point we we have all this architecture but we need protocols to be operative so so what it in this draft in particular "
  },
  {
    "startTime": "01:51:55",
    "text": "what we look at is at the functional domain what are the functions that the network code needs so in this domain we is when we make real what we said before that we propose a visible internal logic and internal architecture that we will prove that can be mapped directly to Sdn and bf and architectures so for this software architecture we what we have done is to distinguish again different functional like main functional components of the software Association of network coding so with at the moment what we have distinguished at this three which are first of all the core functionalities of course which is coding recording the coding functionalities and in the soft look we look at them at functionalities so so of course this means that we with our functions which should be able to instantiate different Network coding options for example different types of coefficients random structured regenerative at or hybrid and a different behavior at finite length for example different admissible that were calamus games and no no because the second way is important because they the second one is flow engineering functionalities so this for this means that we will be using these types of network code is we will choose depending on which engineering functionality we want it could be it could be a congestion control so that\u0027s why I wanted to make the point because then I need you in your discussions before you know we are like a logical level above you where all what you do is useful for us we will be using this so this might also mean that we could give you requirements for example right look we need and then finally we have the physical instruction functionalities this is what makes the bit relation possible so this is just another since we are system thing is when it blocks with its figures this is just a very simple way to to see that we have in the software architecture we have the functions that will map directly to this is of a defined network architectures and today and then the physical structure functionalities okay so then I will not go into detail we we we do have four readies and proposals that map our a software architecture to next to to them software-defined network we are working with network operator on this to have the key the key point here is that even you should distinguish the "
  },
  {
    "startTime": "01:54:55",
    "text": "the nodes which will Rhian code and the knows that only transport the the coded flow so there these are logical differences that need to - we don\u0027t have solutions for that so this is what we are looking looking into here so this finally what are I just now described ideas so identified links for sure with the visualization research group and the moment we we also intend to have the same presentation here and there at least at rest are with and then also with drafts one option would be this that we requirements what we would meet from this higher logic point of view but we I would like here what are what feedback I may get what this useful or not thank you divert him one of the things that I would have expected to see in this section on the flow engineering yeah is the trade-offs between open loop and close loop control because most of these naive network function chaining sorts of things only consider open loop control and for a lot of things that are classically done with NF you don\u0027t need closed loop control it it may you it may be really important to get closed loop control for a coding application where that\u0027s where you need to sort of like optimize between an encoder and decoder needs to be feedback channel stuff like that is there any thought in terms of the flow engineering part of that as to how you represent the open versus closed loop that\u0027s yet because that would you that\u0027s very good input what you are talking about is already to make it to to work out flow engineering but we are still at the moment to identify which flow engineering we want to look into and so they how comes after and this is a very good day thank you so so I guess we finished a slinky for minutes at a time which is great what well that\u0027s fine you can if you you know be my guess so anyway um I think it was a very nice meeting I think well they sign I are very happy with the progress of the group and yes we have seven documents for the moments yeah and and all of them are progressing which is great and you know the more the merrier um they will be related but that\u0027s right and so anyway so I guess we\u0027ll see we\u0027ll hope to see all of you in Montreal and again continue the great work because there\u0027s a lot of progress happening thank you "
  },
  {
    "startTime": "01:58:05",
    "text": "you "
  }
]