[
  {
    "startTime": "00:00:32",
    "text": "Sure. That I have not Yeah. Yeah. It's more or less the for debt to debt Yes. And I go, Yes."
  },
  {
    "startTime": "00:02:11",
    "text": "Ben, do you have slide control? Good morning. Hi, Ben. I I have slide control. Wonderful. Do you wanna do the interest? Okay. Well, sure. Let's get started. So, Welcome everybody to PPM. Thank you for, Michael, for volunteering to help us with minutes. As always, note well participating in an IETF session as this one incurs certain obligations on you these are legal obligations. So it is important that you understand them. If you're not familiar with them, please please familiarize yourself with them right now. In addition to those obligations, which principally an intellectual property. There are also some norms of behavior. As always, I hope this won't be a problem, but if it becomes a problem, the shares are responsible for making sure that everybody is, professional and collegional opinion. This is just an overview of some of the tools. Make sure to use the on-site tool so that can we know who's participating And here's our draft agenda for the session. If anybody has comments on this agenda would like to make an adjustment. Please come to the microphone now."
  },
  {
    "startTime": "00:04:02",
    "text": "I want to note particularly just for everybody's awareness, that This working group has 1 assigned milestone which is December 2023 to complete development of what was then called the PPM protocol. I think that we can fairly say that that is now the DAP protocol. So anybody with thoughts on that on that milestone is welcome to surface them. It it seems a little bit ambitious to me, given their their progress, but on the other hand, I think we've actually made made excellent progress toward that toward that milestone even if maybe we we might not quite hit it. So we'll, the the chairs will will give that some thought. But if anybody wants to have input on that, please mentioned it to us here on the on mailing list. So that's all for the chair slides. Unless there's agenda bashing. No new agenda items. Wonderful. Okay. In that case, We will hand it over to Chris. Who's local. This is like you want me to use yes, yes, yes, yes, Okay. Alright. Can folks online hear me? Let's assume, sir. Yes. Okay. Cool. So the goal here is basically so I have 50 minutes. So this is basically, time spent on kind of the nuts and bolts of the protocol."
  },
  {
    "startTime": "00:06:01",
    "text": "I do see a lot of new faces here, which is great, but isn't gonna be super relevant to anyone who hasn't read the protocol. But if, you know, I guess if you have questions about how the protocol at any point, feel free to ask. We have plenty of time. Okay. So If I miss any issue that you feel is important to discuss, please, please please bring it up as well. I'm gonna go, next slide. So what I've done is kind of like aggregate the kind of the, the main open issues and put them in an order that, I feel is, you know, like, biggest to like, most, most niche so this first one is, actually corresponds to, five issues that have been filed over the last, year or so Some of these are kind of bugs. Some of these are, wow, there's probably ways we can improve the communication cost. So, in support of a couple of use cases, A feature of that is that you can collect a batch of reports multiple times. Each time with a different aggregation parameter. Is anybody I wanna ask what that means? Anybody in the room? K. We're gonna move on assuming everyone knows what I mean. So in particular, this is in support of a couple of use cases. So drill down which we're gonna talk about a little bit later on. This idea that you kind of wanna poke at the data, look at it, look at different like, like, split aggregates in different ways. And then heavy hitters, which is, there's this VF called Popplerone for which this, this was just fine. And you and you need to be the the ideas that you need to be able to kind of, query this, a set of reports on a different set of candidate prefixes at each round of collection. So our requirements here are security. Like, there's, it is only safe to There are only certain sequence of collection queries that are safe, and these are spelled out in the VDAF draft on a per VF basis."
  },
  {
    "startTime": "00:08:03",
    "text": "So we need to make sure that we're enforcing the conditions that are spelled out the particular PDF. Okay. So the core problem is, you know, we've envisioned these these use cases in the draft, but we, no one has implemented this. There are 2 existing implementations, both of which only implement Prio. And, neither has tried to, like, flush this part out in in the design. So we, folks have pointed out potential bugs, basically, Okay. I think all we can do here is someone needs to implement this and then propose a PR to address any issues. And then another possibilities, we just make dApp only compatible with with So I wanted to stop here and see if, anyone had, a preference, a preference, for each either of these proposals or had an alternative in m on q. Simon. Hi. Southern Frieder. I think let's just not do 2. Because we still want heavy hitters. Also, I think there's a bit of an issue because you're saying collecting batches many times. But for drill down, you need to collect reports many times in different batches. That's just not that's a that's not throw it away. Okay. Okay. Okay. I think, yeah, I think you're right there. Do do we have anyone who is raise implemented. So I will implement this, sometime next year if anyone doesn't get to it first. 10 Yep. Definitely planning to implement this in, in Yannis at some point, it's not exactly clear when, like, we're very focused on shipping preovased use cases right now. But we we definitely wanna do this. It's tempting to kick"
  },
  {
    "startTime": "00:10:03",
    "text": "like, everything but free out of DAP for the sake of the simplicity of DAP, I don't think I have a more developed thought than that. I'm not I I don't feel prepared to commit to, like, saying, but it's a good idea right now. I I suspect that, like, it's pretty close to being capable of doing, capable of running the VD apps that have an aggregation parameter in multiple rounds So on balance, I'd say, leave it in. Other thoughts? K. We're gonna take proposal 1 here. Unless I if anyone wants to object please, contact us on the, on the list. Next slide. Okay. Alright. So this has been kind of a pain point for a while now. So there's this, there's this need in the DAT protocol to have, batch selection logic. The idea here is the aggregators need a way to partition reports into distinct non overlapping batches. And the way this is defining the protocol is, there there is these query types. Basically, the collector gets to query, the aggregators to get, to to get the aggregate for a batch of reports. So different semantics for, like, different strategies for different, Excuse me. Batch selection, processes would, would be kind of formalized as different query types. We have 2 right now time intervals, basically, where collector says give me the aggregate for all of the reports between T1 and T2. And then you have fixed size, which is I don't really care how you partition reports, just give me just just give me, like, like, an I a unique identifier for each batch of reports."
  },
  {
    "startTime": "00:12:01",
    "text": "So the problem here is that supporting multiple query types is, has turned out to be kind of a pain for implementation. I've, I've noticed this in my own implementation and, if you look at the issue here, Brandon has a very long and very well detailed kind of treat us about why this is not a good idea. So I I so the the kind of the main observation is that this query type called fixed size is basically gives us all of the functionality we need right now. As long as you're willing to kind of capture different batch strategies as, like, out of bandbusinesslogic implemented by the collector and leader. So the ag just like concretely, the idea is like, you can kind of emulate, time interval kind of semantics using just the fixed size query type. So, go ahead, Tim. So, okay, I think this has to be refined a bit, especially in light of the the discussions we had at the last IETF where, like, I brought it forward with the proposal of, removing time interval queries from the protocol. At that time, there was some pushback on that. Like, some arguments that it was necessary. I it. Wanna misrepresent those arguments by stating them poorly, but I think for instance, like, One of the, one of the notions was that you need something like time interval to be able to align data you get through gap with data received from, like, other other metrics systems. But I think with what's being discussed here in my mind is not necessarily, like, removing time interval Right? Or, or trying to show that we can come up with some, like, flavor of fixed size, but it is equivalent in some respect. I think it's Or you tell me, Chris, I think what this proposal is about is like making the helper specifically, agnostic the query types. Right? Yes. That's basically right. But the other thing we're do we would do is remove kind of"
  },
  {
    "startTime": "00:14:03",
    "text": "the the query type logic from the protocol altogether. So all you have based quickly is you assign the the leader assigns reports to batch IDs by some opaque strategy. The question is whether that's good enough. Yeah. I wonder whether I think we'd have to dig into whether you could still specify whether the leader, should accept uploads Right? Guess you could write that text in terms of Yeah. Excuse me. What do I mean? Like, currently in the time interval case, we save a leadership reject and upload if the time stamp falls within, span of time that has already been collected. We'd have to make sure that we can still reject reports appropriately if we remove that, like, the formal notion of technical queries from the protocol. Yeah, I think that we could. I think that's all I have. Couple of people in the queue. Chan, Hi. I related question. If we are removing the fixed interval type. Can I also relax the fixed side semantics So the max size is optional? I think we I think we would just remove I mean, we can make it optional. We could also remove it. I don't I don't, I don't, I don't, care which one we do. Do you have a preference? I would I would prefer we still have it. Cases where we want to limit the size of a batch but also make it, optional for the case that we don't care. Okay. So I think we could work that out, in a PR. If we, once we actually, decide to take this, if we decide to take Cool. Thank you. 7 I'm happy with any improvements, to performance and otherwise, but I would"
  },
  {
    "startTime": "00:16:01",
    "text": "vote for a proposal tool here to do nothing at the moment because we have it specified we are using it. So Yeah. I think it's just complicates things if we now decide that we don't need it, and it should be out of bands somehow. So, Mozilla is using this? We are using time at the volatility when you I think then we should keep it. I think, Daphne might might remove this feature, unless you ask us to keep it. But, But, yeah, let let us know. Okay. Well, I mean, we have one person using it, I guess. That's news news to me, Tim. Yeah. Thanks. Sorry. Yeah. Simon's comment, jog my memory. So, Chris, you made a point about, complexity for implementations with respect to this proposal. And the thing is, to Simon's point. Okay. So if time interval gets, like, downgraded to some that is like business logic sort of out advanced pest option, collector, and leader that means that implementations that wanna do this, like, still have to carry the code that does it yeah, still still have to deal with maintaining the code that does it. So I think that undermines, like, the argument that this that this, like, simplifies implementations Right. What I mean is if we take this out of this back, if my implementation still has, like, a subscriber that wants to use time interval, then I don't I don't get actually delete any code. So you'd you'd have to your subscriber has to, like, you have to figure out how to emulate the, emulate the same kind of thing in a world where you just have batch IDs and reports. Yeah, I agree. I don't I don't think that that's impossible, but then I think the challenge for the working group doesn't become just like let's remove mention of time interval from the protocol. I think it becomes incumbent on us to write out how would you achieve time interval like semantics using, fixed size? We could. Yeah. We could do that. We could do that. I think there's one other. Oh, hey, Ben. Hi."
  },
  {
    "startTime": "00:18:00",
    "text": "It Is there is there a simplification possible here if a given task config commit to one query type or the other. Rather than allowing both, It already does. Okay. Okay. I think I'm hearing people are, wanna do proposal too. Does anybody object to sticking with 2, implementations, do nothing, acknowledging that implementations are free to not implement, query types. They don't wanna All right. Alright. Cool. Cool. Cool. Next slide. Again, if anyone objects or has further comments, we we can keep discussing it. Okay. Supporting drill down. So the idea is, like, you have your computing you wanna sort of, like, break down aggregate results by, various properties of the client. So imagine you want like, give me the give me the sum for all user agents equals equals Mozilla or or Firefox or whatever. Or geolocation equals equals a a prague. I don't know. So you have sort of like arbitrary labels assigned to reports. And you wanna, like, be able to query the database for, like, for a given label or a given sequence of labels. There's obviously, like, you know, we're getting into a territory where sort of we're sort of wanting to, like, get something from, like, SQL. That we're used to, when we're when we're interacting with databases. I guess, like, you know, how much behavior of SQL you can emulate kind of depends on"
  },
  {
    "startTime": "00:20:04",
    "text": "your your threat model. So, with this particular issue, the main objective that's been brought up is If, clients are labeling their reports, well, they're you're you're adding potential to sort of like fingerprint clients. So, like, how do we constrain the the semantics of these labels such that they don't give arbitrarily drilling down on data until we end up de anonymizing, like, learning the measurements for clients, with a particular very specific label. On the other hand, like, you know, you still wanna enforce minimum batch size because, in order to get some some notion of privacy, you you you wanna make sure that the the anonymity set is still sufficiently large. So there's sort of like a weird kind of privacy you to usability trade off space here that, kind of gets complicated. But, but nonetheless, we can, we can do this. So Tim wrote up like a concrete proposal for, like, adding labels to the report metadata, and we can discuss, like, how we actually like, want to constrain this, if at all, I wanted to bring up another possibility. Tim also suggested, well, maybe, like, is there a way to do the like like split late aggregates by label, in MPC. So we have we have been exploring this problem, and there will be a, a new VDAF proposed at CFRG on Thursday. Called Mastic. Mastic is a lot like popular one except it has some additional functionality. In particular, it allows you to kind of like give me the act, like, you have, like, preole, like, function optionality except you can break down the the the aggregates into"
  },
  {
    "startTime": "00:22:02",
    "text": "and you can kind of partition the aggregates for, by label. So, like, get me the sum for all clients with this label give me the sum for all clients with this label and so on. Neat thing here is that, In doing so, you don't reveal which client has which label. So my claim, and I think we still, you know, we still need to do security analysis for this new for this new v V dev, but, my claim is that you can you can get a you can relax like the second requirement to enforce the minimum batch size because you the anonymity set is still the same size. 10, Thanks. So in the master scheme, if I'm doing a query but it involves labels, does that get represented in the DAP aggregation parameter? Yes. Okay. So, really, what I'm getting at is, if Mastic, like, has all the proper that we we all hope it does. There wouldn't be any there shouldn't be any data level changes needed tour it to work. Is that correct? No. No. Think that we need to get the we need to get the the collect a batch multiple times thing. Right? But that's it. Yeah. Yeah. But that's, like, we need to get that sorted out for any VDAF that has aggregation parameter, but it's not like a master specific problem. Yep. Okay. Okay. Okay. Thanks. So, Sean, before you, before we answer your question, I wanna point out that this has limited functionality so we can't we might not be able to get every kind of query pattern we would ever want. So we're this we're constraining how we can use the system, but, it's it it might be in a useful way. Okay. I see a long queue, so I'll I'll stop talking. Let Shannon talk. Okay. Thanks. Can we not resolve this by just creating one task per label. Yeah. So as as Tim points out"
  },
  {
    "startTime": "00:24:01",
    "text": "in at the at the top of the issue, this doesn't scale very well if you have, like, kind of arbitrary labels So I know you're a big fan of task Prov. But like setting that aside, not everyone is a fan of task problem. This might be easy in task from, but in general, it might not be easy to to kind of spin up a new task for every old, label that you would have. Potentially, yes. But, Yeah. But it's but it's like We recognize that there might be limitations with this approach approach alone if you have a lot of it's Who's Chris Ward? Yeah, we, we kinda, face the same exact or a similar problem in privacy pass where we have this, potential to, like, add different label tokens and doing so might, like, increase the fingerprinting surface. There's other ways to increase the fingerprinting surface. So for convenience, it's nice to be able to label things. That has been sort of the the emerging argument. So I I don't see any problem with one, even with the the the the labels are potentially fingerprintable argument, especially because clients are, like, ones who are slapping on data on these labels, and they're in control of what their fingerprint is? Like, they could just choose to not put put labels on reports, that's totally fine. It's up to a deployment to ensure, like, what their overall privacy story is and whether or not they'll data they're putting in labels is, like, it contributes meaningfully to their fingerprinting surface. So I think we can safely punt on that. The the the complications with, like, how you need to issue your queries and what that means about what data you can collect. That I think Tim noted in the issue. Those are those are reasonable, but, again, I think we can overcome them. So I I I think we should just do two do both, like, continue on the master stuff, get that bdef working for us later on. If there are legitimate use cases for this drill down right now based on labels, so it's just the proposal one to start. Yeah. Yeah. So just, like, get the wire changes done in case we need them. Yeah. Yeah."
  },
  {
    "startTime": "00:26:01",
    "text": "I like that. Cannot hi. So I guess I just want to raise a concern that without having something like this, we had a nice property that a client has assured that the only thing, the that can be collected is an aggregate over a lot set, and there's no risk of my data being personally released. Whereas as soon as we start doing this, there is a risk that you can even with minimum batch size, you can do differencing attacks. You can do reconstruction attacks. Which can allow which can break that promise from a client's point of view. And I think there is a risk of, losing participation because of that So I think we should I would not caution here. Yeah. Thanks, Kunal. Been in case. Ben case, Meta. I work on private as measurement proposals in the pat CG. And we have a use case where we would like to essentially have these labels. Kinda help it's very helpful for supporting large label sets. But I think in the particular use case, the fingerprinting isn't so much an issue. It's a little different setup. Or a server light, gives a client a request and gets back a report, doesn't know what's in it, but can then label it. So it seems like the the fingerprinting is a little less of a concern there. And the other thing I wanted to say is that on these concern that that Kunaal had as well as this lower point here about, like, potentially overlapping queries here. I think there's, like, just shifting toward DP in-depth is gonna help solve a lot of these issues particularly the single client or re identification attacks is is like the right way to address that. And also, I think we would actually like to be able to support one report having many labels and to do that in, like, a like, the DP optimally way where you actually might"
  },
  {
    "startTime": "00:28:00",
    "text": "want many outputs for a particular report. And, you know, if that number is sufficiently large, you wanna use some advanced composition for it. But so I I just wanna kinda really like plus 1. This is a really in kind of useful, functionality and and happy to kind of think more about some of the details on Great. Tim. Thanks. Yes. I just wanted to double down on what, Kunal was saying in that, like, this could be very powerful, this labeling functionality. In fact, as as Ben just pointed out, but like I'd say a challenge that we've had at atuhat Divya where I work, in deploying this stuff is that Like, there's a lot of things you have to do. A lot of parameters have to choose very carefully or you have to think very hard about and whether you're undermining privacy, if you like, deploy it this way instead of that way. So I don't know. I think we have to decide as designers of this protocol. Do we be sorta safe bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike do we want it to be resisted against misconfiguration, or do we wanna like, yeah, well, there's this labeling stuff. Or there's this differential privacy stuff, but, like, you better employ some really talented cryptographers who can help you choose good epsilons or like tell figure out. You know, what the result what the privacy set, you'll end up with if you choose so and so set of labels is. I'm honestly not sure what the answer to that, to that question is. Anyone else in the queue? Nope. Could we do a our PPM's first time if I, Simon's in the queue. We can do it in the tool. Oh, cool. It's a bit. Simon, you wanna say something? 1st a while. It seems that the the miracle. Maybe, just I think I just said this on the issue already that I think, if you wanna do fingerprinting, maybe if you wanna single out reports, the fingerprinting is not that important because the leader sees IPs and can use that. And also, I mean, a lot of the things that that can be done with additional labels you can also do if you implement the labels using separate tasks. So"
  },
  {
    "startTime": "00:30:01",
    "text": "I really like the suggestion of why not both Yeah. I mean, I think there's We with proposal 1, I think we still have a lot of thinking to do because We want the flexibility, but we still want to be strict about enforcing, like, some like, minimal, and an image set. But it sound I mean, like Ben's suggestion sounds to me, like, maybe we can kind of relax that a bit if we have something for differential privacy, which sounds right. Now, I mean, as Tim said, you know, there are lots of sharp edges and things to configure. Right? We're we're already pumping on this in the draft by saying, we're not saying what the minimum batch size should be. Yeah. Yeah. And I'd kind of agree that I don't want to get into the weeds with this, and I don't want to figure out what the differential privacy parameters have to be if you're collecting the same report in 18 different queries. And you don't know with what else. But but but It seems like a more useful way forward. Yeah. So let me just say for I so I think the scope of the should be like, maybe we don't solve all of this at once, but we add the wire changes that are needed in order to support this. So, like, should we do that is, I think, Should we add labels? Yeah. Should we should we add label to the report, labels to the report metadata? Take a shot, shout from the queue. Oh, okay. Yeah. Go ahead, Shannon. Just a very quick comment, someone under many others I mentioned, there are other ways to fingerprint already. I think most of the other fingerprintings, right, can be addressed by some separate technology, like O HTTP to get rid of but the rebooting fingerprinting is inherent with the whole aggregation process. I think it's once we introduce that, it's harder to mitigate than things like finger finger printing from source IP or connection."
  },
  {
    "startTime": "00:32:00",
    "text": "Yeah. So totally agree. Oh HTTP won't help you if you send labels and those get pass through, but that doesn't mean that we can't figure out a way to balance the labels with the DP. Fair enough. Right. So the question is, are we making the wire changes to add the label Yep. Yep. Yep. See if that full on the screen behind you Chris, not just what you like. Yeah. That looks good to me. Great. If I could just, like, elaborate on what Simon was saying earlier. Labels are not, you can still do exactly the same frame we're printing by just giving each, Like, for for each, like, unique label partition or permutation, create a unique task So labels are like, purely a convenience thing. There's, like, no difference between what we have now and dApp wood labels. Like, exactly the same misused probability pickup. Like, so this is, like, purely aesthetic. I've I've but Yes. Yeah. For, like, for the the example, Gabe, was, like, say you want like, 2 labels. 1 is user agent Chrome. 1 is user agent Firefox. You could just implement that by saying there are 2 tasks. First task is for Firefox. The first second task is for Chrome. Done. It depends on how complicated you get with the queries. What if you wanted to know the aggregate for the intersection of the clients who share some feature. Is that, like, a a feature here? Like, you want to be able to support. Like, that's how I took Ben's suggestion. But I could be wrong. Okay. Well, I think that that does complicate things a little bit, but, It the perhaps we need a little bit more specificity in terms of, like, what what what it means to add labels, but I just assumed to mean, like, a label was just a a way to, like, refine a task. Yeah."
  },
  {
    "startTime": "00:34:01",
    "text": "Which is why the question here right now is not to necessarily drill down on on the complete semantics of of of of labels, but just to say like, let's add the wire change so that we can implement the wire change, and we can use it later on if we need it. Yeah. Yeah. Yeah. Bearing in mind folks that there there are organizations who, like, are wanting to ship this, like, very soon So we wanna get the wire changes done that we will eventually need if we can. Clear, like, people can still ship this without this being an RRC. Like, that shouldn't prevent people from shipping We could sit on this for 5 years and draft and still ship it. That's fine. On modify for Jonathan, you wanna go to the Actually, Jonathan, you all wait and queue and then go to the mic. Gotcha. Gotcha. Gotcha. I I'm going to close this poll if only for the aesthetic reason of people seeing this proposal in file in in the room again. And let's take the rest of the queue. Cannot, so, yeah, I guess just wanted to at I just, Chris, I think while a single label definitely can be addressed by, I mean, can be handled by having multiple tasks when you have bunch of different labels. It's very easy to I guess it's not transparently possible to simulate all of that large collection of, features and you can actually do much more of a communator combinatorial set of queries, if you if you have multiple labels and something like this. So I think it does increase the effects of of the kind of queries you can make. Yeah. Tim, it might be sort of moot since judging from the show of hands results, it doesn't seem like Well, I'll let the chairs"
  },
  {
    "startTime": "00:36:03",
    "text": "pronounced. But anyway, I just wanted to to to make the point though that, like, we're talking about here is whether to do plumbing changes to add labels. Right? I think we're not talking about designing and specifying a query language over those labels because I think that's so much harder problem that I am the I don't know. I'm I'm less enthusiastic about tackling. It feels like we'd be doing enough plumbing right, to allow labels to appear so that, like, possibly implementations could do something with them. I I Unfortunately, Ben and I are not in person where we're not whispering to each other here. As efficiently as I would like. I'd like to understand more of the nose. We we we had a the record, we had about a fiftyfifty split among those responding to this poll. I'd like to understand that no position better of of why not make this wire change. Even if you've spoken on that, would you say more Shan. I want to know because I think this just opens a possibility of more attack just having it in the standard, even though We we're not gonna use it, but, I think it's just I don't think we should put it in the standard until we figure out the the impact on privacy. That's my stand But just to be clear, the the the I well, Chris, I think is about to say the same thing as I am so very quickly say, can we just, like, punt this to perhaps a separate draft that defines, like, an extension for labels and then like, like, work on it there. Have to block the main draft on this. You don't have to solve this now, but, like, That's true. To It could that way out. It could be treated as an extension. Mean, it's potentially, I'm gonna be fair. Yeah. With Eddie. Okay. Does anybody who wants this feature, would you be okay implementing it as a report extension?"
  },
  {
    "startTime": "00:38:07",
    "text": "Jonathan? So this this is, just a strict question because I don't understand fares you. Is If I sorry. I wrote it down. Does combining labels, make more information available than just having multiple tasks. Because in my understanding tasks, Reports from different tasks are not bound together. Whereas, labels, you can bind together. Because otherwise combining is sort of meaningless. A report is bound to a particular task. So it can only be processed in in a given task. So Chris's suggestion that labels and tasks are the same. Is not true then because you can't combine tasks because they're separate. It is true in the sense that if you if you want to emulate like, aggregating by label, then you have a different task for each label. And combining labels? That's not possible. Then I do understand your last line on the slide. Where you explicitly combine labels. Yeah. That's that's a that's a mastic feature. That's not a feature of Prio on its own. In any form with with that currently. I, there's there's issue others issues to get through. Don't know if we're having the most productive conversation about this. I don't know if everyone has enough context I wanna suggest that we take it off list and try to reach reach consensus on on doing this as an extension. Anybody object? To, does anybody else wanna say anything else on this topic? Cool."
  },
  {
    "startTime": "00:40:05",
    "text": "Cool. Alright. Next slide then. So now we're, this is kind of the last meaty one the rest are gonna be kind of nitpicky ish. So, there's a a desirable property of DAP is that honest parties that execute a task agree on the parameters of that task. In fact, this is sort of a sort of a a requirement, basically, like, an honest client, in our our in our threat model, you might have the collector and one of the aggregators doing something malicious and actively attacking the protocol, as long as one server is honest in correctly executing the protocol, then, then you have privacy. So, The question is how do honest parties know that they are that they agree on what the task parameters are. So think things like minimum batch size. How do I know that How does the client know that An honest aggregator is enforcing the minimum batch size, it wants it to enforce. Oh, well, go ahead, Tim. Well, sorry. I wanted to let you finish the slide before I before I jump in. Okay. Well, there's, there's kind of, There's three things that have been suggested for, how to like, like, what we want is basically, like, some guarantee that if I'm executing the protocol, then, honest parties agree on the task parameters. One way to do this is there are these bits in task problem, which is gonna be for presented later on. Where we basically derive the task ID that kind of identifies the task. From the task config itself."
  },
  {
    "startTime": "00:42:02",
    "text": "So that implies if if, if you and I compute the same task ID, then we also have the same task parameters. One suggestion is that this is a nice feature of this draft and maybe we can pull it out in some form perhaps move it into the core core protocol, or do something else. Another proposal is just, you know, pick the pick the parameters that we feel are most important to have agreement on and, add those to the AAD for HPK encryption. That way you have a cryptographic binding for to those specific values. By the way, you have the same exact thing with proposal 1. It's just more general. Because the task ID is part of the, the AAD for HBK encryption. And then the 3rd proposal would be basically more or less what we have today, but might need to refine the text text a bit. Basically, just say there must be some mechanism that guarantees that honest parties agree on the task configuration. Anybody not understand the problem statement here? Anyone online? Tim or Nick, are your hands up to to say you don't understand Yes. Go ahead, Nick. But, issue 500 and the repo is making privacy relevant task parameters visible to clients. Is that also what you're talking about here, or is this a separate That I believe is, I'm I'm basically what I try to do is boil down there. It's Yes. That this is an attempt to kind of, concisely state restate that problem. But if if you disagree, let me know. Well, it it just seemed like a agreement on the parameters and making the privacy relevant parameters visible to clients seemed like different things to me, but if they're the same, that's good to know. Well, I okay. So"
  },
  {
    "startTime": "00:44:03",
    "text": "you could, I guess, refine this statement to agreement on privacy sensitive task parameters, or maybe Nick just wants to say that the agreement is not just between the aggregate but also with the client. Yeah. That's that's the goal. That's absolutely the goal. Honest parties that is clients or or aggregators. Alright. This is not you're not about saying it's not clear. Right? It is, So just go ahead. Jonathan. Is it a requirement the client understands what the parameters are or just that it agrees on them. Yeah. I would understand what they are. Everything is everything in the task config is sort of selled out And as well, the fact, because, like, an opaque blob is I can agree on it even if I download There are no opaque gloves. Is is Tim still in the queue? Tim still in the queue. Yes. And I think he has an opinion on the on the resolution. A a must have yelled at me. Go ahead, Chris. I I was gonna say I like proposal too. You know, in particular, it's not clear to me that this is necessary for every single deployment of this. Again, you could just sort of make this an extension. That is then didn't do the AAD for HPE and then in that extension, you describe what the relevant semantics are. Cool. That seems like in the quickly way to handle this. And it would be an extension that falls out of task provisioning which, as you said, attempts to do a little bit more. Yep. In fact, you could probably build past provisioning on top of this existing extension by adding some more stuff. I suppose you can. I'm It's not intuitive me that this would be an extension"
  },
  {
    "startTime": "00:46:01",
    "text": "just have an extension that says, like, parameters, and then it has the values in it. And then all the reports carry that. That's part of the 80. I mean, that would So I think the the task prompt extension already, accomplishes the its goal. It already accomplishes kind of bind all task parameters to the task ID. So I don't think there's And that is a proper report extension. Yes. So I I, yeah, I don't think there's anything to do there. This would just be like, useless work from the perspective of probably, or redundant work from the, but it's not very expensive. So I have no and I think test pro, as you said, is is again trying to do more. So this is taking up that peace peace that just solves this particular Lot of task problem. Great. Yeah. Treat treating that as a just a single extension. Yep. You would layer on top Should we take Tim finally? Thanks. My I think we should do proposal number 4. Nothing. So as Chris Patton laid out. None of the proposals that are here, like, change the fact that that, you start to assume that, like, the aggregators are honest. Right? So even if we do something to speak like test parameters into VAAD or such, any aggregator just, like, lie about what parameters it's using. And and again, as Chris argued, like, this still relies upon, the privacy model of DAC, which is honest aggregators. So unless there's some, like, cool cryptographic construction that I'm not aware of where you do get, like, some, some binding between task parameters and what the aggregators are doing such that, impossible for them to defect. I don't think it's worth adding stuff to the core gap protocol. Right? So, like, particular deployments if they wanna do as task prep does, if they wanna do something that that introduces that binding then and to some extent, like, proves at least agreement amongst all the participants been, like, neat. But"
  },
  {
    "startTime": "00:48:01",
    "text": "DAP makes the choice to, like, leave task parameter negotiation out of the spec. So I don't know why we would tip bring, like, this one little piece of task parameter negotiation into the spec. Cool. Let that be a number, proposal number 4. So, any of their votes Sharon? Shannon, thank you. I'm sorry. Yeah. So my vote is number 1, but I think I say I'm biased. I think that number 9 is slightly more flexible because Did you find the task config? Any new parameters you want to add to task config, it will automatically be agreed upon between client and aggregators, but I can imagine you can achieve a similar thing to these proposal too, but just to response to our team, said a bit earlier, why do we need to do this negotiation? I think it's not about negotiating a parameter that's put it proof. I think it's a lot about transparency and auditability. So the client can see what parameters that it has agreed to an into the client have has a choice to either not open to or you know, did you kind of find out if something some dishonest aggregator is sending them really long privacy parameters. Thanks. I agree with Sean. Both 12 seem good. And they're both free on the wire. And just clear up the situation. So I'm gonna take that as a vote for 2, 2. I just I wanted to clarify, something, in response to what Tim said, which is do nothing. I think my my suggestion for pro proposal too was to make it an extension which means it is not part of the core spec. Which can be considered do nothing. Because you would define the separate extension, which describes, like, what the parameters are, and then how that's found to the AD."
  },
  {
    "startTime": "00:50:00",
    "text": "Record. I I think that, like, is 2 and 4. In a way. Like, does not affect the course back. Do do this, but an extension. Yeah. Exactly. That would be technically a little tricky. Why? Because So your AAD that you're constructing today includes the report Oh, it also includes the report metadata. Yeah. And you could just stick your privacy sensitive parameters right in there. Right. Chris is right as always. No. Not always. Although if I understand Chris correctly, would also require actually sending those things over the wire then, which doesn't add anything. It would You could. There's a couple things I think you go ahead. Oh, yeah. I understood, to to also be sending it on the wire, but it's just it it is it 2 is not sending it on the wire. Yeah. You could you could do it either way. I don't see, you would, I guess, like, if you were sending it on the wire, you would all want the aggregators to, like, check that it has the right value. So Yeah. That's that was my mental model for this, but I heard Simon just say was that number 2 is just like, you literally what I guess an AD, but you don't send on the wire. Just, like, assume that the other person's gonna use the same value in decryption. Putting on the wire sounds simpler. It also addresses the transparency, concern that I think Shannon has really been advocating for. But, again, I maybe that points to, like, perhaps we don't have a shared understanding problem is we're trying to solve here. If it's just transparency, then something needs to go on the wire. Yeah. I don't know, Sean, if you can say, like, what is the most important problem you're trying to solve here, would be helpful. Yeah. For me, transparency is the client can see what press parameter has been decided for a task. So if the new archive is 1, then something's wrong. As a client contributing to a task of wants to know these parameters. Simon, you're still in the queue? Oh, 10."
  },
  {
    "startTime": "00:52:00",
    "text": "What was I gonna say? Right. On the test prep question, and Chris Batten, since you're one of the authors, I think you can double check my thinking here. But, like, I wanna make the point that the can't just, like, for free hoist what's added in task brought into the the main document and get agreement on, like, task IDs In particular, task profiles specifies that participants have to out of band negotiate this, like, This one bit of randomness from which they'll generate, although, the V. F. Verify keys. So So, like, that now it's something we're tugging on this thread and stuff and, like, there's some, like, tangled knots on it. I'm worried that if you take some of the bits of task prop that do, like, the parameter agreement voice them up into DAP. Now DAP is telling everybody, like, no. You thou shall prenegotiate this, like, bit of randomness from which to generate task parameters, And suddenly, DAP is much more opinionated about, like, how you negotiate tasks than it ever was for And I think we gotta avoid that. Which is what's nice about too. Right? We already declared that everybody has the information that they need. If we just add it to the AAD of the encryption, we don't need to transmit it. And and and will still notice whenever somebody disagrees because the reports won't decrypt in Yeah. Yeah. I tend to agree. Like, gonna do anything. Adding stuff to AADs is, like, relatively simple and doesn't increase message sizes, which is nice. Okay. So I think I'm hearing a majority for doing nothing. Doing nothing and then, like, double underlining that extensions can can do whatever they want here. And task proff is like proof implemented proof. That you can do this stuff if you want. Yep. Alright? Work for you? I think so. Cool. Alright. We're gonna do nothing here. We just have a few minutes. I I is there any way way to get a little more time? Do it. Go ahead. Okay. Cool. Next slide then. I"
  },
  {
    "startTime": "00:54:02",
    "text": "I hope this one is easy to resolve. Yeah. I don't know. We'll just find out. Okay. So, batch mismatch is a condition where the 2 aggregators don't agree on the set of reports are included in a batch. This leads to a the following problem. Basically, you can't Your aggregate shares when you add them up, they'll just they're just gonna add up to garbage. So this is like a fatal state where you can't recover a batch, a a the aggregate for a batch of reports. What we've done is add plumbing's, to kind of, detect this. We'll talk a little bit more about the mechanism in a bit. And we've also taken measures to make bad this condition less likely. So it can still happen So if, one of the aggregators kind of, like, loses like gets it state corrupted or something like that, then you're gonna end up with, a problem. But we hope it's rare. So, the my proposal would be to do nothing and close this issue, an alternative is we can try to think of a mechanism whereby the leader finds, like, finds basically figures out which, which reports are missing and resend them and, try to recover. So right now, we're just doing detection. Do we also want error correction? Go ahead, Simon. Does the mechanism that we have cover this kind of DOS attack where I occasionally send a report that decrypts for the leader, but doesn't decrypt for the helper. Yes. So I mean, so that that report would be rejected. So in the if everything goes well during the aggregation flow, you're just gonna remove that report from the the set. Is anybody objected to doing nothing here and, and closing the issue."
  },
  {
    "startTime": "00:56:07",
    "text": "Mike, are you trying to get into the queue? Everything. During the So now you have questions here. What's your last name, Mike? Like the shop naive question here, but if we can detect it, and we already have a case where reports get rejected. Would it not make more sense to have the report Drop and drop the ones that are mis misbashed. And just indicate that there was a mismatch so I believe what you're asking is actually, what what are you asking? So it is there a mechanism when we can detect batch mismatches? Do we know which We don't. We don't. And could the leader not just start over anyway? Or would it have to be resubmitted? That would be proposal number 2. So, like, if if Right now, that's not possible. You can sort of maybe do something hacky and very inefficient. By just because so the the helper is supposed to reject reports that it's seen before. So if you just you resend you resend all of the aggregation jobs And all of the reports that get marked replayed, you oh, assume, oh, that was in there. And I actually know that technically technically could work, but it would be very ugly. We would wanna do something better, I think. I'm I'm inclined to say effect in this match and mark the report as this may be invalid That's one. But but but but So you're inclined to just do detection and or okay. Okay. Thanks. Tom, It feels to me like"
  },
  {
    "startTime": "00:58:01",
    "text": "proposal number 2 isn't really like fleshed out enough for to be able to have opinions on it. You know, like, I think we would need like, not a completely worked out or much less implemented, but something more concrete, like, of like, what are these misfits? I guess, expanding on on my next question, like, are the mismatch scenarios that we envision and what do we think we could possibly do about them? It seems like, well, how hard would that be to implement the other thing that kinda I also worry that there might be some, like, surprising privacy attacks here because, like, Saflo's either aggregator is, yeah, is malicious and then is, like, pretending to not have reports or whatever. Maybe I don't know. Maybe the helper is, like, maliciously, failing to do aggregations in an effort to get the leader to try to resend it, like, the same batch aggregation multiple times, but with just like plus minus one report to try to do some differencing attack. I don't know. I worry about this could be very nuanced area. So we need more, I think we need more concrete proposals of what to do about it to assess them. I agree with that. I think that we actually have the the the way we do report partitioning today is sufficient to to, to defeat differencing attacks that might come up. But, the I agree this is not fleshed out. So the the the task would be if we want to do something the question here is, like, do we want to do error correction, in this case and then we would try to out someone who's willing to, do the work. And what I've heard is no. Although, if someone does it, we wouldn't automatically turns away. Oh, absolutely. Yeah. Absolutely. And you've got about 4 more issues and about 10 more minutes. Okay. Cool. We're gonna take one right for now. Alright. She protects. I'm speaking of the so the mechanism whereby we we've learned if have a batch of mismatches. We compete this thing called the check sum. This is basically like an X or of the hashes a bunch of report IDs. Kind of a weird thing. I acknowledge This is not part of, like, attacking this, like, the the the cryptographic security of this thing."
  },
  {
    "startTime": "01:00:01",
    "text": "Attacks you can do, but this is not really in our threat model. Well, I do post the question in here, should it be in our threat model? It's not right now, but we can consider something about this for defense and death. Okay. I did this in the wrong order. Yeah. So the the reason we have this check sound is detect batch mismatches, the implementers feel this is necessary and useful to still have in the protocol, so we don't wanna get rid So there's, a few proposals for what to do Martin Thompson would like to make this cheaper and he has some ideas for how to do that. There's a, there's a, he has a proposal there. Chris would suggest we can make it optional, like just, have this be something that's like lifted out of the message and, like, added to, like, the the query parameters for the URI. Or, my proposal would be to do nothing because compared to the the crypt crypto bits that are around this, it's it's relatively inexpensive. And I note that Martin's not in the room. Martin is not in the room. He watched by a moment ago. We didn't come 10? So I have an implementation that already does this so, like, that introduces advice in my mind. But I would be in support of, say, I I I think supporting Chris Woods's proposal which would be taken out of the spec and but then implementations still stick it in either query parameter or, like, in a header in the HTTP question responses. So you could still do it. And then we have, you know, but I also wouldn't mind leaving it in because then my implementation's already, complying with this specification. Are you leaning in either direction? I think if you, you know, force me to choose. I think I would lean towards yeah, taking it out and then, like, having applications put it in the header if they choose Cool. I just I don't think we have, like, a super, super strong argument for keeping it Okay. Any other opinions? Simon? We also don't have a super strong argument for doing anything."
  },
  {
    "startTime": "01:02:02",
    "text": "I agree. So you would say do nothing. And the chief proponent for taking it out is not the room. I really would like to resolve this today because it's I I think that we're overflowing this personally, and I think we should do nothing. Don't know if I'm supposed to state my opinion at the mic when I'm Sorry. Strike that from the record. I was just gonna have an opinion. Then let's do nothing. I think nobody has really said, like, we must do something. Simon? Yeah. And and to clarify, I think the the point that Martin was making in the issue is that it was more expensive than other options. But the is still pretty irrelevant in the grand scheme of that. We're gonna do nothing. Next, Next. Okay. This is the bike steady one. So We, in the spec, we do things that deviate from TLS syntax. I want to quickly justify the thing you see on the left. I am following something that I saw in RFC 8446. But, but so that's that aside we have some, like, workarounds for the limitations of TLS syntax if you do a strict interpretation of it. So some have suggested we should extend it in a way and like define our own semantics somewhere. The other option, of course, is to just fully comply with the TLS syntax perhaps at the cost of more verbose language. Or 3, do nothing and just, like, explain the deviations when they when they arise, and and try not to do this too often. Preferences."
  },
  {
    "startTime": "01:04:05",
    "text": "As I recall, the substance of the d d as I recall, the substance of the deviations here is, like, you illustrate on the left hand side, as hand of your your the left hand side of your slide. It's just a couple of places where identiate, like, literals or partial literals of objects, would say, you know, So and so field equals 2. My suspicion on having tried it is that it would take like a paragraph or 2 to explain what the you know, extensions to TLS syntax are so I think we should just do it in DAP and result that would So as as an implementer, I haven't found this to introduce, like, first and then you know, again, challenging ambiguities, in terms of the message formats. So I think it's just, couple paragraphs to explain, how we did the HMRC 8446. Cool. If one was an IETF thing, that would be nice. Then we could just extend it there and use it. Otherwise, I'm also fine with just doing a one off here. And for that specific case, I think it might even just flip it around, you put the 2 in front, and you put the rest on the comment, and then you It's sort of just using a constant yeah, as a speaking as a dad editor, I don't wanna have to add another dependency to this draft. Like, like, writing down language somewhere. I forgot to mention Chris, may well, Go ahead. Whoever's gonna let Sean go. Sean, Hey. I think for the particular approval on the it's just assigning a value to a object rather than defining, any specification, I think we can forward resolve it by Just writing Silicoot or something in the text, So Sean is saying number 1, but do it in the draft. Good year. Oh, yeah? Yeah. Yeah. No, that's Kristen. Yeah. Sorry. One of the issues,"
  },
  {
    "startTime": "01:06:02",
    "text": "that was opened up, and closed recently was, like, shutting about the width of a particular field in the packet format. Just like a epic bike share to this particular point in time, so we just closed it. But it does point to, sort of the the wire format syntax we're using here for TLS, which is very rigid about, like, how wide things are on the wire. Other protocols, like OHP and whatnot have like, moved away from TLS and tax to quick, like, variable length encoding. And I'm wondering what people think about just pivoting the entire like, wire format of DAP to something that supports variable length integers. So We kind of avoid this, like, deviation from TLS syntax altogether, but also potentially resolve, like, How wide should this thing be? Do we have enough space for this and blah blah blah? Not like a strong advocate for it, but, like, it has been like, a trend in other protocols. I'm just curious. I think it would be, quite a bit of work to to change the wire format at this time, at this point, but I don't object like I'm willing to do that work if we think it's the best idea is it? I obviously, it's implementation work. Yeah. But spec work Great. Are you suggesting that would also be a lot? Or No. No. I I'm thinking about the implementation Yeah. Does anybody wanna I go back to square one with the wire format. As Chris suggests. Chris has a concrete. I'm, like, happy to, like, take a stab at a PR just to see what it would look like. Don't have to do it, but, Can you take that as an action item so we can all look at Azure Okay. Chris, what are you suggesting are you suggesting we use the same a different wire from it or completely different Quick quick syntax and wire format is different and Okay. particular, allows you to encode, like,"
  },
  {
    "startTime": "01:08:00",
    "text": "are, like, integers in particular numbers in in a variable length format. So, like, the the width of say a report ID or a report share error. May not always be like 2 bites or 1 bite or whatever it is now. I see. And so it it kind of end up being, like, space efficient, depending on, like, you actually put in the packet itself does allow for more experimentation with things because you have a wider range of, like, k. We actually have a a lot of, like, do a lot of 32 bit prefixing just because there's big messages we didn't wanna do u2 like, 24 bit prefixing. So I think, actually, we would benefit quite a lot from, like, in terms of bandwidth. But, you know, it's like, let's say 10%, like, optimistically, not gonna be a ton, but it we we would benefit terms of communication front, again, like, you know, the bandwidth is not, like, the primary, like, cost here, or I don't think it's the primary cost here. Bit fun. So to some extent, this might be aesthetic, but, like, I'm mostly just, like, trying to avoid, potential bike sheds and that that that feels like it's a way to sidestep someone. If if if it gives us a way to resolve things like this, I think it would be think it would be improvement. Okay. Oh, these aren't these aren't necessarily about, like, wire, like, size bike sheds, but, Chris will take a stab at it and we'll see what it looks like. That's great. Thank you. We've got 2 more. Alright. Let's do it. Next slide. I think I should let the other guys go, though. So we're gonna just, we're gonna I I wanna suggest we do nothing here, the conversations too complicated. Great. Great. Alright. 4 59 do nothing. Oops. If you need to bring him back. Next one? So this is, I I I I suggest we just take proposal 1. Add the report ID and make this, a put instead of a post. We could resolve this one. Chris Stots, Which echo was here to defend it."
  },
  {
    "startTime": "01:10:01",
    "text": "Oh, go ahead, Tim. But sorry. I'd have to reread RFC 9110. No, put seems appropriate to me because it, connotes to the you know, it's clearly, but this is either potent, which means you're allowed to try to retry the same amount. Right? No. The proposal is put and then add the report ID to the to the to the path, and that would resolve it. That's right. That's right. Wait. Sorry. Currently chooses the report ID Oh, the client. Oh, yeah. It's just that it's in the report metadata instead? Okay. Yeah. Okay. I've been fine with that. Let's just make sure to hoist it out of the the dot stated twice then. Put only in the request path and not in the report metadata. Alright. We did it. Thanks, everybody. Mark. I'll go ahead, Mark. Oh, oh, oh, no. And Don't over rotate on the word replacing. I'm I don't know what your use case is because I've been busy. What what are you what you doing? If I were to do this, And then right afterwards, I was to do a get Would I get that representation back? With the protocol does not define a a get for this resource. You just you just put it All HTTP resources should have got Okay. Children should be be it'd be great to get your feedback on the draft. Okay. The if if that's the case, then post sounds like it might be okay. Okay. But but don't don't replace it. Put it as Yeah. Isn't quite replacing. It can be updating too. Okay. Generally, like, the second put would be rejected. So the the the, one one when we put"
  },
  {
    "startTime": "01:12:00",
    "text": "this report, it would only be put once or posted once. That that sounds That sounds right. That doesn't know, Chris. That's not true. You're allowed to put same report multiple times because, otherwise, it would be impossible for clients to retry to usually retrial. That's why I think we're not we we we're running out of time for the other talks, so we're gonna take this offline. Good job. I didn't know if I had a conversation to have. This Ven is sharing the slides. If you really want to control them, you could share them instead, but otherwise, you're on. Yeah. I'm okay with, you sharing your slide. Great. By the way, can everyone hear me? Okay. Yes. Go ahead. Okay. August start. Hey, everyone. Today, I'm going to introduce applying differential obviously to DAP Next slide, please. In IETF 107, we kicked off the discussion of DP on DAP. And to reiterate the motivation of DP, Keeping the measurements private as that does may not be enough for privacy. The aggregate result is still leak information about an individual's measurement. For example, if you were to collect the average height of the group of people on the right pick, served, result is still leak information about the extremely tall person. Defential privacy can mitigate this problem because it provides a nice property that collecting the aggregate result with DP should not change significantly if any one measurement is replaced by another. This is achieved by adding noise to the measurements clients, and so the aggregate shares by the originators. Yes, please. DP is a class of definitions."
  },
  {
    "startTime": "01:14:00",
    "text": "Such as Epsilon DP, Epson Delta DP and etcetera. Thanks. And each of them can be the preferable one depending on the application. What DP guarantee you get against a particular adversary is a function of what information is available to the adversary. Therefore, we need to define trust models. We aim to achieve DPN. Next slide, please. these motivations in mind, we have published a new individual draft With That addresses the feedbacks from IETF117. That summarizes our requirements for DP on deck. To to name a few, want to choose a class of DP Notions that are suitable for DAP for example, pure Epsilon DP, approximateepsilondeltodpetcetera. We want to define trust models. We aim to achieve DP in. We have refined interfaces for DP mechanisms, which were responsible for generating noise. We have refined interfaces for DP policies which are implemented with DP mechanisms and compose with VDAS to achieve DP in their aggregate result. We also want to describe concrete use cases of applying DP on tap In the first version of this draft, who have shown one use case of collecting histogram with different DP policies to achieve the same degree of DP. Next slide, please. We hope our audiences of this track are gap deployments. Who want to cookbook for making their applications differentially private. This includes implementing the DP mechanisms, choosing the right DP policy for a particular application"
  },
  {
    "startTime": "01:16:00",
    "text": "would also like to involve DP researchers and domain We works, because we believe the integration of DP on that would be an iterative process between research and production deployment. Next slide, please. The first section in the draft aims to standardize DP definitions that are suitable for We have introduced 2 of the most common DP definitions One being the pure Epsilon DP. Where Epsilon describes the privacy loss, of observing the aggregate result when there's a change in one element of the batch of client measurements, And smaller Epsilon means stronger privacy. The second definition is the approximate epsilon delta DP which relaxes Epsilon DP with a small delta that describes the probability of information leakage. Allowing for a small delta can allow randomized algorithms to add less noise. And smaller delta means stronger privacy. The exact definitions can be found in the draft itself. We aim to intro, include more definitions of DP that makes sense for DAP in the future as well. Next slide, please. Along with the definitions, We also wanted to find trust models to account for attackers where we aim to achieve DPN. We consider attackers that participate in the upload arrogation protocol and can corrupt parties like clients and interrogators. An address would define 3 increasingly pessimistic trust models. The first one being one aggregator and most clients are honest, owing short OAMC. The DP policies designed for this trust model usually have good utility"
  },
  {
    "startTime": "01:18:03",
    "text": "and the DP guarantee provided by these policies usually it degrades gracefully as the number of honest clients decreases. And we also know this is the same trust model as core DAP. When all clients are honest, The second trust model is when one aggregator and one client is honest. Or in short OAOC. In this trust model, our our goal is to protect the privacy of the only honest client. And the last and the most pessimistic trust model is when only one client is honest. Or in a short OC where to achieve privacy from the only honest client is usually much weaker. Next slide, please. We also define hedging which is a desirable property for a DP policy. To still maintain some degree of privacy witness assumptions about trust model turnouts for us. For example, in a diagram, The green elements are the honest parties, If a DP policy aims to achieve the desired Epsilon DP, in the OAMC trust model, and the deployment turns out to be OAOC It is desirable for a DP to still provide some degree of privacy. That is a weaker epsilonprimedp where Epsilon Prime is much larger than Epsilon. Next slide, please. Ben case, do you have a clarifying question? Questions now. Vince City has a question on the threat model slide. Do you want it an hour later Sorry. I couldn't hear hear his question."
  },
  {
    "startTime": "01:20:00",
    "text": "Sorry. I had a question on the threat model slide, but I don't know if you wanna go through all your slides and then take questions. Sure. We we can take that question afterwards. Yeah. I will go ahead and take it now since we release for this Yeah. So on on this one, this is a good overview of truck models. And I just wanna maybe ask about the scope here. So I understand that that has made some decisions to be a 2 party protocol. But let the this group might also be interested in vdafs that are potentially a 3 party. I know Martin has certainly told you guys about IPA, which uses a 3 party honest majority malicious MPC. So I want to just kind of know if that's something that, would be interesting to put in a document like this if we're looking kind of like as a longer term, sort of research you know, document that starts to kind of try to capture some other threat models that may be of interest to different folks. And I'm also happy to volunteer work like that needs to be done. Sure. I I think we welcome contribution from other trust models, You mean, when we, define trust model, we should define for, like, say, more than when more than 2 aggregators are in the protocol, That's right. This would be the setting where there's 3 aggregators, you trust that all pairs of 2 are honest. But you get malicious, like, active security. See. I see. I think I think currently we'll we'll describe how like, a concrete DP policy will work with the VF. So I think we can certainly account for those if there is use case. Chris, I don't know if you have anything to"
  },
  {
    "startTime": "01:22:02",
    "text": "Yeah. Just speaking, as an author, I would like to keep this document focused on threat models that are relevant to that. And IPA has a different protocol shape that doesn't actually quite fit the architecture. Should we take more questions or should we continue? Take it one more. Go ahead. Yeah. Okay? This is a requirement from Huawei. I have one single question. This figure, you, the client has 2 colors. Why is it yellow and green? May I know what's the meaning of this? Different colors. Yeah. So the green elements to, means they're honest. And, yellow ones means they're controlled by attacker. So Yeah. From from Yeah. Yeah. Yeah. Oh, I mean is, for example, Either any upper bounder for the number of the for the ratio of the clined that is not honest. One is the Yeah. Yeah. For you to gather the correct answer. is typically achieved by, like, a certain best has number of honest clients. Here we basically sketch out the 3 honest clients and one aggregators, they can to get by adding noise together, they can achieve the ideal Epsilon. DP, but went only one honest client is present and will achieve a much weaker epsilon PrimeDPU. Yeah. How does the, for example, aggregator, a collector knows the accuracy of the results You mean the the utility of the from early noise. Or or"
  },
  {
    "startTime": "01:24:02",
    "text": "Yeah. Yeah. Because Or the privacy aspect. Yeah. I I mean, because there are some, number of the clients that is not honest they may give you false data So when the collector gets the data, So how do they know that data is a accurate or not means there any measurement of this, accuracy of the output, That's sort of a different problem than what I think. Okay. Jinja is talking about here. Right, Junior? Yeah. I think, like, typically, like, it depends on our deployment. Like, your deployment can have let's say, client authentication, you have a rough idea of like, how many clients are under attackers control, but but here, we basically we just describe, like, if you have certain certain number of honest clients than you get, you get the privacy you want, but If certain number of them are corrupted, then you're you can still achieve, like a weaker Epsilon guarantee. So the Epsilon here is about the privacy offered to the client not about the accuracy of the measurement. Thanks. We're looking at a different kind of variable. Okay. Okay. Okay. Maybe I will be, discuss offline with Thank you, Alright. Go ahead, Junior. I think I raised hands, but Kunal, are you No. I can just put it in the chat. Nothing super urgent. Yeah. Thanks. I'll continue. I think we'll start at slide 9. It's the slide 8. Yeah. Okay. So the second section of this draft defines a DP mechanisms, was her responsible for sampling noise with parameters derived based on the target DP. Some examples include"
  },
  {
    "startTime": "01:26:01",
    "text": "discreet La Place and discry Gaussian that can generate vectors of random sign integers, Okay. And symmetrical report that can randomly flip this in a bit vector. An important goal of this section is to standardize DP mechanisms to prevent implementation bugs that can break DP. Next slide, please. The 3rd section of this draft defines DP policies. Which are implemented with 1 or more DP mechanisms, and are composed with VDAS to install VDAS with DPs. The diagram on the right hand side summarize how our current VWO exclusion looks like. Next slide, please. And a country DP policy basically applies DP mechanisms on clients measurements, and applies to human mechanisms on aggregators, aggregate shares. Eventually, the aggregate result will be debised if required by the DP mechanism, DB mechanisms applied by all honest parties provide the DP guarantee. Next slide, please. And the last section of this draft aims to define a number of use cases that can be made differentially private on that. In the first version of this draft, we describe a use case of collecting histogram where each class submits a bit vector with exactly one bit set. Or a so called 1 hot vector. describe 2 DP policies that can achieve the same We epsilon Delta DP. We compare them from the trust models they target DP mechanisms they use and the VDAS they're composed with. first policy uses the pure The"
  },
  {
    "startTime": "01:28:00",
    "text": "client randomization mechanism that targets the OA MC Trust model. Where each honest client applies to metric report to this one hot vector. Which turns it into a multi hot vector. For verification and aggregation, we use a private Vida called pro to multi hot histogram. That can check for a boundary number of ones in the noise climb vector. And with certain batch size of honest clients, we can achieve the desired Epsilon Delta DPP The second policy uses pure aggregator randomization mechanism. That targets the more stringent OAOC trust model. Each honest each honest aggregator applies distribution, to this aggregate share before outputting it. To ensure excellent Delta DPU. For robustness and irrigation, we use pro 3 histogram, that can check for the one hotness in the client measurements. Next slide, please. What's to compare the utility of both policies in terms of standard deviation, under different epsilondelta settings. Standard deviation is a good way to evaluate how different the noise count. Is from the true count. And the smallest of standard deviation, the better utility we can usually get. discovered that either policy has utility advantage We under different Epsilon Delta DP settings. And we also note that the policy with pure aggregator randomization. The aggregate noise is doubled in a DAP setting with 2 aggregators. Order to maintain the OAOC trust model. Next slide, please. Ben is about the sled. Then wants to ask you a question about the sled. Yeah. I was a little bit confused"
  },
  {
    "startTime": "01:30:02",
    "text": "looking at this comparison of 2 approaches least to to me, it would seem like they they one of the key variables we would want to vary is the batch size. I think all of these have a fixed end at, like, a 100,000 So I would expect that, like, as the batch size, it was very large Your central DP may be better. You know, maybe for smaller and more moderate ones. I understand the private amplification. Has a big impact. Like, it helps. In this local model, but I just wanna see, like, What if we vary in quite a bit more? Like, how does the comparison look basically, we we fix the goal here to to achieve the central epsilon Delta DP. The, the batch size is like, internal variable we we use in, in policy 1 with pure client randomization. Basically, we say each client applies certain epsilon Local DP and with this this many of, number of honest clients we can get the central epsilon delta dp. Okay. But, like, what would you do if you had a batch size of, like, 10,000,000. I think you the utility, you you you certainly waste a lot of, it will be certainly very privacy friendly because you have a lot of clients, but I think you achieve or you also achieve a much stronger privacy, which you don't really have to. So it's sort of let go. Waste of a privacy budget. Yep. I guess that's kind of my my main concern in the comparison is that if a really large batch size, you might be better off with the pure aggregator approach. I just wanna make sure that, like, we we keep kind of different kind of size regimes in mind with Certainly. Yeah. That's why I think we"
  },
  {
    "startTime": "01:32:03",
    "text": "we'll have to rely on the minimum batch sizing gap to sort of ensure the privacy and utility there. Shannon Yeah. Just a quick comment. So I think the best size here fits out a 100,000 is basically assuming that's the mean by size that we're gonna use for our task. We can do a comparison with much larger batch sizes and smaller batch sizes I think the conclusion, if I remember correctly, for client client pure client randomization for batch size close to EMEA. Actually has the placer utilities and the pure aggregator randomization. Yep. Yeah. Maybe another answer to Ben's question. I think we have a much larger batch, we can adjust the amount of local noise that each client has so that we get the same absolute in the end. So we don't really have to kind of kind of waste. Privacy budget. I guess just the trade off is that if you have really large batch size, local privacy age plan gets will be worse. But on aggregate, we can get the same kind of central privacy. Okay. Yeah. That makes sense. Thanks. I'm thinking Oh, sir. There's still a ton of work to do. For example, we need to work out the implementation details of various teaching mechanisms, we want to figure out if there are other quantitative and qualitative Tira to evaluate various CP policies. We'll also want to figure out if it's worth exploring, MPC protocols for aggregators to collectively add noise. Improve utility And we want to describe more concrete use cases to motivate DP on that."
  },
  {
    "startTime": "01:34:02",
    "text": "Next slide, please. So this concludes all my presentation. We feel this work is important. And that PPM is well positioned to take it off. Our main questions are is this work useful and is the draft scope properly if there are other suggestions, and should PPM adopt this draft. Perfect. Tim, Thanks. Thanks for this presentation, Jennie, as well as all your work on on all this. So I support this work. I think like, this is useful and PPM should do it. But there is one I think there's one question about, like, the audience for this work that we have to be clear on. Is that going something I was talking about earlier during Chris Paving's presentation, think we gotta be clear about, like, do we expect that the differential privacy document and, like, guidelines whatever that we published, sorry, that the PPM working group publishes do we expect that this is only or, you know, organizations that employ talented cryptographers. If so, are are we punching the problem of, choosing good Epsilon's, right, to deployments. I think that's a reasonable choice, but I think we have to be crystal clear about what our expectations are of users the stuff think I think Chris, yeah. crust party? I So right now, yes, we're explicitly punting on, like, how do you choose Epsilon? I'm new to differential privacy. It's It's a very it's it's It's very locate it. And I think one thing we wanna do with this draft is make it accessible as possible. But I don't think we're gonna have be able to, like, promise, like, here is your recipe for picking Epsilon. That's like the one thing"
  },
  {
    "startTime": "01:36:03",
    "text": "that I think is gonna still be a little magical at least until we do more research. Scope of this draft is make, yeah, is basically to make sure big organizations that employ experts can do their best work. We wanna make sure that happens. But hopefully, One of the results of that work will feed back into the IETF and add, like, differential privacy, as another tool that we can use, you know, to make the internet better. So I'm hopeful that will fall out at the end, but initially, it is not our goal to pick up Epsilon, except maybe Kunal is gonna say something different. So, yeah, for what's worth, I agree with Chris Patton. Because like, it's already technically very challenging to, like, do something that is implementable at all that even works I think it'll be too much for this working group to take on, like, generally, I don't know, providing guidelines for how to how to tune differential privacy. Maybe the IETF should do that because there's a lot of things that is gonna work on in the coming years that probably wanna use differential privacy. And, like, if you're really nice, if there were some good general solutions to this, but I don't think take on that responsibility. And in any case, like, even ahead even differential privacy aside, there's already, like, a number of years, the minimum batch size being the best example, that are like, choosing them while it's crucial to the privacy of the overall system. And we are currently like punting those choices to deployments and implementations. So I think that's fine. Okay, other thing I wanted to say Nick Doty raised this in the chat, and I think I flagged it also in the mailing list this draft got circulated I think right now, this document is this is like an IETF procedural sort of. So, right now the draft is, I think it's informational And I'm honestly not sure whether this needs to be informational. Like, wants to be experimental, but I'm not sure if, like, informational or, normative is appropriate here because I feel like"
  },
  {
    "startTime": "01:38:02",
    "text": "This is going to spell out some nuts and bolts like here's the code you need to go right. To go to differential privacy. So as informational appropriate, probably, standards track is appropriate if multiple people are gonna And I believe, like, would have to implement this for the aggregators to be able to, like, correctly jointly compute differential privacy. There will be multiple implementations. Sure. Kunal, best practices to leave video off until it's your turn to get in the queue just so that other people's streams are are smaller. Simon. Yeah. I just wanna say also support this. And I also like Benjamin of, you know, Adding another dimension for the batch size. And, yeah, because I think people will use different batch sizes. So the trade offs will be different. And also for the central versus local DP. It might be good to consider that the aggregators might choose the batch and therefore, the batch size. And then it will be useful to make that call later. And so it would be So I'm in favor of of working on MPC Central DP. Sham, Hi. Yeah. So Oh, what kind of office? So the the the document, I think the school part of the document so far is to define the cans amount of policies, for implementing DP on dev. I agree the fine tuning of the parameters epsilons, epsilon, we can work out later mostly from experience and also, like, some of the batch size sometimes it keeps the deciding factor because you're besides might be depending on your population size. So if your population doesn't reach a median, then you can already chose a medium minimal batch size. And based on that, we can then tune the the local parameter recovered,"
  },
  {
    "startTime": "01:40:00",
    "text": "differential products parameter to get a desired I aggregate her DP apps at all. Great. I think we can certainly add more, considerations on the batch size and the local DPU will add. Hi, Martin. I be in the queue? I I think this needs a little more time to bake. Thanks, one. Do do you want to you do you want to let it bake without it being a working group document specifically. Is that what you're saying? Yes. I see nothing. Yeah. So I think we have a lot of options here. And getting a little more certainty about what people want to deploy. Would be, I think, what I'd like to see happen. That said, not opposed to it becoming a working group if everyone else a working group item if everyone think this is a good idea. Because I very, very, very much want this general thing to be solved. It's just wanna get a bit more clarity about - tight, tight. What the parameters are. Do you want it? Would it matter to you if it's an informational document instead? I'm not sure that an informational document necessarily gets us what we need. At this point. Alright. Can all so I think I agree that there's a lot of options at this point and I think it's somewhat complicated by the fact that that the I think different use cases, different applications with an aid different versions of TPE, different neighborhood relations. So I think we should really think as"
  },
  {
    "startTime": "01:42:02",
    "text": "I want to use DP should be thought of as I want to use cryptography rather than I want I would say, So I don't think we'll get to a point where we get one clear specification. This is exactly the way to use DP. Because every use case is different. Like, if you want to aggregate bounded. You click in non vectors. You want to use a question mechanism. If you want to aggregate histograms you want to use, report or of the ads other mechanisms and I guess the kind of TV guarantee you want may be different in multiple cases. So I think the approach this draft takes is get started on some specific use cases where we know what we want to do or we have at least some good suggestions on what to do, but I don't think we'll ever get to a place where one graph, it says, this is how you do Thank you, Kunal. Closing. Go ahead. Last comment. So, yeah, I think I I I agree with Kunal The point I wanted to make is that The kind of the primary value of this document is kind of establishing the shape of this, like, defining the problem and establishing the shape of the solution, and coming up with us, a few simple, like, tools to put in our tool bag. It's not going to cover every possible instantiation of DP in DAP. In particular, many of us are interested in, in think about, like, how we do this in MPC. Think this could yet another draft. It could be we could think of it perhaps as an extension to DAP. But, yeah, we definitely don't want this to be the the end all, the only thing you can do. This is just kind of a starting point. K. Let's move on to the next topic. Sean, youre Yes. Great. Cool, Saket. Do I have control of the select sync hard. You do you do, and we do not see your video. If you want to be on video, you can do that. A drops."
  },
  {
    "startTime": "01:44:02",
    "text": "Okay. Now you should send me Right. Task proof. So the last talk is about this, inbound task provision extension, have presented this in IETF, WAVA in full. We call it a lot of feedbacks. This is the 2nd pass I think today, I will focus more on the motivation I got some of the implementation details so so a quick word on why we need this. This is One method to provider automated mechanism for provisioning a dev task among clients and aggregators. As you all know, today, Deb, the call protocol does not specify, a standard method for doing auto band task configuration. This extension is aiming to fill in the gap. And a few changes since the last time we presented this we update it to fetch the latest dev and Redux standards. And also we moved the the payload of the task conflict object from extension, which used to be part of the, report. To the HTTP header. This is to address a we installed batteries issue, especially when we sent the same toss config between leader and Sorry. I realized I should have a move on to the slide first. So just quickly describe the task conflict object, gonna talk about it in the next few slides Basically, it's a collection of all the configurations and the parameters required to config that task, includes all the redev configurations, the query configs, and all the endpoints for leader helpers and so But for the purpose of this, this presentation, I think we can just sync over it as all of the parameters you need to configure a task."
  },
  {
    "startTime": "01:46:00",
    "text": "This is basic flow for task proof We have a logical entity called a task officer, reality task also is probably gonna be the same implementer as a leader or collector drop of the task also is to advertise a task config send it over the wire to old clients. Then the client Could I have a look as a task conflict and decides to opt in or not? If the client does opt in, then the client will derive the task ID with a hash of the topic topic object. This is what Chris have mentioned in one of the previous slides where the task ID is basically bound to its task config. And task card itself also is used in the AAD information. So, with this operation, basically, the client and the aggregator will agree on the same task config 4 particular task. So after the top of the calendar has got the task ID, It will upload the report along with the topic object choose it either, for the task ID And then the leader will devise to opt in if this is, a new task, then the leader will actually provision the task with all the parameters from task conflict And the leader vote, bypass the sorry, forward the same information to help her in the aggregate, aggregate, in it flow, task of conflict will be sent in the header file of the HTTP request. the And how far we'll do the same thing to opt in and provision the task So here, team has mentioned previously There is still one bit of auto banner configuration between the leader and helper that is a Vira Verified Key Unit. It's kind of a secret when they don't help her where the client shouldn't know therefore, it's still shared between the data helper. Paris it's, it's a secret shared. It's very low frequency,"
  },
  {
    "startTime": "01:48:02",
    "text": "let's see once a day or once a month it's not worth per task. So, Sorry. So just to quickly go through some key properties, and hopefully this will explain why we why why it is, useful at least, from my perspective. So one key property is, we are binding the task ID with task config. For the client, this is better transparency and auditing. It's a client knows the task is contributing to will be configured with the exact configurations, it has sing And for the aggregators, we can mitigate's a cross protocol attack. So what that means is the leader could Tell Halper, these are the parameters to configure a task Let's say it could decides me by side is only 10, to help her with coffee to that. But then that either could add or ties just the task parameters, these are much bigger by size 2 is a client, declined would not know just house code, 0123 is contributing to actually has, much smaller mean by size agreed by its aggregators. With tough proof, we communicate these because the Didan help her? Have to use the same task topic parameters. Otherwise, it will be it it will not only it will not be able to find the same task ID Another property I think it's desirable. This is mostly operational, because task proof uses the inbound dataflow it doesn't need any auto band mechanisms. So in this diagram, let's say if"
  },
  {
    "startTime": "01:50:02",
    "text": "My organization is, the yellow one we have 3 helpers with 3 other organizations, I also have a leader who's another organization. This example, we're gonna have 3 different auto band provision method Alice, I agree with neither one either totally the 3 to use exactly the same autobank task provision. We use task proof there's no such concern. We just need to implement task proof then it needs to say a message for all of them. Last one is task proof can allow some clan side, flexibility in choosing the tasco congregations, So I think in-depth, we assume all the task conflicts or task parameters that were chosen by the servers and the client would not have any flexibility in doing that But just like we talked about earlier, about the labeling your client setting labels into the report metadata this is a very similar idea. The client might changed its tough, tough conflict to chose parameters yeah, it seems it's better for its own privacy. In this example, it might change maybe I saw it from 1000 to 10,000 And if there are enough client, doing this, then we can still configure a task for these clients, and, collect their data using the updated privacy parameters or task parameters, This will be very hard to do from just server point of view, so the server wouldn't know what flexibility says the clients would need And I think it's, at least, gonna be very tedious to coffier all these parameters. So next one is operational considerations, So, tusk proof,"
  },
  {
    "startTime": "01:52:03",
    "text": "I think it's fair to say it's only suitable for some use cases. It has its own shortcomings, it has a bandwidth waste. So to toss config object is uploaded with every report if you're payload, report payload is a lot smaller than task config or comparable with task config that is, wasting a lot of bandwidth. So maybe that's not a idea use case. So The first CFO character for, a task proof deployment it's a payload size. It's way larger than cartographic size. So this could be a V dash like a previous resound vector. Instead of a pre authory count the second point is, there is a relatively high cardinality of tasks we're gonna configure thousands of tasks every day instead of one task every week, because if you just have very few amount of tasks configured very occasionally than hates. Probably doesn't really matter what type of task copy you you choose. To summarize, similar to the second key property I mentioned earlier, like, if you have multiple aggregate points, pairs if if if if if if if if if if if if if if if if if organization work speeds many other organizations I think it's useful to have one automated way to configure the tasks instead of agreeing multiple ones with each every winter. And the last one, client kinda have the flexibility to ask to to update task config. So I think if you're deployment, fate some of these four points, then I'd say it has a conflict should be, variable option. If your deployments doesn't have any of these characters, or only have 1 or 2 of them, then maybe tough conflict isn't the best choice for you. Lastly, also automation there is, potential"
  },
  {
    "startTime": "01:54:03",
    "text": "attack opened by task conflict that is a malicious client or a cohort of malicious clients they can pollute the aggregator storage by just uploading distinct task coffix, because the aggregator would not know If the topic is legit or not, it will have to provision the task and then realize it's not, receiving any legit data from it. So this, it's gonna be, waste of storage, from diabetes response relief. We can have some mitigation updates. For example, the task officer could sign the task conflict. So it will verify the same signature when it comes back to that either or help her, then we can only we, we, only provision tasks that had been distributed by the that's house closer. So last slide, He's just a call for adoption, or not, can find more details in the latest draft. I think we feel this is useful to not only our development, but maybe for many other people as well. Why we are calling for adoption. As a data extension, That's end of my presentation. I'll open to questions. So Simon is the first one. Yeah. So I understand that you wanna do this automatically. I don't understand exactly why you wanna do it in band. I give the task author as a thought experiment which has sent the first report for each task. To the aggregators, the tasks would be automatically created. And from that point on, all the clients could leave out the extra payload of the defining the task. I mean, I understand why you wanna have a standardized API for creating tasks. I don't understand why you want to do it in line. Yeah. I think,"
  },
  {
    "startTime": "01:56:00",
    "text": "20 in line has a few benefit where you can also achieve similar benefit by having auto bound task proof with a lot of other add ons So doing a thinking about it, we can have the task parameter let's say, task frame authentication, property, which we have mentioned earlier Yeah. But as discussed then, we could do that for free without including them as as everybody knows what they Yes. Agree. We could we could we could achieve all the characters of task proof, maybe accept the point where we need some flexibility from the client to, set their own labels, but you could produce another extension with labeling, But I think one repeating part of task proof is, it's one way of doing all this together. With one inbound mechanism with some treatles like, it's a complexity of permissioning on demand and some restyle binaries, but you you achieve all these points in one method. You don't have to define a separate auto band interface. Today, there isn't a standard way of doing that. If you're telling me there, we can do it auto band. That's true, but depending on which window reward trees, we might have different proposals for different auto band computer issue. Yeah. Agreed. So I'm just thinking it might be better to have different one. I'd I'd like your point that you could actually have the clients decide on which class tasks to create in your proposal. Is that something that you're actually planning on using? Yes. Thank you. This is Sam. I'm not his chair. It's more of a question for Chris, patent thing in front of me, To to what degree does this solve issue 500 in that?"
  },
  {
    "startTime": "01:58:01",
    "text": "Of making sure everyone's agreed on your tasks my opinion is that it solves it completely and pretty elegantly. I think there's reasons why if you wanted this feature, you might do it a different way. So one thing that we wanna do in this is we're also encoding, like, DP parameters and like, one option is, you know, don't add DP But, But, like so But yeah, if if not, everyone's gonna implement DP, at least right away, then, Yeah. So I can see I think there's arguments. I I see lots of reasons why someone would not do this, but I do think it's sufficient for that issue. That's then Hi, benchmarks as individual. Is this safe? Because it seems like I can It seems like I can then through the system, a unique task config, to each user in the population and create a tracking identifier that follows that user around, even if I can't get the value associated with it. I can just see you know, which user or when the user is submitting a task ID. That it is unique to that user. That's something that is largely avoided in the models where the task configs essentially our, are pinned into the source code, and we assume that the source code is basically audited To to do that, you need to have the ability to target a user visa particular task conflict. So it creates linkability. It raises a bunch of configuration consistency questions, which have also come up in, privacy pass and httpTP"
  },
  {
    "startTime": "02:00:01",
    "text": "So how do you how do you track one user by sending, unique task conflict. Like, how do you, how do you target as a user? So there's a even if you don't have an explicit link to some other aspect of that user's identity. Although, you might there's as far as I know, there's nothing here that talks about the that talks about the rules about the transport over which you can provide the task configuration even if you don't have that, you still have the ability to watch individual users across time as they submit reports, even if you don't exactly know who those users are. But the task proof make that situation worse or is that existing attack you can already do with adding data report up uploading. Assuming we don't have a HTTP to mask because the user's source IP. I think I just wanted to raise the issue and yes, it depends on certainly if you if you don't have any user, if you don't have any any additional identity protection for the user, then there are other ways that this could link. Tim, we are over time, but I've Yep. So let's see. Alright. So first off, whenever test prep gets discussed over over the months and years, there's all been a lot of talk about transparency and auditing and so on. And I see the American that, and, of course, especially in, like, a system that's all about privacy, But thing I wanna stress here, and, you know, as as as the officer would be consistent about saying, is that, like, aggregators, like, this all this only works in assuming that at least one of the aggregators is honest. Right? So point being the aggregators can, like,"
  },
  {
    "startTime": "02:02:00",
    "text": "do the derivations and the task config hatching and so on with instead of parameters but still, like, use a different What I really wanna stress here is that, like, this is not certificate transparency. Right? It does not provide guarantees of the at a similar level. And so I want everybody to be, like, I want and again, I know that the author this, and I've been very clear about that, but I wanna make sure the whole working group gets, but, like, this does not buy you when PKI levels of, like, auditability. Past that, I have, like, a couple points about the design test product itself, but given that we're over time, I think I'll take most of the list. I'm interest I'll I'll expand on on email list, but I'm interested in exploring whether we could do this in an HBK config instead of the upload path. And, also, I'm curious about, like, what if I have multiple partners that I'm doing task problem with, like and I have but I'll follow-up an email. Thanks. You wanna go ahead? Tim, I'm very interested to your your, your ideas about how to improve this. What was I gonna say? Oh, I just wanted to respond to then, I don't understand the concern about like, track like, the I don't understand the tracking concern because it doesn't reveal to any information about the client being leaked. Something that core DAP does not hide is the fact that someone is participating in the protocol. That's not in our threat model. So it's just about protecting the data. Okay. So, Let me check In part, I want to get a sense of the room about adopting this now or not. But I I have a different administrative question, which is our charter doesn't let us do. Provision of measurements. So it seems that's done out of and here we have a way of doing it in band elegantly, that also serves other purposes. If we're going to adopt it, do I need to go get the AD to approve a charter change, and the Eddie is not in the room."
  },
  {
    "startTime": "02:04:05",
    "text": "Silence. Of wallet. Well, if you want an opinion, then that's change the charter if we have to and adopt it. And let's do that on this. It seems like a pretty simple change. It's just saying, like, And we'll we'll specify mechanisms for provisioning tasks. As needed. I I want to do a quick then I'm gonna use the polling tool. I'm making the question really brief, brief, which is do you support adopting this draft? I know we'll have to take it to the list, but I do want that since the room Alright. I'll I'll I'll keep collecting those for a few minutes. Otherwise, go enjoy your cookies. Thanks for a good great meeting. You, everyone. Thanks, Sean, for the presentation. What So it does have the slight a section"
  },
  {
    "startTime": "02:06:03",
    "text": "like every party is allowed to decide whether they are going to"
  }
]
