[
  {
    "startTime": "00:00:04",
    "text": "thank you so in um in Switzerland now yeah I'm gonna use the class tears I just Switzerland now those are actually um classified as weapons and you're supposed to give them to the companies yeah where'd you go good morning okay hello good morning thanks for being here so early this is Passover Network and research group I hope we're in the right room everyone bran just declared because we are here it's the right room so this is irtf notewell I if you would like to read it you can download the slides and enjoy it and just remind you because that it's here and also that we are supposed to be nice to each other what we're all trying to do I'm sure uh housekeeping uh it's not a big room but it's still the chairs would appreciate if in-person people would still join the mitekoku if you like to ask questions because it's much easier for chairs to to track the queue and find out who was their first and after you ask your question you can also leave the queue and medical participants yeah please mute until you actually actually speak in which means you join the queue as the first or you are presentation"
  },
  {
    "startTime": "00:02:00",
    "text": "um remote speakers can probably present themselves or just ask me now run your slides uh we have a actually we have a minute sticker I guess uh thanks but uh Xing is remote so if anyone in the room would like to assist because I guess it might be beneficial if someone in the room also helps with meeting minutes any volunteers for the worst part of every session oh come on next person to make eye contact with the chairs yeah we have plenty of time today actually we can wait I see honor thinking about it it's okay you should it's screen you have a great way to understand what's going on you have a backup yeah you have a backup so it's easier you're not alone today and you know actually we have recording so if you are not sure I can always I'm not going to upload minutes immediately after the session you'll have a few days so thank you very much Anna and you can collaborate here yes so yeah uh thank you very much uh yeah we are supposed to wear a Moscow get my one on as soon as I finish with coffee you don't want me not questionated enough um agenda we actually do not have a really full agenda today so we have plenty of time for discussion for everything so Brian will start today with giving"
  },
  {
    "startTime": "00:04:01",
    "text": "you an update on science and then we have a presentation about IPv6 wow and it's not my fault this time actually and then we have a number of Alto presentations it was guest speakers uh so any last minute agenda version anyone has a great idea they want to share with us this morning okay good so not much happened to be honest uh past properties draft is now always calling for Iris review hopefully we'll get it published soon so if you have any great drafts this working this research group shall adopt please send them to the list uh and with this I guess Brian will start presenting as soon as he finish with helping Anna I am going to share the slides uh yeah so um hi Nicola I shamelessly stole your slides because I wanted to give everybody an update from the chair um for um things that you may have missed at the interims um we had a couple of very productive but not extremely heavily attended into a meeting so we did want to report out uh kind of what had happened there um so uh how we got to where we are with Scion was back at itf113 um in Vienna uh there was a side meeting about Scion and then a presentation at routing area open and the feedback that came from that is like neat that's an architecture we don't do architectures um"
  },
  {
    "startTime": "00:06:00",
    "text": "so we decided to pull into pan RG the work of thinking about how to turn this into things that can be worked on more or less independently within the ITF so there are three drafts that were like basis for this discussion in panergy uh one is the overview draft um one is the component analysis so I think it was the first interim meeting that we had where the the feedback from that meeting was um actually can you look at how we can take the system and break it up into components and figure out sort of what the interfaces are between those as input to the decision to you know you know figure out how to document those components um and uh we were happy to accept that the the work of having that discussion Within panergy um had you know the rest of these slide decks here are or the rest of these slides here are largely an overview of what's going on in Scion have a look at the overview analysis draft for that um the interesting slide is here so the the the um uh incorporation that feedback about uh doing component analysis three components pretty quickly fell out of that discussion um and these are I don't want to use the L word but these are almost layered on top of each other so there's the control plane pki the control plane and then the data plane um some of these are um closer to things that could be standardized some of these they're open research questions some of these are kind of maybe the Scion way of doing things and maybe you less interesting on their own within the ietf um but the feedback from that um was to essentially take um"
  },
  {
    "startTime": "00:08:01",
    "text": "what's been written about Scion to date right like so that the The Source data for the source content for the specifications actually bring those into um internet drafts with the intent of publishing on the independent submission stream as sort of like you know eth's implementation of Scion or the Scion lab implementation of science a very common thing when work comes into the ietf we don't really know what to do it with it the source work comes in as an iscrfc is sort of like the here's the starting point and from there we'll go uh on that so um the Scion folks um if you have questions or anything to talk to them there over here uh going and Nicola uh we'll be doing that over the winter I guess we could say um and uh panargy will remain a discussion forum for uh things about Scion until we look at those documents and figure out oh yeah this actually needs to go into this area open meeting for a possible boss or this needs to be uh brought into this working group or this needs to be wholesale replaced with this thing that already exists in the ietf and can be very easily adapted to work with Scion etc etc um so in the meantime uh questions comments Etc about Scion we're happy to have those discussions on the panergy list uh I think we're not planning another interim because like you you guys just have some work to do um before you can come back um and we expect to have sort of a report out on that and possibly a discussion about next steps in research um my personal like chair hat off my personal um bias on this is uh I think there's lots of really interesting stuff to be done in the path Discovery and dissemination space um but we'll have that discussion in Yokohama so if anyone has questions about what's going on in Scion those really wouldn't be for me this is just her you know"
  },
  {
    "startTime": "00:10:01",
    "text": "catching people up who weren't in the interims on on what's happened um I guess we can take those and put Nicola and Corian on the spot otherwise we can move on to the next presentation going once going twice thank you very much okay I get lucky so um uh good morning um I'm Maxine Pirro from the Easter luva so um I'm gonna present uh something that was a really collaborative work within the lab so I'm a PhD researcher my advisor is all the team and also uh colleagues from uh from the U Silva so we've been uh we've been reconsidering what what IPv6 can can do what the rules it can play next slide please so um our kind of thought experiments started uh looking at OIP addresses are used today and so um we we've been looking obviously at ipv4 and in ipv4 um one address usually identify a network interface and so a host that would have multiple network interface as one ipv4 per network interface but not much much more than that due to several reasons um the kernel has not the links kernel is not really great at handling multiple pv4 on an interface that's one reason the second reason is also that we've been accustomed to The Limited ipv4 address space and this is a big constraint so when IPv6 came in it obviously"
  },
  {
    "startTime": "00:12:00",
    "text": "alleviated this constraint space Problem by bringing many more address but the stance so this is a position paper it's an editorial paper uh published at uh at CCR and um we tried looking beyond that so okay we have now many more addresses but is does those addresses brings more possibilities for endos or in the network and so we essentially try to look okay uh can we do better than one IP means one interface um and one of the findings uh that goes hand in hand with one of the strengths of the lab is that obviously uh multi-pass transport protocol are really help in that endeavor so next slide please so you're probably wondering what are those rules and if you have a quick glance at the paper you probably see a beast like that and you're like okay so what what is what are those rules this is a nice meme courtesy of one of my colleague Louis that I took for the slide next slide um so actually we we looked at many many aspects um um that can be improved thanks to IPv6 addresses so we looked at privacy load balancing said man routing uh differentiate services or different differentiated routing and multicast um next slide so I want to start by addressing the elephants in the slide let's call it um so let's talk about multi-homing so um in ipv4 one uh an S is multi-ohm so here it's as1 that as two provider is two as3 what is usually done is that as1 is first it's an as so it's it requests an as number and it will announce its prefix he has one prefix that is announced over the two links and there are many many tools and many many tricks in bgp to do that and to be flexible and this is a wool domain in its own that I'm not that much"
  },
  {
    "startTime": "00:14:01",
    "text": "knowledgeable of but we've been looking at what's the effect of this so the effect is um that actually a lot of the Asus are sub ass so they don't have clients they're just reaching the internet through one of several providers and when you look at the quantity of bgp message that travel over the internet you can see that roughly half of them there are messages coming from a from stubs so stubs are really putting a strain on bgp uh in the internet and we've been looking at this proportion for the last 10 years I think um this is data from the paper and it's it's roughly constant and it's roughly also constant between ipv4 and IPv6 so very likely to use the same way actually um next slide so obviously uh the ITF is aware of this problem and this is one of the latest attempts that I know of obviously um next slide so in IPv6 the proposed solution is is a bit different so um the first striking difference from ipe4 is that the the bottom network is no longer an as so here we call it Enterprise because it could be an Enterprise that is interested into being multi-ohm for resiliency and that kind of stuff so here it's no longer an es what this Enterprise do is that um what is sunrise does that um it receive provider aggregate aggregated prefixes from each of its providers so it will receive a blue prefix coming from as2 and it will receive a yellow greenish prefix from as3 um and with those two prefixes it will distribute them inside the network and each of the device here we have a smartphone will receive one IP from each of the prefix"
  },
  {
    "startTime": "00:16:01",
    "text": "um they're really uh advantage of of this uh um solution is that it doesn't require bgp so bgp is less used um for solving this problem but it has also a really cool feature is that the device can choose which address to use next slide and so when the device has multi-pass transfer protocol and those two addresses then it can really do cool stuff such as quickly reacting to a provider failure because it's monitoring how the connection is going through one provider and could migrate the connection to the other provider it could also dynamically choose the best provider and the best provider could be defined by the application one application needing high bandwidth will choose uh could migrate from one provider to the other hoping that there is more bandwidth on the other or could migrate to a lower latency provider if lower latency is required but there's many many combinations that we can do also we can use the two providers together redundantly using FEC using I don't know plain redundancy or in an aggregated fashion next slide please so to benefit from that um I thought it might be good to look at the status of multipath Transport protocols within the ITF so there are a bunch of multi-pass Transport protocols with a different set of features most of them are overlapping but all of their particularities so the first I thought I thought of is sctp for which the work is still ongoing through this this draft and the CTP today is deployed mostly for webrtc so the second multi-path transfer protocol is mptcp which has a new RFC for its version one and there today mptcp is the largely deployed in the"
  },
  {
    "startTime": "00:18:01",
    "text": "sense that it's available on Mainline Linux 5.6 and it's a it's apparently um available in many Apple devices as well the going further into the the timeline um are closer to us rather in the timeline looking at quick so quick I put it in the multi-path transporter call because it has up feature or two that relates to multipass transform protocol um but it has also a constraint is that you can only use actively one pass at a time but quick as large scale deployment today and the following work in that direction is multi-path quick which is still an ongoing effort and enable the use of several Network paths next slide so we've been involved in quick uh for some years and we've been looking at how quick can be used on multi-ohm servers so we've been looking at multium clan in the in the example but it could also be multi multi-ohm server that will also would like to be connected to several providers for for failure resiliency or for redundancy and all those purposes so um when looking at quick there is a bunch of features that are useful so quick enables the client to change local addresses this is called connection migration in rxc 9000 uh the server have a mechanism to defer client to another address just after the end shake and that's called server prefer address and then there is this ongoing multi-path quick that would enable the use of several Network paths but there is uh um there is a hole in in all that is that quick V1 lacks away for a server to announce or to advertise additional addresses that relate to the connection next slide please and so we've proposed a small a small extension to that I'm not going to discuss uh in detail what it's about but if you're interested to use Quick on"
  },
  {
    "startTime": "00:20:00",
    "text": "multi-ohm servers um this is something that we'd like likely interest you next slide please okay so let's look now at the other animals I would take some of them there there is more in the paper um but let's look at privacy load balancing and segment routing and try to reconsider or high pv6 addresses can help those areas next slide please so um the clients um there is also also something that is uh that is well known RFC uh 8981 so which defines temporary addresses so a device receive a prefix from the network and then fills in the remaining bits with temporary addresses with a limited lifetime um here in an example we have an IPv6 client that use a temporary IPA and then establish several flows towards the internet with that what the RFC or the implementation do is that as long as the flows remain as long as those red flows remain IPA is still used and then IP at some point the ipx players and the new IP comes up this is ipb the blue one but IPA will remain as long as there are flows that use it and non-multipath transfer protocols cannot migrate this is kind of obvious so the opposite of that would be to say that multi-pass transport protocol would help in this case to move the flows to the new temporary address more quickly um next slide please then on the server uh there there has been recently a proposal for adopting kind of a moving Target uh defense with IPv6 this is kind of fun this it's called Choi Opera this is not work from the lab um but I've I I took the idea just to imply uh to explain it simply so um what it proposes is um use a temporary IP from for the server that is within a prefix and"
  },
  {
    "startTime": "00:22:00",
    "text": "this temporary IP is determined cryptographically so uh given a shared key A timestamp and A soul that you choose you get a random IP value random I mean cryptographically random um and so if you share this shared key with the client by some ways could be DNS for instance um then you're able to hop from oneip to another and kind of hides your server from Scanners from all those annoying researchers that try to understand what your service is doing and all of that kind and that kind of stuff so here in the same in the same way as on the client the multi-path transfer protocols could help migrate your client flows towards the new addresses and keep your servers keep your servers hidden in a sense um next slide please so we've been also looking at load balancing and we've been doing a simple prototype and try to to see so to today's servers um are very very likely multi-core um and and we started thinking okay does it help to put one IP per CPU core and so instead of having one IP on the network interface on the network interface you would have several IPS and each of the IP's correspond to a CPU core and so we've been doing um an experiment with quick so we had a setup in the lab with quick and 128 clients that make repeated requests so a lot of requests comes in every time for a certain amount of uh of time and we've been looking at how assigning oneip per core helps the load balancing and in the graph there is uh to box plot there is one for one IP per core and then one for single IP which is a single IP on the network interface and we've been observing that one IP per"
  },
  {
    "startTime": "00:24:01",
    "text": "core is could be a nice way to load balance uh the the load of incoming clients so um the reason for that is that in the single IP case um when the next receives a packet it will spread the packets of the if you spread the flows based on the hash so it takes the packet header does the hash and then decides okay I'm gonna assign this flow this new incoming flow to this core and this is a costly uh this is a Time closely mechanism in the one IP per Core case the clients use the DNS to select one of the server IP and so this one stage of load balancing is kind of offloaded to the client and then on the Nick it becomes much simpler because it's simply about looking at the IP and based on the IP choose the core so this is one step but we could go further like many of the load balancing works from the academics that you probably know of have some sort of mechanism to uh spread the load further so all the workloads are not the same in our in our experiment here the workloads were the same so it's kind of a toy example but if you want to spread further the load you could use multi-pass transfer protocols to transfer uh the flows to a different IP meaning transferring the flows to a different core and helps spread the load um next slide please um lastly one ID that is rather in the network rather than Honda host we've been looking at IDs on the host and this presentation but there are more IDs in the network in the paper so one of the ID is is combining IPv6 prefix and segment routing domains and basically put all the related Services inside an IPv6 prefix this is kind of a simple ID but it has the nice effect of for incoming traffic to be able to Route the traffic through service chains just based on the destination IP"
  },
  {
    "startTime": "00:26:01",
    "text": "um next slide please and so that's that's some of the idea we've been uh exploring in the paper um but really the key message of of our position paper and this presentation is that uh with IPv6 we have a lot more addresses to play with uh which doesn't necessarily mean we have uh the only way to use them is use more device we could just simply reconsider how they're used on the device uh and there is much more to do than just assigning one IP to each interface uh and there could be a lot more thoughts in this direction uh to try to explore what all this means and obviously multi-pass transfer protocol are quite useful on the endos to be able to leverage all those um all those possibilities so if you're interested in developing uh those use cases with multi-pass transport protocols and several ipf addresses just reach to us myself Olivier um or share any thoughts you have now um I think that's the end of my presentation I'm ready to take questions so first I'm using my chair power putting myself in the queue thank you very much very interesting uh glad to see that someone else is trying to solve this multi-home and without a bgpo and IPv6 stuff one comment and one question actually two comments and one question first of all yes IPv6 is basically already right by definition any IP almost 10 apb-6 enable hostile already you have multiple multiple other addresses right link local stable privacy multiple prior research right and so on uh you might be interested to go and look into V6 Ops thread going on because I started some fire there uh by noticing that while it's all great operationally if you start using multiple addresses now we hit in some hidden limitations on"
  },
  {
    "startTime": "00:28:03",
    "text": "which vendors tend to put on us and some people actually in V6 office might find your presentation quite scary because as it's been correctly mentioned there are multiple addresses come in with a cost to the network because yeah you need to sub have various types of caches on your network devices for every address and if you talk about some of the excellent deployments it's going to be actually a route per address and when you move from one route per client to like 20 routes per client you might you might actually go to significant upgrade of your Hardware a question so have you done any like practical tasting on fallback speed on switch over speed if you have multiple addresses and like some of them do not work or stopped working in the middle of the session which actually much much worse um so we're pretty early on the process of experimenting so the the quick answer is no uh but we're looking uh we're looking to continue that work and and this is definitely the the kind of question we will like to answer we thought about um how we could uh proposed to the students on our campus to do experiment at their home and really have a lot of people toying with this on a practical level and and see what are the the drawbacks of having multiple addresses how is the OS handling that and that kind of stuff uh so definitely uh you thought about you you talked about uh V6 Ops uh we are also interested not just on an academical level but our okay today what are the the drawbacks uh of what are the the obstacles in the way to be able to use multiple addresses because I don't think many people have experience on that practical deployments and stuff like that oh thank you so next in the queue Luigi"
  },
  {
    "startTime": "00:30:00",
    "text": "that's me hi uh thank you very much for uh the presentation was very interesting um my question is more about um are you just interested in developing use cases and in a certain way uh how you deploy and use ip6 addresses or do you think we can go further and revise actually the the IPv6 addressing model to the IPv6 address model is that what you said yeah in order to revise I mean the IPv6 addressing mode maybe making it evolve somehow so giving such advice is not an easy position um um so my personal interest is whether in transport protocols that's an also you can see that on the multibuster side of the project um but but really like the in the paper the discussion goes as further as uh do we need ports or is IP address all enough can we address one IP address per process and is that does that works obviously from an operation you know point of view it might seem complicated uh but the the concrete step for us is experimenting with all that rather than like proposing a new IPv6 addressing model and I know there's been an addressing discussion in the ATF going on but I have not looked at it certainly uh if you want to learn and uh I can send you a couple of pointers we might talk more will welcome any new ideas there okay we might talk more offline of that then thank you real hi uh so um you've so from the prior question I I figured that you are more interested in transport and that sort of that's the sort of focus um so so you haven't looked have you looked on anything sort of underneath the transport layer at the network layer for example because at the end of the"
  },
  {
    "startTime": "00:32:00",
    "text": "day um so it comes down to architectural naming issue where this is you know clear sort of uh semantic overloading of ips IP addresses right and uh IP address is considered harmful and then you know like this kind of paper have showed that so um my point is um it might be interesting for you to sort of look at the sort of cohesion of sort of say uh Network layer sort of you know tidying up naming architecture Approach at the same time as you look at the transfer protocol what the you know how like um this identifier locator split Network protocol aware transfer protocol might be something that might be fun to sort of explore um I've I've in my during my PhD I worked on sort of that sort of area so um might be good um if we take this offline and chat more later if that's yeah definitely yeah I talked about transport but like we like root cause analysis in our lab so definitely the network if the network layer is involved and there are some impediments in the network there we're interested to know them uh we're not just sitting on the transport layer but yeah definitely let's chat about this okay cool um Megan uh so idea of like address per application and using V6 addresses instead of ports it's actually quite interesting one I think if we want to go to that direction we would need to change deployment model specifically go to something like 64 per host because otherwise like yeah it does not scale because yeah all this like addresses come in as I said with a price and network probably like current networks would not survive until you go to something quote like three gpp is doing when from Network perspective it's still just around the networks are designed to deal with routes yeah and if you go in 64 per"
  },
  {
    "startTime": "00:34:02",
    "text": "host and you give a host the whole slash 64 do whatever you want with this that will be host limitations uh not like Network limitations yeah so again I guess transport people do not come to groups like V6 soft stuff and but I suggest you might pay some attention to this thank you no very interesting comments so yes the intent was to give us 64 to the host and I almost also just wanted to say that our knowledge is kind of textbook IPv6 uh so so the network or the network courses all IPv6 so that's the only thing we know um but um for from our University at least uh but then yeah so so our our understanding is kind of um is that yeah so IPv6 defined prefixes prefixes are routed only routes to prefixes exist but then in the reality there might be subtle things that we don't know of uh and I'm pretty sure Olivier had some insight about that but like the exploration of thoughts started from there from this context yeah so like there are some there is a devil in the details here yeah but yeah I guess we can talk more thank you thank you [Music] uh support team wait do we have the right slide so ah yeah it's the first one is it it's the right one right it's yeah yeah okay"
  },
  {
    "startTime": "00:36:05",
    "text": "right so yeah thank you very much I'm enjoy the Ross from Qualcomm um and I'm going to be talking about bottleneck structures I have a couple of presentations the one the first one is um price the basics of bottlenecker structures uh interaction and some of the use cases um and I'm going to talk a little bit about also production deployments um and then the second presentation after it's going to be about how to compete on the construction the partial information in the context of multi-domain or multi-automa systems um yeah so next slide yeah thanks next one so uh yeah you know I'm not going to go into the math but basically uh you have papers that is a second paper uh sigmatics paper and extended technical report also and then a couple of graphs um that you can read uh the drafts currently the discussion has been asked in the outer working group but um I'm here more in the research group it's also Wisconsin speakers applications of one like a structures could be within other working groups and research groups as well so uh next up yeah thanks so I'm gonna pick on to start introduction I'm going to pick on one specific communication Network problem which is the problem of congestion control so um the prevailing view in in the problem of congestive control has been based on this notion that the performance of the flow is uniquely determined by its bottleneck lean uh this sort of view goes all the way back to you know the famous Jacobson's second paper 1988 which proposed the first congestion control algorithm with this diagram showing the notion of bottleneck link which literally saved internet from congestion Collapse by proposing the first congestion control algorithm now next to the slide uh well this this is a true statement that the performance of a fluency nuclear determine by its bottom line link what we find is that there is"
  },
  {
    "startTime": "00:38:00",
    "text": "a more sort of um fundamental or hidden story behind it and the analogy that we like to build uh to understand what about microstructure is is that if the problem of congestion control were an iceberg the notion that the performance overflow is initially determined by its bottleneck link would be the symptom the the tip of the iceberg what what's uh what what's underneath what the submerged part is what we call the bottlenecker structure which is here in sort of latent but reveals the sort of system-wide performance of the communication Network system right so and we'll see what that means um in the next slides um yeah next now I'm going to sort of put an example to illustrate what a bottom like a structure is so I'm going to start with the communication Network and in this example circles are links so we have four links link one for link four each one with a capacity C1 through C4 and then lines are flows uh servers in the link so we have six flows each one with the color so flow one through four six so for instance 401 traverses link one only float six traverses link one link two and Link three and so on okay now uh next slide um I'm gonna fast forward and forget about the math and I'm gonna um and this I'm going to show you what the ball maker structure is and how to interpret it this is the bottleneck structure of this communication network configuration and the way to read the bottleneck structure is as follows so um vertices white vertices correspond to Links so we have link one link tooling three and Link four are four white vertices color vertices our flows if there is a direct Edge from a Vertex from a link vertex to a flow it means that that flow is bottleneck at that link so in this case we have the flow 3 is going to make a ling one because there is a direct Edge from name one two four three and the other relationship is as follows e there's a Negative Edge from a flow to a link then it simply means that that"
  },
  {
    "startTime": "00:40:01",
    "text": "floats versus that link right so in this case we have the flow things versus Link to because there is this relationship and that's actually true so protein two uh and proteuses Link one so this is a bi-directional but fourth is probably like a ling one so there is also the directed humbling 1.3 and so on okay so that's that's the sort of the core um relationships described by the bottom abstraction uh and so you're gonna start sort of thinking about what what is happening us um so it's telling us wherefore is bottleneck um more information so if you want to click next things now let's see how we how we can start interpreting these um um one uh one of the things that all microstructural probabilities is how protovations propagate if there's a perturbation on disk on this link on link to say maybe this is why listening so the same alternation is changing or something the bomb microstructure tells us how it perturbates that you want to click on next things and it tells us that the propagation of this perturbation will provide according to this D graph and what that means is that no it's going to have an effect on Flow for flow 2 and flow five and then three but it's not going to have an effect on Flow one flow three and flow C's because there is no electrical platform link to to any of these other regions of the network um so let's let's see how it works if we say there's a perturbation on link tool and maybe a change of capacitor then that's actually going to have effect of flow five notice that floor 5 does not Traverse link to but it's sort of interconnected and and that's going to propagate right we can also see other kind of information sheets and does the reverse work so for instance scan um you know this tells us that actually if I perturate flow one somehow maybe I let's say a traffic shape for one or maybe flow one disappears that's going to create the perturation on the network how will that propagate well there's a platform flow one to flow five actually two paths so that tells us that it's going to have an impact on 405. that's actually not trivial to to the human eye you will because you know floor wine is actually on this region of the network is telling us that a perturbation on"
  },
  {
    "startTime": "00:42:00",
    "text": "Flow one say for one disappears that's actually going to have an effect on Flow file which is not apparently related but the reverse is not not true so if I actually uh change flow finally if profile disappears that's actually not going to have an effect on Flow one because there is no platform profile to flow one right so you can start seeing that so the gradually assuming so keeping the stories about how perturbations provide through a network okay um I haven't told you how to read about microstructure but that's in the paper maybe I'll meet that for for this occasion but if you want to click on the next one now the thing what I've been mentioning so far is sort of like qualitative analysis of the network I've been telling you about relationships how preparations propagate right but one thing about competition structures actually they allow us to compute things and that's what we call the quantitative theoremic structures we can actually quantify these so there's a change on the capacitive link to by certain magnitude uh how is that change going to prepare then what's the throughput that's going to be uh what's the effect on profile in terms of throughput and so on right so we can actually quantify this I'm not going to go into what these numbers are but we can actually continue file and this there's a conversation about can we sort of use these to complete a path of magic that's sort of the connections with panology we're going to try to build that we could actually use some of these numbers to put them as mathematics and then we'll sort of also build that a story in the next presentation but the point about this is that you can actually qualify but also quantify this relationship using bottle the bottle of structure so if you want to click on next thanks okay so now can the flap of a butterfly's Wings in America set up a tornado in Asia of course the answer is no but everything is interrelated and even the flapping of the Wings should have an effect in somewhere somewhere in China right uh so uh and that's the point and that's sort of what the problem like a structures sort of capture this idea that uh everything is in the red and how this uh you know how how things correlate in the structure the structure of bottlenecks that is latent in a communication system so next one okay and then I'll just summarize sort of what I say informally a little bit more formally not too much but uh"
  },
  {
    "startTime": "00:44:01",
    "text": "that's what we call the propagation limits and when it goes as follows if a flow f can influence we say that the flow f can influence the performance of another flow f Prime even only if the bottlenecker structure has a directed path from F to F Prime and this works for flows links and in the interleaved as well so in this case let's say there's a perturation in this flow let's say we traffic shade the flow or the flow disappears from the network you're going to click on next things then this portion of the network will be affected but these other flows will not be affected same thing if you um next one if I if there's a protection in the capacitor of this link then next this portion of the network will be affected again but not this portion of the network right so this is how it sort of works um and then next one okay and so you can actually I mentioned you can quantify these things so there's what uh what we call the linear flow equations and this tells us how this part how this perturbations propagate and and in which uh quantity they propagate these are the questions I will not go into it but one of the points I will make about this I'm going to click on next yeah is that um the bottlenecker structure actually effectively are computational graphs and so um that's one of the advantages not you know sort of the framework that provides us but actually they allow us to make these calculations very fast actually um because our perturbation is really a derivative when you portray the flow you're really you know it's a measure defect of that you're really Computing the derivatives with respect to that small change on that flow right so it's a tool to actually compute the limitation so once we have a tool to compute derivatives we have a tool to optimize communication systems and that's sort of the whole point that uh we can use bottleneck structures as a framework to optimize communication networks and we'll see the applications that that have in in a couple of slides I guess but the bottom line is that we can use these componential graph bionic structure to compute gradients and this is an example and an analogy for those that may be required more more words on the AI field is that really a computational network is like a neural network national graph and so you can"
  },
  {
    "startTime": "00:46:00",
    "text": "sort of uh can actually do backward and forward prep um computations on it to competing one is kind of the grass all the derivatives and sort of uh I'm going to start thinking about um how we can use these you know the graph to actually do very scalable calculations if you're trying to find ways to optimize your network in one example graph you can actually compute all the derivatives uh and then sort of get that result uh otherwise that might be sort of unscaled on other using other tools um this also connects to the field of automatic differentiation where you can actually compute this derivatives fast but also accurate as opposed to using limits which is medically unstable but uh with the compilation graph you can actually you do use AV to make these calculations without error actually with 100 Precision so um if you want to click on next thank you um yeah so let's put an example and I'm going to use this an example and I'm going to query the framework the theory and ask the following question I have this network and now I want to choose a flow that when I remove it from the network total throughput increases maximally and I'm going to assume that the flow the flows are regulated by congestion control I'm going to do the simulation using PBR later but I'm going to sort of query the system say which of the flows is such that when I remove the flow I get maximal in total throughput Improvement on the network it's sort of like finding the elephant flow if you will which is the flow that has the highest impact on the network so if we actually and then we can use bottleneck structures to actually do this and if you click on next then you can you know we can scan the graph compute the derivatives and we obtain these of these derivatives capital F is total throughput so what I'm doing here is what we're doing here is Computing the derivatives of total throughput with respect to changing the rate of a flow which could be for one two three four five and six and then I'll pick the one that has them the the smallest value actually the in this case the smallest negative value because what I want is when I reduced the terminal flow I want to increase maximally through the right so it has to be negative derivative and so if you look at this model's value possible is this one so it's revealing us that the sort of elephant flow that"
  },
  {
    "startTime": "00:48:01",
    "text": "Flora has the highest impact on total through product of the system uh would be actually flow seeks this may not be necessarily serial if you look at what elephant flow the technology and zoom they typically focus on the heavy heater flow the heavy heat of the flow here this is a throughput of the each flow actually uh you know the heading here will be floor five which is getting 75 megabits per second and it's telling us that actually flow seeks which only it's only getting 5 8.3 megabits per second is actually the elephant flow here and it may not be achievable to know you know uh you know our human eye but it's sort of you look at the graph then it starts making sense because flow CX is here is highly strategic flow that's sort of traversing the core of the network and so that starts to make sense and why flow six has such an impact so if you want to click on next and indeed flow six sort of here it's very strategic on the graph this is the completion this is the world like a structure you can see that that it needs this is you know the reason why this is a high impact flow even though it's getting low bandwidth there's the actual simulation showing that this indeed happens this is running uh the network that I just showed with all this explodes you get this performance so that the the the purple flow is the high is the heavy heater flow the big flow um when I removed the heavy heater flow which is flow five it's sitting here on the bottom like a structure we know from the theory that this has no effect on everyone else because there is no path from floor five to any for anywhere else and indeed that's what we see we remove the purple flow and the rest of the flow is actually experience no change they all have the same completion time and but instead I remove flow seeks which is this flow here the flows uh uh which is this flow here one of these one of these flows here actually then we see that completion time everyone is getting more throughput in the completion time as a whole execution here it's reduced um from 679 to 457 right so by removing the mouse hole actually in this case we get maximum perform maximum increase in total throughput if that's what we care"
  },
  {
    "startTime": "00:50:00",
    "text": "about say right so you can start seeing some of some of the insights that the problem like a structure provides in this for example if you will okay then all right so um you know types of um types of perturation supported by boundary construction remember a perturbation is a derivative right it's a types of derivatives that you can compute floor routing traffic shaping link capacity upgrades link capacity fluctuations uh shortcuts forward scheduling flow completion job mapping so you want a job map a neural network on a data center say these are some examples of how you could actually use bottleneck structures to sort of optimize the map these kind of um uh problems by Computing these kind of perturbations these are perturbations on a system when you when you place a job that's a perturbation how does that affect the system and next one okay then I'll talk a little bit about use cases again and so um yeah thanks and so there's this sort of key here that you know building construction at the door root and then what are the applications we like to think about team link branches Network design traffic engineering AI if you even you can see some of the applications 5G resource allocation for performance prediction Network modeling slicing routing congestion control Mac for resilience uh capacity planning robustness analysis data center design engine networks even modeling simulation these are some some of the applications that where um some of them that we're actually working on and some of them are being sort of research and put a list of potential um uh research groups maybe that uh could uh right now like I said we're in the auto working group but um by coming here more in the on the research side I hope they got feedback on where some of these things could could potentially you know uh have a contribution in some of the research groups or or working groups that um that you guys are working on so then next one thanks uh and then in the draft in the draft that I have that we have in the alto working group um two dash right now the first draft uh"
  },
  {
    "startTime": "00:52:00",
    "text": "we mentioned a few use cases so uh application really limiting for CDN and Edge Cloud applications time bound constrained flow acceleration for large data sets uh propose optimization through AI modeling John writing routing system control service placement network computing training neural networks mapping a neural network on on a on a GPU cluster or data center a network slicing these are these are use cases that we elaborate a little bit more so if you are interested you can go to the left and see how we think about Network structures could could help there then I'm going to click on one example which is um optimizing routing and congestion control that's also from draft so let's see what a specific example yeah and so this example focuses on on Google's B4 network from the sitcom paper so this is um uh the the each each of these nodes is a Data Center and that's the interconnect this is the adjacency Matrix you want to click on next that's the same thing a little bit more human friendly which is the Google's uh yeah Google's V4 network from the paper from the sitcom paper uh and how it how it's interconnected okay so we're going to apply a bottleneck a structure here to reason about some of the insights from this network I'm going to click on next uh yeah and so assume a simple configuration with a pair of flows between every data center in the US and Europe we're going to give this really simple uh all links are seem to have a capacity of 10 gigs except for the returns online 25 gig uh if with these two assumptions then we complete about microstructure and we obtained this bottleneck structure okay if we click on next that's a little more graphical uh then that's what we think this is the bottlenecker structure here we have y vertices are links so if you want to click on next two and then on Graver this is our flows or paths and here so there's some mapping so these two tons of Landing links uh link a then link time would would be sitting at this uh at this location the ball microstructure"
  },
  {
    "startTime": "00:54:01",
    "text": "link 8 and Link 10. uh and these two other links here we'll be sitting at this location in the bottom like a structure we are representing here the bottleneck construction what we call a canonical form where it's sort of like um the edges the edges the direction of the edges always go down not up uh unless unless they are bi-directional and so there's this property this this Lemma that we show also in the paper that the available bandwidth um is monotonically increasing as you go down the graph so the Flows at the bottom of the graph will tend to have more bandwidth or the paths at the bottom of the graph will have more bandwidth uh you can see that I'm changing flows and bad interchangeably I haven't mentioned this but there's a version of the polynomial structure which we call Path grading graph which is folding all the flows that follow the same path into a path and you can same do the same reasoning changing floors or path and I think that's that's for pi energy that could be more interesting because we really want to talk about pants I think but um sorry I think I I got I think that's right so but what I wanted to say about this is that you can see that this these two links actually somehow in the U.S are highly strategic because they are at the top at the root of the graph this means that any perforations on the capacity of these links will actually have an effect on the rest of the network actually and this is not true for these other links are at the bottom that really they are not so easy because perturbation these links will not have the same effect so that's kind of like the quality representing about this setting okay now the question is okay I want to transfer suppose that an application needs or data center needs to transfer you know a data set on a sort of a large data set from data center 11 to day Center four right and and we need to decide which path to choose we have multiple path options and so then what we can do here is a random instructions and figure out what what uh what band we will get on each of these paths and the idea here what we're doing here is what is sort of solving the joint congestion control and routing at the same time asking the question if I place the flow on this path uh what's the battery that this path will get and what is the fact that all the other parts will get so the ripple effect the Xposed result I don't want no no after I"
  },
  {
    "startTime": "00:56:01",
    "text": "place it what is the actual performance I'm going to get uh because placing that flow itself is going to have an effect on the network so how is that ripple effect computed so that's what we we're going to do using bottleneck structures there's an algorithm to actually solve this problem which actually combines dice with bottlenecker structures so you know that directories every algorithm so every step is actually querying the bottom like construction building around like structure in parallel to come to to discard paths that are that would never be optimal uh using the really nice approach and so that's why the complexity of this algorithm is V plus e log B the traditional diagram and then we get this result in this case we get that this is the optimal path and we will give you 2.5 gigs per second as created by the polynomial structure any and this is a non-service path actually that gives you higher throughput if you actually use the shortest pad you will get 1.4 I give its per second of throughput so then you can decide whether you know whether you want a high throughput path or the low latency path but you can make that based on an informed decision you can also use this for SLA management so because what you can do like I mentioned once you place that flow you can see how the rest of the flows will be effective will they have a violation in the SLA so before I place that flow I want to make sure that uh that that will not violate SLA agreements on other paths say right so that's kind of IDM yeah next thanks and this is sort of the result here so um I'm here we're using bottleneck structures to uh you know project what will happen if you place the flow in the shortest path or not or not the shortest path if you are the non-short of spot on the shortest path which is lower throughput 1.4 you would place it here at the top actually when you do that the floor the the flow would go right here at the first level if you place it on the on the on the launch of this path the flow would be placed here and that's remember the monotonic property if you place something at the bottom you get more throughput that's what's happening here so the recommendation if you care about throughput here is to place it on the launch shortest path which will give you 2 2.5 of throughput as opposed to 1.4 then you can do the SLI management"
  },
  {
    "startTime": "00:58:02",
    "text": "to go next and then this is the ripple effect uh if I place the flow here using the shortest path the the red circles are the portions of the network that will see an impact if I place it on on the main shutter speed the green circles are the ones that will have an impact so you can see that actually the impact is smaller because we're placing the floor at the bottom of the graph so they were influencing less others so it's kind of also more stable maybe as opposed to here that's creating a ripple effect much bigger than the whole network and then next one is this idea that I mentioned that as I mentioned that this monotonic property that the Flows at the bottom at the top are getting less bandwidth or the paths of the topic and less than me that the ones at the bottom if I place the flow on the top I'm still in bandwidth from the ones that are getting less bandwidth that's you so you could reason that maybe that's not a fair thing to do because all these Flows at the top we're already getting a low bandwidth are going to get even less bandwidth but if I place the flow at the second level these flows have no see no impact right so their their low rate does not get deteriorated any farther and so maybe that's from a fair standpoint you can also reason that it's also good to actually push the flow to the lower level because you get more fluid and you're not gonna have you're not going to have the flows that actually have uh less and uh yeah I think that pretty much covers it I want to put a note on we have uh to the production deployments and on this one is that the national research platform which is a uh a US Hawaii Network used to be called the Pacific research platform at the UCSD Network connecting the Pacific and the west side in the U.S collecting the universities and research Labs um that's called NRP uh it's a U.S wide Network I mentioned and then the other one is the doe is that which ensure um many of you note also which is a U.S or a wide Network connecting also National Labs Etc so um one application we're using for the for the years capacity planning but we're also looking at traffic engineering um and so you know for lack of time we will not go into diplomacy but maybe not some of the time we can discuss"
  },
  {
    "startTime": "01:00:00",
    "text": "deployments and I'm happy with any questions we actually have time so if you want to talk about something yeah um uh we can leave it for for the for the Q a that people have questions yeah I was going to ask that question so we'll leave it for the Q a cool yeah so um we already have Antoine because I think that's the last one okay and one note on discussion my you know uh my you know I love to get or would love to get feedback in terms of where we think this could this could uh connect with other working groups or research groups so that's one topic of discussion but anyhow and you know it's open for any other questions as well of course so I have a question but more on the graphs you are using rather than on the working groups I won't help you on that uh in fact when I looked at your graph for bottlenecks and how you so yeah when you so when when I look at your graph with uh flows that are nodes but you also have nodes that the flows go across that are represented as nodes it reminded me of the work of machulata p a researcher in France working on some tool called stream graphs it's a sort of mix between time series and graph and you have mathematical tools that help you associate properties to the temporality of where flows cross some nodes in the network so I think it would be beneficial to your work to look at this abstraction because I think this typically applies to what you are doing okay okay good I look forward to talking about that yes very nice thanks thanks great work uh sounds very interesting um to me um maybe iccrg is a good place also to to come to"
  },
  {
    "startTime": "01:02:00",
    "text": "um so because probably we have to think about different ways of doing congestion control in the sense that maybe the current closed loop congestion controls are some kind of Last Resort but we come more into a direction of having better planning so that you can ramp up flows very early for example and with your framework one could actually see the effect if I admit a certain flow what happens and is it better maybe to rate limit that flow or just I don't have it at all and so on so I think this is quite useful okay thank you yeah the next the next presentation is I'm going to talk about how to do this uh under partial information and the case of ICC IG I think or congestion control in general can be seen as as a specific case of partial information because in a distributed congestion control algorithm every node has partial information and they're all trying to converge to optimality basically so that that probably could enable another another composition but yeah thanks so yeah Brian Trammel as an individual not as paner G chair um so I had um one question that I missed at the beginning of the presentation uh and have like I should have stopped you but now I'm going to have to go back and re-watch on like 0.75 speed um but so the difference between an edge that is unidirectional and bi-directional right like how do we like when we're going through and like actually constructing this graph how do I know I'm putting two arrows on it so that you have two errors when actually whenever your bottleneck somewhere you have two arrows it's bi-directional the reason is because if your ball like there you're coming got it okay yeah good okay yeah wow the rest of the talk makes a lot more sense now cool thank you very much um the the second thing that you know um uh riffing off of Roland's point a little bit uh I did uh very much have"
  },
  {
    "startTime": "01:04:01",
    "text": "the feeling that I was watching an ICC or G Talk here which is great because I missed ICC org this time so thank you very much for reading this fanergy um I think a lot of the questions about sort of like Computing the optimality um that's a good venue to get like good feedback on that and sort of like develop the idea there the thing that I would be interested in seeing in pan RG is like okay so we have this mathematical tool how can we um you know I'm gonna go ahead and take the mask off so you can see my see my watch my mouth moving how can we um tie that to some of the signaling stuff that we're thinking about in panergy right like so like the the you know you brought up the B4 graph from the sitcom paper which is like okay well you can very clearly see how this would be used in a centralized planning um sdn sd-wan um situation I think you're probably going to answer some of my questions in the next talk so I'll I'll um actually I'll probably re-ask the question then is like I'm really interested in then how to tie that partial knowledge situation into what signaling we would need in a path or internet work so yes I think the next one will will probably perfect on that and maybe more questions yeah thank you okay so I'll then the second part is about okay we know what the bond like a structure is at some level and um we like to actually be a little more practical and and one way to make these particle is okay how do we Implement these uh and under partial information which is typically the SMS that we face in the communication system where you don't know everything they still have to make the best you can invest on the information that you have so let's talk about these a little bit and the yeah I'll do I'll skip the first part actually we've done that so checkbox but then we'll talk about Computing model construction under partial information I'll talk about the distributed border protocol that would allow us to do that the signaling part if you will and I'll"
  },
  {
    "startTime": "01:06:00",
    "text": "put that in uh I'll just honestly have this protocol will work uh and Achieve Global conversions and then discussion yeah right next one yeah same theme papers and wraps next one you can actually skip this yeah sorry um more and more sorry thank you yeah okay so now remember I'm going to actually use the same example so hopefully we're a little bit familiarized the same network configuration but so far we've assumed that we have full knowledge of the network right now let's assume that that's not the case and let's assume that we have two autonomous systems so if you click on next ah okay so we know that this is the bottom line Construction we have full knowledge but if we click on next now we're going to assume that uh and this this network actually corresponds to two Automotive Systems and you know uh each as knows only its own region so as1 doesn't have an information about as2 it still doesn't have any information about as1 now we run the algorithm so you can click on next uh we run the ball like a structural volume that's in the paper to compute the one like a structure uh a is one which converges to this we think that this is the the view of the world this is the state of the world uh this this graph uh but obviously based on you know this uh sorry this is as1 so um now this actually is to uh oh this is your presentation actually uh somehow uh we have to do a Reload if not that's fine I can probably get out quick reload up there I think you got it you got it yeah okay let's see if we can"
  },
  {
    "startTime": "01:08:00",
    "text": "okay hold on um uh I'll understand what you see what we got it's fine okay well I can try again just a second um yeah I don't have any pending no I was uploading from my mail yeah Yeah but I quite sure I huge yeah yeah okay slightly in that um is it still old one right that's that looks like the last one yeah it should be fat instead of floors but otherwise you have a puref those are F's X yeah so uh okay let me is it a is it a is it a serious content problem no okay yeah what's this uh let's move on then and then we'll uh upload the correct whatever you see an app should be a p and uh latest and we'll get the latest updated on the uh because it works for paths basically and so um instead of closes our paths so um as one doesn't doesn't know anything about DS2 and vice versa so if a is uh and this is also swap so if a is uh two tries to figure out the bottleneck structure it will compute this we just which is incorrect right it's this uh this is not the same as this and"
  },
  {
    "startTime": "01:10:00",
    "text": "if uh a is one actually this web uh computes the one like a structure actually we will compute the right thing actually but it's because it got it got lucky um because there is this property that if a part is not it's bottleneck if all the paths are ball making my in my autonomous system then another computer structure with any information from anybody else that's what's happening here with uh with as1 actually this as one that actually uh it happens that all the paths in as1 are ball negative in as1 so then it actually can converge but it's because it got lucky uh and as2 uh actually uh the past two so it's not gonna get uh it's not going to get it right so obviously we need to share some information to make this work so we can click on next and uh the proposed protocol here has these three properties uh conversions which is the key idea but sharing one method per path is enough to ensure conversions to the correct bottleneck substructures here I'm introducing some terminology we could be the global one who called balmic structure and then each as has a bottleneck substructure and the idea is that we want each as to compute the ball negative substrate that's correct what is the correct bottom mixer structure subtraction is the subset of um the bone structure that corresponds to to that as basically intuitively so um and then this is saying that all we need to do is share a path uh a path metrics uh which I'll tell you uh in a minute what what that is um scalability focus on building the path creating graph so here's another thing that we describe in the draft uh bomb microstructures um there are different kinds of boundary constructions one is what we call the floor reading graph which is per flow but this one which is called path grading graph which is per path and that's way more scalable because you may have hundreds of bands as opposed to millions of flows um and and the transition from one to the other is a straightforward actually so um for this we focus on pathgrading graph"
  },
  {
    "startTime": "01:12:00",
    "text": "and so requires only per Path State in this case not per flow and then privacy this is subject to discussion I guess but we think that this could be good in a sense that you know we only need to share one scalar one metric per path we don't need to remove flow information uh there's only three well netflow data or or topology data obviously is a medical scholar per path so hopefully this is this is a good in terms of the Privacy uh depending on the use case so um next one then this is the the the distributed protocol it's in the in the second draft uh but along these are the high level and I don't expect maybe to understand the leaders but the intuition and it's actually fairly straightforward that's that's a good thing okay um so uh it has a netline timer and and then and a message event you know a message exchange event uh the timer is running periodically that's right these two these two events around each as runs their own instantiation but the first thing we do is um some some solutions that's interesting in the draft L is a set of links AI is the autonomous system I so this runs for each AI PL is the path Ling dictionary where we call the path link dictionary for every path the set of Links at that path traverses C is a capacity dictionary the capacity of each link and PM is a path metric dictionary which reveals the information we received from our neighbors okay so this sort of includes the global information that we're collecting by talking with our neighbors and this is sort of like the local information that we have um what this does is compute bottleneck sub structure which is a function that's in Nexus light in the US that it tries to compute the bottlenecks of structure as accurately as it can based on the local information that we have and this mathematics that we receive from the neighbors once the output of this then we consolidate it into the new path magic dictionary this is what we're going to be sharing with our neighbors and then here in the next step we actually share with our Network"
  },
  {
    "startTime": "01:14:00",
    "text": "neighbors we share the output of our computation into the magnetic and then we shared with the neighbors for all AJ and N these are the neighbors um we're sharing the path we're sending a pathmatic announcement message to our neighbors passing our pathmatic Vector dictionary and then uh this is the event upon receiving upon receiving a path Network announcement from our neighbor we simply take the minimum actually um this is the notion that the ball make is always the minimum uh it's this goes back to Jacobson's favorite that all weekend is the the single volume the the most constrained link right so that's that's in that Indonesia's notion but this is taking into kind of Fuller structure um and then if we want to zoom into this function complete by an extra structure that's an exit slide and what it does is this computable mixer structure it runs this while loop which invokes additive iteration the compute bottleneck as structure sort of uh that's again not the one that's available in the paper uh and it it runs multiple times until it uh reaches agreement with the state that we're being shared from our neighbors that's intuition so we compute it completely structure based on the link dictionary the pampling dictionary and the capacity uh um factorial dictionary here we check if they hear about this is the output of our computation our local computation is in agreement with what we've been told from our neighbors then we're good we break we're out if not then we need to do something we just we need to add a virtual link we don't know our neighbors our network network we're going to model that by putting a virtual link and putting a constraint there that's what this is writing a virtual link with a capacity equal to the the path metric that's provided by by the the neighbor as and then we go back and it can be proven as sort of the map that uh if you do this over and over eventually everyone will converge to the right bottleneck substructure when you aggregate them you get the right Global"
  },
  {
    "startTime": "01:16:00",
    "text": "modeling construction we can see with an example maybe it's going to be easier to understand but hopefully it does the intuition about the signaling so and then before putting the example uh what we call the termination condition in the convergence condition um in the previous function you saw that there was domination a break which was it was a while true but there was a break statement the information condition is when intuitively it says that when my local computation is in agreement with the path metric dictionary that's being shared with my neighbors when we are in agreement and we can terminate and in a convergence condition uh um and what it says is that if you run this algorithm we ensure that at the end everyone is in agreement all the mathematics from all the AI from from all the autonomous systems AI AJ follow the paths are in agreement that's that's guaranteed by the youngerian okay so we have these two conditions let's look at an example how this works so back to our configuration so two other systems uh we can click on next this will be iteration one and again this uh the latest version is going to have some corrections on this but it's fine um so um at the first iteration um autonomous system two actually gets it wrong uh it's this is the path metric dictionary uh that is that it's that it believes is the sort of the the state of the wall but it's it's wrong um and then application one alternative system one actually the swap actually gets it right and the reason is that property that I mentioned because all the plans are actually born like in its own domain so he actually gets over here the the as actually gets it right um so this one has already converged uh now they exchange the paramedics so this path metric dictionary is going to be shared with this as now with that information uh for as2 it's going to take another iteration so if you click on next and then in the next Direction the area is going to get it right okay so and the trick is"
  },
  {
    "startTime": "01:18:00",
    "text": "remember we are adding this virtual um so we don't know that our neighbor but we know that it's this path is bottleneck this path four is bottleneck somewhere else and we model that uh by using a virtual node here and this path six is more like someone else we we know we modeled that with another virtual node and then this if you look at this structure this the you are decent with this you get the correct button like a structure so if you click on next end we can also see that uh we can now check the convergence condition and check that all the path metrics for all the pathmatic dictionaries from the two is are in agreement so 1616 8.3 8.3 uh and so on okay so then next and this is sort of the the higher level idea that you would have multiple as each one doing its bottleneck substructure calculation and then sharing this arithmetic announcement messages providing the asid and the pathmatic dictionary and then ensuring that this uh ethernet work stabilizer then you eventually the bomb extraction everyone gets gets it right um and I think that's that's it and then the same discussion can be open in terms of potential applications or questions Roland is making his way to the mic um I think two comments here uh one is maybe I'm I'm not sure that that actually the ass or providers will be that candid and exposing that they have a bottleneck inside there is that is maybe one thing that could be a little pushback for that and the other thing is so let's assume that you know that paths are congested then probably your whatever routing decision will then be based on that and we all know that if"
  },
  {
    "startTime": "01:20:02",
    "text": "you do let's say routing based on Dynamic metrics like this one where you have latency or congestion uh that will lead typically to oscillations at least in several cases so have you thought about what why it is not totally clear to me what what you want to do with that outcome that you identify what are the bottleneck as path so what's the reaction to that do you consider a system where end systems are able to choose a different path or okay so uh on the first question um so actually this doesn't reveal that I you can that I that this path is born like at my as actually um you could do you go to real if you if you want to do that but you can keep that privacy when it reveals is that uh what the as ends up knowing is whether I am the ball knuckle for this path or not that for sure uh so we certainly and then if I'm not the bottleneck I know that's somewhere else but I don't know where some other as now if you want to do the SLA management and figure and you could Envision an overlaying protocol that then sort of output data and say I'm not the bottom like I'm not development eventually would find who is the bottleneck but if you're not interested you cannot put you may not participate and you would not be revealing that you are the ball negative that's if that if you're not interested you could but it but uh but it's only an option to reveal whether the other bottleneck what you get is the information that this path uh is actually bottleneck on my domain and if not I don't know where it's bottleneck and I think the second question is one about um uh not just qualifying these relationships but also quantify them um construction is not just to know whether I'm bottleneck or not but to use it to do traffic engineering once you have the bottom like a structure now you"
  },
  {
    "startTime": "01:22:00",
    "text": "can start Computing derivatives on that and figuring out if I place the flow on this network um what's the expected uh performance of that yeah okay yeah yeah so um that's that's the sort of the idea that we can we want to compute the one with this one like a structure so that then we can do the sort of the derivative analysis on top based on that without knowing other other people's other networks um uh Ballinger structure but still being practical yeah okay thanks okay so uh yes Prime Terminal as an individual again thank you Roland for actually asking half the questions I was going to ask um I think there's another way that we can consider um like there's also a scalability problem here right like so you build a the the the the scaling of the convergence of the inter-as path has to do with the number of a s's in the full Network right like so this is a toy example that you worked us through and the number of paths that or the number of edges in the bottleneck graph inside each as and I haven't done the math because I'm sitting up here at the front but it feels very much like this scale's extremely super linearly um Let me let me try to see let's show the bottleneck structure I'll just talk about conversion let's talk about how it actually converges so if let's go back um back back warmer let's try to pull the the global modeling structure and more and more or until we get to the next here yeah um this the conversions time is revealed by the ball like a structure itself where it works as follows so um okay there are six parts here right the first the first to converge will be path one part three and past six will converge immediately because they have no dependency with any balance anybody else once these three pass converts then 402 and flow four can converge one flow"
  },
  {
    "startTime": "01:24:02",
    "text": "of two of them flow foreign so the convergent complexity is basically solely dependent on the bottleneck structure not on how you split it up into as correct okay um one of the of the tricks that we've seen in other pathway or networking approaches I'm thinking about selling on here uh mainly is when you end up with this with a substructure that is approaching too complex for you know the the algorithm that you're using in order to figure out the route or whatever um you can abstract it away right like so the way that song does this is you can essentially take an S and you collapse it down so it looks like a switch right and I'm actually wondering if there are ways that you could iteratively do that within an as so that you get a very simplified substructure so that the overall structure gets you nearly an optimal result with way fewer nodes yeah um so then we go forward uh I wonder whether that that captures it so you can tell me um Ryan um more yeah more for forward here so this is exactly I think what we're doing what this is doing here in that uh here uh you can see V2 and V1 what they're doing they're collection okay into a single virtual node we don't know what that is yeah it turns out that V2 and V1 are Nas but we don't know for us yes these are two different black boxes right we know the path networks that they of we know they're parameters but we don't know anything else right okay okay okay cool thank you for walking me through that okay any other questions good okay thank you for your mind Jordan so Finley and I guess you are remote I'm getting the slides"
  },
  {
    "startTime": "01:26:01",
    "text": "[Music] okay can I can you hear me uh yes yes we can hear you okay thank you okay every start I said good morning respectful colleagues and experts and this great honor innocent celebrity and on behalf of my groups in the Deep Corporation I'd like to say I would like to work and the sexiness and service provisioning of the network and the topic is what the interviews is database this is a visual service which is known as PB illness the framework use cases and requirements and next slide please requirements in framework.prness as we listed here this illustrates the background information and the tablets interceptions and our considerations beginning with the challenges of the code Network and the Gap analysis of accessible issues and next slide please they're the rapid developments in the complete Council improvisation of cloud computing and local internet that becomes a popular and amazing platform to various Enterprises and government departments to hence data in the cases so a data explosion and massive access to the cloud had improved to be an inevitable incarnation resulting in historically accelerating rates of traffic traversing system that we're doing so as depicted here in this figure of the network domain from Fling cell to equator is divided into several sections and smartflowers written Focus as a network infrastructure in different sections may vary from one to another with Google screen distinctions of"
  },
  {
    "startTime": "01:28:00",
    "text": "network capabilities applications may require Diversified requirements of latency templates or flexible and the country has a demands like the application a b c here yeah and it requires high bandwidths they use demand level vacancy while application C requires a favorites in finance and ideally traffic of distinctive applications just actively into pause shown here in different colors however in conventional networks visit details including post distances and reception bandwidth in a network domain concealed capabilities of the network to remain invisible and those differential aged services are not provided applications for various requirements cannot be distinguished in just a customer really latency sensitive applications could misunderstand that the fortunate of the traffic is a restricted bandwidth from things to cancer which is 22 however in fact the difference in different parts through school and anxiety over 200 kilometers which is here 869 and 626. this results in apparent delay and so find when your marriages service can hardly be provided for applications and next slide please and what's more another occasion of the traffic from dancer to leoning due to the bandwidth restrictions in responsibility and probate learning sections dependent of the overall course along sensory and the product is confined despite the reflection of bandwidth going against to census"
  },
  {
    "startTime": "01:30:01",
    "text": "British 100g and this sectional resources are kindly wasted and overall utilization is relatively low this ideal conditions supposed other sections could be utilized and the traffic to the speed intellectually and next slide is to sum up conventional networks only to provide clients to this course range connection services and differentiate the service treatment is desired under current circumstances the network resources are not orchestratory but property right and for example in China the resource utilization to to be relatively low for about 30 to 50 existing issues like S01 handles the problem by monitoring the latency of multiple rapid paths and Appliance of dynamic multiples optimization algorithm and uh however it requires traffic detection techniques and accuracy and immediately guaranteed simply by Collective statistics thus when instantaneous Jitter occurs on the monitored length the current traffic is usually switched over to a standard required standby Palm which results in a waste the furthermore was an introduction of network coding schemes also exerts active burden of network this one is capable of configuring different priorities in accordance with requirements from the clients and further generates and public corresponding Qs policies to ensure Service delivery letters these sensitive topics such as voice over Internet Protocol and web conferencing making are configured with higher priority and is further into a"
  },
  {
    "startTime": "01:32:01",
    "text": "specific part with better performance while services like 12 bytops are around lower priorities since they are less time assisted and may even reduce and blocks on network links for dedicated lines usually configured between data centers to interfere Network qualities in another scenario it is relatively postalated and the period of service deployments and provisioning is comparatively wrong delays attacking losses and interruptions also occur so with the conclusive view defined granulated services and net purchase sources utilize data enhancements or are considered required and next slide please yes the sun is bandwidth for instance Transit Network also has also been Inked out with various other capabilities including deterministic quality Network slicing endogenous security sector which can be developed as services referring to the software as a service Source a database based open resource service framework is proposed aiming to practice the concepts of laws namely Network as a service you've been said that you reserve applications to our terminal and CPE to subscribe because funding customized Network Services next slightly as a framework of ADB owners the network controller collects the running status of the network and assets and network functions by extracting key attributes including video link lead to length nodes and AP links in particular information includes descriptors of"
  },
  {
    "startTime": "01:34:02",
    "text": "hackners and tailners in the radio layer 3 lens as it uses identifier a terminal system index Etc a distributed database is also introduced here which is the things strong consistency and a typical subscribe propolis mechanism is applied capabilities can be abstracted in a key value skin and a standard schemat template file is utilized for descriptions the cloud concealer or super orchestrator who has a subscribe to updated information of services published with a watch mechanism is performed it enhances the efficiency of information advertisement now written knowledge of network capabilities power calculation can be performed and the services can be very orchestrated and bonds with specific policies also with database clients routing updated information plus degradation can be reflected and learned next slightly to illustrate this excluded process we hear presents a detailed instance the network communicates various clouds and multiple applications Data Center interconnection and Cloud access from various applications are for example scenarios and and the overall Network domain here a b c and d constructs part of the federal topology policies identified by binding suits are also assigned here called network resources and capabilities are more in the sub domain are accepted in the form of BB link and bt-link read the link and retailing constitute a substitution for original links and unique logical topologies are perceived"
  },
  {
    "startTime": "01:36:00",
    "text": "from the perspectives of different style applications here for example scene from cloud a pretty length from a to d includes two parts of segment list a to the draculate or a to d to a relay C but this port is observed with only single segment list by type B resources like Pampers are also distributed respectively for different virtual links the typical instance is the leader link here from A to B we're doing for cloud a is allocated with bandwidth for a 5G that's 45b is only three two a shown below logical topology may present identically for different clouds and applications however resources are reserved exclusively next slide please foreign [Music] which can be identified by local and remote no disorders interface processes and other parameters of capabilities similarly data language represents a battle tunnel and taking signature over IPv6 is ethnic example typical attributes include logic ID no descriptors maximum resolvable link bandwidths binding speed Etc to facilitate our speculation and racing in clouds a new log guiding is defined here to identify our revealing or retelling The Logical IDs be globally unique in the network domain as a team moreover in order to make the customized refinements from different prior applications at the same time the parent networks lead to link resources in layer 2 for topology"
  },
  {
    "startTime": "01:38:00",
    "text": "resources for layer 3. maximum resolvable link batteries for instance is a maximum of the spherical link band resources for virtual links where multiple clients share identical physical links to network and sellers must reduce the maximum visible resolvable linked bandwidths allocate to every one of them exactly of the original physical links in advance is this the traffic can be preserved from potential and possible interference attributed to other clients and after the abstraction the information is written into the database with a key value scheme and a standard schemat template is applied to a check license and description this description the specific entities and then the carbon server is able to accumulate the knowledge of the running abilities of the network and to further break arrange and orchestrate support to steal the traffic next slide please compared to Auto this is known as application layers traffic optimization with similarities and differences or listed in those well and to be honest the abstraction of network of capabilities is designed to be more exploded and diversified which leads to deflated conditions of five granularity services and in water we have specific Auto Service while in DB owners uh distributed databases as the server maybe almost also shares identical features and advantages with auto including accessibility and standardized API definitely Auto provides a universal and normal scheme for explosive of natural capabilities and our sites and perceptions within the owners with focus on the Rival of the network controller"
  },
  {
    "startTime": "01:40:00",
    "text": "and the specific cost calculation operator to facilitate Network Services occupation corporate cooperates well with a filter condition of the convergence of the clouds and the network next slide please before we considerations it is easy to expand more open sources beyond the language Source Services different interests presentation such as topology is Securities and deterministic cues which makes the frame rate of the owners be capable of justifying future requirements appearing with the change of the convergence of the cloud and the network in England conclusion more perceptions and drugs are expected in the future we are looking forward to promoting and to cooperating with working groups and as a colleague who had originated with the issue safety and the service Affinity issues should also be considered in the future and that's all about this today's fifth station thank you all questions all right [Music] hello Sabine from Nokia uh thanks for your presentation uh very interesting so definitely um well to mention I am contributing to the auto working group so definitely we do not take the next up the same approach you try to steer traffic at the network layer while we at the auto working group"
  },
  {
    "startTime": "01:42:01",
    "text": "we try to provide guidance for the application so it's an off-path approach to uh redirect the traffic I would invite you to uh look at the auto work that is ongoing where there are proposals to extend the protocol to integrate compute information thanks yeah thanks actually I've learned some information about Auto a note concept of Auto that uh this is the kind of application protocol or just make endpoint selection to guide the traffic about still make the network domain as a black box that's here maybe we want to expose some capabilities of the network and to and do some traffic with Direction work okay anyone else okay so thank you and this I guess concludes the session so thank you very much and see you in Yokohama so for this one I think you're supposed to okay"
  },
  {
    "startTime": "01:47:49",
    "text": "foreign"
  }
]
