[
  {
    "startTime": "00:00:16",
    "text": "hello everyone this is the sibo working group meeting at itf 112. my name is christian amsas very labor is sharing with me and will be joining us shortly let's get started this is an itf meeting so the note 1 applies this means that this is a public meeting and it is being recorded it also means that if there is anything in terms of patents or other ipr that you're aware of please state what state would state state that or do not talk about that topic at all um this also means that we all want to be nice to each other this is supposed to be a space where everyone can talk up freely so um please ensure that people feel welcome here if you have any questions about any of that um please follow the links that are all listed in the slides um indicated here in think or talk to me or the onwards team depending on what kind of questions arise and our agenda for today we have a few topics first group of first block is working group documents there i'll just give a few a brief update about documents that are sent to the rc editor or our work in progress without any particular updates that need for the discussion here then um filling in for michael who is also busy in another meeting our carson will tell a bit about issues that have come up late in file magic and then we'll continue with seaboard pact um looking at the the open questions that"
  },
  {
    "startTime": "00:02:00",
    "text": "we'll have to answer there before the document can run and after that there will be a few words on the topic of notable tags and um and a large block on the future on future development of city of syria and apologies for whatever happened in there that it says notable text that's why i stumbled here briefly um the individual document that should be here is notable text um which is also something that will need work in the work group but was not planned for today i don't know what happened here um what should be it should be saying here is application oriented literals um extended diagnostic notation which is something that i'd like to ask about whether or not we should we should adopt that are there any changes you'd like to propose any additional topics that we should bring up today um hearing none uh um hearing then let's go to the documents that are uh that actually have left in the working group already just giving a brief update on what changed there in the steps that not all of you might have followed cddl control got switched over to the standards track and is now in the rfc editor's queue network addresses um in the latest iterations after the last itf gain support for zone identifiers which may be numeric maybe textual or maybe absent as they always were and this now is also in the in the rfc editor queue the time tag document we adopted in may is still active"
  },
  {
    "startTime": "00:04:01",
    "text": "but this is largely waiting for input from the state working group because whereas much of this is rather uncontroversial the topics of time zone indication that will also um be supported in the sewer time tag will just need to wait for whatever comes out of the date but judging from having seen the minutes and how of how often this has come up in homewood discussions i conclude that the group is rather active and we just follow what is happening there if there are no comments or questions on those documents i'll hand it over to carson for the next topic of cdl control ah sorry of file magic thing so let me try to [Music] get my slides nice okay so i have one slight deck for file magic packed and for cdl 2.0 um so let's talk about file magic first so what what do we have at the moment we have a way to use 555 799 which is a tag that already was defined in 7049 as together with uh a oneplus 4 tag identifying a specific kind of data item and thus the file format to get an eight byte prefix for sibo data items but that only works for single data items so if we want to have a magic number for a cbo sequence"
  },
  {
    "startTime": "00:06:01",
    "text": "then we would use a new tag which is defined in this document which is also a one plus two check plus a one plus four takes so together we have eight bytes uh plus um conventional content for that uh tag which is the um byte string b o r which uh miraculously becomes c bar when you look at its representation um so that would be a 12 byte prefix you you uh prepend to a sibo sequence it stays a sibo sequence but it just has this additional entry that that identifies it as what the tag nnnn so that is stuff we have had for a while and then we thought well it might be nice to actually have pre-allocated tags for sibo content formats there are two to the sixteen uh siebel content format so it that only takes a small byte out of the oneplus 4 tags so we define one oneplus 4 tag for each of the two 216. content formats and we actually managed to do this not with a table but with a simple arithmetic and so that was all fine and we thought we were done but then i made a big mistake and put in examples into the document that actually are non-cbo content formats so all this the things on this slide really work with data that are in sibo form either a single zebra item or receiver sequence and um of course the mechanism just doesn't work for data that are not sibo-shaped"
  },
  {
    "startTime": "00:08:00",
    "text": "so these examples are really misleading and the the comments came in that we would need to do bytes ring wrapping for these data to fit them into either 555 for 799 or 55 800. um which one could do but then it would no longer be a constant prefix that you just have to slap in front of your your data so it would be more work i mean it's it's a killing amount of work but it would be more work and it would make it harder to peel off that prefix so it would be a much worse situation um in addition you wouldn't necessarily know whether you need this byte string wrapping or not so this this this is a non-starter that doesn't make sense um so we wanted to have a version of the document ready for the the deadline for this itf um but that threw a monkey wrench into that so we since have discussed this some more and came up with the idea that maybe we spend another tag which would be 55801 [Music] which is essentially works like five five eight zero zero so you prefix it uh to something uh but the the something that you prefix it doesn't need to be zero data um so this this would be almost but not entirely unlike a zebra uh sequence um this is this works with cbo decoders that can decode one item and then hand up the raw data for the rest of the input so for instance in the receiver implementation there's an interface called decode with rest which takes one item"
  },
  {
    "startTime": "00:10:01",
    "text": "off um data of binary data by string file and gives you the the decoded item plus the the rest of the data in undecoded form and this this is exactly the api that would be needed for this and yeah that happens to be a relatively common api i cannot guarantee it's everywhere but if you don't have that api just read the first 12 bytes and decode that so so that should uh do the job so with the addition of this we would be able to actually define file magic for all um content formats uh which i think is is desirable but it's a bit of a scope creep for for this document i must admit so um i think this is not a no-brainer but we we should think about that um so assuming that that we can reach consensus um to uh put this in the the job would be to actually put it in to um keep this non-sibo content performance thing with 55 801s and again the examples that i i made kind of assume that we already have that but it doesn't distinguish between sibo and non-zero so that was the problem so these examples would be kept but that changed to talk about 55801 and we would add a couple of examples that actually have a siebel content format using 55 799 and 55-800 so that would be dash 07 and then we would go for working with glass called with that so that's my plan"
  },
  {
    "startTime": "00:12:12",
    "text": "comments questions michael please um so i think that the 55801 is a good solution um and but i i did ask i don't know if we have this problem and so i would a little bit tend to unless someone really thinks we should do that i would tend towards let's not go there and just just stick with what we have i'm also concerned about the review content comments that will result in these things that are way beyond seabor so we have one comment in the chat that says 55801 um just to to to get a bit of a better view would we still have use cases for seabourn uh for num for uh content format numbers in all those three categories that is five five seven nine nine eight hundred and eighty one yeah can could we slim this uh is there any of those that is kind of um where we don't really have a full use case well if we didn't have a use case we shouldn't do it um so um yes i think that there are examples meaningful examples that can be put into the document and i think it's useful to have these examples because we are not now opening up the choice of the three different ways to do things and [Music] it certainly helps to explain when you use what"
  },
  {
    "startTime": "00:14:08",
    "text": "so just i'm taking taking my document shepard hat here the byte string version has been in there for the the dash 05 and dash 06 versions which was what the working group last call um covered so um i'd like just to point out that if we if we extend the scope here this will put the document through definitely through another working group last call and probably a bit of designing on the way there one thing that was pointed out in previous discussion that might help here is that many of the things this document kind of set out to do are already have already happened by early registrations which as i checked only affect the kind of the the parts unaffected by all this so that's not a reason not to do it it's just something that i'd like to put out and make people aware of um if there's any urgency on the rest of the document yeah just to give an example the the one example that that i would build for uh 55801 would use the content format 11 5 42 application slash vnd.oma.lwm2m plus dlv [Music] because that that's a weird format that where it really helps if you actually can identify it by a magic number"
  },
  {
    "startTime": "00:16:10",
    "text": "christian i think you your audio totally broke down now um um is this better now again yes okay um [Music] so i've heard a bit of um i've heard some positive um some positive input and some cautious input on going forward so i suggest that this can be explored in a dasher seven um and that the examples there will hopefully make the use case clear enough that we can go on with this thank you then next up is caution again with pact yeah so this is the slide ahead in july um so the the main issue is stable building um and um i think we need to not boil the ocean here but on the other hand have something that that has batteries included uh so i'll come to that in a minute uh maybe i use should use the fact that this points to chris zipp's records tag proposal for a quick intermission so i just sent some some additional comments to him on the mailing list and i think that that's a pretty good proposal and uh people if you um can um if you think you you have comments on that uh please send them to the list because i think that will be a pretty useful addition to our"
  },
  {
    "startTime": "00:18:01",
    "text": "library of tags so let's go to pact so pack really is three things it's a processing model uh which is in in contrast to to actual compression schemes based on in place usage of of the packed data items so you do reference chasing in the [Music] data you got then it's the registration of a number of tags and simple items that allow you to reference items so these are the the origins of those arrows that the processing model foresees and i think we we have a pretty good understanding where in the sibo basic data model we have the gaps where we can put these references in and finally and this is the part that isn't quite as stable as the rest the the table building and in particular the the nesting aspect uh where we may have more than one uh place in the the data item where something is added to the table i think we we now have a pretty good understanding of a push model or shift model depending on how you think about it where you essentially have a stack of tables and pushing something on the stack means that [Music] you get control over the lowest numbers in the various reference and various referral encodings encodings um and push the existing table entries up uh to higher numbers"
  },
  {
    "startTime": "00:20:00",
    "text": "so i think that that is now well understood if maybe not fully described so that that's probably a place where at least editorial work is needed and basically what i think we should be doing in the base document is um provide um the referrers of course um so we we have uh allocated tags and and simple items for sharing for adding prefixes and for adding suffixes we describe the pad table model including the push mechanism and we probably should describe this in a way that we can add future kinds of referrers for instance using the record or template proposals so the model is extensible but we only fill it in for the three kinds share prefix and suffix we add a basic table setup tag that is making use of the push model and pushes to the share prefix and suffix tables that that's pretty much already there it probably just has to be qualified as something that that is just one way to do things and then we provide a framework for defining more specific setup tags uh where um i think we we should foresee two kinds of setup takes but of course it it's always possible to define other texts that's just these are the two that i expect we will make a lot of use of one is an implicit reference so if an application protocol defines a dictionary um like we we did 20 years ago with the the sip encoding zip compression"
  },
  {
    "startTime": "00:22:02",
    "text": "dictionary there is an rfc that has the the bytes of the dictionary in it similar here you would write in the specification that that allocates this tag the actual table that would be pushed on to this push model for tables so the advantage of course is that you can have very very short setup tags if the application requires that and you you don't have to do complicated lookups it's really just a tag when you implement a specific application uh then you implement the tag for that as well and then you have your application specific dictionary included um so this this is kind of for standardized dictionaries where standardization doesn't necessarily mean going through isg but somebody makes the effort and writes a specification that then registers a tag and the other part of the framework should be hashed references so the the table said setup tag uh would include um a hash value and probably also a cosy algorithm identifier because the hash algorithm identifier to explain how the hashing is supposed supposed to be done hashing of course needs a specification for how the hash input actually should look like and that i think should be pretty obvious by by simply hashing the simple deterministic encoding of an equivalent basic table setup tag"
  },
  {
    "startTime": "00:24:03",
    "text": "um so we don't have to invent a lot of mechanism for this we have everything we just have to put it together in the right way and of course an implementation might just implement a number of those hashed references or it might have a way to actually get that attached reference somewhere um that's not really something that the the data format defines it just says if you have a hashed setup tag with this hash then insert it here so that's my plan for the base document and then we can of course go ahead and do [Music] circumfix and template and record and whatever kinds of packing we come up with comments just for for understanding the um records would then be a use case of of pact and whoever defines the records would set up the table to have these specific semantics is that the intention i don't know okay um i think the record proposal in in its standalone form uh as it is defined today maybe with a couple of tweaks that that i've identified memory that's actually viable so we wouldn't need to put it into the framework but maybe we want to so"
  },
  {
    "startTime": "00:26:00",
    "text": "i think that that depends a lot on on what applications this tag will be used thank you hank yeah hi uh thank you apparently this is hank um so unfortunately brandon cannot uh here with us today uh due to a time conflict but i want to highlight um that i think it would be really cool to use the uh now um finalizing suit manifest specification as an example for a siber pact i think that would be uh something we can start after this is uh moving out of the gate uh as because this will take some time but i think it is it would be an excellent uh exercise to to instantiate this uh in real life so can can you explain use as an example because that triggers some different neurons for me okay so i think that uh there is a lot of redundant references in in directives and and uh for example identify us for several things like classes or environments or software effectively in the suit manifest and my assumption is that and and brenton really works on trimming down every single bite and i think uh as the manifest is already pretty much compact uh i assume that the packed uh approach will still uh yield a significant reduction of size so so that is something i would like to just uh well uh um try out yeah i'm just wondering whether you want to use it as an example in the document no no no no so it would be the suit 2.0 or the"
  },
  {
    "startTime": "00:28:01",
    "text": "suit-packed manifest you know because we can't do this with the rear one if you delay this any more further somewhere that throws stones at me so so that that isn't possible but uh but immediately as this is stable and out i would like immediately do it with pact to be honest yeah okay one one interesting question of course would also be whether you can simply use suit as is plus peg as is and get anything useful out of that yeah that is that is part of the experiment so uh we have to uh find out so but again brandon and i will not be doing this this year to be honest but but but maybe around the next hackathon before the itf in in some hopefully actual location that would be nice okay so that maybe leads into to a general uh request for data items so if if you have any data items that are not entirely trivially and that would maybe benefit uh from sibo pact we might want to collect these data items uh in a repository so we understand what what sibo pack does to them and and of course also how how good different packer implementations would be because the packer implementation can have different qualities of implementation that there is no one way to pick things christian here brief question on packer implementations do you expect these to be widely used because my impression was that the"
  },
  {
    "startTime": "00:30:00",
    "text": "that most of the most of the time packing would be done in a more static way so that the application would use its information on the structure already to create the tags do you think that kind of um free form compression is something that we need to expect in the um in applications that that is a good question so uh if you have a generic picker you probably should call them this way [Music] then you may save some time in your application actually doing these things but of course it requires to actually build the full structure and then submit it to the packer so it it's not something you would do in a constrained implementation in a constrained limitation you would always generate a sibo pact right from the data that you have so yes i see some some areas where generic packers might be useful and that's why i think it's a good idea to collect some some best practices for building them but also the [Music] how do you say that packing friendly sibo encoder apis might also be an interesting subject of doing hacking work yeah just about quick question because i have no gut feeling for this uh how easy or effective would be an auto pack feature in contrast to a manual manually uh i'm going to say configured packing of"
  },
  {
    "startTime": "00:32:02",
    "text": "content where you will maybe guide that a little bit should be this almost the same in the end well that depends on how much machine learning and and ai you put into your packer okay but generally writing compressors is is a a pretty well understood area of work so i would expect that if you write a generic packer that will often be as good as your manual packing scheme is and it will also find some opportunities for packing that you simply didn't address in your manual in fact it might be better maybe not compared to brandon but but in general yes good on the queue so let's go on i don't think that there are there are prepared slides for the for the um for the edn is there something that that you'd like to see there or um shall we keep that for for basically last um for the aop section and so let's do it now um so we had some some uh positive feedback during the interim um we haven't implemented that yet which always makes me a little bit hesitant of of going for something like a working glass troll hi barry but we might go for adoption that that certainly would be possible at this stage"
  },
  {
    "startTime": "00:34:12",
    "text": "um so maybe just a brief um show of hands around around the room given that we have um almost 20 participants um could you please indicate uh using the uh show of hands tool whether you have um well whether you're interested in that document in in for working the working group or well i just have to find the right but i take this as kind of a preliminary show of interest in the in the document this is not on its own an option call that will be later on the mailing list but this is just a brief um brief thing to to guard the interest in the room and i see a lot of hands going up going up here so um um in the minutes please note that this is um even within the short um within a short um show of hands uh showing 7 out of 20 uh raised and none not raised so to me this shows that there is interest in the working group and i think i'll um we can handle the rest of the failing list thank you next item please okay so let's go to city 2.0 um we have talked about that in the in the last uh full itf meeting 111 and i gave some some hints for how this and that particular piece of it might look like and what i want to do today is maybe"
  },
  {
    "startTime": "00:36:01",
    "text": "give a little bit more structured uh overview over where i think cda 2.0 should go and well we have done a few low hanging fruit in the cdi control specification which gives us a few things that that already good on the range 2.0 but there of course we only could do things that didn't actually require changing cddl we just used its extension points and what i'm describing now really is going beyond using extension points and to me it seems that there are two aspects that are also low hanging fruit but low hanging on the way of actually extending the language and one is annotation and the other one is composition so let me talk about those starting with composition so right now cddl works with a single file i mean we don't even talk about files because there is no file structure so there's no reason to talk about files but in practice you have a single cdl file maybe you concatenate that together out of several input files but essentially the thing is a sequence of rules and the first rule which must be a type and not a group is the entry point so at that service value the whole cdda file defines one data type and this this has been quite useful but uh we probably want to go beyond that and i think what i'm here most is that we actually want to build libraries"
  },
  {
    "startTime": "00:38:00",
    "text": "uh which are ctdl files that export one or more rules well typically types but might be groups as well and we also want to be able to import those rules from another city specification whether that was intended as a library or it's a standalone cdl specification doesn't make a big difference so we want to have an export interface and an import interface and to to be able to do this it probably makes sense to actually be able to name the library um so when you do an import you you have something you can talk about what you are importing and you also want to control the naming of the exported or imported rule so an existing city aspect might want to export something but maybe it has a very short name in in that spec and there are reasons why you don't want to change it i come to those reasons and you want to export it under a more useful name or when you import something that something may have a very short name in its context but in the context where you are pulling it into that short name is misleading so if you import something that has the the rule name signature and you have a specification that has three different kinds of signatures you don't want to call it signature you will want to call it full signature if it's coming from the full specification so there is some manage management of names uh needed so i have shown a simple way of doing implicit importing so we might have a convention that causes a tool to actually"
  },
  {
    "startTime": "00:40:02",
    "text": "find a library and then reference things from there so rfc 1990.oid might be something that that at some point every cdl tool will understand so you don't have to to do lots of things to actually get it and if you actually need a short name you can simply write another rule and say oid equals rfc1990.id and um then you will have a short name for for this thing so the implicit mechanism would be an easy way to do things without completely leaving the cdl 1.0 um envelope but of course the tool has to support doing doing this lookup and the the more powerful explicit import would identify a library maybe identify a versioned sequence using a semantic versioning reference so that that's a very popular subject and i think the young people have been discussing this for about two years now so maybe we can actually steal something from them and then when you have identified the library you want to manage what names are introduced i talked about name management potential conflicts and so on so this will be the explicit uh import interface i'm not putting an example in here because i come to the syntax in a few slides so the export interface would provide a way to name the library so you don't just have an anonymous city a file but the cda file itself says under which name it expects to be imported um gives the version number probably"
  },
  {
    "startTime": "00:42:01",
    "text": "semantic version number and you probably also want to identify the rule names that this library intends to export so this is not not a required list for the importer it's just the default set so if you just import the library without saying anything else you get this this exported word set but you can import less and you also can import more so we are not not trying to do protection of uh class internals here uh i mean if if you do that then you know that you are doing something on your own so if the next version actually changes the name of a rule then you have a little problem but in particular during development of things that that may be a much too useful thing to leave out so um the the question of course is how do we do the linkage so somewhere on my laptop that there is a cdfi that says it exports foo and somebody else somewhere else there is a city aspect that says an imports foo but how do the these two files actually meet each other and one way of course is doing this outside the specification language so you essentially give some cli parameters that tell the tool that these specifications files are going to be used as the library files going into that other specifications so that that's certainly one way to do it and that that's again useful during development when the specification has become more established uh and maybe even standardized"
  },
  {
    "startTime": "00:44:02",
    "text": "it should be possible to to give a hint inside the spec for instance a ui that points to a github repository or something so you you don't have to repeat all that information in every call of a cdl tool so i don't have a problem with hardwiring github in here just as long as we have other ways of referencing repositories as well um yeah name spacing um that's probably the best way to handle these these name conflict and bad naming uh issues so rfc 1990. already already shows the idea of a namespace so there is an rfc 1990 namespace from which we import the oid rule and while we are added we could maybe make the the one watch that the that ad610 has where we have a defined prelude that is always imported we could make this part of the model so you actually get control over that this is a little bit like c plus plus using namespace std um except that uh you don't um the default is to actually do that and you would have to do extra work to not do that and maybe we actually want to to think about some mechanisms that allows you to continue working when you have some some name spacing errors um in particular if if you work with revisions that might happen quite often so that's the namespacing"
  },
  {
    "startTime": "00:46:02",
    "text": "let's talk about alternatives um many people want to use the same cdi specification for different formats so for instance you have one specification that explains how to do cinema in json and another one how to do it in c bar and we know how to do this manually the centimeter specification defines it a manual way cta control gives an example of another manual way but we probably want to to make this a little bit more first class so we don't do this on the lexical level alone because that always makes it hard for implementations to actually process this so if we make the alternatives first class we might actually be able to define uh to write a tool that does translations between the two representations i mean if everything lines up properly so this would not be part of the specification but it would be an interesting implementation [Music] project so that's why i want to have alternatives be first class and not just be done on the lexical level like in the cinematic spec finally we should make this whole thing more accessible [Music] to automation it should be able to actually generate uh libraries um so you if you have an rfc that has some cdl in it and i think we now have a two-digit number of those um it should be possible to generate the libraries from those automatically and that should also be"
  },
  {
    "startTime": "00:48:00",
    "text": "possible for new ids so we probably want to establish a few conventions how you expose um ctdl uh in a draft we cannot define new conventions for rfcs but we can define them for for new draft we want to be able to generate libraries from iana registries there are several registries that are just very very useful uh think about interface types which you just want to be able to use um in a specification and of course the the what i'm saying here for for documents and registries is not just for itf sources but this should also be possible for non-itf sources so if there are interesting registries or interesting documents that we want to extract uh cdda uh from automatically uh that we should look at those and um yeah that should be possible from a cdl spec to trigger that automation not in the sense of uh we run a random operating system command that's always a bit uh dangerous but it should be possible to just point to an internet draft and say i'm i want to import the city data from there and put it in that namespace and that should be possible that's probably not the way you actually publish your specifications in the end um because well of course you would reference an rfc and no longer an id and so on um but it would be good to to make the language accessible for this kind of automation okay let's talk about syntax for a second the idea is to do this transition from 1.0 into 2.0 in a way that you won't notice that it happened so cdl files should still be"
  },
  {
    "startTime": "00:50:00",
    "text": "[Music] 2.0 files and cdi 1.0 processors should be able to do useful things with 2.0 files they won't be able to do everything that you can do with 2.0 files but it would be good if these processors can process 2.0 files and yeah there are several places where we can uh stash things into 1.0 syntax um yeah that's one way of doing it but this needs to be designed so i'm not sure how exactly it will look like but i showed some examples um at iit f111 okay so this is the syntax finally the other part that i think we should be doing in 2.0 is annotation um cddl has a processing model that can be described with kernighan's car which interestingly doesn't have a wikipedia entry so you will have to find it somewhere else um so you put in an instance and the model and the thing says yes or it says no and we have extended that with dot feature a little bit but that's still the the main processing model the cdl tool can do more it can annotate a tree with rule names so that's really useful but there is no control the spec writer has about that so is it important that the data item matches text or is it maybe more important that it matches a country so a lot of these rules are actually noise when you annotate trees and of course you want to be able to"
  },
  {
    "startTime": "00:52:00",
    "text": "put information into the specification that goes beyond full names and finally rule names are these things that don't have a relationship to real to the real world so maybe we should do something about that other validation languages have something called a post schema validation instance which is a term i would like to avoid but let's use it for now and the psvi actually uses the validation process to augment the data with for instance with annotation information and possibly even to transform it so filling in default values constructing data from data that has been passed and so on this is all things that can be done in a psvi we don't want to reinvent xsrt so the transforming mechanism will be limited but yeah something maybe is useful here the interesting question is what is the data models for that and it's probably useful to be able to put attributes on on any data item and maybe even to have some richer types maybe even things like application specific edn so we would need to think about representations in various forms and particularly in civil diagnostic notation so for annotation i think the the minimum variable product is uh to be able to put attributes on rule names so you can select which actually rituals actively annotate and maybe associate rule names with some real world concept the ui thing i talked about you might have special description attributes that you just extract out of comments some additional spec writer defined"
  },
  {
    "startTime": "00:54:01",
    "text": "attributes so for instance a unit could be added to something and yeah you could even generate tags tags that are not on the wire because the schema implies them and this already can be in many cases can be taken from the unwrapped information so i if i have a tilde time somewhere i know that that number is a tag one uh time okay and final slide how quickly you should be able to be able to do this again i think this is low-hanging fruit so my objective is to have a prototype and a written up spec by the end of the year for composition and probably for first elements of annotation but that probably requires some more playing around with with actual applications and my objective is to have a complete spec at iitf 113 and well then we can decide whether we are done or want to split this document and publish parts of it and publish other parts later after some more experience but i think we can only discuss this at itf comments questions hank hello hank please unmute yourself no i'm i'm muted i'm just being polite i guess okay so maybe my mic did not move okay yeah so this is saying uh obviously i'm a strong as a part of this we encountered several pain points without a strict composition feature this also includes how we define code points in over maps"
  },
  {
    "startTime": "00:56:03",
    "text": "like are there global for a document or are they uh specific to certain subsets of a single cta sorry i'm saying document here but what i mean is they see the data definition and uh so so yeah this this really uh so we have a lot of ideas how this works uh and i hope uh some of them we can find consensus on in this document that would be really really great especially because i do not think that these documents will come to a working group last call before itf-113 so if this timeline is realistic that would be awesome because then we can incorporate it already and so uh so yeah i i'd say i would even go so far in splitting out more time to do this and i'm in full support of that part um on the annotation part uh unfortunately again brenton is not here i think he has some uh really really constructive views on this and so maybe in the next instagram uh we can read him in and and elaborate on that a little bit yeah we might also run a design game meeting if we want yeah sure that is yeah that is even better if we uh have a higher frequency on on that and then we can use the interim to uh discuss uh uh major uh turning points or something like singularities or something yeah i just wanted to to bring that up to um so design this is a this is an ambitious timeline um if if this is to work i think this will need design team meetings in addition to the interims um the my roth plan would be to start interims"
  },
  {
    "startTime": "00:58:00",
    "text": "again in around december 15th in in our regular schedule but even with these and the holidays in between um this this will a lot of work by by the authors um speaking of which um hank would um hank and carson would you would you collaborate on this document or do you have um are there other interested parties that have shown up so far that would that would volunteer to work on this too i mean it's not a working group item yet so it's technically speaking it's still up to you carson um anticipating yeah i expect that that i will write something like a seed document and then people will come in and and contribute and at some point we decide their co-authors um so i i didn't even think about that yet but i know that hank has been uh pinging me whether i'm going to do everything about this for a while so i knew that tank was going to contribute and brendon of course would make an awesome contributor or co-author anybody else who has this opinion on this wants to write text or code as a as a user of cbor um i not sure i will write much text or code but i'm quite looking forward to the annotation features and especially curious whether this um this work might allow later to not only um very um to use the to use the validation uh to extend annotation in such a way that you can also verify whether your cdl allows"
  },
  {
    "startTime": "01:00:00",
    "text": "unambiguous annotation because right now validation is always unambiguous but many cdl documents out there do not allow unambiguous annotation and if if the annotation extensions facilitate i'm gonna be um checking this i would appreciate this a lot great bank again yeah again thank you thank you um so um [Music] i haven't brought this up yet because that is kind of there's not nothing really tangible yet so uh take this with a grain of salt but i think that some [Music] supporters and they are rallying fast at the moment due to some other things like in the cozy realm a cdd ida might manifest are these requirements for it that is close coming closer to the annotation part so an idea might not uh so so the messages for the input open for rpcs basically make up like a i don't know majority portion of all of that so there might be again external syntax that can glue that together and and and that might make use of some of the annotation parts so i'm just highlighting this because this is just all i don't know a pipe dream today but it might manifest faster than one things in the next months and so why is this interesting uh because there might be offers on that from that pool of interested people but i could not name a single one today with any reliability so the um i was in the skim meeting two hours ago and"
  },
  {
    "startTime": "01:02:00",
    "text": "that would be a nice benchmark for doing something like that as cim um barry is uh co-chair for that so maybe he's now in fight-or-flight mode uh that that we might want to contribute something to that but we can use it as a benchmark and if it turns out to be useful we can still try to contribute to the standardization effort i have to highlight that the other project that is really interesting the ctdl is also called skim but it's a totally different skin it's the supply chain integrity model so maybe we should just start going for five letter yeah probably no like with the five-digit rfc numbers or rfd numbers or whatever we're gonna call them then okay um we are um already in overtime so i take any last comment if there is still one other than that thanks everyone for all your input as i mentioned interims are planned to resume in the same cadence that we had them in during the last its probably starting december 15th may we'll go out on that and also always also on um topics that topics that we just took a rough reading on here for example the interested in interest in edn um with that review on the mailing list thanks and have a nice rest of the itf goodbye thank you bye bye you"
  }
]
