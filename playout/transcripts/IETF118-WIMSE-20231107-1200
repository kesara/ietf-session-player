[
  {
    "startTime": "00:00:17",
    "text": "Alright. Let's start some time for a change. So good afternoon, everybody. I hope you're enjoying your IETF week. And this is a Wednesday parts of a feather meeting. And I can't Spell out Wednesday. We'll get to it. I'm here on with So. And, yeah, let's get going. So And, of course, thank you to the scribes, to the volunteer scribes, please, note the note, well, it applies to this meeting, just like any other meeting, get the IETF both, IP related, issues are covered as well as, anti harassment And, code of conduct, So Please review it carefully. The agenda for today is quite heavy. We have a large number of topics to cover there will probably not be time for questions or maybe just a little bit. And we will be very, serious about the timekeeping. So please have that in mind, especially if you're presenting we will start with introductory material then we will talk about some proposed deliverables, for the working group if one is formed,"
  },
  {
    "startTime": "00:02:02",
    "text": "and we will end with a large chunk of a open discussion. Including, of course, above questions. As a reminder to everybody, we are having a meeting tomorrow at 10 o'clock in calling calling for wherever the allies Alright. So where are we? We actually have a nice, acronym Stan it stands for workload identity in multi them environments, But Wednesday is so much nicer. Thank you to the proponents for coming up with a great acronym. And the mailing list. We have a mailing list. A mailing list has been quite active, please keep it active. If we want to actually create, running activity from this it will happen on the mailing list, mainly on the mailing list. Today is a nonworking group forming off. It is not a goal today to decide on whether this community here. Would like to form a working group. However, we will be asking some questions to gauge the filling of the room, to understand whether we believe this is an activity that the IETF should take on And, of course, even if this is a non working group forming boss, it doesn't mean that we need to have a second buff. We might have a second buff in Brisbane. Or else we might move forward even all the way to creating an actual working group in between, the IETF meetings. And with that,"
  },
  {
    "startTime": "00:04:05",
    "text": "just just one note, please sign in with the online attendance tool so that we can, mark your attendance in. So you can join the queue, participate in the discussion. Stole Yeah. It's just one Yes. But it's not I think we need it to Yeah. So what while I'm waiting for control, I'm, I'm Peter Castleman private identity, enthusiast, may maybe a little bit of context for why we're here. One of the challenges that we see, happening right now with our customers and in the industry is that a very large number customers are running their workloads in multiple clouds, multiple, service environments and they'd really have no good ways to reason over the identities and to protect those, workloads or deploy 0 trust architectures, and so you end up in a situation where you have to learn multiple identity systems And that internston turns into this sort of big challenge around, you know, not having the right skill set and not being able to really pure everything. So that's kind of the the background for why this work is interesting to us and why, we've been bringing this uh-uh, to the IITF. Maybe a run. You can just sort of forward to the next slide if you can't give me control. It's still working. I'm not okay. So when we think about workload identities, or identity in general,"
  },
  {
    "startTime": "00:06:02",
    "text": "you kind of need standards for lots of things. Right? We need standards for identifiers, credential formats, how you were gonna do at a station, see if it's management. We need standard around how we provision, what our provisioning mechanisms are, authenticate, authorize, how we federate across multiple, across domains, right, And then finally, things like monitoring and remediation, right, if something goes wrong with the workload, we need to know which workload and which machine and we need to be able to go and intervene. For all of that, we also end up needing, things like policy and configuration for each of them. And then finally, you need to be able to prove compliance against, your your definitions. So really need sort of a set of standards to deal with all of this so that we can manage our workload identity But the good news, if we go to the next slide, Yes. So that's control. I have control now. No. Pablo Chase. Okay. Next slide. Next slide. Should I have control now? Not yet. Okay. So, The good news is, of course, we're not starting from scratch. There's already plenty of standards in this area. That we can leverage. Specifically standards are not only standards, but also let's call them community project. That's developed in places like the cloud native compute foundation. Something like spiffy, the secure production identifier framework for everyone, it's actually set of ticks a bunch of boxes, right, from identifiers to credential formats, at a station, mechanisms, provisioning, up to federation, And, and then there's, of course, all the work that we've been doing in the idea for around things like MTLS, and various OAuth, standards for authentication and authorization."
  },
  {
    "startTime": "00:08:04",
    "text": "There's also, you know, work happening in terms of policy languages, and work with the OpenID Foundation shared signals framework specifically as a mechanism for us to to sort of disseminate information about, security events. And then, of course, there's work with skin and teeth and rats, all of these relevant that help us solve these problems and I am told I am now in control the power. And there's actually even new work coming to the 4. Right? So things like cedar is another new policy language that has some wonderful property terms of verifiability and provable security, and, I think We sort of have a lot of work happening in lots of places, but one of the challenges is a course. There is a gap. So I'm gonna try and talk very quickly about the sort of things that happen. So when we try and go end to end and we try and build this on standards, you know, you'd start with the resource owner, And that transaction, right, sort of If we look at that, there's sort of a set of work that's covered by OAuth. There's a set of work that's covered by fee, but there's also a bunch of challenges. Right? So for these workloads, these individual workloads passing requests around in side, a compute environment, things like request finding. How do we make sure that you reach original identity is retained in a secure way. How do we keep, I know how do we avoid challenges with client registration in the OAuth world for these workloads that need to sort of spin up connect to an old server, and and then sort of go away again. This is a bunch of Challenges around resiliency, latency, authorization, audit and compliance. Right? These are sort of gaps that that appear"
  },
  {
    "startTime": "00:10:01",
    "text": "There are standards for each of those things, but it's not always clear how you should use them. As you cross, between these sort of standards. So one thing that we've started looking at is how do we connect these different ecosystems Right? So how do we connect something like the work in spiffy with some of the OAuth work? How do we connect share signals framework back to spiffy? Rats and spiffy cedar and the OAuth Rara, specification, for example. So these are sort of places where we can potentially connect these things. But there are also gaps that are not necessarily as simple as just sort of getting a profile of one thing or another. And I think for that, I just wanna check if Evan is online. Hello. Good morning. Afternoon. So so as an example, one of the things that we discussed on the on the mailing list, is this idea for request binding And Evan, I you can tell me to just sort of move forward. Maybe you can describe a little bit about the kind of challenges where We sort of almost have all the pieces. But then doesn't quite fit. And so maybe I'll also let you introduce yourself and then maybe just walk us through that example. Yeah. Absolutely. Kevin Gilman. I work on the stuffy and Spire projects I've been working on this stuff. This is workload identity focused stuff, and been doing that for about 7 years now. If you wanna go to the next slide, I have an example here of there's a pretty vanilla jot that is kind of the typical shape that you'd see in use workload to workload security. This is like super broad strokes you know, a little bit handwavy, but there's a couple differences here from, you know, traditional OAuth centric dot use. The first one is that it's usually pretty tight expiration. This is because of the replay nature of things. They can pop them off, put them onto other requests and stuff like that. It's kind of"
  },
  {
    "startTime": "00:12:00",
    "text": "not my favorite thing in the world, but, Jot is the closest thing we have to interoperable token for worklet identity off services This is what is typically used. Spiffy uses jot in this way. Other other mechanisms, like, and and Kubernetes, projected service comp tokens use similar some So there are these kind of, like, any drops, if you will, there's usually an audience and it's an identifier of some other workload you're calling subject as the identifier holder of that token. And sometimes you'll see an issuer set there there are some kind of ways to get rough OIDC compat with these token validations it's not required. Sometimes you you distribute the validation keys through other mechanisms, but it it is one one way that it can't be done. And so been a lot of pains in dealing with these tokens. You know, how do you, like, so you usually have to be minted centrally And when they have a short expiry that has some, implications on availability, form and some things like that. And, the biggest problem I I, is really just kind of the security around the states as I mentioned before. Spare took in them. So that's why we kind of keep the TTL so short, the the the expiry so short. And we've been looking for ways to mitigate this if at all possible, you know, audio is an expiry two best things that we have that we can kind of come on top of the existing specs with. If you go to the next slide, so when depop was being worked on and I got wind of it. I was pretty excited because I thought this is a really great pattern that we can use to kind of patch up this gap that we have in and the replayability of of of of jot in service service. Off. And so, I started talking with some folks in the community, you know, started taking closer look and thinking okay, you know, how how can we take this and apply it to workload to workload security. And the more that I looked there, the more I kind of realized that it it will be pretty difficult to use the spec as is"
  },
  {
    "startTime": "00:14:00",
    "text": "if you go to the next slide, please. There there were a few things that jumped out at me The first thing, which is not really a blocker, but was kind of a curiosity was the placement of the AWK and the proof itself. I know they're they're pretty good reasons for doing this and and oh off, but in in these cases, it felt way more natural to just JWK in the workload jot right, as a CNF claim, for example. That that that is is, you know, getting kind of closer to X509 certificate. Right? But it was it felt very strange to have to, like, have the validation key in the proof of the thing that is actually signed rather than having the key attached to the identity bound to the identity so that was a little bit of like an ergonomic thing, but certainly, you know, in in the sake of reusing standards can kind of look the other way on that. And then the the the the more I looked, the more I went down, the the kind of more difficult the problems got. You know, I guess there's this access token hash is in the same vein as the JWK doesn't doesn't quite make a lot of sense and work the identity world. And then the final nail on the coffin was this HTML you claim, which is used to bind, the Depot prove to an HTTP request. And that is kind of like exactly the the behavior that we're looking for, but These particular claims are required by the depop library. By the DeepOps back rather. And the whole DeepOps back is, like, very CTB centric. And and it gets us quite a ways it doesn't get us all the way. There's lots of other things we we need to secure, like, GRPC, which doesn't really conform to these things. Cough cup pubsub, things of this nature. And so what we really need is something that's a little bit more flexible able to kind of choose bindings depending on the protocol and and request response patterns that that you're using. That the pop spec requires these to be set."
  },
  {
    "startTime": "00:16:01",
    "text": "Can set them. You could maybe set them to some garbage thing or none or something along these lines. Noel doesn't work too well with across, like, various libraries and things like that. So to interrupt, but we're we're a timer. So Okay. Sure. That that's that's basically, I I took a look at some libraries how to use these things or they're they're it's very difficult. So the question is really like do we abuse this spec? Try to make it work in our way. Or do we write a new thing? Now if we write a new thing, where do we do that Thank you, Evan. A very quick question about the slide 2 where you were showing the whole spectrum of all the standards and everything I am just curious where does this come from, and is there a pattern starting from the bottom to the off, is there a connection between the things that you show on slide 2, or is it just randomly just you just placed all the blocks? Oh, no. So I went through a process, for looking at all the standards that we can find that can help solve parts of the problems that we see with upload. So that is not a random selection. That's kind of a think of it as a curated selection. And I am fully willing to accept that it's not complete. Just to clarify, not about the standards, the diagram that we showed which goes from the identity up to the Oh. Oh, the Oh, that's right. Authorization and on? Is it Is there some pattern, or is it just randomly? No. Again, it there is a pattern. Right? It sort of builds from the bottom. You start with an idea to fire on top of that, you have a credential, format, then you need start thinking about how you're gonna do it at a station provisioning and so on. So that the shape and the sequence does matter. Okay. Alright. Thanks. Thank you. You have it. Ah, okay."
  },
  {
    "startTime": "00:18:00",
    "text": "Yes. I have buttons. Alright. Hi, everybody. I'm Justin Richard, and, Peter, I don't go too far. You're in this one too. We're, we're here talk about some, workload identity use cases. So, Really fundamentally, I I wanna start with this question of, you know, what is a workload begin with, begin with, begin with, begin with, and a workload is really, we can define this as a single piece of software. That that does a specific purpose. Know, it's not just software in general, something that is designed to do a specific purpose. Fulfill some specific need. But the thing is that may consist of a lot of running copies of that same software in order to fulfill that need. And, each of those copies of the software fulfills the same task. And that's the whole idea behind, you know, workloads in these data centers that allow us to do the kinds of scaling that we can do today. So what's identity got to do with any of this? Well, it turns out you need identity in a lot of places. Let's say we've got 3 different cloud services, 3 different, things. And, we wanna be able to, identify each of those. So we know what each of those pieces of software is supposed to be doing. You know, a workload is defined by what it's supposed to be doing. So we want to be able to differentiate there. Spiffy, and technologies like it allow us to give identities and keys and at stores and stuff to these workloads, and it solves, part of the problem. But it, it Actually raises a lot of questions. So with things like smithy, we can have the services call each and we and they know that they're calling each other, and we can do binding to MTLS and stuff like that, and we can do binding to JOTS. Like, Evan was talking about, even though that's a little little iffy at times. But the thing is, like, that doesn't answer the whole set of questions. In protocols like OAuth, we abstract the entire workload concept. This whole, like, series of different things calling each other, we abstract that into something we call the resource server."
  },
  {
    "startTime": "00:20:00",
    "text": "And the resource server is just a functional role that a client software calls, and it goes and gets the things. Now that abstraction is really help because it allows us to have resource owners, that talk the resource servers. And however, that gets fulfilled, the client software and the authorization server, none of that generally need to know anything. But the truth thing is once we get down to the level of actually having to implement anything, get all the way down to that leaf node inside this chain of services. Gonna have a lot of questions to ask. Who is the resource owner that said that this was okay? Did the correct chain of other pieces of software get called before this request got to me. You know, did this request come from an authorization server that I might not have any direct insight into. And if so, how do I know about that? And how do I even to reason about that. And so this raises a lot of questions, like, you're you're gonna see copies of this diagram a bunch of times today. When, Peter did the overlay of, you know, the OAuth happens kind of in the, in the corner here. And fifty kind of happens inside that light orange box? How do we cross that boundary and reason about that in a way that actually makes sense. Let alone a way that is interoperable because the world just keeps getting weirder from here. Because any of those nodes can go off and call a whole other set of, workloads in order to fulfill it job. And this is where the multi system, multi cloud environment really starts to come into play. Because one of those notes can go off and, we get all the way down to that second leaf node in the green there, and It's gonna have a whole stack of questions that it needs to answer. That might need to know that the proper chain was followed in some other cloud before it got all the way down to me. And how do we how do we convey that information? How do we start talking about that? And, of course, this gets weird or still when you realize that all of these external services"
  },
  {
    "startTime": "00:22:00",
    "text": "that our functional roles that we've abstracted probably have their own internal state and systems as well that, sometimes we care about. Sometimes we don't. Or you can go use mine. So we've put together a, a use case document, which you can scan here. And, Peter is, gonna go through some of those now. So I'll talk through a set of use cases that we can that we, wrote up over the last couple of months. I I want to, encourage folks to please go read it, scan the QR code if you're brave enough. And, so let's talk about those. Right? So I think first, when we look at sort of this constrained credential security. What we really mean by that is how do we prevent token replay when these workloads are presenting their identities the jobs, that Evan described to one another, right, when it is compromised, how do we prevent reuse? Right? So that is monitoring and remediation, and then how do we do this so that we can use a similar credentials. And how do we do that in a standardized way? That'll work in all the different compute environments that our customers are using. Then there's sort of this idea of cross workload access. So how do we avoid, so in OAuth today, there's this concept for client registration, but you can each of them individually can be very problematic, or, you know, it's just difficult to manage. When I ask different workloads from different service providers and, also, in different cloud providers. Right? So it sort of starts spanning more and more environments. And we need to do that in a in a standardized way. I see someone on the bike. Should we are we okay to stop Yeah. Or do we want to leave that for later? You can quote clarifying question. Yeah. Yeah. Hi, Erica Scralla."
  },
  {
    "startTime": "00:24:01",
    "text": "So can you just scroll back couple slides because I actually got a a discussion before Yeah. One more. Yeah. There. Can you explain to me what the threat slash trash bottle is here, namely how much do these boxes stretch each other? That's a great question. Thanks. certainly there it is, sir. Is that okay? The Oh, the we there is not a universal land that question. And and that's one of the reasons that I think that we need to be able to, have a language to be able to reason about these kinds of things. Sometimes, you know, and a lot of deployments today, you get, the leaf nodes will be completely trusting the gateway. And as long as it went through the gateway, they don't care anything else that happened. Sometimes that's not the case. And, especially when you get into this multi cloud environment, you need to know, you know, some sort of transit things have happened before it gets. Well, I I get well, that's actually what I what I'm just trying to push on a little bit is like Sierry said, well, you know, you know, do I if I'm, like, down at quux, right, do I know this went through food bar, gateway, buzz, and whatever, right, And, like, it's one thing if I'm trusting BaaS to assert in a way through gateway and gateway to serve the bar. That's quite another if Kwoks has to be able to verify. Thing will hang all the way from the user. And so I'm trying to understand the scope of the problem. I, to me, those are both valid ways to try to answer the question. And so figuring out what the scope of what a potential group would want to answer is is part of the reason we're here. Thank you. Thanks. K. K. Ron, I noticed we're sort of out of time. Do we we proceed, or do you want to just have folks continue. Do we have time left on the for a at the 10 minute mark for this presentation. If you need 2 more minutes to to complete the presentation that Well, what I'm gonna do instead of sort of flipping through them, I'm just gonna talk about the use cases in general."
  },
  {
    "startTime": "00:26:00",
    "text": "Another one is the strain of custody of requests So knowing, I think building on this earlier question, knowing who had access to or who was in the path of this, set of requests Also, how do I make localized authentication and authorization decisions because we have these requirements around low latency and, high resiliency. Right? So we need to try and make these decisions as local as possible, but that comes with, you know, changes the trust model. Set up requirements around audit logs, right, when we operate in disconnected ways, How do we reconcile those logs? Right? What is the process? For a workload that's been disconnected from its control plane for 20 72 hours. How does that workload? And, you know, rational how do you rationalize those audit logs? How do you bring them back together? And I think we talked about authorization and specific this need to do it locally. And then a set of general requirements is described in this document around observability, and manageability etcetera. Right? So, again, I'd encourage folks to go read the use cases I'm happy to talk more about them, but that should give another framing of the set of problems we're hoping to solve here. Alright. So, Evan, you're up with, spiffy. Hey, folks. Evan Gilman again. I was asked to do quick intro to snappy here just because I know it's kind of the term has been popping up a little bit. So what I'd like to do is just just share a really, really quick kind of tour with you just quick explain our set some context here to the next slide, please. So spiffy is a work of identity spec. It lives in the cloud native computing foundation. It's fairly widely adopted for some measure of widely runs on 1,000,000 machines worldwide, millions of machines worldwide,"
  },
  {
    "startTime": "00:28:01",
    "text": "one interesting thing about it is authorizations out of scope we don't purely with identity and authentication and software service, software service. There's a handful of things that, it seeks to solve in that area. First is, you know, basic identifiers. How do you identify a workload reason about that? How do you credential them with those identities. How do you issue those credentials a platform agnostic way. And finally, how do you federate between different domains of trust. We go to the next slide. This is what's called a spiffy ID. So this is the identifier portion. So US is structured as a URI, and the host component here is what called the trust domain name. That's that's kind of your issuer equivalent. Everything that comes after that is is the identity of a workload that lives within that Trust domain, if you will. Go to the next slide. And then, we credential workloads that this scheme essentially by defining profiles over existing document types. 50 doesn't really invent new even types would rather. We we reuse document types that have been defined elsewhere and are generally in wide use. So specialty supports today, X509 and Jot, the specs are set up in a way where we can support additional documents in the future as they become available. This is just kind of a handful of the of the constraints that that we place on them. We place these constraints, you know, number 1 for interop, but also number 2 because some of these things have questionable security properties as I was mentioning earlier on the the drought is. You go next slide, please. I should probably just ask a quick clarifying question in that last slide. Just wondering if the those 2 are alternatives or if they're composed in some way. They they're you can use them either or, they're not don't go together. See people use them together frequently. We'll do like an MTLS channel and then, and then that goes kind of hop to hop and then over the top a jot is attached to the request. As a common pattern, but you don't there there's nothing in the spec that talks about explicitly using them. Together. Got it. Thank you."
  },
  {
    "startTime": "00:30:03",
    "text": "So the next thing that that Spafida finds platform agnostic issues. This platform agnostic bits are really important a lot of ident existing identity system, for example, cloud I'm systems, even Kubernetes are kind of a domain specific when you cross those domains, those those assumptions fall apart so Stevie has this platform agnostic issuance. So he'd defined something called a workload API. And it's, effectively a node local API that is on indicated. So when workload comes to life, that attaches to this workload API and then the spiffy implementation serving that workload API, quote attests the identity of of the workload. Sometimes there's a 2 step process where an agent works to attest the identity of the node, the agent turns around and then test the identity of the workload interrogating various subsystems. And, the the end result of this is a workload is given certain a key or a workload can ask for anything it wants. But the implementation determines the identity of the and and issues to short lived, credential and response on the next slide, please. And then finally, Sophia supports federation, it does this by basically grouping the keys up into a JWKS document. We set a use field to kinda define what flavor of of credential is is the one that the key represents. So as you can see here, we package up both X509 CA's and and drop sign keys into one document. And doing this, we can do MTLS across trust boundaries things along those lines. So if he also defines OIDC like mechanism for fetching and distributing these these bundles. And then finally, there's this component we what we call split the off. Which involves, okay, well, how how do you authenticate these credentials that first involves plucking out the spiffy ID. Examining the trust domain that it was signed by and then consulting a list that you've been distributed of various trust bundles and the trust domains that they map to."
  },
  {
    "startTime": "00:32:01",
    "text": "So why am I here? Spiffy already has a place to live it it's quite happy where it is. It's just not request to move it or anything along those lines. But, there's a lot of related cases that, and, gaps in the ecosystem that are very closely related to spiffy but but not quite in scope for Sophia and I mentioned, but first, if he doesn't invent document types, so when we talk about trying to solve problems, which involve new cents. This is kind of a little bit uncomfortable for our community token situation, in particular, is quite difficult with security availability and performance requirements we have and, you know, state of the kind of open open ended state of of drops back. Something like Deepak would be great. So there's a lot of existing works across various standards, bodies that that we want to leverage. Know, I think historically, we we've kind of done our poor job at at talking across those boundaries specifically in the context of workload to workflow security. And so here to start that conversation and engage with y'all. That's all I have for today I know there were some, Does anybody wanna come? There's some talking, the chat anybody wanna bring any of those to the Mike or I'm not familiar with the SFC use case that was mentioned in trial. Eric. I guess I'm just trying to figure out how's all fits together. May may maybe maybe I'm just not very not following very well, but, like, a lot of different pieces of work that are being discussed here, and it'd be helpful to map of, like, how Oh, then then I look forward to your presentation. I was Thanks, Hector."
  },
  {
    "startTime": "00:34:03",
    "text": "I'm I'm I'm toast, yeah, quickly updated the slides to address all your comments that you didn't give me. Ask So of my appendix, then I put a document to get in contribution to the to the path to look at one specific aspect as a sort of a kick start on on what type of standardization work would you actually would be doing. So you see what the the document name is next slide. So, Justin conveniently provided already a introduction to what workloads are And he also explained on, like, why they need to talk to each other and, well, at least that's is a common case that these different workloads require some form of communication and authorization So it's we're talking about the distributed system here. And Those workloads like use REST APIs and for all of you who are familiar with OAS you know, like, we have these regular OS communication, and these clients, OS clients need to be provisioned with secrets and his workloads while the code is generic, They need to have configuration and credentials that are unique to an instance And in Oz, we have a couple of different ways to do this. Client ID and client secret is one of them. But it turns out, not a good way to do that in this context with a high net highly dynamic context where we want to rotate the secrets. We want to have them the lifetime pound is is Evan just mentioned So we want to have something better. Next slide. And so How could we use that data, namely some other credential types in OAS in quite conveniently, many of these container technologies that manage these workloads like Kubernetes or or also darker, they come with a control plane as they call it"
  },
  {
    "startTime": "00:36:03",
    "text": "essentially protocols to start and stop and maintain these workload and also provision them. And that's where the JWT comes into the picture. Next slide. So when you look at these Kubernetes and Docker documents then you will realize one thing at least from And I did, as an IETF person, Like, there are lots of new terms. Like, these people just invent new things out of thin air. Into slight, hear says, like, this is not a term I came up with This is literally what these guys use. Like, this is the name for a token. Can you imagine service account volume projection. I don't know what that means, but it's a a JWT. Which is configured to a workload. So it that makes those documents hard to read and they are not, the security properties are not well planes. Like, even writing that thing down in IETF language, and, like, how Oasis used in those context would already be of tremendous help for the community to reason about the security properties. That alone would be enough for me. But in this document, we went one step further by actually looking at, some of those configurations, then they conveniently use ROCs that we worked on in the OS working group. So you would think like chop down pretty much Not quite. Next slide. Because they're issues. So here is this is a simplified drawing on how Kubernetes and and some container technologies use this whole dance The blue one is sort of what happens outside the workload. And basically there's some interaction going on between the contrablaine and the agent that sits on on different physical hosts and they these agents are then responsible for starting the workloads and configuring, credentials as they start them."
  },
  {
    "startTime": "00:38:00",
    "text": "So that the workload has some unique instance properties. And then they kick off the actual another sort of authorization server interaction to really talk to, whatever other workload and Justin talked about that a minute ago. And so so in some sense, a pretty simple model, And you would think if you take a JWT from and get it from the comp transfer plane. It gets down as this in this weird name of a token gets sent over to the workload and then you go from there. And he would work. But unfortunately not. Next slide Because they implement the so there's no specification on how you would actually do it. It's mostly just quote and some implementations to it that way and the other ones do it differently. And so if you take an authorization server, and plug it in there, it likely not going to work because they populate the fields differently you know, you can do a lot in a JWT. You can populate things, in one place and then in the other No problem at all but if you want to have some form of insubability, you need to pay attention to what you put because there are some checks executed And interestingly enough, people mix up the ROC that talks about, that, JWT client authentication with another profile of it in, OIDC. And then nothing works. And so that's what we in this first iteration of the document describe. We describe on how you need to populate the field so that you can have interoperable implementations. It's kind of simple from a for us coming from an from an OS working group, because we we obviously know what the fields mean and how you need to populate them But, the impact is quite nice because you can then use off the shelf software you can then, sort of benefit from the OS mechanism, which"
  },
  {
    "startTime": "00:40:00",
    "text": "allows you to easily rotate those tokens and then, do the authorization dense. That's the need even for that little document for which I see a justification for having a working group to discuss these type of things, And Evan just mentioned another one if you this one talks about paradoxons. He talked about proof of possession tokens If you add that on top of it, of course, it's more secure, more, but also more complex it requires more text. Next slide. Profile. This this is a profile best current practice. Take the existing stuff punch it together in the right way. And so I believe. There's value in providing that guidance on how to use some of those technologies. We work on For different use cases, in this context. And that's what we did with that document. Eka, did that somehow answer your question? Okay. Smart Okay. Marka, I believe you're online. Yeah. Hello, everyone. Oh, Romans in the queue. Roman, did you have a clarifying, Hi, Roman. Do you need no hats? So that was a great kind of presentation. Is there a way to cross walk that against the use cases we previously. So also, if we just did, the BCP use described, are any use cases taken off the list that that were there that were aired earlier"
  },
  {
    "startTime": "00:42:00",
    "text": "Okay. May I start? Yes. Okay. Thank you. So First, I I I went to to thank you everybody for the opportunity to be here, talk about the the work that we are doing since 2021 in SPF Assertions and tokens workgroup. My name is Marco. I'm PHA student at Ulsby, and This work has been developed together with other universities, HP, and and the spiffy community. And I will talk about the NASA token model that solve some of the exquisite problems that maybe others are not So, let's see how it fits everything, everything. Next, please. So I I think that's a good way to start here is to talk about the requirements and goals that bring us here. And we started, working on a way to have the centralizing mechanisms that allow any subject and workloads to create authenticated statements. And to do that, we develop that, a civil token scheme, that supports extension and incremental signing. Basically something that we cannot achieve, currently with job tokens, And the idea is to have ice cream that we can add some set of claims. But we need to keep in mind that these these tokens should be size sensitive, and we at least try to to make it cheap to sign and validate And, also, we want to to have support to different kind of identity documents and sold honors because we are not, we at least doesn't want to be tied to a central arnel coal coal authority, we need to do it offline if need to Next to please So the the model that we are working on our proof of concept"
  },
  {
    "startTime": "00:44:01",
    "text": "it's a token construction. Basically, we, we like to call this as a technology agnostic because we are not, working to to develop to a specific, technology. But in our proof of concept, We are focusing in a JSON based model. And this nested model have 3 parts. We have the payload containing the claims. We have the signature, of course, and we have an optional part of the token. That's the nested that can contain another token that we extend. And when we think about the claims here, We we are we try to keep as open as possible. So we do not define some, critical and mandatory claims just I feel that it's strictly necessary to run the the the scheme. But there is one one important kind of claim that we go further on the on the the description that are the identity claims, like insurance, for example, And in our scenario, in other model, we define with 3 different possible values So an identity can be a SPFIG, for example, a common name, could be a public key as a unit and fire or could be an entire dense document Of course, if you think about the next 509 or things like that, it's could be, something not reasonable to put inside a token and that's, important points that we are working on a specific use case for that. That I will show on that. Next, please. So, thinking about this token structure, what we have constricted until now is this kind of mastered the scheme where, as say the token can have. And as the token decided, in our proof of concept, we define some specific claims to the payload, to the payloads, but we can have any other according to the application needs. And as I say, we have something"
  },
  {
    "startTime": "00:46:01",
    "text": "like the agency claims. That have specific type of values. And again, we can have a token inside trucks, we can, achieve many of the, that use cases that we talked before, and we can construct very flexible tokens using it Next, please. Okay. And then we go step further and talk about the signature schemes that we can use in our, Nor token. We we are planning to implementing this 1st phase of the proof of concept to different modes. 1, we call ID mode because it's backed by a identity provider. Our scenario, we are using the Aspire environment to provide those identities. And this is Kim allows to identify the the signer of the of the token. And, also, these binds, an issuer to a unique audience So here, we cannot define more than one audience the idea here you will see is to create a link between them. And to easily track all the the hops that the token went through. And in the anonymous modes, otherwise, in other hands, we We don't care about the identification itself, but we need to grant the, the token, integrity And also, we are using some tricks, with cryptography, algorithms to aggregate the signatures and create smaller tokens. Next, please. So just a few details about the ID modes. So here, the audience has an important role in this, in this mode. Because this is responsible for linking each of the the signatures. Basically, if you take this flow here in the image, like ID 1, create token and send it to 82. ID 2 will be the audience"
  },
  {
    "startTime": "00:48:01",
    "text": "from that I do want to define it. And I do want sense the token and sends the it's certificate or it's a dense document together. And the validation consists in checking all the signatures checking, the identities and check the link between audience and the next issuer to for all this this token. Okay. Next. So here, just, simple example, imagine that we start with that green token. I do want to create that, and set ID 2 as the audience embedded some events document inside this the Ziffer claim and sign it, then ID 2 can extend it using its identity as the issuer and pointing to ID 3 and every hop in the in the flow can use this mechanism. And to validate this token, then we check all these links And we'll check all the signatures and then finally check the events. It documents off every hot. Hi. Yeah. Hi. Eric Straw. I guess I'm trying to understand what this proves. So By time, make it to 3, 3 knows. As far as I can tell, I mean, so I assume there's, like, that that the data has changed it between here as things are processed. Right? That is Yeah. We're not just running a 4 in the packets. We're like, like things are happening along the path. Right? Right. Okay. So like, what assertion can ID 3 confidently make? It seems to me he can make the assertion that some data passed between 1, 2, and 3 was transformed in an unspecified way And all I know is, like, there were some data that happened. Is there a stronger assertion that can make? Yeah. I think so. But what what assertion can it make? Right? Let me, like, let me, like, like, actually discuss, like, an actual kind of threat. Right? So I'd ID 1 is do a money transfer of, like, of, like, of, like, of, like, of, like, of, like, of, like, of, like, fifty bucks. Right? In the middle Okay."
  },
  {
    "startTime": "00:50:00",
    "text": "And and it's like that. It's like that's initial, like, initial JSON token is $50. But one of these guys has compromised changes it to $5,000,000. Is that detected? Yeah. But imagine so that ID 2 is compromised and then try to change the the token that I do want created. But it will should fail because first of all It doesn't change it doesn't hear the token. I'm saying that I'm saying there's other metadata being carried around Like, you're not just passing the packets. This is associated with, like, data, right? Yeah. Right. And so and so that transformation has to be checked. Yeah. But we are checking by validating the signatures and they didn't use it to create them. No. No. No. Okay. Maybe let me try again. So like the like, the the And so, I mean, like, he, I mean, I give you, like, a a really concrete example are trying to, at least, which is like, like, I thing comes in and it comes in in JSON, but has she translated to Seabor for someone later in the path. Right? And in the process of the seabor translation, I, like, changed the values too. How does that get detected? What I'm saying is the problem is the problem is, like, the consumer does not the consumer at the end of the chain, ID 3 does not consume the thing that started ID 1 consume some other transformed data on the left. To preclude. In these templates. And and logic is correct all on the path. I I don't know if I got exactly your question, but what I can say is that since we have an identity authority behind all those identities, use to sign it. If anyone tried to modify the token along the path, or it will be detected because it will need to generate a new signature to keep bit valid, and we will detect it through the wrong identity, use it to create a new signature or it will not be able to modify at all because it doesn't have access the original signature, original key to use the generate this. No, no, that's it. That's statement like photography, not a statement about, about, about, reality."
  },
  {
    "startTime": "00:52:04",
    "text": "It's not a statement about what that trust has been a cryptography. And if I get saying different, if I get 1 or 2 of being compromised, and misbehaving, which is the point of having the shit and shitisters. It's a deal with this misbehavior. I'm trying to understand how architects because as far as I can tell, what the text is on other property, which is a property about like which by a policy navy, Yeah. Okay. So I think there's a There's other work happening, but one of the aspects I think you're addressing is there are aspects of a transaction when it starts that should become immutable regardless of how many work loads it passes through. Right? And if you establish that transaction contact is immutable at the beginning. You know, through whatever that mechanism is, right, then as it passes through, all these other services, they can't change it. Right? So they can't switch it from $50 to 500,000,000. that's a different aspect. I mean, in this particular case, And I think ID 1 could have in its token said, addition to these other claims, here's some immutable context that says it's being transferred from this account number to this account number and the total amount is $50. And there's ongoing work to look at that as well. That's that's that's that's that's I'm not sure we're talking about here today, but But I think that's where that the question you're asking overlays for this. This is about sort of you know, and that chaining the paths, and I don't know, Justin, you're gonna talk about other ways of chaining paths. But, but I think you bring up a really good point that in any of these flows, when you have a transaction that starts. There's aspects of that transaction that should become immutable at the beginning, and we need that as another piece of this overall work. Yeah. Thank you for your comment because that's a good point. We, at least now, we are not, worried about contents itself of those claims, but we are trying to create a tool that then applications can use to to construct it"
  },
  {
    "startTime": "00:54:01",
    "text": "its content and maybe create new logic that can be put over that. Great. I I I think so, like, that that totally makes sense. I guess what I'm trying to get at is doesn't work as you chartered. There's gonna be a document which is a problem statement, which describes the charter where we're supposed to be. And try to, like, hone in on what that what that document is gonna say so that we know when we're done. Right? And, like, that's, like, Mason is gonna come up, but that's the part in front of homeowners. Like, are we trying to do now trying to Okay. I'm struggling to find out the node number 2, which is the issuer for the 3rd statement and I still do not understand how you are saying that it could be compromised. It but it's still the system could still work. So if I understand correctly what you were showing showing on slide number 6 was that the node number 2 the previous slide, if you go back, so so there, we were showing that the probably the node number 2, if it is compromised, the system still works. Is it is it that? So I don't I don't see a direct connection between the slide 67. So Can you clarify a little bit about the Is that the claim that the ID 2 node is compromised? That's that's a good point. Yeah. Because, here, we we are working on as part environment. So if IG 2 is compromised, probably that will be a window of time that this will be compromised too because we are not rotated the key yet. So if the key is compromised and it's it's too valid, it will be a problem, and we will need to deal with that. In some way that we have not find yet and probably wanted to discuss more to to understand, but the idea is to take advantage of that, low validation some time that the SPV entities have, and we try to mitigate this using this is low, is more extension a valid time."
  },
  {
    "startTime": "00:56:00",
    "text": "So if the the keys compromised it, yeah, that's a problem, but we we are try we try to mitigate with smaller conditions. See, but I don't see any way that that you are proposing which which kind of mitigates this. How does this mitigate this? So it is that's the kind of the flow, which is the ID number 2 is signing for ID number 3. Right? So so key said that signing key is compromised, I don't see any way how Right. If the it could establish a connection with ID 1, that that data coming from ID 1, that and the key for ID 2 is, compromised So I don't see how it's protecting that. I think maybe we should move on with the presentation and and because we may be going in a direction. That's not not what this was pointing at. So Okay. So, of course, I don't have, all the answers here because it's a working progress, but it's good to know and and have those feedback because it will be interesting to discuss internally. So, okay, so please next slide. So let's talk through very fast about the anonymous modes. Which is a way to create this kind of binding bit wing designers, but without specifying the payload, who is the audience. Because sometimes we have a load balancer of or something like that. Between workloads, then we cannot assure which were workload, we receive this, but we also doesn't want to use a lot of audiences. So how do we do that? So, basically, we are using an aggregation scheme here using our signatures and basically imagine there, I do one created the token. I did 2 receives. And use a key extraction algorithm to take the token signature And then these key extraction algorithm returns a partial signature that is half size of the original one and aggregation key. And this aggregation key can be used to extend the original token. And this creates, like, a signature training"
  },
  {
    "startTime": "00:58:01",
    "text": "that binds one signature to another. And if of course, we are sending this token on the secure channel. Only the the receiving part will be able to access the correct key to extend the token. So the idea is at the end of the the day, the target workload will receive the token and take all the signature together and validate it. And if it's valid, do we know that it passes through the the notes that should be. Next, please. Here, the the same example just to understand better what happens. So, basically, green parts originally has a full signature, but it was extended. We have just partial one issuers here are just public keys because we are not identifying them. And this blue token then have 2 partial signatures full signature, and using the aggregation mechanism, we can validate it and know if the token is entire file explorer was somehow modify it, and we can detect that. and then we can reduce up to 50 percent the signature size And Kozhikode where extending using part of the previous signature. Finally, the as a future work, we are, trying to develop this kind of hybrid mode where we take the aggregation key combines with the expire private key, and then we have an hierarchy specifically to each token. And then to validate that, in our issuer claim, we have 2 values. An event document. That's back up, for example, for part by a power server. to combine them and get, on hybrid public key that validates that signature. Okay. Finally, a use case that we have, to the model is the lightweight SVID, which is the nested model, apply it this virus server scenario, we are where we are working"
  },
  {
    "startTime": "01:00:03",
    "text": "on the creation of a small and flexible identity document. Basically, as part of server creates something that we called lightweight as feed. And spy agents and other workloads can extend it, adding new claims to what end way to our great scenarios And finally, the last one, of the proof of concept that we are developing to this, newly identified we are working is it has some requirement. Basically, we want to delegates wealth permission to a specific workload, then we need a way to create and validate the all the chain of custody of the token. And grant the security, the token should not be modified in a way and we need to to to granted the link between all the hops and be able to add arbitrary claims. For example, in our scenario, we are adding selector claims from the the station process. And that's it. Thank you Okay. Yep. Alright. Okay. So, I'll try to be quick here. Is Soon as I can do the thing. Okay. Justin Richard here again with, Ori Steele. Alright. I'm Laurie. That's alright. Out there we go. And, we're here to talk about token containers. So we just saw a kind of token container the reason for this is that, You know, generally speaking, we use tokens, like access tokens and things like that to limit access date APIs, but HTTP generally gives us one place to put the token in the request. OAuth use is the authorization header. This is a sensible way to put it. You can cram it in URIs and other stuff if you really hate security, but, by and large,"
  },
  {
    "startTime": "01:02:02",
    "text": "there's really one, with every request, there's kind of one place to put one token. But what if we need more than 1? And that's kind of the fundamental question that I wanted to ask here. The reason for that is, for a lot of the scenarios that we're about here. We've got multiple systems and multiple objects that want to make different statements about what's happening. It's not just about an access token anymore. Say, yeah, I did the auditing, and here's the result. So this gets, back to a little bit of question of what is the transformation that I did? I want to be able to make that statement, and that's not really changing the nature of the transaction. That's just another statement the transaction as it's flowing through the system that I want to be able to make it in a tested way. And, pass that along. You know, software bill of materials, that, we heard, no, wait, that was in this morning. Sorry. The whole week is you know, flowing together for me right now. And it's only Tuesday, folks. But, but ultimately, my my real point is is the last pull it there. And that's that we've got this habit of treating everything like an access token. Because that's kind of the box that we were handed. And so we've got this habit of taking stuff that really isn't an access token cramming it into the access token spot because that's kind of what we have to play with. And I contend that that's an anti pattern and that there's a lot of, cases where we want to talk about multiple different things happening in ways that isn't just dealing with access token. So for example, I told you you'd be seeing a lot of this diagram. And this kind of system, we want, each of these different pieces to be able to make different statements. You know, the client is making the statement at effectively. Here is the access that I have. That is a traditional access token. Really only once it hits hits that gateway. And the gateway to be able to say, I saw this and I processed it, or I just looked at it and it was on the request or whatever statement it needs to make the past set along."
  },
  {
    "startTime": "01:04:02",
    "text": "And every time that we go through the system, sure we can pass that token along, but it's not really acting like, an access token in the same way anymore, especially if we think about sender constraining. Right? The client is the only party that's supposed to be presenting that access token as an access token, everything else along that chain. It's not really an access token anymore. It's, sort of context to the ongoing request in the transaction. And, again, this gets really weird when we start to talk about multiple clouds and the types of things that we do. And, sure, we can wrap tokens, and we can do token exchange, and we can do things like that. But we lose contacts and sort of make it more difficult every time that we do that. So I would like token data structure that would be carried along transactions like this. I've got a draft that talks about this that I posted to the Lindsay mailing list. But the basic idea here is that instead of treating this as a linear system, treat this as a graph. And every time that you get a new statement that you want to make about you can add it to the graph And I really don't care what's inside those individual statements, because that starts to be get to be really application specific. You know, it could be, I audited this or the account had enough money or whatever you need to do But what's important, I think, is that we have a container that allows to, carry these bits of information along with appropriate metadata says, like, this is the slice of the application that did it and allow it to be attested to buy different parties in the system in a way that lets you add to this graph. So what does that look like? If the because I, needed to make some variable names when I test implementation of this. Each of these things is called a bucket, and you put all the buckets together in a crate. Yes. They're terrible names. And, ultimately, if this starts to feel like a miracle tree, there's very good Okay. So I've got one token on the way in, and, I I take the value of that token, which may or may not be an access token, but"
  },
  {
    "startTime": "01:06:04",
    "text": "front door probably is at least the first one. And I, as a bunch of metadata to that. And then I hash that. I, serialize that out in a deterministic fashion. I create a hash for that. Great. And at that point, because that hash is set, that value is fixed in the graph. I can't change the metadata which also means that I can add a signature on top of it in this case, I'm signing just the hash value That means that the signature is not covered by the hash. But we can do some tricks with key identifiers in order to tie the signature to the hash and all that other stuff, but it also means that people that don't care about this particular signature don't need to be bothered by it. Because I can start adding other, structures this. And I'm not gonna talk through all of the different branches here, but one of the fields here in this serialization is that p field that is a parent structure. Any token, any bucket that's already in that graph I can reference as a parent structure. And the way that I do that is by referencing the of that token without its signatures. So, I really, it's, you know, it's very Merkel tree ish. So I say that this is the parent of that which means that if you take this and shake it hard enough, you get this nice little, directed tree. And, this tree properties to it, as you're passing things through the system. Not the least of which is that should I need to go, and call a subsystem that only cares about the value in, say, T4 I can trim everything, but T4 and T1 and hand that off to the subsystem and still have a perfectly valid tree. And when I get the results back, they could have augmented Tijuana t four with any number of other nodes, I can add them back into the tree, and it's still self And that allows me to kind of manage the data as it goes through my really multi environment, multi cloud system in a way that becomes really powerful. This is a graph and graphs are snakes. Ori? Thank you."
  },
  {
    "startTime": "01:08:03",
    "text": "Thank you. So I'm basically hear, just speak about the different cryptographic mechanisms for achieving these graph structures. So, This is your last Yeah. Yeah. I kind of thought you'd talk through this again. Next slide. It you have the next that's what I got in my phone. I've got it. Digital credential workflows. This is my way of thinking about these scenarios. You got, what's the workflow? It's sort of steps, the other processes through which a piece of work passes from initiation to completion, for me, I deal with credential workflows a lot. Those are really just models of workflows in the real world. Or of a software, workflow that represents some complicated process. A credential workflow for me is a is a workflow that's secured with digital credentials. This could include identity documents, which seems to be the word that I'm hearing in every session. And has, you know, a potential application of digital signatures or encrypted envelopes. I work on, securing supply chain integrity and transparent see the skip working group and we look at transparent workflows for supply chain, use cases. So for the supply chain of, software artifact how is that software artifact produced? In the context of applying that to a physical supply chain, what steps of physical transformations occurred from the raw material to the finished product the certifications along the way, etcetera. For me, a transparent workflow is a credential workflow where messages are stored in some verifiable data structure. Which enables new messages representing proofs of inclusion consist and see these concepts of receipts endorsements or evidence And in the structure, Justin just described, that capability is kind of built into the envelope. That's sent in the context of"
  },
  {
    "startTime": "01:10:01",
    "text": "skit we use, a structure called a transparency service. It's a ecosystem role that transparency service provides that can enable that capability And you can put those together. You can have a selective disclosure or a graph structure that has redaction capability built into it as a message, and you can put that complicated graph, cryptographic object into a transparency service that then enables those components as well. So I'm I'm mostly here to to describe that overlap between know, what I see up things that folks within Wimzi are reaching for, the things that I have some familiarity attempting to build over and over again. Next slide. Now from Yeah. Sorry. but, okay. Sorry. It locked. It locked, High women today, no no hat, it's it's it's it's So I see a lot of so I just walked out before lunch, from the Spice BAF. And I'm hearing a lot of the same words, and I'm trying to understand whether we're just using them differently or they're interconnected. So I heard digital credentials which in the Spice BAF meant, I'm building a CWT with heard unlinkability this morning. I heard selective disclosure. So is this work taking the, what would the credential representation, I thought, and think is the word we use? As the the quarter, the the the kind of cornerstone of this, I asked because the previous presentation seemed like it was presenting something dramatically different than what we talked about the sport Yeah. So I just need some help here. Yeah. Yeah. No worries. So, the previous presentation and this one and even Haunas' are all, sort of approaching this problem space and kind of in different dimensions. The previous, one was describing one way to do sort of an accumulative, you know, linear nested structure in order to, talk about how you chain stuff together."
  },
  {
    "startTime": "01:12:00",
    "text": "My, proposal data structure here is how break that linearity to solve some problems where that linearity doesn't actually help us. Is there a way to cons reconcile those? I'm not sure how that relates stuff in Spice is, that Each of the the dark blue boxes there, I this data structure, I am fully convinced, needs to be agnostic to what's in those. But somebody needs to figure out what's in those. Because you wanna be able to reason across those. In order for, in order to make sense of, like, is this actually secure? Like this can tell you the graph is self consistent, but if it's self consistent garbage. That doesn't help. So I still need a way to be able to identify, for example, particular people and workloads across boundaries in ways that start sense. That's where some of the spice stuff might come into play. Or as even a container for this. So if I could replay my understanding, I should not try to link together what Hana said, what your early saying or what I heard because these are not necessarily complimentary approaches. And so they may tackle the use cases. I thought I saw it in the beginning. They may tackle part of them, none of them, or they may even tackle the same ones, you know, competing kind of way. Kind of, I think Peter probably has a better answer for this. I think the way to think about all different things that you're seeing, Roman, is there all ways to solve different aspects of the use cases. Some of them may be I wouldn't even wouldn't even say competing. Right? They're different ways that may both be valid as a solution at different points in time. Right? There are challenges that we may need to solve very urgently for which we probably don't need more advanced cryptographic techniques than we already have. Some of them are things that maybe 5, 10 years out."
  },
  {
    "startTime": "01:14:00",
    "text": "We need to think about how we will solve those things in the future. So I think there's sort of a time dimension to this, but then again, that are also a in in in in They're not all addressing the same use case or said there are use from many use cases, and they're all being addressed by different proposals. Right. And there's also a contextual aspect to to, like, for example, the Honesty's presentation was about if you are on, Kubernetes and you're using this something projected something or another token thing. Can't remember the acronym, but, if you are using that, then there's a certain set of ways you could actually make that make sense. That's a very, very narrow, and very immediate problem solution space, that might feed into, say, how do you get the stuff into one of these blue boxes here. But it also might be, So in that way, it might be complimentary, but it also might just be solving a different problem at a part of the stack, at the same time that this is solving something else in a different context. So they could be separated. They could be together. And I think that One of the reasons that, that we're proposing more work in this space is to figure out where those gaps where those overlaps are because I think that a lot of people are hacking together solutions today. Without that sort of larger thought of How do these things fit together? Where do they compliment? Where do they conflict? And, and how do we even start talking about that Hi. This is Dimitri Zaccadulan, MITDC. So this is everyone's favorite topic of hash links. Right? The So so my question is inevitably have you considered either ipFS style CIDs or RFC 6920, naming things with hashes, or the, naming things with IDs and hash fragment Thanks."
  },
  {
    "startTime": "01:16:03",
    "text": "Those are all great questions. I just wrote this in Java 1 afternoon, so no. But they're they're all great questions. So, this I proposed it as I I would like a data structure to exist with the following properties. And if there are more clever better ways to get those properties. I'm, I'm all for it. And I'm passingly familiar with, with most of the stuff you listed off there. But not enough to be able to say this is a perfect fit for the kind of thing that I wanted to do. So the, I literally implemented this with, like, shah 256 for my hash function. And, I think I used like es 256 out of a Jose library to do the signing. Really brain dead. But just to prove the point that it could be done, even with dumb crypto primitives, if there's a better way to do that, let's let's talk about that too. Alright. Yeah. Grazor snakes, Right. So, This is an overview of, like, the concept of, transparency service and the role it plays in supply chains. So in a supply chain, you have upstream components and downstream components. Justin's comment about the linearity versus graph structures many people think of supply chain as just this linear thing, but it's actually the graph thing that he's talking about before. The supply chains are very complicated. One of the ways you introduce confidence in those complicated scenarios is by creating this concept of a transparency log and then having information flow through transparency logs And every time you do that, you're creating a kind of 1 layer nested token thing. The first layer is the sign thing and the second layer is the transparency logs receipt on the sign thing. So this structure here essentially shows you the science statements they come from some first producer,"
  },
  {
    "startTime": "01:18:00",
    "text": "That guy does registration. Some policy evaluates application specific information, If success that goes into the transparency log, a receipt is produced, and that signed statement and the receipt together become a transparent statement This then feeds back into a potentially very complicated loop. And then that leads to, at the end of the day, complicated and valuable productions from these supply chain ecosystems, these value networks, in the case of a identity workflow that could be delivery of a complicated experience and valuable experiences in software consumer. Physical supply chains, it could mean that you got your device and it had all of the things that was post to all the certifications were done compliance checks were met, etcetera. So I'm This is just essentially to present that view of the same sort of set of challenges that you've seen here. You know, Can you advance? I've got a bunch of, like, working code and skit related headers here, but I don't think that's maybe not the useful thing for us to do here. So, at this point, you can consider my part concluded. The one comment I would make is that What Justin was and what Roman was asking about and what Justin tried answered There is some repetition you're seeing at different layers. Every time you see that It's not necessarily doing exactly the same thing. That it was doing at the other layers, but there's a lot of Repetition, and that repetition is valuable. That's why you're seeing it being repeated. Alright. Monitor, Yeah. Manny Fontaine with Hashmesh, made a a similar comments in other sessions there's a theme here. Indeed, there's layers, as you said, that repeats themselves it it turns out that I think there's a layer that's underneath all this, which is a you know, universally trustworthy cryptographic bedrock of some sort where you could"
  },
  {
    "startTime": "01:20:01",
    "text": "know, actually get automated cryptographic key managements and get, software identity, people identity, organization identities, be registered in an infrastructure of that sort. So this is now becoming possible, thanks to confidential computing. Teas and all that, I wanted to bring that up, in this context because the identity of software is actually also related to vulnerability tracking, and then be able to just go and and react to software deployed out there. So registering hashes, inherent identities of executables into a global interest for the cryptographic fabric actually be extremely beneficial, across, you know, virtually every application. Thank you. Ecker, did you wanna bring your on So, I guess, can you just help me understand what transparency is doing here? Cause usually transparency is about preventing equivocation. But if this office is all signed, Like, it's like and because, like, like, like, somebody understand that word fits in context, So I'm not sure if transparency services are providing any value here. Okay. I'm mostly here to sort of say you see you see this nested token thing. Here's another place you see nested tokens. Got it. The use case for those nested tokens is about and performing this digital notary us. Like, as a notary, I may authenticate you, but I'm not gonna look at the document that prior signing on. Right? So that document has application specific detail. There are workflows where that's the property that you want. Where I just wanna authenticate you, and I'm not gonna look at your document. There's work. There's other cases where I'm gonna authenticate you and I'm gonna look at your document, and I'm gonna apply really complicated validation policy see. And only then will you get a receipt for me? I don't know if those use cases apply here or not. I'm explaining the building block. So I should be be be thinking when I when I see this, I should be thinking counters"
  },
  {
    "startTime": "01:22:00",
    "text": "perhaps more than ICT. Exactly. Yeah. The counter signatures is another, building block that's very much like the other ones discussed Right. Yeah. So, I I I think one of the most important things for folks to take away from the, the whole kind of suite of presentations today. Is that there are a lot of common patterns out there, and those patterns are sometimes happening with solutions at different layers than what a workload type system would actually be dealing with. We're not saying necessarily everything that was brought up today. It's like, oh, this is stuff that whimsy should be doing, but it's stuff that Lindsay should be paying attention to because We should either be copying the best stuff or you know, influencing outbound. The, the token graph structure thing, I originally came up with that structure not to solve anything related to workloads. But to solve, migrating, human user identities across federated domains. You know, I need to be able to trace things, and it's a graph, and it's all this other easy stuff. And I needed to be able to talk about that kind of thing in that space. And I realized that there's probably some applicability here too. And, So, yeah, I think that there's stuff that's happening at a lot of different layers that you're gonna see echoes of. And, I think recognizing those echoes is gonna be really important to figure out, like, where the actual edges and scope is, which the chairs would now like to talk about. Alright. Thank you, Justin. Alright. With that, we would like to bring some of this into perhaps better focus. And then open it for discussion So just to remind you all, this is not the working group yet. This is not even a working group forming buff. And everything. Just about everything is open for discussion."
  },
  {
    "startTime": "01:24:03",
    "text": "We will have a set of, both quest at the end of the open discussion we did have some discussion on a proposed charter on the list. And I would like you folks to take a quick look at the chart scope. Wednesday Working Group has started to address challenges associated with fine grain least privileged access control for workloads. In this and that, scope. So we do have escope, of what we would like to address And then whether we take on specific deliverables That's up for discussion, and we will talk about some of the principles. So the goals that were proposed, on the mailing list. To establish best practices and the document that Hannes talked about is an example of such a best practice. So taking existing technologies, and deploying them for less privileged or, workload a authentication authorization in a specific environment. That's a best practice, and this is the kind of, documents, a kind of documents that, we would like to to publish within the group. Next is to identify gaps in existing standards,"
  },
  {
    "startTime": "01:26:00",
    "text": "like even another discussed So some standards that are almost but cannot be used for workload authentication because of k. So that reason, And then whenever a a large gap whenever a gap is identified and it is not being worked on in a different working group. Or even a different STO. The working group Well, also produce, proposed standard documents. And that's the proposal that was made in the charter And this is a graphical way of the off the describing it So we will be working on So first of all, this is in priority order So some of the things we we talked about today may eventually become in scope of the group but not immediately. We will be starting out with, use cases based on existing, technologies, Sorry. With use cases. For workload, authentication authorization in an abstract way then we will be publishing an architecture document tying it altogether, and attempting to, to resolve the use case is as far as possible with existing technologies, but also identifying gaps in in these technologies."
  },
  {
    "startTime": "01:28:00",
    "text": "In parallel, we will be publishing, best practices that are point in time. So best practices may be appropriate today, but as the technology improves, as we come up with possibly better solutions. Those best practices, might not become test. Anymore and might even get deprecated at some point. As as as we said, We're not out to grab a a huge scope of of standardization work much of the work, will be done in other working groups and that, certainly includes oath could include spies, the spiff spiff itself is being done in a in cncf, does possibly relevant work in, open ID foundation, all good, If there are still gaps that need to be standardized workload authentication, that will be on us. And with that, we'll Open discussion. Erica Scralla. I think, you know, I'm persuaded by these presentations that there's a bunch of interesting work to do here. I do not think this is a good plan of work. However, and the reason it's not a good plan of work. Is the charter is actually incredibly open ended. It just says, like, we're gonna fix problems associated with, like, work flow augmentation. And IETF doesn't fucking complete this. We're gonna be sure we develop some technology like OAuth now we're kind of like filling in gaps over time. You know, this also happened, you know, with, you know, can see TLS does this. You can see SIP does this, but these are not things that will just be invented, and there's no architecture"
  },
  {
    "startTime": "01:30:01",
    "text": "embedded. This is like other people's technologies, and we're being asked to fill in the gaps. And and that is not something that I and that is like a recipe for, like, a a on Ketamari of, like, ridiculous work that, like, no one understands. So, I would suggest quite the opposite, approach, 1 or 2, 1 or 2 things. 1, is a very tightly focused working group to do 1 or 2 other things that says I'm here. And then if that goes well, we can move on. Or alternately, if you want a much broader scope, working group would start for the architecture document and then fills in from there. I do not think what we should do is be like, we're gonna have a working group, which is just gonna fill in unspecified holes and then later world market gesture. That is, like, a recipe. We're not so, like, I'm just asking for doing the work, but, like, I don't think we should trigger it that way. Roman. Just wanted to respond No. No. Yeah, I agree. So the, So the the goal at least from initial conversation was to actually identify a handful of specific things, like, you know, Hans's document, which is very, very narrowly focused. By design and also, and also put together what Peter and I have been calling, a sort of a general BCP, but during wants to call, wants us to call an architecture. But to specifically do that, And in working on that, find out where the gaps are to do more work. So if if there's a better way that we can express that in the charter, please help us with that language because the what you described was a lot more the intent of what, at least what Peter and I had going into that charter. And so, yeah, we would we would love to have that be more clear as to what we meant by that. Yeah. I guess, I would propose the way to handle that would be basically to take what you just said, stuff it after like those opening paragraphs and then have the work items be do those things."
  },
  {
    "startTime": "01:32:00",
    "text": "And then we can re charter with new work items and different things as opposed to kinda having it just be like a grab bag maintenance working group the way, like, a off as now. Hi, Roman didn't know hat. This is partially duplicative, I think, just got set up. The mic, I guess I read that charter text and It reads like the words for a standing working And what I don't understand about this space is why do we need a working group to figure out what the problems are and just have this open ended thing, and then we'll kind of work them. Do we not know them? And so there's something different about the space, which I, I, I don't understand. Colin Jennings Cisco, can you go back a slide, please, just so that one, I think it pumps, so I I'm gonna be saying almost the same thing you you from other people here. So I first of all, a year ago, I was just wishing somebody would be making something like this happen. Like, this is some I could I'm really glad to see this type of thought coming together and very supportive however I can, and I'm happy to help work with you people on writing charters where I route That said, I I I think this is a very risky place to have a very blank chat open charter. I think we should be naming very specific things that we're going to do. And one of the reasons why is this is a huge magnet for people's work that was rejected it at other SDOs to come and re re re res it, correct it again here. And, you know, figure that all together. So I think that the direction I would really go is, again, reversing the order a little bit of this is the use cases, and the architecture and gaps do that first. And as you get your architecture and gaps, clearly straightened out, start forming the the documents you need about how to do things. Now, I understand what the words best current practice mean if you look them up in the dictionary. But that is probably not quite you're probably gonna have a lot of pain in if you're trying to do this all as BCPs at the IT app, you probably are talking about"
  },
  {
    "startTime": "01:34:00",
    "text": "usage documents or something slightly different. I think the documents you want to write 100% agree with. I probably would would I'd wanna talk to you a lot more about why you thought they should be what a BCP, just that 3 letter acronym as 1 unit versus versus exactly, the things that people who are practicing this should go to currently. So that's that's just a little bit sort of figure out that stuff and and and the gaps. And I think that if you it it that I I'm just pushing for any of the things that are going to be the usage documents or the new gaps that we're gonna fill. To get very specific about those in the charter of what going to do and not have it be at all sort of open ended. And of course, won't get it right. You'll find some things that you missed or whatever. You'll re charter. You add those later. It's not it's not expectation to get it perfect first time. It's just Here's our initial scope of work that bounds it. And limits the amount of crap that people can bring because, obviously, you know, this could turn into one of those things that you do go for 10 years and you haven't gotten anywhere. So we need get it narrowed down. So thank you, and I'm glad to see the work. Cedric. Hi. Sorry. I'm Selik Fulner. I also find it very interesting, but I In term of scope, I'm not sure what is our workflow and what is not. This setting. In fact, we have seen, many ways of, composing documents of, putting them into buckets, putting them, putting them into a graph, And a lot of that would apply generally to make kind of complex or D. So I I failed to get what is specific to a workflow as opposed to other open ended, composition scenarios. Hey, Hans?"
  },
  {
    "startTime": "01:36:05",
    "text": "Yeah. I liked what Colin said. Like focusing more on, or are focusing on fine tuning the use cases, looks like sort of like, well, it spent time We had initially comp conference call, separate conference calls, and and this cushions on the list about those use cases and spending more time to sort of write them up properly. I think that's good. Also, the architecture, idea that, echo product. I think that's also That's also excellent because that's, a better way to also Explain how the security properties look like in these these container based environments, which will Also had to inform on how some of, the technologies are being used So So I think that's, limiting the scope and and starting with that one first. Yeah. It's Thanks. Romans. Hi, Roman Delilio again. Got a no hat. I'm having trouble understanding some of the things that it got set up in my line. I don't know how to square. We're gonna write down what we already know how to do wanna make sure people know within writing the architecture down, like, in the new one. So is it that we're gonna write down the architecture that's implicit that folks don't have and same time we're gonna write the practices, or are we gonna write down you could do it now, and then we're gonna describe the new architecture. So when we say architecture, I'm I'm trying to kind of square that between new, old kind of work or what whatever we might do. And kind of those use cases or the use cases for the best practices we were describing. So can I can someone help me out? So I I would this is Hans. Would I would see the architectures, We've seen some of it in this in the slides, and there's obviously a lot of it in for example, the spiffy documents and so on. But it's"
  },
  {
    "startTime": "01:38:00",
    "text": "all pretty much scattered all over the place. And but and, of course, there's variation. So for example, whenever he was talking about the ancient using the the spiffy identity documents He was also showing, Probably not very prominent. There's actually interaction with the back end system. With the control plane. And that's technology that is we are quite familiar with it's used in different places, like in, essentially, are talking about certificate management purposes. Because you need to fetch, credentials request credentials. You get credentials. You also provide at the stations about the host you're running Flutson and and so on and so on. And so describing that, you know, a little bit abstract form not going into the specific inclinations. I think that's, what I would have in mind. On for for a first step. It's not the architecture on how it should look like in the future, but it's, like, documenting how it's done now. So if I just follow-up and repeat what I think I heard acknowledging I'm not the the deep expert in. So we're saying that Things deployed in clouds with technologies like Docker and Kubernetes, this so very widely deployed thing used by very large companies ever that's not written down anywhere. And so we need to write down this thing that's being used in cloud architectures kind of right now kind of pervasively, and that's an important contribution because, again, no one's written down this thing used in production by 100 of 1000 of people and companies right now. I'm just making sure. Yeah. I wanna make sure. Yeah. It's it sounds like kind of ridiculous that I'm that we are making that statement, but I had to look at code to find out, like, how some of that works. That's why they it's sort of like seems surprising."
  },
  {
    "startTime": "01:40:01",
    "text": "It's crazy as that sounds. Yeah. Exactly. And I think I so, I mean, architects, you know, architects are, I I know it when I see it. The the the the the what I was sort of imagining, I think, was the the box is an arrow style road map of how this is how these, you know, need to transfer sort of this level of claim from here to here, and we're gonna do it using approximately a spiffy thing. And there's a gap of there's here's some information we couldn't transfer that were identified just sort of a rough roadmap of how all the pieces pieced together to, to answer even sort of, you know, commonly deployed things of How we all run Kubernetes today? Right? Which are is not. Done, and it's it's not quite just like a matter of looking at the source because a bunch of this doesn't really quite work or people are taking horrible hacks to connect things together. Yeah. Well, okay. I mean, so my clarifying question is, Do we have a pattern of in the rest of the IETF where we documented someone else's architecture, And that was the contribution kind of we made because I'm roofing a little bit off, like, or said that, like, we this one seems different, if we're gonna try to patch technologies we did not develop. And so it can be learned lessons from how others have done 3gpp documented our SIP architecture. Right. So one of the, one of the problems here is that a lot of the sort of specific concerns, that people find when they go to actually the stuff gets lost in, like, institutional knowledge or just in some engineer's head. And if they get hit by a bus, then that's needs to be rediscovered by somebody else. So, you know kind of to, Citrix, question earlier, like, what are what is unique about a lot of this stuff. So we we tried to start capturing that in the cases document. Some of us like being able to make a hyper local decision."
  },
  {
    "startTime": "01:42:02",
    "text": "Right? That's not unique to this space specifically. But in context of everything else, it it turns out to be very, very important when you have this, you know, random little Lambda function that, it does not have x internal connectivity and stuff, you need to be able to hand it enough information that it makes a decision and on with its day without having to go talk to somebody else. And the fact that, like, that is the context that this ends up getting deployed to that type of knowledge gets an not necessarily lost, but it keeps getting rediscovered every time somebody needs to sit down and do this. And so preventing that rediscovery to some extent, should I think be a goal of this work, by capturing the current practices which are best, And, and also figuring out, what weird hacks people are doing that work that probably aren't great, but maybe we should write them down and put fences around them. Because I I've seen a lot of weird stuff out there that people Like, so, Hana student, I I don't think he really got into it. That whole projected token thing it's a jot that shows up as a file on your Docker image. Is weird. But it works, kind of. And so it should have appropriate expenses around it for people, you know, we don't think of a OAuth tokens as files on the file system. In the OAuth world. But people are doing it this way. And so this is exactly the kind of thing that we need to be able to start talking about. And not only have the, sort of the common vocabulary for that. Which I think we're also missing, but have an ability to discuss this in the kinds of context where you get this notion of Okay. Yeah. You need it to be, you know, like, you know, highly robust from disconnection. Okay. But why? What's driving that? You know, is that something that I'm allowed to skip because I think I'm smarter than, than the last person, or have I just not discovered that foot gun yet?"
  },
  {
    "startTime": "01:44:05",
    "text": "Thanks for all the excellent input on think how to think about the charter I think in response to the question about us documenting other people's stuff. Some ways, it's us documenting our own stuff. These you know, folks go out, they adopt OAuth. And they do it in a way that nobody in the oath working group would have thought is a good idea necessarily or would have done. A Yep. Well, I I'm wouldn't be that judgmental. I mean, it has to work too. Right? But the the challenge that we then run into is, you know, someone says, oh, well, I'm using, oh, I'm using OpenID connect and the and of course, that becomes a switch for It must be secure. The IATA must have reasoned over this it must be okay to do these things. And, evidently, maybe not. Right? And so I think, and and that's, you know, you you might say, well, so why still why should we care? Other challenge that we have is identity is sort of this huge ingress point for attacks on our structure, all of our infrastructure. If I can fake an individual, I can do anything that individual can do. If I can fake a workload, I can do everything that workload can do. And that workload can do more than humans. Right? The way are really not a police per privilege access today. So that's actually one of the things in the charter where we we need to aim for that. But, in the absence of good identity foundations. It's really hard to do least privileged access. And again, you know, so I think there's sort of this first step in with OAuth making sure that that being used properly. There's some very clear issues like the things that Evan has pointed out token theft, be having request constrained tokens. Or or immediately sort of takes away an entire attack vector for us. And so these are immediate things that we can go and solve. And again, I think that point, I think Eric, that you raised and and"
  },
  {
    "startTime": "01:46:03",
    "text": "column. Right. Okay. We if we need to write the charter that narrow, Let's do it. But the more I see of the space, I'm very sure we're gonna come back and recharter later on But I appreciate the sentiment of not create a dumping ground for everybody else's stuff that got rejected in other places. So I definitely don't want that. So thank you. Hannes, Roman, you ask an interesting question, like, are we documenting other people's work and I would see it slightly different. First of all, we actually The the queue is closed. I'm in the first no. No. No. Go ahead. Oh, okay. But people at Skipjoy. Yeah. Okay. It's like we do that all the time. So if you look at suit, if you look at rats, if you look at, deep, like, there's typically, we don't invent the technology. Like, there's already something out there, and then we start to standardize it, and And so we need to document a little bit on, like, what are some of the implementations out there and then as technology matures and people are interested in sort of munching things together it then new sort of needs for collaboration arise and in fact, actually, and that's something I'm quite thankful for, Evan who came from that community was able to, in the discussions, give us some insight into to the design rationale on some of the the things that he was actually talking about today. And the those groups have documented some of the stuff. It's just document in a very different abstraction level that is unfamiliar for someone like me working in the IDF who he has about totally different things than they do. And it's makes it that makes it inaccessible or or quite difficult to access that information, for for for someone else, working in those projects, it's obviously"
  },
  {
    "startTime": "01:48:01",
    "text": "it's a piece of cake, but I think there's value in disseminating that information to this community also and to collaborating with them actually didn't create something, a standardized solution that it has better security. Next. Is is that me? Yeah. It's. Sorry. I can't really see that well at this point. Just, I guess, scary for me. Hi. I'm AJ. I'm sorry to be a broken record on this. Now I'm more confused. I understand and kind of align with what Honas just said, but I'm worried about what architecture we're defining. So I'm gonna say something and people wouldn't tell me that's what we're talking about or I've misguided, and then I'll explain why I'm asking this we're talking about identity and authentication as it pertains to identities in mostly workloads that we would see in the cloud. Is that before I keep going is that related, To Justin or anyone? Okay. So what is the architecture we're looking at? Are we talking about the reference open source vanilla versions of Roneti's people here mentioned Docker. I assume they mean OCI container specifications because it's technically doc ready more. For both of those, there are dozens of different very large cloud scalar implementation, self unquote self hosted implementations, it's really hard for me to see where you draw the circle there. And re adopting fast growing technologies, those are now very well and fast sliding moving targets. I don't see how defining reference our architectures, even if we're doing it from an IETIP perspective, and that's helpful. Is not going to be really hard or Something you have to rapidly update all the time most of the cloud vendors despite I think of their documentation, they have trouble keeping up and they often allow people in different ways that play multiple versions of these things in very heterogeneous, very conflicting crucials. That's it. So I don't think we, this is Jess."
  },
  {
    "startTime": "01:50:02",
    "text": "I don't think we mean architecture quite as technology specific as you're saying in the end there. I think we're talking, in sort of broader strokes, that there there is a thing known as a work load. It has instances and those instances get identified and they connect to each other, and that means particular things. That it's terminology to, is what life just said, and I agree with that. And and a threat model is what Ori said because nobody wants to come to the mic, so I'll just keep repeating things. Yeah. But it's, but it's more at that level as opposed to you've got Kubernetes version, whatever version it is, and Docker container, version x and and you're putting them together in this way. That's I don't think that that's what this working group wants to do north and I agree nor should it do something at that level but instead be able to say that there's an image of software doing a thing and have have a name for that and have a that'd be a well defined name. That we can then reason about. Well, It's hard for me to see how you could connect, like, I guess, what we'll call an information architecture. Or or something else to not drag this up further. Well to things that are largely based on examples that we keep repeating as we describe it, which is why it's kind of worrisome. I've been down that road before That's it. mean the work isn't worth doing. I'm interested, but I'm just Doesn't saying Sorry to to interrupt. We're 9 minutes to the hour, and we would like to go into both questions. So I think I think what we wanna try to do is get to you know, is is is there something of interest here? I know we have differences on how or or we haven't quite gotten to a a concise level of, charter or what would exactly be charted, but I'd like to understand if people see this"
  },
  {
    "startTime": "01:52:01",
    "text": "Is there work here that throughout what we've what we've discussed that is appropriate for the IETF. So work associated with workload identity, that that should be done in the IETF is is the question. I think Does that make sense to folks? We're gonna run a poll. I just wanna put the question out there and make sure that we're that this seems productive. So Is this was saying Yep. Well, we're within the context of what we've discussed today. Let's it's increasing still Yeah. So, it the the numbers. It says, 33 said yes. 4 said no, and, there were 61 that, had no opinion. For anybody who said no, if they would like to come to the mic and Let us know if there's specifics that you'd like to give."
  },
  {
    "startTime": "01:54:01",
    "text": "Okay. Okay. So the the next question is we'd like to get an idea how many people would actually contribute in, you know, a number of people, though this was appropriate, but do we have people in this group who would author documents review doc documents, you know, contribute text where needed so This is the next question here, and that's So including review, Yeah. I would say including review. I mean, review is they're important. this was done and I well, you can read the If questioning your thing, but would you contribute? Do you want to have a I don't think if we don't know what the implementation Alright. Let's close this one. So we have, 34 I mean, 30 3, 4, for no And then No. No. No. Oh, sorry. 30 okay. Yeah. 34 10 30 for yes in favor. 10. Nose and, 58 no opinions. So that shows, decent interest there I don't know if we wanna get into any more"
  },
  {
    "startTime": "01:56:00",
    "text": "if we can get into any more specifics about who would implement, because I think I I don't know that we know what those deliverables are, but are there other questions that we should be asking at this point? From a Francesca or Murray. So when this came up at dispatch, we weren't sure being, I'm saying we being the area directors. We're not sure whether should be artwork or sec work. And the four of us are in the room, and I don't think it's any clearer to us. So we think we would like to get some feedback from the room to any of you feel more strongly about the wrist should go to one or the other. Okay. There's three areas for us to choose from now. Seccard. Whimsy dispatch. Don't want to quote them. Yeah. I mean, I asked a question. Sure. It it feels like more art than, sir, to me. Just because it it feels like unless you're going in to create a brand new like, If you're making a new protocol token format that's specific to this, then it feels like more of a sec thing. But if you're talking about terminology and sort of ecosystem sort of alignment or documenting how people are doing this today. That feels more like, less sec. Yeah. Yep. Yeah. So I initially got, like, to say, Zach, actually, and then always sort of half convinced me. I guess I think it really depends on what we're gonna I think if it is gonna be, like, It is gonna be, like, mostly you know, you know, scream around where the tokens go and, like, what's in the tokens, like, it's, like, semantic, then it's, like, an artwork kind of thing. Our PC doesn't work"
  },
  {
    "startTime": "01:58:03",
    "text": "it's gonna be, like, kind of stuff, Justin presented about the, you know, with with the hashes or or I'm sorry. I didn't catch the guy's name, but the, you know, but with, you know, the the the aggregate signatures, nothing obvious has to be in a sec. So I actually would suggest that, like, we try to, like, nail down the charter first And then, like, if it turns out that we're gonna do actually both kinds of things and, like, you know, wouldn't be that worst thing in the world to actually have, like, another working group that, like, these guys are too too performance, and these guys are gonna do this. So I think maybe, like, try to work out, like, what actually we're gonna do first and then we can figure out who owns Can I can I plus one what Ecker just said for integrating They They don't have enough to do? Yeah. But for now, it's Francesca and Could you please close yourself? Thank you for a very good discussion. Yes. I've heard a lot of opinions. I mean, I'm really, the positive point is that there is a lot of interest It's still not very clear. What the scope around what is proposed is. I think that this was to bring, like, the the presentations I heard was a lot of you know, there is a lot of interest. There is a lot you know, of people who are willing to participate And so I think that we should work or on the charter in the mailing list and definitely, like, let's not boil the ocean. Is that the the same? So that's gonna be a fundamental point for this to be able to move forward because if it's way too much or way too open it's never gonna, like, get approved anyway. So Yeah. Thank you. So thank you for running this as well. Thank you very much."
  },
  {
    "startTime": "02:00:00",
    "text": "Yeah. Yeah. I I was literally gonna never used the word architecture of the idea. Yeah. Well, there there's that. And then too much. Actually, I wasn't surprised. Says What is it? No. I would just, like, what? Oh, no. It's, this might Yeah. Right. Well, I mean, it's not obvious to me what they're gonna do. So, you know, it's not if it if they're building new chosen formats, like, Yeah. Yeah. I like the I like the framing of the problem, actually, like, I felt like what it is 1 of the workload identity piece, like, what problem. Actually, I felt like that was I understand that. We can that's great. You know? Yeah. Turns out, like, terminating his pump. He's like, yeah. Okay. I have more questions. For Office of Sears. Yeah."
  }
]
