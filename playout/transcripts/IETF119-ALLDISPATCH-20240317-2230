[
  {
    "startTime": "00:00:01",
    "text": "So Okay. So good morning. It's time. Okay. So welcome to our 1st session of this IETF week. And it's, out dispatch. Actually, it's above. And it's, it is a experiment and trying to see how it works if we dispatch across the areas. So it will it would be good if you could share your feedback to our I ISD. And let them know what you think about this session. Thank you. So first, we got this note well. And, you must be familiar with it. If this is your first time, please to raise the rate and there are some a purchases and, policies, you need to follow And the the IPR issues you need to be aware of and also some, guidance here. Could refer to. And we also got this note really well. It's more about the behavior and, We have this IETF anti harassment procedures if you is more about, you we need to be friendly and, respect full to other people's work. And if you do have any concerns Please raise them. Next. And, there is some, meeting tips since we are the 1st session and you could get yourself, familiar with it. And please do sign in to this, session where the I'll the data tracker or the QR code. And so you will have your name in the brush sheet. And, please use the on-site tool and when you join the queue,"
  },
  {
    "startTime": "00:02:04",
    "text": "For the remote participants, we do have a few in this session and please make sure your audio and video are off unless you are presenting, And your headset is strongly recommended to use. A space. And here are some resources. For this meeting you could refer to. Thanks. Okay. So this is a dispatch session. So please, for all the presenters, And, all the, people who come to the Mac Please focus on the dispatch questions. And there are few answers. To this this past question. All direct the work to a existing working group if you think there is any I'll propose a new focused working group. And that's my, my require a both. And maybe the draft is small, so that may require the 80 sponsored. Oh, any further. If it's not clear yet, So more discussions will be required in the meeting list. All the work is not appropriate for IKEF. Please, because we have limited time, Please keep this in mind Next, Let's see. So to add to that, we we've had a number of people that have the impression that the dispatch session is for publicizing their proposal that is not the focus here we really wanna focus on the dispatch question and, just kind of describe the work that you're doing to the extent needed in order to try and answer that question, but, We wanna try and avoid having a lot of, back and forth or discussion on the the technical details of these proposals. Thank you."
  },
  {
    "startTime": "00:04:04",
    "text": "Yep. We got 9 items. And, so now we can start. Welcome our first presenter Sir, remote presenter. Thanks. Yeah. Yeah. Yeah. Yeah. Please start. You know, I'll Ask the slides. Yep. So could you give me control of the slides, or Sure. Yes, yes, I think now he has which is which is how do I go? If you drop, he can so or I I can work with next slide, which works as well. Right? Okay. Thank you. I'm We'll slow on this. No. No problem. Okay. So yep. So hi, everyone. My name is Francois Michel. I'm researcher at Susilva. And the the Topic of the talk here is a running, SSH connection over HTTP tree. So the idea is to rethink the design of the SSH protocol. And run it over, modern transport protocols such as quick TLS and HTTP. So, SSH is quite famous, so you may know it already. The idea of SSH is to provide a set of secure services on top of namesake your network. So, set of services, is like, having a, a remote interactive shell access you can send also if you could single comments, and you can do for instance, TCP port forwarding, which is quite extensively used as well. Next slide. Yeah."
  },
  {
    "startTime": "00:06:04",
    "text": "So if we look at the, SSH architecture. So the current version is version 2. SSH, V2, the detector is divided into 3 main protocols, so 3 main documents. The first one is the SSH Transport Protocol. Which is, handling the secure channel establishment. So key exchange and that can stuff, and it provides encryption Then you have the SSH user authentication protocol, which allows you to authenticate users on top, of SSH using passwords or for the keys. And then you have the SSH Connection protocol, which is doing the actual SSH work of spawning processes and communicating with them. Next slide. And so if you want to, implement message, you have to implement the 3 protocols and, multiplex it over a single TCT connection, Next slide. And let's say, you want to like, extend, the crypto graphic algorithms, like adding a new one, then, you typically extend the the transport for the call and add new cut points for new crypto algorithms And so you, you update the document and then you update, every implementation. Next slide. So SSH V2 is widely used but it still has some limitations. For instance, it cannot forward utility packets so that means that you cannot forward quick connections, and you cannot forward some some real time protocols that are based on UDP. For instance, it can also be easily detected and blocked so SSH TV clearance on 422 22. So you can simply block vault 22. If your server is running on another port, then, you can simply inspect the payload of, TCB packets If you see a clear text SSH version string, then it's a message connection, so you can drop it. It runs over TCP, which works well, but it's subject to some"
  },
  {
    "startTime": "00:08:03",
    "text": "small attacks, like, packet ingestion attacks, or, manipulations of the second name. For instance, the recent rapine attack was about that. It was missing a run with the sequence number of TCP, to be able to skip some parts of the, of the algorithms negotiation. It's also not really well integrated with modern web infrastructures if you look at modern web infrastructures, you have many ways to 4 authenticate your users. You can use HTML 2. You can use open ID connect, for instance, or we're both in in past keys. And if you want to integrate it with SSH, it can work, but you have instance, to deploy middlewares, that keep, mapping between users and, and to make keys or generates open SSH certificates to do so. So it's doable but there's, deployment burned early. And, also, it evolves in parallel to, the web protocol such as, TLS, quick, and HTTP. These protocols also proposed, a secure channel and encryption, and user authentication, but it evolves in parallel with SSH. And so you have some features that are similar between the two protocols, such as certificates, But for instance, SSH certificates are not widely used, but SSC, HTTPS certificates are used everywhere. And so you can have cases where, for instance, you have users that deploy the their VM with an HTTPS server, And, simply, BS server works well. It has a public certificate But, maintainer connects to the VM using SSH, and it's not using any certificate. It relies on the first and first use pattern. It could use as a open SSL certificates, it has not access to the ecosystem of X, X 509. And so it's a bit less easy to to maintain. Next slide."
  },
  {
    "startTime": "00:10:01",
    "text": "So that leads us to, the idea here of the proposal. So the idea is to replace the the transport protocol and the user authentication protocol SSH by HTTP, quickencls, and, run the SSH Connection protocol on top of it. So that, next slide, you can focus on implementing the SSH connection protocol, and, HTTP and quick N TLS can evolve in independently and be updated. Next slide. Also, you have access to the modern features of this protocol so that you you can have, around multiplexing, but also streams multiplexing, data grounds, and connection migration. Slide, let's see how it works in our proposal to establish a new SSH so the proposal is called SSH 3. I'll be happy to discuss renaming later. So now let's focus on the ID of the protocol itself, but how to start up SSH 2 connections. First, you do the quick and check. Next slide. Once the yanksha the yankshaek is established, you use you send the HTTP extended connect method where you can set, specify a protocol. Here is SSH 3. And to, authenticate the user, you use the authorization header of HTTP, And so basically here, you can use any kind of, authentication schemes that you want with the GTP. Next slide. If it works well, if you choose a good scheme and if the user really authenticate, then you will have a 200 status code, and the conversation is established, and you can use quick streams and stuff. Next slide. If it does not work, then you have an a notarized status code, and then Yeah. You, you, you, you did not succeed authentication. Next slide. So what are the opportunities of using HTTP tree here. First, you have access to the quick API. That means, stream multiplexing, you can send data on different streams and you have avoid head of line blocking here."
  },
  {
    "startTime": "00:12:00",
    "text": "Upon packet losses. Next slide. And next slide, You also have access to, data grants you can do you the key post forwarding. Next slide. And you can also have connection migration so that if you change your IP address, if your user is mobile, then, you can reattach the quick connection without disrupting the SSH connection. Which is quite nice next slide. You also have quick that encrypts and authenticates all the the, the control headers, next slide. You have access, with low effort to do X 509 because system quite easily. So here, on the, on the screenshot is just to show that without prototype, we just rented a an Azure VM run the server and then using ACME generates a certificate as a classical HTTPS server, and you can access it right away without the tofu. Pattern, Next slide. You also have URL multiplexing. So let's say you have several VMs or containers on the physical host. We could put a reverse proxy in front of it and do multiplexing based on The URL or based on the user, or based on the SNI, for instance, next slide. You have HTTP authentication. So with that, you can simply implement password of of a wiki authentications that are used with, SSH 2 next slide. You can also do, certificate based, client authentication. But you can also do more. You can use, for instance, OpenID connect without middleware stuff. and any Which is widely used. And you can also think of maybe a SAML 2 or slide, maybe We're both in or Baski's. Next slide. And finally, it fits well how the internet is evolving. It allows SSH to benefit from the thought of"
  },
  {
    "startTime": "00:14:03",
    "text": "the I the that the IETF has has put during the the the previous years to deploy develop the protocols such as, quick and TLS. And so it can use all these modern features next slide. So what about the threats So there is one here. TCP only networks. So SSH V2 runs on top of port 22. It's, quite well supported on the internet HTTP, tree runs on UDP port 443. It's less well supported, so it might be blocked by default in many networks. So there are ways to mitigate the problem We could use TCP as well in addition to UDP. By, running as a stage of our HTTP 2. There is also the recent quick on streams proposal, which is for posing to run quick over TCP. That might be interesting as well. And, we could also run SSH of a web transport that supports both quick and TCP So it it uses both for us, and so we don't have to bother too much about that. Next slide. And so, yeah, that's that's it for me. So now I have a couple questions for you. So is that work interesting? Does it ring a bell If it's interesting, what would be the best outcome for the proposal Would it be a natural SSHV3 candidate in the, the future, of course, we need, implementations that work well before thinking of any of that, but still, should we integrate it to another existing protocol? Know that mask is already doing the all the UDP IP for wording stuff. So we might think of a new mask methods such as connect shell or connect process, or maybe we could think of other designs. Anyone interested to collaborate on the draft, I'd be happy to have any person that wants to collaborate via co author provides feedback to make it better"
  },
  {
    "startTime": "00:16:03",
    "text": "And is it interesting enough to integrate an existing working group or start discussions on the list or anything. So let me know. If anyone wants to implement and interpret, let me know as well. It's quite easy to implement because it's only the connection protocol to implement on top of HTTP tree. So if you have access to an H3lib, with alerts, or quick, it will work well. It's interesting enough that we have a bit of a queue to discuss, so maybe we should move on to that. Sure. My my my shift is 1st. Mike Bishop Pacima editor for H3. So I'm I like the general direction. I'm a little cautious about trying to do an something on top of HTTP and then reach down into quick. I think web transport might be the better path forward there if you're going that direction. I also kind of wonder if you still need the, the TCP connections when you're doing something that might already have mask on it, Okay. that Well that's stuff can be worked out later. That but As far as the dispatch question, Yes. Yes. I do think that this is squarely in the ITS remit. I don't think there's an existing working group that would contend this. So this is probably something down. Have a boss on, see if there's enough impetus to spin up a working group. Thank you. Mark Cunningham. Hi, Mark Nottingham. Long time user of SSH. Very happy to see, more being put into it. I I question what the utility of of putting it on top of HTTP here is of the list of advantages said you were getting almost all of them are just from using quick, not from HTTP. And especially if things are downgraded, tohtv2orhtvone, which can happen because remember, HTTP is a hop by hop protocol, you don't get any of the advantages you're looking for, really."
  },
  {
    "startTime": "00:18:00",
    "text": "And so I think, like, Mike, I would be looking at other things like web transport or other things I don't think that's a reason not to do this on the dispatch question. Yes, yes. Yes. This sounds great. But really question the need to go over HTTP and and just at a higher level, maybe, for this community, we seem to be more and more needs, or, oh, let's put that over HTTP. And while that's great for my job security, I think we really think about that architecturally. So to the dispatch question, you would point to a boss also? I think a buff would be fine. Okay. I the Thank you. I don't have strong opinions on particular path path path path path path path Great. Great. Tommy Poly. Heather, thank you for sharing this. Yeah, definitely interesting work. I I think we should consider this. I think as people have been leaning towards, BAF would make sense just to figure out what shape would be right. If you are doing it, over HTTP as you've suggested. You're right there to, like, very similar to mask. It doesn't really fit in the charter of mask. Because it's not really proxying in the same way, But, you know, if you're doing that, we should have definitely review from community in there. We also have other things going on in the HTTP BIS working group. Of, like, connect TCP, of, like, modern versions of also doing the similar thing. So we want review there if we're going that direction I think also the points about web transport are interesting. So let's let's have a buff and try to maybe talk about, the different ways you could spell this and figure out which one makes most sense. Sounds good. We're gonna need to close the QFX figure out how to do that, but, David's Ganazi is next. Hi, David. It's Kenazi, putting stuff over HTTP enthusiasts. I'm really excited by this work. I actually see good reasons to put it over HTTP personally, run SSH through our load balancer internally with Connect, and this could be much better. But specifically to the dispatch, question. I think this is large enough to warrant working groups, that would be very supportive of a bot."
  },
  {
    "startTime": "00:20:04",
    "text": "Thank you. Christopher Allen. Yeah. So I share some of the questions of, you know, everything over HTTP, Although I think that's it's not unreasonable. But I also feel like, you know, we've kind of waved our hands at the age off side of things. I just have a lot of questions about using the same keys for SSH developer usage in some of the peer to peer things that are now troll and easy with SSH that are hard with, HTTPS. So I'm hope I'd like to see this as a boss, but I would like to also either know that this is only gonna be focusing on transport and, you know, sort of making a better layering for off authentication. Or that they're also gonna key usage and all of that. Thank you. Thank you. Great. Thank you. Ecker. Next. Hi, Erica's Corlot. So, you know, you're definitely singing my song about having one transport that's good. And I think if you were designing SSH this would like clearly be something along this angle would clearly be right. I the problem is we're not designing as I should have described. There's huge deployed base of SSH. a And so I think the threshold quest and so I agree with people who said that there should be a boss, to, we're gonna do this, but I think the threshold question for that BAF, what to be Are any people who are currently deploying SSH at scale, including the, like, big SSH clients? Interested in doing this because we're not an IETF producing something that says you do SSH ever quick is kinda, like, not gonna very far. So, I think that the the ISG should determine, prior to proving this BAF, whether or not that is in fact the case, because having a BAF wouldn't let no one wants to do it. It's still So if if if, like, you'll wanna do it, then fantastic when people don't, then we probably should not. Okay. Okay. Martin, thank you."
  },
  {
    "startTime": "00:22:00",
    "text": "Thank thank you. I mean, there seems to be pretty pointing pretty clearly toward a BAF. We do have 3 more people in the queues. So and we're about out of time, but but please go very quickly, Alex. Hi. I'm Alex Jahowski, Google. I'm also one of the maintainers of Mosh, which is I think the first use of an SSH like thing over UDP And I wanna say that I'm very excited in having this work move forward. There's a bunch of feature requests in Mosh that would be solved by this work by people basically wanting the benefits of UDP transport. Along with the reliable streams of TCP. So I think, definitely we need to move forward on this. I have lots of evidence that users want this and would deploy this, including Google internally users of Mosh. So I definitely wanna see this move forward. I think a boss is fine. I also think mask is fine, but we definitely would need to do a recharter I think that the question precedent. We need the TCP callback. We need all these things to work k. Thank you. Richard Burns. Hi, Richard Barnes. Just a quick question. I think both is the obvious answer, a plus one on that. I just hate it every time we dispatch something to a buff that takes another 3 months and we waste all that time. So let's I'm I'm looking over at, you know, the various ADs. Like, let's please keep this, moving and have a virtual buff in between the ITS. Sounds good. Thank you, Martin Thompson. Yeah. Martin Thompson. I think Christopher mentioned this, but I think the the the the question of do we do transport or do do we do support and all the various authentication options, might turn into a bit of an active nuisance. So, I I suggest that some some work be done ahead of any boss on refining the scope a little bit, so it's very clear what any working group might be working on because I think the the plethora of options that were presented to us, isn't, isn't, likely to to cause failure more than success. Okay. Thank you. So I think the, strong consensus here is for Bob. Thank you very much. And, we'll we'll move on to the next presentation."
  },
  {
    "startTime": "00:24:02",
    "text": "I neglected to acknowledge our 3rd chair that's, remote Rafat, who is, was here also and, contributed a lot to this and also to our other chairs that, that aren't listed, which are, Daniel Gilmore and, Martin Figueroa. So, thank you to all of them. So next presentation is, Andrea Vescow. next Yes. Do you hear me? Yes. We can. Hello, everybody. So I'm going to present, preliminary work. I prepared with my colleague, to Purugenie on the use of the very fiber credential as a a new credential type for authentication transport layer security. Next slide, please. Yes. On. Okay. Just just to set the ground, very favorable credential is one of components of the sense of related entity, the is a decentralized model for digital identity in which Of course, the entities have control over the information they use to prove who they are and the, identity in this model comes sees of 3 main components. Of course, a keeper the centralized identified it is a URI to essentially an address to, DLT where the public keys is for and at least a verifiable credential that also contain a link to the DID of the of the identity. And both VC and DID are at the full specification in W3C. And, of course, they are are, evolving Next slide, please. Again, just to set the ground, an entity, that want to be his home,"
  },
  {
    "startTime": "00:26:02",
    "text": "says Serena entities start with the creating is public key and secret key, the keeper, then, he's going to store the public key Uh-oh. He froze. Oh, Frows out here too. Yeah. President Okay. Andrea, are you back? We don't have any audio from you now. Uh-uh. Click the present. He off he's Okay. Well, I think we're going to Move on then. And, hopefully, Andrea can get his con connectivity issues, resolved, and, we'll, We'll come back to that. Okay? Do you hear me, though? We hear you now. Okay. So sorry for that. Okay. Good. You're please continue then. I received some Please Yeah. So sorry for that. So we were, deploying an entity, so the public key on the DFT. And then at that point, can request a very fiber credential to one of the issue in the system. And that point today, the entity can authenticate with a verifier"
  },
  {
    "startTime": "00:28:01",
    "text": "to get access to to servicing resources. Next slide, please. And all these authentication works today, essentially it's a South integration occurred at the application layer for the client side So Uh-oh. Happened again. That's unfortunate. In any case, While we're waiting, Christopher Allen, why don't you, go ahead and Yeah. So, this hits a lot of my keywords. Go ahead and see back. No. Okay. Anyhow, you know, there is a spice, charter being circulated for a boss which is talking about verifiable credentials there's lots of stuff going on in the DID verified credential world in the W3C that doesn't map to the IETF very well. Know, I really wanna see some stuff here. To resolve some of these things. I'll even admit even though I'm an invited expert and, co author of the DID spec and W3C verifiable credential spec that, you know, doesn't work with HPKE doesn't work with some other IETF patterns, etcetera. That, this is, you know, this is the beginning of a big important pile how to untangle it. So I just wanted to throw that out as a as a So so This is an important topic, but don't know how to do it. So toward the dispatch question, what how would how would you presume that IETF should take this up. I don't know if if it's maybe it's boss"
  },
  {
    "startTime": "00:30:00",
    "text": "I'm not sure. It just feels like BAF usually has more of a charter before you do a BAF, and this feels like this may be maybe really needs to be multiple buffs. I don't know. I don't know off. Yeah. There there are different sorts of bobs. Okay. Thank you. Andrea, you're are you're you're back? Yes. Okay. Did you wanna continue, or we've got several people in the QA? I I can we can go home, just to the next slides, and we can arrive to the point is that essentially when you have the, in specific domain, like the IoT domain, the use of Xf509 certificate is not forward. And in these scenarios use SSI, can be a very good for many there are many pro just, like, as some example, the endpoint can update rotate its key pair without the need of refreshing the ABC. The the endpoint can also revoke immediately. It's the idea and the identity. So in this domain, the idea of using SSI can be a good liaison, and so if we have this kind of identity, why not to do, authentication directly at the TLS layer. And this is exactly the topic of our ID. Next slide. And what we are proposing, essentially, to add a new certificate type called Vucey in addition to weeks 509 and wrote public key in the existing client certificate type and service certificate type extension, add just a new extension called DAD methods that the endpoint used to transmit the list of the demands to supported by the endpoint to resolve the the idea of the peer And in case certificate type, he selected"
  },
  {
    "startTime": "00:32:00",
    "text": "in this case, the certificate message will carry of course, the content of the inside the the the message. Next slide, please. This is just an example of a food in in shape with the very fiber credential where the client, proposed to use verifiable credential of 509 in certificate server certificate type and client certificate type. And then in for discover about the DAD match that key can use to resolve the DID of the server and the server can then select in this example for example, the the the verifiable credential, to proceed with the authentication. With this very simple, extension in, simple, use of this server certificate type and client certificate type, We can also have hybrid and shake So next slide, please. Okay. I think we're getting enough detail here that We have in the queue with opinions about dispatching several people So, can you wrap up? You to the last can go slight, sorry. The the previous one, So what we have already learned during the previous IETF. First of all, the the TLS working group say that application or domain specific extension to TLS at our scope, and we perfectly understand the reason behind this, the the working group usually only consider extension to Proto that that are widely applicable, why, the same in this case, we are targeting the IoT domain, We also have some discussion with the youth working group there is a possible interest there. But, of course,"
  },
  {
    "startTime": "00:34:04",
    "text": "the extension are out of scope. And so we are here just to listen to your suggestion if, first of all, you are interested in, this kind of work and what are the possible venue to continue discussing the idea. And thank you very much. And sorry for the disconnections. Okay. Thank you. We're gonna close the queue pretty quickly. So if you have something to say about please join the Queue, Hannes, go ahead. Hi. defining or adding a new value to this For registry that defines these certificate types, which this proposal does it's you only need a specification. And ideally, that specification should be done in an organization that actually works on these verifiable credentials, So I would just do that in the received, right, the specification alongside of the group who I'm I'm not a w 2 c expert. Already works on these verifiable credentials and does the work there. If someone Does something similar for things like CWD and and JWDs as it would be for example, in in in spice, then clearly there there is a potential home it was not proposed there and was not discussed. So purely speculation. It looks pretty straightforward to me. Just add a red entry to that registry and then Okay. Thank you. Ecker? I I changed microphone, so we'll see if this one's any less terrible. Good. Good. Okay. So, as As Hottest indicates, if all you need is a code point, then we don't need, that you don't need to do anything, in TLS because all you need to do is is is as long as specification can render 1. Well, I can't help to allow something to fix that separately."
  },
  {
    "startTime": "00:36:02",
    "text": "The, However, there really is only one place IETF right now this could go to, which is TLS, which is the only places really empowered, like, make new code points for TLS other than just doing it yourself. So, I think probably the answer here is to bring it, and I'm also somewhat concerned do some questions in the chat about whether or not the blinding to TLS is actually straightforward as people seem to think And so, I think this really does have to go to TLS. And then if there's no interest, then you should just register off. Yeah. Okay. Thank you. Richard Barnes. Hi. I'm Richard Barnes. I would like to dispatch this to the future. I I think that, like, Eric and honest are totally right that places should ultimately end up as as in TLS or as a private registration, but I think the VC space is just Too unsettled right now, to to do things, in in the IETF. There's a bunch of, several, you know, multiply defined non interoperable stuff, and we just need some time for the space settle down and get some deployments first before we start, defining these good points. One once that settling down has happened, I think it'll be straightforward as as Equinhaunas, pointed out, and we'll just do it in in TLS and it'll it'll go. So if you're gonna dispatch it somewhere today, I'll send it to TLS. But I think we we should hold off a little bit before we do Okay. Thank you. Thanks, Wes. Wes Hardaker. I see. I'm not quite sure exactly where it should go. I kinda like the future idea. And specifically, wherever it ends up, I think that there are multiple of spaces that are working on this now as as the one of the chairs of the dance working group an example of there is some overlap in the solution space. So it would be good to see a a comparison of why you're not following any of the existing work in various places. And, you know, how can it be married and what is different and things like that in order to get a decent evaluation Okay. Thank you. So I think the My reading of the room is roughly that, this goes to"
  },
  {
    "startTime": "00:38:03",
    "text": "TLS, if it's, in fact, ready to come to IETF at all. Okay. Thank you. Next next presentation is happy eyeballs version 3 with Tommy Poly. Can I get my if we can figure out how to create If you can do that, Okay? You need to that Do you do in q I'm seeking is it Grant preload. That's from don't Yes. Got it. Well, Well, you need to join the yep. I I am Alright. I will just say next slide. Hi. I'm Tommy Poly, from Apple, and I'm gonna be, co presenting with, Nidi Jaju, who is on the Google Chrome team. And she's remote. So I'll just give a brief introduction to happy eyeballs as it exists, and then Nitty will take us through, why we need a new version and questions about where this should go. Next slide, please. Alright. So happy eyeballs. It's, a funny name if you haven't heard of it before. This is an algorithm on the client that The reason for the name is that it's trying to make the user's eyeballs happy when they're loading a web page in a browser or doing some other type of interaction by making the connections work quickly, and get to servers that are actually working. Next slide, please. So the context here is this came from, handling the transition from ipv4 to ipv6,"
  },
  {
    "startTime": "00:40:00",
    "text": "on various networks, and it's based on the assumption that, IPV 6 is the more desirable option that you want to use. It's a way of racing different options you have. One of the main reasons to prefer ipv6 actually is that it does perform better for clients. So, Next slide. There are a couple different reasons here. Is not necessarily intuitive, But because we are going through fewer nets on various networks, that, ends up being a better experience for clients We also have, we see a strong correlation between V Six routes and having more optimized servers and better server locations. And so it actually makes the experience better, We have better routing, but also V Six is you know, the future that has been coming for a very long time. So, we want to use it. Next slide, please. But, of course, we can't always use ipv6 even if it's available because sometimes it's broken, and that was the whole reason for motivating happy eyeballs in the first place. Next slide, please. So there are various things that can go wrong, servers, can essentially be available on V Six, but be broken or slow. Networks can offer UV connectivity, but they may have middle boxes that slow bings down or actually break connectivity But one of the insights that we get from happy eyeballs overall is that choosing just one address and trying to make an connection to that and waiting before you ever try anything else that you have as an option. Is a bad idea. You're more likely to run into an issue, and this actually extends to things beyond just which IP address you wanna connect to of a server, but all of the other options you have, banking on just one option working doesn't work very well. Next slide. So I'm briefly going to go over what the v 2 algorithm is. So it essentially has 3 stages. We, do DNS queries asynchronously sort the addresses, and then we erase connections. Next slide. It won't go into detail here, but, essentially, clients will do DNS queries figure out what available addresses they have,"
  },
  {
    "startTime": "00:42:02",
    "text": "A and Claudine, they do this all in parallel, and they have an algorithm for how to, get, wait for the answers to come back. Next slide. The step is that we do sorting. There are existing RFCs on this. next But we also use historical, information and add a preference for ipv6 at the front. Next slide. And then finally, this is one of the key parts. Happy eyeballs is about race and connections. And so are different connection attempts going on in parallel, but they're not all at the exact same time, they are a staggered parallel race. You choose your most preferred option, then you choose the next preferred option after a delay that's based on the round trip time of the network. Next slide. You can look at the this in detail. These are some numbers that we've shared before in mapraging and other venues, But overall, we find that happy eyeballs does a great job of helping us use V Six when it is available. And when you have networks and when you have dual stack hosts available, but we also see even when all the stars otherwise align, a stack that's doing happy eyeballs v 2 will end up using v 4. Around, like, 7% of the time globally. So we do still see brokenness out there. So it still matters to do this. Next slide, please. As a sidebar, There's some discussion that's happened around happy eyeballs that doing this type of racing can hide brokenness in middle boxes, etcetera. We believe that's something that doesn't belong in the core algorithm document, but is something that should be addressed and discussed somewhere within, IETF about how can we do better reporting for errors? Next slide. Alright. So that takes us to why do we need a new a new version? So, Nidi, go ahead. Yeah. So I'll talk about version 3 of the algorithm. Next slide, please. So why do we need a new version? There have been lots of changes to DNS and transports in the ITS space since version 2 was published in 2017, including"
  },
  {
    "startTime": "00:44:02",
    "text": "this new protocol that you might have heard about called QUIC, which was standardized 3 years ago, and more widespread use of it, increasing deployment of ipv6 only networks, standardization of new types of DNS responses in the form of SE SBCB and HTTPS resource records last year, that provide information like adjustments, service priorities, and support protocols, an encrypted client, hello, or ACH is being worked on in the TLS working group. Next slide, please. So, the updated algorithm follow the same overall phases as the previous version Tommy talked about earlier. Next slide, me. However, there's slight tweaks to incorporate the new additions which are bolded. When we, asynchronously, query DNS, we now query for SCCB records in addition to the AAA NA records. Placing SVC based responses first since they provide better hints about address families ECH, priority, and protocol support. There's some additional considerations incorporate, prioritize SBCB based responses in the rest of this section as well. Next slide. So the sorting algorithm for the addresses stays mostly the same, except for the addition with the addition of ECHPs, SCCB priorities, and ALPNs if they're present, we prioritize these ahead of the other criteria to maintain security while respecting priority signals and protocol preferences. Next slide. And finally, when making a connection, the previous version raised attempts until the TCP Hanched completed, but this meant that we might have ended up with a broken or slow TLS handshake, where another 10 point of succeeded sooner. The updated algorithm, we raise connection attempts until the full handshake complete whether that's TLS over TCP or quick Next slide. So there's a lot more detail on slide, which I won't get into now, but as you've seen, we're generalizing the algorithm to for quick capable endpoints due to the benefits that quick provides, including"
  },
  {
    "startTime": "00:46:02",
    "text": "improved delivery, congestion control, and connection migration. Next slide. We also included several considerations based on UCH to maintain security. We still have some open questions regarding reasonable in this area based on clients being SBCB optional or reliant. And when it's okay to start a TCP handshake course and decline hello. Next slide. So this brings us to the dispatch question. Where does this work belong? We started with B6 ops at the last IITIA, as that's where the first two versions of happy eyeballs were developed. However, as you've seen, there are many areas that are involved in this version of the algorithm we'd like reviews from, including ipv6, DNS, quick, HTTP and TLS. Some options that have been suggested are contrain continuing in basic ops with with reviews from other groups, Moving to TSBWG as it's a more general transport group, or forming a new working group in what area focusing on client algorithms and operations. So we'd love any feedback about the best place for this work. Thank you. Okay. Thank you. And, we have a queue starting, Bob Hendon first Hi, Bob Hindon. I support this work. I think it's important. Have a strong preference Whether it's in V6 ops or GSV working group, but I think we should do it. And it should get dispatched somewhere. Thank you the rental committee. I I also support this work. I think it should not go to v Sixops. Think while while it while it grew out of v Six ops, it solves a plethora of other problems and has a variety of hard to predict implications. Like racing stuff that's a secure security sensitive potentially"
  },
  {
    "startTime": "00:48:00",
    "text": "is something that V Six up is really not qualified to to talk about. Right? And, you know, racing quick against HTTP. What are the consequences for I mean, I feel that it belongs in some sort of transport working group, So, yeah, not not in v six ops. That working group should also carefully consider Again, these consequences, and I I would also caution us to Keep in mind that the performance advantages obtained by this protocol And the fact, for example, that it uses ipv4, some percentage of the time may not be because it chooses the best path. It may be because it's just reacting to random pack loss, which could cause, you know, the the second backup attempts to be preferred just because, right? So I think that is something that really sort of try the folks are, I think, most qualified to talk about. To And, yeah, this isn't, you know, not I think this position of saying oh, yeah. You know, this is, you always need to race is a bit simplistic. The the other the position of saying, oh, yeah. Well, we 6 works. You can only try one address is also simplistic. But, again, transport is is is the working group that is most qualified, I think. Thank you. Hey, Jen. Yeah. Thank you very much. I just threads draft again, I really like the changes you've made. I even sent you some comments because I got confused with your hub process. I sent you just an email. Anyway, I think this definitely should be done. Right? Regarding groups, I understand Lorenzo concerns, but I also see a lot of things which do belong to V Sixops. So maybe maybe you really need a different working group or intake or, like, Oh, some place when all interested people come together at work, and I do not see it really matters. Which rooms those people are sitting. But for example, one very important think I think we need to discuss is what happens when you have a dual step device on the network with DNS 64"
  },
  {
    "startTime": "00:50:01",
    "text": "Do you want that to prefer, synthesized records and goals through the not 64, or you want them to prefer the 85 pv4? Right? This is something it's a fundamental question. Right? Do we want to do all step devices? Still used before natively or fake V Six. Right? I don't know the answer. I think it's something we shall discuss. Alright, Ted. Teddy. I think the dispatch question here is best answer by a new working group. It seems that there's a good bit of overlap but it's overlapping different working groups and in different areas And the only way to really bring that together is to get a new working group and assign advisors from the appropriate areas and encourage people to join it. Thanks very much. Thank you. Hey, Ralph. Roughly back on my I thanks for this. I mean, in the IPF. I'm certainly would like to work on that, and I think it is belong somewhere don't have a particularly a strong preference, but as That said, there are multiple kind of, avenues that are pursued here, so maybe a new working group is a good idea. K. K. And Pete. P Resnick, just a voice, what was, discussed in the chat room, a short recharter for taps might be interesting. You know, I think the comment that transport people need to be in on this discussion is exactly right. Somewhere in that area would be fine. Doesn't matter where whose charter you add it to. Or as Ted said, a new working group may be one of these short, you know, quick working groups with single topic is fine, but something that gets this done quick would be good. And, since we've got time, Warren, go ahead. Thanks. It's not actually related to this. Lauren Kamari Nakmanki, Could whoever's got the access point called ZTP under call 435-119. Please turn it off."
  },
  {
    "startTime": "00:52:02",
    "text": "It's using 160 megahertz, and it's over there somewhere, and it's killing the wireless. Okay. Thank you. Once you get the same. Yeah. Okay. So we lock the queue, and, we hear support and the interest sure? For this work. And, some clear comments is not a ops. And, we hear more about the ported to have a new working group that's working group might cross areas, so we need experts. For sure, the transport error needs to be there. Yep. So the winter area now. Yeah. Cool. Thank you. Alright. Thank you. So our nets the speaker. Hear his item. Oh, as you walk me through No. K. David Winkley is next. On large cigarette. Warren wasn't joking. So somebody here has a trouble Wi Fi access point that is screaming louder than all the IETF access points, and which is why this whole section of the room has no Wi Fi. So if you have a CTE travel Wi Fi box please do turn it off. Would Hey, folks. People can hear me alright? Yep. Yes, please. Sweet. Alright. So, hey, everybody. This is my very first IETF. I'm really excited to be here, or at least here online. I wish I could be with you there in Australia. While it worked at places like Google Facebook and now Capital 1, I'm here presenting without affiliation to any of those institutions. My personal opinion is that email misdelivery is an actual and not hypothetical problem. Unintentionally happens nearly all of us. This proposal addresses a real problem that is did for 45 years in email, there's a clear analogy"
  },
  {
    "startTime": "00:54:01",
    "text": "postal mail handling and all involved party's benefit from having a standards based approach to resolving the problem. Next slide, please. So here is a real non theoretical problem. What can recipients do about misdirected email? What you see on the right is an actual email I got in late December. I get maybe 1 of these a week, sometimes for a Diane weekly, sometimes for a Jeffrey, sometimes for a Doug. Some would mark some would argue that I should just mark the email as spam because it the sender's responsibility to ensure that emails are sent to the intended party and should be double opt in a user to make sure that they only send email to the intended recipient for a given account. While there's a grain of truth to that, there's also flows that make it much more challenging to verify an account holder's correct email address such as if a user wrote an email address a sheet of paper for signed up for sign up or faxed it in. And, yes, that's still a thing. Or a representative took the email address over the phone. Now in this situation, the sender is legitimate and otherwise has proper mail sending hygiene with correct ARC, D Mark, SPF, and d him. What it doesn't right, because it's not a subscription list. I have no standard way to tell the sender that they've got the wrong person for this account. And I really would rather not spend an hour on the phone with the sender try and get them to update the records. It would be nice if there were, like, one click on subscribe a simple way to just tell my male client to tell the sender that they got the wrong guy. Next slide, please. So postal mail solve this about a 100 years ago. You probably get misdirected postal mail all the time. The post office knows this. As part of the definition of 1st class mail that they'll transit the letter back to the sender if there was an with delivery. And one of the issues with delivery is there's no such person at the address. So you bounce the letter back to the sender, and hopefully that kicks off a process. Whereby the sender can attempt to find a better address for the recipient or another way to get in touch with them like a phone number. Next slide, please. The question is this. What if email had a wrong recipient notification?"
  },
  {
    "startTime": "00:56:03",
    "text": "It would need to be user initiated via the UI. This wasn't meant for me. It would probably need to only show this if the UI was confident that it wasn't spam, that the message wasn't spam. This is mostly for a B2C, where you often see email addresses of the sender as no reply yet. The human rights to you, and it's misdirected. You can just write back to them like, hey. You sent this to the wrong person. What I like about a proposal that gives an wrong recipient notification is that this benefits the wrong recipient who will, in theory, no longer get the emails not intended for them. It'll benefit the sender because they might accidentally be transmitting PII to a third party, and it benefits the correct recipient because they finally get the email that was intended Next slide, please. So let's say we craft some sort of a return path for misdirected emails, could call this a wrong recipient flow. What? What is this option? What options does the sender have if they get one of these notifications? The first is that it's likely that they have the wrong email address for the user. So they should make a best effort to verify a correct email address. They could use a phone call, a text message, postal mail, email, prior addresses used, send a push notification if the user has their app installed, or even show a message in the app or web experience that they need to update and confirm their new email address. And they may wanna stop sending emails to that known bad address for the account. Note that this is different than a do not email indication user may have a separate relationship with the sender for a different account that is correct. Of course, and as noted earlier, if the center validates the email address mapping to an account, this will mostly be avoided. Next slide, please. Cool. So if we that email should have the same. No such recipient capability as postal mail has had for Century What are some ways that we could implement this? My thought was to mirror that has been seen in Rfc8058 deployment. In only a few years, it has so vigorously become best practice that the major mailers this quarter"
  },
  {
    "startTime": "00:58:01",
    "text": "are going to stop carrying non 80 58 compliant bulk email. Just like 80 58, my proposal has a simple post to a sender provided and sender validated URI. With the client never sending any cookies with the request. For offline use or SMTP only MUAs, the standard could support using a mail to URI. Much in the standard has been drafted with an explicit intent of being a close cousin to 8058. Indeed, one of the 80 58 authors has been helping me with the proposal. Next slide. So here is the proposal. It's actually, in its essence, completely contained in this page. There's a header that senders include for wrong recipient notifications And there's a post to that address by a mail client when the user indicates an email has been misdelivered. That's it. That's it. You'll notice here assigned URL, but there's explicitly not included in the standard recommendation on how to sign the URLs since it's it's only the sender who needs able to validate it. The client just blindly posts to the provided post body and nothing else. Next side, That's it. Thank you so much. I really, appreciate your attention. I'd love to know how we can dispatch this best. Okay. Tobias, first. Okay. Tobias, Flag, are you here? To be a solution, max planck Institute for informatics. So I Personally, I'm not sure whether this Draft, is just adding another version of NDR. I mean, you mentioned NDRs, but technically, it's just encoding a user interfacing based on NDRs because technically we just send an NDR the return policy, and people would just be required to actually do some kind of handling for return process emails, which, I mean, if operators like ESPs would pick that up that might actually also have other benefits So your answer to the dispatch"
  },
  {
    "startTime": "01:00:00",
    "text": "and and actually not sure whether we have something for that at the moment. Okay. Thank you. Trump? Thanks. Does my audio work Yes. I got you. Yeah. I'm the author of 80 58 that you referred to. And indeed, the one click up unsubscribe has been successful enough Excuse me. That that many large mail systems now mandated for for bulk mail. And having talked to some of them at Vaughn, I think we're interested in this too. So, I think we should do it. I think the obvious place to dispatch is assuming the mail maintenance working group gets spun up in the next month or 2, which seems likely it should go there. Thank you. Wrong, Sorry. Busy taking notes. Yes, I definitely think Mailman is the right place to dispatch this I think it is one of many things. There's been discussion of a more general trust and safety response, say, this this message is something I subscribe to and don't want, which is the list on some scrub version, but also this is something I didn't subscribe to. Something that you might want to say back. Or say there's something else wrong with this message. And so a more general feedback than just adding a new header for each new case we come up with and having a general feedback and then a defined set of things you can say. Well, the problem with this message in the post body is we probably want to solve more than just this one problem at once. With this and extend list unsubscribe. Just on the previous dispatch as well, there was a thing in the chat that said that we should dispatch it to every working group and see which one takes the work for happy or or both. Just wanted to throw that out there. Happy draft. Christopher. Yeah. I'm I just So I like this. I think, you know, having it go to, male maintenance isn't you know, isn't a bad idea, but to a certain extent, this is simple. It's following a"
  },
  {
    "startTime": "01:02:00",
    "text": "successful pattern with 8058. Can we just send it to an area director to to basically, you know, do one of the bidited RFC, things, or at least in information craft so that people can start saying, yeah, that's good enough. We'll we'll, you know, we're we're already implementing 80 58. We'll implement as well. Rather than waiting 6, 9 months a year or whatever for this to to go through, a working group that doesn't exist Funny, you should mention the area director. This is Murray, the area director you're talking to. Think that the right way to do this is to send it to Mailmate, which is currently in the process of hacking out its charter before. It'll should hit the next tellet chat on 44 so it's probably gonna go that way. I have no interest in sponsoring another document. Especially since there's a working group coming that is in which this falls very clearly. Her, Scott Fuller. It's Scott Flores Systems. I would not want to give have it are rushed forward because there may be some security implications about allowing somebody to send this arbitrarily unauthenticated, wrong email address. Needs to be thought through. I was, a working group would would be fine. I don't I would I wouldn't go through an area director directly. Thank you. Oh, okay. Thank you. So And the way here support. And so, maybe more discussions in, male maintenance working group to have more feedback And also, we have suggestions to, like, share it to more areas. And to get more feedback. Okay. So next It's a remote presenter. Sure."
  },
  {
    "startTime": "01:04:01",
    "text": "Shannon, are you on the Call? Yep. Right here. Correct. Correct. And Christopher Allen will be joining for, any comments, questions, set her. So My name is Shannon Apple Klein. I'm with a Blockchain Commons. We're working on creating infrastructure that's open interoperable care and compassionate. Next slide. So date is the heart of the internet, but still the wild west. There's two controls on how it's shared or re shared Data privacy is all or nothing. 1 state has breached. It's out there. Being shared with a little concern for human rights. We need to make the internet more humane. Next slide. We have 3 challenges the first issue is that data is not minimized. Interactions involve more data than is needed. And even in the face of regulations, such as the GDBR Next slide. That becomes even more problematic when data gets out there. You can combine 1 batch of excessive data with another. And suddenly, you know a lot about the data subject. Next slide. Worse, when you have lots of data, you can use it in ways totally orthogonal to what was originally intended. Might have given your address to receive the shipment of vinyl records, but when that gets correlated the financial data, provided to your bank as KYC. Suddenly, the burglars are knocking at your door. Our rather pry bar in your window. Next slide. These challenges are all cumulative, More data disclosed means more data correlated means more secondary use means more problems. Next slide. Where's the amount of data being collected? It's growing every year. It's more sensitive and it's more often placed online. We show some activity trackers here. I have one on my wrist. They're a great example. They can record where you are into a certain extent what you're doing How can we protect data that sensitive? Next slide. Digital identity is the next big frontier. It's really coming of age right now with DIDs, MDLs, Idis,"
  },
  {
    "startTime": "01:06:04",
    "text": "But it's been around for a while. I shockingly discovered I have 410 online accounts that contain a lot of personally identifiable information. If that's all correlated, Everything about me is out there. Next slide. Honestly, though identity credentials, health care, they're just the tip the digital by iceberg. How much information could a competitor gain if they accessed shipping records? How much espionage could a foreign country commit if they tracked the executive offices fitbits how much trouble could hackers cause if they broke the chain of identity and software releases? We need to get in front of this now. Next slide. So IETF has some solutions. RFC6973 and 8280, which talk about privacy and human rights considerations. Next slide. 6973 talks about privacy. And the design of Internet protocols Next slide. 828 expands that with a look at human rights considerations such as open secure and reliable connectivity. Next slide. Unfortunately, these RSCs are not enough. Because they're not concrete. And more importantly, because they're just considerations. They're not fired, fired, they're not being used. Even if they were, new privacy innovations and requirements have appeared in the last decade. RFCs are dated. Next slide. For example, take a look at 6973. It's first three recommendations for privacy are to incorporate anonymity. Pseudonymity, data minimization. Next slide. Shannels. Excuse And then you got to, a lot of slides me. And, so please focus on the, this best question. Yep. Yep. We're gonna get to what we're doing and then wire questions very quickly here. So Bitcoin's an example of why pseudonymity isn't enough I mean, we've seen you contract information through it. Next slide."
  },
  {
    "startTime": "01:08:00",
    "text": "Meanwhile, data minimization, though it's definitely a foundational requirement. It causes causes problems with some of the human needs, in rfc8280. Next slide. So there are some cutting edge technologies like 0 knowledge proofs instance, BBS proofs, which can deal with this next slide But we need privacy tech that's simple, well understood, and in production, but still more advanced than 2013. Next slide, We need a middle ground. Next slide. So that's where we, come to our solution, which is deterministic cash data illusion. It's that middle ground. Next slide. Deterministic means the data is always stored in the same way. Next slide. Hashed Cash means that a cryptographic hash is created for each element of data next slide. Next, And Elition means that the data can be removed. And in particular, once the data be to be removable by any holder of the data, not just the subject are the issuer. Next slide. So the format we've been using for this, with working code is a Merkel tree. There's other options. Next slide. In a miracle tree, leaves hash the date of their branch, notes hash the hashes beneath them. A root hash, which is what you're seeing at the top here, verifies the entire structure Next slide. When you lead data, you remove 1 or more branches, but the hashes validating the integrity of the data Next slide. So what you do is you sign the root hash, and then you can have authenticity even when material is deleted. Next slide. So here's some of the core advantages. Any holder of the data can choose to align data at any time. That supports day of amortization because it's suddenly easy to exclude information. But the signatures, as I said, remain valid. Next slide. A hash data elision system can go much further."
  },
  {
    "startTime": "01:10:03",
    "text": "Inclusion proofs mean that you can align parts of a tree and then give proofs leading to the aligned at hashes, allow for the verification of data even when it's not there. Her privacy takes the next step. You can publish only a root hash and give out inclusion proofs to data blocks, allowing individuals to reveal that data are not as they see fit. Next slide. I spoke earlier of the dangers of correlation, but it's actually not all black and white. Sometimes you want co to correlate, sometimes not. An advantage of determines to cash data illusion is that allows you to match the requirements of your data set by choosing a hazard method that either supports our handler's correlation as you prefer. Next slide. For the, IATF the advantages are it supports these 2 RFCs. And in particular, It supports the authenticity decentralization and integrity from the human rights RFC that we're kinda left out if you do core data minimization. Next slide. So we think it's important because can cover a whole different a whole lot of areas, credentials, data provenance, etcetera. Next slide. So, we'd love to see a support for any version of deterministic cash data lesion, but we have one called Guardian Outflow. It includes all of the fundamentals that we discussed already. It's built on a Merkel tree. And it also does additional things like encryption Encryption, operational functions, other cryptographic data, and lots more. We have a full working prototype of it and a reference CLI. Next slide. Okay. Here's our questions. Next slide. Most generally, how can we advance the start of issue. It feels like there's not a good venue, but we have 3 specific things. Next slide. First, we feel like these 2 Frs RFCs have been largely ignored. So, how can we do better on this in a recent, working group charter, we heard there just wasn't a lot of support"
  },
  {
    "startTime": "01:12:00",
    "text": "for these RFCs. How do we improve respect for what we've heard called core I ETF values? Next slide. Specifically on data minimization, how should should we create a group for it? Should it be CFRG should we run a bot? Should we join another group? And next slide. More specifically for Guardian envelope or specific implementation of this did great work with the seaboard group on it, but they ultimately said they weren't the right fit. Vimeo. Some say we should, try and work with Jose, but they do have legacy constraints. So do we farm a working group here? We take it to an area director, or do we do a buff here? Next slide. If you want more info, these are our two drafts, Apple Kleinhash Division is this this problem statement. McNelly envelope is the, write up of our envelope. Next slide. Next slide. Thank you. And this is contact info for myself and Christopher. Okay. Thank you. Paul Hoffman I you gave a list of, the chairs gave a list of possible dispatches at the beginning of the meeting. I think this goes into a different place, which is the IRS there is I've read if skimmed over, carefully the, the 2 drafts. There's a lot of statements in there about this will cause heart. That you'll get certain features and such like that that I are far outside the protocol space, I would propose this would be something, of, that, that is very strongly research and it's not just cryptography. So I would say it would be somewhere in the IRS g, and, I'm sorry. In in the IRTF. And,"
  },
  {
    "startTime": "01:14:00",
    "text": "would, interact with CFRG, but not be in CFRG. Thank you. Tobias, Yeah. So to be honest with you, MPI end, and I I would actually seconds at HRPC, maybe, might might actually be the most fitting place k. Thank you. Ecker. Yeah. So I think part you've asked a number of dispatch questions. You know, I guess, to answer the initial one, Documents you're citing were not produced by the IETF. So the fact that they're being not, like, widely moving to IETF might might might be partly due to that. The you know, there are a number of places to discuss things like this as people suggested, perhaps somewhere in IRTF, though I don't think HRPC is probably replaced since not letting meaningful first protocol specification. The, you know, this is a, a technology field that we might use. And so in terms of, dispatching it in terms of Iutf work, I think that threshold of question, as I sort of said earlier, is it anybody in the IETF want to use it or something? And if the answer is no, then it gets kind of dispatch the devinal. So, you know, I certainly don't think it should be as to any ITR for right now. And I think that, like, the next time you put out this, you should be what you should be asking is to demonstrate demonstrated, desire for people in IET have to wanna use this technology. K. Thank you. We're gonna need to close the queue. We just did. And so, Michael. Yeah. Thanks so much. Yeah, appreciate this. I will strongly concur with maybe IRTF for some of this I'm not a 100% sure exactly what was being proposed there at seemed like a whole bunch of different related things. Maybe there were some technical drafts as well that I know had found to coza and seaborne. And feedback's been given back on that. Right? So, you know, maybe let's complete the work already in progress at cozy and seaboard that has some relation and then"
  },
  {
    "startTime": "01:16:02",
    "text": "go from there and see once again to Edgar's point if there's follow on tech that someone at IETF wants to use, maybe we carry those pieces into IETF very explicitly with 1 or 2 slides. Not 41 related to a broad problem statement. So, thanks. David's Ganazi. Dave Kenazi, Internet Architecture Board. I was kind of confused by this presentation in that it started off explaining how What we have in terms of abstract properties that we want was insufficient in terms of our human rights documents or our privacy considerations documents. And then Proceeded to say And we have a technical solution. To me, that was a leap that I you kinda lost me there. So I would say if the goal is to move forward with this technology, then I don't see a need for it at this time. I don't see any protocol that, could use it. And then if that's wrong, please come back with the those implementers in mind and But If the goal is to say, oh, well, maybe we need another human rights document that has these properties that we want, then, yeah, that that should go to HRBC, but that's not what these documents are. And just like saying, you know, these privacy documents aren't doing anything. Well, if you at the decade since that the privacy 1 was published, we've done quite a few improvements to the protocols that the ATF owns in terms of privacy. So In terms of dispatch, I would say dispatched to nowhere for now until we have clear interest on what protocol should be improved. Specifically and what problem this solves. Thank you, Alissa. Yeah. Thanks. Hopefully, you can hear me. And someone hear confirmed that you can me. Okay. I agree with the the comments of basically everybody who came before me about the dispatch"
  },
  {
    "startTime": "01:18:01",
    "text": "question. I didn't see anything here that Seemed ready to to be dispatched to some place inside the IETF. And just wanted to note as an author of 6973. The point of 6973 in fact, to just provide guidance. Like, it wasn't specifying any, protocol and it was not meant to be mandatory, and that was a conscious decision. Could you be a little bit louder, Alyssa? Sure. What I was saying was that it was a conscious decision to make c973 advisory and not mandatory, because we thought that making a mandatory would just cause it to become a check box exercise that nobody would pay attention to. And instead, I think look, there's actually like a good amount of evidence of how it has been used since our in cases. There's also been discussion about updating it. So if that's something that you're sit in, definitely we'll be interested in talking about that because there's lots of things that have changed in the time it was published. But it's it's meant to be advisory and guidance and not not protocol. And I think this, it seems like the authors are after something different here. So I think the using that as the motivator doesn't really doesn't really work. Great insight. Thank you. Thank you, Colin Perkins. Hi, Colin Perkins, I r t f chair. So we we are always, of course, happy to discuss, proposals and you work in the IRTF either in the the particular research groups or directly come come to myself or the IRS g to to talk about that. As a process issue, though, I do want to remind the room that, this this group can't Cannot dispatch things to the IRTF. Noted. Thank you. Andrew Campling. Hi, and Andrew Kampling. As Alissa just said, 6973 and, in fact, also, H280 are both informational on our RFCs from the IRTF. So maybe the authors hadn't understood."
  },
  {
    "startTime": "01:20:04",
    "text": "What the purpose of those was. But, it'd be surprising if they were apply to all protocols given their informational so they make that some misunderstanding by by the 2 authors, here. On the dispatch question, noting what Colin just said. I was about to say perhaps the r I RTF would be an appropriate place to discuss the topic should the, esteemed chair of the IRTF be, minded to, take that up afterwards. Ted Hardy. Etcetera. Thanks very much. I think the the basic problem here is there there are 3 different things being yoked together, and the fastest way to get progress here is probably to unyoke them. So if you have small scale things that relates to the work that's already going on in, because they, unhoke them from the larger scale. Question and go to Jose with it. If you have large scale questions of data minimization and it affects human rights. You can talk to Cullen or to the working group chairs. HRPC, but those people can't do protocol work in the IETF just like we can't dispatch things to the RTF. So I think you've got multiple different things kind of all put together into a vision here. But the actual work needs to be taken back out and sent to the right places, and there's no single dispatch for the some of it's just frankly out of scope for the ICF as a whole. So I just encourage you to go back and break this into the chunks of work that needs get done and then ask again with the individual chunks separated out. And I think the answers will be much easier. Thank you. Do you wanna summarize Yep. Yep. Okay. So, for this work, And, it seems currently is, not clear where it should go? Oh, no. I mean, like, in IETF. So so in Probably in IRTF and, so first, to break down the work, into more specific pieces and the go to the"
  },
  {
    "startTime": "01:22:02",
    "text": "Related, research working groups to have more discussion and feedback there and then maybe come back. To here and, have more, specific feedback. Here. Great. That was all very insightful. Thank you. So next speaker dragena. Mushi Fins. I'm sad. Oh, here. You cannot insurance I think I figured out how to do, slide controls, So do you wanna control this line? maybe Jim can help you. You can log in. So I can works for firm I'll ask some clients were No. You don't need to do anything. It does start. Good morning, Dragamiano, which I'm going talk about, website and extension to disable masking, next slide. First, I'm going to explain what it is. Oh, sorry. Thank you. So first, I'm going to talk about what it is, white about it and why I think we can disable it and how to do it. So WebSockets enables bidirectional communication between the client and the server. It starts with a handshake, that is using, HTTP upgrade mechanism. And after the handshake, the client and the server can send a message. One question. Is it possible that the left side of the room also gets the slides? I would be lovely."
  },
  {
    "startTime": "01:24:05",
    "text": "Those IT guns? I don't have out of control. Go to chairs. Yeah. Please. No luck. And so, masking is WebSocket uses frames to send the the data that are sent by the application, and, all the data sent from the client to the server are mask with mask masking key, that original payload is exored with the masking key, so to to change how it looks from the wire. And mask a key is sent into inside the the the frame header. So it's not for privacy. It's just for changing how the the packets look on the buyer, how the data looks on the buyer. This adds, extra bytes that needs to set for each frame and also adds this additional processing. Not very expensive operation, but on the server server side where there is a lot of requests this is multiplied by by a lot. By masking was added. Next slide, please. To this was to protect against the pack that was card in this paper. And this picture is the original picture from the paper. Sorry for the IP addresses that are there. Was not intentional. That's it from the paper. So, to for a tax to succeed, special kind of proxies, transparent cashing proxies are needed that are, rooting the data according to the IP address, but cashing the data according to the host name. And the targets of the of the attack actually circle who is behind this kind of proxy. So when when, a user, access website, with a web resource"
  },
  {
    "startTime": "01:26:00",
    "text": "that is controlled by attacker, this, web resource can open up, WebSockets connection to the attacker.com. And, after that can send arbitrary messages, to the attacker. You can also construct a message that looks like HTTP request. This message will be routed to the attacker because the routing is done by IP address. And the tagger can respond with a message that looks like response, which is web socket message, but this looks like the HTTP response in this case, this moment, proxy will will cash this according to the hostname, which is target.com. And when the next users try to get resources from target.com, it's feel that needs to be, accessed using the In Secure HTTP, it will hit the cache and get resources out of the cache. A Next slide? So so masking was added to to change how the the the looks on the wire, so that a client cannot construct the data, that looks like HTTP request. And then encryption does the same thing, but it doesn't happen in this case. Because the attacker controls the client and the server. So it has a key can construct the message in the way that after encryption, it looks like plain text h HTTP. I can potentially cashed by, this cashing process. Next slide, please. Do we still need masking? The this study that I mentioned was done in 2011. And they found 8 outs of 47,000 pads that were affected with with this process. Also, it's it's worth mentioning that at that time, HTTP API mechanism didn't exist on the internet. It existed"
  },
  {
    "startTime": "01:28:01",
    "text": "theoretically, but not on the internet. So this, proxies didn't know how to to deal with this, mechanism. Now it's different web sockets are present everywhere. So probably most of these a proxies already learned how to to deal with, upgrade mechanism. Also that time, a lot more traffic for, plain test. And, and now they are not. So how useful this kind of, catching proxies are at this, at this moment, is also a question. And how many are obviously left. Next slide. If we look at, secure version of WebSockets, that are usually sent on the port for 43, or we can look at at any other port and then port 80, which, sends a usually gets the plain text, HTTP. That will be mean that, this transmit proxy will Listen to the connection that are usually encrypted and cache them as a plain text HTTP. Which is, considering that this Cashing proxies were actually cashing the ClearTech HTTP, it's most probably they were also only listening to the port 18. It's Unlikely they were listening to the other ports. Next slide. Also, for this attack to succeed, Clients will need to access the the the websites in in the example before, target.com using insecure HTTP, considering that there is a less traffic that is insecure now on the internet or less content that is insecure on the Internet now, And, also, it is unlikely that, client will access with insecure HTTP content that it's, that is available, using HTTPS. Especially considering that there is a techniques like, seek to transport security, and efforts like, HTTP first."
  },
  {
    "startTime": "01:30:00",
    "text": "It is also, less likely that, the clients are, going to use an insecure HTTP and and hit, poison cash. Next slide. Therefore, I I suggest, I propose WebSocket extension, to disable masking. This inception, it's using web socket extension mechanism that is already exist. So it's just adding a new token. This is an using the HTTP headers. And I also propose, adding this only to secure connections because and excluding the port 80 because it's highly unlikely that, these caching proxies are going to catch, content on the on the, encrypting ports for 43. Next slide. And when extension is negotiated, the frame sent from the the client. To the server will not have masking key. So there will be less four bytes less in the header and, Payload will not be masked. Frames from the server to the client will be stay unchanged. Next slide? So so, I'm saying you need to for this work and also the working group. I started discussion on HTTP based email mailing lists, because I thought that the audiences. Right? But it doesn't belong to their charter. So that's why I'm here. Also, I implementation of this. And, Modilla is also having, done a prototype, for this Jaft. Thank you. Mark Nottingham. Hi. Mark Nottingham. So just just to the The trade offs here, I think something to keep in mind is that whilst, yes, most traffic is now encrypted, on the web, we we still do have intercepting proxies that"
  },
  {
    "startTime": "01:32:01",
    "text": "you know, our our our intercepting TLS in in enterprises, for example, And so they can still be poisoned by these techniques. Also, I think, one of the other arguments you made was that most proxies have been upgraded. They've had time to to, you know, learn about WebSockets upgrade. My experience in operations of networks is that proxies often are not upgraded very often. And I mean on the scale of decades sometimes. So, you know, I agree that those factors do make it less likely that these attacks will succeed. Think the thing to do is to wait against what the costs of the changes, you know, of the cost of of doing the the encoding are, and and as has been discussed on list, the cost is maybe not great. From the for the dispatch question, we we asked, print here because it's, as you said, it's not in our charter. Although it does interact with HTTP in the sense that it's an attack on HTTP from another protocol, but if if the dispatch is to take it to HDP, I think we could talk to the ADs perhaps and know where the IDs are, but talk about maybe doing it there because it does seem like work like this. New working group. And unless we decide to spin up a you know, WebSockets maintenance group. Yay. That that might be a sensible thing to do. Hurun. Haran, thank you for the introduction, and based on the scenario, are you described, where clients need to access, well, a website using HTTPS to, trigger a Python on cash and considering the challenge, posed by the websites adoption of HTTPS and security measures like HTS and, a relevant question. Might be, how can And organization ensure its website remains accessible wire on 0khtps. Wait without compromising security."
  },
  {
    "startTime": "01:34:01",
    "text": "Especially in environments where, points to cash attack is concerned, and considering the prevalent use of HTTPS and security, house man tag, HTS, By the way, this is my first time attending IETF, and I'm nevertheless. Thank you. Very good. Ecker. Hi. Yeah. We should discuss this in the list a little bit. You know, I think this needs more motivation, frankly, for, before we should be thinking of doing it, that motivation would come in the form of 2 things. 1, I've demonstrated there's substantial costs associated with with the padding with with the with the masking. Given that you're already encrypting the data, and having to do AES or I think likes and measurements would be helpful. The other form of measures would be helpful. Will be demonstrating this is no longer an issue. And, you know, I think you work for a company that has a browser, so you could take those measurements if you wanted. There'll be you could replicate was done, you know, back in 2011. But I think, you know, we don't think it's an issue. What we don't know, the way we got into this hole, was we didn't think it was an issue when somebody checked. And so I think the minimum before your move to security feature was actually verified. There's no longer an issue. I do wanna make one small technical point, which is that the fact that that you think implementations are only stupid at 80 does not necessarily help because the attacker controls the web server, and therefore, they can simply do the is that we do the cash poisoning on Eighty themselves with TLS. As far as I can tell browsers, we'll do HTTPS on the 80 just fine. So, that doesn't actually help you. Okay. David's Ganazi. David'skenazi masking enthusiast. So, first, plus one to echo where I think I would like to see more motivation on this on why is masking bad? Second, to I'm not's point, of sending the"
  },
  {
    "startTime": "01:36:02",
    "text": "I would recommend to send this to the web socket maintenance working group, which is currently called HTTP this. The charter of HTTP this seems from my read to allow this. So I think we should, toss this can to the ADs to interpret the charter of whether WebSocket is maintained by GPS or not. As web transport chair, I don't think we should have a WebSocket maintenance group because it's not like we're doing a lot of work in socket. So I would recommend taking that to HTTP even if It might not. Would expect more motivation before I would make any progress in HTTPS Alessandra. you, Alessandra Gadini Cloudflare. I think An additional problem to the middle box cache poisoning thing is that there are some middle boxes that actually try to actively look at the WebSocket data and sometimes they even try to inject like close frames and I suspect that because the the sort of the negotiation mechanism for the extension would be end to end. And because These kind of proxies tend to not be updated as often as, you know, we would like as Mark Hussein, I suspect a lot of those would probably break how much that is a problem in practice is, I guess, to be seen but it would be good to to try and maybe do some experiments if possible before with the site to actually do this. And I also agree that it's with the other comments that it's not entirely clear with the benefit of not doing the math King It's, but Oh, Okay. Can you summarize Sure. Okay. So maybe more motivations and, gap analysis. To show the necessary work."
  },
  {
    "startTime": "01:38:00",
    "text": "And also, maybe go to, HTTP based 1st, first, first, to get more feedback Okay. Thank you. Next. Bingeja, Please. Okay. Good morning, everyone. This is Celine Joe from library. Next slide, please. The title is about extended and young data model for us. And here is the outline of this presentation. Let's start with the data check trends and problems. Next slide, please. Next assets. Thank you. Nowadays, the data attacks happens more about 8,000,000 did asset tax happen in the first half euro 20 times 3, which has, 31% increase year over year. Next slide, please. And, Also, the disaster tax shows the feature of HIPAA volumetric, the largest, type in 2023 as 200, 200,000,000 requests per second. Amongst 8 times larger than 2000, right, 2022's dry card. To counter this kind of randomly occurring. And the larger scale did also tag, long term purchase, and the operation of large scale to those defense resources come at a very high cost. Next slide, please. And, also, the data set becomes more intelligent, more than half of the attacks in 2023 is more than 2 vectors And, also, this is a typical example of the intelligent disaster attack, the fossil flooding attack can"
  },
  {
    "startTime": "01:40:02",
    "text": "settlements back to a high level for a short duration, which is hard to detect and also harder to defend. And also, there are many new types of attack are emerging, which are also challenges, for the device defense. Next slide, please. So we wanna use, a specific expense, example to illustrate why we need collaborative mitigation. In this case, if, if it there is, for the flooding attack is ongoing and the attack traffic is transferred from the network of the operator to the enterprise for the enterprise, it can tag the, tags in seconds, but because of the limited resources, it cannot mitigate the larger scale disaster tech. So it need the help of the operator. Before the operator, Although it has have the it has the enough resources, but because of the sample based detector detect this method. It it can only detect the attacks in minutes. Which is very slow. So we think the enter enterprise and the operator should exchange the information to do the collaborative mitigation. Actually, we already have those without token threats signaling to do the exchange of the information, the enterprise can initialize, mitigation requests to the operator operator can acknowledge the attacks in time in minutes and develop the mitigation strategies, and then give the response to the to the enterprise and thus the collaborative mitigation can start. That's that's that's next slide, please. But we we used the dots and, find some of the problems that, the data model of the dots is not enough, for example, we want to expand the operator's visibility, the information the way the ability means all the useful information,"
  },
  {
    "startTime": "01:42:02",
    "text": "they can be the attack features, or the network to telemetry message or some intelligence. All these informations will help the operator to do a better mitigation strategy, and then they can use the resources, their, scrubbing device where, BGP full specs, were were something others to do the mitigation. So we think in else, we need a structured attack feature of data model. Next slide, please. And this is the, the other case, if it's if there is a slow HTB attack is ongoing and the target needs the co mitigation, it can there may be many servers that can offer the co mitigation. But which one should the dust claims choice, this is the problem. So we think, we we think could the client needs to know the mitigation cap capabilities that the server can provide in advance in order to make the right decisions in this in this case, in this case because of the slow HTTP attack is complex. It's it can now be mitigated by, you know, with B2B full stack. It must be be of of be mitigated by a scrubbing device. So in this case, the dust client should Chusta's dot01. So the client need to know the mitigation capabilities in advance to do this choice. So what we need is the mitigation capability data model including the strategy and the capacity. Message slide, please. So here is our requirement about the extended data model. Here is the main function of the dots signaling, including the issuing and re response, the mitigation requests in others"
  },
  {
    "startTime": "01:44:01",
    "text": "And in the three parts of it, we think there are they need the extended data model. Next slide, please. And we also do some work the employment tension. Here is the topology diagram of our expand experiment. We built an test by to verify the mitigation effects of disaster tax. And also developed a simplified, a task plan, and a server. So in this this scenario is just the same as the pro problem 1. And, in this case, we add the attack features such as the attack type and the average packet lines or the duplicate message. This kind of message can help the operator fend the, fended attack, in in seconds, with the matching with the netflow data. Next slide, please. And here is the the results of the experiment. We we the attack features the time to start the call mitigation was reduced by 43%. And because of in this simulate, test bed, the simulated devices seem devices have a data forwarding delay of 3 minutes. So, hopefully, in the real network, the co mitigation start time can be reduced from minimum level to 2nd level. That's the slide, please. Oh, so this is our work. We're applying those to our me clobber team DDoS's mitigation framework but found some important data models that were not yet defined. So because thoughts has concluded, we want to find, a pro appropriate working group to other ones or ID. That's all. Thank you. Okay. Thank you."
  },
  {
    "startTime": "01:46:00",
    "text": "Hi to how of Tunghwa University. Thank you very much for your talk. Very interesting in his part. So, about 20, about maybe 20 years ago, the the, academic community has proposed a concept called network capability, which is a, side form of cryptography side form of route intent to express how the network should be forwarded. And the network researchers, including myself, has published a lot of work are using this stuff to prevent the loss attacks. But, in to 2018, I talked with a bunch of cloud providers like cloudflare, like, And they what they're what they said is, like, okay. We should own, the a lot providers they should only care about large stands. So I'm very happy to see that the, you know, from IETF that people people are talking about, okay, only watching the large attacks is not enough to help the downstream customers. So I'm looking forward how this can be, unfolding in IETF in the industry. Thank you very much. So your answer to the dispatch question I'm sorry. Who is it? So what is your suggestion? My my comments is, like, I'm I'm really like to say how this thing can be unfolding in, you know, IETF because I like this, the feedback stuff. Like, from the, from the downstream from the victim to tell the upstream of filters, how they should all their network traffic. Thank you. Thank much. you very Calling from chat mobile, this topic is always important for both the operator and the enterprise network. And for China Mobile, we also have some related products in both for the public, network and public cloud. I think that the proposed requirement is require it's reasonable in your size. It is too worth to enhance the work, including it's sending the related protocol"
  },
  {
    "startTime": "01:48:04",
    "text": "considering some pretty configurations. And as well as a collaboration with mitigation, strategy and the routing strategy since, those, WJ is concluded it is better to find somewhere to promote today's work. Thank you. Okay. So next Paul Hoffman. To try to answer your actual question about dispatch, I believe that this should be a boss. Dots concluded a year ago. Had lots of documents, had lots of interest, That's all being deployed. I don't think that we need a dot's biz yet. I don't think that much has been proposed. They would do that. I would say possibly a one time BAF for this specific draft or for the topic of what you know, not now that we know the dots is established, how do we deal with the data that we're getting for it? Would be sufficient and then hopefully an AD with with the result of the BAF would be able to AD sponsor it, or to say No. We'd, you know, not AD sponsored. We really need a working group, but I think a BAF would be sufficient for this. Just I haven't seen much else post dots in the last I think it was, like, last April or whatever that it was concluded. Thanks. Paul. Thank you, Kent, Kent Watson, a chair of Netmod Working Group. We have a standing agreement to publish any young modules that don't fall into any other existing working groups but we're not domain experts with guts. So be best if you had domain experts to look at it. But for publishing the young module itself, we could do Thank you. Are not. Yes. I'll move to the Broadcom. I would go for a buff as well from, I'm this much perspective, on the content"
  },
  {
    "startTime": "01:50:05",
    "text": "I really don't know how you're going to have the list of the mitigations from the servers because I don't know the normalized, normalized, So if they're not normalized, I really don't know how it's going to work. That's it. Okay. So, the summary of dispatch would be above. And, maybe not for this draft. So maybe more related to topics. So you could get more feedback and during this idea. Weak, weak, Thank you. Thank you. Next 10. Are you ready? Hello? Can you hear me? Yes. Please start. Oh, hi. Everybody. Tim Bray here, not representing anybody. We go. So this work came out of the IETF Jason Pass working group, which has just shut down I was co chair, and we shipped 2 RFCs, one for irreg apps, which is a Small interoperable. Regatta dialect should work the same across popular libraries in Jason Pass which has been around for ages. And in both cases, we insisted that the text the unit code in UTF 8 and then had to consider whether that meant all of And that question turned out to be harder to answer than than we thought and and thus these draft. Next slide, please. That So, most protocols are structured have data structures have text and uni code is good. And then the question arises. Do you wanna use all the characters? And the answer is no. You don't. That is the term code point is gonna come up through this discussion, and those are just the integers that are used to identify Unicode characters, and you can see the number of them. Here's a lot of them. So, some of them are what we call problematic. Next slide, please."
  },
  {
    "startTime": "01:52:05",
    "text": "So this is the worst thing that can happen to you. And, So that is perfectly legal JSON per RFC8259, So if you write a protocol and just say, well, we accept our input data in JSON, somebody could throw this you. You can read what those things are. In the value of the example field, there is nothing that can usefully be shown to a human and some things that are going to cause, real parsing problems. And add it's what's gonna happen is unpredictable. Some implementations will of of JSON Partners will return you a helpful error. Others will crash. Others will will actually generate ill formed UTF8 others will replace the bill form stuff with the little, Unicode replacement character, which is that little diamond chip thing with the broken. Java will replace it with mark, it it's it's it's a mess. So that's because these characters are all problematic. Let us walk through and sort them into 3 baskets. Next slide, please. So the first two are control codes The old people in the room will remember what these are. These go back into to ask you days. And they are the 1st they are the first thirty two bytes starting at 0 and a 120 And they were used in sort of discussing ways in ISO 8859, and even worse ISO 2022. You can't wholesale condemn them because they include new line carriage return and tab, which we refer to as the useful control codes and the rest is legacy control codes. But but the ones here, like, like, 0 null and, some weird form a control thing are not are not are no longer useful. Next slide. Then that, DEAD there is, a surrogate surrogates are an artifact of UTF16, which is an artifact of a period when people believed unit code could be expressed in 16 bits, which it can't and utf16 provides these surrogates to allow you to"
  },
  {
    "startTime": "01:54:03",
    "text": "express high value characters by pairs of surrogates And they're only for use in UTF 16, and UTF 16 is normally not sent over the wire. So if you see these, almost certainly something has broken, it you you this should never happen, but it does. And one of the reasons it does is because in Java, the native chart data type is actually a utf16 code point. And if you prefix and arrays by taking the first 10 characters. It's real easy to end up with one of these things. There's these are really problematic. They break in in all sorts of ways and just to never appear. Next slide, please. Then there are some other foot points that are not characters, and they're called non characters. They is complicated and barring, but UNIPO says specifically that don't use these except internal applications. They don't define what they mean by internal applications, but I'm pretty sure they mean not over the internet. And they can't be displayed. They have no no use. So what we wanna do is offer, 3 subset that, in part or in whole, avoid these problematic characters, and thus are safer and better. The first one, next slide, please. It is called unicode scalers. And this is all the code points that aren't surrogates, and it's pretty widely used, not just in CBAR and Ijson, but over in the W3C, you know, the white working group and and things like that. They use, a unicode scalars quite a lot. And they're much better than all the, unicode points because they exclude the surrogates, which are the most problematic, but they included all the control codes in non and so on. Having said that, you know, it you may end up having having to use if you are wanting to handle seabor messages. Next slide, please. Then in 1998, XML picked this set of characters to bless. And, it was the first to point out that some of the controls were were useful, but not the rest."
  },
  {
    "startTime": "01:56:02",
    "text": "And it gets all the surrogates. It does not get all the non characters. And so, you know, XML may not be popular these days, but it's been around a long time and been used for a whole lot of text And people just have not had problems that I'm aware of with character repertoires, And if you're in something like yang, is it required to exist in both XML and JSON. You're you're probably stuck with this repertoire, Next slide, please. And then this is a new subset we invented for the purpose of this draft and this is all the non problematic code points. So it removes everything, and it's got ABNF the ABNF here is taken straight out of the draft. The idea is that should this draft, become, referenceable, it would be really easy for somebody writing another draft specify what subset they wanna take up So next slide, please. So this is not the first thing that, IITF has ever thought about, this is not the first time IITF has thought about code point, subset. So there's IDNA out there. And that's about domain names. And if your text field is a domain name, we're not adding any value. With unachares, just, you know, use IDna. Next slide, please. Then there's Tracy. So There's nothing wrong with pracy, but it it doesn't seem to get much visibility. And the weird thing is that in I've been involved in a lot of the IATNN discussions around around IITF over past years, and I'd never heard of it. So I'm not even sure how that could happen. And then in all the discussion we had with with hundreds of emails, on this particular draft, nobody brought it up. So it's not much I'm not sure why. I I I've looked at it. I I'd anything wrong with it, but it's pretty big and complicated. I mean, people are just saying, Oh, I just don't need all that stuff. I'm not sure what's going on, but in any case, there there's no conflict. That that you could use pricy and unit charge together. Just fine."
  },
  {
    "startTime": "01:58:01",
    "text": "Next and last slide, So after we were pretty well finished with the JSON path, work. We decided to, write a draft come and cover what we've learned. And, our our ADs told us to take it to those 2 mailing lists, and we had really a good discussion with some really passionate and deep unicode people and went through seven drafts and it's way way way way better than what we came up with in August. So big thanks to all those people who have pitched in. This is received, you know, as as much discussion as some working groups give drafts of this size. It's already been referenced out there, in a couple of places. I don't know. I, I, I believe that having this around to would be handy to creators of, new new draft have to handle text fields. They certainly would have been handled for us, handy for us in JSON Pass. And I think it would be, useful to have this exist As a, as a standard track document in in the IETF. So thank you. And, we look forward to hearing suggestions as to how that might be shaped. Do you have any other people? So I'm co author. Tim was remote. I'm local. So I figured I would be the one standing here. Okay. Thanks. John Clenson. Hi. Tim My biggest concern is that if we end up with a large number of different profiles and ways of talking about unicode characters and limits on them We basically end up confusing everybody. And, and there was a lot of incompatibility in interoperability problems. I think you're problematic characters list, I also see some things in the ranges which you indicated are okay, which are probably problematic."
  },
  {
    "startTime": "02:00:01",
    "text": "And, I understand your comment about precede not being widely publicized but it's not clear to me in making yet another competitive document. 40. Being much more widely publicized or much more widely used. So the question is, can we Start with Tracy and if necessary, create a new profile or discuss what the deficiencies are there. And it's not Why not? So your advice on dispatching this, John? I advise in dispatching this is that I would like to hear from the authors why this can't be built on a precinct? Foundation, and it cannot be built on a crazy foundation. Then we should be discussing Pops or Working Groups. If it requires modifications for PACE C we may need to start that working group up again, but I don't see this as an independent effort. Okay. Thank you. Pete Pete Resnick. My dispatch recommendation is ditch this document. Their the reason pracy exists is for folks like you to read through the requirements and register a profile. Do that. Put what you have in this document into a pracy profile explain why it needs to be different than the existing pracy profiles. But if you need 1, make 1. But We don't need a working group. Tracy gives you all of the instruction for how to build this. Build 1, implementers don't need to look at all the pre seed documents you do. Implementers get to look at the profile and use it. Do that. Pete, so I I have a follow-up question on that. If Because it it's our belief that"
  },
  {
    "startTime": "02:02:01",
    "text": "pracy profiles have not been well used and are are barely known. Would that change your mind, or would you say you know, like you say, ditch this, and you know, as we still won't have any focus on pracy and therefore, other groups might do things without knowing Would you you know, how how do we get pracy profiles to be better now? If if we've ditched this. This this as an RFC will have some focus pracy profiles won't. I I I think if you in particular, go to the JSON community, which is what this is aimed at Mhmm. And say One of Yeah. Yeah. Right? Here's the document that describes which things to use pracy profile settings so, I I mean, you're you're saying crazy profiles don't have visibility. Therefore, we should publish in this form that has higher visibility Nick give pracy profiles visibility. Create one point to it. Say, this is what we need to do. Announced it of mailing lists. Great. on lots Okay. Thank you. Alright. Thank you, Kirsten. Thank you. I agree with Pete's dispatch verdict, but not for the same reason. A document like this should give advice. I think this gives really bad advice. It it's really useful information about the history of things. So that's it's a good read for people who really care about this subject and and with a 7th or 8th revision, no longer can, contains a lot of incorrect statements. So that that already makes it a use for a document in some way. But I think it really should be useful. And the the episode that Tim related to was, in Jason Path, we had this problem because we have Jason is our input. Language. And Jason accepts toxic waste."
  },
  {
    "startTime": "02:04:05",
    "text": "Toxic waste is is something that that is not unicode, but something that adjacent parts is is going to ingest. And then get turbo Stomachcake. And and Tim, you even had an example where where one of one of his systems broke when when that happened. So that's one thing, but then there is this weird term problematic character and then every character is problematic, and lowercase a is problematic. What you need to understand is what is your application and what what do you want to do with these characters and so on? So, think document that gives useful advice we really I need a to people who want to define new protocols. If you want want to use an old protocol, it did already tells you how to do that. SMPP trades you exactly how how to operate in this a space. We don't need a deduction for that. You need a document on you, implement us. And I think we should find some way to to have such a document I thought I might just vitalgent quietly somewhere, but now that this document is out there as well. It's going to be the the next subject in this meetings where I'm gonna shut up. Okay. Thank you, Harold. Hello. Uni code offers many opportunities to shoot yourself in the foods. This document Well, I'd like the presentation better than the documents. Because the document seems to say that As long as you're only handling code points, And don't care what the code points mean. You can get away with all the doing this set set of rules. But, It failed to acknowledge the fact that"
  },
  {
    "startTime": "02:06:02",
    "text": "If you try to assign any kind of meaning to those call points, you into a world of other troubles. I mean, I did a 2008 presses, all the string prep for name prep for We've been in this, Waist plan of hers for many years. With it, Significant applicability statement and a and a forward pointed saying If you Try to do more than just ship slap around the characters. Cap around the code points. Do you want to look at these other places? This could be a useful document. But I'm not sure where where we should take it to get to that useful document. That that was my next question. Ori Steele. Hi. We're still incoming art AD. The back to the dispatch question. I heard folks saying, we wish this was a pricy profile, Pricy is a a working group that's not currently active. Has there been is there a giant pool of work that needs more pracy work in the chat. I can hear folks saying they looked pricing, they decided not to use it in recent documents for various reasons, So I'm a bit concerned that, we're sort of pinning pracy on this, while we can also see evidence that folks don't wanna use pracy. It's, to the dispatch question regarding this, it seems like it's headed either for an AD sponsorship or for, a a new pricing working group with a whole bunch of other, challenges associated process. And I don't like either of those options personally. Thanks. Pete here. Yep. Yeah. Yeah."
  },
  {
    "startTime": "02:08:01",
    "text": "The the queue was closed, so I didn't wanna just jump up. Pete Resnick. No. The the nice thing about Pre C is that it has this whole framework, it it becomes effectively like an IANA registration. There we have this framework where you can one of these profiles. If these guys go follow it and do it, they might need some advice from the internationalization, list in order to get it right. But for the most part, it's follow the directions in the document and create the profile. So no working group needed. 1 to summarize that? Thank you. Okay. So for this draft, presentation is a good brief and the per wide useful advice at least a a good starting point. And for the work, So, people, maybe more prefer to proceed, although it's not popular So yet. And, also some suggestions to, work work work more on the process and make it more visible and, Yeah. Good. Thank you. Thank you. Thank you. Thank you 1st Walk it there from here. Nope. Here? Thanks. I have the estimators. Clothes and stuff. Okay. Thank you. Now this is a really unfortunate slot because, I I had to to pick on this other draft that that actually is trying to reduce for work. So so I apologize for this."
  },
  {
    "startTime": "02:10:01",
    "text": "A while ago in 2019, I wrote a document which I think was useful at time. Because I could point explain. These are kind of the choices you're going to have. When you are using unicode, And this has been around for a while, and, Tim's and and Paul's draft, kind of prompted me to, dust this off a bit Next slide, please. So, obviously, this is not happening in a vacuum. We had this draft in in 1969, which it was called an RFC at the time, RFC 20. Which we actually turned up into IETF standard, some some decades, later, which is ASCII. And, as Keith was was an externally defined document that we imported and and started to use a lot. In the Internet Internet, I think we can say it's built on Eskeith And, well, an interesting document here, for instance, is RFC 854. Which is the tenant edge protocol specification. Some of you may remember, tenant, and that defined a network virtual Tom And that's that's pretty much What what has, added to the specification to As key as as a foundational document, how we actually use it in the IETF. And, then 15 years later, it became clear that SK is not enough had to do something about, covering more characters, and we got an ATF policy on character sets and languages. And, Harald is is one of the people who made this happen. And th this is busierp18. And, nobody has since"
  },
  {
    "startTime": "02:12:01",
    "text": "questioned PCPA team. I think we all agree that UTF age is the way we are going to interchange document, and the underlying unicode is going to be our character a model And, actually, 5 years later, we got an another, Internet standards, standard 63, which defined UTF 8, more precisely. This came as sequence of several documents until it was complete And finally, in in March 2008, John, who has also been at the microphone already, co authored, document that essentially replaced NVT, the the old network, which your terminal with one that is based on on Unicode and answer a few questions that came up when you do this So this is essentially the pledge problem in which we stand. And, the the question is, is there anything left open here next slide. The problem really is, sort of, on on not the problem, the opportunity, the nice thing. Is that, we don't need your network virtual terminal very much anymore. We're not using Tenet that much we are using SSH, but, Today, we are defining protocols that have their own structure have XML, we have Jason, we have CBOR, we have whatever And, these already provide the structure that we use to to have to derive from In eski, you have something called record separators and unit separators don't know if you'll remember those we actually use them in JSON sequences. But normally, the structure is coming from something else like XML, Jason. Cboe representation. From it. So the protocol designers today use XML is the Jason or Sibo as their foundational technology and then have to decide"
  },
  {
    "startTime": "02:14:02",
    "text": "What kinds of unicode springs go into these little fields, what goes into an attribute, what goes into an element, and so on. And, well, at at the end of the the start of the previous decade, was, like, helping in designing a protocol, and we ran into the problem we we needed some more text. So we actually referenced five 198, but it wasn't that useful. I mean, that still works, but, it it was a a compromise. And as some people have said unicode is more complex than ASCII what's that? So Portugal Designers really need help. I fled. So, given that this came up again in the context of another development that I going into a cold cuspid I started writing a document, and trying to get feedback back on the art mailing list with some exclusions to internationalization director, and, also got lots of good feedback and learned a lot, due to the the approach here is to have a relatively simple menu of choices that pro designer can can make unfortunately, these need options because applications are different, but this is about eight pages, of of document. And then I have some more ten pages of appendices about terminology, which really important in this space about the history, legacy issues, Hobi got that toxic waste into our systems. Sometimes uni code normalization, which is relevant to to many people who think it isn't relevant to to them, and, finally relationship to 51 98. Next slide. So The objective for this document was was to be useful for protocol developers as as a guide document, something they they can read and don't need an afternoon for that,"
  },
  {
    "startTime": "02:16:03",
    "text": "but also maybe as a reference, a new specification can point to and say, we are using this particular subset of of, uni court Of course, this subject could be expanded. A lot should could become a longer humid when the it would become less useful for, developers so really that the guide aspect is is quite useful as it is. Reference aspect, might require a a down ref in in a document yet that uses this or might require some some standardization. So I I don't have a strong opinion on this, but I think that would be useful to to, have as a reference mechanism. And I'm not thinking so much about formal mechanisms like pre pressy profiles and on, but simply as something that can be pointed to and, for instance, the difference between one dimensioner and 2 dimensional is pretty important in many other cases. So this is something that document can be quantity. So I could just continue developing it in quiet on my own, or we could, set up some, some things that looks at this in a more consensus oriented. Wait. I'm not, proposing anything specific, but given the previously discussed document I would like to hear about. Okay. Does anyone have any opinions on dispatching Kirsten, what in in the absence of a queue, what would be your preference about How you would like to see us dispatch this? Well, I thought I got pretty good feedback on art. So there there is a certain kind of consensus that that is wavering for the roof. But it's not captured. And I'm mainly interested in getting a little bit more of of, yeah, people have looked at this and and it kind of"
  },
  {
    "startTime": "02:18:00",
    "text": "seems to be a good choice as such, of choices. Good. Well, ask for a queue and one shall appear. Go ahead, Colin. I'm not an expert in the space, Colin James. I I've seen credible amount of time and energy spent into these problems and my read of your document, Carson, is that it comes to slightly different conclusions on some of the things than some of the other many working groups that have looked at this area deeply. And having yet another set of conflicting advice on this stuff will probably make the situation worse than better. So I think if we do do something on this, we need to do it in a you know, fairly serious working group type white. This is not something that an AD can just, you know, sponsor or that we can just do slow in some area like that. We need to We need to be very serious about it and be willing to deprecate some you know, say some of the stuff we did in the past was wrong, and we're gonna do this in side, side, don't agree with that part of your statement because I mean, we have legacy, and and we will always this legacy. Of have course. We will still have JSON with all the toxic waste in it. We are not going to change this. This is for new designs used for points that that people can congregate I understand, but it's advice for a new design might be a little bit different than what And that's why I think complicated. It. Thank you. John Clenson. First of all, I I I agree with Kelvin about the convrecating part. The our our general internationalization work is in, is in a bit of disarray, a a situation which, has been discussed at at length with some of the relevant IDs and we may be on track to getting some pro forward progress, which we have not in my opinion been the last couple of years. As co author of the document which"
  },
  {
    "startTime": "02:20:00",
    "text": "Carson dismissed as NBT only. That was not the intent. But that document at this point is clearly showing its age and and needs some rethinking. And, And I wish Mike Petlipsky were here because he was able to get far more articulate on some of these things than, that I can as those of you who do it or do it with no. But I I think the solution for this problem, this document for a dispatching stamp me is to look at the existing work talk much more clearly than the drafts do now. About how it relates to existing work. Integrated with whatever the do swerve doing it with thinner nationalization more generally, and, and see if it can become part of the picture rather than yet another conflicting picture, even even going partially conflicting because I'm very, very worried about our ending up in a situation where we got multiple spec switch. Are not the same, although they overlap, give people too much of twice about where they should go on what they should look at without understanding your choices And, and that's it. Recipe for interoperability problems, as I said before. I'm not opposed to this draft, but I think it needs to be part of a larger picture. Thanks. Thank you, Ted Hardy. It's not hardy. I I believe, again, you have 2 different things you're trying to do and that the answer may be different for the two different things. From the guide perspective, I don't think that needs to be a standard track RFC. And in fact, it might be a better guide if it were not an RFC at all. But one where it could, iterate more rapidly as experience with trying to use it with different protocol situations was learned So I think for the guide side, I would suggest to take it out of the RFC stream entirely and then ask yourself is what is it that you want to reference"
  },
  {
    "startTime": "02:22:00",
    "text": "as a new specification that is not itself also something that you could write up as a pre c profile. And if there's an answer to that, I think we go back to what we just said. If there's a reference that people need that can't be a pricy profile. Maybe we need to fix pracy and then make that work, if we find that You know, we absolutely can't do that and we need a different thing, then I think this would need a working group. But I think if you split these into two pieces again, I. The answer sort of fall out naturally. Thank you. Thank you. Thank you. Harold. Hello. This is John again. I have some of the same objections to this draft. The As to the other drafts, Meaning that The amount of trouble you can get into is much larger than the than the The DAF SIM syndicate. But, Copying this one to the other drafts. They seem to come to They are frankly incompatible. Publishing both would be a disaster. So If we want to specify something that says, here's a reasonably, say, sane set of unicorn to use in this particular situations. We need to get one we count dispatch both. Okay. That's the end of the queue. You Can you summarize that? Let me try Yep. So And then this work is, Jara, a lot of existing work and so be careful about this, overlap. With the existing work. And, and this is also complicated new design. So So probably for this work and the first display date and take the guide a part of it and figure out what is the new specs"
  },
  {
    "startTime": "02:24:01",
    "text": "will be needed, and then start from there. So, more feedback, more discussions So in the the venue would be the arch mailing list, 3rd or or in I18 Yeah. This is not really an internalization document. I mean, trying to be Not too wrong on internationalization, but really is about political design. Yeah. Okay. Thank you. Okay. Thank you. I can I just interject? Because Carson just said one thing that I think is unclear, is taking it to the art mailing list We have 2 mailing lists as we both as both Carson and Tim and I have pointed out, there's the art mailing list and there's the I18n director, the internationalization director at mailing list. So if it's gonna be dispatched to a mailing list, it would be good to know which one to dispatch it to. X, Yeah. I think Kirsten said that since it's more of a protocol matter than internationalization per se. It should be dispatched to art. Okay. We're at the end of the agenda. Thank you all for your participation. And, have a have a good week. We're about 35 minutes early. This is great. Okay. So the summary of the dispatch outcomes will be sent after session in the meeting list. All dispatch meeting missed. Thank you. Hi. Very quickly. So so Lars, I got, AD for this session for this both. We would also like to hear feedback on how this went for you as a participant. Do you like this all dispatch model of, talking about potentially brought new work in this broad new group or would you prefer something else? So please send that feedback to the ISG. Thank you. Okay."
  },
  {
    "startTime": "02:26:03",
    "text": "Think that went pretty well Yes. For the time management. Yeah. You see? The exact Yeah. The timer on the screen, it really helps Yeah. But, I do take some your number Yeah. Some limited never applies. Yeah, there's some there's some there's some, like, Well, maybe, I mean, There is a style thing. I different people have different and It's hard to pretty say Yeah. But you know, and also IRTS name. And what if we have that even on Well, you know, I think, Ted, we will handle this time. Yeah. Hey, buddy. But, I mean, honestly,"
  },
  {
    "startTime": "02:28:03",
    "text": "the fact that we were able to get the discussions in 15 minutes each, that's It's really one. I don't want we But it's it's it's Bye. Still, I mean, Jim and Chuping. Are you aware that you're at Micah's hot Are you aware that Mike is hot?"
  }
]
