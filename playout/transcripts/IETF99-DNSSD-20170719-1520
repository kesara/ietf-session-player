[
  {
    "startTime": "00:01:00",
    "text": "hang on is there another Chinese okay yeah if we can somehow get them with a suitable moment onto this laptop yeah we need to get started who\u0027s know do the honors okay good afternoon this is the DNS service discovery working group Tim and I are the chairs thanks oh yeah right right and next and here\u0027s the this is the new note well right here\u0027s this I didn\u0027t do the diff I don\u0027t know if anybody has but it\u0027s there okay give you a minute to absorb that everybody\u0027s scroll down to the bottom and click that click I accept ok next please do we have a job a real a volunteer great thank you and Tim Tim the hero of the revolution is going to he\u0027s gonna take is gonna take minutes for us and feel free to jump in on the etherpad and and put your own if you oh great thanks and if you know a name that that we don\u0027t get in or something else gets missed feel free it\u0027s a collaborative effort ok yep the stuff you find when you go to the data tracker here we are next so this is the data tracker screenshot showing the status of the various documents so what we\u0027ll talk about some of them today but the requirements is obviously being published for some time now as an RC hybrid come on to in a moment there\u0027s just a couple of things that need doing there whereas discovery proxy as it\u0027s now called before that gets pushed up to towards the is G the mdns Interop is in the RFC editors queue I don\u0027t think it\u0027s popped out yet but it must be very imminent where I\u0027ll be talking about the pairing and privacy drafts today it\u0027s the first item on the agenda and then push is also very close I think Stuart\u0027s just got one kind of key question he wants to ask the group about a change it\u0027s made to the last version ok Tim since he I\u0027m writing the Shepherd thing for push yeah somehow you guys put my name on it which is interesting it\u0027s basically it\u0027s basically all done I\u0027m getting it sort of getting all the formatting because I very much stuff at the the normative download references "
  },
  {
    "startTime": "00:04:01",
    "text": "around the session signaling thing which has been just a good time for us and DNS op so that\u0027s the only thing so you should see that by the end of the day modular what else I got going on ok so I thought we\u0027d had a discussion ok that\u0027s alright absolutely fine so yeah the girls today have we finalized the submission what we need for the submission of the discovery proxy and Bush though we still have this dependency on the session signaling as mentioned discuss the DNS SD privacy draft and the outcome with working last call that we did there are a couple of comments on that that I think have been addressed and the device powering draft and then go through the various first drafts of the future work agreed last time then Stuart\u0027s got a slot for that today and then the final thing we got about 15 minutes or maybe a bit more at the end we\u0027ll see how time goes just to discuss discuss a draft that carry and maybe other authors have written over in the core group about the interrupts between BN SSD and Co Rd and potential mappings between the two so we did discuss that very briefly last time but there\u0027s now something a little more tangible just to discuss okay and here\u0027s the agenda for people that have got fighter pilot vision at the back you\u0027ll be able to hopefully read this so twenty minutes for the privacy draw device powering 30 minutes first Stewart\u0027s talk about some of the new items Ted thank got 15 minutes on the mdns relay and carry 15 minutes on the dns SD rd eatin syrup okay seeing any violent disagreement that\u0027s good so just one quick slide on the hybrid proxy draft it might be that Stewart has something in his deck about this as well essentially the 0-6 update was published some time ago whose renaming the hybrid proxy discovery proxy as we agreed that\u0027s up there\u0027s just a I\u0027ve done the Shepherd report it\u0027s just a couple of things to iron AG one is changing the reference from home to home DARPA and secondly there\u0027s a little bit of confusion it seems over the IP our statement that I had a discussion and that was Stewart and we just emailed the Secretariat check what\u0027s going on it looks like they might have erroneously withdrawn the statement on this document when they were withdrawing other than the requirements document that originally erroneously had the IPR statement on it so anyway we\u0027re in touch with the cataria and hopefully will resolve who had that removed and then take it from there okay and then DNS Bush again I think Stewart might be mentioning this in his deck the the there was a very small number of changes going to dr. - 12 which is the version we intend to push upwards and I\u0027ve just emphasized in bold there the main difference which was allowing the client to talk to its normal DNS for cursive resolver or try to talk to it "
  },
  {
    "startTime": "00:07:03",
    "text": "first before talking directly but I think sure it might come on to that later so heads up on that one okay so that\u0027s it for the the introduction so first speaker I think is Christian or is it Daniel Christian and Christian Christian before you start I have I have an announcement this is going to be my last meeting as working group co-chair I\u0027m going to step down if you\u0027re if you\u0027re interested in becoming a co-chair of the the DNS SD working group working with this guy who makes it all very easy it\u0027s really a pretty straightforward working group to to to manage and run please contact either myself or Tim or our fearless area director Terry thanks have you thought about reconsidering your option that not I just like to say thank you thank you for the effort that you\u0027ve done a wonderful job over the last couple years this is being one of my favorite working groups I said one of okay good afternoon so DN SSD privacy and the NSSC pairing it\u0027s an effort that started two years ago and which we hope is on its concluding stretch now summary for those who have not had to do after so summary of the DNS privacy enhancement the idea is that instead of discovering directly by asking what you want you do a rendezvous on up pseudonym and you open a secure channel and then the queries are sent over the Anchorage channel so that nobody can read what you\u0027re doing and nobody can guess who you are so it\u0027s a simple enough what have we done since last time we\u0027ll walk right on the prototype implementation we had a couple of reviews detail review by Stephan and by Ted Thank You Ted thank you Stefan\u0027s we published a revision that answers the first question I hope we have not published a revision and so in Ted\u0027s question yet because I mean time so I have here a couple of issue that Ted waste and I thought it was be good to review them one by one because I meant I don\u0027t give you everything some of the test comments are as he thinks we\u0027re kind of just fixin there\u0027s no point there but some we need to maybe explain it more the privacy exchange rely on a "
  },
  {
    "startTime": "00:10:06",
    "text": "shirt on on a shared key between pairs of hose pairs of nodes and Ted was asking the questions hey why don\u0027t you guys use public key technologies since more modern and it was actually a very deliberate decision is that public key technology means that your public key is an identifier and the public key exchange is failing out to the public key exchange that does not disclose the public key and so if you are try to do privacy public key is not inside the right fit not not immediately so that\u0027s the reason why I mean the other thing is that a private key exchange it that is known as a shared secret between two nodes when it is used provide an immediate verification that you know with the other guy so you know what to disclose why so as the public key man you would have to have a pair of public exchange to do that and so death currency is welcome because it will it will force us to check back at the text that we have to make sure to explain the rationale properly so it\u0027s not ambiguous yes last moment in the IOT we repeatedly run into the problem that we need a secret handshake yes where we have a member of a group that tries to ascertain whether somebody else also slumbers of the group yet without either disclosing that they are remember and also can be true groups yeah is that something that we use for you well that\u0027s what we do okay that\u0027s what we do okay it\u0027s a second issue it was raised by my Stephan we make the Devonian who operates on an M it\u0027s basically the way you do a secret handshake is that you have the knowns and and and and a shut secret and you compute a hash of that and you you verify that they both know the harsh and it can let much what you expect and to simplify the protocol we decided to make the hash but for the norms the function of time the value of making the non harsh a function of the time that both ends can predict the nonce and so if the nonce is said the time rounded to the next five minute or something like that that means that you have only to do a computation of this ash of nonce once every five minutes wise if you let the nonce be a random thing that anybody can choose you open yourself to a potential denial service attack that in which someone sends you lots of different nodes and forced you to "
  },
  {
    "startTime": "00:13:06",
    "text": "compute lots of hashes and depletes the battery of the small device or whatever so that that\u0027s the reason why we chose that what Stephon was pointing is that there is an edge condition there when you are just at the end of the 5-minute interval like within the 5-minute interval yeah you can be your time situation needs to be just as good as say one minute or something like that but yeah at the end of the interval yeah people are going to switch from these slice of five minutes to the next size of five minutes and if you are not careful I mean one will believe that they are before this one will be if they are after and they won\u0027t get too much in fact it\u0027s something we sort of an in fact in the prototype implementation where the fix but we did not document it properly in the text so we fix that in the Russian two by saying hey what your xxx do is that if you are at the end of the interval you also consider the next hash and if you are the beginning of the end of all your code also consider previous ash and that\u0027s why you you eliminate the edge condition so we documented that in Indore - for the issue that was raised by Tara say hey these business of updating your ash F at a short interval that\u0027s fine when you\u0027re doing broadcast because there is no state and nobody cares is it\u0027s a bit more problematic when you are when at the end of the interval you have to push an update to a server because if you end up pushing frequence of deaths every five minutes to the server then you have server overload not to mention a peak of load at that exact time so this is Ted lemon that\u0027s not actually exactly what I meant although that may be what I said what I was concerned about is not so much load on the server which I don\u0027t think is really a serious issue but rather that the caching behavior of a DNS sd client will be such that it will remember records for longer potentially than than the lifetime of these if the lifetime of these things only five minutes yeah a record might be cached longer than five minutes and why we must there obviously would set the TTI to five minutes but yes well right but I mean you know is there any particular reason to not have it be more in line with because you know DNS is D and and an M DNS in particular do a fair amount of work to avoid retransmitting data that\u0027s been transmitted multicast recently yeah and when you when you tune things up so that you have two multicast more often it\u0027s really not that good of a thing to do so unless there\u0027s a serious and the the reason why I made the suggestion is because I didn\u0027t really think that there was a serious risk of replay attacks that would be mitigated by making the interval five minutes rather than 30 well it\u0027s I mean "
  },
  {
    "startTime": "00:16:07",
    "text": "the yeah I mean you have six times more chances to get a replay attack in 40 minutes right like what do you get if you do a replay attack so basically what you did was a replay attack is that you can discover was on someone is at the location yeah so the the concern we have is that someone listen to a hash two to one of those notes at one location and then replace it at another location to see whether your body has moved to that also location right that well that was what we were concerned with yeah so basically if you make that wait for say one month then you have a real problem because you track someone yeah thirty minutes if you make it for you you suggest forty minutes and that means that basically I\u0027m exposed that if I move to here to someplace as in forty minutes that move might be discovered now of course in 40 minutes I can only move in the next town basically so yeah that risk is only the best level yeah that that\u0027s what it is yeah I mean there there\u0027s it seems like there are there are some attacks that you can do that that if you if you have that degree of control over the network infrastructure and a whole bunch of different hotspots in various places there are a lot of games that you can play to to know that - not so much know that a particular device has moved but if you if you if you know about a number of devices and you can watch them looking at each other then you may be able to learn a fair amount about about their associations by having this kind of overview that you\u0027re talking about so that seems to me to be a bigger risk actually than this it components it took to you yeah yeah come on sit right so it\u0027s a classic premise that if I have one leech I block the auto leak at what cost yeah so the problem is that you\u0027re pushing a fair amount of potentially a fair amount of data in these in these pairing or not in the in the in the service discovery part of this and so there is a trade-off being made here yeah and and as I said I mean I\u0027m I\u0027m not opposed to moving from five minutes to 30 minutes it\u0027s just a different way of an a what I would call portable wisdom I\u0027m fine what I would actually suggest is is that if you\u0027re using the the registration protocol five minutes is fine because it\u0027s all unicast and I don\u0027t care the load on the server isn\u0027t that much if it\u0027s multicast then I would want you to use a longer interval because the load that you\u0027re creating as long as larger you see what I mean oh yes you know I was constantly opposite yes yes yeah in the multicast case the load on the network is increased by shortening the TTL in the in the unicast case who cares okay so fine I would also do it in all cases then but yes I had a small concern "
  },
  {
    "startTime": "00:19:10",
    "text": "about the previous slide the five minutes interval ah hi I\u0027m Angela from Boston University yeah so this is timing B\u0027s right how I\u0027m just a little concerned how this will be implemented is it implemented as counter or as an absolute time absolute time which is really bad if because if you can change if there is a difference between times then you can again like if you can change move the clock by five minutes or five minutes then you can again do the same toss that you\u0027re preventing it well yeah it only works if your minute if we choose an interval beat five minutes or 40 minutes then we require that this time synchronization will be a better than data I mean is there a reason why we can\u0027t implement it as an encounter yes no no we cannot it\u0027s because you you don\u0027t have a common concur between the two stations you have to do a prediction and you have to make it valuable all the time and it settles but I think in terms of time it\u0027s you know the alternative is to have a random number that changes all the time but then you have no caching property and then you have a risk of an exhaustion attack by having multiple random numbers yeah I don\u0027t know what the right metrics should be but I think time is a it\u0027s just five minutes like you can how is time updated it\u0027s MTP and you can attack look I mean if we take suppose that we adopt Ted suggestion to make it 30 minutes instead the earlier in time synchronization you have to be really bad how does clock drift like you there\u0027s some small interval right no it is so when it accepts both yes and yeah it\u0027s like no I mean it okay if you are really concerned about them synchronization we can take a larger interval it\u0027s sort of both concern that\u0027s fine yeah but yeah Oh Shepherd relays okay sorry sorry I thought you had a message from Jabba cremated life Dave Taylor so if there are use cases that are important where say one end does not have a source of absolute time I don\u0027t know if there some you know i OT case amin stewart was arguing the other day about you know using dns SD for you know constrained environments and things if there is a case have you actually looked how much weaker does it get and i\u0027m not saying you should do this this is actually legitimate question how much weaker does "
  },
  {
    "startTime": "00:22:10",
    "text": "it get if you had a way for the requester to put in its guess as to what the absolute time is which should be public information because everybody really ought to know that right and if the receiver then just simply trusted that because that\u0027s not the only thing that\u0027s computing the hash over how much weaker is a crypto get is my question in fact in fact the the time that you believe the value of the interval that you believe in is the first 24 bits of the token so in the protocol as we broadcast those tokens you will learn what years like i believe the time is so you could have decided saying as if it\u0027s the receiver of the query for example had no clock and it just took whatever the requester said was the absolute time does it actually weaken the privacy promise is one yes it does it\u0027s much weaker it exposes you to be play attacks had i don\u0027t know if it already does but calling that out in the privacy consideration and the security consideration section it\u0027s probably a good thing because that might become a frequently asked question okay okay well perhaps you know if you want to use it for that here\u0027s what you lose right yes Stuart Cheshire from Apple I wanted to thank uncial for her comments and explain a bit of backgrounds which it probably l people in the room wouldn\u0027t know it\u0027s very easy for us to say well we assume the clocks are synchronized and Anne Shiell has spent a long time working the TP working group working at houses how to synchronize clocks yes securely so there\u0027s a lot of thorny issues here and I think it\u0027s worth discussing probably not we shouldn\u0027t rattle on it right now in this meeting but I do think it\u0027s an interesting area and and again I mean what we may want to do is what they\u0027ve success is having the in the implementation consideration what happens if your clock is not properly synchronized yes yeah that sounds good okay fine so we will link to uh so longer intervals and we will add consideration now and also comment that that Matt is that when when a device advertise itself it advertised the list of instances that are present which is F activities of pairing and the number the number of pairing in this list is a property of the device so whether you have eleven of seven or or twelve can be used to cannot identify you and third suggestion was should we do some kind of fuzzing there to break that kind of fingerprinting and it turns out that in our prototype what we do that so yes "
  },
  {
    "startTime": "00:25:10",
    "text": "again that\u0027s something that we cannot document in the Security section as one of the mitigations it has about zero cost because I mean you you just add a couple of random numbers at the end of of your thing and people will compare them but it\u0027s just the number of comparison is doesn\u0027t increase the cost widely that\u0027s so we\u0027ll do that and another suggestion was hey we are doing discovery there for services and it\u0027s all about instance name in SS of the SLV recalls and things like that what about application like SSH that are basically just using the host mem and and yeah and in fact again that something that Daniel implemented in his in his moto types what he says is basically what you do is that you discover the privacy service you verify the IP address of the privacy service about the secure channel and you tie that IP address to a host a private local or some such name that can then be used as a host name basis I a simplement ation of that so it\u0027s by something that we have implemented that is tested and we can document that\u0027s okay so that\u0027s pretty much the end for the privacy document basically all documents have seen except for the change in time I kind of editorial in nature and clarifications may be in yes that\u0027s not that nature I think here so I mean they fit in the character that you shall do at the end of foreign sport so I think that pretty much that means as well I mean we have to answer the comments we have to do it and also you have to answer all those comments along the line of what I I described there but pretty much grabbed on yeah yeah nothing same yeah the pairing draft Genesis D pairing basic e-discovery week we license all shelf secret and we wanted to have at least one method of establishing those charge secrets so we have the paragraph explaining this explaining a photo shoot in professors you do discovery using mdns or DNS SD and you use the key argument protocol which is in our case just doing of a TLS anonymous connection and then you do a key verification in which you extract the negotiate key from the TLS context and you use Amin basic here commit bears a copied first protocol to make sure that you can verify that computer hash on both side print art a short string like the first "
  },
  {
    "startTime": "00:28:11",
    "text": "digit of the harsh on the on the screen on each screen or in each display and then you verify that those display much and it has good cryptography poverty so well-known algorithm and once you have that you need both and a verified 38 matches you can remember a secret and and use that forward so it\u0027s very straightforward there\u0027s no no difficulty can be implemented in a very simple way so the appointment that we had very few with you we had a video from Steve Kent back in January and it was nice I mean wait give us a lot of feedback and we but basically steeper said yeah it\u0027s fine I mean the document is fine and then we from the clarify I\u0027m not falling asleep that\u0027s purchase a pairing no privacy righteous yes yeah okay oh yes yeah Christian\u0027s testing you yeah yeah thank you and so basically we are very few reviews demand and after Steve contribute that that was the next one and so we did a revision before that with the mostly clarification based on owner proofreading and all that but there that\u0027s what you request was a couple of clarification and I\u0027m not going to go into the trifurcation and then to big suggestion relative to QR codes and to analyze system spec so QR codes in our draft we proposed an option to use QA QR codes as a way to speed up the user interface the QR code are grafted on top of the previous protocol we can use one QR code as part of the discovery in which instead of doing a network exchange for discovery you read the QR code and that gives you a unique private name that you can discover safely and the at the end of the exchange instead of manually reading the number on the other screen you read the QR code and then you compare it to what you have on your screen so it\u0027s really UI sauce on top of the existing protocols and that\u0027s pointed at a it feels like a separate thing it should be separated and at that point I have two options I mean and I would like to get feedback from the coupon on those two options one option is to leave it in document but maybe move it to a another chapter of the document says hey if you can tweak your code you can do this and that will that will make your UI simpler so it\u0027s one option and the other option is to "
  },
  {
    "startTime": "00:31:12",
    "text": "remove it completely and do that later in another document and frankly I would like to get feedback about what people prefer and I think there\u0027s another question about splitting the document as well so maybe yeah maybe come on to the next one and then we have a discussion about okay all the splits that might happen the Pauline document as it is kind of long as as almost 20 pages which is basically 16 pages of another analysis and two pages of spec and and that was saying hey you know what if you put the spec in a very short life see I mean I can give that to a developer and says can you do that and say yeah sure I can do that as easy because it is in fact is it\u0027s literally maybe twelve lines of code okay and on the other hand if I give him a twenty page document which goes into a long discussion of the academic research on the subject he\u0027ll be scared as a I need to analyze that I need to understand that let me read that for week or two and then I\u0027ll tell you so so that suggestion was a split to two draft but the analyst is informed in one to Avenue one in function ref see and put the specification in a shop Standard Oil to see which is simpler and will be implemented quickly and we\u0027ll have less a minute will guarantee more on top beauty and actually stiff can\u0027t met the exact same second suggestion we delayed that because a feedback in Chicago was a wait a bit until we do that but I can definitely do it the fire hose is that if we split the document we have to redo all the last hole and all that but it\u0027s a bit okay so that that\u0027s pretty much where we are and the next step is basically if my understanding is that the private discovery gloves is basically ready emails is no question but the doll for the pairing we need to have this Annihilus split and we to decide what to do with secure code and we probably needed a second last call with DES I think that\u0027s a really good summary that Christians produce the zero three I think it is for the privacy and check the people who made the comments are happy with those resolutions and we\u0027ll push that up on the pairing yeah I think Steve and Ted have both made the comment about splitting it and I think we\u0027re on the fence so to speak about that I I think your comment about making it as simple as possible to pass to someone to implement is actually a very good one so they\u0027re not going to be put off by a lot of discussion and analysis in there so personally I\u0027d be leaning towards the split possibly both spits but I being seen to see well Ted and Carrie think on the mic line Ted lemon so yeah I mean I actually read the doc I deliberately did not read sections two and three I saw the thing "
  },
  {
    "startTime": "00:34:12",
    "text": "in section 1.2 about you know the rationale for maybe splitting and I thought well let\u0027s test this and so I just said okay I\u0027ll start I\u0027ll start with section 4 and I read section 4 and I was like wow this is really easy see you happiest and alone with yeah I mean I I just think we shame to not capture that experience for other potential users of this document the the explanation of the theory is really great like I really enjoyed reading that it was very helpful so I don\u0027t mean to say that it\u0027s not useful I just think that if you put it in the same document yeah you\u0027re you\u0027re running the risk that somebody\u0027s gonna do exactly what you said they\u0027re gonna look at it and they\u0027re going to say whose is hard yeah and I think the other issue they\u0027ll call me to have make here is we\u0027re not rushed for time to get this through because something else is depending on it so I can take a little extra time to spit as long as on the topic of the QR code I think the idea of actually separating a tentative section five is a good one my main concern about the QR code is actually that the UX isn\u0027t very clear like it would be good to actually have a little intro section in section 5 yeah that says this is what the user will do because yes you know I can tell you what the user will do I\u0027ve read the document but but it\u0027s not entirely obvious and the UX is actually a little weird yeah and and you I think you really have to want privacy to want that UX yes so so if you really want privacy then yeah absolutely it\u0027s nice to be able to just take a snapshot of the SRV record yeah but if you don\u0027t like it\u0027s gonna be really hard to explain that to somebody who\u0027s not savvy about security yeah and the the thing that you lose by not doing it is relatively you know it\u0027s not a thing that I would be concerned about personally I mean you know there are lots of ways to do pairing that yeah that are reasonably private okay Carolyn Christian I was wondering if you were aware of the EAP newbs proposal that was presented in the t2 TRG summary you know working group or research group the other day by Malik study and his collaborators but it basically is based on this idea of using dynamic QR codes for network admission control and so I don\u0027t know if there\u0027s some may be shared primitives and particularly shared UX that you guys could potentially talk about but as we you know try to package this stuff up for you know just unsophisticated users it\u0027d be really great if we could come to some common operation today that they can you send me a pointer to the document demi-monde can do is a quotation the minute and and say hey it\u0027s also doesn\u0027t they I mean look at the yeah you know YouTube might want to get together in chat if you can yeah okay thanks okay thanks else is coming to the mark I guess we could take the feeling of the room on the two separate splits so I don\u0027t know what Danielle is viewing us but if you want okay okay so those in favor of "
  },
  {
    "startTime": "00:37:15",
    "text": "splitting out the problem statement stroke analysis from the spec in the pairing document please raise please don\u0027t raise your hand yes Daniel Catherine on closer to the mic you\u0027re a little I am yeah I am but he has to raise his hand on the meet echo there\u0027s a raised hand icon you have to click and then your pack man comes and then we press a button and then we check the QR code and then we let him in okay so give him another 20 seconds oh yeah yeah press the red button Ralph for the last time maybe press again you might be muted Danielle hello yeah yeah I just wanted to say that I can hear you it\u0027s like all I wanted to say because you asked whether I\u0027m listening yeah and do you agree with the proposed resolution how splitting the document speaking yes yes and and speaking at your code in a special chapter yes I think that\u0027s a very good idea right okay okay okay so we\u0027ll take the do we have to press the button to cut him off as well normal yeah okay all right bye that\u0027s so fun so all those in favor of splitting out the problems take analysis bits from the solution bits raise your hand yeah separate document all those you think it should stay as one document raise your hands okay and all those are a reading email reason okay so that was that was about ten four and one again so I think we say go ahead and do it I\u0027ll just do a check on the list maybe just to confirm over a week okay so yeah and to keep the put the QR code in a separate chapter in the solution bitch yes is that what we said what was the proposal for the Curie we need to have a check on that that is in the solution document so I mean I don\u0027t want to murky played a number of documents if you do yes well with this we\u0027re not in danger of running out of IRC numbers yet oh my god oh really "
  },
  {
    "startTime": "00:40:18",
    "text": "I\u0027ve just heard about it about five seconds ago oh my god you\u0027re getting out just in time Ralph what was the question yes so I think we probably ought to take the feeling of the room about what we do Dave three ways okay just two ways yes you can leave it as it is now you can move it as Christians proposing or you can split it a separate document I think the example that Kerry gave is a possible argument as to why a separate document might make sense if you would tend to say exactly the same thing about the UI as you would in the other draft and maybe a third one and so on you know I don\u0027t know if there\u0027s value but it is value and asking the question that way to see what they\u0027re suppose the third option separate draft separate chapter and exactly how it is down in it no change okay right so let\u0027s go through those three so all those in favor of leaving it as it is now raise your hands all those in favor of putting it into a separate section in the existing document raise your hand six all those in favor of putting it into a completely new document and or sting the IRC numbers raise your hand okay so we\u0027ve got majority was about it was one seven one I think there\u0027s a separate section in the same document great thanks very much Christian thank you so next up is Stuart and three on the PDF link box that 20-minute session turned into about forty five so I will go through this really fast because I want to leave time for the other agenda items that are important anyway it\u0027s six minutes behind it\u0027s okay oh yeah okay so bit of a reminder about why we\u0027re doing this because we have multicast dns multicast is expensive or unreliable or both on many newer network technologists on the old coaxial Ethernet you stick the vampire tap in and all the packets go everywhere anyway so it doesn\u0027t matter on Wi-Fi as we\u0027ve gone to higher data rates multicast has not kept up so the disparity between unicast and multicast has got much bigger a battery savings on phones and tablets as meant multicast is much less reliable on Wi-Fi when we have more complicated home network topologies that aren\u0027t a single link link-local multicast doesn\u0027t go everywhere when you have mesh networks like a to 2011\u0027s supporting multicast multicast reliably is very cumbersome and of course on enterprise networks "
  },
  {
    "startTime": "00:43:19",
    "text": "most enterprise networks I would say today just block multicast at the AP so there\u0027s a number of reasons we want to get away from depending on multicast quick state of summary Ted and I have been working hard and we got our four brand new dog before this meeting and there are now enough documents that unless you\u0027ve been following this from the start it\u0027s not clear how they all fit together so that really called for a road map document and I\u0027ll talk about these others in a bit more detail we have a way of registering instead of using multicast we have the broker which provides a layer of indirection for the discovery proxy and we have something that Ted came up with the idea of a relay that is a compliment to the discovery proxy three of our documents have been updated yet minor updates the discovery proxy document is basically finished not expecting any changes there is this issue about updating the reference to dot home which is a trivial change it depends on push which depends on session signaling which is currently still being debated and we are trying to push that along but that is that is where that sits right now two documents were not written and as a result of the discussions with Ted he has kind of talked me around to the point of view that we don\u0027t need these and that\u0027s why I\u0027m mentioning it to get the sense of the room if other people agree the advertising proxy was conceptually the mirror image of the discovery proxy the discovery proxy is what lets a remote device say I\u0027m not on that link over there but can you do discovery for me on my behalf the advertising proxy would be the counterpart where a device offering a service like a sensor or a controller like a light switch could say I\u0027m not on that network but can you advertise the service that I provide using multicast and a related issue is when you have multiple links in the home you don\u0027t the names to be duplicated so we want to waited to deduplicate the names and Ted made this point that we\u0027re doing all this work to move away from multicast because there are a number of reasons it\u0027s not just desirable so do we really want to put a lot of effort in perpetuating more use of multicast and when you put it that way I thought no we don\u0027t so unless other people feel strongly my filling right now is we should drop this and and really consider I\u0027m seeing nodding from Dave Thaler there so that\u0027s good we need support multicast for the 15 years of legacy devices that we already have on our networks but but moving forward I think we should be encouraging unicast registration as a much more efficient "
  },
  {
    "startTime": "00:46:20",
    "text": "and reliable mechanism for the networks I just talked about so I don\u0027t a rathole on it now but at some point I\u0027d like to hear more about how to deal with legacy devices but okay but no no that\u0027s actually a good question because that\u0027s about what I was gonna get into a even have pictures okay so because of all these little pieces I actually think it\u0027s good to break independent things into separate documents Ted made the comment that if you want an implementer to look at something something that seems small and approachable is a lot more attractive than a hundred page spec they\u0027ve got to wade through so where things do naturally decompose into modules I think that\u0027s great but knowing how these Lego blocks stacked together then becomes a challenge so I have taken a first cut this is just a draft zero zero but this is a start at doing the roadmap of how these fit together and this is a few pictures to elaborate on that so a client gets a configuration from the network here at the IETF the network is telling your devices you should look in meeting dot IETF dot-org the mechanism for that is in RFC 67-63 so I won\u0027t spend time repeating that now but the client gets configured automatically or you can do it manually if you want to type it in how that happens is is a separates question but once that is done the client then follow those instructions and it says I\u0027m going to query link 1 dot example.com well the normal DNS NS record delegation hierarchy tells the client and that this device on the network is the authoritative server for that domain name so the client sends its query there and the discovery proxy instead of consulting its own file on disk like a normal DNS server it uses multicast queries to find the answer to that question guess the replies sends them back to the client so this is the basic motivation behind the discovery proxy a remote client can now act as if it\u0027s local and the proxy will do the queries on its behalf the client can be configured to look in more than one domain which has a number of useful applications so you might tell it to look in three domains and it will then query three links three different discovery proxies and discover three different sets of servers and get all of those results back and present them in the UI this is done and implemented today and works fine when you have more clients all of the clients are talking to all of the discovery proxies and if your discovery proxy is a little bit of software built into your Wi-Fi access point it may not be engineered to handle thousands of connections and the clients if they\u0027re battery-powered may not want to have multiple connections so the solution "
  },
  {
    "startTime": "00:49:22",
    "text": "here Oh before I get onto that little tidbit I wanted to point out because it may not be obvious clients don\u0027t all have to query the same three so a client here might be directed by the network to query three different links and a client here will query links one two and three and a client here will query links two three and four so if you had say like a long narrow building or maybe a circular building that sort of doughnut-shaped then then the clients in each segment can be directed to the network to query their segment and the two adjacent ones so you have a kind of sliding window effect that you\u0027re discovering things that that are nearby and you don\u0027t have the issue that if you happen to be right at the edge of your segment you\u0027re finding the thing 10 feet away because you\u0027ve got this plus minus 1 overlap but let\u0027s go back to my simple example where all the clients are querying everything and you\u0027ve got this big mess of connections this is where the discovery broker comes in instead of telling the client to look on this link and this link and this link we say you just look in services or at example.com and the authoritative server for that is the discovery broker and where it gets its answers from is not a zone file on disk and it\u0027s not multicast it is unicast DNS queries to the three different discovery proxies and then it can amalgamate those results and return them back to the client and that way if you have multiple clients each discovery proxy still only has one connection to one discovery broker which is a big iron server in the data center and each client only has one connection to that discovery broke up so it saves battery power on clients it saves CPU load and resource requirements on the little discovery proxies on the network so that\u0027s the motivation for the discovery broker is it lets you put a big server in the 19-inch rack and not expect every little access point or every router on the network to support thousands of clients so let\u0027s go back to the simple example without the discovery broker and the last thing I\u0027m going to talk about now is an idea that Ted had and like a lot of good ideas it\u0027s one of these things that in retrospect seems really obvious once it\u0027s explained to you and Ted Ted is a long history working in DHCP and I\u0027m guessing that might have been what inspired this in the residential markets your home gateway has a DHCP server in it and coming from Apple with our airport base station line that\u0027s my model of DHCP so thing in the home gateway but in the enterprise all the routers on your "
  },
  {
    "startTime": "00:52:23",
    "text": "network run this very lightweight bootp relay agents and the actual brains of the corporate DHCP server is a big iron server in the data center and Ted said why don\u0027t we do that so here instead of having a full heavyweight discovery proxy on each link we have a discovery relay which is like the bootp relay agent for service discovery and it talks to one client and that client is the actual discovery proxy so we\u0027ve taken this piece of software the discovery proxy and split it in half so it has got this relay agent it can talk to over there but it does its thinking and logic processing over here and of course once you\u0027ve done that those three light blue boxes on the Left don\u0027t have to be different bits of hardware that might just be software running on a single server in the data center so this is Ted\u0027s inspiration and Ted will be talking in more detail about this later on so that\u0027s the end of the pictures and I\u0027m just going to run through the rest of what the roadmap document covers and how that relates to the documents and in my mind the way I divide this up is in three parts is how data gets into the namespace so that it can be queried part one is all the legacy multicast dns devices that we have and the answer is the discovery proxy is the backwards compatibility story for existing devices and it builds on these other two documents the relay is not a modification to that document the behavior of the discovery proxy is exactly the same the only difference is instead of having a physical en zero Ethernet Ethernet interface that it\u0027s sending receiving packets on it\u0027s now got a remote virtual interface almost like a VPN tunnel to somewhere else but the behavior of the packets sent and received over that virtual interface are exactly the same so that\u0027s the legacy story part two looking to the future is how do we want to do this without so much reliance on multicast and that is active registration so to that end we have a draft 0/0 on what we are calling the Service registration protocol which in a way is just another name for DNS update with some profile or set of use cases imposed on it we use DNS leases as a way to do automatic garbage collection so if a device goes away its data doesn\u0027t persist forever at EDD came up with a very interesting idea of how to do useful security without "
  },
  {
    "startTime": "00:55:24",
    "text": "onerous configuration and that\u0027s first-come first-serve security when you connect a device to the network and it says my name is X then if that\u0027s the first time it\u0027s been on the network and it has physical connectivity on your link then you say ok I trust you you can register the name X and along with doing that it registers its public key which has a much longer lifetime that the key might have a week or a month lifetime whereas the other records are only an hour if you then turn that device off it will disappear from your network it\u0027s not there anymore but its key will linger and if something else comes along and tries to masquerade as that device the registration server will reject it and say no you you can\u0027t tell me your Stewart\u0027s printer because I know Stuart\u0027s printer and your knots to us princess printers turned off right but I\u0027m not going to let you jump on the network and start capturing those print jobs so that is described in the service registration document or at least a simple outline of it I like that idea because it gives it gives better than no security without difficult keys it doesn\u0027t replace some of the other things we\u0027re talking about like QR codes and other things that may be better but I think there are cases where this might be an appropriate solution and then the other optional addition here is the energy saving stuff because power management is really important in today\u0027s world especially battery-powered devices the whole Internet of Things home automation many of those devices especially door locks or isn\u0027t an interesting example because it\u0027s hard to run a power cable through the door hinges so almost all door locks have to be battery-powered thanks dude sky now see who\u0027d question regarding their first-come first-serve security if I have a device that has that name and then I kind of throw it in the trash to the brakes and I get a new one does that name get stuck forever as their solution to this the the model there is that you would have to go to the administration page for your home gateway and manually erase the device so it could it could not get on the network without you as a human author izing that exception and saying yes I actually do mean this really is my new device and I trust it thank you make sense yeah Michael Lorenzen same question I like I have an open WT device at home my factory defaulted and my ssh key goes away and i have to do these ssh keys again so this is a very common case so whoever makes this administration page device this should be like it needs to be pretty easy for people to understand what\u0027s going on and like the failure case how to make that understandable to the user and Camelot is interesting it would be nice if your open wrt gateway kept its ssh private key somewhere that didn\u0027t get it raised so frequently it would wouldn\u0027t it it would I your your "
  },
  {
    "startTime": "00:58:26",
    "text": "concern is noted for many of the devices I have in my house like you know the nest thermostat in the garden sprinkler control and stuff like that I\u0027m not in the habit of wiping their firmware on so much of regular basis as I do with my open wrt gateway agreed but if there should be a recommendation about this being in so when you factory default it keeps it keys is there a downside to this I don\u0027t know but that\u0027s a good point yeah they favor so on that at the same point yes if you have a home router or whatever that\u0027s not that big of a deal although you have to worry about how do you scale it up to say you know an enterprise or a campus network or something like that and so I wanted to point out for comparison what wins server is also known as NetBIOS name servers do in that case specifically for enterprises because you do have to be able to span well it\u0027s temporarily off the network or whatever but I don\u0027t remember the exact details but at the 10,000 foot level if you haven\u0027t heard from it and so long where so long might be you know a month or whatever the policy is a week or a day what the policy is then when you need to know you unicast to that guys IP address to say do you have this name right and if it\u0027s been so long before you\u0027ve ever heard from them in the past ring that\u0027s been a month whatever and he\u0027s not there now then you do automatic garbage collection and you just throw it out and you pretend that you never got it in the first place and so it\u0027s like having a TTL on that record that says you either have to like ping me or re-register or be on the network when I ask you and if none of those are true then you don\u0027t need to have to send a human like MLD even what\u0027s that time-out be long enough to span yet the device comes and goes he comes into the office he goes away or whatever so it has to be long enough but this notion of being able to reach out and say hey last chance anybody there before ID garbage collect you I like that idea Thanks you know why they deployed and that\u0027s been there for you know 30 years or whatever so good good to know thank you Julia scrubber track am i right in understanding that this cannot be implemented if I don\u0027t have right to built our system storage do I need to put a disk in every single Rooter yes the the registration server I think if you implemented it only in RAM and you didn\u0027t have persistent storage that survives a reboot you would get weaker security properties right for as long as you don\u0027t reboot it it would remember the keys when you rebooted it it becomes another first-come first-serve scramble and during that window an imposter could get on your network so it\u0027s it\u0027s a it\u0027s a judgment trade-off whether you think that security downside is acceptable or whether you\u0027ll pay the extra for a bit of flash storage in that device I think both work what\u0027s the intent of the author of the documents "
  },
  {
    "startTime": "01:01:26",
    "text": "will you send the ATF police to my home if I implemented without persistent storage become a registration server the client can have a factory embedded aha that\u0027s not the problem but private key manufacturing times doesn\u0027t change but the server\u0027s got to remember the public key I I am thinking that our position would be given that this is better than nothing security there\u0027s there\u0027s a spectrum of better than nothing and security that has a burner ability if you power cycle the Gateway until everything gets back on the network and reclaims its name personally I could live with that what do you think Ted should yeah Ted\u0027s agreeing it\u0027s acceptable especially if that were oh yes especially if that were clearly documented in the specification someplace yeah yeah yeah right exactly we\u0027re gonna cut the mic line here David\u0027s cannot see again um so just to make sure I understand this well what we\u0027re doing on is the name which is the user visible name yes right I know of a manufacturer whose name I\u0027m blanking on right now that\u0027s making a lot of devices called David\u0027s MacBook if you look at the ITF network there are a lot of things called that what if I\u0027m the second one to show up with that what\u0027s the expectation for my device am I supposed to become David MacBook one and so on and so forth or something else that\u0027s a good I agree and if the answer is that manufacturer should stop doing that that could be a possibility thanks for raising that point I\u0027m not gonna try to answer it right now because we\u0027ll run out of time if it automatically renames then that\u0027s one solution but that\u0027s also unpopular if your computer changes its name against your will so that is a thorny user experience issue certainly if if I am connecting for some reason file sharing screen sharing some kind of service to David\u0027s MacBook here at the IETF I to suddenly get the wrong one tomorrow which is the point of this security the challenge is that what you want to have happen in your own home and what you want have happened at a conference of a thousand people are different and that\u0027s and making that automatic is interesting Carolyn I just wanted to raise the point that came up during the privacy discussion earlier about the fact that this is a persistent identifier that might expose some information so you might want to at least note that the security concerns section why not take a look at the secret handshake you know sort of technology that we\u0027ve been discussing yes we\u0027ll definitely want to check what\u0027s revealed thank you okay so "
  },
  {
    "startTime": "01:04:28",
    "text": "I said there were three legs to this I\u0027ve covered the first two which is getting data into the namespace for your 15 year old printer which is not have its firmware updated getting data into the namespace for the future worlds of products that don\u0027t exist yet and then once it\u0027s in the namespace the question is how do the clients do the queries and the good news is the clients abook for more than 10 years supported both multicast and unicast querying so just a quick recap with the documents here dns push notifications is a way of getting timely updates over unicast dns to give it the same time in us that multicast dns has and that builds on session signaling the discovery broker is this layer of abstraction that lets us do the sliding window around the building and other things like that in an efficient way without n-squared TCP connections and that is the last of my slides great thank you she\u0027s got a couple of minutes for questions go ahead yeah if you go back to the where you added the relay on the diagram yeah we split that up you don\u0027t have to oh so maybe again oh no it\u0027s not peanut oh sorry yeah of course you felt that where we had the relay yeah we next right there you intercept the relay and then you said that you could like collapse the discovery proxies right there yeah so then what is the difference between the collapse discovery proxy and the discovery broker they have some similarities in terms of the operational issues of where you put the hardware they both have the advantage of putting less demand on the little nodes out in the edges of the network the discovery relays more lightweight because in the other picture you really have a full-fledged discovery proxy that knows how to do the rewrite rules it may have some application specific optimizations in it the benefit is it\u0027s only supporting one client but you have to write all the code in this case there\u0027s less code running there\u0027s no no I think you misunderstand me okay discovery proxy now it\u0027s been split up into these two pieces yes and the piece that the client is talking to looks a lot like the discovery broker now from the clients point of view it is using standard or standard ish DNS if "
  },
  {
    "startTime": "01:07:28",
    "text": "you can\u0027t the push notifications it is using those standard ish mechanisms to do its queries and the client doesn\u0027t know whether it\u0027s talking to an authoritative server with a text file a broker a proxy it could be talking to a broker that\u0027s talk to another broker that\u0027s talking to a proxy the client I mean that\u0027s one of the benefits here is is those arrows on the left-hand side are the same protocol in all cases I\u0027m writing at the discovery proxy and I can\u0027t tell the difference between that in the discovery broker in this ah the difference the the terms refer to what I might call functional units not necessarily pieces of software and I think if I describe the functions that that might make it clearer the discovery proxy is a gateway from a unicast domain name to doing multicast DNS queries so it is a unicast or multicast gateway the Discovery\u0027s broker is a unicast to unicast gateway and it exists to do a fan-out so that one unicast query comes in for services on example.com and that may be fanned out to two three four five individual queries on the other side the Discovery proxy never does a fan-out it\u0027s always a one-to-one a query comes in for link wanted example.com and a query goes out on one link using multicast so it is a one-to-one multicast unicast or multicast translator the broker is a one-to-many unicast to unicast fan-out multiplexer now of course these could end up being folded into one piece of software that is doing all of that under the covers but in terms of the specifications this is why I kind of made the allusion to Lego bricks is it may tends to decompose those or separate logical functions you can combine them in imitation absolutely thanks yeah we do need to move on I think you had someone want to just say a couple of words about an implementation just quickly while you do that we\u0027ll bring up the next or I can just sneak in your slides that you don\u0027t need so just speaking yeah I am took your Honam geography and I sort of accidentally independently implement that large parts of which steward was talking about for the registration service this is tofu yes yeah oh thank you so you\u0027ve got about yes we go fullscreen you\u0027re off yeah oh if you\u0027re freestyling yes so so it\u0027s sort of it\u0027s sort of a it started "
  },
  {
    "startTime": "01:10:29",
    "text": "out by me wanting to be able to find my devices in the network and so what I what I wrote was a sort of DNS update proxy server that sits in front of an authoritative DNS server and we\u0027ll do the first come first serve slash trust on first use registration protocol which is identical to what what Stewart was torturing about and then that will and then it will apply some policies you can say only talk to these IP addresses disallow certain names disallow certain address ranges and then it on the other side that proxy will be normal TCH signed updates or it can update Unbounce upstream server so you can also do like if you have you on your network you can put internal addresses and one and global DNS and the other and then the client will do most of the lookup dance I didn\u0027t it doesn\u0027t quite I have not read any of these drafts before implementing this so I\u0027ll go and change that to support this um and it\u0027s about 2500 months ago next slide so and these are the main differences and this was before I spoke to Stewart if not highly accurate anymore but instead of the update leases I just overload the TTL which has some sometimes I don\u0027t know if we can discuss that on the list later whether or not like it allows you to do per record lifetime from the client to like so they become the garbage collection times whereas the update lease that\u0027s for the whole thing so that\u0027s that\u0027s introduced that it just it only speaks TCP so that you can put this thing theoretically they could live in the cloud which I think when Beauty is talking about you need flash to implement this well you cannot have it in your root and you can just have it in the cloud and then because if you use TCP you get a collect back should you don\u0027t have to worry about spoofing and then there\u0027s a server grab and it doesn\u0027t do the sleep proxying and it doesn\u0027t do full dns service discovery so I created this just for a and records and but other than that it it works and I use it to sort of fight my devices on my network with ipv6 and it goes into public DNS and so on and it also has this like you can also use this once you\u0027ve registered the key so the client can tell the server how long is my P don\u0027t need to be around so if it\u0027s a client that\u0027s only running in RAM and it knows it\u0027s going to go away consider with a short lifetime but once you have the key you can keep that p.m. and you can in principle allow updates from anywhere so I can have like my laptop mydomain.com refer to an IP address and at ITF it\u0027s great which is an ID okay thank you yeah if you can send details so that\u0027s the list that people can take a look that we fantastic so now we have Ted somewhere my myriad of what do you get this one "
  },
  {
    "startTime": "01:13:33",
    "text": "yeah yeah yeah yeah okay so we need to kind of speed up a little bit I\u0027m gonna go through this pretty quick because I think Stewart actually covered most of the concepts my name is Ted lemon by the way it\u0027s this one sorry here we go so basically Stewart already explained all this stuff let\u0027s see so that\u0027s who Stewart covered that so so some key points that Stewart didn\u0027t mention in detail so the discovery proxy that\u0027s the that\u0027s the thing that that accepts unicast queries and sends multicast queries discovery proxy the modified discovery proxy that speaks to a relay proxy can still speak directly the link that\u0027s connected to it it can also use a real a proxy to speak to the link I expect that in the home net use case which is the one that mostly informed this for me the relay proxy and the discovery proxy sorry the discovery relay and the discovery proxy will be separate devices even on the same on that router and of course it can speak to the two links that it\u0027s not connected to using a relay the discovery relay is really stupid it doesn\u0027t do any translation it just receives multicast packets from the it receives the content of a multicast packet from the discovery proxy and and multicast sit on the approp when it gets multicasts from the link it sends them to the discovery proxies completely stateless there isn\u0027t a request response kind of thing going on it\u0027s just one it when it gets a multicast from the link it sends it to whatever discovery proxies have subscribed to that link and when it gets a multicast to send to a link it sends it to the link there\u0027s no nothing more than that any caching that occurs happens in the discovery proxy the discovery proxy talks to resolvers even though even though the discovery relay is speaking unicast on the upstream side regular devices are not ever supposed to talk to it and in fact we the the draft has details about how to set up the operation of it so that that doesn\u0027t happen because it\u0027s kind of important that it doesn\u0027t happen yeah so there\u0027s a ton of stuff about management in the draft that may seem like it\u0027s superficial or unnecessary but this is a to make this work cleanly requires "
  },
  {
    "startTime": "01:16:35",
    "text": "clearly specifying how the how these devices are discovered how they agree on the on the identities of the links and all of those things the management stuff just to I have this this like issue with the discovery relay in the discovery proxy that it\u0027s not clear to me that you really to Discovery relay right discovery relays nice because it\u0027s smaller than a Discovery proxy but it adds a fair amount of complexity when you put in the Discovery relay however that complexity wouldn\u0027t go away if you didn\u0027t have a Discovery relay in the automatic configuration case you still need all of this management stuff whether it\u0027s automatically configured through a management console or whatever you still need to be able to say so suppose we well so you\u0027ve got devices that are that are you got the central device that answers queries and you\u0027ve got all these all of these routers on your network each one of which may be a discovery relay and you have to configure that it\u0027s the central server to speak to the discovery relays if you you know I lost my train of thought so the point is that that\u0027s this operational stuff needs to be specified because it needs to be it it needs to be the case that when you have a network with this kind of setup that that everything connects cleanly and you don\u0027t have anything left out and you have a clean way of saying what connects to what so that\u0027s why that\u0027s that management stuff is in the document has anybody read the document by the way well that was a more general question we have who has read the complete set of documents that Stuart intead of put forward so ok so I think I mean the explanations here have been fantastic I think it\u0027s based on the fact that any four people have read them it\u0027s a bit early to ask where they\u0027re talking this working group items but yeah I think we\u0027re gonna have some good list discussion you know now that we\u0027ve had them introduced yeah I guess I don\u0027t the the main high level stuff that Stuart presented is the stuff that I really wanted people to see i I wanted to call your attention to the management stuff because it is it\u0027s more than half the document of the relay document and the reason it\u0027s it doesn\u0027t necessarily belong in the relay document but it seems like a good place to put it because that sort of muxing and democracy needs to be documented somewhere and it would be a mistake to implement a relay that didn\u0027t support all of that muxing and do muxing so hence in the same thing we talked before about a draft that how you deploy this stuff and that would be kind of part of that yes I mean it could go in a separate document I mean I think that\u0027s one of the questions that the working group should probably answer yeah if it went in a separate separate document obviously we\u0027d have a document that described both how to manage the connection between discovery proxies and discovery relays and also the connection between discovery proxies and discovery brokers so that would be a few more moving parts it\u0027s actually not a bad "
  },
  {
    "startTime": "01:19:36",
    "text": "thing but it\u0027s it\u0027s absolutely required to do the management stuff if you don\u0027t do the management stuff you\u0027re screwed oh definitely I mean make a quick request we only have ten minutes left and I would really love to hear the stuff that carry out I think I\u0027m done so unless anybody else would like to say we have one minute left on this say okay great thanks Ted and and stewardess you know I think people have got a really good idea of the future items now so the last item on the agenda is Kari who\u0027s going to if I can find it that\u0027s the mapping one isn\u0027t it it\u0027s going to talk about the interactions between the core resource discovery in the SSD Interop we\u0027ve also got Caston in the room which is great to join any discussion so you\u0027ve got ten minutes so I Steve probably got the wrong one as well I don\u0027t know why this - there there you go any second now it should appear okay all right so I will do that basically I\u0027m not sure if we have deliverable in this group but I think we at least have the desire to sort of discuss this topic of interoperability between what the core working group is doing visa Vee resource discovery and what we\u0027re doing visa Vee service discovery so I guess my job is to I\u0027m just gonna start by asking you to suspend your disbelief til I get to the end of the talk I\u0027m going to try to make the case that at least at the level of restful api entry points there\u0027s some commonality between resources and services so anyway this work historic no this work goes back actually about six years oh yeah sorry this work goes back about six years originally when the core working group was chartered they did not have a requirement to do their own discovery but to demonstrate how it might be used with existing discovery mechanisms namely DNS SD my colleague Peter van der stalk and I did a bunch of drafts in core talking about how this could be done but eventually core decided to go in a different direction and so as kind of a stopgap we said well here is at least the way that you could translate between the two systems and our motivation for that was to support heterogeneous environments for example HTTP servers or HTTP clients and co-op servers which could be enabled by something that Cora calls a cross proxy because of the similarity that\u0027s what we have before so I came here arrests on both sides so anyway I hope to sort of explain or answer the the why and what "
  },
  {
    "startTime": "01:22:38",
    "text": "questions here and then at the very end we\u0027ll just talk a little bit about how we proposed to do this it\u0027s not okay I think the point I want to make on the first slide is that service discovery and resource discovery could be viewed as being complementary resources are potentially much finer grained than services so potentially I could formulate a query in the resource discovery world for the B register of a color light bulb but practically speaking you really want to you know come at that light bulb from some entry point and then from there you know using the tools of rest namely hypertext links and get to other places that you might be interested in I think you okay with the screens now yeah great what do I need to press for you next I\u0027m not going to touch it now it\u0027s working okay all right next slide after that all right so these are some of the basic background items the main deliverable of core of the core working group was the coop constrained application protocol building on other IOT standards that had come before such a 6lowpan for supporting ipv6 over constrained links and ripple which was the output of the role routing group coop originally was rest with a UDP binding an interesting side note there is that multicast restful operations are now possible so the rest world basically is a set of architectural constraints you\u0027ve got a world of servers resources and as I said earlier you expect that a good restful implementation will allow you to explore it using hyperlinks takeaway from this slide is rest as the hammer so they try to basically cast every other problem as a nail and they they look at the world as consisting of resources okay so to talk a little bit about the resource the resource discovery method that they came up with it\u0027s based on core link format which in turn is based on web linking it makes use of these things called type links it\u0027s basically a relation between one link which is typically the thing you\u0027re asking you know what other links to you do you provide to these other links which are target links and the relation between you know the anchor and the target yes between resources yeah all right that\u0027s what I meant and obsolete target attributes so in the core world you basically can query a server and say give me all the links that you provide "
  },
  {
    "startTime": "01:25:39",
    "text": "by doing a get operation to a well known URI which is not well known slash core optionally you can provide a query string and what you should get expect to get back from that is a set of links that match your query so the core link format document RFC 66 92 find some new target attributes there\u0027s a thing called R T which is the resource type there\u0027s AI F which is you know tell me about your interface specification and the approximate size so as I said if you consider a restful api entry point to be something like a service then this is the sort of resource that you would want to potentially export from the core world into the dns SD world I should back up and say that as an efficiency core is also positon sub resource directories which is a repository of all this information from all the links that exist on that network so the logical place for this mapping agent to contact would be the resource directory and we have a draft that sort of describes this but that\u0027s a working group item over in the core working group it basically defines two new target attributes one is exp which is a hint that the the server who registers that links as I want this to be exported to a different naming system the second thing that we have is an AI NS attribute which is the instance of that so there are other hints that can be provided such as the domain that you wish to be registered in if that\u0027s absent then the mapping agency tential e has to figure out you know is there a good candidate you know for for the the the domain to put this in dot local being probably the obvious default hostname if it doesn\u0027t already exist has to be you know sort of cons DUP in the in the DNS world next slide it\u0027s a bonus points for quota and no any records element all right so don\u0027t take this too literally there\u0027s probably mistakes in this example in fact I know there are but the color coding is meant to sort of show how the mapping could potentially be done so here the mapping agent has has basically done a query to the resource directory and it says give me everything give me all of the give me all the links that have this exp attribute set and "
  },
  {
    "startTime": "01:28:41",
    "text": "then it gets back for example a response where the resource type is oh I see temperature and this is one of the mistakes should be oh I see dot RR dot temperature but and then the instance name is indoor temperature and the interface type is you know kind of a semantic tag application-specific semantic tag that tells you how to operate on this thing the resulting our ours is that a host name was synthesized if if it wasn\u0027t provided the quad a record is registered and we end up with a service of type oh I see this is the thing that I presume would be registered with the register of the service type registry but then below that the subtype of that would be a temperature sensor and then we would basically take other things that have been provided and they would be text value pairs that would be put into the text record so that\u0027s basically in a nutshell so with all my said it\u0027s on better being probably just stretch on a a few minutes to see if anyone\u0027s got any quick questions or comments on that thanks Jim I mean Kerry thanks Kerry I have a question for I\u0027m Stuart Cheshire from Apple for for you or maybe for Karsten that the OIC in that example which is in my parlance the service type in in core world it\u0027s the resource type is that registered in their eye on a service type registry there should be some sort of a namespace I think convention yeah well with the link format there are two registries so that the names that are under RT equals and the names that are under IFE codes they have a registry and oh is he EF is there court now has registered some some a te resource types there so this is this is the name that is registered but it\u0027s not a service but there would be no reason not to sort of like take the preamble part of the thumb of the namespace of those resource types and register that in the service type registry this could just be an RT and this this could be a rendition of the registered type and it would work for everything so you wouldn\u0027t have to inventor right so just what values can "
  },
  {
    "startTime": "01:31:49",
    "text": "have dots in them right and so the question to the stewart is or the in the blue down below or at subdue I see UDP is it a problem with OIC has a bunch of dots dot separated labels there put underscore to see there procedurally is a problem because they I honor I mean from a software standpoint we could escape the dots but but the the specification for the IANA service type registry says letters digits and hyphens because that is sufficiently expressive we\u0027re not going to run out of them and when you ask for a string you don\u0027t ask for a string with an ampersand in it if you\u0027re trying to wholesale import names from somebody else\u0027s registry with a different set of rules then they might not follow the existing Ayana rules and would either have to change the rules I mean that\u0027s a bit awkward to change the character set so that\u0027s the problem in procedure anyway with putting the entire rté into that position the procedural ish issue with doing what kerry has on there is and of course since as you mentioned there\u0027s errors on the slide the actual example that\u0027s registered as OSE does are that temperature and so where is the r dot in here and so i\u0027m guessing it would be our temperature underscore subbed on other words the RS and the very left end it\u0027s another sub label even beyond that right or you have to escape butter or whatever it is right so that the question is how safe is it to assume that the leftmost label is the one that\u0027s special I guess we\u0027re probably assuming that the the mapping agent has some sort of intelligence but yeah otherwise we might have to come up with some convention for doing this which i think is uh III Marshall is gonna go some for serve and got in terms of conventions I\u0027ll make one last quick comment because we do need to wrap up and I suspect this is a discussion I have to have with Kirsten and maybe we can do it offline but but for the minutes I want to raise this issue so other people can think about it to me when I say a service that is some entity on the network that you talk to with a protocol you maybe tell it to do things or you ask it questions and when Carson talks about a resource that\u0027s an entity on the network that you talk to with a protocol and you ask it questions or you tell it to do things to me it sounds like exactly the same thing but every time I talk to the corporate when caster\u0027s changing his head shaking his head right now it\u0027s like noticed on service it\u0027s a resource but the description of resource sounds like exactly the same words I used to describe a service so the a I think would help this discussion if we could actually figure out why resource is not a service certain III guess that\u0027s my claim is that certain certain resources quack like a duck okay thank you Carrie and still it cast an easy one last final quick comment that the answer to that which I\u0027m not going "
  },
  {
    "startTime": "01:34:52",
    "text": "to give is exactly the reason why we have this excusing there so we can identify resources that are worth it being announced as services so some may be some may not be so I think from the last meeting where we just had some people come together and chat we\u0027ve now got to the point where we\u0027ve got a draft I think it\u0027s been adopted by core this draft least the naming suggests it has been draft IETF core blah blah blah well the content of that draft has been part of the core resource right for you for like okay well it\u0027s good is now coming to light so he can discuss it sowing encourage more discussion of that thank you to everyone just to quickly wrap up on the actions I think we\u0027ve got a fairly clear idea of what Christians doing from the huns and votes that we took I\u0027ll just confirm that on the list Stuart stuffs and Ted stuffs a little bit early to adopt because only four people have read it so far but I think the explanation he has been fantastic and we\u0027re making some headway now on the Interop here which is great so did you wrap up thank you all so much for your collaboration goodwill and willingness to move things forward this will working group has been a real treat to work with we have just gotten down to it and gotten it done it\u0027s really I applaud all of you [Applause] okay so meeting closed I think the planner is in Congress 1 \u0026 2 in 15 or 20 minutes was there when we arrived can you unplug my power this one oh it is thank you "
  }
]