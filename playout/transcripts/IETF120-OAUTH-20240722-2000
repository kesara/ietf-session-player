[
  {
    "startTime": "00:00:04",
    "text": "Let's hear that already. Let's get done yeah yep Zerrini? No, we didn't do it. I didn't have any that. All right. Is there any? No. We didn't do it. I didn't. Nobody's inviting you Well, yeah, we'll forget of something, yeah Okay, hello, everyone Please take a seat Please take a seat and let's get going Thank you Okay Welcome everyone to beautiful British Columbia and the first Oath session This is the not well As you know, every that we do at the IETF, is governed by the not well So if you're not familiar with this, please make sure you're everything that we do at the IETF is governed by the not well. So if you're not familiar with this, please make sure you get familiar with this Meeting tips I'm good to hear myself. No, I'm good to hear please to sign into the session via a Datatracker. This allows us to know how many people are here and allows you to know to join the queues via a Datatracker. This allows us to know how many people are here and allows you to know to join the Q. Do you have any? Thank you"
  },
  {
    "startTime": "00:02:01",
    "text": "Q Do you have any, thank you. No, no, is this, did you join the session? No, no, no, okay Yeah, I'm not sure And if you're remote, please make sure to your audience and video is often, unless you want to speak up A quick update, we have three documents that are in a work group consensus Protected resource metadata, we actually I am the shepherd for that document, so I did that review and I've studied that right up there and I think next week we should be able to push it to Deb. I don't know if Deb is here but yeah hopefully next week we'll be able to to ship it the other two, Hannes and I will take care of them later in the coming few weeks The other one is we have the RFC Editor Q. We have two documents The last one was waiting for the security BCPs so now hopefully both of them will be published in the coming I don't know, a few weeks You never know with the RFC editor, okay So our agenda for today, we have a a few weeks. You never know with an RFC editor, okay. So our agenda for today, we have SD JOT, Christina, and Brian will talk about that. Then Brian, will talk about SDJOTVC a transaction token, I think George and the tool will be talking about this, okay? And then Aaron will be talking about a offer transaction token, I think George and the tool will be talking about this, okay? And then Aaron will be talking about all first party apps and client IT metadata And the last one Peter will have about 10 minutes to talk about in encrypted authorization response. We had to shuffle"
  },
  {
    "startTime": "00:04:02",
    "text": "shuffle the agenda a little bit we had PICA here first initially but we moved that to Friday Now, we still have a meeting tomorrow and another one on Fridays just a a reminder. So that's it for the agenda. Any questions, comments? and Jindabashin? Yeah, Mike Perrug is taking meeting minutes Thank you, Mike. If someone else can also add notes or keep track of the meeting minutes, please do so to fill in gaps filling gaps because it's sometimes difficult to sort of follow the intense discussions The link to the meeting minutes is on the agenda page You just go there Okay, Christina or Brian? or both 15 minutes? You have 20 minutes, I think. Hi, everyone Hi everyone, I'm Christina here to talk about this Dejot First things first, small affiliation change I did get, I did start an associate professorship at Kio University, so this work is being sponsored by Keog University. Next slide, please And kudos to brilliant background by brian campbell. Next slide So we are sticking to our pretty much common agenda for stage of presentations now. I'll start with quick over here refresher what it is goes through changes from last time, open issues, and next steps. Just to show in the room, how many people do not know how a stage out works?"
  },
  {
    "startTime": "00:06:02",
    "text": "work? Like never saying, never heard I'm just kidding. Okay, great news So I'll go very quickly over the first part then. Okay, next slide please please So in a nutshell, we are in enabling selective disclosure of claims within the joint by when the job itself gets protected, they sure is protecting the hashes, non-reversible hashes of o the data and the data is sent alongside, so just, you know removing the data out of the initial set does not impact the issuers on signature so that the allows for select disclosures in an nutshell And yes, it does assume on street party model kind of where there's an issue or is DJI who issues that there's the holder who gets it and the holder who presents it to the verifier. And we have been saying it from the very beginning but our motto has banned simplicity is a feature, so the goal is really um yeah tried to make it as simple and easy for implementers us possible. Next slide, please please This is it. Please parse it But just aside, um, probably see a lot of new characters or last remaining character that wasn't used, which is still there. The first three strings, dot separated, is JWS and those thingies after connected using TILA is something we call disclosures. So basically, this is the whole string that holder would get from the issuer. Next slide And the payload, so this is decode"
  },
  {
    "startTime": "00:08:01",
    "text": "header payload and the signature So in the payload, you would have an array of strings and each string is a hash of an array which i mean basics before you are in coded array, which contains a assault claim name and claim value in that order order So this array... Do I get to be like a singer? So basically an array gets encoded and get hash next slide please please Yeah, so if you were trying to disclose only one of those, use select disclosure that matches that hash, and next slide, you would send only that disclosure So the previous long string was what that issue This string is what's being presented um so you see they're like much less green parts and this one. So this is a case where user decided to disclose on the part of it. Next slide, please Okay, kudos to Richard F. Nord Barnes, who I don't think is in the room A slight update in terminology, so we are now clearly differentiating So a thing that gets issued, that we're called as D-JOT now, and the thing that gets presented was key binding, we're calling ST ST-JOT plus KB. So this is the thing which gets presented when the key binding is needed. So in SDJOT spec itself we're leaving it open, whether key binding is required or not So in this case, two is the string that we're saw on the previous slide, when users selected was trying to disclose, users adding another job, which is something we're calling key binding jot, which proves possession of the cryptographic key material, which is in the job itself. Next slide please. So that was"
  },
  {
    "startTime": "00:10:02",
    "text": "a quick overview, probably not too quick So last idea, since last IETF Brisbane, we've published to versions, 9 and 10. And again, kudos to an amazing background from brian campbell. Next slide, please So what's new in . I already mentioned this but we're clearly distinguishing as SD-JOT from SD-JOT plus KB Thanks a lot to again, Richard for working with us on that and that kind of unblocked a lot of other things So second point is, it's been that issue that's an issue that has been open for a long time but we did provide a b and f notation for us St.JOT and OZ other parts The third part is what was needed for EIDIS implementation of, is SDJOT, where some implementations need J JIS, which is JSON sterilization, basically and we updated the structure to reflect their feedback Yeah, that's it And then, yeah, we did clarify some things um that, you know, came as an implementation feedback uh so yeah some sections got consolidated, clarified clarified how examples are perceived. So yeah, the bottom four points are really about kind of editorial. And the bottom point is interesting so before we were leaving it pretty open that any mechanism can be used for the key binding and we're we the language much, much stronger that like pretty much it has to be the confirmation claim that is used. Next slide please So that was nice now to ten"
  },
  {
    "startTime": "00:12:01",
    "text": "again there was also research feedback We do have a feature of recursive disclosures and we have been getting some questions around, you know how that works. So we added some clarification to, you know, hopefully stop getting those questions. And then a tutorial updates and fixes Next slide, please So in our GitHub right now, we have when I was creating the slides, it was two issues and Brian opened one more, so now we have three But they're all really editorial So, yeah going to the next slide so the question from the editors to the working group is, hopefully there will be no SDJ job presentation in the next IETFs, meaning do we think the draft is ready for the working group last? Hmm people have a chance to review the legislation? version of this document? No. Maybe version is the last one? Do you remember? Ten. Ten you've reviewed the last version of 10, please raise your hand Okay, two people three maybe, four, five okay, okay, so I think we need probably more sorry, somebody in the queue like you dropped Okay. Let's hear you sing out. Okay have these three open issues? resolved because then we could potentially just start a working group last call We can't start a working group last call if they're open issues in the document. Like is there something?"
  },
  {
    "startTime": "00:14:02",
    "text": "you are going. Brian disagrees Wait going? Brian disagrees. Wait The editorial of the M.I. Oh, yeah are editorial in nature, and my hope was to consider them as sort of rolled up underneath the umbrella of last call feedback. Okay Thank you People on remote cam here Which, what? Like, Brian, the most recent comment Zach, he went to the microphone He went to the mic after that, yes Okay that's fine okay. Brian just said that editorial comments, editors are hoping to address as the working across whole feedback. Okay so it seems that few people review the document and I think honestly, and I think we should, we should a work group last call and just make sure that people review the document and get it going, right? So if, as long as these open issues are just editorial, I think we should be okay So we'll do that next week, okay? Watson I think this work is actively harmful to end user privacy You know, we're saying that you have these tokens and are just"
  },
  {
    "startTime": "00:16:02",
    "text": "discussion of the privacy impacts is really, I think, in the draft still underselling the key point, which is it's the sum total of information you ever show as well as the fact that where you showed it is completely visible to everybody. What's on, do you want to? get closer to the mic and repeat that again? fact that where you showed it is completely visible to everybody what's on do you want to get closer to the mic and and yeah sorry I think can people hear me in the um let me turn up the yeah it's difficult here in the room. I think maybe. You know, I, in the, um, let me turn up the... Yeah, it's difficult here in the room. I think maybe... You know, I've heard, can people in the Meetecho hear me? yeah so do you want maybe um write that comment in in a can people in the Meetecho hear me yeah so do you maybe um write that comment in in uh as uh like in in the chat there that would be helpful helpful uh let me okay okay uh what is going on Yeah, I'll do that Okay Meanwhile, anybody else has any comments, questions? any concerns? I'll just preempt say that this is far more privacy preserving than non-selective disclosure JOTS. What a surprise That the zero knowledge proof mechanisms while being attractive are yours from potentially being deployable if we actually want to allow some sort of selective disclosure meaningfully in mobile driver licenses and European EID documents, this is our last best hope because we actually know how to secure the keys in hard storage and do the sort of traditional cryptography"
  },
  {
    "startTime": "00:18:02",
    "text": "which we have yet to, you know, all due deference to the JWP folks come for the next meeting, yeah that's still a work in progress. So if we want to plausibly do selective disclosure this is our best alternative, and we should continue progressing it Awesome. Thank you, John. Go ahead Thanks, John. I think somebody else in the queue Mike Barack here. I'm going to strongly concur with Mr. Bradley, having evaluated a lot of these options and run a bunch of tests, this is at least available today working and prevents disclosure, like it provides the ability to property minimize data, right? That's a good thing. That's a desirable property, and we can use it today So I'm a big fan of this work proceeding Thank you, Mike. We have issues of participants in the room think I'm going to stop that. Okay, thanks, Christina We'll start the microbrelaskol call next week. Okay, thank you Brian You want control And let me find you here Ha ha ha ha ha Jack I encourage you to point out other areas as we go on Copy paste is a bitch"
  },
  {
    "startTime": "00:20:02",
    "text": "Excuse me. Sorry, as they said in the local festival festival right so i'm here today to talk about SD job-based verifiable credentials Unfortunately, my co-authors, whom know about this than I do are not here so you get to listen to me today but we are actually at IETF 120 and Vancouver there in the background, which is IETF 20. Thanks again, Dick. Ryan raised you much tolerant than Christina. How about that? You can adjust it out can adjust it. Or adjust it out. I'll hold it that way. Both hands I don't know what to do with them anyway. Okay it dance to? I might not dance, but John Brown I'll hold it that way. Both hands. I don't know what to do with them anyway. Can I dance too? I might not dance, but john bradley is pretty strong in that area so hey you've seen this before sort of the rough agenda here We're going to go a little bit of a refresher, talk about changes from last time, talk about open issues and questions in general and discuss next steps So, the basic idea is we're just describing a data format as well as validation and processing rules to express verifiable credentials which is a term many are familiar with and lots of people like to use with JSON payloads, both with and without selection disclosure based on the SD job format and we just learned about the SD job format and learned that everybody was our already familiar with it so I won't go into a lot of detail on that, thankfully. This uses SDJOT jot as well as the well-established jot content rules and extensive following model as a base for representation of verifiable credentials in hopefully a way that real-world people can actually use and deploy My thing goes on here. It does not at all in any way utilize the W3C's verifiable credentials data model, either version 1,11, or version 2.0 in progress"
  },
  {
    "startTime": "00:22:02",
    "text": "Thank you There's no, now with less RDF already yet. So a few examples or a and again an example that I'll go through here just quickly to kind of illustrate how this works This shows how these pieces could be used theoretically, hypothetically, to represent the concept of the person identification data from the ARF architectural and reference framework, using as the data of a German citizen. So we've got some input claims here Basically, this is the data representation of this person's data in the I'm saying, personally identified data or whatever it's called, But some of the main concepts here to look at are we've got a bunch of claims name, family name birthday document type address whatever some pieces of age verification, which are just in JSON are straight up Boolean values relative to the age. There's nothing super fancy going on here, but they can be individually selective disclosure or not. And maybe sort of the key pieces of this is a hypothetical URI represent this set of data as the verifiable critical type, the credential type saying what's in here In this case, it's just an example, it's a URI, but the idea here is that this whole thing is typed with the VCC construct and that says in turn what the actual data within the credential itself would look like To make it selectively disclosable, you do some of the selectively disclosable stuff. Here's the whole thing encoded it's not really that valuable to look at But here is the payload after being sort of processed for selective disclosure And you see very similar to the example that Christina just showed, the SD underscore SD claim here showing the hashes"
  },
  {
    "startTime": "00:24:02",
    "text": "of data that is contained in disclosure outside of the signature. Those are all the attributes or claims that have been redacted or made selectively disclosable in this document You can see, for example, the age equal or over These are the various age-related claims. Each one of those over 18, over 21, over whatever have been individually redacted so that the holder of this document can choose one or more of those to reveal to the verifier as appropriate for the transaction as long as a bunch of their other data. Notably, the confirmation is still here and clear That's a key That's probably all that's super relevant This is the actual content of some of those claims So each of those hashes maps directly to the encoded disclosure construct that's outside of the signature again. This is just some of them, so you'll see like the actual hash of it is what in the document. That's what's integrity protected. The content is, um, uh, for transmittability and based what's in the document. That's what's integrity protected. The content is encoded for transmittability and basically as sort of a cheap canonical algorithm, it's not actually canonicalizing, just encoding over it, and then the actual contents of that include a salt for non-reversibility, the actual name and value. Here's just showing some of them name, birth, street address, locality, and so forth forth Sorry. And then the actual example of what would be presented would be the same content before. It's really hard to tell. I don't know why I thought this would be a good idea to put all this text in an example but ultimately this is the actual jot itself. I didn't even color code it to make it easy to see, and it contains only a couple of the disclosures. Oh yeah, in this case actually it's only nationality and the"
  },
  {
    "startTime": "00:26:02",
    "text": "age over equal to 18 disclosures that have actually been included in this. And then on top of that, there's a key binding jot included, which is basically another signature with an nonce and auditing an issue at time, and a hash over all the preceding content that more or less more or less proves possession of the private key associated with the confirmation key that has a public key within the actual sign token itself And then what is this? Oh, and then upon validation after processing the whole thing, going through checking the integrity of those hacks, against or finding them, and then replacing their value within the JSON of the document itself to produce the data that the verifier will have for further processing. This is sort of after the representation of the claims that are revealed and disclosed to the verifier itself So what's happened? since IETF 119? We are at least verifier itself. So, what's happened since IETF 119? Weirdly, that's the same number that had the beginning of the slide. Thanks, Dick In Brisbane, we've published in 04 just a couple of weeks ago It's an opportunity to throw a picture in there. And what if have we done in 04? So we updated a reference to the IETF status list draft document we had a individual draft name in there and now it's a working group adopted document. We entered tight metadata, but just the sort of beginning of a structure around typing metadata for individual verifiable credential types. So beginning to introduce things like a schema document for the type introducing display information naming information, although that's not in here yet, it's coming or a possibility to come, for the types So rather than the actual raw clay names, you can reference names to display to an end user and"
  },
  {
    "startTime": "00:28:02",
    "text": "give them locality information to display in different languages and so forth. So the beginning, constructs of that are introduced in the latest draft as well as actual JSON schema typing for that metadata And with the anticipation that metadata the latest draft as well as actual JSON schema typing for that metadata and with the anticipation that that metadata structure itself will be developed in so subsequent drafts to include more relevant and useful information editorial changes I always like to give myself credit for that. Updated the terminology to clarify digital signatures are one way to secure these VCs and their presentations. This is some if I remember correctly, some sort of weasel wording around the fact that there are some folks that want to do sort of like a ECD type key exchange up front and secure some of these pieces with a Mac to for reasons, for reasons, we're not describing how that works or how it could be done we're made sure that the language in the document itself didn't preclude that kind of application algorithm so that it would be legal for the types of entities that would want to do that can do it without being in a direct violation of anything in that perspective rfc would be legal for the types of entities that would want to do that, can do it without being in a direct violation of anything in RFC, prospective RFC, excuse me. And then we reworked some key resolution validation rules around X5C, which is the certificate header chain in the document. We had some varied some things that needed some rethinking and hopefully it's much more clear, intuitive, and similar to how you would imagine validation rules would work when there's an X5C header in the document itself Open issue There's a lot of them and actually after sort of glancing over them, there's probably too many to go over in here. And it's a little bit out of hand It needs some work and some clarity"
  },
  {
    "startTime": "00:30:02",
    "text": "That's really all I can say at this point so you don't want to discuss any of one of those right now? You have time Maybe maybe I was hoping you wouldn't say something like that just skip over it um You know, It's up to you at the end. Yeah, we'll come back to them We are diligently working on this, but sometimes the issue tracker gets, gets out of sync with the level of effort and ability to keep up over the hair. And I think we're kind of here there. It needs some TLC I imagine we'll get to it, and all in all, I think things are in good shape, but we need some work Maybe, oh, some current work in progress this is maybe more relevant although just related to what I'd said before about extending what's available in the type metadata itself There's a current open pull request that defines basically display and claim metadata so that really any of the parties involved with the transaction can evaluate the metadata independent of the document itself and give meaningful end-user display information about it, including like, I don't know, there's all kinds of stuff that are both localized, generally display names and information about the credential itself as well as individual pieces for each of the claims. Oh, maybe no notable, we are going with an approach where in order to identify the particular claim like what claim this data is about, we're using an array of string values, which basically identified the location within the document"
  },
  {
    "startTime": "00:32:01",
    "text": "itself where this claim exists which is, I don't know, seems sort of intuitive but various different approaches to this have been thought about and thought about in a lot of different places And this is a hope to do something simple that's easily implementable and doesn't bring in any dependencies like a JSON pointer or Jason path to do sort of the same kind construct but with a lot of other uh shall we say baggage I am currently fighting with Dr. daniel fett about what something like the locale should be a key within a map of the JSON itself or an object to indicate it or whether that should just sort of be a sub-property of the data itself. I'm obviously right about that, but we'll figure that out later So Brian, we have two people in the queue. Do you want to take questions now? Do you want to wait? Yeah, now's as good a time as any okay you're on he wants me to go first Okay, go ahead. I'm mostly here to save you from needing to build time by dancing or or del delegating that to me So the metadata is interesting I take it that none of the things that we're talking about is metadata are actually disclosed to the verifier This is information that's for the purposes of the wallet processing or the whole processing I think it's like largely intended to be for the whole processing and functionality, but certainly the verifier make use of it to do their own you know, display information or whatever, either on requests or upon verification And it's not a secret from anybody. It'll be well well-known, resolvable from somewhere So I guess that's a question is does it is it's scary from privacy well yes, because it may actually disclose what claims are available etc cetera. And so there may be some privacy leakage"
  },
  {
    "startTime": "00:34:02",
    "text": "There may be some reasons why you might know want to disclose that or it might not be ideal to disclose that to the verifier The other questions so one of the problems that were ignored about wallet interoperability is around the issuer expressing a policy to the wallet as in I'm issuing, I'm the German government and I only want the wallet to disclose these claims to people that have the appropriate QAC issued by a German verified issuer, which is a real but twisted thing So it will, as people develop these ecosystems, if we want interoperable wallets right now the European Commission kind of, thinks of things as, well, if you want to have a policy build your own wallet and then it will do that but if we actually want interoperability, we probably need to express some sort of policy in an interoperable way from the issuer to the wallet Is that metadata perhaps? a way that we could communicate that? to the wallet so the wallet would know? yes, for California DMV Anyone can ask for over 18 but if you want, the person's address, perhaps you have to be on a trust list someplace someplace So the question is, would the metadata perhaps be a way to annotate? that sort of policy information for the wallet to consume? Perhaps, yes. It's not actively on the list of things we're planning to add to it but I am well aware that there's an interest in expressing that sort of policy somewhere as well as"
  },
  {
    "startTime": "00:36:02",
    "text": "some debate about the appropriateness of where that policy might live. I think I'm aligned with you that metadata is probably maybe a good place for it rather than embedded in the credential itself I don't know, actually so we we need to find maybe yes maybe yeah So I think we need to figure that out and maybe using this document, see if people scream. I could definitely be amenable to that. I think it's probably the right place. Back to your previous comment, there are probably cases where the privacy of what the whole credential may or may not contain are relevant and meaningful you don't have to use this mechanism for that you could hide it and in most cases i think the actual potential content of any credential is going to be pretty well known anyway. So it's like, this is just describing it in a way that's meaningful And if you have more, I don't know, maybe I'm not thinking about it hard enough. I think that some sort of privacy analysis needs to, we should at least you're probably right So, you know, I'm one of the most anti-privacy people around but I will observe that we need to have an answer when people do look at this and say, ah, well, you're leaking So we need to at least, if it isn't a problem, we need to understand and explain why it isn't a problem Fair enough. Thanks, John Your own Your on, chef on, Chef. So, more or less in the same area but even simpler So I have a VC with an SDJOT in it I go to a bar here. I'm being asked whether I'm over 21 Then I go to a bar in some other country and I'm being asked whether I'm over 18. Do we have a protocol for the bar to actually"
  },
  {
    "startTime": "00:38:02",
    "text": "express what they want from me? even before policy? Yes? Christina do you want to go the mic? Hi, Christina. So is Deja and is Deja Duvici are kind of protocol agnostic? meaning the transfer protocol, but like, for example, PINITY for follow presentations protocol, that is vitally being used right now to request these things. It does have something that we call career language that allows to request like, give me, you know, like only this claim So yeah, we have that. And we, sorry if it's too much extra information, but we are introducing and updated, hopefully much better query language in a PEP, which is not presentation exchange. So yeah, we are actively working on that Maybe just to clarify, this is literally just the token format itself and the constructs, I guess, plus metadata and so forth there is work in the collected we around requesting presenting even issuing, and so forth, but that's not happening in the scope of this document or this working group for that matter matter So, okay, the subtext was the metadata probably needs to be aligned with this kind of query Yeah, the subtext, yes Great point. So we actually have something like this already in the Open ID for a room aligned with this kind of query. Yeah, the subtext, yes. Great point. So we actually have something like this already in the Open ID for Revalry credentials protocols And that's where I and Dr. daniel fett do argue where I think that those needs to be somewhat better aligned, but because those protocols, so those photos do to find something very similar to them But A, that's probably not the only problem that people want to use and two um did try to introduce these changes but the product was"
  },
  {
    "startTime": "00:40:02",
    "text": "being widely used right now and people did not want big breaking changes So long story short, we are doing our best to align them. But with mixed success so far Thank you, Christina You is clear. May I proceed? Yeah, I'm being told I have 26 seconds. Is that? Yeah like you can go a little bit further. Okay um, so media types. Um, You know, you know. So, um know, so the term verifiable credential was coined and sort of popularized. I'm not sure of the right terminology within the W3C standard organization for a variety of reasons that I won't go into and don't fully appreciate There has been an interest in defining something a little bit simpler, a little bit easier to use at least from the perspective of people involved in the world and doing so within the IETF for better or worse that work, this work here has used the term verifiable credit as well because it has some meaning to people so it seemed straightforward to sort of reuse the terminology in a way that conveys what's going on to people familiar with the term Until very recently, the W3C verified credentials working group was planning on requesting this set of media types at the top here which were a number of media types that were in intended to convey sort of complex layered structured processing rules"
  },
  {
    "startTime": "00:42:02",
    "text": "around their credentials, namely that it's a verifiable credential or presentation using JSON LD and then potentially secured through means of a jox an SD jot, or a COSE signature or COSI signature. I'm not sure how to pronounce that Apologies. As well as a number of structured suffices to be registered as well that helped convey that information. There was some disagree within the media type working group as to the okayness of multiple suffices suffixes I don't even know how to say it and whether that's okay the most recent conclusion, although I don't think it's a final done and done but is where we're at now, is that it's not okay that it's not allowed And so recently, that working group within the W3C request and received registration of application V and VP and is hoping to also register VC plus chart typo, there should be a P there a few others, and application VC plus SD Jot, which interestingly, enough, high breath, is the um the same media type that SDJOT is currently using within its specific and which a number of dependent down-the-line specifications have used and a number of early interoperability interoperability sure what the right terminology, some early pilot programs within the EU are also using in production right now. So we have a bit of, a fight discussion potential conflict coming around media"
  },
  {
    "startTime": "00:44:02",
    "text": "types and their names, and although it's just a string there are a lot of vested interests and interests. I'm having with words today time with words today. Brian, we need to wrap it off. Yeah I don't know what to do about it, here it is So, yeah. We have two people in the queue so let them. Yeah, so, Ory people in the queue. Yeah, so, Ory. I'm going to jump to the next slide, though, because it's got a pretty all right orie steele uh Art, AD. The media types session for this IETF is Friday at the 1500 time slot The document that previously was requesting multiple suffixes has, in fact, been modified to basically say don't do that Everything you said regarding this being a problem is actually I stand with my AD hat on, ready to assist you in your exploration of media types and what they could be regarding this being a problem is accurate. I stand with my AD hat on ready to assist you in your exploration of media types and what they could mean for your work It is a problem. We've got to sort this out I'm looking forward to conversation with you throughout the rest of the week, but I just want to say if you care about fixing this problem you may need to show up to the media types group every now and then to provide guidance on their documents and help them progress some of this, and I'm happy to help facilitate that to the best of my ability I thought that was this, excuse me, this afternoon Am I mistaken or did the schedule change? oh I'm looking at 120 yeah that's why I can't find it thank you it's whatever time is about to be put in the chat. It's this afternoon, I guess That's what I get for standing up at the mic as soon as I'm triggered by this. Okay Mike. Withdraw. Okay That's it. Let's wrap. Wrap it up I'm done. Thank you, everyone Thanks, Brian"
  },
  {
    "startTime": "00:46:01",
    "text": "Okay, George this one come Yeah, yeah, you all me, okay that's fine. Yeah, let me know. All right Sure go the next one. So the tool and I are going to talk about transaction tokens and what we've done since IETF 119. Same location, different shot, if you were paying attention from last deck Next slide. So I left, so let me ask a quick question here How many people are familiar are not familiar with transaction tokens? This is like the third time we've been talking about them A few people. All right, so let me give the 30 second. I left the intro slides out of this deck Fundamentally, in most deployment, architecture today, you have multiple workloads that need to handle something that needs to be done and we tend to secure the communications from one workload to another workload. We don't tend to do any anything in regards to the entire transaction So this is about how can we potentially create a to- that represents the work that needs to be done to complete this transaction and it get passed through each of the workloads that needs to do the work It's not, it's in addition to whatever sort of service server-to-server kind of authentication or communication perspective that might be there. Lots of good properties happy to talk about it afterwards The way I set up this deck is really just to sort of very quickly run through what the changes have been since IETF19"
  },
  {
    "startTime": "00:48:02",
    "text": "119. So hopefully we'll go through this really fast and then we have got like three slides for open questions. So that's kind of the plan here. So this one, PR 73 for anybody who wants to go back and look, had to do with the fact that a transaction token is valid within a logical trust domain You might have multiple ways that transaction tokens get issued, but logically they all form a single entity And they're only valid within that logical trust domain So we have this concept of a transaction token service, the thing that issues the tokens And so one of those one logical transaction token service for the trust domain, there'll be another talk next tomorrow. Is it Brian? Where we're talking about chaining across trust domains So this is within a trust domain. Next slide slide Yarn has raised a number of times issues with privacy considerations Obviously, if you have got transaction details in transaction token, that's private information don't log it. So we've updated the privacy consideration. We added privacy considerations and have added text there More could probably be added, so we would love feedback from anybody who reads the spec and feels like that needs, you know please contribute text there are ways to address logging things that allow you to sort of track what's happening without exposing any of the data Those can be applied. Next slide We have the concept that there may be a work that needs to get a new a transaction token that has slightly different context but, you know, maybe it needs to, you know, restrict some mechanisms in the token"
  },
  {
    "startTime": "00:50:02",
    "text": "itself. So we added clarifications about what can be modified and what can't be modified Obviously you don't want the subject of the transaction token or the audience which represents that logical trust to be changed. We didn't explicitly call that out. So those kinds of changes were made for replacement transaction tokens Next slide The added some clarification around the fact that the audience claim represents this trustamine and it affects the value of the audience claim should be the unique identifier that represents the trust domain. For other people that are thinking about this, we also added and may come up later so we can skip it when we get there, the subject of the transaction token is identified within the context of the audience. So when you think about an ID token, the subject is in the context of the issuer, in a transaction token, the subject is in the context of the audience. Next slide So transaction tokens were intended to support both external requests coming in your network from an external environment or client, as well as requests that are initiated within your trust domain So you can think about it internal versus external in one way. You know, generally an external transaction is going to have a token associated with it already. Maybe that's the same all assertion. Maybe that's an OAuth access token and effectively you're exchanging that one the access token for a transaction token, and there's all sorts of good properties that we've talked about in the past about the ability to effectively down scope where your inbound token may have some broad scope, and what you're trying to do is very specific"
  },
  {
    "startTime": "00:52:02",
    "text": "you can put that very specific purpose into the transaction token. However, if it's internal, how do you represent the work that needs to be done? And so we've explicitly added the ability to send in as the subject token a self-signed JWT I think we have a issue about this. But what we've added to the spec itself is basically additional clarifications about how you would, you know, do an internal initiated ability to get a transaction token for this workload Next slide Added, a tool's done a bunch of work to add registry and HTTP header work. The expectation here is the transaction token will be carried in a new HTTP header. Brian's been super help in helping us get the text right and we may need to do more work there. So super appreciate Brian and this sort of verification of what's been done so far. But these are just basically some of the strings that we clarified within this particular update to the spec. Next slide We add basically a subsection for the AZD claim, which is the authorization details, and to basically add clarification text about how it's different from the request context claim and then adjusted the exam to match. Next slide slide Basically, you know, to be expected or but we added explicit text that, you know, if you're doing a replacement transaction token, you can't increase the scope of what was in the original transaction token There's probably some"
  },
  {
    "startTime": "00:54:02",
    "text": "nuance here that we have to adjust and think about. So would love comments or feedback in that regard, because I think there may be times where the report here that we have to adjust and think about. So would love comments or feedback in that regard, because I think there may be times where the replacement transaction token may be you know, orthogonally change the scope and that probably is okay but how you know whether it's okay or not is, is of interest Brian, did you have a comment about one of the slides? Yeah, I'm sorry, on the last slide, you don't even need to go back. But it struck me again that the name, authorization, details is literally the same name of the claim from RAR. Yes and that i i find that confusing every time I hear it. So I don't know Speaking of name fights, I don't know. I don't have a better name, but maybe thinking about a different name would be helpful for Yeah, so I would love feedback on that It was intentionally the same need because. That's terrifying So, so because right when you think about rar and you think about the inbound rar request and that you know, the experts right behind you, an inbound RR request. He wrote more of it He wrote the parts you don't like that um was Accurate. Was, right, you're basically, at least the way I've seen it used, you basically were defining what it was that was specific about this offer you know, the authorization requirements that were specific, the things that should be effectively immutable that were make their way into the access to token, so the access token can only do those things And this was effectively to be a container that described the immutable aspects of the transaction I'm not too particular, right, if we can come up with a better name, that's fine"
  },
  {
    "startTime": "00:56:02",
    "text": "But that was, for me, the semantics were very similar when I thought about it hence using that to start with Little brands, go on. So one of the main ideas of our was about conveying some of that information. But really, it talks about different pieces. It's really about client to authorization server and trying to codify how that link can be communicated communicated And so maybe I need to look again at what the draft's doing, but it feels like maybe it should either reuse the claim directly if it's, if that intent or use a different name if it is a different intent. At least I find it confused having not specifically read the details of the latest draft, so I apologize for that. No words Hi, justin richer similar concerns is Brian in terms of the alignment of this. If it's going to be a similar enough name, it really should just reuse the syntax. I don't think that that's the intent of this is to reuse the syntax and so calling it something like transaction context instead of request context, I think might make all of these kind of problems go away. I would, however, encourage the authors to specify a way to specifically include a RAR authorization details object structure, that array structure that RAR defines give us a commonplace to put that the same way that we have a common place to put scope because RAR from the beginning was always in intended to be scope, but with more knobs to turn turn Are you talking about the request context field or? I am not I said transaction context in addition to request context I may have also said something else that was incorrect"
  },
  {
    "startTime": "00:58:01",
    "text": "so sorry about that that's the case Okay, next slide slide um there was some concern that we got feedback around the TXN claim, which is basically a unique ID for this transaction token that in some contexts, some deploy they might not be able to use their existing identifiers for how they do that and get them into this claim So we basically just said that if you can't do that, make it n underscore a. It's still a reason claim, it's not optional, but you can fill it in with a nothing It's not recommended, but, you know and I'm happy to take feedback that says you must put a real value in there as well, but that was we were responding to to feedback in issues. Justin justin richer, isn't this just null with our value in there as well. But that was, we were responding to feedback and issues. Justin. justin richer, isn't this just null with extra steps? or optional with extra steps? I'm wondering what the extra steps actually. From a processing perspective, I mean, you I'm wondering what the extra steps actually. From a processing perspective, you can do it multiple ways, but I would personally, I'd prefer to have about something about, you know, something that explicitly says, I'm not going to get you a value in it as opposed to just sort of like leaving it non-existent in the transaction Okay The error case here is that a naive process ends up lumping together a bunch of transactions under NA. And if you look at any record system that, like, dumps every with the value of null in a field, it's it's the it's the same problem I think this is a little bit bigger footgun. We sort of took this a little bit from the transaction the token exchange spec did something similar in some context but"
  },
  {
    "startTime": "01:00:02",
    "text": "if the feedback is switch it from NAA to null or to open corin null close pran which is what you know apple does or whatever i don't find right just Right, yeah, it's just feedback on that. It's this just feels like a hidden foot guy if, because it's a string, because it's, looks like a valid value but there's semantics within the value itself that you additionally have to process. That's what worries me about this particular approach. I guess it like a valid value, but there's semantics within the value itself that you additionally have to process. That's what worries me about this particular approach. I guess I'm not sure why are there additional semantics Because I have to not only say take the transaction claim and that value and just treat that as the value I now have to look at the value and see if it's a specific value before I can continue processing it. Whereas previously, I either take the transaction value or if it's not there, I do something else. That's a much simpler code break than this and a lot harder to miss miss Except for I have to do the optionality that says you gotta do it You're not getting rid of the optionality. That's that's what I'm saying. This is miss. Except for I have to do the optionality that says... You gotta do it. You're not getting rid of the optionality. That's what I'm saying. This hides it in a way that I think is dangerous I'm saying the logic to basically say when I parse this I then have to go check to see whether the claim is present or not. I'm doing the same level of checks regardless Right. It's just I'm doing them in different places. But maybe you call it a statistically unique identifier and just put a 128-bit random number in there, and then you're done and you have a unique identifier for everyone That would also work work You hopefully would not have any collisions in that context Thomas. You would not. Go ahead, Brian token exchange is, I put that there, I'm sorry for it, but it was there to work around a constraint of a specification that that extended and it didn't have the ability to make optional and so it's pretty ugly but"
  },
  {
    "startTime": "01:02:02",
    "text": "in this case you are controlling both constructs. So I wouldn't take that as a reason to do it this way so would love feedback from the community on, you know, where we want to go personally, to me, there's a huge amount of value for me in having a valid transaction identifier in the token and not having one seems not ideal so i would take you know i'd probably prefer Hannes's suggestion of putting something in there that is unique and you know, even if it's unrelated But, but anyway uh please you know issue or um the oathlister we'd love feedback I'm assuming, Brian, you don't have another comment Sorry. No, slide. Yeah Yeah, you can see you guys. And updated perp, can go to the next slide And the HD guys. Okay. Go to the next slide. And the HTTP head registration. All right So we've talked a little bit about this but I would love feedback and we've talked about this as a team, right? We would love more feedback on these in use cases where, you know, some process within the system I'll give you a classic example, you know, you have an inbound mail delivery server, right? So it's getting inbound SMTP requests. And that server wants to get a transaction token to pass with the delivery of all the workload that have to happen in order to deliver that piece of mail into the user's mailbox, right? you want to ensure that, you know, the only thing that can happen across this set of workloads is affected delivery of content into an inbox. You don't want to to turn into how do I read the person's email, right?"
  },
  {
    "startTime": "01:04:02",
    "text": "from their inbox right so you there's a lot of value in having a transaction token in that context right what should that inbound email server use as it's subject to there's a lot of value in having a transaction token in that context, right? What should that inbound email server use as its subject token into the transaction token server? in order to obtain the appropriate transaction token for? that use case? What we have specified right now is use the self-sign jot There could be other ways of doing that, so we definitely will love some feedback around that aspect of use case within the transaction token spec Joseph Does it have to be a self-signed shot, like would there be a case where you would want this to come from this subject? to come from somebody else? in that? No, it doesn't have to, hence we're you know for these in you know one of the options is you just leave this completely out of scope from a specification perspective and just say, this transaction token service is serving this trust domain and within that trust domain it's willing to accept you know, whatever it wants in the subject to token. We have both the subject token parameter and a subject token type parameter so that could be defined low locally for that deployment And we can just say within the spec, how you do that's out of scope, but the transaction tokens are intended to solve that use case That's an option, right? This was a way of saying if you want to do it in this particular way, you can but no, there isn't anything that is necessary necessarily you know, super valuable about having it self-signed other than obviously if you have a signed at JWT, you get some"
  },
  {
    "startTime": "01:06:02",
    "text": "level of integrity protection, you know, across the API call. Right. So, I mean, it seems to be a self-signed, it could, self-sign could be useful in in many cases right so i think it's kind of good to outline that and maybe i don't know I'd have to look at a little bit more and think about it but maybe there's maybe there are trade-offs you know, between doing self-signed and having some authority sign it or something right and then there's maybe a security tradeoff there that we can describe in the document so that's okay okay thanks Joe Let's go to the next. There's like two more questions that we can okay thanks joe let's go to the next there's like two more questions that we we can um uh you can talk talk to them but you're not gonna take care. Yeah, we don't have any time to cover the but this was, uh, one of them had to do with you know the easy to them, but we're not going to take care. Yeah, we don't have any time to cover these, but this was, one of them had to do with, you know, the, the objects that are that contain, you know, either request context claims or the transaction or the authorization level claims, do we need like a full IANA registry? for these or can they, because they tend to be very specific? can we, you know, leave them effectively out of scope? So please, this is an old issue please add uh thoughts here and um and then there was a question around metadata. Like should we add some level of discovery meta? there was a question around metadata like should we add some level of discovery mechanism for the transaction token service or is it enough deployment specific that any of the entities within that trust mean would know where it is and therefore you know, additional metadata isn't required. So again, please, we'd love feedback on these two issues and any others that you thought of Do you have a quick comment there? Very, very quick. I think self-scient jots are a major foot similar to nan algorithms"
  },
  {
    "startTime": "01:08:02",
    "text": "I would love to see them go and replaced by a simple JSON object Thanks, Yerong. Okay George, that's all. Thank you, guys Aaron Sounds Thank you Let me try to pass that thing I have no idea of my voice is going to work. There we go Okay of my voice is going to work. There we go. Do I get slides? I thought you want to share it. Do you want me to share it and then pass it? to you? I would like to control them. Yeah, yeah There we go thank you Okay, wow, I do not sound normal. I'm sorry, I'm losing my voice apparently, too much yelling on the water last night with Tim We had some fun on some little pedal posts. It was fun Okay, first can talk about OAS for first-party apps. So this is, I don't have an agenda slide. I should start doing that, but it's roughly the same plan of quick recap of what this is about, but I'm going to keep it really quick because this is now I think fourth or fifth time we talk about this here essentially this is a draft that addresses the problem of developing of first-party apps in particular usually mobile apps want a better user experience for their users and what currently is recommended by the best practice for Oath for native apps, which gives you this"
  },
  {
    "startTime": "01:10:01",
    "text": "Instead of following recommendations, people are finding very creative workarounds to avoid popping up a web brand and some of these workarounds are slightly terrifying and we would like to provide people with a better option and a standard option and one where we can all properly agree on things like security consideration of the solution One of the goals of this particular draft is to make it fit in with the rest of the Oath billing blocks as much as possible mirroring how the web authorization code flow works but leaving similar to the web authorization code flow, leaving the specifics of how the user actually authenticates up to implementations out of the core framework. So just like the authorization code flow does not say, now put up a password form and ask the user for their password, we're doing the same thing in this draft So this is kind of an illustration of the flow where the blue parts are the part in scope of the draft and the part in the middle is the implementation specific this I guess I'm missing a line on this which is the time axis which is from the left to the right of the slide But essentially, the client starts the flow. And then it goes back and forth with the authorization server to collect any whatever it needs from the user to authenticate them for the context of their request and then eventually results in an authorization code which the app can then take to the existing token endpoint So this is done with a new endpoint called the Authorization Challenge endpoint Essentially it is accepting any parameters that would have been sent in a query string to the authorization endpoint or in a post to the PAR endpoint, and it accepts a post from the client to start and continue possibly continue the sequence the response from this is going to either be we're done you got an"
  },
  {
    "startTime": "01:12:02",
    "text": "authorization code, or we can't fulfill this directly and we need you to go to the web and finish the flow on the web, or whatever else you want to do for your implementation Also importantly, this is not meant to be the only end point that they have to do throughout the flow, which again is similar to the web author's flow where the client starts the flow at the authorization endpoint, but then that authorization endpoint might redirect the user to five other endpoints or even off of the server completely before finally reassuring the opportunity code. So we're just trying to keep it the same here So changes since last time The, um some work around depop binding to make it, you know, make it work with depop, we have a little optimization of actually actually using PAR as an optimization for this method of actually when you need to go out to the web Basically it meant that that redirect your web instruction turned into an error response and the request URI moved to the error response, which then looks a lot like par URI moved to the error response, which then looks a lot like PAR. So hopefully if you are using PAR, then this is, again, kind of just a natural fit If your implementation knows that it will frequently be redirecting to the web there's another optimization you can do, which is including a Pixie Code challenge in that first request. That way you can skip sort of asking for it again We also, thanks to Brian for clarification that the follow-up requests after this endpoint do not need to be form-encoded. They can absolutely be whatever you want, and they can be at any endpoint We also clarified that this odds session value, which is essentially meant to tie in all of the requests to happen until an authorization code is returned, is"
  },
  {
    "startTime": "01:14:01",
    "text": "meant to be only on that device. It's not meant to hop over to the web or be shared across devices It is meant to be temporary It's meant to live from the point of starting the flow to the point the authorization code is issued Okay, so that's all great one of the things on the other things that happened to since the last meeting is there's been a lot of interest in this and way more than I actually thought in farther along than I thought So Microsoft has public docs now for this API. This is based on a slightly earlier version of the draft, but it is inspired, at least inspired by the draft, and looks similar to it Yahoo has a present at Identiverse just a couple months ago uh is that right how time works um yeah may Describing their research into using this for their own apps, Ot Zero at Octa has an in-progress implemented now. I don't have any docs to share of that, unfortunately, yet but it is an in-progress implementation now as well. And there's a public issue on the Kiklo-Kripo from people showing that there is interest in building it in there as well. So I think that's pretty exciting. Yeah, I think that is WSO2 also. They have an implementation I forgot to add that one. Thanks Yeah. So that's the update quick update, and essentially this is the next steps, I think, I think this is ready for a working group adoption call. Yeah the other sort of large pending item is I do think it would be useful to have an explicit, explicitly defined method for when the user interaction mode is pass keys how does that how does that work so that at least that one can be standardized?"
  },
  {
    "startTime": "01:16:02",
    "text": "And, you know, we still leave everything else up if you want to do other things in addition to that, but at least for pass keys we should have a standardized way to do that so Tim has been working on that already and it's in a pending PR now as well. Awesome. Okay so we're going to ask for a call for adoption right now. So I'm going to ship that austin wright now Bye Number are still rolling so let's get people a few more minutes for your more seconds yeah yeah Yeah yeah okay okay looks great i'm gonna end it here Great. I think we're strong support here. So it's a doubt so thank you for that Yeah, Deb. Yeah, yeah, absolutely will repeat it. Yeah, yeah, absolutely. So again, there's just a follow it up on the list right yeah absolutely yeah absolutely that so again there's just follow it up on the list right go ahead follow it up on the list right yeah absolutely yes okay to follow it up on the list, right? Yeah, absolutely, yes. Okay. Okay, so just for my notes then you're going to follow that up on the mailing list"
  },
  {
    "startTime": "01:18:02",
    "text": "Next week. As always. As always, yeah. And then the next week would be to publish as is a revised name version With zero version. Okay. Thank you Okay Go ahead. Yeah, go ahead On the previous draft on the first party apps, yeah so this has emerged as a potentially very useful mechanism in the context of credential or follow credentials world for presentation of a credential during issuance course relation code flow where the issuer wants to turn around and ask the user to present something so if the first assertion request is a redirect it messes up the user experience Is that a lot of people, whom i redirected to look at this draft says that it's potentially helpful, but at the same time, it is a first-party intended mechanism So I apologize for throwing this at you like this So maybe you should fall up offline, but do you think that your drive right now might be something helpful for that use? case? There's, it was a very very clear goal from the beginning to only define this for first party applications okay it is obviously possible that the same mechanism works in a third-party app because ultimately it's just talking about, you know, how bits are moving across the wire but there's a lot of text in there that describes what you don't want to do this for third-party applications and all the things around that. And really, the context of the draft is set with that in mind. So I think if there was going to be a"
  },
  {
    "startTime": "01:20:02",
    "text": "use of this for this kind of third-party scenario it would be best as a separate draft so that it can properly discuss the security considerations of that scenario Okay, I'll look into the considerations you already have. Thanks. Okay George, you have comment? I think, Christina, it's a really interesting question and happy to have a conversation about it I think that the nuance here is that when you think about presenting, credentials, those credentials in the current world, using password some other thing, that's stuff you don't want some random mobile app out there to see in the context of you know, using the client attestation stuff that we're talking about later this week with an app and some holder binding and some other stuff, right? and the fact that you're presenting a verifiable credential that's protected in some way that right, if the credential itself is protected, then that's may be different. So agree with Aaron, right, we might need to see is there a way that we could extend this spec? to cover these things, but probably useful at least right? now to do it as separate work. But I love to be part of those discussions Okay. Tony Question before for Tim, but why just pass? Why just pass Keyes? We not Okay Yes, I think if we, if that's a top of mine use case, you should look at these together, the way, essentially, if you're look at the WebOthen extension, right? now it's in the spec, but it's just with parameters do have to pass for this to be successful. There's no reason why that couldn't be inputs to like the digital credentials API. And I think for, for, spec, but it's just which parameters you have to pass for this to be successful. There's no reason why that couldn't be inputs to like the digital credentials API. And I think for 4 of VCs, it's intended to be used cross domain, I don't know if"
  },
  {
    "startTime": "01:22:02",
    "text": "there's actually any concerns there because you're presenting your connection you know, I think we should think about that in the context of yeah that was just the first use case yeah case yeah, taken out by my own bag. So in the link he had, it's a separate link because I could emerge it. I forget what happened, but there is essentially a section on Webathon Webathon Webathon I couldn't hear that. Is Tim's work in a full request? Tim's work is in a yeah in a poll request right now, yeah Okay, next one Next topic. Great. Thanks. Okay. Continue nutrition of photos from the area this was from last night, about 300 feet in the air Okay, client ID metadata document. This is something totally new first time presenting this here. Co-authored this with Amelia, who is actually online So I'm going to give you a description of what this is for and also the status of the implementation OK, baseline scene setting, go off client registration. This is the thing that has to happen. Clients register with the authorization service to establish things like where it's okay to redirect the user. What is the client's name? What is the logo to show in a consent screen? What scopes? does it support, what authentication methods do it? use? There's a whole handful of properties that get registered Currently, register happens either out of band, developer goes to a website of a product of an authorization server, manually enters this information There is also a couple other different ways that can happen, but in some cases this is actually not possible to do in particular when the developer of the client does not have a relationship with the authorization server being used"
  },
  {
    "startTime": "01:24:02",
    "text": "in particular things like an open source chat app that connects to a self-hosted chat server Apps that connect to things like Massadon, there is no central server that a developer can register this information in okay so you probably thinking dynamic client registration. Cool, this solves the problem A client can show up and provide this information to the authorization server at runtime It is a solution to the problem, however, in practice, it's has turned out to be mostly unsuccessful for a couple of reasons And again, it's specific Anybody else just hear that? Okay so in particular, a couple of problems that have actually happened in real life if you want a play-by-play of the details there's a link below that goes and you can read about people going back and forth discovering and then solving and then rediscovering these kinds of issues Primarily it has to do with the fact that in this world, it is a n times m problem of any number of clients showing up at any number of other authorization servers with no prior relationship and trying to maintain registration information from both sides clients having to remember which authorization servers they've read registered and which credentials they've been assigned What happens if the authorization server gets registration? from thousands of clients and then they want to prune ones that haven't been used in a year? and then that client actually wasn't really dead and then it doesn't know that it's been pruned so it's just a big a big mess of state management and as often leads to just dead ends for the end user of like, my app doesn't work anymore. Or why am I seeing 100 versions of this app in my security settings? Why does it look like I've authorized this app 100%? times? It's the same app"
  },
  {
    "startTime": "01:26:02",
    "text": "So essentially, this is not really a feasible solution solution There was a previously proposed solution, presented a couple of IETFs ago about client discovery that defines a well-known endpoint for client metadata. This is very similar to this draft, but there's a couple of problems with this method that made it not really, when I went to go write this up, I really asked Tobias if I could just steal his draft and he was like, yeah, I'm not going to do anything with it And I went to go do that and realize actually it's not going to work either because of the problems of using a dot well-known pattern for this kind of thing um my favorite one being what happened when you have these kind of multi-tenant systems of hosting? multiple clients on a domain or multiple tenants with multiple clients on a domain It's a giant mess. Like, you know, one of these versions is what you kind of want to do. And then one is what you have to do according to the dot well-known syntax. So it's the same problem that we have with authorization super metadata, how the reason it's different between O-Walth and OpenD connect It also means that we can't actually host this document in a location that's different from the clients website And it doesn't really work for non-public apps, but that's maybe not the best example of this anyway, but essentially, I wanted to start with this and then realize it wasn't going to end up I end up this draft is relatively short essentially what it says is pick a URL and take all the properties that you would have done a dynamic client registration request with, which are all defined in this IANA registry, and put those in a JSON file at that URL, and then use that URL"
  },
  {
    "startTime": "01:28:01",
    "text": "as your client ID in a NOAA flow NOWL So this is what it ends up looking like. You have you know, all your OAuth parameters and then client ID is this URL. At that URL is a JSON document and the JSON document has to have a client ID parameter that matches the same URL that the document was fetched from. And then I can have all the other properties in there as well. There is an open question about whether the client URI should be a prefix of the client ID or whether the host name should be match things like that. You're curious, chime in on issue number 10 There's some good arguments for both directions if you like, so it's an interesting discussion so then it talks about, okay, so the idea is, here's the metadata at this URL, it's in the client ID parameter this is the first time this client has shown up at an authorization server so it should go fetch that data to display things to the user. Or it can just not if it doesn't want to, or it can validate the data and ignore values that it doesn't believe or trust or whatever. The point is that that information is available if the authorization server wants to use it for displaying to the end user in the consent screen the other important part though is that that metadata does include redirect URIs, which is one of the security features of OOath so that is the list of URIs that is the only list that is allowed to be redirected to for that client. Another fun thing you could do is publish a JWKS URI, and now you can actually turn these into confidential clients with JWT authentication And the metadata documents do have to be publicly accessible so that the authorization server can fetch them Okay so before we get to the questions, I'll see what people want to say in the queue okay um they"
  },
  {
    "startTime": "01:30:01",
    "text": "david uh Just a little concern about the comment on, I think it was page six about showing the URI the presence of things like the logo URI and Clans name, because I don't believe being able to get a JSON file hosted on a web server should be considered to be buy-end that that's an official client of web whatever organization runs that web server That's kind of the purpose of, David That's kind of the purpose of sorry, yeah, that's kind of the purpose of having it in dot well known is so that there can be a process of single location for those types of metadata that are basically server level and thus could at least be inferred to be organization level Are you saying you want the logo URI to be at a dot well? are basically server level, and thus could at least be inferred to be organization level. Are you saying you want the logo URI to be at a dot well-known path? No, I'm saying that the difficulty with the approach of arbitrary URLs is that there is no world-representable client identity So there's a unique identity, but there is no way I can know for sure that this is an official client of webmension.io, just in the basis of someone being able to put a JSON file on that website That is true and that's essentially a unsolvable problem in this space and it's an accepted risk in these kinds of deployments There's not really anything because not really anything because this is not run by, there is no single registry of this information that is maintained by people who run the authorization server There is no, you're not going to get help by that by changing what path it's on So it's just like, that's just the way it is is"
  },
  {
    "startTime": "01:32:01",
    "text": "Okay, Brian I think Mike was ahead of me, but I'll just, I definitely, follow all your reasonings for not using the well-blown application, but I get real worried about this, basically an open vector for anyone on the unauthenticated public internet to just say, hey, go grab this document from this arbitrary location So it a very minimum, there needs to be some real serious guidance on the server side about how you can practice that safely And I think maybe to David's point previously like the the relationship figuring out who this client is and whether you trust them that those aren't the same top level domain feels like it may be under any potential establishment of trust that you might otherwise get in a scheme like this, where you go out, validate the TLS host name and associate that with the client, the redirect URIs I haven't quite thought through that, but maybe you have and I'm There's two different concerns one concern is whether or not the URLs in here are on the same host as the client ID document And that one like, we could say that they have to all be on the same host, and that is a reasonable conclusion to requirement to make for those reasons Maybe. And that would solve several problems. The one that you can't really get around is the fact that anybody can stand up a web server on any domain and use it in any request because that is how this is supposed to work So like that is by design, right? For sure like, the correlation between where that"
  },
  {
    "startTime": "01:34:02",
    "text": "web server is, its TLS certificate and some oriented trust in that, I think, is like you want to have that design, but I think you want to maintain that that correlation so I can't stand up something that points to your servers or vice versa Oh, yeah, I mean, that's the reason that the client ID value has to be inside the document, right? And that's what protective resource metadata does and authorizations are permitted. Same, same thing, right? So, yeah, like, I should not be able to create a document that has these values that lives on some other URL that works, which the way to prevent that is to make a requirement that all the host names match of any of the values in it, right? which is kind of the best we can do in this world where it's designed to be open. It's designed to have anybody show up with a new client that is on unknown to any of the authorization servers Yeah, I think I agree with that. But then there's also the issue of you want to make sure you also at least have some guard about someone showing up with a pointer to their 800 gigabyte virus infected document, just having the servers downloads those repeatedly and things that may not be on obvious. We have a handful of that kind of stuff in there already There's like notes about don't fetch local host URLs with some limit on the size of documents like ignored if it's not Jason blah blah blah that's stuff's pretty straightforward. Not really worried about that the that the other interesting one that there is a good discussion going on in this repo now is though is about development clients What do you do when your authorization server is your development server on your local laptop? and your client is local also. Now you actually do any post URLs to work, so there needs to be some sort of flag for like, okay, we're turning on local development mode so it's okay to accept you know"
  },
  {
    "startTime": "01:36:02",
    "text": "anyway, there's a discussion going on about that right now It's, um don't, I didn't put the issue number in here, but you can go find okay um that right now. It's, I don't, I didn't put the issue number in here, but you can go find. Okay, I'm going to take more comments here, Michael zhou are we on time? We have time Hi, Mike Barak here. I put a few links in the chat. Ori at some point, dropped up some metadata discovery stuff that was I mean, it was a typical ORI week project, so he thought through it a little bit and there's some pages up there and spice on that topic specifically this is very closely related to a lot of things we've been dealing with in terms of system to system for supply chain use cases and traceability credentials And eventually I'll be able to process things at the same time but I'm not there yet But yeah, it's very similar to use cases we have in practice where we're having multiple parties exchange credentials and need to discover where am I going for this endpoint to go that, you know, that conforms to such and such API definition, how do I make sure that? digitally signed, et cetera? We've utilized it DidWeb for that pretty extensively. However, that obviously has problems right as an editor of that draft that's been sitting there forever, you know, whatever, it's got issues, right? But some of those issues have been addressed and looked at by other folks, right? So I did put a link out to someone that has, I think, from our local current jurisdictions government that actually thought through, like, how do we bind? this stuff back into DNSSEC and stuff like that? so that you can get around some of these security concerns So I don't think there's a perfect solution to this yet, but it is certainly a real problem. I think the furthest ahead that I've seen is some of the work that's started maybe in Spice, and we'll find out on Thursday on that"
  },
  {
    "startTime": "01:38:02",
    "text": "So rather than duplicating efforts, maybe we could just consult and share resources and not beat each other over the head and have three things defining the same thing and a bunch of arguments over it Justin. justin richer So I haven't had a chance to read this draft yet so here are my opinions on it Of course. No, for real, though. I think that the trust model is very much in line with dynamic registration. It's meant for an open connection That part's clear, and that's the type of thing that you can put a problem guardrails around plus SSI because this is a huge SSRF thing but i mean you know you know that there's, it sounds like there's already some stuff in the dark about that, and that's great. I also, however, wanted to point out, there a bunch of sort of half-baked prior art in this area, not least of which is something that John and I wrote 10 years ago which was basically how do you cram all of that nonsense into a Jose object as the client ID? It's called Structure Client ID or something like that. I think you ran into that at some point. Yeah, yeah And so it never went anywhere. I don't think anybody ever actually implemented it, but it was a similar idea of making the client IDD, semantically significant with that in mind, Open ID Federation is doing a similar thing with making the client ID semantically significant with automated registrations, and there's a client ID type proposal that Torsten's brought up All of this is going to have to work together if it's going to work at all because otherwise this is we're going to have multiple semantic layers on top of a field that was intended to be an open value decided by the authorization server and nobody else got to have a say in what was in it So, a lot of foot guns here Christina"
  },
  {
    "startTime": "01:40:02",
    "text": "Christina to add more to that um so i think i just wanted to offer some real-life implementation experience we have from the Openity for Republic credentials world because that's where we have, we had the exactly same problem. That was why Tobias Torres and I brought this you know, like similar proposal you know to IETF like few ITs back um exact same problem. That was why Tobias Torres and I brought this, you know, like similar proposal, you know, to IETF, like few IETFs back. So basically what we do is, what we do, is we introduced the client ID scheme parameter, which did give a semantic meaning to the client ID that is being brought by the clients that have not been previously registered And a few insights we learned is so one, I completely agree with the statements that based on what do you trust this, right? like the redirect uri the logos but not and I think you're saying it's web, you know, it's hosted at the endpoint but you still kind of need just other stress behind it one way to do it, to have a list of trashed URLs, but then you know, how's it different kind of from registering all the fans? And what we've seen people do is the mechanism is usually used with a signed request So you signed request with the key that's a obtainable using multiple mechanisms of any federation being one of them And, you know, you can go up to the root of trust that you actually trust. So you need to know is that route of trust that you can go up to once you can validate the signature on the request So maybe that kind of mechanism could be helpful here as well Having said that, back then when we brought it to IETF, there was no match up appetite, if there's appetite now to progress this, without absolutely like to see alignment between what we've been pioneering because when the client ID is URI, there might have multiple ways to resolve it to something like this right? Like there could be Open ID Federation it could be an X5 or 9 related mechanism where the definition is a 65, this, you are, excuse me"
  },
  {
    "startTime": "01:42:02",
    "text": "is the same as San DNS in the X7 and I cert or, you know, things like that or even a don't know stuff So, and, sorry, just, I'm sorry, I'm sorry, I'm to organize as I speak, but another thing is, so I said we introduced the idea of client ID scheme but then from security purposes, whenever the client ID gets passed throughout the flow, because the removal from security purposes, whenever that clientity gets passed throughout the flow, because there were multiple mechanisms how your eyes could be resolved we realize that or, you know, our favorite dr daniel fett pointed out that you have to kind of combine client identity with the scheme to be able to securely identify and trade that owner of that particular client ID. So, well, we don't have a rough consensus yet, so I can speak relating to our working group, but what's seems to be the direction is to, yes, some namespace, the client IDs and the scheme in front, which sounds like something else have considered So long story short, we do have some specific implementation experience that if this work progressed I would really like to be incorporated so the things don't go further apart Awesome. That was a lot I do, I do want to just point out that by definition in this deployment, the Federation trust route does not work cannot use that. There is, by definition, no single authority that governs who's about a lot be a client in this world The closest we have to that is DNS. So I authority that governs who's about allowed to be a client in this world the closest we have to that is DNS so we can't just to use open ID federation for this I don't think I'll ever be the person saying just use a bit venifederation. It doesn't work that way, yeah But yeah, I just wanted to point that out The now I can't remember. Yeah"
  },
  {
    "startTime": "01:44:02",
    "text": "yeah, okay. So, yeah, she threw a lot lots of things at you for now so yeah, she threw lots of things at you for now. So, Ari, do you want to go ask you a question? or comment? So you had a slide where you had the well-known with the sort of multi-tenant uh structural identifier thing in it. Yeah, so there's other OAuth documents that have a similar structure. Maybe it was SD, BCSD JWT, or something like that where, you know, you trying to discover multiple unique identifiers on this well-known origin or domain thing. So I, and you had mentioned keys at some point in here, like the, and then document, they are disclosing key uniquely in each of those URLs Can you just repeat the thing you said about does this fit together with those keys? Is this like a universal solution that, you know, this JSON object could have keys in it, and then they could just use this thing too? I'm trying to like see the relationship between this and that. And I have a the second question, which is about security implication of this, which I probably just ask you all sure yeah so what I was what I was getting at is that because this is a all the parameters in this document are the ones in the client metadata INA registry one of those is jwk s you So you could put the JWKSURI in this metadata document in order to advertise public keys of the client Before we run out of time, I do want to go to my very last slide which is to show how much this is actually already getting built out There's a handful of live implementations of this. Some of only some of which I wrote myself. There's some in-progress work. The blue sky folks were actually at the hackathon here yesterday and their demo will be this evening, I guess. I didn't know, I don't know how it turned out yet but they were working on this is incorporated into their"
  },
  {
    "startTime": "01:46:02",
    "text": "Oath profile there's a lot of interest in this in using this as well and I think one of the I think one of the reasons for it and for the relatively quick adoption of this in the implications is because it is extremely narrowly specified. It is saying we're using HATPS we're using DNS, we're using DNS, we're using ID metadata that's already in IANA It is a very narrowly defined profile of this and it's not meant to solve every problem. It's also very unlikely that a deployment that uses this would also implement other more typical Oath as well of requiring pre-registration because it's again it's it's for a very unique deployment of a oath o-off so that is all okay thanks yeah it's clearly clearly deployment of OA. So that is all. Okay, thanks. Yeah, it's clearly, I see a lot of interest, but I also see gigantic security horse in there, which sort of makes chaos me a little bit when people start in implementing sort of an early version and glance over the security aspects, because some of those security aspects have also been discussed in the dynamic client registration, which there we added mechanisms like the software statement and so on to deal with some of those challenges so yeah looking for there we added mechanisms like the software statement and so on to deal with some of those challenges. So, yeah, looking forward to see a discussion about how to deal with some of them Okay, thanks, Aaron Peter Let me get the best"
  },
  {
    "startTime": "01:48:07",
    "text": "Got it? Go ahead. Yeah afternoon, everyone. My name is pieter kasselman I am going to talk for a moment around an idea called encrypted authorized response and really just hoping to float an idea and maybe get some feedback based on experience in this room room so let's talk a little bit about the challenge or the problem right so authorization code flow with Pixie is great It avoids all the challenges with implicit grant flow. It prevents user agents from accessing tokens and protects against authorization code and CSRF attacks if you use Pixie But it does have this other challenge, which is it does require the sexual round trip and this has an impact sort of on costs especially at scale and also user experience with latency and page load times and things like that and so one idea is, well, what if we could just encrypt the authorized response? So in this sort of very simplistically, could the client generate an ephemeral key? Could it send that key material along the authorization server as part of the authorization request? and then have the authorization server return? the encrypted response to the client? and then the client can decrypt the authorization response with this feral key and have access to the access tokens or other tokens so that's kind of the idea and I'm kind of curious, first of all, if folks have thought about this, or they've tried this, or in the process of developing the authorization code flow whether this is something that has come up So that's kind of the"
  },
  {
    "startTime": "01:50:01",
    "text": "hope to get some feedback from, or if people have had experience with this and just want to come and chat to me about that, that would be great I think looking at this, right, there's sort of a bunch of security questions that come up when we do something like this So, first of all, right, credential leakage right would this give us a similar level of protection to what we'd get with the authorization code flow? via browser history, right again? similar level of protection or worse? level of protection to what we get with the authorization code flow by browser history right again similar level of protection or or worse better see Brian said it's going thumbs down. Round access to token injection, right also central constraining right how would we do how would we do how would do central constraining these tokens And again, see Brian taking a deep breath there and a big smile. And then also around redirect your eye validation and also refraud tokens, right? Would you even consider returning a refresh? token? So that's kind of some of things to some questions that come up but kind of curious to see, because this feels like an obvious thing that people might have tried or looked at or analyzed over the last couple of years and really just looking for some feedback or insight from experience with this Okay. Philip hi everyone um this is philip skokan from octa hi peter nice to see you remotely um do you envision this as an extension to the author Hi, Peter. Nice to see you remotely. Do you envision this as an extension to the authorization response then, like to the authorization endpoint response? so this still travels in the redirect back to the client and the extra round trip that you want to avoid is the call to the token endpoint yes that's yes Okay, so this is JAR avoid is the call to the token endpoint? Yes, that's, yes. Okay, so this is Jarm. This is something we developed in the FAPI working group where we already have a JWA authorization response mode"
  },
  {
    "startTime": "01:52:01",
    "text": "which you can also use to encrypt the response and effectively you're asking for, if you're talking about getting the access token as well, you're asking for an implicit response using the JARN response mode OK, thanks for Lepaldev I'll have a look at that. Thank you. Yep, you're welcome Brian Brian Philip is right as usual except one major difference um from jarm as it uses pre-register keys for the encryption, and it sounded like you're talking about ephemeral keys which is maybe one different but it's definitely worth looking at Jarm and um analyzed is too strong of a word but i have looked at a lot of this stuff and some of these attacks in the context of FAPE, which is where the JARM specification was developed and my very naive analysis is it doesn't actually get you a lot of the security properties that you might want to get from here So yeah, sorry to say that a lot more thinking probably needs to be done but it's it there's a lot of subtle bad things that don't quite work the way you'd hope Thanks, Brian. Appreciate that Yep, so thanks for that feedback. I was also curious, right, maybe there's been some formal analysis on this I was hoping Daniel would be here, but I'll probably try and catch him a different time and then I guess in terms of next day steps, you know, maybe my might write this up as an individual draft just to get a little bit more of the detail fleshed out. But thanks a lot for the references back to Jarm. Brian, thank you And Philip Okay, awesome. Thank you. Thanks, Peter Yeah, put it there. Yeah Yeah okay. Any other business?"
  },
  {
    "startTime": "01:54:04",
    "text": "We have six minutes So if you don't say anything, we would sit here, stare each other at six minutes We won't let you out Now the exam Thank you all. See you tomorrow Okay That's good. Yeah Good stuff. You should find some time"
  }
]
