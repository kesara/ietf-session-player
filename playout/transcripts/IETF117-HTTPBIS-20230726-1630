[
  {
    "startTime": "00:00:08",
    "text": "Okay. It's 9:30. So let's go ahead and get started. we have a Take her a minute. Thank you very much, Jonathan Hoilen. very much appreciated. although you should bow down to Jonathan. That's Yes. This is the note well. Hopefully, you're familiar with it by this time of the week. But if not, These are the policies under which we operate. and that that apply to you, especially regarding things like intellectual property rights, and code of conduct, for example, anti harassment procedures and so forth and so on. If you're not familiar with this, take some time and look up on your favorite Internet search engine. IETF note well, and you should find something that looks like this. So today, we have 2 sessions in this IETF. Today, we're going to talk about the active draft we have in process and a few other topics. We have resumable upload, the template of connect CCP, then prompted authentication, structured field values, revision, and the retrofit structure fields and a brief sideline into the query method. followed by an update on the status of old service. a report from the WebSocket's design team and a proposal for a header called request OTR. Then on Thursday, we have just other topics, which we can go over then. But for today, do we have any agenda bashing? Any changes additions to that. And can everyone hear me okay? In the back, I see nodding in the back. That is good. Okay. We really have to eat these mugs then. Okay. Any other attend to bashing? Chris, are you agenda bashing? No. Okay. Alright. Then let's go ahead and get started. I will attempt to stop sharing this. do you do that? this button,"
  },
  {
    "startTime": "00:02:00",
    "text": "No. Yes. That's just kinda laggy. Yeah. It's laggy. Okay. So and how do I share slides here? the document it's it's it's have the uploaded phones? Yeah. Yeah. Oh, Yeah. Probably understand. Yeah. doing step up. this one? Mark. I might just share my screen, buddy. Yeah. I'm a just share my screen. And Jonathan, if he could also drive slides from this device too. Yeah. My machine is super laggy right now for some reason. No. It's the machine. Okay. Sorry. One second. This is going. Yeah. 2, I can help you in just a second. Let me get this going first. Yeah. My machine is dead. 1.5 step on the machine step. We're having technical difficulties. Please stand by. Here LTE for the win. we go. Did you do that? Okay. Fantastic."
  },
  {
    "startTime": "00:04:05",
    "text": "Go ahead, John. Okay. I have 1. Good morning. My name is John and Flatt from Apple. And today, we'll be talking about the resumable uploads draft. So there are several open issues. and there will be time kind of after each of those issues to open the mic and discuss. So feel free to get in the queue whenever. and let's begin. Next slide, please. Cool. So first off, in the past few months, there's been some new implementations of the draft. There is the test dot net server built on the dot net framework. There's the Neo Rezumable upload package for Swift Neo and URL session client on Apple platforms. Since the making of these slides, also one of the authors, Marius, has done a lot of great work in compiling and also creating more client and server implementations that follow the draft. and logging their interoperability. He sent an email to the working group yesterday, I believe, with a link to that repository. So if anyone's interested, I highly encourage you to check it out. Next slide, please. And in implementing these servers, we made an observation that there's sort of 2 ideas of how to approach this. One is the additional service takes this idea of a removable upload, handles all of the resumption for load to your back end service. And another one is where the resumable upload protocol is kind of built or wrapped around your current back end logic feeds all the data straight through there, but also handles the"
  },
  {
    "startTime": "00:06:00",
    "text": "resumption. And so maybe not right at this moment, but perhaps in chat or offline, We'd love to get some feedback from those with back end integration experience. maybe some recommendations on how what we can recommend to server providers when implementing a protocol as this Next slide, please. So our first open issue is the upload complete header field. and the current draft uses upload incomplete as both a discovery mechanism and as a way to do a potentially more advanced option of chunked resumable uploads. However, Upload incomplete false or a double negative often leads to confusion. So the proposed idea is to use upload complete instead. And there's already been some discussion in prior meetings about this. And it's that I think one of the points was that there's a slight difference between upload complete for the client versus for the server But, also, this symmetry allows us to echo the field on success in this successful case. So next slide, please. one of our questions to the working group is can we lock down upload complete as the preferred name or are there other ideas? Other thoughts on this symmetric versus asymmetric naming? we'd love to hear your feedback on this if anyone has comments or questions. I see a thumbs up, multiple thumbs up, that count. Is that general consensus? Awesome. Next slide, please. Our next issue is on multivergent support. So, currently, the draft"
  },
  {
    "startTime": "00:08:02",
    "text": "details how a client sends the draft version. It supports if the server supports that version, then it advertises resumable uploads. However, as the draft evolves, we can imagine a case where a client might update to the newest draft sooner and a server that they were previously talking to for resumable uploads that has not yet updated the client loses the capability to perform a resumable upload. And so can we make this transition easier or next slide, please. Do do we want to make this straight. Like, is there interest in solving this multivurgining issue? And, also, If so, do do other people have more insight or experience on draft versioning like this that they would like to Comment. If this season is here, I think. my preferred way of holding this would be having a suffix for each header being I I mean, like, upload complete draft 3 or something. Because then I mean, having a different name on head it's a general way of us extending HTTP rather than having a larger number field next to a different header field. Awesome. Thanks. Yeah. I wouldn't worried too much about this at all, I know that we've changed semantics and the previous. slides. But that was a complete header change. took because there was point. and that'll be fine. Are you aware of any reason that this might need to change. The answer is probably no. But if we do need to change it, then we can talk about spelling something differently. we drop an e from complete or something like that."
  },
  {
    "startTime": "00:10:03",
    "text": "things Right? I don't I don't -- Yeah. We we can spend a ton of time engineering like that. And I don't think that's really worth Okay. Yeah. Thank thank you. Yeah. That's good feedback. Thanks. Cool. Next slide, please. Our next issue is on adoptingbyte Range patch. So byte range patch is a draft that's that's going to be called for adoption in the HTTP API working group. And how we would adopt this in the draft would be eliminating the need for the upload offset header field by using this byte range patch. For instance, upload offset of 50, becomes content range bytes from 50 some known number. If you know the content length, else you can use the indeterminate 52 whatever form. So this could reduce the number of headers because we could also remove upload offset from the offset retrieving procedure. the server could for instance just respond with a content length, which semantically can make sense for a partial upload. next slide, please. So overall, What are our thoughts on adopting bite range patch? But, also, do we want to depend on another draft in another working group because this dependency could come into play with different timelines. WatsonLAD, Akamai Technologies. I think BitRink regards to the merits of bait range patch, My understanding is that that's a little different than this case. we're talking about an upload about one file We're just moving it to the server, and we wanna have sort of server side is we don't care how many times you got resumed We just wanna see it when done. Supporting bite range changes"
  },
  {
    "startTime": "00:12:01",
    "text": "is always more expensive than or a lot of the times, it's more expensive than pending, particularly in some exotic storage architectures or if you have some implementation where you're moving the file at the very end. So I think we should probably not depend on it just with the difference in semantics we want to express. Thanks for the feedback. I think in the draft, we would specifically be using it only for that a pending case. and not patching, like, multiple ranges throughout the file but it would be more of a semantic change in how we say we're doing that. I believe we have maybe some Yeah. I'll I'll send this thing. and and I yeah. I'm we will let you attach thing. I'll see you on Thursday if you're if you're gonna be in the API's working group. The For depending on the draft and other working group hoping that we can push this through fairly quickly. Like, I'm not sure there's too much more of evolved in it. So if we can push it to us and, like, our RFC, hopefully, then that shouldn't interrupt the work here much. as for the feature set I think one of the benefits is that because it's specifically numbers, we're going to modify these bytes. the server can properly process. messages that may receive be received out of order or things like that. or it can actually verify that if it receives a resumed upload that there's not content that's missing in the that would just get silently corrupted if we otherwise didn't specify we're starting or zooming the the upload this byte offset. then the other benefit of the bite range patch is it also does And"
  },
  {
    "startTime": "00:14:00",
    "text": "specifically a numerator at the end of the upload or the expected upload is. So you can actually verify, We are expecting 500 bytes, and we've received 500 bytes. Therefore, the upload is complete. and that you can eliminate that upload complete header that way. And you can know this way, you don't have to know if the upload is complete or not. from the start of the request. That's something you can figure out at the end of the request. There there are a number of different forms and media types don't have to support all of those. You can just say in this spec, know, it you it's an error to do this or that, or you can just ignore that behavior. There's shouldn't be any conflict there. But if there's any further questions on that, which we'll definitely I I definitely like to hear the issues. because, like, one one of the motivations for this media type was actually specifically a basis to do resumable uploads So Thank you. Yeah. Thanks for the info. I think the upload complete header field would still be needed for discoverability. And I believe still the decision between chunked and and complete, but maybe we can follow this offline or on the issue. I think there's other people in the queue. apple. I think oh, I I've looked into adopting back range patch I think the First, I have a concern. it's changing the syntax of the content range header, which might not be compatible deployable. I'd say, and Also, it's currently we we are de debating between adopting dropping upload complete or not. And the the problem is if we drop it, the current replacement storage is not upgrade. we we are needing to further chunked it into"
  },
  {
    "startTime": "00:16:00",
    "text": "Either a multipart respond requests or into this binary format, which is sort of also multipart. I I like to flush that a lot more before we a thinking about adopting this wide range Thanks. Tommy Jensen, Microsoft. I I don't think the benefits of having the additional data that that provides outweighs the fact that then if we're still supporting the upload complete header field for discovery, Now there are two ways to express where we're uploading to, and I dislike ambiguity. Expedited feedback. Eric Nagger and Akamai, just to have echoing some of the previous comments. But I think one thing on the your response to watch them. I think if we were to use a patch, we would want to be able to cover all the cases, having having something that says, well, we're using patch but you can't actually use it for these cases. You only have to use it in this kind of subset of ways. would would would seems like it would be resulting in a lot of implication implementation ambiguity and bug potential. So if if so we'd probably want you if we were to do that, take on the full complexity So of of those cases, and therefore, might wanna take that full complexity into a do we really want to do that switch. think the inter meet I think it's part of the content range 1 like, thinking about how this interacts with intermediaries and how many kind of intermediary would just keep work would keep working. versus we need we need some substantial changes support the content content length of I'm post post stuff might be on another consideration. Yeah. That's great feedback. Thank you. we have more in the queue, or maybe we might wanna move on one more, I think, Marius. Okay. Marius. Yeah. Hopefully, you can hear me. So as I understood it, the the drop from Austin includes, like, multiple parts."
  },
  {
    "startTime": "00:18:01",
    "text": "one is, for example, that it has content range also now defined for and writing or modifying requests but also, like, the new media type, and and if we decide like, the media type isn't really the thing that we're looking for. Maybe it's also suitable to just say, okay. We wanna reuse content range, and therefore, avoid introducing, like, a new add up field upload it off said, So maybe if the entire draft doesn't work out for us, we can also just, like, pick the parts that Sudas. Yeah. Thanks, Maurice. Well, I was getting in the queue to channel. Julian comment from Zulow, but I see Julian into the queue now, so I will refer to him. Hello? Yes. up. Good morning. I just wanted to point out that the semantics of edge HTTP patch absolutely require us to have a media type. We can't just wear a fence here. So even if it's something like applications slash append, we will need to define that type if we don't use something else. for that reminder, Julian. So so so there's no way to use patch without a in your top. would be undefined. Yeah. is a good point. Thank you. let's take further discussion maybe to the issue or the next slide, please. you know, Another open issue is perhaps more of, like, a feature edition, upload progress via informational responses, the use case of this or the idea of this is after the initial 104 response, The server can send additional informational responses with the upload offset or the number of bytes that it's successfully stored and saved. and this might allow a client for instance to"
  },
  {
    "startTime": "00:20:00",
    "text": "release data associated with the upload from before that offset. So my question quick question is, should this be included in the draft? Is there ish interest in it? And If so, maybe how much or in what way? Tommy Jensen, Microsoft. Active disinterest given some of the experiences we've had with intercompatibility with 100 responses, just generally speaking, That's good to know. Thank you. Answer a couple of odd regards. I would generally be in favor of something like that in order to, you know, have a mechanism for clients to observe progress even, you know, while a certain chunk is uploaded, terms of monitoring and detecting probably calculating speed also. transmission. So I I would find that helpful. Thank you. well, so generally speaking, servers are allowed to send 100 Our information are responses at any time, any number of them. So it'll be I think it'll be kind of awkward to prohibit sending them at some cases. So I'm in favor of taking this proposal. Oh, Thank you for the feedback. Marius, Yeah. Sorry for that. refute. And one thing that we don't have to think about if we reuse 104 for this or if we have to, like, because it's, like, I think Status code is than to, like, indicate that resumability is supported by the server. And if we can just reuse that for that or if we, like, actually need a new 100 response code for that. But that's something to figure out probably. Yeah. So I'm hearing that there's like, some interest, some direct disinterest, but we would need to kind of figure out how much should be included in the draft. in terms of a recommendation."
  },
  {
    "startTime": "00:22:06",
    "text": "Does anyone have ideas on that, or perhaps we can also take it to the issue online I will take you to the issue. Next slide, please. The last one is open issue, not in this working group, but in the what working group? And it's more of just to know Mario's opened an issue. asking for feedback on the draft. from those folks and also as an API proposal for fetch. So something to note. It was labeled, needs, implement, or interest. So if anyone's active in the working group or maybe potentially interested in implementations. of feel free to check that out there. Next slide, please. And this is slide. It lists just some of the other open issues. Some of these are have come to more or less of a consensus or maybe even have PRs open. but but but we can take the time to address any comments or questions from bees or any other parts of the presentation. Alright. Then we'll give some of the time back to the next presentations. Thank you all. And thank you very much. Next up, we have a template connect TCP. bin, Okay. Hi. I'm Ben Schwartz. at meta, and this is template driven HTTP connect using for DCP. Or, really, as a reminder, what we're"
  },
  {
    "startTime": "00:24:00",
    "text": "about is basically mask for TCP So HTTP Connect is a long standing way to Move TCP through HTTP, this is a variation on that idea that aligns with the mask template driven proxy system. so you can see there the proxy is identified by a template, which tells us how to construct a request in http2. In http3, that's extended connect. in HTTP 1.1, that's via the upgrade mechanism. So this draft is very simple. and I think it's pretty stable and close to done. Yeah. there's a little bit more text needed, like, security section, and it would really it would be really great to get some implementation variance, but it's it's really a a very simple idea. The one interesting change since the since adoption since the last time we talked about it, is a new text about false start and 0RT team. which were requested by Tommy Polly, I believe. the so the for background, conventionally, with the TCP proxy You would have to do whatever TCP and TLS setup you need to do, and then you'd need send a connect request to the proxy and get a confirmation, and then you could start sending your payload. So the with t c with TLS or quick zero RTT, if you're doing a resumption, that you can skip some of that. And with the false start we're talking about here to be clear is not not TLS 1.2 false start. The false start is a is again, terminology borrowed from mask where you might want to start sending upload bytes before finding out if your HTTP requests succeeded. with the understanding this, if the request failed, then those bytes are not going to reach the target."
  },
  {
    "startTime": "00:26:01",
    "text": "And that is now documented and explicitly allowed, in this in this draft, whereas for classic HTTP connect, it was sort of not very clear whether it was allowed. Martin. Okay. So we're not talking TCP fast open, aren't we? That is, I think, orthogonal. I see. Tommy Shaking his head and going. Yeah. that would be a bad idea. I would I would suggest. If if you like, things things breaking, braking, Biome's enable it. but I think false start is probably a bad term to be using in this case. It it's quite misslating, Okay. I'll Make make a new one. Alright. Alright. Well, this is David just said, does he mean TLS false started? And and I'm like, no. because that doesn't make any sense in this context. This is mask style false start, Is that a thing in full in mask? Did we make that mistake there? It does not call it false start. Okay. Good. Good. Good. Good. Find it find a new terminology. That's all I'm asking. Mike Bishop, Akamai. I I don't know that we ever had a term for this, but the h three spec did have to have additional language around Connect saying that It's weird in that you have to handle the request on the headers, and then process the body after you've opened the tunnel. I think that's really all you're talking about here. The the client is allowed to send the body And while it's waiting for response. Yes. That's exactly right. Yeah. Yeah. Okay. So noted, we will find new terminology for that. The reason I mentioned that this is my last"
  },
  {
    "startTime": "00:28:01",
    "text": "There's there's a little bit more of a cute Casuco. Oh, okay. Right. So I think doing apples, but it's fine for HTTP 23, but I wonder if as any security issues with doing it over HTTP 1.1.com. Yes. And maybe we have to write that down. Indeed. Oh, far. Very prescient. I I'm impressed, Kazufu, Kazuo figured out that problem, you know, about 2 months faster than I did. Is there any more queue? Yeah. Yeah. I I was just gonna mention for terminology. Yeah. we can take this to the issue too. But in the Connected UDP mass stuff. It just talked about it as the client sending it optimistically. So you can just talk about, like, optimistically sending the body data. That might be it. oh, okay. Wait a second. Okay. Yeah. I'm not sure not sure what appears in this draft currently, but it will definitely try to match I'm the mask terminology So I I wanted to highlight one that exactly Kazuko's point here, which is that this is all well and good in HTTP 2 and HTTP 3. In HTTP 1.1. this gets a little weird. because if according to rc9110, the server allowed to say, no. Thank you. I don't want to upgrade In which case, the bytes that follow are continue to be HTTP 1.1 rather than whatever the upgrade protocol is. which to me strongly implies, although that's not quite explicit, that you're not allowed to do this kind of optimistic transmission in hdt.11.1 with upgrade. And so that's what this draft currently says. It says that you that shall not Connect UDP But, like so so on the one hand, we'd like to be consistent with that. On the other hand, it would also be good to be system with Connected UDP because that's that's the parallel thing for this draft."
  },
  {
    "startTime": "00:30:02",
    "text": "Connect UDP is has a little bit of a different take on this says the client must abort the connection. if the upgrade fails. So that's a little bit different. Maybe a contradiction with the HTTP 1.1 spec, which says the server is allowed to deny the upgrade. not exactly a contradiction. The server is allowed to deny the upgrade, but and then try to continue speaking GTV 1.1, but then the client is definitely going to kill the connection. So that's a useless thing to do. Also, the Connect UDP says that the client can optimistically start sending packets before receiving the response. So that sounds like this optimistic transmission is allowed. doesn't explicitly exclude HTTP 1.1, although you could argue Maybe it's implicitly disallowed. But if it is allowed, then there's this, like, potential for some very weird stuff here where, like, you could have requests smuggling due to disagreements about like, what protocol we're speaking, I don't really have a strong opinion. I have some bad ideas in red here, but I just would like to close this out and find out what what people think the right answer is. Yeah. This is really bad. I think I I think of what the connection is probably a mutual re requirement here -- Mhmm. -- in this case. So Unfortunately, service not really in a position to know whether the client's waiting or not. when we're talking about HTTP 11. so so concretely, the client sends the connect request to the server, and the server rejects it. If the client was waiting on positive affirmation before it started sending Right. Got it. then potentially, it could say, oh, I saw the"
  },
  {
    "startTime": "00:32:00",
    "text": "rejection, I can make another request to this. Right. And and by the way, know, as noted here, that's actually a pretty common situation. because If you'd if you have you a 407 proxy authentication required, that is the flow that you're going to go through. Right? Now I'm not sure that that's really a good situation to be in. overall sort of holistically because it means that you don't get to do the optimistic sending It's also possibly the case that the if you allow for that possibility the fact that you assume the client's waiting for a response before it continues. and this is how everyone expects http11. connect to work, then 9298 has a bug. in the sense that it it probably shouldn't have allowed optimistic sending. On the other hand, other way we could approach this is say that if you see a connect attempt, then that connection is gone. no matter what. Mhmm. and we treat that as whether whether it succeeds or not, the connection is is either successfully upgraded or the connection is now no longer usable. from the perspective of either side. And then that creates an obligation on both the client and the server to abandon the connection if if the rejection occurs. So the one thing that seems odd about that is that if you look at the http1.1 flow here, there is no connect request. Right. there's a get with an upgrade. Mhmm. Yeah. And if that upgrade token is unrecognized, for example, then the server is in HTTP 1.1 land where it's supposedly allowed to reject the upgrade and keep the socket open. I believe that the understanding there was that the server would project would would ignore the upgrade and answer the request. Okay. Either way, it continues to speak HD 1.1, which means that the payload then is going to be interpreted as HTTP 1.1 for this proxy, which, again, puts us back in request smuggling."
  },
  {
    "startTime": "00:34:03",
    "text": "Yeah. Because one of them has a content length that you pay attention to, and the other one doesn't. was their windows. Well, Like, who designed these protocols? It you all used get on this stuff. So I think you painted yourself in a little bit of a corner I think that Mark points out a a good Good point. in that there's some usage of this and it is limited to get which means that the the HTTP request doesn't have anybody And I think we've just created that that that that same problem that we just saw. I think we probably need to do some updating of some ROCs. Yeah. Yeah. I mean, this is gross, but I don't see any other way around it because it I think just the the the published RFCs all contradict each other in ways that create security problems. So but there's but there's that that seems to imply some breaking changes. And it's called job security. at david Skanazi, connect UDP enthusiast. So speaking as the editor for that document. The intent there was that it would be possible to send data, like, you know, years of your UDP sorry. Your Datagram capsules with your get that's an upgrade that would then be sent into as UDP. in practice, I'm not aware of anyone actually using Connected VP or h 1 or anyone ever planning for doing it, so it's not that But my main point here is I'm not sure this attack matters. So like, Either you have a server that supports connect to UDP. And it knows what's going on. And let's say it gets a request for it, or or this, you know, and it doesn't like it. It's gonna shut down that connection."
  },
  {
    "startTime": "00:36:01",
    "text": "and If you get a server that's never heard of this, that's when you get into the world of they might misinterpret things and Quest smuggling. But like, This attack where you have capsules that are actually spell HTTP things. that very clever. like, that presumes that you have an evil client. No. it presumes that you have an evil traffic source behind your client. Well, the if if your traffic source is UDP, that's only sending capsules So to to 0. Right. Yes. Capsule type number 2559 or whatever is is not currently registered. if that were registered in IAnA as a cab having a meaning that was relatively commonplace. then a local traffic source could potentially exercise it. And so my proposed solution here in red for you is to change Ariana registration rules so that any confusable capsules are unregisterable, and therefore, we can never have this problem. Yeah. Yeah. Speaking is one of the designated experts on that No. But, specifically, like, there's no such thing as a connectivity p client, that's gonna take input from an arbitrary source and just shove it into into any capsule. Like -- Connect IP? Connect IP, I would argue, is essentially that. Right? Connect IP in a system tunnel configuration except essentially arbitrary IP Datagrams generated Yes. But that uses the datagramcapsule, it doesn't use. There is no point at least in any of the implementations I've ever seen, that lets you shove in custom capsules from something trusted because custom capsules could be bad, regardless of this. Right. So this only applies if capsules with confusable types are registered."
  },
  {
    "startTime": "00:38:04",
    "text": "in as having a meaning like, oh, this is a capsule with this particular DSCPbyte value. That's registered in Ayanna as having this value. And now I can trigger that from an untrusted source. Alright. I'm starting to see what you mean. I think that's kind of too far fetched for us to won't wanna fix honestly. Maybe a note on the you know, for implementations, don't allow this kind of crazy thing sounds safer. So it it sounds like we're not going to resolve this. today, and we're running at time. I've closed the queue, and if the remaining folks in the queue could be relatively brief. Lukas Pardo, job security enthusiast. Yeah. Like, this is gross like, you know, you haven't caused the problem that you've kind of pull the covers off something. that that that that It it's a shame. But, hey, I think we need to fix this stuff, especially the 1.1. like, saying it won't happen, like, it can. And somebody will do this. Request by Glenn keeps coming back and and biting us. So if if maybe the the idea is we pull because that connects stuff out of 11 10 and try and make a document that's more coherent about with the the whole mask zoo of things that could be an option. But I'd I'd be willing to review and help support some of that work Watson Lad, Akamai. We had a similar kind of issue with NTP where existing uses squatted over a whole bunch of interpretation of fields that are supposed to be free. It was bad. We only now just have a draft at fixing this. You might want to go register those types if they're going to be problems if they were later coussel hook, I think we have to do something for this. our precedence in informational responses"
  },
  {
    "startTime": "00:40:04",
    "text": "has been that there would be intermediaries. Therefore, there concern in sending informational responses over a cheating if we pull that precedence, we have to do something. And regarding what we do, I think I wonder if I everybody is actually interested in optimizing HTTP 1 point 1 at this point. I I'd rather prefer, you know, just bidding this behavior in htp 1.5 and calling at the Hi, Alex from Hopsky Google. I mostly wanted to save from our variance in the mass working group, I feel like we did spend a huge amount of time trying to do one one back with compatibility for the core document set. And while I think that that was probably the correct thing to do because there is still growing adoption of H2andh3. I think that we are probably crossing the threshold where continuing to invest new features like this in h 1, which already does have particularly amazing performance characteristics, is probably not on the right side of the balance sheet for our energy. And I would prefer if we just mark this feature as h 2plus and maybe agreed on a moratorium of not really building more of these performance optimization type things into HTTP 1 and sort of encourage moving to h 2 into error calls. So just to respond to that, the current draft takes essentially the what what I would call the slower approach here. Right? It does not have a performance what I would call a performance optimization really for HTTP 1.1. I do think it's valuable to have an HTTP 1.1 specification for this because of intermediaries that speak h 1 on the back end. So I think the queue is closed. up, Right. Right. Thank you very much. It sounds like we have some more discussion. We'll give you more time next time. Next up, Mister Skinazi, I believe we have unprompted off. Oh, okay."
  },
  {
    "startTime": "00:42:01",
    "text": "Okay. I'll try and do it this time. Let's see. Here we go. Good morning, everyone. I'm David Kanazi, and today I'll be your authentication enthusiast. Yay. Alright. So this is our unprompted authentication draft, which my coauthors, Jonathan, and is here locally, and David Oliver is here remotely. Next slide, please. Alright. So to for folks who weren't in the room last time, who haven't led the rest. Very short summary. The idea is we want the client to authenticate to the server. We wanna use asymmetric photography, and we want the server to be able to hide the fact that the it offers this kind of authenticated resources. It wanna wants to be able to tell anyone without the keys. Oh, I'm Sorry. I have no idea what you're talking about as opposed to, yes, I support this, but you don't have he's please authenticate So we adopted the document in this working group back in February. We had a great discussion And at the last ATF in Yokohama, and we remote wrote almost everything in the document after the from the working group, as is standard in this community. Next slide, please. So I'm gonna go over the current Russia the solution and at the same time what changed since last time. So the kind of key clever idea. Thanks again, Chris Wood, in this document, is to use a TLS key exporter to generate some fresh data, and then we sign that data. and send it a and the the client signs it with its private keys, sends it across, and then the server can verify with the public key"
  },
  {
    "startTime": "00:44:00",
    "text": "that the signature is valid, and it has the properties we want described from the previous slide. and it also has nice things. Like, you can't replay it on a separate connection. Next slide. Alright. What changed? So before, this used to be a separate brand new, unprompted authentication header. This is now a regular HTTP authentication scheme. So it fits into the existing mechanisms that we have in HTTP. It's called Signature because I was feeling particularly inspired. And you can use it with authorization, with proxy authorizations and whatever other cool beans we we might end up design designing for authentication. And we completely dropped the HVAC feature from the spec because was the feeling from the room last time. No one cared. that next slide, So the TLS keying a border is a construction from underlying TLS, and one of its properties is you can pass it a context. Think of it like some extra data that you've feed ed in that gets then hashed as with the TLS master secret And to to generate the keypad output from the exporter. So we decided to put everything we could think of in there because more things covered by the signature equals better, as I'm told by the cryptographers. So what we landed on was which signature algorithm we're using, The key ID, which is kind of the key into the server's database of public keys. the HD with the origin. So scheme, host, and port. And we decided on the realm, which is a concept that exists in authentication, which allows the server to say, I have multiple realms on this origin. it's not particularly defined, and it's defined as bite spike spike spike spike"
  },
  {
    "startTime": "00:46:00",
    "text": "if you don't need it, it's the empty string. So we just added it here. if you use a ship your arms, you can use it. Otherwise, you just have a 0 bite and you're done. We decided not to add the full URL, and as in the path inquiry are not part of this. And that allows us for when you have repeated requests on same margin, you end up with the same authentication. In that way, you using h storage header compression, you only send it once, which is kinda nice. and you'll see soon why we end up but that'll save a non zero amount of bytes. Next slide, please. Alright. So Turns out when you get people to read documents that have things like signatures in them, they tell that you got it all wrong, which is great. So Turns out that there are plenty of attacks here. This seems legit paper is super interesting if you have Reddit. And 1 of the things that I didn't know is that there are some signature schemes where you can have if you carefully craft your key, you can have a key that we're all or a signet your key on your signature. It can be valid for multiple inputs, which can be used for evil things. So as a way to kinda rule out that entire class of attack, instead of just when we use the key exporter and to generate this kinda nonce that we're gonna sign. Instead of just generating that, we generate a bit more data. 16 bytes. and we send that in the header. So that allows the server to ascertain that the client indeed has access to the t TLS master secret that it actually ran the exporter. as opposed to just gave you a signature that happens to be valid over everything. crypto is hard. Next slide. Additionally, when you sign things, u, you can run into attacks if someone reuses their"
  },
  {
    "startTime": "00:48:00",
    "text": "public keys for multiple different protocols. Of course, in the document, we say you must not do that, but people still like to run with scissors. So let's build a little system to avoid this. So we just copy pasted what TLS 1 3 does, which is instead of just signing a nouns, You have this little static string before And instead of something that mentions TLS, we have something that mentions signature authentication so that if you can have a signature for this, you're not gonna be able to use it for TLS if someone were to reuse the same public product key pair for both, which is a terrible idea. But even if they did, now we have this problem are next slide. Alright. So all of this now that we have, it allows us to send a really nice entire phone book with our header, So you put the key ID in there, you put the signature algorithm, You put the verification, and you put the proof. and but wait. We can add more. Next slide, please. Alright. So I wanna apologize for the group. I was in a rush. I only had time to put one meme in the slide. So I hear y'all like structured headers. Everything should be a structured header. We love structured headers around this. And seeing by how much m naught is staring at me and at me and going up in the queue, See how much he's twitching because I said structured header instead of structured fields. I hear that you all care about your structured headers and your structured field. Julian, you're feeling staring at you from thousands of miles away. Go ahead, Mark. Oh, no. No. Finish your little thing. Well, I mean, I was about to go to the next slide. So if you have a question on this one, from it. so many."
  },
  {
    "startTime": "00:50:00",
    "text": "So your u we want every field to be or even every header. Let's use your terminology. Every header to be a structured header. not every value to be a structured matter. in in team. And I I feel like that may be where you're going. Exactly. Okay. Alright. Next slide, please. So right now, we have a bunch of parameters as part of authentication. We saw, like, v is this verification? We have the the key ID, and a bunch of them including the proof the verification and the key ID are bite sequences. Like, your signature is a sequence of bytes. And so the way you get that across in HTTP headers is based 64. And you know, everything should be a structured header. So structured header support byte sequences and the way they're represented is with pay 64 surrounded by Collins. except Off parameters are not structured headers. Those were defined way back. And I forget I don't think you're opening that kind of warms in retrofit. Are you? No. And I'm get Maybe. Anyway, so Yeah. So And the reason it's not trivial to open up that can of worms in retrofit is that it doesn't quite work easily. So here's the ABNF for those parameters. and they're tokens or quoted strings, but that means that you you can't put colons in there. So what we did is we added quotes I forget. What's the next slide? Yeah. So right now, the draft has quotes than Collins, which is kinda gross. Some people said it's still kinda neat that because once you've removed the quotes, you can pass that into your structure and header, parser. But"
  },
  {
    "startTime": "00:52:02",
    "text": "So the 2 obvious proposals here are We keep this thing where we have quotes and colons. Or the second one is we just say this is not a parameter structured, and we just use base 64 URL, and we did did allow padding because padding in base 64 is only useful if you can can concatenate them, which we won't ever doesn't make sense to do here. So I see that people have thoughts. Alright. I can't see the queue from this angle. I'm I was first. Go for it. So as one of the authors for the privacy pass authentication scheme, which has this exact same property I would love to see alignment between those. And we had the same thing. So We ended up on neither of these. No. because we're doing we're doing the base 64 in quotes. Alright. We have proposal 3. No colons. just just quotes. And I think that's kind of what it had to be to make sure that because the thing is not necessarily a token. because it could start with a number, I think. So the the safe thing was to put it in quotes. or sorry. Sorry. I'm gonna insert myself. So but it Do you mean when you say token, do you mean structured field token, or do you mean structured field token? I mean, I I forget all of the context, but what ended up being the thing was to do a base 64 in quotes. Okay. And so did Surely, someone in the room can answer the question. Can the tokens start with a number? because if that if you can't, Yeah? Yes. Yes. So I think -- HDDP token. Yeah. Yeah. Yeah. So For for authentication parameters, proposal 2 should work per the ABNF, I think we do explicitly allow the equals to be there. Oh, okay. Yeah. That's why. Alright. Okay. And, like, you obviously don't need to have them. But if you do have them. It's just, like, it's always safe to have the quotes around it, and but you definitely don't need the call"
  },
  {
    "startTime": "00:54:03",
    "text": "Okay. Perhaps we could agree on not proposal 1 and then move on. That that sounds good. I Alright. Well, the queue's not that crazy. Go ahead. Yeah. Martin Thompson, I don't wanna talk about this. want you to fix and wanna talk about the last thing. Yep. That's agreed. Do do other people wanna talk about this thing? Or how how about this? I personally, I think proposal too is the way to go, but does can everyone live with that? If not, like, raise your hand, come up to the mic, No. No. No. Alright. That sounds like we can move through that. -- in the issue, probably. Okay. Alright. talk to Tommy and make sure that we align on this one and what whatever is necessary, but Can can you go go back with because this is your syntax. Yeah. Alright. So we'll resolve this. Please go to issue 2581 if you care. to all of the stuff we're David was talking about how he very meticulously reconstructed the stuff that we did in the TLS working group. Wiz. Yeah. All that stuff. Alright. So it's I was looking at this this discussion. We're going through, and we're having a bunch of conversations on the on GitHub about this one, and I wanna make sure happened here as well. And This is parallel invention of existing feature that that is in TLS. And all of the things that you described are exactly the sorts of things that we went through designing the exported authenticators. And what you have done is invented exported authenticators. Probably not as well because I think there's probably a few things you missed. then then Jonathan may may disagree with me or agree with me, and I noticed he's after me in the queue. Oh, he was. I think we should"
  },
  {
    "startTime": "00:56:02",
    "text": "just use exported authenticators for this. And There are a bunch of really nice properties of those. One of which is that we don't have to do a whole bunch of careful crypto cryptographic analysis in this working group. and replicate the work that's been done for those. So over to others. Right? I'd love to hear people's opinions on that one. My personal take is that Those had a layer of complexity that was quite a bit more than this. but I'll I'll take an action to look through that a bit more. Mike Bishop, Akamai. I'm I was gonna say more or less the same thing. I think the export of authenticators would cover this. There is Modulo the question of TLS stack support for them. which is maybe an issue that we would need to think around? The complexity that you're concerned about, I think mostly comes from the certificate request fan. which you you This is unprompted. The server's not asking for anything, so you just pass in an old request. And I think that would simplify it down fair bit. The other thing is that the the key, it's has to be representable as something in TLS. So might be nice if it's a cert, but if it's not a cert, feel us can accommodate those. And Thanks, mate. That makes sense. Yeah. I was second this. This sounds like the discussion we had 5 years ago in exporter authenticators, including all the pitfalls, you hit them one after the other. In in particular like, one one thing that sort of struck that stuck out for me here was the definable context for the TLS exporter not necessary if you're going to be signing the fields anyway."
  },
  {
    "startTime": "00:58:02",
    "text": "just we also don't typically define a don't actually sign the fields. We just sign the output of the TLS We border. So that's why we shove things into their context so that they end up in there. Okay. So that's was also a potential security issue because those things are now implicit in the derivation of the exporter, but not covered by the signature. So there's a potential confusion issue there. You get a signature failure rather than an explicit mismatch. And generally speaking, yeah, TLS exported authenticators with raw public keys. You don't need a cert. for it. It's any certificate type would make sense and it's structured and it doesn't need a TLS library to work. It's effectively this with TLS Framing. rather than rather than structured fields. That's my understanding. Okay. I'll I'll take an action item to Right. Think about how this would look based on just for the authenticators and see if I can convince myself that it makes sense and it's not a pain to implement, but that sounds reasonable. So as the person who did security analysis of both export stuff applicators on this. Yes. They're very similar. the key thing that doesn't exist is that sports flow authenticate is is explicitly not defined as unprompted, And if the client is sending it it has to be requested by the savva, Yes. The spec says that. Whether that's a good idea or not is is a different question. And then think the reason why was there was some issue with early data. So if the client sent an exported authenticator in early data. It didn't It didn't have the same security properties."
  },
  {
    "startTime": "01:00:05",
    "text": "Right. It was I I'm trying to remember what it was. I think it was the if the authentication was gonna fail, then the client certificate was still leaked. right, it was a privacy thing, not a security thing. But yeah. So I I I think we could solve that if we change explosive authentication say the clients can go first. and don't do it in early data. Alright. I'm I'm probably -- -- a lot of people staring at the feeling because they're thinking about this. let's let's think about it some more clearly this this sounds like it might be possible. So let's figure it out if that's the case. That that's an issue. Okay. Done. Great. Uh-huh. Kyle, Kyle, Kyle Eckritz. if is proved to exported authenticator complicated for some reason for the library complexity. Another option is a token by name construction. on And I know that right now token binding is negotiated at TLS layer also, but enough option for that is negotiate through an out of band mechanism just like we do here. Yeah. And and, like, as with those like, this construction looks a lot like token binding during correct. Okay. Thanks. Alright. So Again, I'll I'll I'll also need to go back and look at the expert authenticator's recollection is that, I guess, from a crypto standpoint, the client should be able to generate it and we may just need to open things up. for that, I would argue for doing that. As far as complexity and layering, On Thursday, we're going to present there's gonna be a presentation on kind of trying to revive secondary certs at least for the server giving that that is a thing that is useful for some of these same proxy use cases that"
  },
  {
    "startTime": "01:02:00",
    "text": "I think we're interested in for the unprompted off, And so if you're going to have to implement something anyway, using the same mechanism between both of them sounds good. And, you know, I personally did the implementation for expert authenticators in, like, 3 different TLS stacks to get this all working for us. And it's not too bad, and I'd love to have to only do that once and not also do this thing. So -- That that makes sense. And, like, have to you know, it might be possible to use the TLS export authenticators and then kinda encode them at the HTTP layer as an off scheme. Again, I'll have to think about it more to see and where that goes. Chris? Yeah. Not to, I guess, further complicate things, but But building on export authenticators or were you proversing that with some slight changes to let the client go first seems reasonable. We implemented this, and it turns out that, like, if you don't really have like, an HTTP like API that gives you access to the TLS layer quite complicated, obviously, to implement. So you because you can't, like, poke at something and say, give me the exported thing that I need. So I I don't know how widespread that problem will be for different implementations or if you really have to open up stack a bit to implement this for the use cases that you care about. But if if if it's, like, particularly problematic, it might be worth like like like like considering if we need to bind this to TLS at all and maybe doing it entirely at the application layer. Just a thought. based on the implementation experience. Yeah. Well, the the important thing here is that if you have a signature or you need to sign something fresh, and you don't have anything fresh at the application layer. For sure. They're like like like questions like that to deal with. So, like, one thing that what was what was discussed, like, what if you just, like, have the client generate a random nuance in a time up and sign that and, like, have the server, like, do some sort of check to see if, like, this is not too fresh. Like, Jonathan's gonna, like say, you can't, like, prove that and, like, the the things that I'm doing, which yeah."
  },
  {
    "startTime": "01:04:00",
    "text": "fine. But, like, This this is like it turned out to be a real implementation hurdle. at least for us. So just noting it. Okay. Yeah. I'll I'll look up the there's We closed the queue, but if you can be very response to Chris' thing. Yes. We disagree at the mic line. It's fine. The I I did the security analysis of that. I think I even shared you the slide I I can prove that that's insecure and it comes up with, like, 3 or 4 attacks. timberance. So Let's not do that. Thanks. You had one slide left. Do you have enough food for thought, or do you wanna do that too? So I would like to do part of that slide. Okay. So that you know, if we decide to switch to exported authenticators, A bunch of that slide doesn't make sense. but some of it still does. So Kind this system relies on the client having a publicprivate key pair, and the server having a database of public keys. pretty standard. And that database is indexed on PID. and the registration protocol as in the client telling the server, hey. My key idea is this, and my public key is this. is out of scope because every app, generally, you know, if you're a VPN provider, you already have a system for that. We don't wanna specify a new system for exchanging keys. That said, as inner quest to allow people to run with scissors and not injure themselves There are some attacks where you don't have a proper bind. If you don't have proper binding between key IDs and public keys. weird stuff can happen. So Jonathan can talk a bit more about that. But The thing we had here was to add the public key to the kiosk border, that which to remove some of the class of those attacks."
  },
  {
    "startTime": "01:06:03",
    "text": "Turns out that then you have to talk about, like, reliable encoding of public keys put it in the context or sorry, deterministic encoding of public keys, which is a bundle of fun. I don't wanna touch ASN 1. So it's kind of my question for the group here that still relevant one way or another is This side like, Is this class of attack in scope? For example, like, my mental model was you have a registration protocol that's not completely broken, and the output of that is that you have a a unidirectional mapping of key ID to public key where a key ID only ever matches one public key, and you also never do key rotation. Or if you do, you know, that you restart this and whatever. Well, how do people feel about that? Like, do they think that this class of attack is important to solve because it gets into some like, hairy hairy tamarind things that are outside of my understanding. Or do we just say, hey. We have a we assume that you have that database and if you don't, well, that's then you don't use this. How do people feel about that? So we tried Chris Wood, I don't have a super strong feeling, though. does seem like it would be sensible to document the assumptions that you're about the registration protocol? Absolutely. Okay. Assuming you do that, then happy with whatever else. people think. Thanks. Yes, I think it's pretty important that the client and the server agree on which public key was being used. as part of this. So I think we'd probably work work with this. I'll talk to you offline about how I think we can work on Wait. Just to clarify, are you saying we can work on it in terms of documenting it as an assumption of the protocol or as in working on it as in it at the protocol layer. I think we need to fix Yeah. Okay."
  },
  {
    "startTime": "01:08:02",
    "text": "Dennis Jackson. So if you do something like export exported authenticators, you kinda get this for free. which is nice. I think you do wanna do this because that's a lot will use, like, short truncated key IDs and just expect it to work. obviously, like, It won. It won. It won. Okay. Thanks. No. That's that's useful feedback. Add With export or authenticators, you don't get it for free. you just directly send it on the wire explicitly. Yep. Yep. free. Okay. Okay. Alright. And that's it for this. That's definitely have food for thought. The editors will look at export authenticators and see. I really love the getting things for free because last work I have to do, the happier I am, Modular job security. So thanks everyone for your time. and on to the next one. Okay. Now we have Mark. Thank you very much. That was lots of fun. One moment. We have structured headers, I mean, fields. So while we're doing this screen share. If you haven't signed in to the data tracker, For this session, please do so. There's a QR code up on the screen there. there should be a blue sheet passing around, which feels weird to say that because of how it works now. Where is that sheet? someone have it? Oh, it's just sitting up in the corner alright. Can can you circulate that, David? because I saw some AMS staff walking around earlier, counting heads and I know they'll yell at us if we don't have good numbers that match the head. You know? Don't get a cell then. So"
  },
  {
    "startTime": "01:10:00",
    "text": "we're gonna talk about structured fields, biz, This document, we took it to last call, I believe. We had one a big issue raised in that which was the ability to use non ASCII strings, For some use cases, we ended up agreeing there was consensus declaration by Tommy that we would add display strings as we decided to call it. We had a PR for that. And the only issue that kind of came out of that discussion was this one from PHK. And the issue is basically look. We're using 2 kinds of encoding in the same structure that's really, really not great. And and so the obvious thing to do here was to just use percent in coding. I put together a PR for that and that's been reviewed by some folks. Wow. This is laggy. and it's it's relatively straightforward. The only issue in the the reviews of the PR that I think merit some discussion is whether or not we normalize case in the percent encoding. so it can contain the percent in code characters. excuse me, can contain letters, In many contexts, those are case insensitive. But in structured fields, we're being very exact about how things work and and how they're serialized. And and a a couple of folks have said, yeah. We should probably define which case should be used and mandate that. I'm pushing back on that a little bit. because people are likely to use existing libraries for working with percent encoding. They're quite prevalent. especially the URI libraries, and they generally do not enforce case. And so there are 2 separate decisions here. One is is do we mandate a case"
  },
  {
    "startTime": "01:12:00",
    "text": "for serialization? And then do we enforce a case when we're parsing? And if my concern is if someone uses 1 of those libraries, Excuse me? They may not have access. to to to enforce a particular case. or, you know, they may not decide to go and do the extra effort to enforce the case. That's Also, I feel like this is a little bit strictness for a strictness sake. We have other places where there are potentially alternate serializations of our structured data, and we don't enforce a single serialization knuckle serialization there are there. So I see Martin shaking his head and pacing. Go for it. Yeah. I I find it kind of odd to think that this would be the the default here would be that you would pick up a library to do something that it's like 2 lines of code. Yeah. Okay. I don't want a dependency on the Euro spec. I I think we should specify what it is that we mean rather than go off and have someone have someone It's very poorly specified and that's best in that specification at least by the standards that we've applied thus far -- Sure. -- to this specification. And I would rather deal with the the encoding thing here, at at which point yeah, we can just just pick up a case or lowercase or what have you. Just go with it that way. I I I I think, concretely, most of the things that we have in this specification are Well, there's a ringing out of this microphone. It's bad. they they are canonical. simply by virtue of having the specification being very precise about how it how it manages things. And maintaining that would be, I think, a a good idea. Most. Not all, but most. Yeah. Yeah."
  },
  {
    "startTime": "01:14:01",
    "text": "I suppose maybe the way that resolve this is to actually go and make the change your suggestion and see how onerous it is. and I'm not against that. I'm just I'm just I'm just I'm just I'm just Wanna make sure we consider that. Did I hear you volunteer to revise the ROI spec in the middle of that? No. Okay. Oh, him. Yeah. Chris? Any other thoughts? if Chris Lemons and then Kazuko. Oh. Chris? Chris? Chris go first. Basically, that. The People are gonna use existing libraries, but asking for an extra call to L case or U case at the end. for those things is probably not 2 owners. Mhmm. Chris Lemons. See, that that's what worries me a little bit because that is now a One extra thing to do has a little bit of a perf Yep. because the whole well, I think I kind of agree what marks it. I'm not sure if I haven't this thing is really a chemical concern. The fact that we don't prohibit for example, also newer newer tractors to be using the person in coding. So to check if the values values are equivalent, we have to decode $3. So I don't think there's a practical benefit in requiring them to be in Milwaukee's law. No. dumb. Great. It just lost the connection or something. Yeah. I I think if if there was a security location that we could illustrate or something that would maybe be a different discussion, but but I I don't I don't sense the strong motivation here. No. No. That's not to say that I I grew I think I agree with you, Martin, that maybe we shouldn't rely on the UI maybe we should specialize this ourselves, but I don't know that that's motivation to require a particular case."
  },
  {
    "startTime": "01:16:02",
    "text": "I I don't know if this is my convincing or not, convincing or not, there are performance implications for for being having to processed both up and normal case. Right? So you know, you know, Whatever. Yeah. Yeah. Yeah. I don't know. We we shape these things off in a number of ways in different places. Like, the field names are or lowercase now. Right? yeah. Yeah. arguably if we're concerned about the performance cost of converting Sure. Then you know, that's roughly equivalent to the performance cost of having to fix it in parsing. So so then this is the real problem. how do we choose which? case. me set up a poll. I mean, just just So so it was on the screen previously, but I I suggested language. I suggested language. And I suggested that maybe you could cite RC 4648. And in RSC 4648, it's uppercase. Thank you. Take that what you will, but someone someone else has obviously put flip the coin, flip the coin, previously. and no sense in like, reflipping it. Sure. Sometimes it makes sense. I never mind. Yeah. No. That's fine. I'd I'm I'm gratified that this is what we're down to with this spec. Like, Yeah. Yeah. Okay. Thank you. think that's any other so assuming that that's the case, we'll go ahead and work through that, maybe have more discussion, then I think we can chip this back. Yeah. We can we can do it, like, a second last call. Okay. and then Yeah. Yeah. Yeah. 2 weeks or something and then move on. Okay. Let's move on then to retrofit structured fields. And I think the only one that really this is almost editorial"
  },
  {
    "startTime": "01:18:01",
    "text": "we really wanna discuss is 2521. And and this is basically working through the implications of how extensions work in map fields. And I asked folks for feedback on this. I think a number of times in the issue by ceasing people And I'm talking to myself. So now I've got you all trapped in a room. Yeah. And so the kind of my thinking here is that you know, if if if you read the issue, I I I won't read the actual issue. But For a map field, if you've got a complex one like cookie, when future extensions can be defined. you really have 2 choices. You can either say all future extensions to that existing field have to be syntactically compatible with structured fields types. or you have to define predefined a type for those future extensions and shove them all into that type. Otherwise, someone's going to define an extension that aced generic structured fields parser is gonna look at and say, I don't know. And that's not a map field anymore. That's something else. And and so the kind of I don't think we have to choose one approach here, But if if if that analysis is largely correct, which is what I'm really wanting feedback on. that has implications. We need to make a decision for for different kinds of headers. For cookie and set cookie, I've already had some informal checks with some of the cookie folks and said, is it okay if all future extensions have to be syntactically valid structured fields, And they've said, yeah. That seems reasonable. I really want a 100% make sure they understand the implications of that, and that means we need to put actual text in the the spec, constraining future extensions to cookies. And then I think we can close that one off."
  },
  {
    "startTime": "01:20:03",
    "text": "authorization and WW, we authenticate, which is the other For issue we have open I think we have to make this choice. And I think it's probably the same thing. We need to actually update the HTTP spec and say future if we really mean this, if we're gonna define those headers. we have to update the the HTTP spec and say that future schemes have to fall into this bucket. It's a little different because authorization in Dub Dub authenticate do have the base 64 form. But because they also have the parameterized form, you probably wanna say something like it has to be either a structured fields token, which is not an HTTP token, or a structured field string, which is almost an http string. but it can't be something else. other forms of tokens and strings in HTTP. And then for link template, which is in in another working group, but also is infected by this, we've already made this decision. It always requires parameters to be serialized as strings. which that's the way to do it too. Any thoughts? I see Julian's on the queue. Julien, we can't hear you yet. But now? Yes. Okay. Sorry. I don't still don't get why we have a problem with authentic location because the parameters are either token or quoted string. As you said, the tokens in HTTP are not watch out for you tokens. So The only thing that we can say that will always work is is this is a swing. I mean, if you have a token, you have to put it into a structured point. And if it's a string, it meets the wall and was backdrop field string, and there is no other kind of type in authentication."
  },
  {
    "startTime": "01:22:00",
    "text": "And I believe that Sorry. Go ahead. That's that's no extension point there. It's fixed. I'm listening. I'm listening. You would hear what you're saying. I am concerned that I know you believe that that tokens and strings are interchangeable. in in parameters in HTTP. I'm not convinced that people who implement and use parameters, understand that. and that some of them lock in and say, well, this has to be a token or this has to be a string. could be wrong. I'd be happy to be wrong. but I don't know enough to to say definitively that that's not the case. Does you hold now? Okay. thummy? So on that point, earlier, we were talking about for the unprompted off what format that is, and I I my homework on what we did in privacy pass, and we had reviewed that a lot with Julian. So we did end being like, hey. You know, this is either a token or a string, and it really just depends on if there's the padding there. whether or not it's there, and we did have to go through and make sure the implementations all handled both. So There are at least, you know, cases where we are having efforts to not ossify around assuming it's just one. and it'd be nice to have something written down for that. Okay. I think I think what Julian is really saying here is that the the the mapping for authorization is complete. necessarily complete. and that no extension to authorization, we'll be be such that it cannot fit within the mapping that exists. I'm not sure that's necessarily true for all of the other fields that we're talking about. Yeah. Yeah. And so I guess the question is,"
  },
  {
    "startTime": "01:24:01",
    "text": "what our philosophy is with respect to the mappings themselves? Do we expect to have an escape valve whereby you have the non map version. available in in certain context or is this exclusively the case that using the mappings and not only the mappings. because if that it's the latter case and you're only using the mappings, then an extension exists or is if defined, then we do have to deal with this problem. Otherwise, I don't know that we really do need to deal with this problem except maybe informally. as in as when it comes time to defend to define an extension, to link template, we can say, well, you know, that's not gonna fit very well in structured fields. Therefore, maybe we should do it this different way. Yeah. I don't know what what what the philosophy is here, and so I I don't know what the right answer is. Yep. The philosophy is that, yeah, to use this specification you need to be able to fall back at least for the the other fields, the compatible fields. The map fields are to this point, we've been trying to make sure that they're complete mappings. But but, yeah, certainly, we can take the same bar there too. Yeah. I I think in in that light if the if there are the 4 if the fallback exists then that means that we don't have an absolute requirement to to curtail, we can say, suggest as opposed to create a constraint because otherwise, it's a bit weird for us to define what is essentially a transformation of of a field. but then go back and apply constraints such that the transformation is possible. That's find that a little awkward, and I'd rather avoid that I I So so apply that thinking to cookies, for example. Yeah. Again, I don't think there's anything we've done in cookies that would be a be a problem lately in the past, and I don't anticipate"
  },
  {
    "startTime": "01:26:00",
    "text": "being a problem in the future for mapping. So maybe that's sufficient. And and so you're saying we don't need to have a hard requirement in the cookie spec. Yeah. Although this specification could contain advice to people who are extending Yeah. If you want to be the the map fields that we're defining. ideally, what you would do is this. Mhmm. Which is to find them using structured fields compatible types that fit within these mappings. I I don't know. I can live with that, I think. Yeah. To me that takes me to the other which is authorization and double up authenticate, You know, if we're going to say that that has to always map to strings, that kinda makes me unhappy because we've got folks stuffing binary stuff in there. Come on. You know? You know? So Yeah. I don't know what to do about that, though. Yeah. So concretely, in that case, I don't know how someone presented with the string that is the unmapped version of of authorization Is that an s or is that, by the way? It should be. Sorry. He's he's gone negative. I typed it. Yeah. Yeah. I don't know how someone presented with that string. would would would would be able to make a decision about whether to map it as a string or a binary thing if we allow for the possibility of binary. Yeah. Yeah. now it may be that if you directly construct 1 in a native form, you are you have the ability to put binary in there in place of the string I think I think that may be something that we want might wanna consider that. So a little while ago, we ripped out the mapping headers, the new headers. the new field names. Yeah. to make this work, you'd really need to define a pair of new fields. And then I think so. Yeah. Because I I"
  },
  {
    "startTime": "01:28:00",
    "text": "to Wow. Yeah. I don't know. To make it interoperable potentially. Yeah. make it useful. Yeah. Understood. Then you'd say, well, these are structured fields. And here's how you carry these existing authentication schemes. And if you define a new authentication scheme scheme can define it to explicitly fit into this if you want to. Otherwise, you can't use it here. Oh, yeah. That's interesting. And so so David's new thing could say explicitly IMA Fu header. Yeah. Yeah. on the structure. s s f authenticator, whatever. You know? Yeah. and -- 1. -- 1. The other way to do that is Yeah. Okay. I don't have a good answer for that. It's it's all getting yeah. Yeah. Yeah. Yeah. But that's effectively an upgrade of the entire authentication framework, And I feel like that should be a separate piece of work maybe. That's not just a retrofit. Yeah. Okay. So I think I've got a direction on this issue. And I think on this authentic authorization in Dub Dub indicate headers. My Inclination is still to punt on that because as as I just said, that's not really retrofit anymore. That's kind of a bigger issue. Because if if if we just say everything's a string, we're not really getting the value out of search field there. Any further thoughts on that? I know Chris would you had some desire for that, I think. Sorry. We're talking about the retrofit version or the map version, the authentication headers. If if we didn't do that, would that make you incredibly sad? Okay. Don't wanna make Chris sad. So Yeah. Okay. Alright. I think that's all we have. for that spec and less anybody else. has anything else. I think I I wanna get this incorporated and then step and have a look at it and figure out Is this still the right shape? And is it trying to do the right things? Is it at the right level of vagueness and"
  },
  {
    "startTime": "01:30:00",
    "text": "abstraction, or do we need to do more or less because It it is a somewhat speculative piece of work in that it doesn't actually allow you to write any code right now. And that makes that makes us a little nervous too. Okay. So, yeah, this I don't think that's even though we'll probably drain the issues we'll probably step back and think about it before we go to last And that leaves us at query Just a brief update, Julian, I know you're here. Do you wanna talk about it all? Or There we are. Yeah. I yeah. I'd I'd like to apologize that there has been no progress. I really have have been busy with other things outside the IETF. And when I had time I concentrated on structured fields and the 2 largest specs. which I think we'll go into finish in the next few weeks So After that, I'm hoping to get back to that. When I do I? Great. Okay. So watch this space. We'll get some some motion on query soon, hopefully. next up we have a very brief update, I think, regarding the Alt Service task force Mike, did you wanna say a few words or So much like Julien's comments. There hasn't been a whole lot of movement here. Part of that is that we would like to see some implementation and trying out what we have defined so far. So if you have implemented or interested in implementing, there's not a down. If you haven't implemented and could, that would be fantastic. Otherwise, this draft kinda sits here."
  },
  {
    "startTime": "01:32:01",
    "text": "Thank you. Thanks, Mike. And now we have a short update from the WebSockets. design team. Lucas? i, 24. Oh, Ken. Let me stop this thing. code. I need to stop that time. Okay. No. Oh, Okay. So I'm Lucas. I'm a threading a needle a little the the thin eye of the needle enthusiast. This is a report on the design team set up to help can draw considerations and maybe come up with some proposals. about the discovering WebSockets over HB2 and HB3. stuff that we discussed in the the last IETF in Yokohome And so As part of that, we looked for some volunteers to come in, and we had some good response. Good fairly good representation from clients, servers, and other folks who are just interested in WebSockets. As usual, you know, people get a bit busy, and they kind of contribute, and then got distracted with other things that are more important. So In trying to thread that eye of the needle, I've taken some discretion is the lead to try and draw I think were the conclusions from that. And that might not be fully representative of what everyone in that group thought. But I've encouraged them to come up and have some discussion. at the mic line just in case that's that. So we I tweak the slides late, late, I wanted to do some late binding while I was here this week to try and if we could resolve some of those things or get some clarity."
  },
  {
    "startTime": "01:34:03",
    "text": "I've done the best I can, but these slides, I'm gonna present, I think, are slightly stale. The tweaks are different could update the date tracker after that'd be great. But, otherwise, let's just crack on. So we have yeah. This has been going on for 2 years. got a list of folks who volunteered. Thank you very much. this was a a a team of people globally distributed in a lot of flexibility in hours. I really appreciate the efforts and inputs there. What we wanted to do is try and draw the key points out that we discussed last time and have discussed the mailing list for the last couple of years. and I'm I'm sitting Robin Marks is barbie thunder here. That's effectively, these are the ones that I think we're the most key. that when a client sees the WSS URL, it has to make a bet on the connection to use to open the web socket to it to it. And this isn't a WebSocket that takes over the whole connection. This is a WebSocket reflectively a stream for the WebSocket resource. And that could fail. And if it fails, it can fall back and do something different, that's okay. But using HP 2 and HB 3 has advantages because of the multi plexing, and the the the other benefits that that has of shared fates and lifetimes and connection views and etcetera, etcetera. so you want to do that if you can as a client, But if you make the wrong bet, has an impact. It has an impact on the latency aspects on the client side. You waste around trip. we think that's important. Others might disagree, but we think this is important. If it's not important, we probably don't need to do anything, and you can just live with how things work today. But if we do wanna solve it, we need a solution that can do that. and it also wastes things on the server side. people open in connections because they believe it's kind of the this the the connection is gonna by the expectations or requirements that it has, and it fails and then you fall back. and and that's a waste it's probably So what we want to achieve"
  },
  {
    "startTime": "01:36:00",
    "text": "is to increase the chance the client can bet on the correct course. There's information out there that they can use things are implicit. Maybe there's some history and heuristics. But we'll just wanna front load a lot of this stuff to avoid wastage, other key point here is that picking between h 1 and h 2 is different from picking h 3, And this is because of the underlying transport protocol. you know, you know, you know, CCP. and the quick And, therefore, the decisions that the client needs to make or the choices or the bets, vary. And trying to find a solution across those two things is tricky, a solution that works, so maybe choice between h 1andh2 is is hard to apply to h 3, and that maybe we don't need to solve that. But if we could, that would be fantastic. And in in the discussion, we've talked, I think, last time about other things that you also use extended connect that maybe would fall into this bracket. But through the course of the discussion, we we really wanted to descope those things. We have an issue with WebSockets, and we think we can do better. Stuff like mask. We're we're talking in other groups. as we should about proxy discovery and aspects where you can have a different form of communication of the expectations or capabilities of the endpoint and what should happen. the failing modes and conditions are different. Web transport similarly has its own model and interactions. Maybe some of the things we're saying could apply there. but that was not our focus here. And so what we did is is take those points and kind of break them out into properties of the solution. So we wanna come up with proposals? And what what are the important things that the solution should have because there's many solutions, and some are good in some areas and some are not so great in others. And this was the list that the group came up with. and you're ranked. So"
  },
  {
    "startTime": "01:38:01",
    "text": "priority at the top. The most thing Porton and the one at the bottom. And and, you know, this is kind of a throw throw it at the wall, see what sticks. and then try and see what we think is really needed, which is this would be nice to have because it in Cruz. Yeah. warm and fuzzy feeling we have if we deployed this thing. Another stuff, that's probably really important for the end solution, such as the ones at the bottom, like downgrade protection, or or other stuff. Like, we we came up with this, and then we realized we needed some more clarification education even within the design team, and we didn't feel we had the time and or expertise to do that. So I see. because they were in the queue. Is this a clarifying question? or Yep. Huddl Hoch, a clarifying question. In the first priority, you say that be able to establish web for the without additional round trips. Doesn't mean is there a premise that there's already an existing HD. HD. collection using HTTP, and they're starting web. So get to commercialize it about starting web at connection where from a point where there's nothing. A bit of both. I think, you know, this is some of the difficulty in in trying to understand. Depending on what a client might already have open. if it has a connection open, and it had the information that that was WebSocket. So page 2 capable already. whether that's based on a clear signal or some historic information. No. It's gonna make the the extended connect request, and that would fail and then it needs to fall back. That's one round trip. gonna fall back and open the TCP connection you know, that's multiple extra round trips. I think Yeah. Sorry. And there's other there's other conditions. But effectively, as I say, the key point is around reduction of latency. If what we can do is get to a point where a client can not have additional round trips on top of round trips it would have to make. then that is a good end result."
  },
  {
    "startTime": "01:40:02",
    "text": "I'll just go through these quickly as well. I think explaining some of this would would help, actually. So Now the second one is about server agent rollback support. And this is kind of what I was talking about last time. So the ability to have phase rollout migrations, tuning things off if they're going wrong. An ability to kind of change your mind or have more control other than trying to sludge hammer everything everywhere all at the same time. But that's different. 2.3, which is effectively reneging on something that you you advertise. So mid connection. trying to yank the rug out from under the client. is this something we we think is pointless of trying to solve for. But we kind of have this situation ready with with connections that you know, maybe There's various reasons, and we kinda solve this with go away. We're gonna drain you, and we'll all know what we said before. We really don't want to. and maybe it'll break. But, you know, you've got an opportunity, and we're gonna tell you the new thing. and the new conditions that we support. We've got things like hop by hop support we wanna avoid. proxies and change of proxies getting confused about the kind of WebSockets support that there is. or confusing the client. would be really nice 1000 logical consistency between h 2and3. This is the journal HP thing that we might not be able to. There might be good reasons we need slightly different solutions. But wherever possible, if they can align this. as much as much And that just makes rationale of the design easier, And what would be nice is to just to determine the status of the port of the support after a connection is established. So I can't quite phrase what that means now if somebody else in the design team can do it as in clear, but we don't wanna have to kind of actively probe if we don't want to. or that this information is available just once and new way to to do it is to kind of go and speak to the network yet again. it should be Storable in some way."
  },
  {
    "startTime": "01:42:05",
    "text": "And so we we came out with effectively 4 potential solutions, not many others, but we think these four mapped to those properties fairly well, and those are the ones we wanted to pay attention to. So two of those we talked about last time in in in this Wicken Group, the DNS option. And There's one proposal for that. The proposal could be different. but the idea of using the DNS to advertise the capabilities of the the origin or the authority or whatever the correct technical term is for this thing, that you're about to connect We also talked about the setting, which would be presented on the connection the thing you're thinking that you're talking to. And then there were other options that have been kind of passed around the mailing list. here and there, such as using an ALPM, a new identifier to encode that information such that it could be invoked during things like handshaking or old service discovery or the stuff. And that's that's a bit complicated, but we what we didn't have there is any con kind of concrete write up proposal, which makes talking about it difficult. And so in one of the latest slides, I've got some cons on what ALPN is, like, downsides to that approach. And that's maybe reflective of one solution, and a different solution doesn't have that. And that's taken out of the slides and the vision of going to data tracker. This is not fair to the the posal space. And if someone could have the cycles to think more on that, Maybe maybe this would be solution we consider. But but bottom. And then options kind of feature discovery for the server you're actively connected to, which it's it's general HTTP feature discovery, which we don't have a solution for anyway. Those are the only 4 we considered against our set of properties of the solution. we did some nice, you know, give them numbers and rank them and do this and times by 2 from us. and"
  },
  {
    "startTime": "01:44:02",
    "text": "one by NICE and whatever. And no matter kind of what we did, This was the the result. that we had. That's You can look at the numbers. They don't mean anything really. therap arbitrary. But I've I've The analysis of that is that Kazero? Let me just go back. Sorry. I just wanted to point out that the numbers look the opposite for DNS and settings Uh-huh. I mean, I I think and if you calculate the some DNS is 29, and settings is 30 I might I might have yeah, I've I've tried to transpose things if if if yeah, that's another tweak we'll make before we post these to the data tracker. Thank you. Just keeping on it is. What's what's good is the results analysis is the correct bit. So so so from our findings, options have a it was a clear neck some outlier. Martin, If if because you always write DNS is not on top. Okay. Well, with with -- No. No. I I did wanna I did wanna say one thing. that it's not about whether or not you got the slides. Methasade. But the the the conclusion that we've reached in other context is that DNS is is very good. as a sort of hinting mechanism but it is not very good as a means of establishing sort of the point. authority, about the status of a server. Yes. And and so I'm gonna think about when you when you go through all of these things. It's not something that's really reflected in your sort of metrics for this one, but it's something I think underpins a lot of the decision making that we have And that that probably should have put that on early in the slide. This is all about hinting. and trying to make things better. You're the only the ultimate result is the response code you get when you try this thing out."
  },
  {
    "startTime": "01:46:01",
    "text": "And and that's about as best we can do. We can put lots of stuff in in anywhere. And no matter how strong we say the hint is, it could still fail. and the client's still gonna have to deal with that. And it can already do those things today. So Anyway, back to this. We wanted to discount options. We've done a spent too much time with that. DNS was on the top. It wasn't much between those things, is that in within a margin of error or not? was trying to explore some of the cons, some of the practical deployment considerations that these hangs have. amongst people in the in the design team. And but the others in the working group might not And if so, come come and discuss. So some of the constraints is that, you know, DNS. If you're gonna put something in new record types or new options that Not all clients can access that. today. Today, That's something maybe we're trying to gravitate towards and that within the time line of what we're trying to achieve, maybe the problem will just go away. Well, it's not just I can support accessing the or querying these record types in because of a library dependency. There's there's other work that's going on like privacy proxies where the separation of concerns from the connection that's being made and the thing that's doing the DNS query could mean that we don't today have an ability to back some of the hints that we would like to put in the DNS. that's probably a technically solvable challenge, but it would be a creation of a dependency of some work that we don't have, and I don't know if anyone's trying to solve that problem yet today. We've seen some of this with Tommy's next hop alias proxy draft. or spec or returning pieces of information. But we are level not to kind of make it DNS over HDD headers but maybe what we're seeing from this. And another stuff is that that solution is maybe desirable. for different kinds of use cases. Alex. Can we leave the queue to the end because we are very time constrained? That's okay."
  },
  {
    "startTime": "01:48:00",
    "text": "let me let me just route through. Yep. So so the other option is settings. This applies to a connection. the server would say yes, I supported Extended Connect. And, yes, I support WebSockets using that extended connect method on this version of feed I'm using. But when I was in the shower one day, I thought of an edge case that happens here because the setting applies to a and we wanna do more connection coalescing where the properties of those things, may vary because we're trying to coalesce As a vendor, you can support multiple different, domains and administrative domains who wanna configure things differently. And if we tell people that they can coalesce using the mechanisms that we have already or there's like, certificate frame that we're gonna talk about later in the week. You end up in edge cases that I think could happen where Somebody never wants to enable WebSockets of HB2, then somebody always does and and we just we're back to where we are today. So I think that's to me, that's kind of But there could be a way to redefine new settings that are origin scoped And maybe that's something we need to think about as coalescing that's better. I don't know. the guy. The guy. There's that. And the LPN option, didn't have a concrete proposal, like I've already said. It's it's unclear if you can help with this selection betweenh2andh3. Right? You can do it with advertising a list of things I spoke to h and h 2 and h 2 WebSockets and have the server just use ALPN as it normally would select the most preferential. But if you're trying to do something like that by putting LPN values into old service headers. or ALPN values into the DNS. kind of maybe don't get those benefits anyway because the head is broken and the DNS is gonna lie, and the DNS is a different option if we encode the same information. a different way. and that's it. So"
  },
  {
    "startTime": "01:50:03",
    "text": "We don't wanna do everything because it's complex. builds things. There's no perfect solution here. I think we we we clearly can't find something that's just gonna work and everyone is gonna enjoy it. this is about trying to create a hint that helps. And if we can't do that in a way that's can be done timely and pragmatic. Personally, I don't think we we can do anything. So the the the the direction is that DNS has some snacks today. It it could those could be resolved. it's a decent way to to hint things. It's already being used to hint things like HTTP version support that then you need to go off and try and create a connection to that thing, and then you learn it didn't work, and then you have full back mechanisms. And so closing thought that while Sangamo might ease that pain today, I don't I think the issues with coalescing kind of intractable. for me unless people can clearly tell me I'm wrong, and I'd be Fine. Fine. Fine. So this is a summary which I've just summarized That's that's it. Our next steps are really you know, do do you wanna accept kind of recommendations or the findings that came out of this group. And can we can we wind down the design team and move the discussion to into the working group. Okay. Thank you. So we already have a fairly substantial queue. We have one more topic that we'd like to get to after this. I don't know if that's gonna be possible. but even with the queue we have, Please be brief and to the point we will be closing the queue very soon. Hi, Alex Schanowski, Google. I'm gonna start by saying thank you to the design team for all the that you've done, and I'm sorry that I'm about to descend and say that I don't think that DNS is right way to do this. I mostly wanted to ask if we'd actually considered a alternative I don't see on there at all. which is maybe we should be adding another field to the TLS"
  },
  {
    "startTime": "01:52:02",
    "text": "handshake sort of similar to ALPN where we can declare which features a client wants. Because the thing that I really see here is that we have a problem with the hinting mechanism because it's really really unfortunate that we don't have a consistent baseline of features between HTTP versions. And what we really want to have happen here is a semantic that without having to go to fallbacks if possible, you get the right answer on the connection. And if you could imagine a world where you say ALPNH1H2, required future WebSockets. The server can say, well, I don't support WebSockets on H2. They're I'm gonna choose h one. And that's not really something that you can really express in the DNS hinting mechanism because you might not necessarily have uniform back ends. even though your front end server might support everything. So I feel like there is a combinatorial thing here that can't be expressed So if we don't believe in adding, like, an h 2.1 ALPN that changes the baseline, maybe we should be bringing more settings frame information to the handshake. I really don't like the callback mechanism that we Thanks. Then Schwartz, Meta. So As as a a Diana expert for the service bindings registry, You know, I I think something like this certainly can be put into those records But, personally, I think the right solution here is not a technical solution. It's It's a an RFC that says HTTP is version independent. because the the idea that you have services only in certain HTTP versions on your origin. We have URIs that's specify them that are version independent. is a a huge tangle. And we don't have to come up with a technical solution for every problem. We also are empowered to tell people the right way to use the systems that we've built. In this case, the right way to use these systems is to offer the same things across all the versions of HTTP that you operate. And if you're in a state where that's not true, that's okay. We can tolerate that, but we should treat it as a transient STATE THAT'S NOT THE TARGET STATE AND INSTEAD OF TRYING"
  },
  {
    "startTime": "01:54:01",
    "text": "optimize that, we should encourage people to get out of that state. Thanks. David Benjamin, a strong agreement with what Ben said. Basically, all of comes from us having the wrong baseline. I wanted to point out the So the ALPAN thing so so doing something like ALPAN is the only thing that solve h1andh2 because that is where the decision is being made. It actually the DNS thing actually won't work at least the way alter us service b HP as in service b are currently written. We put a lot of effort. There was a lot of time spent on the be all service stuff to make sure that DNS is not allowed to downgrade the HP version selection. And so when you say h 2 in DNS, it actually means the whole family of HP protocols that, like, share that entry point up until, like, TLS or whatever. And so by the, like, current text in the service speed draft, like, you but saying h 2 and h 1 are based equivalent, and there is no consideration for you to, like, further filter it. And if we add that, then this means DNS, something non authoritative, is allowed to downgrade the protocol that you select, which will introduce other problems, should we, like, ever add new protocols that run over the same transport like an four that runs over a quick v 1 or something like that. So, like, We should treat this as a transient mistake that we made when we defined 2 and h 3 that we didn't set the baseline right. We can choose how to get out of this transient issue by, either defining h 2.1 or just to saying this was a mistake or citing WebSockets is not worth the time. I don't know. But, like, I think the current the current the the proposed solution is mostly going to add problems rather than solving them. Watson lad, Akamai. I just had a strong sense of deja vu in this conversation. It felt very much what have when that trying to advertise h3orh2. And, obviously, there's some differences But it seems like the same kind of monopoly of solutions come up and the same kinds of"
  },
  {
    "startTime": "01:56:02",
    "text": "drives, like, have an outcome, but that's not good enough. We want to put in DNS to be faster, want to remember. So I think there's this is this very strong sense which those are are connected, we probably don't wanna go through the whole wheel twice. Eric, can you hear Apple? So one of the the challenges that we have when talking about selecting between h 2 and h 3 is that by the time you're doing AOPN or anything after that. It's a little bit So that's a a bit of a challenge. think the the point made earlier about this is this is purely a hint is a good one. I which is People are already are doing this today. People are already choosing today? Today? Today? People already get it wrong, a arguably very, very small percentage of the time. it might be interesting to even look at data for how often we get wrong. because it may be that this is actually a nonissue. Okay. Was that helpful, Lucas? isn't surprising. I I would I I I would respond to some points why I'm I'm push on time. I think I mean, for me, the second point's answered that I that the the the questions or feedback here cannot be answered by the design team. than we had. And if we were to to create another design team and have more people, not not not convinced we would be able to have the resource all the time. come up with that that we couldn't just do in the working group because it's animal mode of work. Okay. I think the first question is a clear no. So so So, yeah, I I would ask the working group to to come up with Some. clearer now? Like, should we even do this? if so, again, yet again, facts are considering the different options. But it to me, it's been a very valuable process. So, again, thanks for everyone involved. and and the feedback. Likewise, I think just getting a little more clarity and little more discussion is is is always a good thing. So thank you."
  },
  {
    "startTime": "01:58:05",
    "text": "Okay. Shivan, unfortunately, I don't think we have time to get to your presentation. we will try to fit that in tomorrow in our other session. So I think we're done for today. you all very much. Thank you, Jonathan, for taking minutes, and, hopefully, we'll see you tomorrow. see a tomorrow phone."
  }
]
