[
  {
    "startTime": "00:00:13",
    "text": "um one right yeah sure but we we would need to populate the real on the real world and we'll be coordinating taking it to the list after this reaching out to people okay stuff like that yeah i mean that's yeah it was kind of just trying to do so that's um okay good morning everybody uh this is the first in-person quick meeting i've"
  },
  {
    "startTime": "00:02:03",
    "text": "for first day technology woes uh apparently we have a bit of an av issue with the screen behind me in terms of that would be running me tako you know visualization of what's happening but don't worry uh we'll live on um in case anyone in the room hasn't yet done it there was a qr code to scan on the way in that would cover the blue sheets and that would allow you to participate so we'll be running the queue via the the website slash application that that qr code would load so if you would like to get onto the microphone while you're in the room please use that tool similarly for remote participants you'll be familiar with using the me tattoo tool to participate in terms of sharing your microphone and entering the queue and so on and so forth so without further ado let's get on with some administrivia and some chair slides i'm sharing how do i forward the slide there we go with a note well so if you're not familiar with the note well no well the note well we are on our second day so i hope some of you would have seen this yesterday uh the noteworld is a reminder of you know the policies in effect uh on various topics such as patents and code of conduct uh you know so please do just go and follow the links and read up on this and understand how your contributions on participation in the ietf follow processes and policies in addition to that just like last time we'd like to draw a specific attention to our code of conduct and the expectations for how tf participants extend respect and get to see to their colleagues at all time again please familiarize yourself with these and if there are any issues that you encounter with code of conduct the chairs the ads the ombuds team are here"
  },
  {
    "startTime": "00:04:00",
    "text": "so please reach out to us we have a note taker brian has volunteered thank you very much as always if there's anyone who would like to dive into the notes app and help him that would be brilliant we do need a board the bluetooth already handled that's good we would like a javascribe would anyone like to volunteer david thank you very much uh we've covered the till these slides are taken from the last time around so some of the outcomes might change it doesn't look that way to me um so again i would hope some of you are familiar but if not you can always use your intuition oops wrong link to the agenda there we go the obvious error we are iatf113 um please ignore that link that's my fault but the the rough order of events is listed here anyway we're going to do some chair updates keep trying to keep it brief uh you know as we've uh completed quick vision one it kind of people uh maybe not following the working group so closely so we just want to give you an idea of what's happened since last time um then we'll get into the adopted working group items so we'll cover version negotiation quick load balancing quick v2 onto multi-path and q log and then we have one additional item to talk about zero rtt bdp would anyone like to bash that agenda nope okay so brief update since last meeting the the multi-path document was adopted into the working group which is good um work is underway there we'll hear from miria later about what's been happening what issues there are to resolve etc uh the hp 3 and q pac"
  },
  {
    "startTime": "00:06:03",
    "text": "drafts ended all 48 after about a year of purgatory so uh we're making some progress there the datagram draft entered all 48 yesterday just as we were on the train to somewhere um so the uh we'll we'll be following with an update to the list about how we're going to manage all 48 comments um around this time but should be nothing out of the ordinary in terms of our working group github flow of issues and resolutions so look out for that the ops drafts the the applicability manageability draft completed ietf last call we're at zero github issues right now so thank you for all the reviewers from the various areas um and for the editors in responding to those issues uh i think we're in a good place we will be working with our head to progress onto the next stage um and the grease bit document uh is dura shepherd write-up from me um so that's on me and that'll be coming soon ahead so just just look out for that one related work um we had mask yesterday which was you know good we have web transport on thursday which i hope will be good um and there is a media of a quick both session on wednesday morning so tomorrow this time that you might want to look out for i won't go into any more details there so i have two slides that i would like to talk about general working group business the first one should be fairly straightforward but for those who maybe don't know the the data tracker holds both our charter and our list of milestones um the data tracker allows generally speaking milestones to have dates or no dates you can't mix them but you can"
  },
  {
    "startTime": "00:08:01",
    "text": "go inside and toggle between the two um currently the quick working group uses milestones with dates and all of the milestones along the lines of submit draft so-and-so to the isg if anyone looks at those they're all past you um we're also missing some milestones for the documents we've adopted um since since that happened we can blame codeword for that but but i think what what's what's kind of fun from my perspective is no one seems to have complained about this and that we're making good good progress spencer's in the queue uh okay this slide okay um as far as we're considering we're keeping active and everything's going along okay so uh none of this is unique to the quick working group as far as i can tell i wanted to do some data driven analysis uh so i scraped the the data tracker api and gathered some information it's not a thread on the working group chairs mailing list as far as i could tell but at the point in time i did this there was 123 working groups four of them used non-dated milestones and the rest is dated of those dated milestones over 500 oh sorry if there were 500 and 400 out of those were late so that's about 80 and the median value was two and a half years so my my interpretation is they're pretty pointless um having goals and in general is good and we should strive to keep on top of the work that's happening here and keep it tuned along and we do see that so for the quick working group the proposal would be to switch away from these dated milestones which adds you know some work for us to decide what the date should be and then what it should be when we don't hit that because of various reasons um but the order of presentation of that list would be the anticipated sequence of our documents"
  },
  {
    "startTime": "00:10:02",
    "text": "so i see spencer in the queue and then david after him please go ahead spencer yeah thank you uh so spencer dawkins and um i applaud the discussions that are happening everywhere in the itf about uh that we don't lie to ourselves but when we stop lying to ourselves and start telling the truth people will notice that something happened the people in the ietf will adjust but i would suggest you to i would suggest you all to be very clear in what you're doing and why and i would ask the working group to consider their chairs to consider uh dropping a liaison message to people who've already interacted with the quick working group from other sdos and explain to them what is happening and why and that we all think it's a good thing and that this is the way this this is reality for the last however long the quick working group has been in existence anyway and now they can tell what we're actually doing but it seems like to me that without that having the dates suddenly disappear completely would send the message that you have we have no idea how long this is going to take which may be true and you might as well go ahead and try to do stuff that's in scope for this working group yourself in another sdo and that that would be that would be a train wreck so um like say i i i know you all will do the right thing whatever that is but uh"
  },
  {
    "startTime": "00:12:00",
    "text": "that that would be my uh input into your consideration to do the right thing thank you thank you spencer um we'll take we've captured some notes there so we'll take that into consideration david please david scanasi quick enthusiast um sure this is between the chairs and the a.d please just decide like let's move on we trust you okay thank you um okay uh and i'll just try to hammer this through um for anyone that may have been uh working with the quick uh drafts while we were still in development before rc 9000 or before they got the instructions to the iana team to construct some tables we had something called the temporary eye on a table which is a wiki page on the bass drafts repo this was intended to capture use of quick and hp3 extension points before those tables were created so that we could just coordinate amongst the community and avoid nasty collisions that's covered stuff like quick versions transport parameters settings frame types error codes and so on um and it's there and we we thank people who have taken the effort to go and register the values there however the ayana tables now exist and we would encourage people strongly to use the actual tables that they should be doing using the established ir procedures in the relevant quick or http 3 documents saying that we do have a bunch of values in the temporary iona table and we want to get those into the into the proper ones as well so we just wanted to give people a heads up of what's going to be happening um and not effectively archiving that temporary table locking it and then assisting with the various responsible parties follow"
  },
  {
    "startTime": "00:14:02",
    "text": "the due process to get everything into the full official tables so there's no action immediately required from anyone but just keep an eye out on the list or for any direct contact that might be coming from the chairs and please assist us in doing the right thing and that is the end of the chair slides as you know in the queue and i think we're good to proceed on to the first agenda item let me switch slide deck thank you lucas my name is david scanazzi i'm a quick enthusiast and let's talk about quick version negotiation um next slide please so uh had this slide from i don't forget how many years now and i just keep adding lines and then it's starting to not fit but conceptually we've been doing vn for a while used to be in google quick it got added to itf quick we split it out to its own draft we redesigned it as a working group and we've kind of landed on something that everyone likes or rather that no one dislikes and over the course of the last um almost year we've done quite a bit of editorial work that's where where the document was quite lacking but we've kind of gotten it in what i think to be a decent shape between the editors um next slide please"
  },
  {
    "startTime": "00:16:00",
    "text": "skip that one thank you we had one question which is in a way editorial but kind of fundamentally changes quite a bit how we um see that uh like a lot of the text and ecker and i didn't quite agree on it so we thought that's great we can bike ship this with the working group and it's on like the definition of the term compatible version negotiation from the draft the way i personally had been thinking about it you would have when you use the same version that the client offered that would just be using that version uh and compatible version negotiation would be when you use that feature to upgrade from one to another um ecker's coming at it more from like the tls side of things where when you thanks martin uh when you um look at that wow lost my train of thought it's early here when you actually stick to that version that's also compatible version negotiation you just negotiated the first version that was offered by the client so do folks have thoughts here it kind of the the reason we're bringing it is like it editorially changes kind of a lot of the document in terms of how we think about it and these are terms that will stick with us for a while um [Music] and ecker if you want to add something uh hop on but otherwise yeah i'm opening up to the floor does anyone care i can't hear you okay you're marked as unmuted but we cannot hear you uh we can't hear martin no all martin martin just tried his thing as if the like audio is yeah yeah"
  },
  {
    "startTime": "00:18:01",
    "text": "okay okay we can hear you empty so the problem is on your end necker my maybe microphones don't work at 2 am in california nope try turning it off and on again i'll let let's take empty first while ecker tries that maybe switch microphone or i don't know empty go ahead so ecker's right you're wrong um this is version negotiation even if you pick the same thing it's a lot cleaner that way then you don't have to think about it too much uh the other thing was a version is always compatible with itself is the other way to think about it that works for me um all right proposal we actually do what echo wants um if you don't like that please come to the mic now and i'm the jabra scribe so can someone just double check that there's not too much happening in the jabber all right then next slightly so that was the last issue we we're going to do some editorial work on this to clean it up uh kerr and i are meeting next week to do that but we're pretty much done uh we we have some reasonable amount of implementation experience we don't have too much deployment with compatible vn right now um [Music] but we think this is ready and kind of the question on where we proceed is do we want to tie the progression and timeline of this draft to what we're doing in quick v2 which is kind of the first way we have to really exercise compatible vm"
  },
  {
    "startTime": "00:20:00",
    "text": "or do we just want to move this forward or you know do working group last call and then park it what do people think why especially the chairs um [Music] no strong opinions from chairs right now it's too early for strong opinions uh so um state your name at the microphone oh okay sorry martin duke google uh and v2 author and um i think v2 is waiting for you so it will not be a blocking thing as well i'll talk about in like the next presentation all right then um i barring like we're gonna do a bit of editorial work in the coming week uh after that i think we probably want to request working group last call then okay thank you we had martin in thecube oh oh sorry there's uh empty back in the queue yeah so having implemented both of these i think that technically they are good uh i think that the version negotiation draft is a bit rough editorially and so i have to get a little bit of time to to see what you and echo manage to put together next week i think there's some ordering things and some terminology stuff that's a little bit shaky but um it's technically sound i've implemented it i've implemented v2 they both interrupt with i think three or four other implementations and i think we're deploying it so whoops cool a quick question mt uh you had a few very good editorial issues that you filed on the draft um [Music] we resolved these like right before the draft to deadline and submitted a new one that hopefully addresses those are you referring to the one before do you think we need like that it's still a bit rough with the latest one oh well we read it last week um i'll have another look yep thanks um do you and we're happy to do that do you think that we're okay to move forward to working with last call and then you know after we address some of the editorial things and"
  },
  {
    "startTime": "00:22:02",
    "text": "address more editor things after working with last call or let me take another look um but if the editorial state was as it was when i last saw it i liked to see that work done before working group last call there's a good chance that somebody could get messed up in that process sounds good when you take a look at um at that police foundation with specifics if you have them thanks yeah cool uh ecker's next in the queue [Music] how about now yes okay oh i can explain what happened later it's not good um anyway um the uh i i i think if we're going to make substantial hurdle changes let's just do them and do our new class call because like you know other otherwise we'll have to do working class call again so um okay that that makes sense all right okay that's it on quick version negotiation thanks everyone thank you david we've made some time up there which is great um that's appreciated which slide would you like to start with b2 b2 okay so does this work with the mask all right sweet [Laughter] uh next slide so the closely related v2 draft uh just for any of you who are not paying attention this has a few purposes it is not adding any features to quick it is not um fixing anything about quick version one it is an effort to grease the version field to have a target for this vn thing that that david and ecker have been working on and also just while we have the quick brain trust together kind of develop a template for what a new version should look like and give people kind of an example to follow when they do quick versions that actually add value next slide"
  },
  {
    "startTime": "00:24:02",
    "text": "um oh actually before i get to this uh there aren't really much there isn't much in the way of open issues um the there's mainly just an editorial thing about what goes in the vn draft versus what goes in the v2 draft so david and i are playing hot potato on a couple issues but i think these can go together probably to working group last call pretty soon we have pretty good interop with v2 um there's one issue that might be contentious we had a little we had a few people who felt strongly discuss it um offline but um alpn is is the one thing so after a bit of wrangling we've decided that v2 should use the h3 alpine rather than h3-something um uh and of course for doq and for moke or mock or whatever it's called uh same thing next slide so the draft currently says that yes all these alpn's apply um this has so there's a few reasons number one since compatible version negotiation there's not a lot of cost to to messing up uh just to using sort of the incorrect version um certainly the case we don't anticipate a lot of v2 only servers and clients out there um as a practical matter some implementations would be would be uh complicated by having to to to revise the the alpn in use um as i talked about a couple itfs ago if we have lots of versions and lots of alpn's then the registry sort of explodes and that's kind of a bad thing to do to the alpn registry for just on on behalf of quick and finally as a deployment issue um obviously a lot of h3 things are are tied pretty closely to"
  },
  {
    "startTime": "00:26:02",
    "text": "to the quick implementation but in principle if you have an if you have a abstract quick implementation with an api the application should be an alpn to provide to to use in the connection and um if you're trying to roll out new quick versions deprecate all the quick versions in a quick implementation then you would then have to change all the applications and that sounds unhappy so for all the reasons this is where we've landed um and i'd like to open the floor if people have a big problem with that or a small problem with that okay we have mike bishop in the queue mike go ahead waiting to see if uh audio is going through all right um so to be clear i'm not coming to the queue because i have a problem with it i think this is the right call i think this is the wrong draft this needs to be in version negotiation um and you can mention it here too but i think version negotiation needs to talk about a lpn selection across versions and when you can share them when you keep them okay i i will say that in terms of our forging consensus we sort of punched the issue of incompatible versions um i think that this this logic should apply to incompatible versions but i'm not sure that is a universal sentiment um the current the current um sort of pattern that we're developing here is that if you are doing a new version draft you should go you should essentially inventory all the existing alpn's and say if they work uh conversely if you're doing a new um if you're proposing if you're registering a new quick alpn um you should really inventory all the existing um quick versions and sort of say if they work and then ultimately becomes unmanageable we can have a registry but i don't think we're anywhere near that point yet yeah i i have a feeling unmanageable or not"
  },
  {
    "startTime": "00:28:01",
    "text": "there are eventually going to be either versions or protocols that don't do that work and it we just need to write down somewhere what happens when you don't know whether it's supposed to be compatible and probably the end is the right place what's that david davidskenazi what to do when like they're not compatible is already in the vm draft mike uh or did i misunderstand what you were saying let's talk about alpn which i don't think is mentioned in the vm draft what to do when you're not sure whether the alpn is compatible with the version and i think the answer is don't use it well so i mean we've all overloaded the word compatible which is a problem so the compatible version incompatible version is referring to the the pain of version negotiation that's the context i was using it in the other issue is like does this does the does are the features of the particular quick version usable with the application which is a different question and that is that is the question that needs to be addressed in each version or in each draft that either proposes a new version or registers a new alp okay and ideally we have some concept of upper layer feature compatibility but how do you quantify that yeah i'm not sure how to write that down either um like i have some good boilerplate i think in the v2 draft that says like this is the same so it should be fine and i'm going to add something about doq since doq has essentially shipped um okay so david oh i'm already here great um i want to add to a few of these things"
  },
  {
    "startTime": "00:30:00",
    "text": "because um so first off i don't really believe that there is a notion of i don't know if this if this application layer protocol works over this transport like any specification of a an application their protocol will tell you what transport it runs on and if it's another transport it just doesn't work period unless you have some reason to believe it does and you you we're not gonna this isn't the taps working group we're not gonna mix and match things and hope for the best um sorry um but no so going into this a bit more this is quite a bit of a mess um [Music] and the the fundamental reason why this is such a mess is that you know and obviously this is obvious in hindsight wasn't at the time we really messed up alt service uh when we did alt service we used the lpn tokens whereas that's not what we should have used we should have used a combination of alpn and the entire transport stack underneath because when you go to another service that is the information you need to know so let's say i connect to this website and tells me it's accessible over http 3. i need to know what quick version i send an initial at and if we are just talking about a lpn here it makes sense to reuse the h3 alpn for quickview on a quick v2 because the lpn is only sensit makes sense only in the scope of an underlying version whose handshake you're doing and that way you can go up to the next thing um but when you're doing all service all this completely falls apart um so so you're segueing nicely into i think what is the next slide if that will work lucas this this is the next slide oh"
  },
  {
    "startTime": "00:32:01",
    "text": "yeah right okay um right so lucas and i have um proposed the draft um which is essentially adding an alt-service parameter that tells you what the quick version is um which will solve the problem for h3 if people support it um we will also extend that to service b once you know we get a couple draft versions under our belt so um this is sort of our long-term solution to solve the problem that you're describing whether or not people will take it up is out of our control but um that's what we have um so i see the queue is closed so i'm gonna go sit down but uh and let mt and ecker chime in but i think this is really important i really believe that we cannot move quick v2 forward and kick this can down the road um i personally believe that we need to solve this uh and stop like just writing more things like there's no rush whatsoever to deploying quick v2 no one's waiting on it and i would like to see this solved because if we ship quick v2 and then we realize that your draft doesn't work out then we're we've made yet a bigger mess for ourselves thanks david martin thompson please just waiting on audio so um i put it in the uh and i'll probably read this out anything that's compatible with quick both on a version negotiation basis and a feature basis is probably okay to use the same lpn i think we'll have to word that a little bit more precisely i think you need a strict or a superset of the features that the protocol was using which means that for instance if you define a new version of quick that only does streams and doesn't do datagrams it would still be okay for http probably maybe"
  },
  {
    "startTime": "00:34:00",
    "text": "depending on all this websocket stuff um but that's the sort of idea that we're going to need to we would want to write down i don't think it works if you lose features in it in the transport and i don't think it works if you lose compatible version upgrades because then you have performance problems and that's part of the reason why we're talking about the all-service thing i think that's primarily why we're talking about the old service thing because if if we're just doing lpns and didn't care too much about it we could do um we do version negotiation right in in that case so um i think everyone else here on the chat has been saying we should add it to the vm draft not the quick v2 draft and i agree with that we're gonna let david respond quickly to that just as the vienna author sorry very quickly um the quick version negotiation draft isn't specific to any quick version obviously so it operates at the level of the quick invariants the quick invariants don't have a notion of lpn because the quick inversions don't have a notion of tls you can have a quick version that's based on noise or what have you so that is yet another reason why this is a mess that's true but we also include a whole bunch of advice in there about what to do with retries what to do with a bunch of other things uh zero rtt i think it was as well so i think probably what we can do is put another one of those subheadings under that section and and say what do you do with lpn in the case that you that you have it i think that's the right thing to do here i don't think this is a property of v2 i think this is a property of pn and i guess the question is what we have to write down right now um i think we've reached agreement that v2 will be fi specifically we'll be fine if we just use we use the alpn and we're"
  },
  {
    "startTime": "00:36:02",
    "text": "establishing a pattern that people might follow um unless there's a reason not to so maybe we can trust future standards writers to say well you know this pattern is not working anymore and so we should do something else but if i mean i'm not gonna if if we want to put it in the vm draft that's fine with me at least but uh i think like with alt service we can only do the best that we can with the information that we have at hand and the experience that we have i suspect we do we do know something here uh and that's based on the implementation experience that we have that suggests that you can use the same lpn under the sort of narrow constraints that i described and then maybe outside of that it's for the for the reader um you know work it out for yourself okay we're we're kind of um out time for this but we'll let akka respond well speak quickly i think you can do that yeah so so i'm not sure how quickly i'm going to speak since things have kind of backed up for a while um so i think a few points um first i think i think like the worrying about like this is probably a little a little more premature um but let's let's let's not the the situation like largely is going to be um i i think okay um in in the sense that um you know trying to run like a situation where you actually have this much confusion about like a the properties of the underlying protocol and be the properties of jlp support seems like probably not like a great idea and we'll probably not try to create um you know you know what application you're running again it's not like your aopn switching between doq and um and h3 right um so um you know uh that that they should do this in like x now hello seems a little weird um i think what that i think what the um uh"
  },
  {
    "startTime": "00:38:02",
    "text": "you know um david uh you're right that this strategist is agnostic about whether it's tales or not but it's it's hard to believe that any any future thing we design isn't gonna need some aopa and wood construct and so even if that's carried in some entirely different way in the transport negotiation in this in the you know protocol it's going to have to go somewhere i think um you know we aopm was added to tls for a reason um i think there isn't it has to appear i agree this has to appear if anywhere in the vm draft but not and not in v2 um i think what has to appear um is that any exterior protocol negotiation signal you do has to be done from scratch when um when when you do an incompatible vn which is to say so suppose for instance that you're um that uh you know if you offered v1 you would have offered a lp at a and when you offered v2 you offered aopn a and b well when you when you get a vn that forces you back to v1 you have to offer a and not a and b because otherwise the attacker is able to force you into posture of choosing a specific aopn uh offer by doing a um uh by by doing uh uh um by doing a vn so i think um and i haven't thought about it if it's entirely possible there are other things like that that have that property and in every single case um they have they jump from scratch now i think it does kind of imply that things are done from scratch but i think it really has to be explicitly stated thanks ecker um i think the the concern that i'm pulling out of this i mean i think i think we're moving forward with v2 using the v1 alpns but um there's david's concern about maybe holding something up until this hp bist draft matures a little bit i'm not sure what would be held exactly b feed the vn draft of the v2 draft i was hoping to ship both of them like soon i think they're both essentially i mean the remaining concerns are editorial"
  },
  {
    "startTime": "00:40:00",
    "text": "so i think they're ready for working with last call unless we want to see how this called service thing shakes out i don't think it's necessary for sorry i should have responded i don't think it's necessary to wait for that um i think the change that i'm supposed to make to the end is straightforward um if if any change is needed i'll file a bug to like check for the change um and um because i don't remember if we have any tests about this and i think that the v2 thing is fine i don't think we need to do the old service thing frankly at all but like certainly not before we ship this okay if if and like i said if you want to wander over to hp bis and and express some support for that that would be helpful um should we move on yes please okay next set of slides all right now for something completely different um quick lb oops nope click the wrong button one moment okay so when last we met um this thing had exploded through some scope creep into uh this multiplicity of config options and there were like three different algorithms in each algorithm had a completely different implementation and had completely different parameters with different limits and um there were not a lot of implementations we'd not done any interop the second problem is still a problem but the first one um has improved next slide okay so now uh i got rid of all that and there's just the one thing now basically every connection id looks like this um uh and it could be encrypted or not and um if it's if it's the specific magic length where it can be a single block encryption decryption because the it's 17 bytes then then it is otherwise you use this multi-pass thing um so this is much cleaner conceptually i think it's a lot easier to understand and it's much less code having haven't implemented it both ways next slide"
  },
  {
    "startTime": "00:42:00",
    "text": "um so these were sort of the last time these this is kind of the path forward i i uh proposed for this um we did a quick we did get a crypto review we did make some changes we just got another crypto review which um was a little less positive about what we had done and so christian and i are working through that they kind of want to do more passes which seems like a problem so we're we're exploring that on how to fix that i was going to delete the block cipher but there was some push back and i think the new system where there's just a magic length where you do it you use a block cipher cleans up a lot of complexity it's like 10 lines of code so um i think we'll just leave it in um and i sent an email a few weeks ago about splitting the draft so there's to remind you guys there's this load balancer thing where we encode the server id and a any connection id and then there's like this mostly unrelated thing about offloading retry to some sort of service or hardware thing or whatever um and uh that like is loosely under the theme of middlebox coordination but otherwise there's no really ship at all and so um i think there was pretty strong support on the list to um split those and i've already got a pr for that so unless somebody comes up to the mic and says this is um a terrible idea i'm probably going to push commit that um shortly after this and then like from an edit so there is again some more crypto review stuff to do but like the design is getting pretty close to being done i think what we really need is some interop and some deployment experience i think um i think google has the intent of deploying this in the near to mid-term i'll say um so that will at least give us some experience to try to manage handle all the configuration and all that i've gotten some bytes from infinate financial about their implementation so um maybe i i would have thought by now we'd have more servers that supported this but that seems not to have happened so if"
  },
  {
    "startTime": "00:44:00",
    "text": "you have a server implementation i'd really appreciate um some effort in this space but um i i don't think we're a mile away from from last call but it needs a little more maturation before we get there we have ecker in the queue please go ahead hi so yes i i am just catching up to speed on the uh um on the top on this document um uh i did read the inria review and it was quite concerning um i guess um you know i don't think we should invent our own version of ffx in this working group um and um so either we should remove that section or replace it with fx um but like it took a it took enormous long time to get ffx right um and and a lot of a lot of a lot of real photographers and so um i i i think we should like like i think i think it was like regrettable the center which we innovated um you know in uh um cryptographically um in doing um sql server encryption is about the limit of like what i'm willing to see i etf do without like a lot more computer review than we seem to have i mean the concern about f of x is 12 passes um which seems like a lot um cheaper but like i mean like um sorry i cut you off go ahead well so i mean like we have a zero pass option in this this design still where people don't encrypt at all so so it's it's um uh like this is not a well-formed idea right now but i'm thinking about possibly having some sort of um configuration option where like you kind of can turn the knob on on how well you're doing here in terms of like number of passes or something but that's i gotta go a couple rounds with christian and and the crypto review to figure out what we're doing there but i understand your concern yeah i mean i i guess just like like just like yeah i i think just just generally like"
  },
  {
    "startTime": "00:46:02",
    "text": "the the itf used to do this kind of thing and like used to life freelance a lot on the crypto um and um and like we've really moved towards having like you know as much as possible having validated crypto that we have like high confidence in and um and so like that so to not have that seems like a regression and if the answer if we can't solve this problem then we should throw up our hands and say we can't solve the problem and not and and and like wait for the photographers to solve it for us rather than um you know and uh mean and you know it is possible there's something that is that can tell this problem given the more limited design space than fpe um uh but i think for us to like write into post-standard document um something which we like like this little confidence in seems unfortunate okay i mean i'm certainly um i'm certainly open to the crafters like proposing something in the like sub 16 byte plain text space that um you know meets meets the meets the constraints that we have i'm not married to this particular way of working um and i understand the concerns i'm just uh this has not been forthcoming to at this point and i've not completely digested this latest review so so um i need to huddle with christian and figure out what we're gonna do about it perfect timing to ask christian to come to the microphone oh excellent yeah i mean i i'm i'm kind of i have a lot of sympathy for what echo said okay as in uh we should not invent stuff and uh i actually insisted to have these crypto reviews to make sure that we are not uh out of the deep end what is interesting is that one of the crypto review was really positive and it is unclear that the in-area attack"
  },
  {
    "startTime": "00:48:01",
    "text": "is actually important in the case that we have but we can we can check that i would much prefer to have something that is completely standard and yeah i mean if if we are okay with 12 passes let's do 12 passes but i i must say that we we will we have to discuss with you know folks to understand exactly what the implications are and if it is to say don't do that well we won't do it or we should not do it thank you christian i don't see anyone else in the queue you have one more slide martin do i okay sure but it's is on the i've already forgotten what no i forget this yeah yeah nobody cares about your documents that was good unless somebody cares about space in the documents we don't want to talk about that all right excellent thank you thank you which brings us on to the next gender item which is multibath yeah hello everybody um i'm elia cooleven i'm presenting for the also group here and i hope my authors will just jump into the queue anytime they want to say something and we go to the next slide yeah so multipass draft was adopted earlier this year and we submitted the zero zero version and the zero version had already a couple of editorial changes and clarifications and stuff compared to the individual draft um but no design changes i believe and then we submitted a new version just at the submission um deadline which also mainly"
  },
  {
    "startTime": "00:50:00",
    "text": "had editorial change but like to to a larger amount like we added some kind of overview section to make it easier to read we had a couple of clarifications about how to use or like what's the relation to existing transport parameters and there was some clarifications about timeouts and so on so this is technical stuff but it was clarification stuff missing and not like supposed to be any kind of new design changes or anything like that um yeah look at the div yourself if you want to know what the details are um so um let's let's jump into the open issues um next slide we have a bunch of open issues in github and these are not all of them but like they're also editorial ones and we also have a bunch of open issues sorry which are unmarked at kind of extension because in this draft we really try to focus on the bare minimum to some extent really what what's needed to make to set up new parts and manage new paths and so we have basically this six design issues which are currently open and i would like to quickly run through them and see if we can make any progress the biggest design issue is the last one here in the slide that's a big question about using one or multiple packet number spaces but if you look at the github issue we also made some progress there had some good discussion and maybe have a way forward so let's see where we are um yeah let's start okay this is an issue that has been around for a while as i just said when we when we took the existing multi-pass draft and and merged them into this draft we really tried to concentrate on the bare minimum and so this part was existent uh in at least the alibaba draft but we didn't take it over and the function we're talking about here is to indicate to the other end that one of the passes or multiple of the process actually should not be used at this point of time so you just keep them as a backup and that's a very"
  },
  {
    "startTime": "00:52:01",
    "text": "typical scenario you have like this hand hand-over scenario where you open one path on your wi-fi oneplus and your cellular and as long as you have good wi-fi connectivity you don't want to use a seller because it's more expensive but you're the client you have this knowledge you're requesting data from the server and the server doesn't know that so you want to tell the server don't use this pass as long as you have a different path that's the functionality and that is related to package scheduling and these kind of questions which we declared as out of scope for the space draft but this functionality seems to be very basic and very important and useful so the question really is do you want to add it back as i said it was there in the alibaba draft there was a frame called path status we don't have that frame anymore pass that is had like a lot of information not only this information but this was like one piece of the information in there and it's also a function that is part of multipath quick for example because there's a bit in multiples quick so when multi-pass quick sorry multi-pass tcp when multi-pass tcp was designed they also decided this is an important function they want to support it so any opinions should we re-edit there's no pr yet but like i think uh and we don't have to discuss about how we want to edit just like getting some feedback if people think it's useful yeah we have a few people joining the queue so uh spencer's up first i'll just let him get to the physical microphone yeah uh this this is spencer dawkins so um i think that this is really basic and i think that almost everybody that has a cell phone that has wi-fi connectivity we'll find that you know we'll find this late useful sooner or later"
  },
  {
    "startTime": "00:54:00",
    "text": "so i think this is i think this is really basic uh it could be a separate extension but i would expect that everybody would be negotiating the severed extinction so you know that's just kind of where i am i'm still thinking my way through kind of all of the different reasons why people do multipath but uh on this one it seems like you know it seems like um this is also something where i know something about my end that i want you to know and um that you can't guess you know you the server can't know that i had this preference and uh it seems like it's harder to do you know it's hard you know not having this will make things harder uh in the base protocol this is uh in the base multi-path extension uh but uh that would be my theory thank you thank you spencer tommy paulie please all right tommy pauly apple um so on this you know i think they're pr you probably could have other implicit ways to tell the server that i don't want to use this path yet by saying oh i haven't been actually sending anything from the client on this path you could do things like that but that would be relatively complicated um and you know i think a lot of the cases where we've seen multipath deployed so far at least in our experience is when you"
  },
  {
    "startTime": "00:56:01",
    "text": "have very specific applications that are using it where you have a lot of coordination between the client and the server but hopefully with multipath quick as quick is more and more ubiquitous on the web we're just going to start using this to random servers that we don't have that with so i think having something explicit would be very very useful here just to avoid some of the cost cases the fact that there is something equivalent within mptcp i think is a very strong argument for saying we should have at least parity with it and i don't think we should necessarily go beyond it and so i would encourage us to stay minimal and not add a huge uh bunch of complexity or too much extensibility right now there just you know use whatever the simplest uh bit we need to send but let's do something to at least maintain parity with mptcp yeah if i remember correctly this um mp prior option was designed to be extendable and and provide more features but at the end they only um specified this one bit in this initial version so yeah uh jun fay please proceed uh hello this is unfair from alibaba i want to add some more information so actually in some of our applications we already see users complain that we use too much of the cellular data so i think the cost is a one of the very important factor that ultimately affects user experience so that's why we think it is actually important for us to have some explicit way to for example if we see the data is consumed a lot on one path and we can explicitly send a signal to set up setup path as standby so i actually agree with what mira just said i think it's important to have this functionality"
  },
  {
    "startTime": "00:58:03",
    "text": "thank you marcus in the room marcus armando telekom as you know mia i already participated in the discussion at github and i fully support this idea the only question i have is one bit enough at the end or do we need more bits um in the multi-pass dccp i will present on on friday during the tsvwt slot i will present that we spend for mprio option four bits so we have multiple levels of prioritization for paths so maybe that is something which could be also considerate here yeah as i said there's no pr and no pr yet so we will propose a solution uh i hear definite agreement that we want at least this one bit so let's see where we go thank you thanks and then hang on one more person sorry the advanced feature regarding to the scheduling you basically signal the scheduling preference of your pass it's not a zero one decision it's actually you can signal uh how much traffic you want to go to a specific test so i think it should leave out the base drop it should be put into another extension drop yeah i think that's maybe a little bit of a separate or like yeah that's a functionality you might want to use it well at some point but if it has to be part of the base back is a is a different question let's wait for the pr and then have some more discussion cool thanks yeah then next issue yeah so um this issue is also easy um in rfc 9000 only the clients can migrate and there are good"
  },
  {
    "startTime": "01:00:01",
    "text": "reasons for it because it makes the whole thing much simpler and that's also the main use case however if i'm right and i might be wrong i believe the reasons for having this restriction is not valid for multipath anymore because in a multipass case you're not closing the old path you're just open opening a second press so if the second pass fails to some extent you still have the old one so i don't i didn't find a good reason to actually keep this restriction um it's a change to it would be a change to what the base version one spec says and we try to keep those changes minimal but if we don't have a good reason restricting um the multi-pass functionality in a way that doesn't allow for certain use cases this doesn't seem to be useful for me so i wanted to have some feedback if people think this restriction is still useful or if people are open to actually release that restriction we have like we've got a few people joining the key so mike please go ahead so the issue here is not so much that you don't want the server to open new paths as that with nat the server opening the new path will usually not be useful if it sends the first packet so what i had envisioned for server initiated paths was basically a frame that looks a lot like the server preferred address transport parameter where the server asks the client please try to reach me on this ip address and then the server and the client is the one who sends the first packet to open things up with an app so i think if you want it to work in most situations you need a little bit more machinery and not just removing the restriction and you can remove the restriction and it just won't work most of the time so yeah that i totally agree but i think that would actually be an extension that"
  },
  {
    "startTime": "01:02:01",
    "text": "we kind of didn't consider of of the space functionality and the point is if the server tries to open a path and you fail then you know nothing happened you just fail in in the multi-pass case because you still have the old pass so um yes you know in many scenarios it might not be useful but there might be use cases where it's useful and it's just like not necessary to have this restriction from my point of view thanks mike martin please yes uh martin zeman protocollabs i would like to point out that having server initiated path would be really nice in the peer-to-peer use case as it makes the protocol more symmetric short and sweet eric uh i guess i would um i mean i'm sort of not not approached that necessarily but like my assumption would be in the peer-to-peer use case you're using ice anyway or something like it and therefore like um and of course the situation went different like are we ever going to use are we ever any i mean are we ever going to do quick multi-path like i mean there's a peer-to-peer case where you like just like randomly probe new powers with quick rather than with lice i don't know isis for recovering right you might still want to open the pass for some reason from the server side uh i mean i mean realistically no real realistically like um uh realistically you like need ice to like punch the holes in the nets and do all kinds of other crap like like that's why that's why i like that's why like all the any anybody passed off and like whatever did you live above ice i mean yeah so i think in the net as we discussed in that case it's not useful and that's like a very common case the cases i have in my head are more like these kind of mask proxy cases where you was in like one network and you want to use it right again i'm not i'm not opposed to this this change what i'm saying is that i don't believe in the peer-to-peer case"
  },
  {
    "startTime": "01:04:00",
    "text": "it will actually be functional yeah okay so uh hi brian trammell google uh i basically came up to this or put myself in the queue to say something very much like what mike bishop said i i think what i'm hearing is the right way to do this is to release the restriction but maybe add some language here that says by the way this is only going to work here and point to future extensions because i think the the server address thing that that mike was talking about is super useful and i'd like to see that extension maybe follow very closely on the heels of this i think it's it's um and like releasing this restriction in the initial multipath extension sort of points in that direction but i think you need to be very explicit about what the what this is going to get you in the base case and then point to future work to actually so like you need the like exercise or on the ice stuff uh and then uh very excited about mike's um server preferred address so thanks mike please go ahead okay i'm still on the view i'll get down now oh sorry okay eric please details details so i would be fairly hesitant to release this in the multipath extension um i joined the queue just to say that at the time when we were doing client initiated migration in the original quick spec there were an awful lot of fairly thorny problems that we were able to punt on by saying that the server can't do this and so i think just my initial reaction to this slide was like oh yeah sure like you know try to open a new path it'll be fine if it doesn't work nobody's upset um but it might be worth going back and digging up some of those discussions because there were a lot of fairly painful things and so i think my personal preference would be to keep the restriction here and it have a completely separate document that opens that up like personally i think it would be super useful i'd love to see that for peer-to-peer use cases"
  },
  {
    "startTime": "01:06:00",
    "text": "but it seems like that would be best as a different document that can then spend lots of time and focus on those issues as opposed to being an afterthought in this document which has its own issues to deal with so this is exactly the point um like i know we had like a whole lot of discussions but like my memory wasn't good enough to figure out what we discussed and so i tried to to read the draft and figure out what the restriction was and i think the main restriction was exactly these net use cases and the risk of failure and i don't think that's a reason to keep it here in multiples so if there have been more reasons and somebody remembers better what the discussion was or maybe have to dig through github or whatever um then then we should pick them out and we should discuss them but i didn't find any other reasons and if we don't have a good reason then like i don't want to keep this restriction but like if you if you if you remember better than i do then just send an email to the list or to me that would be helpful spencer uh this is spencer dawkins um if i was understanding what eric was suggesting and i'm asking both eric and maria would would it be possible for this extension draft to be silent about this and we could have the conversation about what what could happen in the base quick protocol is that is that kind of what eric was suggesting i'm i'm sorry i'm not sure what you're suggesting yeah well i i'm also kind of asking your understanding of what you know given that input what would you do next yeah i think we we just need a little bit more discussion and dig into like this old discussion okay okay uh um yeah okay and i hope eric can help with that yeah i i i thank thank you for thank you for presenting this particular issue"
  },
  {
    "startTime": "01:08:01",
    "text": "okay i think eric's a hangover from when he joined before uh let's go to janna now please yes i'm waiting okay i think i'm in um so the one um one thing i might note is that simply removing the restriction doesn't really tell us much about what the problems might be it's about what you want to do after that so i would say that if there is a design about what is going to happen it's going to be a lot more concrete in terms of an analysis of the problems that might happen with a new mechanism that the server uses i'd say sure go ahead remove the restriction but let's see what exactly i mean whatever it is that we end up doing from the server in terms of initiating new paths and so on and so forth will make it more interesting uh for us to understand the the interactions with various things and as eric was pointing out there were a lot of little corners which we walked down uh when we were doing the client initiated uh migrations and be interesting to go down those paths again once you have a mechanism here to speak of yeah i agree um but it sounds like people are interested to actually have that discussion so that's good thanks christian yeah uh we we have had that discussion a number of times in the author's list and on github and i i really disagree with miria on that one where i come from is that the multibus option has been designed to be as compatible as possible with the existing quick v1 and if we do a departure from the quick v1 restriction that we only start from the client"
  },
  {
    "startTime": "01:10:01",
    "text": "that departure as a cascade of implication an example would be for example who validates the pass right now we have to pass validation by saying the server can only use it if the client sends non password editing packet on it on the pass there are restrictions like that and i really really believe that it's better to leave this server initiated thing to a separate draft that fully discusses it yeah i mean um as you said we're disagreeing a little bit here um because we do change things in the in the base back right and we we ask we to keep it minimal but if there's no good reason to keep it then we should remove it and there is at least one good reason there is at least one good reason which is the validation of the past by the client sending traffic yeah but i think this this is just symmetric in that case so i don't think it no it is not it is not it is not symmetric it is not symmetric the server must not send data before the client has sent non-validating packets on the pass so you're saying um even if the server opens the connection we still need the restriction that first the client needs to send data yeah and and basically if you don't do that cascade of thing it doesn't work i really wish we dropped that issue for now and we punt it to an explicit extension that that's what mike said which is like bishop which is basically to exchange the address et cetera et cetera do the full shebang don't don't do this one tiny thing on the side and don't hide it in the main draft okay i mean it's noted um as i said i think we disagree because i think this"
  },
  {
    "startTime": "01:12:00",
    "text": "is a smaller change than you believe and maybe you should figure out how big the change actually is to figure out a way forward no it's not it's the principle i mean in principle we should not do small changes like that okay let's uh let's get harold in the room to speak thanks chris harold john speaking in from the webrtc experience where we have peer-to-peer we have client server we have different reasons for opening new channels we have failover anything that restricts failover is a pain in the posterior but this actually is server initiated is a useful tool in more places than multipath so i think the right way forward is to initiate action on server initiated channels independently and make sure that you don't block multipath for using from using it when it's available so two different things because it's more useful than just multipath yeah i think the conclusion is still believe it open the issue but we might don't prioritize it okay um quick time check we have about 10 15 minutes left okay so however you'd like to use that what's the next issue okay um so i just i just note this i don't think we haven't have to discussion right now um this is an open issue we have um where there was a proposal to also have some kind of effectively zero rtt behavior for new passes because currently when you open a new path you"
  },
  {
    "startTime": "01:14:00",
    "text": "have pass validation so it takes a whole round trip time until you can send data on the new path and the question was do we want to make more than that but i would just like point you at the github issue at this point there's no pr yet and we need further discussion there we have three people in the queue um please please keep it short janme please everyone this is yummy from alibaba for this issue we can include some token mechanisms to help endpoints validate the appeals address quickly and surely this will bring complexity for creating new passes and we need to consider the security problems very carefully so at first we want to make sure that whether people need this or not um because in quick we want the points must to pass validation first before sending non-profit package during migration so if people want this we want to to hear your voice here thanks brian uh hi brian trammell google i i would just point out that a answer to this question what i think caused the previous discussion to collapse into one of its two states so maybe spending a little bit more time on this not right now but revisiting the multipath server restriction removal after there's an answer here because i think that might actually make the the path validation restriction removal on server initiated paths easier thank you and eric there we go i would actually question why we would need this unless there's a concern around sending data on multiple paths within the first round trip of the connection because i think the idea was that other than in that case you should"
  },
  {
    "startTime": "01:16:00",
    "text": "always be able to have a valid path by the time you need to actually send anything on it and so it would be really good to have kind of a clear picture of what the exact use case is where opening this this box is is necessary at all yep um yeah i think this is maybe an action item for yanmai if you can add more information to the github issue that would be helpful next actually can we take the next one first that's okay um so that is a discussion that came up when we tried to clarify how the idle timeout worked um and currently what we're saying is that like you have this idle max idle timeout parameter and you just use it for all paths but given the passes might be very different or you might use them in a very different way it could be useful to actually have different timeouts on different passes and you might want to actually um you can also just like do that locally and it will not totally break but it might be useful to actually sing all this information to the other end so um discussion so far was basically um we had some people saying yes this is helpful because it's more explicit and it makes it easier to close your passes at a at a valid point of time and then there was also an argument about no this doesn't give you much and it's just too complicated so more input would be nice at the github issue or a quick comment if you have anything here i think more discussion is needed at the github issue so no queue let's go back to the previous issue okay okay and that's an issue which is actually related to the packet number um space question because that's only an issue that exists if we use single packet number spaces on our paths so if we decide to use multiple packet numbers spaces this issue just goes away um and we also we have a pr for this so maybe this is straightforward but some"
  },
  {
    "startTime": "01:18:01",
    "text": "feedback would be useful so the problem is if you have a single packet number space and you send an acknowledgement and you provide and you acknowledge packets in the same frame that have been sent or received over different passes and one of those packets carried an ecn marking you cannot as the receiver of the act you cannot distinguish anymore which pass the ecn marking was on because the ecn feedback in quick is just like a counter so the counter increased but you don't know which path so we need to address this issue it's an open problem um and there and like what the current text proposes is like three things it's a recommendation for the sender of the acknowledgement to actually separate if you if the ecn marking increases if ecn is used and you see a marking then try to separate your ex you can you can always always just acknowledge packets of one pass in one egg that's a loud and quick it might increase your exercise quite a bit but it gives the receiver of the egg the information it needs to figure out where the congestion was that's just a recommendation if the sender of the egg doesn't follow this recommendation and you when you receive such an egg where it's ambitious and where it's not clear where the congestion happened you have to assume the most conservative case which is like the congestion might happen any path and you should react to it on all paths that's what the pr says right now the other option is always to just disable ecn support and so if you received such an acknowledgement you can decide at this point to disable or of course you can just like whenever you use single packet number spaces you just don't use ecn at all that's like the easiest solution but would make me sad actually um so that's the pr um and i don't know there was a bit of discussion with christian i think but i believe this is mostly ready to merge if people agree to these recommendations"
  },
  {
    "startTime": "01:20:02",
    "text": "gary just joined the queue so gary doesn't agree or disagree and hasn't read so the implications i will read and i'll look at it i don't like the last option that don't use ecn or break ecm by just making everything a lowest common denominator seems like the wrong way to go at this stage so um i agree okay happily read it and happily give comment okay okay um yeah then let's move to the big issue actually one more yeah so um the the big thing that we need to resolve in this group is really do we want to use single packet number spaces on all paths or use separate packet number spaces on each path um and like we had this discussion already before we adopted the draft and we kind of in a stage where at the current draft actually describes both options in the hope that people would implement both or one of the options we get some more experience with it um so this is a little bit the analysis about what's the pro and cons and i quickly will run through it but then also talk about the pr that we have there right now and like christian or anybody of the other authors feel free to jump in the queue anytime and just um add stuff so from an efficiency point of view the multipack and multiple packet number space solution is more efficient because you can just reuse the existing loss recovery logic and everything is like clear and easy um but effectively what the implementation experience showed so far is that the single number packet space if you like do a little bit of an additional effort is like from the performance point of view nearly similar efficient so that's like not the big point to distinguish things here code complexity is something we discussed a lot because initially we thought like having a single number package space means actually less code changes while having multiple packet number spaces really adds like a complete new code path and if you don't use that"
  },
  {
    "startTime": "01:22:00",
    "text": "feature it might not be used very often so that was a concern but to actually have a good performance with a single packet number space solution you have to be really smart about how to to send your packets in order to keep the exercise small in order um to have efficient recovery mechanism and so on and having the smartness in there is additional code and it's additional logic and it's probably also additional logic that we don't just want to leave to the implementation but specify in the draft to some extent because otherwise people will implement this and just get bad performance and will not like it so we have to give a advice about it and its additional code and so you know the big difference here is like the third point it's the egg handling um where like multi-part the multi-packet number space solution we add a new acknowledgement for and you can really distinguish which packet was sent and in which path and everything and ecn information is clear we don't have the problem that i was just like talking about before and in the single packet number space solution you really have to add some logic to make sure um that like your x don't increase because if you have two passes with very different delay you see x you see holes in your egg uh in your x space and that can increase the x a lot so you have to be smart about how you send your packets how to distribute the packet numbers and how you create your ex um and yeah so you know like as i said i think the code complexity is like not the big point here anymore because they are kind of trade-offs but what's still a big difference is that use of no connection id on both ends is not supported with multiple packet number spaces effectively the multiple packet number spaces need some kind of identifier in the packet to figure out where your packet belongs in order to decode it so you need a connect connection id and that's really the big difference next slide yeah so we did discussed about a lot"
  },
  {
    "startTime": "01:24:00",
    "text": "about like how you can enable this use cases also for multiple packet number spaces and there are some ways to actually handle this if you only have like one connection id in one direction um it might not like it might be a little bit fragile or like um not easy and some fiddling that there are possibilities but like this table mainly just tells you that um you at least lead like our conclusion is you at least need one congestion one connection id in one direction with multiple packet number spaces brian in the key so thanks a lot for both of these tables that makes this issue a lot easier to understand um i would say on the previous um on the previous slide uh you'd said that the the code complexity is kind of a trade-off you have to choose one or the other i would point out that in the single pn space in order to be performant you need an entire set of special cases whereas in the multiple pn space you just need a new abstraction where you might not have had one right like so you already have a loss recovery algorithm instance maybe you didn't split it out in the right way and we're forcing you to do that that does seem to be like a very green yellow to me so i do think that the the the code complexity on the single pn space if you're trying to do a performance seems to me to be a negative on that side than the other one it's like basically do we want to force people to do more more code complexity with respect to like a completely separate code path as opposed to an instance of an existing code path versus the zeroing cid problem i mean i just use three colors here right so but i think like it's what i want to say here we call complexity it seems like to be like the big argument at the beginning yeah but right now yeah because it really okay good so i think i'm just restating your point thanks okay thanks thanks brian uh martin thompson"
  },
  {
    "startTime": "01:26:01",
    "text": "yes okay so um i think perhaps there's a code complexity piece that you haven't um gotten on the multiple p n spaces side here which is the key schedule if you're going to be using multiple packet number spaces you can do separate key derivation for the different spaces otherwise you will have knots reuse so um i guess that's probably just another version of the saying that same thing which is you need multiple instantiations but it does change the way that you um even start using a single path in that case which is a little awkward so i if i remember correctly it was actually a point about so in in if you if you decrypt your packet in a multiple packet number space you have to use the nons and the connection id so that will actually change your decryption logic with which was like one of the negative points here um right that's all thanks martin christine i i have been we have been discussing that for quite some time and uh the um the point that the master that miriah is making there on the additional code is really based on the implementation experience in my implementation and and yes you do need the additional code if you want to uh to do that that additional code is actually on a common path you can use it in the in the unique past but it has the advantage of dealing very well with things like the size of hack in general and with the the issue of um out of order delivery in general because out of order delivery also messes the size of hack and if you you were to see that you would see that for example"
  },
  {
    "startTime": "01:28:01",
    "text": "if the network was doing equal pass multi-path that will be it'd be useful as well so in my implementation that logic which was added is in the in the main pass it's not some kind of things crafted on the side the uh one one thing i would point out in the proposed solution that we have is that actually christian um as you're here should we just move on to slides up and you want to talk about this yes yes let's move there yeah you want to take it or should i yeah yeah i can i can take it i mean basically because i i i look at the problem and i say okay we mostly have an issue with uh no with zero length connection id if we if we were not using zero lens connection id we'll just use multiple number space and yes it's a bit awkward i mean we have to do some changes on the interface to the um to the encryption but that's not too bad i mean it's it's something you do once and it's done it's easy to test now if you want to support multiple connection ids you end up with two pack of complexity you have one pack of complexity on the receiver side i mean if as a receiver i decide to say hey i am going to receive another connection id and i am going to also support the server when using multipass when using multiple paths then by doing that the the you are forcing yourself to uh implement all the arc logic for multiples i mean basically make sure to not sending too many hugs making them"
  },
  {
    "startTime": "01:30:02",
    "text": "so what i like about that is that it is an optional complexity an application can choose to either use zero lens connection id and do the complexity or not use zero lens connection id and then don't have the complexity so that that's something which is on the on the x side which is very well optional and i think that we have something a bit similar on the server side here i mean on the on the side of the the node that is not using zero lens connection id but speaks to a node that is in that case the complexity is on the sun path i mean how do you manage multiple links how do you manage to do that and and in the loss recovery logic mostly that loss recovery logic only engages when the sender actually sends on multiple paths at the same time so it's again optional we can have a sender that basically says yeah i mean i'm going to do multipass i assume that my peer will have a full length connection id if they don't i will do a fall back and i'll say i don't want to buy that complexity we'll just send mostly on one bus that that works so basically i think that if we take that approach we get to a solution where the complexity on either side is optional if you want to have the feature of the orleans connection id you have an additional complexity but i mean things are well defined and and you don't get the complexity if you don't"
  },
  {
    "startTime": "01:32:00",
    "text": "want that video so that's the spirit of the unified proposal let's say make the complexity optional and if people want to have the the benefits of using short connection ideas are not null connection ids then by the complexity and get the feature thanks christian we're we're at time for this session all together and i appreciate we've got some people in the queue but um we're seeing good interest in this topic um so i think we'll need to take it offline and follow up you can take the clue [Music] corey could you be quick you do you need to respond to anything or could we just take this offline gary would like to talk more about the act situation but you do it online off after the meeting thanks that's appreciated i would really like to figure out if my co-authors want to add anything janmay is there anything briefly you would like to add to support the effort for the unified proposal on last page for three reasons first the solution takes advantage from both single pn space and multiple viewing spaces as for most implementations which use long connection ids it could take the best efficiency of ack ranges with multiple opinion space and for implementations which use non-connection id they could support mod pass with single pin space we don't have to worry about choosing from a or b we just take the best of both and the second point is that for implementations we just have one single solution for each situation it surely would reduce complexity and the last point is that we don't have the risk of failure for interrupt tests and this will probably happen in the previous version if two endpoints choose to support different p and space solutions in the unified version we don't have this"
  },
  {
    "startTime": "01:34:01",
    "text": "problem because the id in pakistan or distinguishes the situations that's why i strongly support support the unified co-host as an individual thank you okay thank you um yes so the the pr here probably needs some editorial work still uh so don't get confused by that but other than that i think we uh have a way proposed way forward and like if more people want to implement and provide feedback that would be very useful cool thank you right thanks mira next up we have robin to talk about q log thank you we can hear you we're just granting you a slide deck control we can see this in the room are you okay yep it should be fine all right morning everyone welcome to the superman update for q log um so called because for all three of our uh existing documents this last update we basically went from clark kent to cal-el um meaning that internally they're still pretty much the same person they have the same superpowers they just look quite differently on the um outside and that is my way of saying that we did mostly editorial changes in this past update but of a very specific kind as you might know one of the main things that qlogs does is define different types of events that you can log for the different protocols so and the event fields that you need to log in the types of the data that is in those fields and to define what that should all be up until now we had been using a typescript alike dialect mainly because at the beginning when i started q log i didn't know about any better options since last time we know about something called cddl the concise data definition language"
  },
  {
    "startTime": "01:36:01",
    "text": "which is a much better fit for this and also an official itf standard so that's basically what this update was we switched from typescript to cddl and as you can see from the examples here on top it's actually relatively trivial for most things it's mostly a little bit of syntax that changes string is now called text and number is called uint and the question mark is for an optional field is before the field instead of after things like that right so it should be relatively simple even for people not very experience with cdl to understand most of uh of the new syntax however cdl does bring us quite a few extra opportunities to make things better for example our q log events are generally described as very flexible you can add any new fields if that's needed in your personal implementation and tools are expected to handle that now in the previous definitions we kind of indicated that with as you can see a comment right hoping that people would do the right thing but in cddl there's actually an official syntax for doing that indicating here that you can have any number of text fields so key value pairs where the key is a string that's the asterisk text and the value can be then any value that you may want so that's a that's a much cleaner way of doing this and cdl's other interesting options for example um one of the things that are in the quakecraft is that you can have tls level alert errors and they map onto quick level errors but we didn't want to make a new uh text string enum entry for each and each of them individually so originally in typescript we had like this very non-official syntax for doing that while with cddl we can actually use the regex"
  },
  {
    "startTime": "01:38:00",
    "text": "operator and defined as a little bit more clearly what type of uh string we're expecting there for that kind of error another thing that we can use is the unwrap operator so we have quite a few events that actually share quite a few fields think about you know the difference between a pack and the scent and a packet received the packet remains a packet um previously we may mostly manually copy to the fields and sometimes you know if you forget to change uh or to keep these changes consistent with cddl editorially it's very simple you have this unwrap operator the squiggly line where you just have the common fields in one part and then you can just unwrap them at the location that you need them basically meaning you just copy paste the fields to where you uh where you want to reuse them basically so that's mostly editorial but the main thing that i was really happy with with cddl is the ability to be a bit more specific about extension points um ctl is a feature called sockets or plugs which are indicated here with the dollar sign as you can see where the idea is that it's kind of like a a partial type so you define the type so in this case the protocol event body that's defined partially at one place and then you can extend the same type with new possible definitions in a different place and in practice for qlog this is very useful because we have what we call the main schema so that is like the main document describing all the high level stuff for example what is a generic event look like as you can see on top but then we have sub documents that describe the different events for in this case hp3 and quick and you kind of want to properly link up those two definitions across the different documents that we have and that was very difficult i found in typescript there we just again had the data for an"
  },
  {
    "startTime": "01:40:01",
    "text": "event was anything it could even be just a number or a string not very well types well here the approach we're taking now is that you have a very very clear listing of all the different events in for example the acp tree document and then you can say these belong to the protocol event body partial type that is defined in the main schema and so you can do a proper checking uh in in tooling for example as i'll get to soon if if you're actually using these things correctly as they are defined in the specs right um those are like the main things there are a lot of smaller things um for example we have the size operator meaning we can be a bit more precise about how large certain fields need to be that's not super useful for json but let's imagine someone wants to make a binary serialization of q log down the line it's good to have these things defined up front there's also one thing that i am planning to do it's not in there yet but for example adding some metadata to the events as well one concrete example is that we have the notion of event importance so not all events are as important as the others and you shouldn't be logging all the events all the time because that would be way too much logs and so we have the concept of core events most important than base and then extra that you can have for debugging purposes these again these indications are done in like a pros way in the current drafts but cdl will allow us to have this inside of the actual definition as well which i think would be useful for a variety of reasons next to those things we did a big consistency update of all of this across the different documents we properly named all the code blocks we properly split up examples and that kind of stuff to make things a bit more tidy but so that was like the main thing that we did in this in this update and i wanted to get back a little bit to why we did this um first"
  },
  {
    "startTime": "01:42:03",
    "text": "of all we now have cddl which is a iutf standard is an existing rfc which is better than having not an rfc but in my mind much more importantly is this this will help us with having some automated tooling some powerful automated tooling down the line what we did for these drafts is already have some basic tools that basically extract the cdl from the markdown documents and combine them into a single cdl file which we can then validate using existing cgl tooling to make sure that we haven't forgotten anything or that our type interferences are are consistent and that kind of stuff and then we've also been using this to generate dummy uh json files so that we can actually check you know is is our is our q log is our cdl definition actually correct um is it representing what we want it to represent so that's what we have and then we hope to go for even more complex things which are here in red which is for example generating other representations of the same schema so for example let's say you have you want to implement a q log library and for some reason you want to have each of the events as a separate class or substruct right now you would have to do that manually which again is annoying to keep things consistent with this you might be able to generate this automatically down the line another very useful use case is automatically validation of actual q log json files so i imagine this that you just upload a q log to for example qvis and then it can tell you okay this field is actually required and you're not logging it or you are you have a typo in this kind of field which we've seen happen in the wild a couple of times um all of these things i think will be useful not as much for existing implementations but especially for newer ones or the ones that still need to update to the newer versions but especially as we look to extend q log beyond what we have now again i'm we're still not sure if we're"
  },
  {
    "startTime": "01:44:01",
    "text": "going to look for tcp or anything but i think it's at least i have concrete plans to start working on some q log things for web transport for mask for multi-path um down the line and i think having this kind of proper tooling and validation in place will make that process a lot easier for everyone trying to implement this down the line right so that's what we did why we did it now what we want to do by next atf is mostly more editorial stuff so a lot of the pros was written during draft 23 24 and so a lot of things has been updated since a good example of that is the qbank drafts right where we have renamed http headers to http fields which are of course carried in the new http3 fields frame right and some other pros updates another thing that we plan to do is adding a couple additional events and fields that we don't have now things that allow you to log on which cpu or tread for example things were happening but especially also again for qpack we currently have very obtuse um events i think that could be a bit more high level bit more usable for people because i don't think anyone has ever actually implemented the current queue back events which i think is a clear indicator they're kind of missing their goal so we really want to get on that for the next step most of these i think we can do ourselves but especially for qpack i don't think we have to the necessary expertise um within the editors and so we are looking for as you can see on the right our own lowest lane or maybe in this case a louis lane to come help us out with that i created an issue for that number 199 if you're interested so that's things we can mostly do ourselves and think we have a grasp on but there are a couple of open issues"
  },
  {
    "startTime": "01:46:00",
    "text": "that i wanted to bring here now that will need to be resolved before we move to rfc of course one of the ideas is split up the main scheme even further to remove especially operational concerns there for example we have an environment fire variable that you should set as a implementation where the queue log should end up we also have a well-known endpoint that nobody's actually using at the time so maybe we shouldn't even have that so the question is do we keep that in the main or do we even need to specify that at all right then there are a lot of discussions about versioning and extensibility we have clearly said that we will not take this into too much account right not try to already estimate how things would work for tcp and stuff down the line but we still need to have a few extension points and idea how to handle different versions of the main schema versus versions of the protocol events and that kind of stuff we have a couple of i think proposals for everything but something so people with an interest in that might look at these issues there as well but the main thing for me which i keep bringing up i think in every keylog target did and i still haven't had anyone really give much feedback on this is around security and privacy right how do we handle that within q log the more i uh try to find a business the more it's it's i think or at least i'm a very bad searcher it appears that this is an unsolved problem or at least an unspecified or unstandardized problem that most companies just do what makes sense for them internally and they do it in an ad hoc fashion and there are no existing documents that you can refer to as you should follow these specific guidelines and if that is indeed the case then i wonder if this is something we should be doing in q log because it seems like a very big undertaking a very important undertaking as well"
  },
  {
    "startTime": "01:48:00",
    "text": "but something that would very much delay qrock lock itself right so either i'm looking for people to tell us these are the best practice documents you can refer to or people to tell us what is like the i wouldn't say the absolute minimum that we have to do to make this good with q log to make it appropriate but at least give us a way forward in what should be specified in q log before we can get to rfc so that we can start working on this as soon as possible that's it thanks thank you very much robin um you know just just as a independent perspective the the cdl work was good and those pr's if anyone didn't see were quite big um so the the efforts are appreciated and that does really unblock us um on on progressing these other issues that uh are both big and small um but i think if people would like to contribute it would be um really appreciated it it might be just something simple to buy off and knock off got a few people in the queue uh brian first i'm going to close the cube just so that we can keep the pace going but uh so yeah uh tldr robin uh let's schedule a little bit of time offline to talk about the security and privacy stuff i'm willing to help on that i think you've properly identified that this is a gigantic can of worms uh we semi tackled some of these things in the ipfix and peace psamp working groups about 10 to 15 years ago so there might be some prior art there that we can draw from but um let's follow up on that offline thanks brian eric kicking in all right uh yeah i would say for the security and privacy side of things i would advocate for per field indicators in addition to whatever other guys are going to give um like big plus one let's chat with brian and you know figure out how we tackle the kind of"
  },
  {
    "startTime": "01:50:00",
    "text": "high level concepts but something that we've found uh internally for a variety of things that get spit out by different implementations of of various things at least within apple platforms is that it is extremely helpful to have kind of a very local indication of hey you're in the middle of writing some random code somewhere and you may not be thinking about the fact that somebody could use this to derive or understand x piece of information that could be considered private so yes please let's have some high-level guidance somewhere but i think having something that is in this document not somewhere else for potentially each field of hey you know we've thought of some random thing that you could combine this field with this other one and understand something about a person that you might not want or that they might not have been thinking of at the time when this was getting logged would probably be very helpful for people even if to say oh hey you should go read this other high level guidance somewhere else and would that be simply like this is a sensitive field or this is sensitive field and this is how you should encode it if you want to be privacy sensitive yeah probably something along those lines of even just a single field of like this is a totally fine field spit this out as much as you want separate from like hey by the way this is your like one of your main tls keys you probably shouldn't be logging this okay thanks thanks jonah i think i'm in um yeah i'll agree with uh what eric said i was up to i was i came up here to say that perfield indicators are very useful however i'm also going to caution um against going too deep down that rabbit hole this is uh there's a lot of local semantics attached to what data means"
  },
  {
    "startTime": "01:52:02",
    "text": "what um there's this value in indicating levels of sensitivity of of various bits of data protocol information because as eric was pointing out oftentimes the consumers of this information don't necessarily understand what how how pieces of information can be put together with other pieces of information but at the same time because you don't have global view of how exactly these traces are being used are they being used in a client side a single you know are they being used in in in in in tandem with other logs that are also existing you just don't know the scope of uh the total storage that we're talking about the total view that we're talking about it becomes tricky so i'll say that these should be considerations not rules um and that's appropriate i think it's definitely very useful to have perfect indicators but just be careful about um losing yourself in there it's not about making it perfect it's about giving much more information than what they would have without these indicators so uh with that robin thank you very much and goodbye and we'll go on to the last presentation of the day from nico we can see your slides but we can't see or hear you nicholas are you speaking we cannot hear you nicholas"
  },
  {
    "startTime": "01:54:11",
    "text": "corey could you maybe help support yeah how about i we'll see if nicholas can resolve his issues while you're leading hi i'm i'm going to read the mic hi i'm gory i'm not nicholas so if nicholas comes online he will carry on but i'm one of the people who worked on this along with christian and tom so um and stefan from orange so let's talk about um what this is about let's draft please next slide oh nicholas is in control yes go for it and we still have no audio okay right okay so the premise is that there are two pieces to this puzzle one of them is about remembering some of the transport parameters from a previous connection and using this to somehow initialize a new connection and we've been doing this with tcp in one way or another for a while and quicks different to tcp quick's probably best to tcp so can we do this explicitly is it possible to implement a way of caching and reusing the parameters and perhaps specify a bit of logic around it so christian very helpfully implemented some of this in pico click you can go to the url and download this and use it and we have been using it and testing it so the method does work we chose one use case because nicholas has a lot of experience with satcom and we got some real satcom links some simulated satcom links and we evaluated how this might help when you have a path that has a very large delay and perhaps a lot of"
  },
  {
    "startTime": "01:56:01",
    "text": "bandwidth but you don't initially know whether to use it so you do this usual slow start thing and it goes very slowly and you do this new thing and it can go very quickly which is what quick should do um they would say more about this data it's not my data and the thing is there's a link at the bottom so you can look at what the data looks like and look at the experiments that were done and read the bdp extension draft which is one of two drafts we know factored out so after talking about this for a few times at the ietf we're coming here with a bit more solidarity and what we're saying is we think this is actually two problem spaces what frames you might need in quick to actually do this what are the rules and guidance for doing this when you have that information or maybe you take a different approach but you still do the same thing so the first thing is why are we doing this why can't we just say well go whatever you like well of course we care about safety and we care that the network conditions might not be what you expect so most of the time they're going to be exactly what you expect exactly what you saw last time but if the ip address isn't the same maybe that's an indication you're not talking to the same endpoint if the rtt is significantly different that's a really good indication that your path characteristic isn't the same and you shouldn't be using the same congestion control parameters you were last time and of course what does the same mean if you measured it a year ago and you measure it now obviously it's stupid if you measured it a week ago a day ago an hour ago what's the lifetime of this information we don't have answers to that one by the way but we think we should have the other thing is"
  },
  {
    "startTime": "01:58:00",
    "text": "whatever you measure even in good faith you might have had the whole of the capacity available when you last did it someone else might have come in afterwards and you now don't have that full capacity available how do you prevent stamping on top of them as to having out new connections well it turns out that the overestimation you might get in using standard congestion control and the starvation of things probably could be avoided in most cases by not jumping to the full capacity you jump to a little bit be more conservative and importantly you get really out of that congestion when you see it maybe this is actually a reasonable way to operate maybe it's not far from things we've heard in ttpm recently with high start plus plus is there a problem with malicious clients could you have a client that actually just uses this information to try and blow up the path and make things worse for people well we look to this and we don't think that's a particular issue look at the draft so we have draft quick careful resume the idea is that we have one minute one side one one minute yeah okay [Music] it's about carefully resuming i have talked about carefully resuming and he's got safety guidelines in the next slide nicholas nicholas next oh options tremendous promises there's different ways to do this otherwise we won't be talking about it and we'd like to see this widely implemented by other people because that's what quick's about different implementations working together and we'd like to suggest one of these has been the recommended way to do it let's go for the next slide next slide nicholas these are the areas where you might get benefit and is there any interest can we make this a working group item can we"
  },
  {
    "startTime": "02:00:00",
    "text": "make one of the smoking group item will people actually help us make these into rfcs and that is the important question here so we've had um this topic on the as time permits bucket of quick and we've always run out of time for the last few sessions at least anyway um it would be really good to get an indication of people think this is something of interest to the working group maybe you know the shape the specific shape of it needs to be slightly different but um you know these folks have been working on things and i think you're looking for an indication should should you continue working on it or switch tracks to something else so i think you know we're at time we probably can't have that chat right now but um it'd be really helpful if if the group here and remote and on the list could give us an indication yes no rather than just crickets because we'll have to read that and interpret that in some way so thank you please get in touch with that we're at time we're going to get booted off in a minute i neglected to mention at the start of the session we have quick and hgb3 stickers at the front desk please come and get some because i have hundreds of them in my bag i don't want to take them all home but if you have friends or colleagues or whomever might have contributed or interested please take some back with them too and again thank you all very much for your time and patience can you can we mute this thing can we mute this thing um"
  },
  {
    "startTime": "02:02:05",
    "text": "you"
  }
]
