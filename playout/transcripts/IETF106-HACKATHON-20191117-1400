[
  {
    "startTime": "00:00:30",
    "text": "[Music] okay hey there\u0027s two o\u0027clock so we\u0027re just about to get started with the presentations is anyone still in the process of uploading your presentation okay so we have a few hands if you\u0027re able to upload it in like the next 30 seconds I\u0027m going to download everything that\u0027s there and we\u0027ll essentially run through everything that that\u0027s there at this time and then afterwards I\u0027ll go back and we can individually pick up ones that we missed or that God updated or something like that but just to try to speed it up I\u0027m going to pull everything now and we\u0027ll just run through it in order and plus that way you can kind of see where you are in the list and when your your slots coming up yes it\u0027s available yeah are you yeah okay are you are you ready maybe so I just I don\u0027t forget because you won\u0027t be in the list although I\u0027ll let you go if that works here why don\u0027t you why don\u0027t you go ahead and pull it up yep when it\u0027s loading it\u0027s it\u0027s a bit slow still okay at the moment okay I\u0027ll leave it there and I\u0027m just gonna make a couple of announcements so hopefully it\u0027s it\u0027s loaded with some time okay so so the way this is going to work is you "
  },
  {
    "startTime": "00:03:30",
    "text": "know we have that three minute time limit as I mentioned rod here will be keeping he\u0027ll be the timekeeper and he\u0027ll give you kind of a nice like sort of one-minute warning when you have only one minute and then he\u0027ll give you a less nice you know notification I guess when your time\u0027s up if you don\u0027t wrap up in like two or three seconds there\u0027ll be something even worse so everyone start clapping okay we can use that practice that sounds good so yeah please do mind your time and and realize we want to get through all these and we have a lot of presentations fortunately so okay so we\u0027ll get started the first one is not slides it\u0027s a website and turned over to you cool thank you this was not what I\u0027d planned to do in the geomap session today I\u0027m brawn this is topic box which is one of fast miles products that was built on top of jam app even before she I became a standard and it\u0027s a mailing list product so I\u0027ve slept in all of the ICF mailing lists see there\u0027s quite a lot of them here and showing what can be done with something like a powerful search searching for anything by me on any of the mailing lists over the years and we can scroll through here and see all the stuff I\u0027ve done on every ohdf mailing list and you can search for anyone in there over the entire corpus of gigabytes of mail and it\u0027s really really fast so this this is Sir J map as it can be used right now I\u0027ll send a link to this around once we\u0027re happy that it\u0027s a little bit more stable and everyone can have a play with it it slopes in in slightly less than real time because it\u0027s pulling from our map but this is what you can do with modern IMAP a modern email standards I\u0027m at replacement feel free to poke around in ITF topic box - scratch comm that\u0027s all I\u0027ve got you don\u0027t want me to search anything while we\u0027re here come along to this cool is next get back my okay so different than usual all just seems by default it put things in reverse alphabetical order so we\u0027re gonna go go backwards which maybe is a good way so so you I\u0027m just gonna go in order here so the first one\u0027s going to be Yang and then se e and so on so you kind of have an idea when your slot is up so yang mediator who\u0027s "
  },
  {
    "startTime": "00:06:32",
    "text": "presenting that one one other thing I should warn you to advance the slides use the left and right arrow as opposed to the up and down if you up and down it just kind of scrolls through the slides here\u0027s the description of our hex down this time and this time our hack song is about as a v6 weepy and young mediator next so here is our hack song plan we we have things when we when we developing the ietf service modeling and also the device model we we have facing this kind of problem here on the left hand side there\u0027s a the Sdn controller architecture like in a lot of deployment most as the in controllers needs to do like different vendor adapters to use different vendor native young to manage the whole network but we also have some service provider have other requirements from them like the they they have their requirements they don\u0027t want you like facing different vendor specific yum modeling so they thinking maybe they can use IETF native young to manage all the devices and a network and here\u0027s our proposal to this kind of problem so we are proposing to use a mediator as a as a solution to to migrate the vendors basically young to IETF young like in the right that right now like there\u0027s most vendors they don\u0027t have implemented IETF young right now but they can using the mediator as the "
  },
  {
    "startTime": "00:09:33",
    "text": "proxy to the ITF young modeling when managing the the whole network the sd1 controller in the network could could only use like idea as a basics or PGP SS to control the ho s a VPN services then when they\u0027re when most when right now at moment they can only use vendor specifically on to develop the SI basics function okay thanks so here is the topology and this is our hexam topology to to control the whole network and and here\u0027s our okay okay thank you here\u0027s our demo rego and will you be at the hack demo happy hour also okay oh no no worse so I think you\u0027re going to demo it at the hack demo happy hour to so that\u0027d be great if people want more info let\u0027s go back yep I believe you are if I can figure out how to navigate back to where I want to be here okay and yes a wonderful the wonderful world of Chromebooks okay so we did a bit of work on the SCE project today with some congestion experienced being a small extension to ECM that we\u0027ve been working on this year and this is covered by two drafts currently in the system and also related work in a new queuing algorithm which we hope will improve deployment we wanted to test some of the more challenging traffic scenarios according to RFC 503 3 I think and we just like to address some of the existing problems by revising aqm so the traffic scenarios we wanted to look at we\u0027re bursty links that are often associated with Wi-Fi these are typically problematic for high fidelity ecn schemes we first check verified that this affects SCE as well with the "
  },
  {
    "startTime": "00:12:33",
    "text": "original marking scheme we wanted to check bi-directional traffic on the asymmetric path as that\u0027s another challenging scenario and also competition between SE and non su traffic has has been based on the mailing list as a concern so starting with the last point first we know that in a single queue se enabled aqm se gives way with just plain ecn support in the aqm se competes fairly in backwards compatibility mode and with fair queuing SEO also competes fairly now we introduced nasty queueing to have minimal extra complexity over a plain FIFO and that helps and to adjust the bursty links on the path we changed the SE marking over to use caudal instead of a read play about algorithm and this turns out to have helped wrath of a lot increasing throughput from seven to forty megabits per second we weren\u0027t really able to do very much with the bi-directional traffic when out of time but we were able to make some progress with a key CN and SCE compatibility where with the help of Logan and Richard who like we\u0027ve added to the team list the work is mostly in our github repository and the link is in the slide thank you okay thank you very much and next up would be IP wave it looks like thank you okay okay hello this is a jump or jump from a sketchy you know this time IP working guru we demonstrate the IP of a wave ipv6 packet delivery over I go to the 11 OC be a mode so the custom plan you can see the packet a transmission over OC be Moses so pickle environment the case T SLC associate the wave of communication important to so we are used the commercial Wi-Fi a module working on 5.9 kike here at the SRC a friend also we are demonstrating opposing 16 neighbor discovery walk in to the allowable or CB mode also we can "
  },
  {
    "startTime": "00:15:34",
    "text": "demonstrate the video on the streaming service so to attract are relevant so what cut a ton and is a custom project so we fixed some compound error so the the Connor the comparation from the owner another University we tried to clear out the make file error or so we enable the PS atiyah up and also we enable the back camera driver so we can successfully a computer IP version 6 address and also UDP data delivery and also video there are delivery okay so this is a testing environment so we go over there we have a two or laptop computers we can insert the Ubuntu Linux and then we can enable the errors that nowadays call comm Wi-Fi module so we cannot successfully delivered so this is the video on the snapshot we unloaded a video on demonstration a clip or so we can unload it the menu for anybody who have interesting you can install intensity so this is the summary so we are learned so how to configure how to IP version 6 delivery on top of a commercial Wi-Fi learning 5.29 gigahertz ok also during this hackathon or we showed current the neighbor discovery I P wave is not a complete so I feel great working group we work on for our neighbor discovery to enable automatic illegal Opera Builder s also neighbor vicar recognition will be done in near future so we have a champion me and jung yong kim sun-shin university also post student ok also alliance ID that you can get a bit of clay and menu and also original contributor is check you know conquer University impossible thank you okay [Applause] okay next up we have a survey six mobile oh yeah sorry I didn\u0027t catch it this time but okay hello everyone this is Satoru presenting the IIT Hakkasan for its our basics mobile user praying I explained it a bit our Hawks on plan to simplify the mobile network its idea is describing this right it\u0027s a basic my buddies were praying while DMM working group so we "
  },
  {
    "startTime": "00:18:36",
    "text": "implement mobile user plan requirement into one single main layer which is si v6 i PB square it\u0027s our basics to be able to integrate mobile is a friend to the one to the underlying layers so what got down is here we achieve 5g aware mobile user brain function I\u0027m not sure whether you already aware or not the five deep pocket format and that\u0027s use opera implement on the EBP and p4 platform and now he\u0027s able to inter work with other sto protocol which is gtp you instead rest Mona so github repo is a better proof for your review and get you can get chrome and compare it to try that future in your local environment and the code has being submitted to be PPG eric to be debuts so one lady who is already verified by Jenkins so that\u0027ll be sure it\u0027s a runnable on your environment as well so what we run here Isaac the the BPP and a p4 is already jerrod platform to makes easy to implement new function to be extensible but we found another requirement to modularity for the platform to implement his a basic mobile function so that\u0027ll be a good feedback for the open source community and other things in the IE and my colleague walk home figure out a new functional idea to be implemented so this is wrap up our team member it\u0027s to see i\u0027m murakami if he who is your past time to join the Hakkasan and Kentaro i Basava have become a leader and Phil Berger we also have the skeptic code to de generate the SR basic oh no gtp you a 5g our pocket which is very new and this is the lack of the the point URL to show the people code which is also available on the idea of Hakkasan github library so please check out thank you okay so next up is a ECA and then after that we have PII great thank you my god sister Michael from hallway and in today wave huh concern is about to implement "
  },
  {
    "startTime": "00:21:37",
    "text": "one even condition action young day tomorrow and this is our hack plan we will we well find relatives and the possibility of the Union mother for our policy basically even amendment to implement and the test an event in easily folder location as of holding application in the network device and we also implement in test and the chain reaction of the coordinate the humans and here is a reference if you there are two rates our document appraiser a date and if you have some stressor in the comments they are welcomes and here is my use case and scenarios is a automatic detect if you don\u0027t have the possibility hunted module we need to do this work step by step and it rely on operators experience but now we have a Jungian module we can generalize a young instance and submitted to the at was ninety was implemented come rated to in person scraped and subscribe to the relative teacher and our sizes either if it meets the condition it will ask you some specified action to use as Detective works out some self-healing works and what we do you system away the wrapper on is a photo localization and the self held implication did not work device and to provide the out who are localization self-healing such as architect and here are way also to our one network with application to display that he was changing over time the last one is the young instance is a is a script general read by you say models and write one is a scenario eight shows that event appears and recover eight what will end okay we collected many useful comments and we know that yes you say young ml the yonder the mother can develop not an image to spot automatic photo localization and self Harry and also across many other use available use case such as mass filter and it is computing and we have a great member sentence their comments and contribution and also we will have shown our demo in tomorrow\u0027s happy hours and if you are interested in this topic it\u0027s just thank you okay so next up is PII and then after that we have I to NSF "
  },
  {
    "startTime": "00:24:46",
    "text": "hey folks Santosh I\u0027m part of crabs information security team so the topic is on okay so I\u0027m Santosh I\u0027m part of grabs information security team which is a right healing company based in Singapore I\u0027m sure quite a few of you would might might have used there were companies services to reach the venue from our hotel so the topic is on a personal information identification and logging so basically you know like in in today\u0027s world they might have several of the log sources could be that servers or any of the other applications that might be inadvertently logging PII data and this is one of the challenges that we face and you know like regular I know like my day-to-day job stuff so how do we effectively identify and take right actions on PII data it could be redaction masking encryption or trimming it out from privacy reasons as well as data and compliance reasons before we send this data out to any third-party processing could be external sock knock or you know like a vendor who is trying to debug your appliances right so you might want to sort of trim that out so the hackathon plan was to you know like identify the conventional methods of you know like how do they work when you want to sort of parse the logs conventional methods like largely regular expression based but not a lot of contextual data you know like as opposed to the proposal that we are putting on the table with respect to tagging the data at the source before it is sent out for any sort of processing or parsing and then probably put this logs out and lovely so this is a lot pipeline that we have you know like try it out as part of our proof of concept so you have a log source could be like engine eggs or any sort of sis cloak files or whatsoever and put it for PA a data detection under action is one of the use cases that we are tried and we can clearly see that you know like you probably would have a lot lower accuracy but the conventional methods especially the red one indicating at the bottom is showing the hash index which is actually matching with probably a national ID see Singapore\u0027s NR IC or something is what we were using that also gets redacted as part of this so yeah so what we have learnt is you know like a regular expression based detection will induce false positives in our logging analysis as opposed to tagging so this is what it is thank you [Applause] okay so I to NSF is next and then on deck is mud okay thank you Taurus well this is a poor jung-gu "
  },
  {
    "startTime": "00:27:47",
    "text": "so this is the tenth consecutive I to an SSR hackathon so over all three years we work for ohm I turn SF so previously we are demonstrated that the major interfaces such as registration to page consumer-facing and natasha key function MSF facing also we can demonstrate T the script avala generator so this time we want to demonstrate NSF the monitoring so this is not a complete yet as we are keep going for next year and comedy yeah so we use the open source especially comedy will be I used especially the notification picture will be used for monitoring okay so this is the cuss on project so we have so collaborator and also student and also the newcomer the two persons joined so the right side we have some information for this hackathon so this is the our eye tuna type of framework the left hand side our going to provide the intent of base descriptive surpise a right side we implemented using on table and actively and also Sdn technology based upon their light and also of the stack so this time we try to implement I turn SF a nap and I set up the monitoring so on waiting work so this is our basic are tracked okay so I am an editor for destruct we based on our castle experience we will revise this trap so we\u0027re under how to implement we got some direction of implementation or I turn except NSF prophase NSF yeah monitoring so this is the last piece of the arrow mode in our working group I think you okay so we have mud and then after mud will be BMP okay hi everybody so we had a slightly smaller table than we did last time this time we did some we were planning to do a little bit of a improvement on the mud visualizer we had we actually were going to do do a visualization of one particular device called yes SC comm recorder Brian showed up to implement mud and grasp and I was doing some debugging on an internal implementation and then our fault of the folks at c-calm have been looking to develop a model to use mud for to actually make devices accessible and in a scalable fashion such the device doesn\u0027t have to implement a lot of mechanism so a lot of "
  },
  {
    "startTime": "00:30:49",
    "text": "this got done turns out Brian didn\u0027t need to work too hard at this he got the initial work going in about 30 minutes we still have some signature work to do I\u0027ll talk about that savio from the Federal Institute Brazil built out some capabilities in the visualizer if you haven\u0027t seen the visualizer it\u0027s pretty cool you can actually visualize mud files and and see what sort of access of device we\u0027ll get I did my debugging I have more debugging to do we actually did test the device and we were able to visualize it and we did some we did some initial modifications for the mud manager for parsing the file extension this is a little view of Brian\u0027s work that he\u0027s done with grasp top UI he\u0027s not yet comfortable pushing this into a pip repository given that yeah we have a has a couple more things he wants to do and we really want to bind it to one of the open source mud manager implementations here\u0027s like an approval flow that I\u0027ve been working on such that one of the key things that we have for administer network administrator\u0027s we\u0027ve got to make it simple for them to understand what\u0027s on their network and have a simple approval flow this is what we were working on we learned a fair amount actually the first of which is that autonomic computing one of the things we said was that on and I\u0027m an autonomic competing needs to give some thought to ad-hoc authorization models in terms of what devices can talk we reinforce that mud is not meant for device configuration but network configuration did individual individual eyes device that it\u0027s not meant for device identity open source version and management is still a pain everybody still knows this and the Python API is really need a little bit of help regarding verification and CMS and here\u0027s the people who are involved there\u0027s an updated version of this presentation that has a nice picture and correct spelling in some places so thanks very much and see you in the next hackathon [Applause] okay so next up is OB MP and then after that we have a MB a and bi is that what that it was perfect hi everybody I\u0027m Thomas from the PGP manipur monitoring protocol the girl working group and what we did is said doing some interoperability testing between data collection and routers focusing on the alt monitoring and peer up peer down message types which we have from the BMP local area an adjacency hip out and we\u0027re using the newly via shock the MPD sector and the updated PMS ECT this is "
  },
  {
    "startTime": "00:33:51",
    "text": "our testing topology just three impalas PE routers and data collection below URL if you have VMP router which is implemented is tuned to new drafts you can access this website and send over the internet the BMP messages to us and I can have a look how they are look like we identified some gaps namely regarding local originated routes in the BMP local it it seems that RFC 42 71 doesn\u0027t really specify what the next stop activate attribute should look like we take that to the NGO working group another thing which we identified was regarding the pier up messages when in adjacency rip out pre and post policy configuration was applied depending on implementation either one or multiple messages were sent so and this ambiguity me meant some some hiccups on the on the data collection side and on the BMP d sector we take that as well to the working groups and see how other vendors implemented that and yeah the good thing was lab environment was working and the bad thing in the test took longer than expected so next time we\u0027re gonna do in 107 we want to improve our testing and also at now these additional three drafts which are building up on the current one which we test it this time thanks a lot and these are all hackathon new timers thanks okay fantastic okay MBI you guys are next and after that we have sweat hi I\u0027m max I mixed from taps and MB which are closely related the sake of fun so some of us worked on taps which is like a replacement for sockets basically we have been here before yeah those are the drafts we had interactions with and then we also try to work on Emme which is the new draft by Jake and so what did we get done in taps we managed to implement an endpoint racing which is neat we\u0027ve had between agates once you implement the protocol Racing\u0027s in a way of endpoint racing and protocol racing and also working on local endpoint racing there have been a lot of fixes for taps during a heck of fun and we found some new interesting interactions and issues for Framus which "
  },
  {
    "startTime": "00:36:51",
    "text": "are going to take to the working group then for mb we implemented the first draft implementation we created a first draft implementation of the protocol and that was also the first time our taps implementation in pytho and really got used so we brought a real framer for the first time in stuff like that yeah that\u0027s basically it basically that\u0027s thousand relevant git repos okay so Swift and then we have pluggable transports after this years thank you everybody so my name is Vincent we have been working on the sliding window FEC Korek yeah what\u0027s goal is to design an open source correct for recovering packet losses and reduce latency compared to traditional real ribbon for instance block codes there are strong relationships with the Korean efficient paper communication research group and we have been working on also on specification of the ILC correct for that source code for that which is almost published as RFC 86-81 it\u0027s a matter of days so the goal yes I kept on as I said is to design this reference open source free correct and also to challenge generic API internet draft that explains how to use such collects what we\u0027ve been working on this time is to centrally the decoder side which is the complex part of a correct this is where you have to manage and do linear system decoding using some kind of Gaussian elimination so we took advantage of an existing library following that but this library was done was designed for different context with different logic and so this this is complex to line this this library with what we are doing here so this is basically what we\u0027ve been doing thanks to Siri can do Mema and we also I don\u0027t find an issue in the generic API internet right - that\u0027s right we continue working on the Python wrapper as well as the testing C application - so small team free people including myself that I can do Mima if you are "
  },
  {
    "startTime": "00:39:52",
    "text": "interested in is the github repository and you can also attend our research group meeting on Thursday afternoon thank you ok pluggable transports and after that is J map for D mail yeah hi everybody we work in the area of traffic obfuscation for Internet freedom and human rights and we\u0027ve worked for a couple years now on an application level technology to help us do that to defeat the defeat deep packet inspection the idea of pluggable comes from the fact that it\u0027s hard to keep the internet open and the half-life of these jeez is pretty short and one of the reasons to be talking about this particular topic of usability today is that these things do change quickly enough that it\u0027s hard to keep users informed and hard to give users a new way to an understandable way to sort of stay in the game so we\u0027re looking to set up a create a development environment for us to look at some of the usability issues and the problems we face and so we set up this marionette which is a goal language implementation of something called uh parts of a finite state machine that does format transforming encryption so we can make one kind of traffic look like another kind of traffic and this gives us many ways to do that so it\u0027s a good environment that has many options for the user to select all of which are completely opaque if you\u0027re just a regular user and you need to get something done so we want to understand how to you know what the limitations of the current model this marionette project is are along with what the global issues are that users face and can we put these things together to give us give ourselves a good development model for looking at user experience and making some claims about future user experience this is how the idea of pluggable transports works overall here it is in in in marionette where you have a client that runs low is locally hosted on your device that helps you select a format transforming encryption mode that that is collected by a server which itself links to the application server so there\u0027s a number of things in here and our current model they\u0027re fixed and Static and they need to get a little bit more dynamic so we have to look at how do we bootstrap the client properly how does an application configure itself to use that use that that proxy and how do you select what kind of transform and what kind of technology pluggable transport technology you want to use and also which server it is do you select that\u0027ll implement that technology in the way you need so I\u0027d like to thank the "
  },
  {
    "startTime": "00:42:53",
    "text": "team at marionette who did this environment based on some some university research that was done first in Python and then another team implemented this and go our sponsor is inter news and we thank idea for giving us a chance to talk there\u0027s a lot more on pluggable transports at pluggable transports dot info when we have an internet draft on it also in the usual place thank you very very much okay and thank you alright so next up we have a game app for Gmail and after that is WebRTC hey everybody I\u0027m Seth um can I just got a quick show of hands of who uses Gmail regularly that is a lot of people hi I\u0027m Seth this is Neil from pass fail I so Neil\u0027s worked for the last good while to make a beautiful new application protocol for email clients to be able to work effectively because IMAP is terrible honestly unfortunately all of the people in the room here which is like about two-thirds of people who use Gmail today can\u0027t take advantage of beautiful new Jay map API and as a result you have awful loading bars when Gmail loads and you don\u0027t have a lot of options because third-party email clients need to implement email functionality specific for Gmail or they use IMAP both of which are vaguely terrible so um so we thought well wouldn\u0027t it be great if we had some sort of map from Gmail API Gmail husband a snake you guys too well gmail has an API yeah if we map Gmail API across the je map so that way if anyone wants to build a nice new modern email client you\u0027ll be able to do so easily and it\u0027ll work well so we did and this is a little J map um web client made which Neal worked on yeah so we already had this demo demo well climb which is open sources is on github and we just thought let\u0027s see if we can get that to talk CA also we quickly coded up this kind of translation layer in the middle and it baby works and you can list stuff yeah noon browser email um so that\u0027s what we\u0027ve spent that weekend doing um and J map if anyone\u0027s curious to look at the slides is actually quite beautiful you can do these kind of recursive RPC queries unfortunately Gmail\u0027s api is oh yeah Gmail\u0027s api is kind of awkward and slow and we kept running into rate-limiting issues we quietly suspect that Gmail doesn\u0027t actually use their own API to build their own email clients and it sort of hasn\u0027t been exercised it\u0027ll be really great if anyone is interested come chat to us if anyone those people in the Gmail team or you know it\u0027d be really great if Gmail included jam up and that way we could we could have all of the stuff working well so yeah if you\u0027re interested there\u0027s all this stuff stuff on github although unfortunately as we said it\u0027s all very proof of concept and I\u0027m really be great if we "
  },
  {
    "startTime": "00:45:54",
    "text": "could throw up a website which was you know gem up with Gmail already working but it\u0027s really slow and after you refresh it a couple times it starts taking or for a minute to load just because it\u0027s the right limit but come and find us afterwards if you want to see you live demo show you something see thank you okay so I believe next was web RTC and then after that we have a deep okay right thanks hey guys so the RTC web group was officially closed last year in Bangkok so it\u0027s been a year that officially the work he\u0027s done and of course there\u0027s a lot of blood left so we\u0027re coming to the hackathon to go deep into the stack and clean the last remaining stuff we were not as many people this time as usual in Asia that we were in Europe and so on but we still had some interesting project program so we had apple Intel and a few other coming today to try to bring a new codec in the RTP part of the stack everyone even though it\u0027s done at i/o media it touches RTP which is done at IETF so we wanted also to you to you know share the copies and look at all we can make him better and so on and so forth eventually we got a few bugs actually addressed with patch pending review in different github repository that touch on on the stack and we think we might progress into sharing some tools that are going to make bandwidth estimation and congestion control easier to debug and visualize across different group whether it is di vita core that takes care of the RTP protocol or our MCAT which take care you know specifically of the congestion control so globally less bugs address but a lot of very interesting discussion that should lead into shared tools and share development for the next IETF in Vancouver alright so the usual suspects plus a few first-timer Intel join us for the first time thanks and welcome I hope it\u0027s going to be good enough to make them come back and participate we were certainly happy to have yet another an implementer providing feedback to for the specification and another company based focusing on security and encryption that we wish is going to join us again oh thanks okay cheap is next and then MDT thank you "
  },
  {
    "startTime": "00:48:57",
    "text": "this is teep three minutes talk doesn\u0027t mean I have to talk three minutes just going through slice great team will sorry misspelling and what we plan is evaluating the draft with origin is story from authority without a version and then in what highly modified to have a tea proposal and we brought few implementation to Tam which is as works as a server and the device to the different kind of device and got done is all pictures so I don\u0027t have to type on the slides so type on the table this is Eli on the tip Pam it\u0027s able to upload the TAS over here is Oba sons time and this is the device running on arm opti and hacking in the bucking and many things didn\u0027t work and finally yeah t transit application was able to install on the T and what we learned is many things it\u0027s it\u0027s written in the slides but I\u0027m honestly for the implementation it\u0027s long long away Dave stamps and device is pretty much implemented but we need a strategy how to make it as a properly in the future of the reference implementation and that\u0027s the wrap up but before finishing it this implementation will cost a lot of a different kind of knowledge te how does it work in different kind of CPU and json seaboard and HTTP stack or have to be working perfectly to implement on something on top of it and how needs the knowledge of how the device boots sick so yes it\u0027s a lot of work thank you okay so MDT and after that we have a ssh HTTP 4-5-1 forward and backward in the hello everyone from far away our project is used yong-dae tunnel tag to filter different discrete categories of yarn data knows within young modules and and provide a consistent representation reporting for the same same category of young data nodes we have two related drafts actually they exist existing Janusz telemetry provides a mechanism to select and subscribe your operational data "
  },
  {
    "startTime": "00:51:59",
    "text": "object it\u0027s based on a selection filter but there is no document to discuss how the selection filter can be specified to address this issue we introduced the self-cleaning conception which can be interpreted as instruction that data no the selection principles so with the self explanation information so so with the self explanation information that\u0027s the net of the Netcom clients can select which type of the objects are of interest for example to extract the features from the management data objects such as CPU usage we develop a running code and deploy during the telemetry collector and provides module data node or to automatic tagging automatic alluring and automatic subscription mechanisms the left figure is out is our tag model we call the OPM model the over object type for example for example the interface is an object type and P for property the interface name we call it is the property and M for Mature the CPU usage or the receiver or the stand bytes is a matrix the right finger is how we realize our OPM model in our demo you can see we we collect the CPU usage from the two devices generally say without any pre-configuration the monitoring data can be collected and displayed can chemical acted matically and displayed on the GUI error results we imported our collected data to the two in flux to the influx TV as the data source and we process and analyze the telemetry characteristic data using Grovner both the two software\u0027s are open source we better inform the project we better we better understand the key value of the telemetry tagging and we found it is important you have more developers to implant it and more service providers to deploy it and here our team members thanks very much okay so next up we have SSH HTTP and after that we have coin RG test okay so thank you very much it\u0027s a pleasure to be here among all of you so I\u0027m just presenting for the team from Mauritius so the plan was to get some work done TLS 1.34 some open source packages big plan was to get some work done on SSH mostly X MSS which is a first quantum "
  },
  {
    "startTime": "00:54:59",
    "text": "signature and it was also on our plan to finish HTTP for 5-1 Drupal module which was taking forever so so what got done HTTP for 5-1 were final fixes for Drupal but upstream maintenance requested TLS 1.3 support for an open source project known as check firewall loads of XM SS and SS f p SS h FP support added to a bunch of tools so quite a few of them were relying on Association just wanted updated since OpenSSH came out with X MSS one of us to seize big victories parameter because it\u0027s used as a library for ansible so the idea would be does this have ansible eventually be able to do some of us stuff so what we learn we are just really at the beginning in terms of toom cryptography like we\u0027ve got feedback from curdle working group and but shares of a cardio working group are actually asking me to stop sending more drafts to the working group so we\u0027re still it\u0027s very new and I think we\u0027re going to be busy next year with more obvious kind of work so the people who do it did it in from Mauritius or actually quite young between 15 years old to 19 years old so I\u0027m just a picture of the group and thanks to Rogers Capital for hosting very wet emerges and was overly soft team members so again thank you very much alright so are we here here for coin our G and then after that is was that c4 and these two forward backward I\u0027m hi I\u0027m Murray I\u0027m representing at the best table for computing in a network we\u0027re a proposed research group but we\u0027re trying to do things we\u0027re about data playing programming and adding computation and the network so our original problem that we had started dressing at our first hackathon in Montreal was to do packet filtering and we started with that as an idea we had some tons of inputs actually there\u0027s a big p4 org that has a ton of templates and all kinds of things for us to get going and virtual machine and we had a great participant Michelle who "
  },
  {
    "startTime": "00:58:00",
    "text": "because of his own work had also a lot of tools to get people getting going we\u0027re still at a set of individual projects because our team we don\u0027t have we have a team we have a bunch of people getting together and trying to have fun and but in the future work for the next hackathon we intend to have a project that will keep everybody together and we intend to have that defined by by the group so what got done obviously who editorials for people like me and others who don\u0027t really know what p4 is about or not enough we had Michelle who continued his work on service function chaining and he had great improvement on his code so we were very proud there was a just for fun in coin we address a lot of industrial networking issues and so we had coy who actually designed something to do packet filtering for sensor networks where you actually can define what a packet and how a packet is treated based on the measurements from a sensor we also had Aris who started looking at some BGP origin validation they had a snafu they figured out that p4 wasn\u0027t good enough for that and so they took an alternate route we also had Luke who helped them and look at one point also figured out that the limitations of p4 we\u0027re validating some of the aspects that we have in the working group that we want to use the p4 and the pilot the data plane processing to do very basic packet filtering and we have a another device or another processor to do more advanced computations what we learned we learned that from the Delta from last time we\u0027re doing much better there\u0027s much more people who know about this field and much people who know about the language we agreed that we should agree on a version of p4 before the for the meeting would help we could do that at interim meetings decide what type of setup we want to have bringing a VM on a USB would be great and by the way yes should be more poster boards with pens and paper because it\u0027s fantastic to communicate with the people around your table and not just the people online on slack and this is the fantastic team we had actually all the start people or new stars the great people I see I think I would like our two local people from Singapore to stand up because we had two people from local the local community who found us which I think was amazing [Applause] and I\u0027m done and join us Friday thank you okay great so next up we have C 4 and then BMW G after that let me summarize the support project so this "
  },
  {
    "startTime": "01:01:02",
    "text": "project is related to our general research group and the support is open-source software platform enabling shishi and communication fit is comparing two ways these two are F sheets the main objective of this project is to enhance support functionalities in the context of the two proposed draft shishi an info and the network holding for shion and a DM so more precisely in this hackathon we implemented to support functions one is in network controller using incision info which come some operate which can enable some operator to check out in network condition and the configure which data packets should be cached and second is a Content producer application called Campari which can you which can utilize donor - according in the context of shishun communications as a shipment we built and tested the basic problem modules related to the two functions and regarding lessons we got we need to make more more feasible and flexible naming scheme and deal with interest packet loss to improve the performance of these functions here the team members and we can get more support information and the source and the source code from this you aware thank you so next up we got BMW G and then after that we have the measurements team hello everyone my name is KJ from University in Korea and secretin so we try to define the words of our draft in the BMW G containerized infrastructure benchmarking so for that draft to reroute that the superior allocation are the technology for this these days is and not guaranteed to the deterministic results so or we want to verifying this or to use some tools so the first is a native kubernetes CPU scheduler and then second is comparing with CPU pining technology using the cmk by Intel so so we want to allocating "
  },
  {
    "startTime": "01:04:02",
    "text": "same number of a CPU apart and the measuring the support and the latency to analyze the impact of the metal preference of the container itself so this is our system so we have a to of physical server in the remote side and then the one server or they will be deployed a t-rex on the barometer and then on the container note also we use the DPD k and then continue PPP CNI plug-in for networking and then force if you pining we use CM k and then when it\u0027s native or cpu scheduler but unfortunately we couldn\u0027t get the expected result yet because there\u0027s so many issues in there or for configuring and installing and then all the stuffs or some some part of the hardware and OS and Nic dependencies and then the main our struggling point is that some networking areas like the UDP and even a checksum error so or so since that the BBP is a little invisible to the user so we are we are struggling to define or figure out what is a problem in there so and they\u0027re trying to solve problem as well as possible or and then after we made it and on share to return to the BMW G and nevertheless the we\u0027re under such different things and the difference between the pre switch and benchmarking switch benchmarking and and that a function is ER so we thought that firstly we thought that just for informs switches to the container but there have so many the configuration is needed and then on the other end we learned more than understanding for technology and then configurations and all the options we tried and or and or one the one thing one more thing is the checks power consumption so our site server was shut down during the hackathon for some for why or run when running checks with 100% CPU usage so this is our team member yeah and thank you very much ok so what do we have next measurements and then we have after that LP ran and then I\u0027ll go back and get the ones that we missed earlier Thank You Charles yeah ok hi I\u0027m mal Morton and I was working with Lynch avataan remotely on our measurement project and here it is we we talked a bit about this in Montreal we were we\u0027ve been working "
  },
  {
    "startTime": "01:07:03",
    "text": "on an internet draft now we\u0027re into the third version of maximum IP glare capacity metric and methods of measurement and it\u0027s a UDP based method at the ITF we\u0027re trying to gain experience with really challenging access one gigabit per second with lots of users that won\u0027t go away that\u0027s you guys so we compared that with TCP Kubik this time last time we compared it with you cos system which is also TCP based and we run the test we iterate the measurement parameters and do it again so we were also going to examine the crossover with the benchmarking project that you just heard about but we\u0027ll have to wait for later in the week so here\u0027s what got done this time looking over here at the right we had our measurement system implemented in this nice little PC minute mini PC system so we\u0027re able to run that bare-metal and we also had a Google Cloud VM located right here in Singapore less than 4 milliseconds away and it was still a 15 to 18 hops the measurement system sends traffic in one direction and it gets feedback in the other direction so it actually makes adjustments very quickly and we use the UDP and IP 3.6 clients and servers to do that you can see on the on the right is the I guess on the right hand side of the graph is the percentage delivery for packets that we were able to measure using the UDP system you can\u0027t get that kind of information readily from a TCP measurement or the delay variation very easily as well what we what we\u0027ve got here we\u0027re measuring a one gigabit per second bottleneck somewhere between us and our server and our UDP measurements in blue there are pretty close to theoretical the lowest one I\u0027ve plotted here is 998 megabits per second when corrected for Ethernet header and one VLAN tag the other ones are actually higher and the last one there had loss ratio of practically nothing so and then the three TCPS are not doing so good so let\u0027s see here 23 seconds okay so we learned a lot today was testing was really messy so don\u0027t test on Sunday many PC was good a good bare metal platform we need to do better load adjustment the search algorithm uses loss and delay we need to have a better threshold for loss and we got some actions for the existing draft and so forth yep you and me are synchronized so we\u0027ll try to do that later with the keep going with the benchmarking group this week okay next up after measurement I "
  },
  {
    "startTime": "01:10:03",
    "text": "forgot oh the LP one yep you go and left and right before that thank you hello everybody since we are getting to the end of this session I decided to post it the last slide first so here\u0027s the project rep oh and the team picture we had a dozen contributors this time quite a big team compared to the other times the usual suspects draft authors and some good software developers we had so eg from Japan who usually attends remotely you flew in at his own expenses just to be with us this time thank you so much so eg we had the olivier new newcomer to the IDF and hackathon who brought his expertise as well and one remote participant from Chile so this is a shake the static context header compression and fragmentation to be used over low-power wireless wide area networks we have a couple draft the first one is pasta IHG review and is we want it to we want to implement an open-source implementation for that the the goals were for those who have seen this presentation before last time we integrated the fragmentation and compression code and so this is done and now we wanted to clean up the repo we had some remnants from the old structure so this has been done we\u0027ve improved the documentation make it easier for newcomers to understand what how the code works and how to get started and also to improve the functionality because the the draft has a lot of features in it and we hadn\u0027t implemented everything and so thanks to olivier we set up the Travis continuous integration so we get more professional at the way our software is developed and so what we learnt is of course a better shared understanding of the specs between everybody around the table we spotted obviously a few issues in the implementation we even tried running the the test code on memory device itself and yes it fails it\u0027s a big - big with the test environment so we need to split the code but that gives us some way forward and of course we need more tests more test automation we also spotted a missing element in the data model which is another draft that we work on at the working group and also we think we are ready for interrupt we know of two other implementations which "
  },
  {
    "startTime": "01:13:04",
    "text": "are not open source and will be probably doing an interrupt that in its hackathon that\u0027s it thank you ok so yeah now as promised we\u0027re going to go back and try to pick up some of the ones we we missed from before starting with DNS there we go yeah let\u0027s see yeah so left and right for forward backward and thank you very much all right welcome so these are the results of the did the DNS table good so as usual in the DNS with a DD Venus table we don\u0027t have one single plan we have a group of individuals with their own plans and we work together and we talk a lot but we have a number of themes the privacy DNS privacy of course it\u0027s important in the past years DNS protocol improvements container DNS and service provisioning and submitting some measurements good genus privacy continuing work on dinners of atilla\u0027s but previous in the previous years we worked from from from the stuff from the clients to the resolver new work in the DNS privacy deprived working group is from the resolver to the tortoise a dot also gold so there wasn\u0027t hack kind of proof of concept implementation inbound how to implement that using a subnet specification and a host name - fela date it to have an authenticated tillis connection to an authoritative nameserver how to bootstrap this list is something the deprived working group has to work on so if you have ideas in this room you\u0027re welcome to join the discussion on deprived working group Friday morning Dinah\u0027s over HTTP the pi9 has and made a design for implementing the OS in by 9 and with that we have in 2000 2008 in by 9 and bounds in not resolver and in power Dinah\u0027s this so we have for open-source implementation of do H which is good so if there\u0027s a choice there\u0027s an options different options for deployment also a proof of concept implementation of DNS over hp3 quick working progress based on one minutes things in case some protocol "
  },
  {
    "startTime": "01:16:06",
    "text": "improvements cookies server Dena cervical keys why should we care about DNS server it\u0027s a way to mitigate DDoS spoofed addresses you can filter them out so DNS server cookies we did had an in specification it wasn\u0027t very Interpol you could make different implementation decisions with the base specification we solve that we have three four implementations that are interoperable and extended error well skip that not a draft working on service provisioning I want to mention that it\u0027s important something we are thinking L in the Dinah\u0027s community thinking a lot about how to solve this problem in the last ITF there was a new draft we did an implementation of that draft it was called HTTP SVC at that time it has been renamed to s PCB surface binding we have that in implementation and got some feedback thank you ok so the order and whose next is a little harder for me to figure out now just because I\u0027m going to basically go back and I\u0027m gonna pick up all the projects just go from top to bottom and anything we missed I believe we\u0027ve done all of these and the next one I think that we haven\u0027t done is cap or if you see yourself in the list and I skipped you and let me know we\u0027ll go back and get you so Kapoor who is presenting that one [Music] great okay here we go and so left and right go forward thank you hi everyone so I\u0027m Remy I was working here also with the Salva and hang were sitting over there on the captive portal some captive portal proof of concept for the Capitol working group for people who are not familiar with the work they\u0027re basically the first objective of the the what they have kept kept pulled API let\u0027s discuss in the working group is first to make captive portals this bad because they\u0027re like very often really bad and because the for example detecting that there\u0027s a portal is really tricky but apart from that it also enables number of use cases for example knowing how much time you have left on a portal if it\u0027s limited or like knowing how much data you have left also having a way for you to know if you\u0027re still connected or not if like the the network just is connected you and you have no idea about it general it\u0027s not great and also it enables use cases such "
  },
  {
    "startTime": "01:19:08",
    "text": "as you know having in fight on containment in the plane we don\u0027t have internet anything like the schedules tight iam timetables if you are at the HTF knowing like where you\u0027re making is oh like the train at the train station stuff like that so general flow of the demo we built was first you will discover the API endpoint for that API so it from the draft it could be a ready HTTP every six hours all the link relational header as a backup we use we implemented as DHCP then basically the demo probes the endpoint to Detective or portals of is open or closed I get the session information and show info in a notification so this is a demo that was implemented on an Android phone like with the open source iOS P and on the access point sight so we have so a team from Google session which who is here today who provided so one implementation that they have you know for for for this captive portal API so yeah and they provide whether the client is captive or not they provide the captive portal page how much time is left and also a URL for information which happens to be the IETF information page so here\u0027s what the demo is I can\u0027t show you because on a screen would be way too small but here\u0027s what it is basically you connect to a Wi-Fi it tells you tap you have to sign in the usual thing when you open the portal which is you know the in this case the Google Station provided portal you can log in you get free Wi-Fi and then you get this notification that tells tap to manage and when you tap on this you can get you know information about this access point which is basically the ATF info today and that\u0027s it contact here for me 440 station you have a server and hang and the code is on a OSP open source next up if I remember right is I fit where to go there it is do we have someone to present I fit okay "
  },
  {
    "startTime": "01:22:15",
    "text": "left and right okay hello everyone I\u0027m an angel from away and now we are working on we worked on the Institute flow information telemetry the I feet provide a reference framework to acquire data about a packet on its a forwarding path but when we deploy it in the network there are several challenges for deployment in Carroll Network firstly the performance the forwarding impact due to the packet processing and the pen device and the server overload due to exported data and there are others some other challenges for example the limited data flexibility and extensibility and the deployment issues and encapsulations and the tunnels and the primitive models API for commercial applications so we we are considering several key components to address the challenges including the smart flow selection the export data reduction the encapsulation and autonomous and the dynamic network probe and owned amount of technical integration and this is what we implemented last time in Montreal and we implements the postcard based telemetry and achieve several use cases including the delay monitoring for no link an end-to-end and we also implement the packet loss monitoring and the past tracking this time we add two functions why is the scratch guided elephant flows direction we can dynamically insert the sketch in in the device and select the elephant flow for high-precision monitoring and second we the the exporting data packing we can give define the number of packets to be bundled and define the time interval to force export in this way we can reduce the exporting data and next time we are going to attend the hexan again and we will use people switch to implement and the demo this thank you okay next up should be spend [Music] "
  },
  {
    "startTime": "01:25:19",
    "text": "okay weird a quick measurements team working on the spin dump tool so for this hackathon we plan for adding some more functionalities to the spin dump tool which is basically a network latency monitoring tool so we wanted to implement support for what is called a delay bit it\u0027s an experimental proposal of adding another bit to improve latency measurements we also wanted to improve our RTT statistics and we wanted to add more more spin bit supports to quick stacks so what we got done was that we added support for this delay bit so we can get improved RT measurements for four endpoints that support that one we also improve the statistics by adding some some more statics like standard deviation of the RTD measurements and we also implemented some RTT filtering based on that and we also managed to get spin bit support into the move fast quick stack from Facebook the team was me Marc Sylar yari Arco Fabio Mauro and Ronnie Evan thank you [Applause] [Music] wishy is next and left and right to go forward and backward right thank you okay hello everyone here\u0027s a report from we see our work on IOT semantic hyper media interoperability our plan for this this time was work on data model convergence and automate translation in particular with the 1bm language and tools also we plan to work together with w3c web of things we had a joint meeting this Friday together with them and they joined here on their web of things block fest activities and finally we plan to work on a new P which is this translation between binary and and JSON based data models what cut down the over this weekend we had a lot of work on the 1dm tools and concepts in particle are doing conversions between 1 DM SDF and live with them to emit somewhere else so this is the reverse from the what we did one last idea where we did it\u0027s at 1 a.m. but will also enhance that kind of translations we also have a linter for 1 DM model so you can check the validity of your models and we worked on a CI in github to actually check real time when "
  },
  {
    "startTime": "01:28:20",
    "text": "you commit new models they are actually valid most of code for above is already available on on github on the link above we also had very good discussions on architecture use of semantics how we can handle dynamic descriptions and in particle how should we work on convergence across SDS on various specifications in this area on U P now we have also basic encoding from chasing the binary so we can go both ways on between JSON based and binary based models and web of things we have no first version of TD discovery using coop Rd one thing that we agreed to work on going forward is this Symantec proxy so the idea is to go from one DM descriptions potentially with use of some RDF to thinking descriptions and then we could be using something like Symantec proxy or a gateway to work between applications and devices from different ecosystem see if you\u0027re interested to work on this topic you\u0027re very welcome to join our ongoing Vichy activities at the tingling Archie something we learned again of course we knew about it you shouldn\u0027t do models and and examples by hand you make a lot of errors there good CI helps here automatic tools are even better it\u0027s not like the tools don\u0027t make mistakes but they make mistake in a consistent way so it\u0027s usually easier to fix on the flow here\u0027s our team members and if you want to learn more about you can go to we sheet of space or to our idea packet on space and we are welcome to join on the ongoing activities thank you okay next up is l4 s and then NTS after that oh there it is okay so this is low low low latency scalable throughput for us from the transport area and it\u0027s it\u0027s essentially a transition mechanism from today to a position where everything can just be low latency without having to particularly do anything about it and we mean really low latency links there to existing code and the specs we had a number of remote people as well today and also three new people to appear on site and three remote people who were remote last time so it\u0027s it\u0027s not all bad when your remote some people do it "
  },
  {
    "startTime": "01:31:20",
    "text": "twice what we got achieved really three projects the first two of those bullets about testbeds and the first one was one of the new people getting them to work through the read million check you know it a fresh set of eyes can through everything without anyone else telling them site information and also the the other one going on on the test another testbed was running TCP progress as well not so much versus but coexistence with bbr v2 which has an l4 s transport within it as Google\u0027s PBR might as deep is the community one ran through full set of tests on that on accuracy n ill-posed started Saturday on this looking at the limits code to prepare it for up streaming into Linux so you he was getting his head around it all reviewing the code and sequencing the patches so they can go in missed that one reasonably in order and they\u0027re also that a complete remote team working on NS 3 added first start up got that running but still more to do on that need a testing framework around it updated the g oq to the spec although that\u0027s still in progress and he added configuration code so if the auto configures when you all the ECM DSP stuff for the NS three implementation a piece of TCP so we learn we found a few missing steps in the readme accuracy n found it\u0027s more flexible in first appears this was also with the SE e team here Richard was explaining how that might be added that was already reported industry is useful for getting things done okay next up is MTS and then who was it TMR ID I think and I think that\u0027s it unless I missed any yeah you guys here it is okay getting close you know the "
  },
  {
    "startTime": "01:34:28",
    "text": "drill laughter thank you so hi everyone my name is accused of an eagle I worked for a net mode in Sweden so I\u0027m gonna talk about about NTS it\u0027s security firm for MTP basically okay sorry so time is important is it\u0027s basically the message and I think everybody knows that so I didn\u0027t have to come up with a lot of examples and when it comes to time of the internet MTP is the protocol that everybody uses it\u0027s been around since 1985 I think it even predates BSD sockets so NDP is pretty old NTP does have some security but it\u0027s based on symmetric keys pre-shared keys so it doesn\u0027t really scale to a lot of users NPS adds the kind of scaling we need to be able to do secure NTP to everybody and I wants to meet haven\u0027t done a lot of progress today which is in a way good it\u0027s because we got a lot of things done at early hackathons in I had my first hackathon was in Prague and I felt that we made a lot of progress at that time so today what I\u0027ve done is really just been working on scripts to verify the functionality of the entire servers that\u0027s because we had netted her MTS servers up and running now and we intend to keep them up and running so I\u0027m trying to build tools so that our IT operations department can see if anything fails and quickly corrected it might be interesting to other people so I\u0027ll try to open sources I\u0027m I\u0027ve been also working on how to on how to actually start using NTS in a client and I\u0027ve been using entity SEC as an example and this how-to is suppose to or I\u0027m going to show how to do it with the NTS services for a university not real anger has done those we have cloud fire officially we said that they have entire service that they intend to keep running I\u0027ve done a an implementation for net mode which is a Frankenstein\u0027s monster of my Python code and the time stamping from Crowley and NTP SEC they was around a couple of servers and sort of good news the NTP NTS draft was submitted for publication on them the 7th so hopefully this will actually become a standard pretty soon and not much to say today it\u0027s been me Krista fighting on deepest today people who have been working on NTS and I\u0027ll be at the academia tomorrow if anybody has some questions or wants to see anything what has any one is about NTS and there\u0027s a link to the draft all all so if anyone wants to see it thank you [Applause] ok next up is TMR ID "
  },
  {
    "startTime": "01:37:32",
    "text": "[Music] [Music] [Music] Thanks so we\u0027re working on a problem that comes from the real physical world you\u0027re at a emergency scene you see this unmanned aircraft hovering above the building that\u0027s on fire and you want to know whose it is so you can figure out whether it\u0027s like another fire department and has some business being there or maybe it\u0027s the guy that started the fire so there\u0027s another standards development organization ASTM International that\u0027s been working on this problem for the US Federal Aviation Administration and various other civil aviation authorities in the rest of the world problem is their standard does not provide for information that is immediately actionable and privacy-preserving so we\u0027re looking at leveraging some ITTF work mostly related to hip we\u0027re going to need to update hip with some new crypto and make it hierarchical so fundamentally this is to make the claims that come across one of these remote ID systems trustworthy so we started early at the New York UAS test site we did some stuff with DNS lookups what we were working on today is a shake 128 based hierarchical hit as a temporary stand in for a seasick based hierarchical hit Adam got bun two builds working cleanly on recent Ubuntu we started discussing observer to pilot emergency comes via hip proxies back in New York we flew a Bluetooth broadcast UAS from what ID of currently standardized flat hit what we\u0027re gonna demo here right now and you here in the room aren\u0027t gonna be able to see this but those who are playing along at home since the cameras right here will be able to get a better experience I\u0027m gonna start a scan here and then Adam is gonna start broadcasting using his cell phone as a surrogate for an aircraft and I hope that the Bluetooth range reached it did my screen paint yes it did those of you who are playing along at home can see that the UAS ID type is a host identity tag which is not in the ASTM standard but we\u0027re lobbying for it to get added to that standard we need some more reviewers we need some inter opera the experimenters some of the work that was done in hip a few years ago on an experimental basis really needs maturation some of the drafts need maturation when I say UAS from what I D roles of who is I\u0027m really talking about the whole domain registration process not so much the who is protocol probably the new are DAP protocol how are we gonna use DNS because the privacy-preserving aspect is really important duly constituted authority needs to know who\u0027s flying that thing so we can tell him to get the heck out of that airspace because the buildings on fire underneath them or whatever but the little old lady "
  },
  {
    "startTime": "01:40:33",
    "text": "next door who just doesn\u0027t like the buzzing sound in the neighbor\u0027s backyard shouldn\u0027t be able to use this as a pilot harassment tool so the new IETF work will be mostly in the hip working group but we\u0027re also going to need to do some coordination with other standards development organizations including ASTM the International Civil Aviation Organization and the radio technical Commission for aviation and so all the team members are noobs except for Bob Moskowitz and please join us set up off Tuesday morning thank you so we have a presentation on net cough yang managed tester that I missed and then we\u0027ll have a quick after that so left and right before heading back okay so our goal is to implement RFC 2544 tests in simple command line two that connects the devices part of the test setup over net conf and those devices had the young model so we have a draft that describes this solution which is described by this diagram here and the execution of the test should be as simple as running a command line providing a configuration based on the UNK models mainly the topology ITF model augmented with data about connecting and specifying what kind of parameters the test should actually take into account when executing so this there are many different RFC 25:44 implementations but they usually involve graphical interaction which is not so easy to reproduce without there is no model so this is this was the goal of the test so to do a RFC 2544 you need the hardware to actually execute it correctly and then we had to make hardware for that so "
  },
  {
    "startTime": "01:43:33",
    "text": "we we have two testers one is a proprietary tested on the bottom and the other one is the open source open hardware tester which is running Debian both of them are running Debian and you may want to try net conf this error the middle one is the open whoa cheap switch that we used as a device under test and we put net Kampf D wrapper on top of that so that we can have a transactional model and that\u0027s about it thank you okay quick usual suspects were in the back corner there interrupting their quick implementations I think we had seven clients and eleven servers actually participating that\u0027s a little worse than usual a couple reasons for that number one we I think with lower attendance here in Singapore muted in Montreal and some others and secondly draft 24 drop only a couple weeks ago when I think we\u0027d several implementations that weren\u0027t quite caught up yet nevertheless the story is fairly similar a lot of a based on functionality we\u0027re pretty strong Interop on even though some of the details are changing we have a few implementations that are doing some of the advanced IP address migration stuff and some of the more advanced HTTP 3 features like push and and so on but probably not as many as we would like overall I think things are moving forward a lot of production implementations are are maybe don\u0027t quite have all the all the interoperability checkboxes that some of the some of the you know the for fun implementations are having but they\u0027re getting there and there they\u0027re getting closer to do something can actually deploy questions it\u0027s all I got thanks ok any presentations I miss ok one one thing I forgot to mention earlier if some of the teams if you want you\u0027re like a team photo taken or something we have our friendly photographer who will hang around for a bit afterwards and you\u0027re welcome to stick around let them know you want to get a team photo taken several of you mentioned that you plan to present the hack demo happy hour tomorrow that is what from 6-10 740 p.m. would love to see you there if you do plan to do that the sooner you sign up the easier it is for us to to plan and manage the space and we have a cut-off time at noon tomorrow if you sign up after noon we\u0027ll try to accommodate you but I can\u0027t promise that we will especially if we have a lot of "
  },
  {
    "startTime": "01:46:34",
    "text": "teams presenting the code lounge will be here kind of this half of the room so I know some of you said we didn\u0027t get a chance to finish everything or you know we have other things we want to continue working on you\u0027re welcome to use that space if it\u0027s helpful you can also schedule time there\u0027s a page for the code lounge you\u0027ll find it in the hackathon wiki and so you can sign up there and welcome you to do that how to thought you know next time I think what we\u0027re going to do is we\u0027ll give a time penalty to anyone who doesn\u0027t get their slides in like well one less minute or maybe one more minute if you do get your slides in in time and a bit of an incentive there other than that I think we\u0027re we\u0027re done thank you all for coming here early spending your weekend with us I hope you got a lot of value out of the hackathon I think I\u0027ve certainly seen a great sort of impact of the hackathons had on on what\u0027s happening in the working groups please do bring back what you learned into your working group feel free to upload more like your presentations if you have things you want to add to them you\u0027re free to do that even after the hackathon ends that\u0027s all good because that\u0027s a great resource and we have meet echo recording all this so we\u0027ll have that too in case you want a recording of your presentation any questions comments feedback well thanks all except that all right well thank you all and we\u0027ll try to make sure we have as big a space and in Vancouver and hopefully even more all of you show up and tell your friends bring them along too so thank you very much enjoy the rest of the I [Applause] [Music] "
  }
]