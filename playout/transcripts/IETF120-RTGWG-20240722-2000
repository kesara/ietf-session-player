[
  {
    "startTime": "00:00:06",
    "text": "Thank you Thank you We are about to start. Jones, please take your seats It's really low wim henderickx Guys, take a seat. We're about to start and engine should be coming any minute minute So welcome to Vancouver 80, 120, and we are off opening crowding working group meetings It's a very busy agenda today, so please be on time, please come up and we'll try to get two slots in double but for now it is what it is, so please be efficient, please cooperate your thing So anyway in this meeting you are"
  },
  {
    "startTime": "00:02:00",
    "text": "subject to IETF standard process. Please make sure you are reading the document mentioned here. You are well not where and you are with them So I received since 119 none. We are still in progress of working true We have adopted two drafts, the multi-segment SD1 and dejuvenated this natural source routing, which we are trying to fast track and actually get very quick to be ready for working with plus call We have submitted three drafts for publication So thanks authors for working with us with Working Group to make it possible BGP peak editor, we really need you to add dear editor, we really need you to address the editorials Please help us to help you QS model, there have been many questions We know that QS data models very complex topic. There's many models as implementations So we continue working on it And we are people into multiploing BVD We plan to start working with last call after IETF 120. Jeff. Yes Wearing my BFD chairhead. Please call that also in the routing RTG, BDFD mailing list as well. Absolutely. Thank you Sasha, any questions? So, again, as I see very busy agenda, so please cooperate with the and be on time Linda Is this that?"
  },
  {
    "startTime": "00:04:06",
    "text": "Okay, so I just take this moment to give up. I don't think it's going to work for you because it's from my left Okay, okay. So as the multi-segment SD1 through the cloud backbow just major update since the being adopted to working group draft. Next page So here is basically the background You have CPEs located in geographically far away distance. And what they are STO and traffic among themselves and may go through public transit, which public internet, which can be slow on particular performance, so you would like to dictate the traffic steer the traffic through the cloud backbone So we call Mardi-Sec dictate the traffic steer the traffic through the cloud backbone so we call multi-segment ST1 because there's SD1 segment from CPE to the first cloud gateway and then from EQAS gateway to the destination Next page So what really does is really to steer the traffic and we have some draft is proposing to use Geneva Heather, because to genev header is being supported by many cloud vendors and in the Geneva header you basically list down the the you want to egress the network and maybe you will include some other sub-tlbs like include nodes or exclude nodes so that you can help to steer the traffic to your desired destination In this environment, from A to the source, A, to Gateway, there could be multiple paths, could be IP, SAG pass could be POS pass, but nevertheless, it's aggregate"
  },
  {
    "startTime": "00:06:00",
    "text": "all those different unrelated paths into one pass, SD1 pass, and then with the DNA Geneva header to dictate on where, how you want to steer the traffic through the backroom backroom Sure, what happened. Next page page So, um doesn't show it anymore anymore Okay next page Next page. We finish this page and we go to the next page Next page That's the reason and we go to the next page um next page that doesn't go anymore See. Oh, okay, so here the major complaint One progress we have made since last IETF, we got the multi-second ST1 option class for the genie encapsulation that's already assigned by IANA. And underneath this option class, we have defined six subtyovs, basic assigned by Iyanna. And underneath this option class, we have defined six sub-TOVs. Basically, there's an endpoint where you want to egress and there's originator and the have defined six sub-TOVs. Basically, there's an endpoint where you want to egress, and there's originator, and there's also transit and include transit and exclude transit. And last, one is about authentication actually that authentication, we have a new draft in security area and we present that at today's old dispatch and talk to the security ADs and to find a proper place"
  },
  {
    "startTime": "00:08:00",
    "text": "to and then to basically standardize how we do that H-MAC-based authentication just for the header purpose Next page Okay, so here's the payload. We're just talking about data plan The traffic itself, we're talking about trends traffic, because from CPE they may have traffic to be terminated at the plan, the traffic itself, we're talking about transit traffic, because from CPE, they may have traffic to be terminated within the cloud. That is actually through the SD1 pass at the cloud gateway being terminated and then services being served And this is talking about transit traffic from A to B, both are CPEs and you add the Geneva header to indicate this is transit traffic And this header, the payload is already encrypted by IPC and here we are adding another authentication just for the gateway to authenticate the header. Make sure it is not tempered Next page So here's are some major changes. And since it's being adopted to the working group draft we have based since it's being adopted to the working group draft, we have basically enhanced all the writings, and thanks to adrian farrel review and quite a few other people's review make the document IFC ready and this describe all the fields in the sub-tobs and we let's change revised illustration how the traffic goes through the source to the first gateway, through the backbone and egress and to the destination That's the major changes since being adopted as working group draft We are hoping to get more reviews from the working group community and that's it Next page"
  },
  {
    "startTime": "00:10:00",
    "text": "So we also need some people who are expert in Geneva to do the review. There is an old draft which is expired about Geneva IPSEC on top of Geneva reaching out to the authors to see if top of Geneva, reaching out to the authors to see for their review, for their experts feedback. That's the draft name We need more reviews. That's it Any questions? No, okay. Thank you, Linda Thank you. Good work Thank you I don't think I'll take the whole 10 minutes. I'm just going to talk about some of the options we have now for reviving the, not reviving the VRP MIV to talk about some of the options we have now for reviving the, not reviving, revising the VRP MIV, I mean, gang model and go through them and just bounce off the working group, the one I'm leaning toward Next slide So we recently completed actually it was last year, RFC 9568, which revised the base VRP spec to have all the inclusive language. We changed it all But once we did this, it was amazing the number of technical comments we got and the improvements we made, especially in the area of IPVC because it turned out back when 5798 was done there wasn't near the experience with IPV6"
  },
  {
    "startTime": "00:12:00",
    "text": "VRP and deployment, so we fixed a lot And basically what we did is we, the big change that motivated all was we you use the term active router rather than the previous term And like I said, now that we've done that we want to do the same for the VRP MIP, which really, as you can see, it's RC8347. I don't know of any XN accent implementations but there's also some things to change in that as well. There's also a may have change in that as well. There's also a MIP, which is very old, too. I don't know if we'll change that Won't be me or doesn't. I can say that. Next slide So here's the problem we have. Yang 1.1 as defined in 7 as defined in 795, doesn't allow identifier names to just be changed in revision because you know that would not that would be a non back compatible change so the way that you do it is you're supposed to deprecate the old and add the new and then sometime in the future you can get rid of the deprecated ones. Well, the problem I have with that is, you know, the RFC cycles aren't that quick. We have had some, we have had some ones, at least in LSR, go through real quickly when it's just, you know, opposite cycles aren't that quick. We have had some, we've had some ones, at least in LSR, go through really quickly when it's just, you know, procedural changes. But I'd rather do it in one cycle Anyway, that's why I'm doing it. So there's three alternatives to this One is the brute force approach. That's where you do the two iterate You do it the way it was meant to be of deprecating the old identified and defining the new and keeping them both in the Yang model for at least, you know, one revision"
  },
  {
    "startTime": "00:14:00",
    "text": "cycle or one, you know, probably a couple years or whatever. And then with the new RFC, you take out the old ones The other one would be, this was one we have years or whatever. And then with a new RFC, you take out the old ones. The other one would be, this was one we, I had some talk and I at least had one Ops AD on board with this you just change them. You say, okay, we always said, Nyang, we can make bug fixes that are NOMCOMpatible So what we would do in this case, we would treat the non-inclusive language as a bug fix And the third is in this case, we would treat the non-inclusive language as a bug fix. And the third, this is an interesting one. I thought about updating this is to just define a new Yang model That's the old name, actually what this was supposed to say was I IETF, VRP, hyphen 2 You'll see that. But anyway, so it kind of you kind of just, you know, you kind of, you know, bring the mountain to Mahat see that. But anyway, so it kind of, you kind of just, you know, you kind of, you know, bring the mountain to Muhammad. Anyway, next slide So here I just have you can see the changes I made that, you know, there's a type deaf, there's a couple ideas identities, and the one thing, there are no config true leaves that are changed It's only upstate, but I'm unfortunately, next slide I guess I should have taken the question a clicker. It would have been easier on you, Jeff. But anyway I will survive. Okay. The one thing, there is a notification which, you know, if somebody did implement this and we found that, you know, you take taking it out would be definitely not backward compatible because it uses the new identity it uses the current identities and uh this and we found that you know you taking it out would be definitely not backward compatible because it uses the new identity it uses the current identities and and types okay"
  },
  {
    "startTime": "00:16:00",
    "text": "next slide so we already talked about this this is the easy way I mean, not the easy way, but the the way that NetMod has defined to do it of just changing them and keeping the old ones. I'm not going to say much more about it this. And I don't like this one because it doesn't, you know, I'm doing a whole RFC, but I'm not really removing the non-inclusive language like we did in one shot for the actual base protocol specification next slide Now this is the one about treating as a bug fix and I got I've gotten mixed on this i had one management ad tell me absolutely you couldn't do this, and I had a previous one tell me, well, maybe we could do this because they're not config There was mixed But I'm thinking this probably wouldn't you know this probably wouldn't be worse the controversy it would be called. And I'm, and I'm thinking back to one time I know right now we were talking about fixing the type death for IP address in in the in the in the types you know the RFC 699 in the Viz document and I advocated okay right now you can specify the default is to specify a zone on an IP address which means the default is to a have like a percent sign and then the name of the end interface The problem I know this, I know that and then the name of the interface. The problem I know this, I know there's a lot of people that use the IETF types in native models. There's at least one major implementation that uses it but if you specify an interface on the end of these IP addresses, the transactions are going to fail Well, anyway, we didn't decide to change these. We kept the old ones and the solution was you change the models, the non-IET"
  },
  {
    "startTime": "00:18:00",
    "text": "models to use the type that it was meant IETF IP address, no zone. So I don't, what I'm getting is I'm not very confident that if we would be worth trying to get non-backward compatible changes through So I don't, what I'm getting is I'm not very confident that it be worth trying to get non-backward compatible changes. Next slide So here's the one I want, here's the, here's the, third and there's a reason it's last. That's because that's the one that I think I'm going to try and do. We just change the name. We come out kind of like Mib 2, remember, you know, Mib 1, Mib two this is going to be ietf brp one that I think I'm going to try and do we just change the name we come out kind of like mib two remember you know mib one mib two this is going to be i.etf b r p hyphen two yang that would we can do it in one shot. We don't have non backward compatible changes i don't know of any implementations of IETF BRP And uh, uh, slide So I actually had, I'd like to proceed with this I actually had just because it accomplishes my goal of doing this in one RFC cycle And I, and there's a public source I mean public source, an open source implementation routing stack that they were talking about. They asked me, what were we going to do on this? And I said, I'll know after the IETF, I think I'm gonna go for it. That's the, the, the, holo rust routing stack Renato Westfall He's got somebody who, not himself, but he's got somebody who, wants to implement the yang model for BRP. So this is the one I'm going to try in got somebody who wants to implement the Yang model for BRP. So this is the one I'm going to try him. I guess we can talk about this on the list. I'll shortly after the idea BRP. So this is the one I'm going to try in. I guess we can talk about this on the list. I'll shortly after the IETF, I'll do the new version that uses the new name and request the new identifiers"
  },
  {
    "startTime": "00:20:00",
    "text": "for the new model from IANA that's it Thank you. And as a working group participant I do support this approach. We want to reduce the amount of bureaucracy and number of cycles As working group chair, we will send to the working group list proposal and go to support and objections Huh? Am I hearing? Yeah, we can hear you Oh, okay, thanks. Hi hi everyone. This is Fan Zheng from China Telecom. You can wrong this place Oh, okay thanks. I'm presenting the update of Young Data Modo for ARP and a new draft of Young Data Model for IPV6 address resolution on behalf of the other authors Oh and the young model has been for presented in routing workgroup like several times as I remembered Since the last presentation was about years ago, we are going to recap what the ARP models cover There are some basic art functionality in the IETF IPO model that allowed you to configure dynamic ARP and static ARP entries"
  },
  {
    "startTime": "00:22:00",
    "text": "So this draft carrying in the extra bits of ARP that are not in IETF IP, but lots of VANDR vendors have supported. Things like proxy ARP configuration, GRADARP configuration, and ARP statistics on interfaces So what do we change this time? Mainly it's been editorial improvements to improve the description in young module and the security section and also yun chung juan to improve the description in down module and the security section. And also Yong Qingju and I have joined as new co-authors And this is the current tree on the latest draft. And it's not changed since the last update update update The Arbyong model has failed the gaps of IPV4 address resolution, but it cannot provide support for IPA since ARP is only about IPV4 IPV4 So the address resolution of IPV6 is covered by neighbor discovery protocol defining RFC 4861, which also covers the functionality like router and prefix discovery And some related functions such as duplicate address resolution DAD is defined in RISC RFC-4862 So similar to ARP, IETFIP has covered dynamic and static IPVC neighbor cache entry on NAC DAD on interfaces, the finding like a lift for neighborhood cache for IPV6, a leaf for its router flag, and a leaf for the number of cost-deductive neighbor"
  },
  {
    "startTime": "00:24:00",
    "text": "solicitation messages with DAD DAD And there is IETF, IPV6 router advertisement, which is the submodule of ID there is IETF IPV6 router advertisement, which is the submodule of IETF Unicast routing, which is really to NDE, but it only comes the configuration of Router Advertisement Therefore, we need another young model to cover the rest of functions of ND that are not covered by the above young model, but a lot of vendors have been supported In this new draft, we define FPV6 young model ID IETF&D to support the configuration of MD, especially about a draft resolution of LPV6 and related functions like proxy and proxing neighbor advertisement. NUD DAD, and NG packet statistics on interfaces This is the current tree of ITIF and D. As you can see, that we define the container for ND for global configuration and per interface configuration, which augments the IETF IP as for a neighbor cache entries, we define style timeout global and per interface It is the timeout for neighbor cache entry in StoState A store entry will be discussed if it's still in stow state after the stow timeout is passed And the node age augments the neighborhood cash list defined it in IETF and IP which is the time has passed since the last eligibility confirmation for the neighbor And the dynamic discovery enabled"
  },
  {
    "startTime": "00:26:00",
    "text": "the dynamic IPV6 address address resolution on interfaces We set this enabler considering the risk of hijacking of dynamic address resolution And as for NUD, we define the node to enable the function on the interface and reachable time for the time that's considered enable reachable after reaching its reachability confirmation confirmation The NAS interval is the interval of retransmating NS messages of address resolution, a new DM and DAD, also known as retranstime in our IFC-4861 The container proxy NAA includes enabled of two different types of proxy The intervillain proxy enables router proxies for hosts in the same subnet with different villains and all proxy in enables the router proxies for all hosts which means the router will respond to it messages with its own NAA all host, which means the router will respond to NS messages with its own an A message no matter what the original target is And last, the container statistic contains the ND packet statistics on the interface and that's all and any feedback and comments are welcome and really help us improve the drafts And we would like to ask for adoption of the IPV6 address resolution Youngmodel draft Thank you draft Thank you. So the UP Young Model Draft was a working group document for long"
  },
  {
    "startTime": "00:28:00",
    "text": "time, but it was expired. So now we have a new editor that's committed to drive boost the work through. So we will continue that work and then so um also add a new job for IPV6 address resolution that I think is useful so we'll try to start working group adoption call for the new draft so please review and send your comments if you have any Thanks Thank you Thank you Jeffrey, do you want to present now? later? Yeah, because I we'll go to the number six instead of five, because Jeffrey need to be away for, yeah Hello this is from Can you hear me? Can you hear me? Yes, we can hear you Yeah, and you have control of the slides Okay, thank you so um Yes, we can hear you. Yeah, and you have control of the slides. Okay, thank you. So, I'm Phongyang from China Mobile and I'd like to share some thoughts on how we are can transform the SRI technology into some network services, some ideas This presentation is by me and chuanfa wang Ling from H3C Uh,"
  },
  {
    "startTime": "00:30:00",
    "text": "why way to this? we have some kind of observation First is that we see two important pieces of information The growth of internet traffic has seen down, and the second IP the SRIPv6 is being rapid deployed worldwide and we are and we China Mobile IP networks has been upgraded to the SRIPv6 last year and we are explored in how to convert SRIPv6 capabilities into service offerings that can generate the revenue. We can see some of the revenues Most of the revenue come from the 2CM to H of our revenues. Most of the revenue come from the 2C and 2H services and some of the revenue come from the 2C is from the mobile users and 2H from the residential users and the 2B is from the business government incomes for but the problem is how after we have upgrades on that network from the IPV6 to SRV6 and how we can turn the technology into some kind of the services because when we cannot because you know, SRIPv6 can only run in the limited domain and cannot be running on the last last only run in the limited domain and cannot be running on the last mile, which is outside of the limited domain So when you can kind of the mechanism to"
  },
  {
    "startTime": "00:32:03",
    "text": "meet this requirement The basic I, basically, I, needed are the traffic classification and traffic steering But for those two mechanisms there are some existing tools we have listed some of the some of the tools existing but all of the those tools cannot meet ours requirement. For example, Q's is not trusted when it carried from the external limit domain and ACL are not scalable and the DPI risk some privacy concerns and the are not recommended because it's only running in the limited domain as well like as SR6. So we need a new mechanism It should be trustable, scalable, and simple, and some other like it can be cross-domain support cross domain So we have some. Would you take question? now or advance of the presentation it's a very quick question a c lindam okay i'm not familiar of this 2b 2c 2 h or advance of the presentation? It's a very quick question. acee lindem. I'm not familiar of this 2B, 2C, 2H nomenclature back on that slide. What does that mean? Okay, to be means some of the network services are provided to the enterprise and government Oh, is that, is that classification? Yeah in industry that I should know? I don't know okay it was just yeah"
  },
  {
    "startTime": "00:34:00",
    "text": "So usually the B2B, B2C and so forth business to business the customer customer to business. Oh, that's B2 not not to be okay. To be are not to be So, so the two C is to the product for the mobile user and to each is for residential users users so we have we have some ideas about about to share share Here we propose our solutions which is called ARN application responsible network maybe the name is not very good but we just call it at this moment moment It is an intermediate layer between applications and networks that encapsulates SR6 networks services applicable to MPRs as well by carrying the ARR has also has an ID which called ARN ID It can be carried in the applications, DOH payload that is destination option header It is provided a data bit plane API interface by Z this Actually, the ARNID, we have the user side ID and the network side ID unless maybe the picture is not not show the show very nice Let's take a look at the overall process"
  },
  {
    "startTime": "00:36:00",
    "text": "and see how Aaron works On the left side, we are I want to talk about how it is allocated In most cases, the first step is first step is network service required network service almost planned in advance with a print network service requires, network service almost planned in advance with a predefined as a slice or passes, which can be associated associated with network RNADs and be configured in advance on edge network devices Step to one of the user subspe to network service such as low latency service operator assigned locally unique user ARNID associated it with purchased network service. The network ARID and configuring it on the backbone network service service services Then I will show how to, on the right side, we show how to use AID So the step three, the user can encapsulate the user ARN ID for specific applications as needed Currently we carry the AID in the DOH and step four, a backbone F device map to the user ID to the network map the user, user, yeah receiving the packet. Furthermore, it will map it to the corresponding network services, for example, slides or the path. This enables application that do not support SFVIX 6 to call the network services"
  },
  {
    "startTime": "00:38:00",
    "text": "Then some of the share about the security and the privacy. User AID are REMD randomly generated for each subscription. They protect user data privacy and the network services are encapsulated where the network AIID invisible to users. That's protect the internal network information from export to outside During the mapping, you have got my pleasure of your user AID Okay during the mapping of user user, to the network ARIDs access control can be implemented such as we can prevent the authorize user we can, we can, we can, we can, authorize the user to do the programming ID So the basic framework is simple which has we have the control and the and the user edge and the network edge services network devices So the user, yeah can be generated by the API application or the user as devices and the network AID and the user AID and the user ID are mapping are done on the network edge devices This mechanism can also support the cross domain interoperability So So, uh, we, we, we, we moment, we have put the air ID into the"
  },
  {
    "startTime": "00:40:00",
    "text": "DOH function, DOH extension handler, and we have three kind of, so yeah one is only encapsules network capability and also the other one is encapsules both of the user like the middle of the right hand middle of the middle shows which both has the network and the resource AR ID resource here means some kind of cloud services and wen lin the bottom right one, that is only for the cloud services without the network services So we have some use cases here because the time, we have runoff time we are not able to go into more detail So basically in this page we have briefly show how we how custom can subscribe the ID and how we can get both of the directions of the traffic can be speed up up And last we are doing some kind of lab test to verify our idea We have several kind of vendors to implement in the devices and we are done this work in this year and the last one in comments that's all all any questions so right now in RTDWC we have proposals for APN ID ARN ID, service ID so I guess we need to consolidate the idea. First of all, figure out whether they are useful. That really, they use case for them and then"
  },
  {
    "startTime": "00:42:00",
    "text": "work on a consolidated solution now all kinds of IDs Thank you. Thank you I've just looked at i mean i just looked at the draft i have to admit i haven't participated in all the discussions. I know there's been BOP also, there's been boffs in something else related that had application in the name and everything. This kind of gone and I'm wondering for what the you know, I just saw the use cases, what is the advantage of this? over just assigning a behavior to a SID? To an SRV-60 SID, you know, the existing? of actually inventing a new indentment? and putting it in the header of every packet So matthew quick answer is that let's go to the first, second page. We have problems at SRF6 that is wrong in the limited domain and we want to change the S to have the SRA to to define some kind of product case selling to our customers So because you cannot run in SR6 on the last mile, which is outside of the limited domain So we need some kind of technology to invoke SR6 pass So then you'd get standard behavior for these A&S or ARNs across, you'd like have, you standardize these, right? That's what you're saying, and they'd mean the same thing to everybody is that what you're saying yeah yeah um joe you are the do understand the difficulty of classifying"
  },
  {
    "startTime": "00:44:00",
    "text": "customer traffic at the edge and you seem part of this presentation seems to be a request for a new field that the customer can specify from the customer CPE to the operator provider-edged router to simplify classification So my first question is, why is that? a field? any more trustworthy than allowing let's say, a DSCP? on that same link? It seems like the exact identifier technology either have the same problems of trustworthiness or I'm missing something about why this works better than the existing identifiers But yeah, look, the as we the reason is that the Q's like for example, DSP does not carry any kind of the user user information You know, all of the DSP is standardized and every value has the specific meaning But we here we have no. DSCP is a sick standardized and every value has the specific meaning. All they still know, DSCP is a six-bit field and there are recommended meanings, but not required meanings Now, if your argument is that six bits isn't enough, that's a real reasonable question, but let me then state the other half of the question. If you assume you need something new to identify what the request is from the"
  },
  {
    "startTime": "00:46:00",
    "text": "user and you have some way of knowing the user is allowed to make this request and you need more values than a DSC it still seems that within your network you could use MPLS SIDS, SRV6, SIDS, or any number of trustworthy technology You don't need a network ARNI to go with it, even if you need a new user ID that relates to AC's question Yeah, yeah, let me have some explanation on this. The first we cannot use SRW6 on this. The first we cannot use the SRW6 SID is because SRI6 only running in the limit domain. And we want to run it outside of the limit domain. Well, but then network, the network ARNID is within your limited domain No, no, no, because because ARID can be encapsulated by the customer but for example I because ARID can be encapsulated by the customer. But I thought you said the user ARN ID is encapsulated by the customer. Yeah, yes, yes but the network ARN ID is not for the customer's use unless you're allowed the customer to direct traffic and that gets you into a whole new set of problems. You add why is NSH not recommended? It's because you can't trust the customer to direct traffic across an operator's network Yeah, yeah. For your network side, because we want to support cross domain that... Do you mean between operators? Yes, please move the discussion to the list we are running out of time it's all valid questions"
  },
  {
    "startTime": "00:48:00",
    "text": "Joel please do you send your questions to the list And it's not only applicable to Iran, it's applicable to all other application ID frameworks and you gave these guys time so I asked them. Sure, I understand Please do send it to the list. Jim Yeah, just to comment, to be honest it was a little difficult to understand remotely what's trying to be done here, but a couple of things jumped out and that was talk about network slides and talk about interfaces from customer to the network And it just struck me that there's a whole bunch of work that's been done in the T's working group that they might want to take a look at unless I'm completely missing the point of the presentation I would really appreciate your reaction on the list and try to address all these questions They've been brought in before with different kind of application layer ideas and they need to be answered before we can progress Okay, thank you Adaptive Have the control of the slides please go ahead. Okay thank you. Can you hear me? Yeah"
  },
  {
    "startTime": "00:50:00",
    "text": "We have the camera Hi. Okay You have 10 minutes, so please stay to the timer Sure Hi, I'm yao liu from Ziti and my presentation is about adapter routing notification for load balancing So, adapt routing is a routing mechanism which makes dynamic routing decisions and changes in network load state And adapter routing can be local or remote for local or better adapt routing after congestion occurs the node decides traffic to be rerouted and it changes pass locally. And the remote adaptive routing is used when there's no other uncongested paths available locally And adaptive routing notification, which is also called ARN, is generated and sent to upstream nodes. That upstream node changes the traffic paths accordingly As we can see, for remote adaptive routing, the AIAI is an important element In this document, analysis on different mechanisms include the information area in how they are delivered into the network Some key points should be taken into consideration for change traffic paths remotely because of the end For local nodes, it should decide which remote nodes through the AIM be sent to. This determines that address of the AIM message For the remote node, first it needs to know which traffic forward remote nodes through the AI be sent to. This determines the address of the AIM message. For the remote node, first it needs to know which traffic for what interval needs to be adjusted. In most cases, the traffic identifiers carried in AIM can help to locate the corresponding forwarding table Secondly, the AI node needs to know which point in the traffic's forwarding table needs to be blocked The information can be carried directly in the AI"
  },
  {
    "startTime": "00:52:00",
    "text": "or indirectly indicated by the ARN Following us on ANN options. For Option 1, the ARN is sent to the upstream node alone the reverse traffic forwarding paths. and upstream IA node treats the ARN receiving port as the original output of the traffic on it. Below is an example Traffic one is sent along the red colored path from S7 to S-10, S6 6. When traffic 1 is received, the traffic identified and the receiving part of it When home S-6, when congenital occurs, and it decides that traffic 1 should be rerouted. S-ZX checks the local traffic records for the receiving part of traffic 1, and then AI for traffic 1 one is sent to upstream node S2 via the receiving port For S2, after receiving AI, if there's other non-c congested paths available, it will block the AIN receiving part in the forewarnings table of Traffic 1. If there is no other path, the S2 should further send AI or PS paths available, it will block the AIM receiving part in the forewarning table of traffic 1. If there is no other paths, the S2 should further send AIV's own receiving part of traffic 1 which means S2 needs to keep the receiving record of traffic 1 as well About the pros, there's not too much changes for the routing and forwarding procedure. And the main cause is that it's a stable solution, needs to be maintained on the local device for every traffic required adaptive routing notification And for option two, the answer routing notification. And for option two, the RN is sent directly to the nearest upstream node that is able to perform AR for the traffic And the original output of the upstream node available to the nearest upstream node that is able to perform AR for the traffic. And the original output of the upstream node of traffic is carried inside AI in this case So when S7 receives traffic 1, since there's more than one pass available for traffic"
  },
  {
    "startTime": "00:54:00",
    "text": "1, that chooses one output for traffic 1 forwarding and puts his device ID on the part ID into the traffic. To S4, the procedure is similar It replaces device ID and port ID in the package with this own. Then on S2, suppose that there's only one outport S2 will forward traffic directly without modify it. So on S6, after congestion detected, S6 would send it AIRN directly to S4 with the device ID and output ID obtained from the traffic and S4 would block the output for the traffic accordingly. In this option, no traffic receiving records is stored locally but the packets of the traffic need to be modified when being awarded As we can see, the AI mechanisms require devices to consume additional resources and AIN is not necessary for all traffic in some networks. For example, the routing smoke flows has not much effect on relieving the congestion compared with sluts. So in this document, AIM tech is introduced The only tagged packets are processed additionally for AI after traffic seeped and AIN are generated only for tagged traffic after congestion So here's the site summary. The definition of adapted role routing various in different contexts So in this draft, adaptive routing is regarded as a fast partial path adjustment mechanism in respect to the this draft, adaptive routing is regarded as a fast partial pass adjustment mechanism in response to southern traffic imbalances caused by now network events. And AI and tech helped to reduce the processing burden on the device"
  },
  {
    "startTime": "00:56:00",
    "text": "due to enabling ARN ARN Next steps. There are still some AIN options on carbon in the document. For example, sending AIN by Microsoft some AI options uncovered in the document. For example, sending AIM by multi-casts, we'll add them in the future version and welcome feedbacks and comments Thank you Sasha Sasha Weinstein I haven't heard anything about loop avoid with this scheme How can it be provided? Maybe I have missed something, but you change routing on the fly for part of the traffic, all of the traffic doesn't matter. How can you guarantee that this scheme is look free? Yes, this is one point that is under analysis in the draft. So when you change it, the remote path at a point, you may cause the switch path still passing through the congestion link and the loop. So, especially when you especially when the network is more than two times But after further, yeah, and the pass adjustment procedure, the link can finally be adjusted And one and option to solve this problem is standing A.N"
  },
  {
    "startTime": "00:58:00",
    "text": "They are multicasts. So, so this problem is standing AAN via via via their Mardiast. So the related notes in the network can adjust it their paths accordingly But you can control the scale of market costs to be considered and not all the network operators want to introduce multipass traffic into their network So this point would be further in the future version and thank you I may have missed something, I'm not sure I understand your response. Let's take it offline on the list Thank you. Okay. Thank you Supporting group participant if the reaction on iran is to block port you'll oscillate. You'll block the next part that will become best past our destination exactly in the same way you create congestion before So it definitely needs to be done per traffic class on the port, not per port Introduce yourself. Yeah. dean bogdanović we have so many QS mechanisms that are not being used So for me, this is just another QS mechanism. And what are the chances for this to get used? really? But so generally, so compared with other Q's mechanism so at least in this document the adaptive routine is seen as a partial pass adjustment mechanism"
  },
  {
    "startTime": "01:00:00",
    "text": "and it can be used together with other load balancing mechanisms For example, you first you can use the network control plans and control the traffic paths globally. Then when the congestion occurs, you can use a debtorality routing to respond quickly by adjust the path. And then the controller made it then make global adjustment, so afterwards So maybe I can further further further then the controller may then make global adjustment so afterwards. So maybe I can further analysis and compare comparison with this mechanical with cues during the future version It would be a good topic to discuss on the list, especially the loop avoidance, the lock avoidance, and how can you use it in a way you don't oscillate between ports creating congestion yet on another path Yeah, thank you for your comments Okay, so this is a draft between, uh, or with our collaboration on several organizations including Kevin one Jeffrey from Juniper, and Chang Wong from New H-C Router info advertisements Some quick background is that backing the last IHF, there were two presentations and drafts that related to this the first one is the draft one idea next next hop nodes where we would consider the next, next hops, the low loading information when you do the low balancing"
  },
  {
    "startTime": "01:02:00",
    "text": "And another one is draft Liu in the passive wear remote protection Basically, they rely on matthew quick notification of remote down links for fast re-roll preparation Draffleu in the passive wear remote protection. Basically, they rely on matthew quick notification of remote down links for fast reroute purposes. In both cases, we require fast flooding of link or neighbor or pass information outside the route protocols So the goals of this is to specify a generic way of doing that flooding, routing information outside routing protocols and make it easily extendable and make it hardware friendly, for example certain information could be sourced or handled in the ASIC, things like that We do not try to refi information as is. For example, if you receive, advertisement from one neighbor you try to reflut it as is to some other neighbors You could consume the information and generate your own advertisements flood to other neighbors that's fine But that is not a concern of this document This document just tries to define mechanisms to do the flooding. We also do not try to specify how often the information is flooded and how the information is returned and used. We just provide a basic message pass So this is basically a UDP-based flooding. We would get a new UDD port. We have the versions number specified here with some reserved bits there and funds flag bits. The main information is encoded as TLVs and authentication and acknowledgement, they are all optional Because this is UDP-based, so fragmentation"
  },
  {
    "startTime": "01:04:00",
    "text": "is theoretically allowed, but it's unlikely to be used because we quite often would want the information to be timely flood and handled so you would just send multiple messages instead of larger UDP message So I'll skip the authentication or part there. It's very similar to how the is done with the BFD BFD The destination address of those the message could be your of these four situations. The first one is the IP for Mauritka's address for all the routers on the subnet or the IPVision one is the IPV for Maltica's address for all the routers on these subnet or the IPV should be sixth version of that. It could also be a low- or remote unicast address and a non-link local multi-cast address so that you can flood the information to a whole bunch of the receivers using the underlying modicast I mentioned that the message body could include a lot of TLV to include the information. One example is the neighbor pass information TLV Basically, you just include a bunch of neighbor records and each neighbor record include that neighbor ID and 8 bits encoded information I will talk about that encoding information later. Similarly, we could have a link info, TLV that includes a whole bunch of a per link record Each link record includes a link ID and encoded information Here the encoding information is eight bids For now we only define value zero. Just to indicate whether the link or passes are"
  },
  {
    "startTime": "01:06:00",
    "text": "we only define value zero just to indicate whether the link or pass is up or down. This is used for the situation where we want to use the remote link up and down for fast reroutes Other values will be defined in the future. For example, it could encode the load information so that you can use it to the low balance considering your next, next hops We need some further discussion and agreement on this. So in this kind of version, we don't encode that information yet but it's should be easily extendable Technology meant, so when you fly that piece of information, you may simply require the receiver to acknowledge you back or you just keep refreshing When you do want to acknowledgement, you just include a sequence number and then the receiver is supposed to explicit acknowledgement back Otherwise, you just refresh and the receiver will just age out the information they receive. The sender can change the refreshing rate either on its own. For example, the information that is flooded, it keeps changing, right? Depending on the changing rate, you may change the refreshing rate Also, it could change your refreshing rate reactive For example, your flooding very fast initially, and then you get a complaint back saying from someone saying, hey, I cannot handle this much. And this is the rate I want you to do Then based on that, you can also check your refresh rate So if agnoticed means"
  },
  {
    "startTime": "01:08:00",
    "text": "is required, then you set a sequence number in your message and the receiver will send back a message inside that message, there will be an acknowledgement TLV including the sequence number for the message that it's acknowledging for And Refreshing, re-notes notification, if a receiver cannot keep up it can send back notification saying that hey please slow down or something like that So that message will contain some TLVs for the refreshing rates notification the the value of the tlv will include other TLVs for which we are requesting the slowdown the refresh refreshment Finally, another use case is that in some, this is, there are some use cases that people are talking about where a router may request its upstream saying that please do not send me traffic for this flow and they could be used for their purposes. So we basically send a five tuple in that redirection to be just saying that, please don't send me for their purposes So this is we're trying to design this as a very extensible and very generic way and we basically you can define all kinds of TRVs to include the information you want to flood the next step for this work is to add security considerations especially when we want to flood this information to a bunch or remote the receivers using multicast, or even Unicast as long as multiple hops away. We have some security considerations, but typically the"
  },
  {
    "startTime": "01:10:00",
    "text": "use case for this is in the World Garden so shouldn't be too bad but we need to need to have some security considerations put in place And also, the how do we address this? the load information that we need to address in future revisions in the meantime we want to get comments and suggestions from the working group and have some discussions and maybe collaborations on this work We do have people in the queue, so yeah, go ahead Hello, Antonro Sanko. I have maybe a very naive question, but when I use define the messages that you are using, I was wondering why you don't piggyback your link stage routing protocol, because it seems a natural extension to link-states routing There are two reasons. One is that quite often those other flooding for the use cases here needs to happen very very quickly. We don't want to buy bother links data protocol with that kind of load. And another reason is that there are some concerns with using Roger Provincial protocol as dump truck. And this is also something that we want to avoid. So this is basically another mechanism that goes on the side of the routing protocols Thank you Hello, Nancom from Huawei Tagalog can you jump to page 12? Yeah, next page No about the flow redirection"
  },
  {
    "startTime": "01:12:00",
    "text": "Okay, yeah I'm a little confused on the user case of this TRIWA It seems not the rotor information Can you explain more how to use this TTI? Does specific use case for this one, I don't know liu chang Wang is here, he can probably explain it better, but at least the design use cases for this is that a router is receiving traffic for certain flow, but it realized that it cannot handle it for whatever reason. He just want to other routers to stop sending traffic this way So he just used this one. Whether this use case is valid or not, and whether we want to put this into this protocol here, that can be discussed But this is at least the one use case that's the people have sought up using this flooding mechanism okay it's a information is flooded to over the network Maybe there are some other tools to install the rule of blocking specific flow. Okay, thanks for your expert explanation. Just one clarification This flooding is not the entire domain. It's basically just flat to your neighbor. Okay I understand. Yeah Okay. Thank you A C. Lindem-Lavin see this is a lot the same of some other mechanism, but it is a little bit different. Is this information? it lasts, is there actually? an adjacency of your neighbors or is there any relationship? other than you save the information or is it kind of"
  },
  {
    "startTime": "01:14:00",
    "text": "stateless, there's no sessions, there's no adjacency or so session state, right? Or is there? um right now it's just it looks like it was just it looked like you know and there's also there's also this thing in lsvr that uh this see randy bush not in the room The, uh, the L3 links State, you know, the Discovery Protocol with uh you know you know that that has all this security and all of its in implementation already done So there's a lot of overlap here of a lot of things, you know and, you know, both ISIs and OSP, if we do have the link scoped LSAs but there is more overhead in them because they are they persist until they time out or whatever you know, it's a, it's like a, it's like a piece of state whereas this seems to be more like, okay, you just tell people about this and it, and they retain it until it changes or until it could be like a one-off too, right? You could tell somebody, okay do something right too correct uh yeah is until it changes or until it could be like a one-off too right you could tell somebody okay do something right too correct it's a lot similar to the isp link local flooding um but uh we don't because this could be, could have could happen very very quickly in some use cases people are talking about mini second level flooding. And we obviously don't want to bother IGP with that Well, you know, some proprietary, there's been some proprietary uses of BFD where they put other stuff in it Yes, we, we, we, we that. Well, you know, some proprietary, there's been some proprietary uses of BFD where they put other stuff in it. Yes, we can see, I'm not, I'm not saying that's a good idea but it has. We are really over time Oh, sorry. Janji TNCCC if better, if you can show some picture about how you're going to set up these things, because only read if better, if you can show some picture about how you're going to set up these things, because when only reading your slides, I don't know how you are going to"
  },
  {
    "startTime": "01:16:00",
    "text": "create those over the top neighbor or adjacency. That will be created statically or dynamically on demand all kind of control play information here sure the two other drafts I mentioned at the very beginning, they sort of expand prices use cases for this, and they indeed do not talk about the remote flooding. I have another draft that is not been published that does talk about the remote flooding. I think I will publish that soon That should provide some example on the remote flooding But other local flooding, soon. That should provide some example on the remote flooding. But other local, local flooding that two other drafts I referenced to earlier does provide some some information So the session or some receiver or some server or whatever things will be configured on a router to receive the flooding information from the center right? Right. If you don't have, you don't have configured, you will not care about the UDP port. Yeah, thank you That's what I want to make it. Okay, thank you. Thank you Thank you general comment, we've been having the fascinating notification frameworks in this working group since early 2000s. They're probably about 10 drafts published of the last 20 years let's try maybe to do a interim and review all of the solutions because what everybody is trying to do is to take your upstream, don't send traffic to me Either send it to someone else or just don't send it to me a variety of solutions that involve control plane, involve just forwarding probably it would be good to do some consolidation and see where we are going as a working group with this And again, granularity is important If you block in another port, maybe it's not a good idea, but then you need to understand what to block less loaded port"
  },
  {
    "startTime": "01:18:00",
    "text": "There's difference between different traffic classes between different queues. So it's much more complex than just block the port somewhere upstream Okay, let's go to the next presentation I will present Hi, everyone I'm Jamim from China Mobile. What I'm going to talk about today is adaptive routine framework First is the problem analysis. In many cases, ECMP flow-based hash may lead to high congestion and variable flow complete time. For example, in the first figure, the link forwarding packet with color orange is more likely to be congestion Besides, due to the lack of congestion awareness, the load on already congested link might be exacerbated, as is shown in the second figure, A3 is unaware of the link to affirm already congested Continue to send packet to A3 It will increase the congestion level of that link Additionally, the current load balance mechanism has no ability to distinguish the large flow from small flows So if there's two kind of flow arrive, simultaneously, ECMP will destroy them evenly across equivalent paths leading to a load imbalance So there are some possible solution to start this problem. First, we can"
  },
  {
    "startTime": "01:20:00",
    "text": "increase the flow intrepate by refining the granularity of load-balanced algorithms such as based on cell package or flow light so that the flow could be distributed more evener Moreover, after perceiving congestion, the device could change the flow character like 5-tapo or IPV flow label to prompt rehash or reroute. In addition, adaptive routing based on networks statement based on network state measurement also could be adopted select the optimal path according to the real-time network condition and this approach also is what I'm going to introduce today So what kind of abilities? does an adaptive routine mechanism? need to have? First, to achieve even low distribution per flow load balance and per package load balance could be performed and each packet perform congestion detection including link-based detection and flow-based detection. Upon the detecting congestion, notification should be sent to the remote devices to perceive congestion at earlier nodes Respond to their congestion notification Congestion adjustment could be performed by adjusted to pass weights or pass loads or by redirecting flows And the pieces on the affirmation analysis, we proposed an adaptive routing framework consistent"
  },
  {
    "startTime": "01:22:00",
    "text": "from four parts, routing plan forward adaptive routing policy, and remote congestion detection A routine plan is responsible for the transmission and calculation of routes besides the local information. Information from a remote link should be included to calculate routes for the global congestion awareness the calculated routes and the remote paths info would be adapted to the forwarding plan. And forwarding plan, and forwarding plan is responsible for pass adjustment based on the mode of adaptive routing and the remote link congestion information and the traffic is forwarded following the adjusted forwarding table Then is the adaptive routing policy It is responsible for dynamic adjusting rules according to remote link congestion information or flow information and adapting the forwarding plan the last is remote congestion detection it is responsible for detecting link congestion and sending congestion notification to neighboring devices So specifically in the routine plan, when calculating routes, the paths need to be perceived, and the pass information will be attached to the NACSO. For the BGP, BGP-based network, remote paths information can be the BGP identifier corresponding to the next, next hop It can also be the BGP AI's path information or BGP route ID For IGP-based network, remote pass info can be the interface information"
  },
  {
    "startTime": "01:24:00",
    "text": "from the next hub neighbor device to the next hub device, which could be the interface in that or the local address of the interface In the forwarding plan, the forwarding table is maintained based on the routing table provided by the routing plan and it could dynamically adjust the weight and the load value of forwarding table according to the local and the remote link quality as well as the payload of forwarded packets and generating an appropriate flow table for flow-based forwarding and the performing a lower balance during packet based forwarding here is some adaptive routing policy specific and adaptive routine policy could be categorized into flow based and packet based adjustment. The flow-based adjustment mode could be further divided into weight-based dynamic ECMP flow adjustment and flow redirection-based adjustment Wade-based adjustment mode is for link level congestion event adjusting the pathways to avoid the congestion for sub-sequiation flows Flow redirection mode is for specific flow redirection mode is for specific flow congestion events. The congestion congested flow is redirect to ECMP link with lower loads and sufficient bandwidth In the packet-based adjustment mode, the load on corresponding link is that dynamically changed"
  },
  {
    "startTime": "01:26:00",
    "text": "Each packet will be sent through the link currently with lattice load load. And the potential out of each through the link currently with lattice the load. And the potential order of issue within the same flow is resolved on the application receiving side and for congestion control congestion detection perceived congestion events by monitoring a link buffer bandwidth and Q size upon congestion, send congestion notification to neighboring devices The notification information can be off to tab past information, 5-tapo information of the congested flow Here are some examples of their three adjustment mode In weight-based adjustment case, as is shown in the figure, when they four advertised, the network segment 20.1 with Moscow 24 to 20.1.2 to 20.1 with Moscow 24 where BGP to all spans the span will advertise their network segment with the next, next hop 8.8.8 Then a forwarding table will be created on Leaf 1, like the top right diagram and it contains the remote pass information With Spine 4 detect a change in congestion on the link Spine 4 to the 4, the information including detecting node of Span 4 in congestion on the link Spine 4 to lift 4, the information including detecting node of Spine 4, congested the link Spine 4 four one minute to go okay congested link, spine 4 four to live for and congestion level will be notified to its neighbors after"
  },
  {
    "startTime": "01:28:00",
    "text": "they've received this notification, it will look up the local forwarding table based on the past information and reduce the weight of corresponding for forwarding entry from 25 to 10 according to congestion level. By the process, above, the new traffic will be forwarded in updated properly and thus ease the congestion Here is the example of flow redirection mode The first line is the characteristic of flow, and if this flow caused the congestion and the spine four will notify congestion even to neighbors with past information and the flow feature after Live 1 received this notification, it will increase the load of corresponding forwarding entry from 10 to 100 for example, according to the congestion level. Additional, locating the corresponding flow table based on the congestion flow information, lift one will read redirect the congested flow to the list load paths, or maybe from span 1 to lift 2 2 Here are the examples You're over time Your overtime, please finish up. Okay Oh, here are the exam of packet-based adjustment cases, so the same forwarding table, same can congestion event, and the same notification is sent. After receiving notification, lift one load"
  },
  {
    "startTime": "01:30:00",
    "text": "up the local forwarding table based on the pass infer and increase the load of corresponding forwarding interest from 10 to 100 according to the congestion level. Therefore, the subsequent packet will be, we prefer to choose non-contradition passes That's all my presentation. Any questions? Done Yes, then, will you back, Canada? Did you think of a way to support that? once the flow move by congestion? like having some kind of a way to trace it for the people supporting the network? Is it part of your initiative? Because I haven't seen it in your document I guess not Thank you. Thank you Hongi you are next And Hongi from Huawei You mentioned several times adjusting pathways or pass loads And so what's the difference? The weight is the ECMP weight for the weight-based adjustment if the link is congested it will the neighbor will adjust the adjust the weight of the link and the load means the remaining bandwidth of the link. So if you lower the, if you"
  },
  {
    "startTime": "01:32:00",
    "text": "increase the load of the link and the and the will not be forward in that heavy load pass so the load value is set manually it is not detected by some mechanisms It is adjusted according to the congestion level and the congestion level is determined by the congestion point I think we need to move AC please it's way quick I'm an AC Linda Moll Lundum 11. I was just going to say there's been other drafts at this IETF about how to handle per packet ECMP, but this draft just made, this framework just makes the assumption that the big flows can be done per packet and the problem is pushed on the application of packet reorder but if the flow is that big that means it's an awful lot of reordered packets that they're going to have to do. I don't think, I think that handway isn't going to work. Maybe we should move that I think we should take it in any way and please do remember, if it's a data center your RTT is five to ten nons the second. By the time, BGP sends a update with updated weight, you jared mauch Pascal congestion. You are completely dead or free, right? So your control loop time is crucial here and i don't think any control plane in general would be capable notifying upstream nodes. There's a congestion, right? We're talking about orders of magnitude timing Next presenter"
  },
  {
    "startTime": "01:34:06",
    "text": "Okay, and the chapter about the framework for him Okay, thank you. Later, the chapter from for the framework for implementing postless techniques in wide area networks So first it is abstract and this document proposed a comprehension framework to adjust the challenges of efficient variable, and cost-effective large work is abstract and this document proposed a comprehension framework to address the challenges of efficient, variable, and cost effective large volume date transmission over WANs. So the framework for on the planning and managing traffic paths network slicing and utilizing and utilizing motto-level network buffer and then I will give the instruction in the last ATF 119, we just have highlighted several critical large data transformation use case and that we emphasize the necessity of low packet laws and high throughput in WANs such as scientific research financial transactions, and multimedia content delivery So we think the character at the requirements of large data transmission. And I listed as follows. First of all, we think the characteristics at the requirements of a large data transmission. And I list as follows. First one is the large volume and the data sets involving these transmissions often reach terabyte levels. So and the prices need large volume broadband dedicated line for the large data transmission. But it's very exciting so the enterprise must be balanced in need for high capacity date transmission with cost consideration and the second is the timeliness and time need for high-capacity data transmission with cost consideration. And the second is the timeliness. Timeliness is a critical factor for data change"
  },
  {
    "startTime": "01:36:00",
    "text": "transformation over WNs, such as genetic research. Delays in data change transformation can render data for data transformation over WNs, such as genetic research. Delays in data transformation can render the data obsolete, leading to incorrect results and conclusions So timelessness is high-capacity broadband for the large data transmission And then the third character of statistics is the predictability Due to the predictability, we can planning and managing traffic paths It helps in optimizing resource allocation, minimizing congestion and enhancing overall network performance And so due to the characteristics and requirements of large volume data transmission, we have some challenges But the first one is the limit the first factor is the limit net capacity and it leads to the traffic conflicts, which may result in cooling and jetta the second one is congestion hotspots, so we always know the packet transmission it will leads to latency and reduce the network's throughput. The third one is the inefficient buffer utilization Local devices buffer common met diversity traffic It may result impact loss Fishing the challenges we propose the solutions as a follow The first one is the adapt planning and the management of network resource We can allocate network resource based on shirley net network information So we can do the full things I'll do the three things. Network resource reporting and user request Network devices report attributes"
  },
  {
    "startTime": "01:38:00",
    "text": "such as bandwidth, latency, and buffer capacity we can salute control plan protocols like IGP and PG report attributes such as bandwidth latency and buffer capacity and we can salute control plan protocols like like IGP and the PGPS. The second one is the network resource allocation and policy distribution. Controlers calculate out IP-based dedicated lines just like the IPTunnels with the segment routing within within the one domain based on a variable and flexible bandwise and buffers. We can use in the sr policy data traffic is there into the epitonels at ingress nodes and directly to the dedicated network slicing The third one is a network data measurement and telemetra. We need a real-time resources measurement based on measurement packets, which helps the sensing utilized, and very available resource on network links And this second solution is the use and management of the motto level network buffers us. We can advance the congestion management strategy, which are necessary to coordinate buffer information amount of devices across network. We need a need three things First one is the single device buffer sharing and management. This is the promise of the Bava coordination, initial Bava resource information can be managed better controller or exchange through the control plan protocols like IG and BGP. The second one is the correct buffer coordination, initial buffer resource information can be managed better controller or exchange through the control plan, protocols like IGP and BGP. The second one is the cross-device buffer coordination given the nature of large data transmission a single device buffer might be in sufficient for absorbing burst traffic Therefore, multiple device buffers of the same fine-grained type"
  },
  {
    "startTime": "01:40:00",
    "text": "e.gid, the same priority and slice. Should be used to collective So in the technology, we should differ control signal and the triangle conditions for buffer coordination and the third one is also the net networks, the measurement and the telemetons Here we will measure the buffer sides Okay, the third one, the third one is the requesting source data control. If a network device comes to solve the congestion problem itself, we should use it one is the requesting source-rater control. If a network device can't solve the congestion problem itself, we should use the solution, network devices can send the rate control request to the source where data packet marking or separate control packets Okay, finally we give the conclusion, the proposed framework adjust the challenges of a large volume date Transmation over wines, we can use the enhancing traffic management and resource allocation strategy and the efficient buffer management The framework ensures efficient arrival and cost effective data transmission So its approach meets the demands of the data data-intensive applications, provide a lower solution for large volume, data transmission in one environment Okay, and that's all, thank you greg mirsky Erickson so if I understand correctly, there are objective of your investigation is to provide bounded latency in the wall"
  },
  {
    "startTime": "01:42:00",
    "text": "packet loss rate. How that is the difference from the subject of deterministic net networking working group? and in leads in our solutions, we focus on the tech deterministic networking working group. In our solutions, we focus on the packet loss. Because the packet effect solutions we focus on the packet loss if because the factor of the packet loss and due to the load throughout and the determination that were and they focused on the latency and the data the determination networking and they focused on the latency and the JETA. Thank you. No actually it's all over the above It's bounded latency low jitter and low packet loss rate So I think that if anything that have you considered discussing this with the data? net working group Okay, okay will discuss data, okay uh i don't understand yes no I mean I just the my solution in our solution and just focus the package loss and just this factor factor I'm going to start clear Okay, so you are saying that you are not considering bounded latency And not direct factor the latency, we definitely always saying that you are not considering bounded latency? And not the direct factor, the latency, we definitely, our direct factor is the and about the throughout and the packet loss okay okay let's take it a little bit Thank you. Okay, thank you"
  },
  {
    "startTime": "01:44:15",
    "text": "Okay good afternoon. On behalf of the co-authorist, I my presentation is a couple of use cases of high-performance wide-era network which we believe currently fair to address the new requirements from the use cases Hussimson Okay let's go back to the first Thank you Okay. Um, when we're talking about high performance to wide area network, it seems because we believe the Yuski system we raised it in the draft in this slide require a higher performance than the band net provided by the current wide-air network technologies because there is a massive digital transmission to shows in long distance to collection such as cloud storage and backup of industrial internet and data and digital twin modeling something like So the industries lead to software the problems such as which may result from long distance to long slow feedback and core screened, note balanced, and no throughput and so on. That's why we record it's a high performance to wider network achieved effective high throughput transmission"
  },
  {
    "startTime": "01:46:00",
    "text": "transmission Okay. We have two sclero. Number one is the distance transmission between two sets. Actually, it could be a mom multiple, multiple sides. Um, said one 1,000 kilometers right here as to the as a threshold, but not exactly, actually the first typical excuse is the high performance computing for it scientific research which should generate to 60 to 100 gigabets of data every five minutes and requiring data transmission from one laboratory to remote science default analysis. And when it comes to distribute, storage, which would involve the moving data from one storage system to another, and it's to maintain the data consistency across the multiple science and the third one was the data expressed service, which requires the data task-based data transmission and point point model and high resilience and throughput with the single data which might be ranging from a terabytes to 100 terabits and the first one is to the multimedia content production that all material data from a large scale we wrote the show or film with the single transmission of data in the range of 10 terabytes to the 100 terabase and so it needs to be transmitted between the data centers with different storage sites And the last one is the data backup in disaster recovery. Working and backup data centers actually is the master's leaf data center. I built in different locations to cause long distance and massive data transmission for disaster recovery A second story is the DC intercollection among the DCs. It's about the collaborative training across multiple data centers"
  },
  {
    "startTime": "01:48:00",
    "text": "In this scenario, it needs to be provided on-demand task allocation to different clusters to sufficient bandwidth and no latency and high throughput and extremely high network availability availability and reliability for the data center and communications. The parameters exchanged significantly increased on this system scenario, so the amount of digital transmission across it data center and typically from tens to hundreds of terabytes The object chiefsman goes to the high-performance-wide network. The primary goal is the effective high circuit transmission, which demands higher performance Number one is that ultra-high bandwidth utilization which needs to the efficient use of the available network capacity, maximize the data transfer rates. And the second one is to the auto no packet loss ratio, which is very critical for the high street code because according to one of our tasks, the experiment of data ending for the high circuit because according to one of our tasks, the experiment that data indicates that for TCP, the circuit would dramatically decrease to up to about 90% with the packet loss ratio of 5%. And the third one is to no nature standard nature The around time negatively correlates with the throughput And gaps for the existing technologies with regard to it latest in nature, the around time negatively correlated with the throughput. And gaps for the existing technologies with regard to the massive data transmission of throughput and gaps for the existing technologists with regard to the massive data transmission over the white data networked. The characteristics for the high-performance wide-air network is those two points. Number one is the massive, any further flows data with large bursts which always would have to co-eat with the concurrent services. And the dynamic flows"
  },
  {
    "startTime": "01:50:00",
    "text": "Because the wider network gets involved among multiple sites, so there's a problem where results from the long distance system multiple hops, and the diversify the past land multiple domains between the DCs And there's the gaps for the existing technologists, when it comes to the optical fiber direct, that direct the collection which uran applies to the sites which the distance between the sites is limited to less than 100 kilometers When the distance is larger than 100 actually the cost will be significantly increased. And the D.C technologies suggest priority flow can And the DC technologies suggest priority the flow control is, it is, it is, there's a slow feedback and the high round trip time latency, and Jeter. So, uh, uh, high-performance via network requires improving the flow control precision When it comes to near street logging technology, network, current network is the passive and unaware of the status of the service. So it requires to coordinate with the end systems to make the fine-grained scheduling of the resource and because the current network resources, utilization rate is quite no, particularly in the wider network so it regards fine green traffic scheduling. That long-distance transmission requires to auto low packet loss and long distance latency in JTURE guarantees yeah that's that's war and we actually set up at the site meeting at Tuesday after long. Everybody welcome And any comments and suggestions"
  },
  {
    "startTime": "01:52:00",
    "text": "suggestions? Hi, dean bogdanović. So, Detnet created a document, RFC 8578, which is the use case for Detnet and they talk about issues that different applications, different industry verticals expect from networks and they are not that much focused on the networking technology as much what certain verticals like multimedia than energy sectors need from the networking what character they're looking for to deliver And this is a document that provides really well well-defined use cases. If you want to take a look for a high-performance van, I would suggest you take a look all the requirements for, I believe there's about nine different verticals in the document that they are talking about what are the expectations on the networks from the networks The other part is that when you're writing some applications and they rely on networks on connections, not all data is the same Some data if you lost the data, can lead to catastrophic events Some data has to be delivered, but it doesn't matter in what time frame And some data, if you get lost, doesn't matter And in none of your presentations, you did any discrimination of the data for different use cases and you can find that I believe also in the 8570 So that would be a good document to consult and then, you know, references and say what you could improve compared to that"
  },
  {
    "startTime": "01:54:00",
    "text": "Yeah, actually, oh, wait strongly believe that net is a good technology to address the requirements of use cases but this is a cost balance we have to take into consideration If we deploy a dead net technologists along among the water network, the cost would be significantly increased. So we are trying to strike the dedicated balanced The cost, the networking cost compared to the, let's say, energy sector loss in case of a catastrophic event is minuscule Okay Hi, Greg Nerski Erickson I agree with uh opinion that this seems to be one of the cases for deterministic networking whether it will use existing solution for the deadnet name probably what you point to that net service sublayer which is using pre-off, well, that's a question but again I agree that for the critical communication or industrial automation, or energy sector loss of data or out of time deliver is catastrophic so you know the cost would be justified but again, I appreciate that you clearly pointed out that your objective is to provide bounded latency, minimal jitter and low tech loss rate, which is exactly the subject of deterministic networks in my opinion. Thank you Yeah Thank you you"
  },
  {
    "startTime": "01:56:00",
    "text": "Hawaii, and maybe similar to previous province. And I'm curious how you define high performance here. There are too many others best to define high performance from I think the term and the title is still a bit broad and feel like HP1 mentioned here is doing everything and so my suggestion is to think of a more suitable word from the perspective of use cases If you want to differentiate from a determinist network Yeah, actually, we will look into the use case system debt networking group but I as co-author of that draft today, I think the use case is raised in this draft quite different from that, but I will look into it. I agree part of the requirements maybe overlapped use that networking group thank you thank you You've got three minutes. My proposal would be to postpone this till Dublin unless you want to go through one slide just to explain what it is Thank you Everyone, can you hear my voice? Yeah. Okay, and before I start I need to make it clear that there are some problems with my IETF account so I cannot log in, so I temporarily buried this account to give a speech Please go ahead with some presentation. You only have three minutes oh wow okay, okay. I'm painful, I'm glad to share this draft for you. OSF"
  },
  {
    "startTime": "01:58:00",
    "text": "framework for AI Network Yeah, for background, let me quickly summarize the background As AI training model gets larger and larger, we find that traditional data center network cannot longer meet the needs of AI. So we need a new set of architecture to support AI network In the furring is simple E.N.R.T.E. Network traffic characteristics and the requirements requirements And in general, AI training may have fewer flus, but most of those are elephant flus with a strong burst. In addition, any link like PIN can have a serious impact on the training task. So AI network needs higher than with higher stability and low latency More details can be formed on the link below to view our draft requirements requirements Here are some typical solutions for law balancing ECM allows for a loss for fast-to-fall about switching by this distributing traffic cross multiple equal cost paths The disadvantage of this approach is that it creates harsh pollution polarization And in OSF can spread data per packet or per cell two every link which is more registered than in tap hash Okay I think it would be a really good moment to stop We are exactly on time and you won't have time to go there. I don't want you really to spend time presenting to empty room. We will give you a slot during next IETF, and so you could"
  },
  {
    "startTime": "02:00:00",
    "text": "go and need us through this My apologies for running out of time. Sure For the working group we are having AIDC meeting on when Wednesday that's in context of routing working group where we've got really exciting agenda for you from Dr. Lophoff and Eddie from Alibaba. They'll be talking about actually some type that's very close to what we discussed here Adaptive routing, what do we do? in AIDC to actually provide capacity? how congestion control might work? And do join us and we plan to have an interim because most presentations are conversion on the same topic. How do we provide notifications? that is high fidelity enough fast enough and doesn't consume a lot of resources to notify upstream notes that there are some events down downstream, either congestion, loss of connectivity, reduced connectivity. So we'll definitely do interior in between ATFs, trying to gather And last comment, try to think into connectivity. So we'll definitely do interim in between ATFs, trying to gather. And last comment, try to think end to end in most of these networks and endpoints run congestion control. That's really high fidelity either it's DCC and based or timely based It usually takes a couple of RTTs to detect there as a failure or congestion or some kind of events so of them are intelligent enough to differentiate between in network congestion versus incust, which is congestion at the last point, so toward the server So in many cases, this is much better place to deal with congestion rather trying to deal with it in the network Those networks are very different than, you know, what we've known before. So again, we'll address some of this during IDC and we'll definitely have a interim to talk in detail of this topics. And thank you everyone, and see you in Dublin Dublin and just pay attention to our RTCWG mailing list where we'll announce the interim date and time"
  },
  {
    "startTime": "02:02:06",
    "text": "Thank you very much. Get him very good No, this stuff is good, you know"
  }
]
