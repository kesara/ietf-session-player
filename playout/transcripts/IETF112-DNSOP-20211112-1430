[
  {
    "startTime": "00:00:05",
    "text": "okay so sorry just a short dry run yeah seems to work tom thanks next slide tom yeah excellent [Music] okay [Music] so welcome do we give another minute co-chairs people are still joining cutting up all my windows so yeah another minute is a good thing okay it's for everyone this slide chopped one a quarter something like that because i atf 11 yeah indeed okay november 202 yeah that was yesterday but it's the same slide deck sorry it's the same slide yeah in my own my own view the slide disc is uh i did it was shown then i made my window bigger now it is better but it should resize probably it's a resize thing yeah it's a slide of yesterday but i will jump to slide 16 in a moment for session two yeah the same as yesterday only less"
  },
  {
    "startTime": "00:02:00",
    "text": "exactly i think we can start with a good crowd welcome for the second session of dinosaur for today 12 november um okay these are the dinosaur chairs myself tim vicinski suzanne wolff warren kurami is the area director jabaroom the same the minutes will be taken by paul paul will use his own will take minutes on his own laptop not using code him or it's now hedge doc i think called but please if you want to drop text use the url here shown codemd or hedgehog of notes it's today it's notes itf.org and we will integrate the notes the minutes okido we assume that you are familiar with the note well and also with the itf code of conduct the short version is be a nice person good any other things well yes agenda for sorry the agenda for today um this is we made a small change um we added with hardiker to the agenda for today after the discussions after the presentation there was quite some discussion on the in the job room on nsec 3 parameter guidance and the chairs and wes luckily thought it was a good idea to continue this discussion also in this session so this is the agenda for today there's the oh sorry i mess up as a bit the ites are excuses itf hackathon results will be"
  },
  {
    "startTime": "00:04:00",
    "text": "presented first by tom then dns catalog sounds by willem and then the guidance of for insect three parameters by wes and then there's the new draft by peter thomason automatic dinosac bootstrapping yeah let's go let's get started tom you can ask permission yeah i will give screen to you all right thank you can you hear me okay yes excellent perfect [Music] all right can everyone see the slides yes thank you even better thanks all right uh thanks i'll uh i will be presenting the hackathon results of the extended dns error response uh test that we did it's uh based on the uh the draft by uh roy schwarzenegger and it builds on extended dns errors um hence either that's how i will be calling it i i'm told roy the writer of the draft doesn't enjoy the abbreviation but uh for now it works um this was the topic of this the main topic of discussion even during the dns op interim meeting on the 26th of october and there it was discussed that would be nice to have a measurement that a what would happen if a authoritative would send a unsolicited eds option to uh in response to a resolver"
  },
  {
    "startTime": "00:06:00",
    "text": "so there was also an email about this on the mailing list so that's what we tried to do um for this we used uh ebbf the extended berkeley backed filter this is way beyond what maybe some of you know is it what was used for tcp dump it now runs in the inside of the linux kernel so it's a restricted uh subset of c is what was used um and with this you can create nice uh server uh name server agnostic or even resolver agnostic programs which you don't have to anticipate beforehand so it's just a drop-in if you will and here linked you see the place where we have a repository for the code so you can if you want to try it yourself uh trying yourself is actually really easy so you clone it initiate the sub module then load the program into the kernel what is omitted here is that you will need to have some dependencies but you know that's fine and then here we show that it actually works so the url we used here is report.intelnetlabs.com um as you can see here because th this is for those of you who like to look at code is uh how we can sorry how we can configure this program that's what i was looking for so we have a report domain which has said is a report.nlabs.nl then we chose the eater code as you see there it's it's the first one for the experimental ones and then we have a sampling rate this was also discussed during during the interim meeting that would maybe be nice currently we tested with"
  },
  {
    "startTime": "00:08:01",
    "text": "100 but maybe other other tests could be done without so for the measurements we used a ripe atlas for those of you don't know it it's uh a ripe ncc measurement platforms it has about 12 000 probes and these probes um you can you can ask them to do a lot of things for here we used use them to dns queries um we have we we asked them to do two either to our baseline measurements which was to neither dot uh anonymouslabs.nl which just got a response back and we also did a measurement to either dot and on the labs.nl which got back a unsolicited option um as you can see most probes participated and uh we used the python program to as you can see that we linked there to process the let results check yes i think of everything all right so what we learned well um about 0.5 percent so 95 resolvers get a baseline but don't accept the unsolicited message then you can see a lot of resolvers there this is mostly due to that um the right measurements uh right measurement probes uh have more than one resolver in their respective networks so roughly two less than two usually um and then uh the the funny part is on the right here you see is 73 do they respond well to a uh"
  },
  {
    "startTime": "00:10:00",
    "text": "[Music] an unsolicited dns option but don't uh respond to our baseline which we think may be due to just um our margin of error of the internet um but as we conclude here we oh sorry i see peter so peter uh the left circle means the baseline which most of the uh no yeah i said most of the resolvers got back so so that's fine so that's the baseline is good but then on the right you see the part that doesn't overlap that's responses uh that are only from the eater and not from both so so so in the middle there's there's positive to both and on the right there's just a positive response to just our test not the baseline which makes it weird okay if that's fine i'll continue [Music] i see ben schwartz that's the question i'll we'll get to those at the end i think um all right so um we'd like to answer the question would either the adoption of either give operators more confidence to dnsec deployment um we don't know for sure maybe not but we think there could be a missing piece and the missing piece could be something like a driver and dns sec so that would mean it would be something like dmarc maybe"
  },
  {
    "startTime": "00:12:03",
    "text": "so you get the reporting without the failures and you could place a bit in a dns algorithm field uh or maybe somewhere else if other people have other ideas about this um so that you as i say get the failures without uh sorry get the reporting without getting the failures which would be maybe give operators more confidence to deploy it in a sec this would also allow for a quick rollback in case of any other failures really for example packets that are too large so that's been what that has been what we did we link again to the implementation and there could be an idea for a new document driver and dns sec and we would very much like your opinion thank you tom thank you very much i do see peter and ben on the queue peter peace hello can you go to slide 5 please of course next slide all right sorry one more one more sorry i counted actual slice not your numbering yeah in the edness response just above the question section there are two trading zeros is it yes or is the spec unclear about something no no it's a bug so if we go one further you see a um trailing zero in our reporting domain uh we suspect it's that sorry we we we suspect it's that that's a trailing error from us uh so sorry right okay so the spec is clear this it's a book thank you thank you"
  },
  {
    "startTime": "00:14:02",
    "text": "okay okay ben please go ahead hi uh so i'm i'm just a little confused you're sending an unsolicited extension in the response correct why why this was discussed during the interview meeting okay that this would be better than the resolver asking for the reporting agent with the edns option because the this is also sent to the dinosaur mailing list by roy irons he said that authoritatives are more likely to not respond well to an edna's option that they do not know about than that resolvers are to getting a unsolicited edns option okay so it seems like the intention half of that it seems like this data provides half of the test we need for that right because the other half is is to run the the opposite test and send uh send a nonsense no sorry if the baseline measurement neither that does not provide the insulated option and either does provide the unlisted option right so strangely enough there are also responses which are received from resolvers that only send the elicit unsolicited option but you know i think that's just the when uh the error rate that you would normally get from any measurements so so i would have confused there too it seems like there are more clients that are unable to reach the eater endpoint than there are clients that are unable to reach the this right non-eater"
  },
  {
    "startTime": "00:16:00",
    "text": "endpoint so that's correct a positive error rate right a positive impairment of accessibility yeah um so we we can't say that it's safe to do this you know in some absolute sense no that's true but it's only like 0.1 percent or something if you calculate the uh the error rate which is already there but zero zero one percent sounds pretty high to me yes but therefore there's also the sampling rate right so you don't have to send the unsolicited option with every response it could also be like on five percent of the responses or something okay anyway that's also true in the in the client to authority in the resolver to authority direction the result the resolver could could tag only a a small percent of queries yes yes that's also indeed that would also address the uh the the case that not all authoritatives would respond well to unsolicited or unknown easiness options yes okay yeah so i would like to see see that tested too especially since it's uh as ray points out that behavior would be clearly out of spec thank you thank you for your feedback uh yeah i closed the queue i saw victor and peter also want to join the queue but given time we have to continue with the next presentation please continue the discussion on the mailing list and yeah any other any other means willem please so the next presentation is on catalog zones willem"
  },
  {
    "startTime": "00:18:01",
    "text": "i'll give you permission okay okay yes so dennis catlock is a method for automatic dns zone provisioning among dns primary and secondary name servers by storing and transferring the catalog of zones to be provisioned as one or more regular dns zones so what does that look like on this slide there's example catalog zone so it's simply a list of zones listed in the catalog zone called member zones on the slide is an example showing what it looks like they are enumerated with uniquely valued labels in the zones section in the catalog zone as pointer records the example on slide uses the domain name catson but that name is actually free to be chosen one could consider something below a reserved tld for example such as infill it the picture shows a primary and its relationships with secondaries so the catalog zone cat zone is distributed along these relationships and from the catalog zone the secondaries learn that they should serve example.com example.net and example.org so what's new since version 2 we introduced the terms catalog producer and catalog consumer to describe everything more clearly in the draft producer generates the catalog zone and a consumer processes it produces and consumers do not necessarily"
  },
  {
    "startTime": "00:20:00",
    "text": "align with the primary and secondary relationships for example in this slide you see that there's one machine producing two catalog zones for one the blue one the producer is also the primary and the consumers are the secondaries and the other catalog the green one is generated by the same producer but the primary is not a producer so other sets of configurations are possible it's nice that we have four authors of open source name server implementations working on this task and discussing the dwarf because the resulted this this resulted i think in the most permissive and generate way to handle and implement catalog terms for example we no longer have text on optimizations that are consequence of predictable rnas the organization of the current draft has been geared towards describing what the catalog zones looks like what the basic operations are and how they work adding a zone removing his own migrating his own zone state reset and how catalog consumers should deal with occurs such as member name clashes and member node name changes memozones can have properties version 4 of the draft has more uniform and consistent description of how properties may be defined properties from standard documents are always one label below the zone member"
  },
  {
    "startTime": "00:22:01",
    "text": "we described three such properties in the draft which are optional and i will go over them quickly in the coming slides implementations or operators of catalog zones may also define their own properties below the lamp label xt which is itself one label below the zone member name a property described in the draft is the coup property c-o-o or from the change of ownership and it allows for controlled migration of a member zone from one lock to another and in the example uh you see that the coup property of the catalog zone catzone signals that it's will be migrated its member example.com will be migrated to the catalog other cat zone so the consumer has the member name catzone of in catzone this is the unique id a so to say associated with example.com the zone is then not migrated yet but after the consumer receives an update that adds example.com as a new member of autocad sound it knows that example.com came from catalog catzone it knows the associated member name unique id a so it can look up the coup property and see that the migration has the catalog catson's consent that's so the the whole operation can be performed rather stateless which is nice this is actually how uh the power adenos implementation handles uh catalog zone"
  },
  {
    "startTime": "00:24:02",
    "text": "migration so if if the member zone name in the new catalog is different from the old catalog then the zone associated states such as certain data and the essec keys and whatnot is reset if it remains the same that then it's migrated to the new owner as well so note that the old owner has control whether or not the new owner will receive this state because it can add the coup property and change the member name at the same time instead of having one set of configuration per catalog zone the group property which is also defined in the draft allows to have more different sets of configuration in a single catalog in the example on the slide example.com is configured to be signaled to be signed with insect3 and example.net is configured to not be proficient with dnsec this allows for atomic change of configuration of member zones and it fits well with not concept or not dns concept of templates and also nsd's patterns then we have another property the serial property is not the the uh are not synced in oh with me talking yeah that's that's true it's so easy about that so i have notes as well okay yeah so this was the group property by the way so it's you know the atomic config well what i just said the serial property"
  },
  {
    "startTime": "00:26:05",
    "text": "is another property defined in the draft its intention is to increase reliability of certain updates because you know if you have a large number of secondaries and a large number of sounds notifiers might get lost on the internet or secondaries might be down and not receiving the notifies and it's also the intentions also to reduce the notify and sarah query traffic if you have lots of secondaries and lots of zones so how does that work [Music] well so the serial number of the member zone shower record is in the serial property of that zone then if there is a update of the catalog zone with a new serial number the the consumer which might be a secondary can then fetch the zone because it knows that it has a different solar number than what it's already serving uh no netify is then needed also if the catalog zone is fresh and then it may clear the refresh timers for the member sounds so this property is optimization built built upon catalog zones and it's not dealing with the catalog itself so that might be a reason to not have it in this document and to split it off to a draft building upon godzilla zones i don't know i leave that up to their work group we also updated the security section it now"
  },
  {
    "startTime": "00:28:03",
    "text": "makes very clear that the administrative control over what zones are served from the configured name servers shifts from the server operator or the consumer of the catalog to the owner the producer of the catalog zone content and we have a other edit peter thomason he contributed text and ids and did a lot of work on this kitchen so he's a arthur nato so this version of the draft is the result of thorough review and discussion with the goal of getting it in shape for publication as rfc it has catalog zones specified to the best of our ability and we request you to review it thoroughly with the documents witness for working group lost guymind and that's it you can now answer questions thank you willem i see peter peter van dyke in the queue well not actually a question more of a comment wes do you want to go first go ahead i actually said no you should go ahead well actually let me i do have a clarifying question so in your example slides you used uh real looking tlds at the end of your of your zone and in the document you use dollar cat z uh one of the things i worry about is these will leak because it's the dns and everything leaks and so what are you actually thinking for naming records on the left-hand side of your records with respect to that so are you worried about uh the the the cat sound tld that he used in the examples on the slides"
  },
  {
    "startTime": "00:30:02",
    "text": "right so in your in your slide examples you didn't have dollar cat z is no that's right i wanted to use uh actual real looking examples but that's actually right yeah right with real looking examples i'd be very tempted to require something under like dot arpa or something like that that we can you know black hole or something because uh you you will end up leaking a new tld and that would be yeah i agree or dot infill it or something yeah i'll update the slides how about recommending that people use names they own for their catalog zones yeah or maybe both you know we could have a recommendation saying you either have to own the the the name of your uh catalogue or use a reserve top-level domain yeah so something like that sounds good hi um paul speaking um i just wanted to say that i'm initially i was really skeptical about catalog zones and being too much of a oh you know put configurations into the dns thing because we're dns people view um but since then i have started deploying this and i'm really super happy with it um i can you know run different different vendor dns software without having to muck with configuration files and different syntaxes and i think this will really help diversify name server space where people can easily run multiple name servers so i just want to say kudos go on make it better thanks victor please go ahead i didn't see i didn't see a discussion of the sort of security of the transport stuff how do"
  },
  {
    "startTime": "00:32:01",
    "text": "we know the catalog zone that is in the draft i didn't put it on a slide but it is in the it was already in the draft for a long time so we recommend to use private transport like a transfer over tls and also use our dedicated channel with t-seg or otherwise all right have you considered signing these zones because one could imagine putting a trust anchor right on the receiving side for these zones and then validating content signatures and all kinds of stuff is that reasonable or is that crazy i i don't know uh yeah yeah or maybe if you're mv or something yeah then you could have hierarchical distribution because you can trust it from the origin i don't know if that's a useful idea or not but anyway i don't know but it's interesting to consider yes thank you thank you willem thank you authors of catalog zones so um it's close to working group last call right here there's some work to do for you for the working group please review this document this version and certainly when working group lost call uh you're kind of obliged to have a re review the document um i think you also because it's already in use by some of well some of the vendors already put this to use and i think there's also feedback from users we just heard from paul wowter so please uh well that's good and um what's else is there still interrupt testing going on"
  },
  {
    "startTime": "00:34:02",
    "text": "yes yeah okay that's still going on but it would be so so we have uh i think this document is ready yeah you know so uh it would be nice to have a review uh while we're doing interrupt testing excellent okay we'll ask the the working group to do a review interrupt testing and then we can go for working group last call and have again a review by the working group and move forward thank you very much um yeah next is wiz uh i know you want to run your slides your own but you can also use the shared slides from me to echo but you prefer requests to share oh sorry yeah yeah yeah i do see you all right all right uh here we go so yesterday was that just yesterday i've lost track uh it was actually a very fruitful con conversation i um i'm notorious for deliberately putting up things that i that i expect uh people to be against so yesterday was no small it was definitely in that case so i want to try this again today is a little bit different today i actually think based on conversations on the mailing list and on the discussion yesterday that we may be at a good point for really wrapping this up with some text that i will propose at the end so based on discussions yesterday and based on the list we know that we want zone publishers to move to iterations equals zero i think there's a lot of consensus around that not today we know that we want validators to start enforcing lower counts and that serve fail is better than insecure because insecure allows takeovers and surveillance at least"
  },
  {
    "startTime": "00:36:01",
    "text": "denial but we want to do all of these at a reasonable deployment rate um it's not an instantaneous move that we've made a lot of progress in in part thanks to victor's reaching out to a lot of people um but you know this reasonable deployment rate is not going to be immediate and it's going to be large so how do we get from where we are today to you know accomplishing these goals so we want zone publishers to move to iterations equals zero uh so this is my recommendation for how to modify the draft so this proposed text uh this is uh you know actually a suggestion by paul hoffman that i made a little bit stronger and it's in section 2.3 and it's in the middle of a paragraph so some of these are a little bit hard to read out of context but i'm i'm really trying to propose essentially text that will go in uh we won't do wordsmithing live but nsec mitigates this concern and if insect three must be used then it should have an iterations count of zero basically and so what i want to hear today is is there anybody that can't live with this text we'll discuss uh in a second you know timelines but but you know this is zone publishers really should do xero i see nobody in the queue so that's a win all right so how do we get to b and d so b is we want validators to start enforcing these lower counts and how do we do this at a reasonable deployment rate uh so for this we're going to steal text from propose from petter thank you and it will go in section four that says uh really talks about timelines right so as of november 2021 setting an upper limit of a hundred iterations for treating a zone as insecure is interoperable without significant problems but at the same time still enable cpu exhaustion attacks and for this reason validating software vendors are encouraged to continue evaluating insect 3 iteration count"
  },
  {
    "startTime": "00:38:00",
    "text": "deployments and lowering their default and acceptable limits over time so it puts it on the shoulders of both software vendors deploying releasing validating resolvers as well as operational staff although i don't really put that in there uh i should probably add operational stuff paul paul one paul on my screen number one so i'll pretend to be pull one so normally at itf in in rfcs we don't actually put things like expiry dates in there so and that's a good reason for that because we don't really know or can predict what the future deployments will be like so that we internally have something where we say um we'll get back in november 2021 and we'll reevaluate based on measurements done by people like victor is great but i don't think there should be anything in this in the document we have a dns guidelines document that tells you what to do what not to do that one should be regularly updated if you have this versions and that's where this text should appear but not with dates so this isn't a time this isn't a deadline right this is where we are today and it's the starting point for what people might want to consider um i recognize i actually was hesitant to put this in the document too for exactly that reason that rfcs don't typically have history in them um so i will take that as a is a complaint from paul that he would prefer not to have it i guess paul you're still there any follow-on oh so yeah i'm still there sorry um yeah i i still think we should not put dates in there that the only updates on on rfc documents are the ones from the publication date well okay how about as of as of the this publication right we actually have done that in a number of places um you're right that the hard date's probably but that's already implied if you if you put in a shoot or a must and the document gets published and that's"
  },
  {
    "startTime": "00:40:00",
    "text": "the date you have like i don't think we need to put date for smithing into inside documents okay paul two just a quick question and i'm not sure i've been following because i'm busily taking minutes i thought you said earlier that this suggestion was going to be to go to nx domain but um in the second line here you say for treating a zone as insecure right so right now right now the insects i just wanted to make sure that that was intentional a thousand times that's cool okay great thanks the next slide we'll talk about that uh can you hear me yes okay good well one option would be to take the first paragraph and either move it to appendix and say well this is the history appendix blah blah blah or just delete it because you know the second paragraph stands on its own you know the vendors have to evaluate what's actually feasible to enforce at any given point in time and you know adapt the defaults they ship to current situation because that's what vendors do anyway so i mean but i really think this is bike shedding because it's not setting any expiry date it's saying at this specific point in time the situation was this and this i don't see any future prediction in the in this two paragraphs so i don't really see the objection okay so i will note before you leave that um if we delete that first paragraph we're deleting suggesting the upper limit of a hundred right um so which may be okay right that still it still leaves it up to vendors as to what to do victor"
  },
  {
    "startTime": "00:42:01",
    "text": "uh one possible solution uh is to just remove the date and say that validator should use a limit of 100 or less and then you know with the less being based on paragraph two and just immediately recommend a hundred uh as a as an upper bound for the upper bound if you like yeah but if you do it should then that that limit ends up kind of looking like it's hardcoded forever and that's not what you're trying to say so we might be able to do that carefully i should say you should use a limit often you know no more than you know uh yeah i i i see a point i don't know but that's an option just to recommend it as and then say it lower if possible okay now sorry uh a little bit time keeping so not contributing to the disco i think we all agree only this is a little bit worse smithing so maybe we can take that to the mailing list because uh yeah sort of yeah the traditional the traditional answer at this point is please send text yeah but the main thing everybody agrees kind of the approach but we have to be yeah yeah all right thank you sorry so the last one uh is sir fail is better than insecure and so um we talked about this yesterday so the text i'm proposing this this totally needs wordsmithing so let's not wordsmith this at all i sort of put together late last night after not enough coffee again but similarly because treating insect three with a high iterations count is as insecurely zoned subject to attack validating software vendors are further encouraged to lower their default and acceptable limits for returning serve fail for large iteration count values and again we have text about dates and maybe 500 is a reasonable starting point based on the discussion on the last slide i would argue that last sentence we should just drop entirely anybody have objections to that first sentence especially being put into"
  },
  {
    "startTime": "00:44:00",
    "text": "the document as our path forward yeah uh so peter did want to point out on the in chat that um are we talking about operators or vendors and it's this tandem thing where um that's always a problem i i think i will try and put in wording to talk to both operators and to um to vendors that's a good point better and then i think we'll quit just a quick note from a vendor because because vendors have to do some defaults and when it breaks by default users go to vendors and cry and that's the reason why we try to establish reasonable values that's it i mean of course operators are free to patch the software or pay vendors to do something else but this is about defaults right everyone can change the software any way they want yeah and some in some documents in the past we've also put things like this must be configurable you must provide a configuration hub and we haven't done that in this document so all right um i believe i don't even know oh and then i haven't proposed appendix but i think we can do that on the list um and again that's from paider all right i think we're done [Music] thank you very much uh we do have oh sorry let's go ahead no just that um i think we've done all we can here but please take it to the mailing list and send text because we want we want this to be right yeah victor you you want to add something since peter cox is in the audience i'm curious whether you know he has any issues with you know reducing the cctld iterations to zero i notice that uh de is currently one of the ones that's uh sort of slightly on the high side [Music]"
  },
  {
    "startTime": "00:46:05",
    "text": "okay please go ahead peter sorry that didn't work yeah we do hear you now oh thank you apologies for the delay um yeah while i cannot comment on on victor's question to to probably to the extent that that would please him my um or or be sufficient um my concern is this approach of of driving this through by way of standard so um that's that's what makes me um speak up here um i think i understand at least part of the goal but there is a slippery slope in in sliding into into a compliance game that we that that the itf usually doesn't engage into as and which is why i made that remark uh enforcement is is a bit of a strange concept when when actually the mantra is that there's voluntary adoption of standards if you're seriously if you're seriously mitigating a security risk then that's a different issue but then that is probably something that ought not to go into a protocol standard but rather be dead within it in a different way and i'm and i'm missing those signals and again apologies for not straightly responding to victor so this is a security standpoint and we need to document it as don't do this in implementations anymore right we're functionally modifying how you should implement insect three but we'll let the chairs go on we can take everything else to the list thank you thank you wes thank you peter victor uh peter do you have a short"
  },
  {
    "startTime": "00:48:03",
    "text": "remark i saw you in the queue but you disappeared no okay i just wanted to say that yes it is such a security issue but west was faster so i disappeared from the queue okay thanks thank you and then we go come to the last presentation automatic bootstrapping by peter peter thomason uh peter please go ahead hi yes i just requested sharing the screen do you really want to share screen yes um entire screen share all right hope you can see my screen do we have a hard cut off at the half hour uh not exactly but i think after five minutes the room will be closed but uh okay so we'll just speed up a bit and that's fine yeah um so i'll be talking there's no problem i'll be talking about authentic um but automatic dns bootstrapping so putting in the s records into the parent um by means of authenticated signals from the zones operator i'll explain what that means so um today when you bootstrap your dns sec delegation you have to somehow get the ds records to the parent there is various ways for this often involving the register the registrant which is complicated doesn't even know dynastic exists and all this and all of the different methods um have some downside at least one of being unauthenticated um like cds from insecure or out of band or being slow things involving multiple steps for example registrant and error prone too many parties no automation and so on um especially the authenticated workflow involves too many steps so you started the dns provider which has the key material usually the registrant fetches it through some web interface then goes into the registrar then there's epp too"
  },
  {
    "startTime": "00:50:01",
    "text": "many steps and it takes forever and the more direct steps are currently unauthenticated which are the dashed lines um it's promising to consider the pull from the dns separate directly but as i said it's not secure for bootstrapping although it's in-band which is nice and the goal of our proposal is to add authentication here so that you get something that's automatically immediate and doesn't require state at the parent um the solution we propose is to transfer trust from the dns operator i'll explain what that means so first thing you need a signaling mechanism from the dns operator what is that so the goal is to allow unit operators to publish arbitrary information about the zones they host and do that in a way that is authenticated and per zone and then obviously the question is how it can be done and the proposal is to use the namespace under each nameserver's hostname for example underscoreboot.ns1.dcko in our case of our name servers and then require dean essec on those names so that records are validatable that requires the name servers to be in secure zones and then under this namespace announcement can be made under some owner names which are zone specific once you have this mechanism you can use it to publish an authentication signal you start out with the cbs and cd and sq records at the apex of the target domain of the customer's domain and you just co-publish them under that signaling namespace and under the signaling namespace it will be signed with the ns zones keys so that's from the operator you can validate that um so you can as a parent you can fetch the cds records as usual from the customer's target zone from your child then validate it against this using dns and if that's successful um you can provision the ds records in the parent that's what we call transferring trust from the pac from to the target domain and you should clean up records when you're done to make sure there's no"
  },
  {
    "startTime": "00:52:00",
    "text": "clutter hanging around there's a visual representation of this which is i guess nice to have let's start out with dotnet and dot com dot com is where the example dot com customer will reside and dot net is where the provider has a host name for its name server which is securely delegated now when the customer books example.com it's usually not secure and at that time the dns provider will add cds and cdsq records at the example.com zone our proposal is to co-publish them identically under the name servers domain under supplements of that and sign it there and then the parent can come query the child domain validate against the signal from the operator and put things in the parent zone so we use an established chain of trust on the left to take a detour and as a result you get bootstrapping for dns delegations which is authenticated immediate and resilient against non-active against active on wire attackers um there are a few technical considerations um i would like to point out so first of all there is no collision with a conventional use of cds and cd cd and sq records because those live at the apex only while we propose to put them on subdomains of something so there is no collision the draft currently also proposes to hash the ancestor labels for example example dot hashoff.com.nsf um this avoids hitting length constraints and has other implications too but it's a point of contention um and i think it would be great to get the working groups input on that so we can either do that after this presentation or maybe on the list i also have slide on that separately so um hang on and there should also be an extra label before the names have a host name here it's called underscore boot so that you can delegate the signaling data to a separate zone"
  },
  {
    "startTime": "00:54:00",
    "text": "the precise name is to be determined this naming scheme allows putting things in the separate zone so you don't accidentally touch your name service ap records you reduce the chain on the name server zone which you don't have to touch all the time you can delegate bootstrapping stuff by parent if you want for example you could delegate the thing um and you could also provide a discovery mechanism for example if the zone uses nsec then dot com parent for example could start an ansigwark at hashoff.com.provider.net and then start bootstrapping all the children which are configured on the name server um it may be interesting to know how realistic this is in terms of practical outlook so there are two deployment requirements one is that the nameserver targets are not part of the same zone because then you can't establish this this chain of trust because you're going to catch catch-22 so in bellywick doesn't work for this but john looked up a few numbers for us and found that baileywick only has less than a percent prevalence in common.net um so that should be fine probably also for other tlds and the nameserver targets need to be in securely delegated zones so question is how frequent that is and we did an analysis from the tranquil top 1 million data set and we looked for all insecure domains which don't have currently a validation path um what the name server targets are and if those are in secure zones when you have that you can compute the number bootstrappable zones which is where all the nameserver targets are secure but the domain self itself doesn't have dnsc yet so um by looking at that um we probably could have done better we had a bit of a failure rate we should have retried more maybe but we got almost a million domains five percent of which are currently um secure which is"
  },
  {
    "startTime": "00:56:00",
    "text": "just a cross-check seems in the right ballpark um and interestingly about 25 of those delegations have all name server targets in secure zones so that's a good sign and if you consider how many domains have this property of all name servers in secure zones and at the same time the domain isn't secure yet itself and then you get that around 22 or 23 are bootstrappable which is a very uh i think inspiring finding we also brought this down by um top level domain and by provider um so you can see for example that of the dot com domains 23 are bootstrappable which is 120 000 and the numbers are not as large obviously but still i would say significant for other tlds and then by provider we looked at the um the name server zones soar name field and if there is [Music] if this was non-ambiguous then we put it here and you can see that cloudflare for example has 250 000 domains amongst the top million 76 of which are bootstrappable um so that's around 190 000 which is also a number with high potential impact here's the slide on um whether we want the hash label or not i'll first talk about um what are the pro arguments because it's currently in the draft and i want to explain why it's in the draft um i have personally no stakes at all and it would be inappropriate obviously as i will also uh say the the against arguments but only afterwards so i guess please hash please um are the arguments for hashing um so it helps staying within the limits especially length limits and number of labels limits so you get a more predictable number of octets you expand on the the ancestor that may help reduce number of edge cases there is also an ambiguity if you have um a domain for delegation with multiple layers like multiple labels like food.bar.net and if you have a delegation here at bar then there are cds records which show up"
  },
  {
    "startTime": "00:58:01",
    "text": "for that delegation itself of the bar.net underscore boot zone and that could be ambiguous because it could also signify the bootstrapping records for bar.net which is different and there are some other implications of that and i would like to probably take this particular point to the mailing list then it also improves privacy during discovery um because um to do an insect walk you need to know the hash of the parent uh so if you have some private enterprise domain for example nobody would reasonably be able to do an insect walk if they don't know where to start um and it gives you a flat structure which may simplify the scanning logic if you for example know ahead of time that you only have two labels here in all cases um and in case um so that's an idea i just had i don't know if that's reasonable at all but one could say that one should have a more general signaling mechanism so it's called underscore signal not underscore boot and then the specific signal would be specified as a prefix just like the properties for the catalog zones we underscore cds for example and um yeah so in case you would have multiple prefixes like in the case of srv records or something it would be better if if um the number of labels here is pretty predictable but it's just a thought i'm not saying this is a very strong argument counter arguments are um to smash the hash and um so obviously it has complicated implementation all cooling needs to be able to hash makes debugging more difficult you can't just use dig you need to get the hash somewhere and also i think most notably it was pointed out that synthesis is more difficult if you have a hash because imagine a request comes in for example.samh and you would like to dynamically serve cds records for that you somehow need to look up what the corresponding target domain is from which to take those records so you need a mapping but you need that for the ancestors only so probably the number of mapping entries you need is few so you wouldn't"
  },
  {
    "startTime": "01:00:00",
    "text": "need it for example that's the order uk you would only need it for co2k in this case also for those who like um let's say a special fetish for weird implementations you could probably do this with a dname record i know there's implementation problems so it's a half serious um idea it's cashable but per parent so it wouldn't be much of an extra performance penalty um yeah so the question is whether the benefits justify the added complexity so what now we have a signaling mechanism of zone specific information from the an s operator to the public it's authenticated in banned immediate and requires no third parties um we propose to use it for authenticating cbs and cdnsk records some people have expressed interest and i think the potential is quite high given the numbers i showed earlier and perhaps there will be other uses in the future um for multicenter key exchange for example there was an idea um we need to settle on the naming scheme to hash or not to hash that's the question and um if that's something that the working group would like to get involved with and finds it interesting then we would be glad if the group considered adopting this draft thank you thank you peter we are right on the end of the of the session excuses oh sorry um still i want to give the opportunity to give feedback people from the room victor please go ahead fantastic work let's adopt it uh without the hashing okay thank you so it was also on the mailing list uh oh sorry paul please go ahead as i saw your name yeah you did the wrong but i did the wrong button i'm sorry um i also just"
  },
  {
    "startTime": "01:02:01",
    "text": "want to say um because i've given a lot of comments about the small bits of the proposal i did not like um let me just emphasize as well that the majority of your proposal is awesome and i think we should adopt it and continue with it okay yeah yeah i did see feedback on the mailing list so there's interest in the working group i also hear support in the working group here live so peter as you might remember yesterday i'm not sure you were able to attend to the opening of the dinosaur session we did yeah we okay so we we are accepting new work and i will switch on my microphone so we are adopting new work uh but uh in a controlled way so um the chairs will reach out to you and uh given the work we are now finishing completing and uh sending to the isg for review also new work is adopted uh you are you are on the shortlist but again uh yeah uh we will discuss it with the chairs and with you and making uh yeah estimation of amount of work and work and manage the work group load suzanne tim sorry peter you want to add something not really i just wanted to thank everyone who chimed in on the hashing discussion because that's obviously the most valuable type of feedback okay thank you for your presentation and your contribution suzanne please sure um just wanted to say thanks to everybody and just remind people that we had tried a couple of things with reporting more to the working group and running interim meetings between ietf week meetings and those seem to be successful and helpful to everybody so we're going to continue to do those things and watch for"
  },
  {
    "startTime": "01:04:00",
    "text": "questions about proposed dates and proposed agendas for the next interim yeah indeed thank you i would like to thank you the working group for your well positive discussions really good i really enjoyed the sessions from today and yesterday please continue discussing these issues on the mailing list and also excuses we're running out of well four times four times four minutes uh beyond the time well time slot we were allocated so it might clash with your agenda excuses but again i think we had a very good session thank you all see you at one of the interims we are planning uh in the next month and for the next itf 113 bye"
  }
]
