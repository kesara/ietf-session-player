[
  {
    "startTime": "00:00:05",
    "text": "he pointed out that if I hand this directly to Adrian he\u0027s just going to turn around and hand that the something to the people in this community it\u0027s any good right yeah so he said why\u0027d you just run it through - I see an RJ you know so maybe I should just you know propose we adopt it you know it\u0027s just something I\u0027m running doing any just how every that\u0027s a good question for Colin I don\u0027t think so I would say just I can just produce they produce an offbeat you can say it looks just you know I\u0027m pointing out that you know this is a check point and then we\u0027re you know as Thomas proposed we\u0027re maybe border you proposed but we just write a new you know a new RG level learner picture yeah and we can just reference this as prior work because we\u0027ve done I think we\u0027ve gathered enough it may be just copying what working before you do it but maybe there\u0027s actually no need to do okay good morning please find your seats we\u0027re gonna start soon right so it\u0027s ten o\u0027clock and then I think it\u0027s not that early so there\u0027s no excuse to be late okay good morning this is IC energy welcome to Singapore these are my coaches Bowie woman and day for Ann and I\u0027m their coach oh and before we start so we have an updated note well note and so it\u0027s important to be aware of that so first of all so that this one hasn\u0027t really changed but so you\u0027re still expected to let us know if you introduced IP our CIP are in the presentations or discussions yeah second the IRT F is also following the IITs policy so for privacy and could of conduct so check out these two our C\u0027s here and talk to the Ombuds team if you have any concerns or questions and so finally we\u0027d like to remind you that this is the internet research task force so we are doing research here we are generally not doing standards although "
  },
  {
    "startTime": "00:03:07",
    "text": "sometimes we use the same methodology so we do drafts and at some point our C\u0027s quite often the goal of the work that we do here is just to enable additional you know experimentation people enable collaboration on certain topics but it\u0027s really not about producing standards check out this my RTF primer if you have questions on that okay so yeah I see energy as all the other groups has a mailing list a web page data tracker page and so on and so for this meeting now you to say kindly agreed to take notes thank you very very much it\u0027s not the first time the materials uploaded and this is the agenda for today so it\u0027s you can see it\u0027s it\u0027s pretty packed so we didn\u0027t have a full day interim yesterday because we just had one in Macau so we\u0027re going to talk a bit about that as a summary I\u0027m not going to read through all of this right now I\u0027m just asking around is there any update and you do wanna bash the agenda anything we missed okay so then let\u0027s get started so we had this interim meeting in Macau in September after the ICN conference there so the conference and also our highest energy meeting was kindly hosted by the University of Macau so thanks a lot for that and so we had a kind of interesting agenda so often we use these post conference meetings to do a deep dive on uncertain interesting for example paper presentations that occurred at the conference or some some in-depth technical discussion and so let me just give you a quick summary of what happened here so Jeff Berkeley and and and Tim actually organized a full-day workshop before the conference that was called touching the future Internet and that was at the took place at the School of Creative Media at the city in Hong Kong and so this was about yeah creating new ways to deal with distributed multimedia and was a specific tool touch designer and NDN so the the background is that so say in the old days when we "
  },
  {
    "startTime": "00:06:07",
    "text": "when we were doing like like video which I\u0027m streaming and so on I mean mostly concern was like linear video and he thinks well actually today they are much richer ways to interact with multimedia so for example in this say multimedia presentation environments or theater environments where Jeff works you are mixing constantly mixing different sources and so on and so the idea that Jeff and his team had or to provide a good networking support and could api\u0027s for that and so they actually integrated in the end in a commercial tools or touch designer by a canadian company called derivative and so gave this to designers or researchers in that space and so for experimentation and that was a really cool workshop and Jeff gave us a summary so check out his slides from the interim if you interested in that shank did an update on I see an open I\u0027m not gonna talk about this now because Thomas is talking about this later and Chang also talked about quality of service for ICN in the 80s so there\u0027s a draft in IC energy about these ideas and so that team also had papers and demos at the at the conference and so in general the idea is that while QoS of course has a long history in the IP world and in ICN it\u0027s quite interesting to revisit qsr because actually you have much more resources to control so you can actually achieve you know better control maybe a more fine granular qsr control and you also have things like the ICN naming approach so you can actually also maybe be a bit more expressive about classifying flows and so on and so especially in the constrained IOT environment it makes a lot of sense to look at resource control quite carefully and so this work at a case where they wanted to support really critical IOT communication so like life-saving alarm signals for example and so they looked at you know what can you do in an isolated fashion on one node so how you deal with the different resources how you can you can relate the different say ICN forward resources on one note but and how can you also distribute the coordination in a larger network so with that I think "
  },
  {
    "startTime": "00:09:09",
    "text": "that should be a good teaser for you to check this out and then we had a discussion about ICN and low-power long-range communication so Laura in particular so you\u0027re probably familiar with SE lo pan develop I\u0027m working and I see energy or 6lowpan in the in the ITF and so and low-power wide area is a bit different so it\u0027s also very constrained very low-power but wide range and you connect well something to something like the Internet in the end and so you don\u0027t have this gateway more than necessarily and turns out that our different communities in the larger ICN space have been have started looking into into Laura because it\u0027s quite quite interesting so for example we had a presentation from the Hong Kong Applied Science and Technology Research Institute a stream and they are developing in a ndn based system for a smart water meter collection in in Hong Kong and so had talked about their prototype implementation and so they are their ideas on that and Peter kids man from from riot invited the team gave us an update about the Laura support in in riot so there is a proprietary code by Centex so the basically inventors of the Laura Phi protocol and so that that\u0027s integrated into riot but riot is also working on a bit more elegant implementation of Laura into there the general networking stack so basically Laura is supported quite quite well and right that\u0027s good news for people who want to do experiments also ICN experiments in that space and so after this kind of more presentational ancient discussions we had a in-depth discussion about some design opportunities or designer alternatives for doing ICN in Laura or over Laura and so I\u0027m not going to repeat this right now so we probably continue this and we\u0027ll be able to tell you more about this in at the Vancouver meeting if you\u0027re interested in participating we just used the icy energy mailing list so please contact me or command use the main list okay and then finally Christian shooting gave us an interesting update about his thoughts "
  },
  {
    "startTime": "00:12:12",
    "text": "about push based communication so push it update to and so if you have been here before you maybe you remember an earlier presentation we talked about the general idea and so the motivation to four is doing like a hand only push communication and so this time he had some more information about say some protocol design ideas I don\u0027t think I would do a good service in explains because this takes more time so I just refer you to the presentation and okay so that was a quick summary about the Macau interim and with that I am I think we should start with the regular program can you bring up the slides yeah is if you have any questions on the McCowan room let us know okay and so the first presentation is will be given by Dave on on the flow Balance ideas and so this is a little sorry I\u0027m little tall here there we go so those of you who have worked with Indian or CCN like protocols know that an inherent property of those protocols is that one interest message produces one data message and you get this property of the overall system called flow balance so this talk is about some characteristics of flow balance that are desirable versus undesirable and how we might make some small changes to algorithms and protocols to improve the performance of a flow balance based flow in congestion control scheme so this draft has been around for a few months haven\u0027t gotten very much in the way of comments on it so we thought it might be useful for me to sort of bootstrap the discussion by giving a talk so the outline is basically I\u0027m going to give a short background on flow balance and how its congested how it\u0027s connected to congestion control algorithms sort of like the baseline bottom line issue which is whether you\u0027re counting interest messages or actually counting bytes as one would do in a classic congestion control algorithm and end with a protocol proposal for how we might enhance both ndn and CCN X in order to do a better job of this next so one interest produces one data which has some very nice properties including the inability of a node to just inject data "
  },
  {
    "startTime": "00:15:13",
    "text": "into the network because if there isn\u0027t an outstanding interest for a piece of data any data message that sent in is is is allowed to be and likely to be dropped the second point is that these messages at the at layer 3 were up where the ICN protocols run are bounded by a level a layer 3 MTU not a layer 2 MTU and in the case of n ta andn at least in theory that l3 MTU is essentially unbounded because the designers decided for some reason which I don\u0027t want to go into because it will start me on a different rant that the MTU size is a TLV value which means you could can at least in theory have gigabyte m2 use or petabyte m to use if you you know if you want to wait around long enough in practice this is limited there\u0027s a compiled in upper bound in the nd and code base which will wind up being an architectural constant I suppose and that\u0027s for K bytes for CCN X it\u0027s a fixed size field so the maximum theoretical l3 MTU is 64 kilobytes same as UDP or TCP in the IP world so if if the problem you\u0027re trying to solve is how do you fit this into the l2 and to you you need fragmentation protocols in the case where the l3 and the N or 16x message is bigger than an l2 em to you I\u0027ll probably screw up right okay so what\u0027s the problem here the problem is is the small data objects in terms of constructing your ICN level data packet are inconvenient for a number of applications because the natural object size you want to deal with is larger than a link MTU so things like video frames are larger than an MTU various other types of say row of a database table or any number of data structures are larger than an MTU on the other hand you also have applications with very small data objects such as voice over IP audio data frames which can be as small as 20 bytes sensor readings which conceivably could be even small or you know 2 3 4 bytes and if you don\u0027t know how big a l-3 data packet coming back at you when you issue an interest is how do you do the resource allocation in a reasonable way what people have been doing if you look at the existing resource allocation algorithms that have been implemented and and measured they make very conservative resource allocation decisions and assume MTU size packets at least l/2 and to size packets and in some cases even l3 and to you size packets and then there\u0027s some per packet "
  },
  {
    "startTime": "00:18:13",
    "text": "crypto overhead in terms of how much you have to hash on every packet and what you include in the packet in the absence of manifests which makes things bigger than you might like to this is equivalent to the how do i size a data packet when I put it into a VPN tunnel because I might you know the native data might fit on the link but then I add the extra overhead and I\u0027ve spilled over and I need fragmentation so why don\u0027t we solve this whole flow balance problem with fragmentation there\u0027s a bunch of different fragmentation schemes I won\u0027t go into what they are you can do end to end you can do hop by hop you can do hop by hop with cut through any of these things but the bottom line is that this doesn\u0027t actually solve the flow balance problem because you still have to allocate buffer and link bandwidth at each intermediate hop because the stateful forwarding and you have to set that aside for the maximum size objects because if you don\u0027t do that you it this is similar to the fragmentation problem in IP you\u0027re going to get congestion collapse on overload because you can\u0027t put any single thing back together again in a reasonable way so here are some design considerations that led to the scheme that I\u0027m proposing here so you once some means to allocate link bandwidth for data messages with an upper bound larger than the path MTU and a lower bound lower than a single link MTU you want to at least handle moderate sized objects and I sort of took the you know the C CNX view of the world which is it\u0027s unlikely you would ever want to have an l-3 MTU greater than 64 kilobytes as opposed to really big ones and finding the right trade-off if you allow really big ones between handling a large number of small objects or a small number of large objects if you look at the math that\u0027s very quickly an intractable resource allocation problem you just you just have no idea what to do and in many of these congestion control schemes resources are allocated for the returning data packet based on the arriving interest not just waiting around waiting for the data packet to arrive in doing some kind of tail drop or aqm scheme on the data so that means it\u0027s really useful to know when an interest message arrives how much data you expect to come back based on the arrival that interest message so the solution is actually super simple you just add a TLD to the interest message saying this is how big I expect the data coming back for this interest message to be and you use that to calculate bandwidth allocation for the return hop instead of just counting oil interests equally so that\u0027s super simple only it isn\u0027t so there are a number of problems here one is well how do you know the size you know what are you putting the interest message well in a lot of cases for a lot of applications this is actually pretty easy right for sensor or other Internet of Things applications the data is instrument readings these are known by the applicant their fixed size they\u0027re known in advance by the application protocol "
  },
  {
    "startTime": "00:21:13",
    "text": "and you can just you know tell the l3 you know this is temperature reading is four bytes long right in video streaming the information is also available ahead of time in the manifests these are the application layer manifests which contain the names of video segments and their sizes and also for the audio so you have that information at the application layer as well and then the case for something like VoIP almost all the known vocoders have fixed size frames which are negotiated at the start of the session so you know before any data is exchanged whether you\u0027re you know if you\u0027re doing LP kelp you know they\u0027re going to be you know somewhere between 10 and 20 bytes per sample all right but that doesn\u0027t cover everything sometimes you don\u0027t know right and what if the consumer has to guess so we need to deal with consumers that guess and if you allow consumers to guess you need to deal with both honest consumers and malicious consumers so the second problem if you have if if if the user is guessing or something that you thought you know what you was right was wrong the data could be a lot bigger than the estimate and if that\u0027s the case the data can result in two things first you can get unfair bandwidth allocation where you\u0027ve allocated resources for for this much but this much comes back so in the worst case you can actually amplify congestion by sending back a lot more data than you\u0027ve allocated the resources for so you have some number of choices here I won\u0027t spend much time on them you can forward it any way which is safe if you\u0027re not congested but that\u0027s unfair and unstable when the link gets congested you can forward the data when the links uncongested but suppress the interest and reject it when the link is congested or you could say well you know people miss estimating their nefarious characters so if you if you ask for too much you just drop the data as a way of punishing the user for the Mis estimate but if you\u0027re going to do that you need some kind of feedback though and you\u0027ll notice that in the protocol proposal that I\u0027m making there is a an error code that can come back on an interest if you drop the interest or their data coming back due to due to the Mis estimate being too big so the next problem is well the inverse problem the data is too small so you don\u0027t cause any congestion by overestimating the size of the data coming back but resources get inefficiently allocated because not all the set-aside bandwidth is actually used for the returning data so there\u0027s some things you could do here too one is to well let\u0027s just ignore this problem um because you know you if you\u0027re doing stochastic resource allocation on the return link somebody will get to use it any way you could account for the usage according to the larger data size that "
  },
  {
    "startTime": "00:24:13",
    "text": "somebody could have said and then you\u0027re sort of penalizing people in the domain of their flow control for that Mis estimate or you could attempt to adjust congestion control parameters around this it\u0027s a little too more detailed for the talk here look at the draft for that and then problem number four the one that always rears its head in any of these architectures like Indiana and CCN which is interest aggregation because multiple interests can be aggregated at the same point and what if one of them says the data is 10 kilobytes and the other one says the data is you know 64 kilobytes what do you do how do you how do you manage this and again the draft has a bunch of possible approaches to this I won\u0027t spend much time going through the details here just read it in the draft there\u0027s some reasonable approaches to deal with interest aggregation here by the way anytime you try to do something clever in either nd an or CCN you\u0027re gonna run up against huh what am I going to do about interest aggregation so we see this in the quality of service discussion between ant later as well and then of course you have malicious actors you have people who are intentionally overestimating they decides with the goal of preventing other users from using the bandwidth so or consumers intentionally under estimating data size and the goal is to sort of have the interest processed while other aggregated interests are not processed so you can have one users interests interfere with another users interest denying them access to the data so the simplest approach here very much the one I recommend is this is effectively an interest flooding attack deal with it the way you would deal with any interest flooding attack there\u0027s some more sophisticated things you could do but there\u0027s some additional computational cost in terms of tracking the state necessary to distinguish a malicious Fermin honest use of the scheme so from a protocol proposal point of view this is really simple there\u0027s a proposed encoding it\u0027s a single new TLV you stick the expected data size in at CLV and the interest message it goes along with the interest message any forwarder can look at it and use it in order to be able to allocate ban with for the returning data based on a byte count which is what most congestion control algorithms would like to do rather than pessimal E or stochastically based on I a assume them to you size and that\u0027s the end of my talk thank you ok thank you to people if any questions going once how many people read the draft yeah ok that\u0027s probably all right so the goal I have here is to have you find the sufficiently interesting or scary one "
  },
  {
    "startTime": "00:27:13",
    "text": "way or the other that you go read the draft then you tell me how stupid the ideas or how wonderful the idea is or what we should do with this going forward Thanks ok you can just keep sending that and we continue with slick all right this is a complete change of topic so I\u0027m going to talk about an update to a draft that has been around pretty much since Genesis you know the creation of Indiana and CCN which is a method for for doing manifests which are ability to describe collections of ICN data objects so the background is that this has been around for a very long time the design was done I don\u0027t even remember probably 2014 sometime like that around the time the CC next one dot o Christian shootin for CCN light came up with with an early version of this that\u0027s how it got the acronym name click and in terms of the protocols were dealing with manifests are useful in in Indiana in the sense that you don\u0027t have to use them you could put everything you needed in every single data packet but they\u0027re critical in CC NX because c c NX is heavily biased toward not having all the state that you need to process a data message in each individual data message but assume that you can get the common pieces of information through an aggregated data structure like a manifest so the examples here are cc NX is heavily biased toward having what are called nameless objects which are just the implicit hash of the of the of the name together with the data it can need it in order to take large objects logical objects and segment them into data packets of various size and it\u0027s also needed if you want to express collections of objects the equivalent of like filesystem directories or database tables so it\u0027s been implemented it\u0027s been around for a long time it\u0027s been in use in real applications for a long time so where are we well the current state of affairs is that the draft expired in 2018 the original authors have gone on to greener pastures pretty much and don\u0027t have time to really do much work on it so I sort of cajoled two of the existing authors to kind of resurrect the work and we had a meeting in Montreal to sort of say hey what how do we get this sort of going again and we got some a little bit of help from some but mark Moscow and I basically said hey let\u0027s just go get this going it\u0027s a critical piece of technology we need for both of these designs so after some work we got finally got a new version of the draft published a few weeks ago so it\u0027s a lie however you say it\u0027s now alive again so some things haven\u0027t changed "
  },
  {
    "startTime": "00:30:13",
    "text": "Flik still uses this notion of a hash group which is a group of object caches that represent individual data packets that\u0027s an ordered list of these content objects that point to either the the native data object at the bottom or you can build a Merkel tree of manifest so one manifest can point to another manifest in a manifest tree that\u0027s all still the same it still has metadata in the manifest that tells you how to interpret the manifest using a relatively simple automaton to traverse the manifest and it also has this nice property which I think is underappreciated is that you can encrypt the manifest using different he\u0027s from the ones that are used to encrypt the data and the reason why this is useful is that mana you may want third parties and intermediaries to actually be able to interpret a manifest to do various types of optimizations without actually giving them the data encryption keys for the underlying data so what has changed quite a bit actually since we\u0027ve learned a lot since in the last year and a half since since the work went idle so the first thing we did is we added this concept of namespaces so that you could really describe how the naming conventions for sub manifests and data objects work right and the prior one just sort of assumed everything was a nameless object you couldn\u0027t have a manifest pointing to a list of entries each of which had a name right so we\u0027ve defined the three namespaces name space opera nameless operation which is 2.2 Hache objects a single prefix which says that everything under the name of the manifest is a lower level on next level hierarchical name component or segmented prefix where every name is unique so you can do all three of those things obviously the first is the most efficient since the stores the least amount of data in the manifest the next one is sort of intermediary where you\u0027re sharing the prefix among the other objects and the last one is you know if neither of those things holds you can still construct the manifest for a random collection of objects so each hash for group when the manifest can use its own namespace so the application and manifest namespaces for where you\u0027re pointing the things can be different from each other the second thing that\u0027s changed is we how can I put this this sounds really different it\u0027s really not all that different but there have been some changes to the encryption scheme I think these are all pretty much for the better there\u0027s no before the encryption scheme had something\u0027s not covered by the encryption and hence various pieces of metadata would leak so we\u0027ve redone the the syntax of the manifest such that no information leaks are since it\u0027s all encrypted under the key "
  },
  {
    "startTime": "00:33:14",
    "text": "that encrypts the manifest and it was done in such a way that you didn\u0027t have to do data copies you can do in-place encrypt decrypt of the data structures in the manifest we removed one piece of flexibility we had which is in the original one you could have different encryption keys in different hash groups of the manifest we decided that was unnecessary complexity got rid of it if anybody is using that we\u0027d like to know because we\u0027re gonna take something away from you and now there\u0027s only one encryption key for the for an entire manifest our manifest tree we specified in detail how you do pre shared key encryption and group key encryption for the manifests group key encryption is probably the most useful for a data structure like this in terms of processing the keys and the actual encrypt decrypt that turns out that they devolve to the same underlying code that you need to make it work and we added extensibility mechanisms so both the encryption mechanism and the key location mechanism for getting the keys to decrypt the manifests are extensible so we can add new key location capabilities we can add new encryption schemes second thing that\u0027s changed is we\u0027ve enhanced the metadata so the manifest metadata is sort of completely refactored it\u0027s in different places in the in physically in the data structure than it was before allowing both direct and indirect subtree hashes and now the the way manifest metadata is handled is exactly the same between the node level which is for the whole manifest and the hash group level which is for subsets of that we added a general extensibility message mechanism so if there\u0027s any manifest level mech and metadata you\u0027d like to add to something hints about video coding if it\u0027s for video objects or hints about time series semantics of sensor data ratings something that\u0027s application specific you can put stuff in the manifest rather than having to go out and actually fetch data objects for the application in order to discover those sorts of things we also add a metadata on the pointers in the hash groups so now you can have annotated pointers as well as plain pointers and the annotated pointers allow metadata and extensions on every pointer so a good example here which reflects back on my previous talk is that you can put size information on every pointer so that just by parsing the manifest you know what to put in for example one of these expected data size things when you go to fetch something you can also use this nicely if it\u0027s a linear data object like a large file you can use this for seeking because once you have the manifest you know the length of everything and you know where to go to get a particular byte in a linear data structure you can also do hints for traversal order if you have a "
  },
  {
    "startTime": "00:36:15",
    "text": "video application where you would like to fetch things in an order different from the order in which the encoder produced them decoding hints and all sorts of other things so it the only thing we\u0027ve added to the actual spec is the size extension for annotated pointers but it\u0027s extensible you just register tlvs so number of miscellaneous changes locators which are names that are topologically sensitive we can have multiple names for the same underlying data based on a manifest these can now be an array as opposed to just a single locator so if for example you have a set of data that you want to name with a manifest then you want the names to allow you to stick producers in in the infrastructure of multiple service providers such that the actual names are routed topologically with the service provider but still maintain all the security and keying of the application you can do that there\u0027s a lot more detail on the draft that\u0027s expanded probably to twice the previous size there\u0027s a lot more explanatory material and we now have a Python implementation which is not exactly the whole draft but pretty close so we we\u0027ve added to the implementation enough - for you to start working with it there\u0027s still a few things to be done we\u0027re not quite ready to last call this we intend to do some more work between now and the end of the year to update the two implementations and get the python implementation up to date we\u0027re missing an eye on a consideration section which is just mechanical stuff that we need to register things and we don\u0027t really have a security consideration section which is in fact the big problem and that is sort of like needs to get get written so we\u0027re done thank you cool thank you our students questions questions so look at this it\u0027s really important actually don\u0027t want to build applications for these things right so yes as Dave mentioned this is really a critical piece of work and so we\u0027d like to publish it as one of our specifications next year if you like if you thought this was a good thing we did send a thank-you note to mark Moscow because this is not his day job yeah right so we as chairs we really like to encourage people reading this draft and so if you are working on any ICN implementation please look at it very carefully would be great if you could even consider implementing it so again it\u0027s it\u0027s a key piece of technology it it can do much more than you know just enabling the use of collections it\u0027s all cut out to be a your tool of supporting "
  },
  {
    "startTime": "00:39:16",
    "text": "a better cooperation between notes and the networks as they\u0027ve pointed out so it\u0027s would be good to have more people looking at this okay thank you so next is Zhang Hao giving us an update about the name dilution work the second from the left it\u0027s the right [Music] [Music] please stop your video streaming right now we need the bed with four slides sorry about that they stood some progress and I think I had this before we like this morning science hmm I\u0027m sure not it may be real open one more time [Music] that\u0027s best maybe the best way know what the clicker work we move the clicker to your machine as well but the network is finance must be the other trouble okay this is for update on a nurse document I\u0027m Jonah from a tree we have a to talk mint on NRS one is the design guidelines from NRS in ICN and the other is the architecture considerations of ICN using an RS and the first one has been the title of the first one has been changed it from the requirement to the design guidelines we haven\u0027t discussed the "
  },
  {
    "startTime": "00:42:17",
    "text": "according to the requirements for a long time but last among it last meeting in Montreal we have updated and changed it a title to the design guidelines and we asked for the RG last comfort post document in Montreux and we have we got some comments through in in the mailing list and I just copied the Davis comment for the two documents and the person on the design guidelines the technical comments may require a second last call but the other architecture consideration documents there are some technical and editorial comments but those are those can be dissolved without without requiring a second call and these are a scoffer bulls document the first one design guidelines focuses on the NRS itself as a service or as a system in ICN and it provides the LRS overview and LS functionalities and anesthesia guidelines as well and security considerations and the other one architectural considerations focus on things related to the ICL architecture so it describes a how I see an architectural change and what implications are introduced within the ICN routing system when NRS is integrated into ICN so when you look for the and iris example you have to see the first strap and but when the second one is a related ICM but is focused on the ICN architecture not the eyes and iris itself so these are the difference of the two document and we added what we added in the introduction across explanation of the two documents which was the comments from day and for the design guidelines document we tried to adjust all the comments from tables and I\u0027m very sorry that I haven\u0027t send out the how we address how how we address the comments by the mailing list but I explained me a little bit for now and then I try to send that out as soon as possible during thirty\u0027s ITF meeting so please look please take have an intention on the mailing list and give us a good comments as well and we mostly accepted and agree with our Tabas comment but discovered content discovery technologies we he did suggested change "
  },
  {
    "startTime": "00:45:21",
    "text": "it to the information or a Content request but we change it to her 2d content to recast the routing the reason they actually the the part that content is covering written was we explained how I share Aurora step work actually it was quoted from the ICN research challenge ERF sees in there what is en robin step is one is a lame the first is named as a motion and second is the discovery and third is the delivery but we instead we just copied that those tong so we put the contents in front of the discovery and the delivery but in a I think it made some confusion on the using that along leads of the discovery so our intention was the content to recast the Rory so we changed it and there are some few part that we use the content discovery originally we try to change it all but we miss the two part so we fix them in the next revision and similar comment from the mark he what his comment was it would be good to clarify discovered turn in this document but and he also mentioned the there are two discovery which is in the one is lammle they discovery and the other is content discovery but we consider both because this in this document we try to consider any type of NRS to show the possible functionality of the NRS and but the discovery party is not the main issue of this document as well so we deliver the the Tom and also this discover each terminology has not been defined even in the terminologies document so I wonder if we if it is a too late to edit the Tom the discovery Tommy in the term knowledge or not but we can about it and third one third person\u0027s comment it would be worthwhile to include some reference to ongoing 3gpp work so we stayed in as a short sentence to reference 3gpp work but I\u0027m not sure if I added the right reference he asked for a but I would separate later and there was a various comments but we mostly deflected and I answer and "
  },
  {
    "startTime": "00:48:22",
    "text": "and send out how we addressed it I send up by email this morning and there was a poll on scope and II he gave us a lot of comment which was good but that was a good discussion for ICM but it was a little bit out of scope of this document so we accepted some of his point but we realized some but also I said how we addressed and what was the out of the scope in the pie in the Melanie\u0027s as soon as possible and architecture considerations documents there was only Davis comments and we are deflected and but we couldn\u0027t quite completed all his comment for this revision so what we trying to do is we will complete it as soon as possible and submitted soon again but and for now I only mentioned but one of his comment on NRS caches so we assumed and I said reserver have cache it it was because Anna\u0027s cache it could be helpful for or such a case of the live streaming service E and for like a time on critical service you know you don\u0027t have to do the name that is reserved every time so for that case we assume the and as caches but because of that there is a architectural considerations or cash yes when you even use the cash there is always of issues on cash but which is not really directly related to the analyst issues so we haven\u0027t addressed much for this revision but we\u0027ll fix some part in the next division but since the cashing I\u0027m not sure either relate to that I see an architecture or the an arrest system so we\u0027ll look for which which trapped could be the better if we we mentioned about the inners caches in in ditra indeed wrapped thank you okay thank you any questions Hamish Madhavi I\u0027m Luke I have a question regarding prions comments if I remember correctly pooyan was mentioning the problem of name "
  },
  {
    "startTime": "00:51:22",
    "text": "administration and enforcement of the of the name distributed name administration did you address this names not really because the name is namespacing we mentioned in the trap but in this trap we are not trying to show will discuss about the namespace itself well the point I mean if you just look at the DNS I mean the way the DNS is built at this and for it enforces the distributed administration of names so you I can\u0027t just change the name of Google or something and that is actually an important point here that\u0027s why heroes it yeah well Koreans comments was mostly related to do about compared was related to the DNS and I think the NRS is a similar to the N DNS but is a different and maybe I can I can I can make up reply for the through the email then you keep maybe more comments I stew card my question has to do with the earlier draft the design guidelines in security concession Siri security considerations 6.1 accessibility second paragraph the NRS may support access control for certain name records so the only users and producers within the proper lists can access these records so that assumes the traditional access control list model of access control and I think name resolution naturally Maps better to the capability based model of access control since essentially these are pointers references etc I wondered if you wanted to address you know capability based access control in addition to ACLs no okay thanks you want to respond to that well well uh we\u0027ll consider well your comments thank you okay good comments thank you so this is basically still in last call or I think the one ref may be updated right yeah okay okay thank you Janna and so next is the new speaker it\u0027s called de Varenne talk about pasta "
  },
  {
    "startTime": "00:54:24",
    "text": "me feel like I\u0027m getting unfair bandwidth allocation here well what we\u0027re getting this slides up let me preface to talk to say that this is work based on a paper that Cinco and I published in ICN seventeen that turns out perhaps has more than just research more more than just a little bit of interest in the community so we decided that maybe rather than just sort of you know go read the paper we would take it a step forward and explain a bit about how we might want to do this as part of the CC NX and Indian Protocol architectures and so people could actually use this to move forward on on application development rather than just you know seeing some research results so think of this as a proposal to enhance the protocols using the work there\u0027s for those of you who have read the ICN paper you can go to sleep because there\u0027s practically nothing here that isn\u0027t in the paper the the biggest job was converting late ektu XML but you know we all know we all know that how\u0027re we doing here not so good oh dear what happened did it wasn\u0027t working when it was on board EA\u0027s laptop let\u0027s switch back yeah I\u0027ll try to do this quickly because I want you know I want fair time for for other people at the meeting there we go I just put it in full screen all right oh great alright so quick outline I\u0027ll give you a bit of introduction to the background of path steering I\u0027ll talk about the design of this path steering scheme a bit about the packet encoding and when you do things like this you you you may have some additional security considerations over pure longest name prefix match Spile forwarding so so here\u0027s the problem statement as we know the communications capabilities of these ICN protocols are both inherently multipath and multi "
  },
  {
    "startTime": "00:57:26",
    "text": "destination which says that if you launch an interest the forwarders have the capability of spraying those interests over multiple paths and reaching multiple destinations that match the name of the object of data that you want to return however we have no mechanism for consumers to affect the selection of which path among the feasible paths gets used for any given interest data exchange so the forwarders can spray the packets on the various paths and um when failures occur it\u0027s kind of hard for the consumers to actually figure out what\u0027s going on they may be getting performance glitches because if the if the packet goes over one path that hits failure of some sort if it happens to be selected for another path that doesn\u0027t you you have a very difficult time figuring out why your performance is what your performance is so some of the motivations for employing the ability for consumers to steer packets on the path is to monitor and troubleshoot all these multipath network connectivity problems all right which don\u0027t exist so much in IP because IP basically only supports ecmp and not general multipath and also doesn\u0027t support multi destinations since the address is expressed are either unicast or anycast addresses and multicast an IP is a whole different kettle of fish so you\u0027d like to be able to do that and have tools like the equivalent of ping and traceroute in IP in order to diagnose problems um secondly in order to measure the performance of a path you need to be able to send multiple probe packets down that path to figure out what the properties of that path are from a performance standpoint and if you can\u0027t control whether a given interest message gets allocated onto a particular path you have no way to do any kind of fine grained performance measurement of your pads my particular interest in getting into this work was because of the work I did over a few years on multipath congestion control because some of the more sophisticated multipath congestion control algorithms actually require you as a consumer to count the number of available paths uniquely identify those paths and allocate traffic according to the capacity of those paths proportionally so there\u0027s a number if you look in the draft you\u0027ll see a bunch of references for a variety of multipath congestion control schemes that depend on the ability to steer packets on the paths and then there\u0027s interesting traffic engineering and Sdn possibilities here if pads can be pre-loaded for traffic engineering purposes into forwarders via a third party that has done measurements or or other types of or other types of exploration so here\u0027s the design the first question you have to ask is how do you label the pads and from our point of view on the "
  },
  {
    "startTime": "01:00:30",
    "text": "mental model you might want to have which is a little dangerous um is something like source routes or MPLS LSPs or segment routing enumerations it\u0027s not exactly the same so be cautious but at a high level we\u0027re basically constructing a data structure that contains information about every hop on a particular path so in the paper we publish we examined a number of possible ways to encode this information including bloom filters and this very clever thing called canter pairing functions which go back to go back to your CS days and look at them they\u0027re very cool they wound up only working for short pads for us but very cool data structure a label stack similar to MPLS but we chose instead to use fixed size labels in a polynomial style encoding for what we propose to put in the protocol it seems that the best trade-offs in terms of flexibility size and processing overhead so the way it works is pretty straightforward and interest contains a path level marked is something called discovery mode and is forward forwarded normally through the longest name prefix match in the FIB when a data when a content message is data message comes back it carries the path label which has been modified on every hop to add information and what is the information that\u0027s added its whoops the information is a next hop label for every next hop that a future interest would would do so then once you get back this data structure in a in the path label in the data message you can insert that into a future interest message and that interest message will be routed over the path that was previously discovered so you do a longest prefix match within that fib entry there\u0027ll be this matching of the next hop code point and that will cause the selection of the of the outbound face under that fib entry to be selected for that for that data back for that subsequent interest packet so it\u0027s relatively straightforward some obvious advantage of this an ICN ping application can reliably measure the path RTT by sending multiple interests over the same path and then met you can measure the path a traceroute application can iteratively discover multiple network paths now one thing I\u0027ll bring up really briefly here is there\u0027s partial overlap here with the existing work in ic NRG on on CCN info which has a separate forwarding strategy for doing path exploration and discovering all the possible paths that the various fibs contain returning those and then being able to diagnose that\u0027s "
  },
  {
    "startTime": "01:03:31",
    "text": "clearly more powerful it\u0027s higher potentially higher overhead has some other different characteristics so we\u0027re not necessarily proposing that this is an alternative to CC n info it\u0027s an another tool in the bag of tricks okay so the consumer multipath congestion control algorithms can discover and distribute load across the pads and as a sort of side benefit if you suspect you\u0027re getting a content poisoning attack because of the way the particular path that was selected by the forwarders passes through a poisoned cache you can select a different path with routes around potentially poison caches and then a brief mention you can do traffic engineering solutions if you happen to believe the Sdn religion for pushing everything into routers via third parties so what are the complications here well the clear complication is how do you invalidate paths if the routes are changing right so with path steering you still use the prefix match to find the set of next hops for which the path next hop is chosen so the only time you need to invalidate a path is when you go look up the next hop in the fib entry for that for the forwarder and the next hop label that you had there is no longer there right so if next top selection fails we have a way of returning an error that says you know oops invalid path label return that to the to the consumer he can invalidate that path this potentially just try other paths or discover other paths there\u0027s an option you can either reject it or silently forward in case the user doesn\u0027t really care and you can control this behavior through some options that we provide in the path label data structure so the next top labels are assigned every time a fib entry changes and on the reverse path the data or the nack is dropped if you\u0027re returning an entry returning data for a path that is no longer valid okay and the forward path the interest is intact so the packet encoding is a very careful trade-off between how big this has to be to handle longish pads more than a few hops and how much compute you need to do to actually select a particular path in terms of computational overhead so we add a new hop by hop header which is the path label and the individual next hops are is is constructed as a bitmap and that are actually 12 bit chunks here\u0027s a quick picture of the data structure which contains the path label some flags which is like discovery mode and strict the vs. fallback mode and something called the path label hop count and this "
  },
  {
    "startTime": "01:06:31",
    "text": "is an important thing that those two things one is it tells each forward or we\u0027re in the path label bitmap to extract the particular next hop label you want the other nice property it has is since this will count opposite the hop limit you can detect when you chop traverse forwarders that don\u0027t support the path labeling needed me to finish up ok I\u0027m almost done so we use 12 bit things which is a trade-off between how quickly you need to in Val eight pads in order to not have aliasing and how much space you need to do so some security implications real quick clearly consumers can try to maliciously Mystere interests because if you use a 12-bit next stop label you only need two to the twelfth interests in order to explore and find a valid on next top label to try to exploit so to mitigate this you just periodically update the next stop labels the minute maximize the lifetime of pads and the path label can also be encrypted hop-by-hop we have a hop by hop encryption capability that doesn\u0027t require any sharing so that you don\u0027t leak topological information to consumers about all the forward is on a pack there\u0027s some cache pollution potentials where a consumer and a producer can can collude to cause poisoned information to be returned over certain paths so there\u0027s a relatively simple mitigation here which is you annotate any cache entry with the path that the data came over and if it\u0027s different you don\u0027t is it good entries with maliciously constructed entries and I\u0027m done thank you great thank you any question obviously I\u0027d like to see comments on the list about this I think we you know we might want to progress this forward as a party item right and check out the my C on conference paper that Dave mentioned okay Nexus tomash wit also in a a new draft on tiny leaf and we are putting up the slides [Music] so this whoops okay hello everybody this is a new draft but actually there\u0027s not a new subject this is inspired from a discussion we had earlier in earlier "
  },
  {
    "startTime": "01:09:31",
    "text": "meetings here and this it basically ranks around the other draft I\u0027ll talk about today is this ICN lo pan if you remember of those who have been here remember we have been involved or have been working on compressing data that is to be transmitted in IOT constrained environments and the reasons for this is that there\u0027s low bandwidth with high latency slow links and energy constraints so we actually want to save as much bandwidth and as many bits as possible similar to what the people in the in the in the IP world - and along this line we had the we came across the times the timer\u0027s in CCN and NDN and these timer values are relatively large numbers they\u0027re usually NTP timestamps and we were thinking about how to compress them just looking at the data structures we have in the interest we have two timers one is the signature time of the interest message in the case and interest is signed and we have the interest lifetime message which isn\u0027t a relative timer and that describes how long an interest should be should be maintained in the in the pit at the others at the data sites we have even three timers one is again the signature time the the time when the data was signed and we have two others two other absolute timers the expiration time and the recommended cache time those are also absolute timers whereas the interest lifetime is a relative time and the idea is to to do better on compressing these timers we had the proposal in the ICN lopen draft but the problem is if we compress times as I will just discuss here then we can\u0027t recover in all cases the original times and now the the idea was okay why don\u0027t we try to adapt the spec of CC NX so that we actually choose time of values that can be compressed and recovered completely yeah so we\u0027ve looked at the the current represent representation of timers we have the relative times and the absolute times the relative times are our time Delta\u0027s in milliseconds and they can be can be one to several octet so they are flexible the absolute times are inflexible in the sense that they are NTP time stems and have have eight eight octaves in length so that\u0027s "
  },
  {
    "startTime": "01:12:31",
    "text": "actually a pretty large number oops the idea discussed already along in in the ICN lopen draft and which is actually harvested from an from the IP MANET world from RC 50 497 is to represent x in a logarithmic scale so that you actually can express them in one to two octet is a relatively large range of times but with different granularity for small values you have a fine granularity for larger values you have a larger coarse grained granularity the idea to integrate this in CC and X is very simple if you have a if you have a time delta timer with the TTL V length of one or two bytes then we assume that this is a compressed time otherwise that is just a normal representation of CCN X so just to give you some numbers or some some ways how to do this with a in a one octave case so what you do is you take your 8 bits and you fix a fix a certain amount of bits as the exponent and the rest as a mantissa and then you build timer values know you build timer values as you see the equation they\u0027re constructed as as the mantissa times times the exponent 2 to the B times the value of C that actually fixes the range so you have to we have to fix three values a the length of the exponent the links of the mantissa and this C value here the examples for a for length a equal to 3 B to 5 and C 1001 over 1,024 and this those are actually the numbers taken from from the RC previous mentioned that means you have a range of expressiveness between the smallest value is the C and the largest is about 45 days we can of course use other timers other ranges for other expressiveness so looking at the timers again we have the absolute times and that the absolute times are difficult to to compress as such as Delta times look at looking at the signature timers these signatures can be in the past so you you can\u0027t express them as Delta\u0027s they can be far in the past they can have they can have basically all values so we are not we are not addressing to it to replace those but we are we\u0027re looking at at other absolute timers here and "
  },
  {
    "startTime": "01:15:31",
    "text": "this is the in the data there\u0027s the recommended cache time and the expiration time those are also encoded as absolute values in the in the CCN expect but could be actually changed to two like taking the signature time as the baseline and then using doubters to express the exploration time in the recommended cache times and that will be a discussion we would like to to have with you or have on the list whether this should be done or shouldn\u0027t I would actually change to two other timer values into much shorter shorter encodings yeah what will be the next steps well we would probably investigate a little bit about the ranges that are that are appropriate for for the different applications in the different Delta timers for instance the the values I showed you would be very nice for interest lifetime I believe but they may not be appropriate for the Delta x in the in the object lifetime yeah and otherwise I guess the question is whether this is the research group will be interested in just doing this work or changing this spec because it\u0027s actually a very small small thing to do but I mean a decision on whether whether we want to change the timer\u0027s in CCN expects thank you Thank You Thomas right so that was the important information at the end so the whole idea of this work is what to unify the time compression that has been done in the say IOT space before and say possibly update the CC Nexen specs with that and so that\u0027s why I think it\u0027s important to for people to review this and basically here tell us what you think about it one thing I forgot to mention as some of these timers are part of the signature and the of the envelope that is signed so if we cannot recover this the timers under the compression we cannot actually compress these timers without destroying the signature and right one of the major motivations actually yeah sorry I forgot this okay the other is just a very brief recap or just a very brief addition to what happened to this ICN lopen draught this is actually has been presented several times many times he had discussed in quite detail has matured and about ready ready to go so what did we do we had several reviews also on the mailing list in particular by one chef "
  },
  {
    "startTime": "01:18:31",
    "text": "mr. Shi F trouble in pronouncing so yet also commended on several things the last way or in typos and on operators what we also did is we harmonize the the ICN open draft with the teed time ta Vedra draft I just presented a second ago so that those fit together nicely and the second discussion question we had from the montral meeting was the this draft originally concentrated on efficiently compressing like the default standard cases and as a default standard cases case we identified the generic name components for named object for the names of object and this is actually what is shown here so what we do is we have a recompress we compress the names under the under the assumption that the the names only consists of generic name components limit the length of the name components and then actually we compress it down to down to a very short very short name there has been the discussion on the mailing list and also in Montreal whether we should include types types here should also account for type name components and Shang made a proposal in in Macao to to just have a give certain fix a certain kind of types like version numbers and and timestamps in in these names to to make to actually to make the smoke expressive to include some types which led to another discussion on the mailing list about all there are other types that are also interested and actually our way out of this discussion because we can\u0027t really judge on what name types are the most interesting and what or not is to make the to make this in extensible extensible extensible thing so the idea is we we have in the ICN lobe and we have you want to interrupt or no keep going in the eyes are opened we have dispatch fields and these dispatch fields can be extended they have extension extension fields and the ideas to define and such an extension groups such an extension field here that has has to to further values to to incorporate flexibly name components for instance defined in dictionaries or in something else that copy could be "
  },
  {
    "startTime": "01:21:31",
    "text": "actually special specified in future documents which are not which are not part of the spec you want know are you done well basically no I actually it\u0027s appropriate to that slide so ask it now or just make the comment now go back one well this is basically and so wrong um this seems to me anyway to be a poster child example of something that you could use manifest metadata for to actually explain what what dictionary you you\u0027re using or so yeah that\u0027s right so for a whole given you know subtree of objects that use certain type name type components you can put in the manifest metadata these are the ones that you Det that you would be compressed that\u0027s actually the extension what I wanted to show anyway but yeah you that the point is in this extension address you would have you would encode a compression strategy that yeah but those have to be in every packet that\u0027s right those would have to be in every packet that will be annexed yeah yeah so yeah so just think about using manifest metadata it seems like a nice trade off okay so we think about the manifest metadata and otherwise we\u0027re I mean we think we are pretty much much done with this draft so we\u0027re asking for right Thank You Thomas so just on the last point I mean we have to find a way to deal with these dependencies meaningful way so if you think about the manifest approach I hope this wouldn\u0027t affect this current draft so we don\u0027t have to wait with this draft to figure out a way to use manifest for the dictionary description right yeah I guess we I mean we probably we think about this manifest and take it to the list I mean the the the price we are discussing is actually relatively low so I mean defining additional dictionaries would mean that we have one octet extension of that year which is also not that that bad right so I think from our perspective it\u0027s good time to last call this draft now and it shouldn\u0027t keep us from thinking about the manifest and idea later okay so we will issue a last call on the main list please please please have a second look at the at the draft so and this is also going to be an important specification for ICN in IOT so we want to publish this because it\u0027s important for building IOT solutions was ICN okay so next is Greg right so I\u0027m coming in with an update on ipok which "
  },
  {
    "startTime": "01:24:34",
    "text": "we recently adopted as a research group document and who stole the ticker thank you all right thank you this would be a fairly short update so giving this update on behalf of my co-authors just militant chain you to the concept if this if you\u0027re new to ipok its idea to use CC n as the forwarding plane for a mobile core network so not running CC n on top of IP on top of LTE think a PC a things like that essentially use CC annette as as that forwarding plane and then run existing IP services on top of that and so i his IP over CCM and the idea is that it would replace LTE PC and the gtp tunnels that are used for that for mobility and then once you\u0027ve got that forwarding plane of CCN in your mobile network then you can now deploy native CCN applications and get all the benefits that you know in network caching and and mobility that comes along with that status I did a fairly detailed presentation on the protocol at the interim before the Montreal IC energy or IETF meeting link is there if you want to take a look at the slides from that so I\u0027m not going to go through a detailed overview again today after that meeting there was an adoption call on the mailing list and it was adopted and shortly thereafter or a couple weeks after I updated the draft and submitted that as a research group that changes or were pretty minor added one reference in response to a question on the mailing list and then I updated the references to the CC n document since they had become RFC it around that time and was it open items there\u0027s only one open item that I\u0027m aware of maybe I\u0027m forgetting something and that was a comment from toss about consider including a comparative discussion of mobile ipv6 and multicast mobility we\u0027ve had some offline exchange via email and plan to think up sometime this week to discuss that yeah I just Canet I mean that the point is you\u0027re you\u0027re trading CCN mobility versus IP mobility and you\u0027re in a research group so it makes sense actually to position between the two and I mean multicast is interesting in this case because I\u0027m CC n is also a reverse path forwarding so multicast ability is actually the direct counterpart of your approach that\u0027s at least for a scientific completeness I guess yeah I have no objection to doing I think that "
  },
  {
    "startTime": "01:27:35",
    "text": "we could come up with a short subsection in the document that that discusses that I wouldn\u0027t want that to become you know the book the document but you certainly cover that and and with your help Thomas says I\u0027m not an expert on multicast mobility or actually on mobile ipv6 either appreciate the offer to help so that\u0027s in I think there\u0027s unless there are further items that come up on the mailing lists either as a result of this I\u0027d suggest that once we\u0027ve gotten some text together on that that we should consider a level okay thank you Greg and just one question from the chest and so it you keep using the term CCN in this document shouldn\u0027t it be CCX it should be second I guess that\u0027s one question so I just want to confirm about the deployment strategy in like I see any in 5jc this is not relevant but I won\u0027t confirm this is like the first mode or second mode of its overlay or underline because we were quite confused about that definition so it is part of this study in the deployment consideration or not which one so I puck is discussed in the CC on over PI G Draft and I\u0027m not remembering exactly the terminology that\u0027s used there but essentially it is using CC n forwarding natively over so Ethernet row over another layer to technology in the core network and not with IP underneath it and then running native CC n applications or or IP applications in particular in this case IP applications on top of CC NS that is that foreign plane here\u0027s the question and your name please okay by the way and the mic is not picking up the voices really well so you have to move really close to the mic if you say something okay so it sounds like that\u0027s gonna be one more revision and then we might consider that\u0027s calling it wait that\u0027s right I think we can probably get these edits done in the next row by the end of the year so next next few weeks okay so I\u0027m very good thank you very okay so moving on like this you\u0027re crossing the sea in the room oh yeah also a new draft on "
  },
  {
    "startTime": "01:30:42",
    "text": "Internet services over I CN n 5g a LAN environments if you can just put hello everyone this is actually it\u0027s a version zero zero but actually it\u0027s a revised never Eiland draft we presented it in NASA a meeting moon chill it\u0027s about the so when we play the other one the IPO risin over fabula so rana the presented the idea I\u0027m pretending now is we call the Internet services over ice and over fifty lon in terms of icing world fevzi actually we have another related were on our G draft labeling ice and over so gpb\u0027s fifty next generation core network so inland draft talking about the how to extend the 5g control plan and data plan in order to support us in over forty a network or 4G system so the current one is kind of for Exantus stabbed near the feather is think about if we have the HTTP HTTP for example internet services such as HTTP if you want to ride over the ice N and also here will focus on fabula because fabula is can a vertical our virtual land a group of some years so we want to look at this how to support this you know the utilize Ison and the underlay and also utilize the Ison and the kind of a slice in favilla environment in order to support the the upper layer the HP up our internet sources such as HTTP so basically in this draft we presented to use kisses whines about the control a plan because contraband you know they felt control plane the use HTTP protocol is kind of interest services the signal use case we are including the job is Kali the HD streaming so we introduced a faulty line architecture according to the education and of course it\u0027s ongoing studio in CPP the architectural Falchi next generation corner work in support in order to support our Jalan most more counter contents in in this trophy\u0027s the making demanded also the architecture in order to supports the interest services over a single on for example we need to introduce the "
  },
  {
    "startTime": "01:33:46",
    "text": "Ison API in order to supply upper layers for example sue this SNP I the upper layer such as the UTP they can call this API to send the packet to the data to the eyes in there as a part of that we also consider the service proxy operations in order to support the legacy devices which means it only supports the ice and natively so for those kind of legacy devices they talk to the service proxy operations from the air the service proxy proxy it can translate the LexA device operations to the you know with proposal e at the icing or 5g lon and also part of that is we need to have a component we call the name resolver in order to you know discover and the fan in the past ID because even though we use the ICN the underlay we still using the past based forwarding for example in order to send send a one Ison packet from one UPF to another UPF also we also consider the dual stack device reports because in some cases the device supports commission on IP protocol also support the that we propose here the inter services or icing over 50 lon and then the deployment considerations we basically took the guidelines from the research group document about the ice and deployment guidelines specifically to our commands were taken is Ison and the underlay and also since we are here consider on how to do that 50 lon so we also take the Ison and they slice because and you know the the 4G system suppose Network slice and nicely and that\u0027s kind of being content including the it\u0027s chopped so we received a few comments back in July in mnchen meeting so we made some those two major changes number ones and a paragraph to describe the how to realize how to achieve this interest sources over a single file on under you know some other transport networks we talk about the Easton transport networks in Section four to a further one here the father to we and a paragraph to clarify we also can use a bigger traffic engineering and then you know one type of other transfer networks in order to support the inner source is authorizing over fifty line so essential idea was to basically say the beer of trafficking in your controller is quite similar to the HD in control controller so we can base into this inner sin configure some you "
  },
  {
    "startTime": "01:36:49",
    "text": "know they the positions and a bit strings in order to utilize the pass is forwarding again from for example from one UPA for a lot of UPF a lot of changes we replace the IP services with the Internet services one of the reasons also the computer by the pier but the folks not meeting in montral is I think the the inter services in the more meaningful and more consistent with the content with the motivation covered by this draft that\u0027s kind of for to mere changes that we made so far of course there are some other of future updates we plan to do for example currently we have two components the flow management and also the mobility handling so those two components currently is its kibriya we plan to you you know under the future updates for example for the flow management we plan to describe how Internet transactions are mapped onto single transaction our relation with the joint flow control across all transactions I\u0027m not going to repeat this you know the perimeter thinking or the promise to Adam you know more description and more content or run those two components flow management and mobility are handling another thing what you plan to do is in the we we plan to show a demo in next meeting 107 in my cooler so the plan was to showcase a realization of Internet services over a little too for example HD and transfer network using the Ison based routing of course we mention one for common component we proposes service proxy so the term knows suppose terminals as well as a service approximate solution will be demonstrated and as use case because it will be you now with use case I described in this draft example the HTTP video streaming or video viewing yeah but there you have any feedback or question oh wait just keep going yeah I guess I\u0027m almost done I guess yeah all right so quick question um you\u0027re running you\u0027re running HTTP on top of an ICN protocol yes so what spec defines that mapping so you say what\u0027s the back or yeah what specification defines the mapping of HTTP on to the ICN because I didn\u0027t see it in this draft this dress was sort of hand waves and say we map HTTP on top of ICN I I guess a while a waffle idea was "
  },
  {
    "startTime": "01:39:52",
    "text": "to the icin because I should be a nice and so basically you were asking how to map right because both layers or different a once idea is working to the icing is going to be extended by providing certain API to the upper layers for example two or four api\u0027s were described in the draft is send a packet and a collection so using this this assume this ice and API is there so in order to use HTTP in a packet from a source to a desolation the sender the HIV layer and the sender is going to call the API and talk call this isin API talked to the ice in a layer and to the cinder side and then send a packet down to as in there from there the icing and there is going to you know use the ice and make known class the past based forwarding in order to send a this ice in packet of course a payload that will be the HTTP packet sending this ice and packet tail packet for example from one you piaf for other UPF and eventually the destination UPF is going to like you know recover the original HIV packet and send it to the eventually sent to UE for example so basically to answer your question you founder understood correctly there will be something we need to propose and we need to extend the ice and near for example here is a by providing certain api\u0027s to the upper layer like HTTP ok thanks just quick thing this still has me confused but not to take time here on it which is that sounds like that requires at least double the packets of a native HTTP so why don\u0027t we you know dive deeper into this when you do the demo in Vancouver that would be nice if you could explain how the HTTP mapping we looks like yeah cool thank you very much ok next is we\u0027re done I\u0027m gonna update on hope I hope authentication in CC n X or Indian and never walk I\u0027m reading from nice [Music] yes I\u0027m from a ICT Japan and today I will present updates on the ha post "
  },
  {
    "startTime": "01:42:52",
    "text": "after hope I hope I was in the game in containers in Germany Turkey and the name written on it working last time we at ITF 1:05 I presented that basically design of the Hoppus theater market some feedback on the motivation the initial chasm and trust establishment and so this time I give some updated for the draft and this the updated my own version zero one easier to the included the motivation clarification and the motifs collision on the initial trust establishment first this is simple introduction on the continental network and numerator networking and there is a consumer see another sign out as an entry say and the end user where people would either hope I hope finally reaches the copy cooter and then copy hood a reprise with date heart and in this procedure the three entities involved one is the publisher consumer and a copy cooler we consider to add a virtual model why is the content a poison attackers yeah is the attacker impersonated the copy hooda to provide a free coca-cola broker uppity the data the current in currently the company\u0027s only signed with key of the ante who publishes this data so the consumer may always retrieve the wrong effect data because of the because the Reuters cannot details of entity of the data so it is necessary for the rotor to use the authentication service to for the thousand kids that data so the second attacker we consider is the inches of flooding on Hokulea is the attacker can impersonate the consumer to request the data much existing worker faxing on the restricting the inches at any rate so it is ratified the treaty is necessary for the copy Hooters to use service to authenticate increased packet this is a teacher some teachers of the condom poisoning a tackle the attacker who drew the providers effect of gravity corrupted the data then the consumers in out of the interest the end the data faculty that we will be prior to the consumer one so this is a proponent one yet a consumer always reaches the wrong data because the intermediator rota to Lotter detected the benefit of the data so after the SS the data was attached hope I hope this data obviously the consumer tool I send out of the interest energy and also the wrong packet don\u0027t did how we appear applied to the consumer to from the cash the memory of "
  },
  {
    "startTime": "01:45:53",
    "text": "the closer rotor so the second problem is that the fact era our Futurecast which pollutes the rotors as a bit Russo sprays so we identified two requirements here the first requirement is after all the rotors and on the past need to verify the data before cashing but we do not to avoid a heavy and complex tasks a and the senior management cysteine the second commonly that\u0027s the consumer need to verify the computer and a data which were pass to identify the some the polluted auntie\u0027s besides the hub verification this is introduction of the inclusive radiant haircut the other is the consumer send out the floods of the increased to the native occur to me of a machine the rotors so the first problem is that the Nodoka may be broken of course there are some much existing worker-owned focusing on the road and limiting so but finally there are still some malicious interest can still reach the copy hood so the cop car still need to provide some priority the data so it is not audio solution so the what we identified two requirements here also the first one is there to the not the hopper rotor needs to any eliminated changes chance of the increase of flooding attack the second commentator is a cop who don\u0027t need to modify the increased apocalyptic before reprise the data so the suppose in a summary that is some summarized at manageable hobos who policy is single mechanism enabling the potential was indication from any consumer to the data to the copy holder in kanuni publisher and also to the data retrieval path and it also enables the router to authenticate the interest so it is data orange the mechanism and that doesn\u0027t necessarily rely on the external servers but it doesn\u0027t exclude the use of the certificate authority as it is the contributor to the suspension model we propose during our hoppers but here I\u0027ll introduce our modification and from here is introduction on the initial trust established and for the use of the CEO certify Pournami we use the hash of the public key to impurity into the name to prevent the stoning and the progeny of the existing names the solution here we "
  },
  {
    "startTime": "01:48:55",
    "text": "use the public key to is embedded into the name to inability to be sealed certifiable the name owner can use the corresponding private key to ascertain its ownership to sign the message sent from this entity with an M but we needed to notice that an attacker can create a you name from an arbitrary public key however the attack cannot cannot impersonate somebody else\u0027s name here is the conclusion we updated the tapas draft on the modification clarification the initial trust match if you trust the establishment thank you thank you any question okay okay so just change again because a sudden can you come up yeah this is adapter hell I don\u0027t think we can\u0027t do this [Music] so we had a couple of additional society events on ICN this time so one was a heck of an activity by energy T and colleagues on the C for implementation another one was a Q s discussion that wasn\u0027t really at the hackathon but that took place on non Sunday which is really like to update you on those so the present me quick report are the support project in this hack zone so simple is open source software a software platform in a weighing machine communication which complete with two RF seeds the main objective is to enhance to this several functionality in the context of the two proposed draft one is she\u0027s aiming for and the secondary is network "
  },
  {
    "startTime": "01:51:56",
    "text": "coding position and the nvm so more precisely in the second so we we implemented two simple function y is a network control using machine info which can enable some operator to check out a network connection in network condition in a Turkish condition and which data should be cached and the second is a Content producer application using which can utilize the network coding in the context of she and communication so other achievement we built an test it\u0027s a basic problem module created to date to function and we it\u0027s still ongoing and we need to make more flexible and feasible naming speak and the deal with interest pocketers to improve performance so here the these team members and you can get more information and the source code or from this URL thank you okay great so that that\u0027s great to see that people are doing this microphone activities so let\u0027s do more of this next time thank you very much and another laptop switch let\u0027s see how it goes fuck that\u0027s but yeah much better oh you switch to marking them on yeah sorry the presentation laptop didn\u0027t work today so I\u0027m just going to sit down um so as you know we announced a sort of an informal side meeting about what I see and RG might be doing about quality of service stuff going forward and we "
  },
  {
    "startTime": "01:54:57",
    "text": "didn\u0027t get a lot of attendance but the attendance we got was some pretty good engagement from variety of people so I\u0027m just going to quickly run through some of the things we talked about and our idea is if people are interested in they\u0027ll take a poll at the end whether we should have a follow on inform we\u0027ll get together later this week we would be targeting the early the morning open slots for Thursday in order to get together so we we looked at the existing drafts that have that address various quality of service things but the discussion ranged somewhat wider so some of the things people seem to want to talk about is what what interesting research can we support by working on quality of service stuff do we want to actually try to come up with a defined architecture for doing quality of service in ICN how much should are the experience we have doing quality of service work in the IOT and low end low bandwidth low capability network environment use that to drive some of our quality of service work because that\u0027s where people have spent a lot of time sort of like the high level question is who cares if people don\u0027t care there\u0027s not going to be enough participation to really make some progress some more detailed questions like do we want to mirror the kind of class-based quality of service capabilities that diffserv provides or do we want to also accommodate flow style quality of service capabilities similar to what M serve does and who will implement and measure whatever we come up with because if we just write specs that\u0027ll be you know fun for putting things together but not really affect things so we have a whole bunch of notes I\u0027m not going to go through all the notes there they\u0027ve been posted to the data tracker but just to give you a sense of of what we talked about we talked a bit about what the alternatives are for flow classification we talked about some of our terminology is kind of loose and we need to to clean it up some more for example there\u0027s already some confusion about why some people think flowing congestion control are sort of very closely related to one another and other people think those are sort of separate topics and you want to talk about flow control and congestion control separately and whether QoS treatments should be bound together with flow classification or not so there is some sort of general talk about about this quality of service architecture polemic that that then I published a few months ago and what we should do about that we\u0027re interested in more feedback on that I think our default after talking to Colin is to actually move it through I cnrg but treated as an individual "
  },
  {
    "startTime": "01:57:57",
    "text": "submission so it doesn\u0027t bias our future work in coming up with a quality of service architecture I\u0027m trying to think if there\u0027s anything in here that I couldn\u0027t that you just couldn\u0027t figure out by looking at the at the materials no I think that\u0027s about it so please look at this stuff ask questions and let me just get a show of hands who might be interested in showing up Thursday morning for further discussions on this topic all right all right so we\u0027ll do it instead of doing a doodle poll since there aren\u0027t very many options other than really Thursday morning um we\u0027ll try and get a room yes it would be in the open tslot time from 8:00 to 9:30 right so since there seems to be enough interest we\u0027ll go and try and schedule a room and and send the room information to the to the IC n RG list for Thursday morning okay okay great I think we\u0027re done yeah so thank you also as you have seen I mean this was a pretty packed agenda so thank you all for your contribution and your discipline so next time we\u0027ll have to find a way how to deal with that so we are likely going for another full day interim on the other hand we would also like to encourage more hackathon work and so this what kind of conflict was the weekend before so maybe let\u0027s discuss this a little bit so if you want to do some hackathon activities at the next ITF it would be good to let people know in advance so we can Kona a little bit and make sure that you have good attendance at you a cup on table or she\u0027s please give us back the blue sheets and enjoy your lunch okay we\u0027re done thank you very much [Music] "
  }
]