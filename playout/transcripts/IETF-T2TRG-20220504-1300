[
  {
    "startTime": "00:00:29",
    "text": "uh so we are still waiting for people to come in that are not so familiar with the meat ecosystem i believe the the question i i would i would make israel answered i see that the lecture will be recorded where it will be available and when it is usually available two or three days after the meeting in the ietf youtube channel okay youtube channel yes and if you go to the chat you will find a link to the current notes and the current notes will be updated with the video address as soon as we"
  },
  {
    "startTime": "00:02:01",
    "text": "know that okay thank you very much good so i think we are approaching 30 participants great so i think we can start this is the thing to think research group we are having a work meeting which is a meeting we tend to do between our major summary meetings to get some progress on specific topics and today's topic is digital twins i'm carsten berman i'm sharing this group together with ari carolyn and i need to do a little bit of bureaucracy at the start um this is my version of the so-called node well slide which tells you three things you may be recorded actually you will be recorded as you can see from the red recording uh blob down on the screen um there are some code of conduct rules here which i will summarize with be nice and there are some ipr guidelines which"
  },
  {
    "startTime": "00:04:00",
    "text": "are necessary because this is an organization that is not trying to to generate some cartels and so on um so we we have to follow anti entry trust guidelines you can find more information at iitf.org ipr and the short version of that is that if you know about the patent claims to some technology and want to talk about that you need to declare that knowledge and this is the the long form the official note well slides that that you can per use this is the code of conduct slide and uh finally um a few words about what we are trying to do here um it's uh easy to confuse the irtf with the ietf and and that's somewhat okay because we are closely related organizations but the research task force focuses on longer term research issues while the ietf really focuses on on creating standards short-term issues of engineering and standards making so what we are not discussing today is making standards we might be discussing what we would like to ask the iatf to make standards for but we are not a standards development organization which doesn't mean that we don't occasionally create rfcs these are then usually overview uh documents or documents that address specific uh questions uh we often do work on terminology because it turns out that it's very difficult to get work done in a space where the terminology isn't very defined um so that that's a typical out come off"
  },
  {
    "startTime": "00:06:01",
    "text": "an irtf activity but just just getting goals set for other people to to publish their papers about also is very much a goal of the irtf so we have a notes page which is on on the hedgehog notes note system uh the link is on this slide and in the chat as well we have a jabber connection to the chat but you can see the chat on the left part of your screen if you click the the chat button uh so you usually don't have to go there and of course we have a mailing list in the research group which uh uh it makes sense to surpr subscribe you will not be totally drowned with me we have a relatively low volume mailing list uh and we also have a github organization and we usually have a repository per meeting so this is the may 2022 meeting so you will find the repository under 2022-5 digital twins and that's where we will upload the slides we will also upload the slides to the official ietf systems which are a little bit harder to to navigate so this should be the arri thank you since we have many first uh time ietf first here so just a quick note on the meet ecosystem so if you have any questions or comments of the presentation you can use the join cue button uh on the top left part of your screen just click it and you will join the queue and then we can give you um we will let you know when it's good time for you to have a talk or that that's the best way to join for comments yeah you mean the the hand button"
  },
  {
    "startTime": "00:08:00",
    "text": "we have these beautiful icons that nobody understands exactly it looks like a raised hand when you hover your mic your mouse over just leave you or join you great thank you for for this hint this probably should be on the slides um so um what is the thing to think research group about um it's meant to be discussing research issues that that have become of interest or still are open in getting an internet of things going that is not just using the name internet but really uses internet uh technologies and one important aspect of this is there are many aspects but one that's important enough to put it on the slide here is that we are talking about low resource nodes constrained nodes that need to be able to be part of the internet of things so we focus on issues that might have opportunities for iitf standardization but of course essentially catering to the the general research community is is of interest here as well and with respect to the iot we really do this full stack so we start down at the ip adaptation layer right above the radio and we end with application layer concerns security concerns and so on um so within the organizations irtf and ietf there are three blobs and and we are part of the irtf blob the green blob really is the the working groups so there are i think 13 right now just mentioning two here um and there's also a blue blob which"
  },
  {
    "startTime": "00:10:00",
    "text": "are working groups that uh really look less at protocol development and more at how do you actually run these things how do you actually implement uh these things so i cannot do a full discussion of the organization here but i think it's important to keep this in mind and that's why i have another uh slide here so the ietf does the standards uh from the detection adaptation layer uh higher on to transfer protocols and profiles for transport protocols security mechanisms application data formats data models we have created 16 working groups since 2005 three of which are closed because they have completed their work that's something we tend to do in the ietf and we are done we stopped working while the irtf is really about interfacing to researchers and defining programs of research getting summary documents out and so on so today's subject is digital twins and this is a concept that has become increasingly popular in particular for iot or more general operational technology systems and the idea is that there is some physical object that uh being a thing in the internet of things it is also has a digital interface um but uh that may be difficult that may be consuming battery that may have low bandwidth and so on so it's often useful to actually have another digital object which is not a physical object but somewhere on on a server which is called the digital twin of the physical object so that that is a counterpart of the"
  },
  {
    "startTime": "00:12:01",
    "text": "physical entities and uh of course the important thing is these two are synchronized so they are twins are just that that only one of them has the physical environment as well and uh of course this means that we need to send back and forth sensing data and and control information actuator information and what we want to do today is start work on digital twins in a more formal way as an activity and the result could be that we capture relevant terms including a definition of digital twin in the first place identify ietf technology that already solves some of the problems that are important in this area and on the other hand identify gaps so we know which further standards development may be useful at the ietf and on the other hand which research opportunities are there that would be useful to have to do good standards and not just any kind of standard so today's meeting really is on the the on the level identifying questions we are not going to generate answers um today but it's really important to understand the whole gamut of questions before you start answering them and of course digital twin is a specific term but of course we have other terms for concepts that solve related problems so for instance in the rest architecture we have proxies uh which solve certain problems and do not solve other problems that digital twins try to solve"
  },
  {
    "startTime": "00:14:00",
    "text": "and even the brokers from from the message queue world often do things that are related to digital twins like recording last wishes and so on and of course these things also come with some naming systems that may be important when we talk about digital trends we also do work in in the irtf about implementation environments that may be useful for setting up digital twins so things like like edge computing or in network computing may be of interest maybe not so much today but i think in the long run we have to talk to the research groups that work in this space as well and finally digital twins live and die from modeling so if we have modeling in particular data interaction module modeling that we can share between the digital twin world and we will hear later about that actually happening um then that is going to help both sides and the same of course also is true about security so for instance authorization is something that needs to be done in the physical and the digital side of the twin system and it helps if our mechanisms actually work with both so the plan is to do a quick introduction and i'm already five minutes over time then we will have two talks from people who haven't had a lot of contacts with the i contact with the irtf before and there is a digital twin consortium behind that so i'm very interested in hearing this point of view"
  },
  {
    "startTime": "00:16:00",
    "text": "and we will reserve a little time to do clarifying questions after that so we probably don't want to go into the big discussion we can do that at the end uh but maybe we can um we can take questions during the talks of course but maybe it makes sense to have a slightly larger question section afterwards then we switch over to what we have been doing in iatf and irtf first of all there is a network management research group that is talking about a network digital twin or digital twin network unfortunately they had their big workshop last week so we were a bit optimistic in in trying to get someone to talk about that but i'm going to show two slides here what that might be then i want to quickly talk about sdf and the asdf working group and which is modeling approach and then we have two talks from people who actually are using modeling technologies to do their work on digital twins and we have time for a discussion at the end okay with that uh unless there are questions about the agenda i think we can move to the first talk and i relinquish this slide how do i do that uh hi i am starting to share my screen you should see that now yes okay great"
  },
  {
    "startTime": "00:18:01",
    "text": "thank you very much uh i am antoidia joe i'm going to be uh presenting some some work that we've been doing the last few years by way of introduction uh i have been developing integration platforms for building systems which is really iot for about 30 years so i have a lot of experiences and and trying to bring systems together at that level um and this work of cnscp also knows connection profile came out out of work that we've been doing the last few years in developing um a an integration platform uh in the internet era as it were so we came up with this mechanism and it became clear to us as we started to think about deploying it and implementing it that it should be something that is put in the public domain so we are in the process of doing that making connection profiles open and we can speak a little bit more about that so um one of the things we've been doing the last couple of years is testing out this this mechanism within the digital twin consortium community essentially sort of incubating this idea and it's very been a very very interesting experience there testing it out with a number of uh really sort of different use cases that we may be able to talk about towards the end so the way um we have um thought about thinking about the the this problem is really from a system of systems perspective um and the dtc the digital twin consortium is actually in the process of writing a paper on digital system or systems um i'm one of the authors of that and so the the what's sort of interesting to us is that when we started to think about system of systems as a way of making um systems in be able to interoperate with each other in a digital twin"
  },
  {
    "startTime": "00:20:00",
    "text": "um one of the interesting motivations is this paper that was released in 2010 from ibm that basically said that the the global economy 100 of the gdp of the world is um actually a system of systems but we're not thinking or running it as a system of systems and it is um quite a sort of economic paper and they basically said that this is costing us four trillion dollars back in 2010 so it's about 10 of the world gdp so it's a big problem um and obviously there's a value in trying to figure it out um so the way we started to think about it is that because the world economy is you know by definition extremely complex i i was trying to simplify um what system of system is and came back to nature and thinking about flock of birds because the flock of birds is clearly a system of systems there are two types of entities here a flock and birds they obviously organize which is a flock which is a system in the birds as as animals are systems so when we dig into this and start to understand how does a flock of birds work how do they know how to do this and they do this over and over again the the thing that became sort of interesting is really the relationships and the only relationship that really exists in a flock of birds is relationships between one bird and another you know one bird can know that it's following another bird and um so on and so forth um all of the birds have some kind of um mechanism like this and that is essentially what makes the flock there's nothing else there's no there's no um [Music] other entity that's actually forcing the the birds to fly in that way it's actually themselves so we tried to uh then take that to a sort of systems discussion and this is the the the way we decided to depict that we have essentially a system of systems that's depicted by the gears"
  },
  {
    "startTime": "00:22:01",
    "text": "that you see here that is made up of these constituent systems um that are essentially you know equipment and other things in iot and the little twin um but we already know from the flock of birds that the gears aren't really there so they're sort of invisible gears um and what you're left with is a whole bunch of nodes which we refer to as interface nodes so think about the interface nodes as the brains of the birds and the equipment here as the body of the birds the brain of the birds knows about things it knows about the system of systems it knows what's around it and it also knows about itself it knows about its health etc and once we start thinking about it this way then each node becomes unique and once each node becomes unique we start to be able to think about relationships between two entities two two birds as it were so l and k are two entities and this is really the relationship that we see as being valuable and connection profile is a mechanism to model um the behavior of that relationship or the contents of that relationship and that's really the the premise of connection profiles um the way connection profile works is that the the the constituent systems the client systems and the server system there's always a client and a server in a connection profile mechanism they instantiate themselves into the system of systems and creating these sort of virtual modes so you have the two virtual nodes as part of that instantiation they they provide information such as the context of where what they're interested in uh if you think of the birds that particular flock of birds as opposed to the one that's um five kilometers south of it and the the mechanism then asks the the systems to declare what is this able to do in terms of connection profiles connection profiles all have names so"
  },
  {
    "startTime": "00:24:00",
    "text": "this the the example here is proto.example.cis all the profiles are given names such as that so what this client is saying is that it can consume this profile and the server says they can serve that profile in this particular context so that's kind of the premise of of what needs to happen what the system of systems does as a broker it looks at that and it says okay there are two compatible um complementary connection profile declarations in a particular context so what it then does is it goes and looks up the connection profile model of pros of example dot says and it creates an instance of that at the context in question and from that point on metadata flows between the the the client the virtual client and the virtual server and the definition of the what matter the metadata flows is exactly what is in the connection profile itself that i'll explain in a second so we think about this as metadata so we think about this as a control plane of um of this whole system um in many cases uh in most cases in fact in iot and digital twin there's the the systems themselves have some kind of protocol and some kind of need to communicate direct directly with each other so connection profile mechanism allows this to happen and with the metadata potentially being communication parameters that will inform how this uh data flows directly between the client and the server so this is the simple the the the the the the mechanism itself in the simplest form the other way to think about this is um when it's not a digital twin um the mechanism is the same everything above is the same the the difference here is that the connection instance then we can think about that as passing data rather than metadata right so both applies and the mechanism is the same for both the connection profile itself uh this is"
  },
  {
    "startTime": "00:26:01",
    "text": "an example of one uh it's actually pretty simple this is header information this is the name as i said all of the names have this sort of form similar to domain name form but it's not domain named at all so header information the most important part of this is the stuff on the right hand side because this describes what type of server this connection profile was uh created for and what type of client on what type of application what type what kind of purpose um so a connection profile you can think of as a as a codification of a use case of why two systems need to communicate to do something and the payload of connection profile are these what we call properties and the properties are tagged either as being properties that come from the server or from the client and these properties need to be filled in at instantiation not at the model stage so um here there are a number of properties uri cost so they can be any type of property that makes sense for that particular application that's defined in the in the header and the client also has to provide um some some properties as as per the use case um so this is this is the the simple nature of the connection profile connection profile sits in a broader thing called connectivity naming system which is first of all it's made up of connection profiles themselves obviously a whole bunch of them and um the the the full picture of the connection profile is that there is a then a connection profile registry where all the connection profiles are put into um it's somewhat similar again there's some sort of analogy to dns so think about this as being very similar to how dns servers work we then have the client nodes and the server nodes these are applications they're representing applications as per my previous slides they have interfaces"
  },
  {
    "startTime": "00:28:00",
    "text": "to the to the uh registry and then you have the broker and specific interfaces uh with client and server nodes um as i mentioned earlier um the this is really the the open source sort of mechanisms and licenses that we think is appropriate for the different components and all of this is done for um innovation to happen either on the client or on the server end or on the orchestrator itself and obviously this is where we work so um it's we we think it's a very um useful mechanism to make things connect with each other so um philosophically um this is really what's going on here we believe that we currently live in what we describe as an endpoint centric world and so that if you take a diagram such as this that we see all the time all over the place what we do is we think about the nodes we think about the endpoints because the endpoints are where computing is is where application is where data is where people is where things are right everything that we as humans do typically is a node when we draw lines between them we really think about them as communication between endpoints 5g wi-fi etc etc that's the way we think at the moment we think there's a better way of thinking about this and we call this a relationship centric uh view of it where the endpoints are the same endpoints we had before nothing has changed there um the the difference is that the root the the relationship the lines then become relationships and what we're really proposing is that we should really be managing and thinking about those relationships because that's really where the value is i think we all know that data static data if it just stays there forever it's actually no use data is useful when it gets used and when it's transferred from one system to another so um the the the"
  },
  {
    "startTime": "00:30:01",
    "text": "the thesis here is that we should really be managing that and sort of um extracting the most out of that so as a way of explaining what this uh what this means if we think of the endpoint centric world that we live in if we have two pieces of equipment two systems of of any sort and there's data in in both that from an application perspective we need to move between one and the other what we have to do today is we have to have a whole bunch of other parameters and metadata and other information to enable that data to go from one side to the other everything from the uri of the server to keys inserts and all sorts of business rules and stuff like that that we need to have on both sides and they need to synchronize and they need to match before data can actually flow and really the the only way that we have to do that um is two main ways uh one is through the very comms pipe that we want to put the data in right so we're using the comms pipe to control the comms pipe which is kind of not really a a good way to think about that so that's the main way of we're doing it and for really really critical information we resort to ourselves humans sneaking it so thinking about things like api keys the way we do that is we email them or copy and paste them to with each other so this is the way that we have to synchronize this we think this is very very expensive all of this very expensive very risky and actually creating a lot more issues than they solve but it's the way we do things at the moment so that's the first challenge is that the synchronizing everything is is hard the the other uh challenge um is that this um picture here of of the of the network as it were is not normalized right nothing is normalized here when you when you look at the sort of the the abstract view"
  },
  {
    "startTime": "00:32:00",
    "text": "i'm sure there are apis that are normalized and there are ip packets going back and forth but you you can't tell what this line is for example across these two nodes because it really depends on the actual application there's very little little normalization and that's really what's creating um this this complex world that we live in um as we move to relationships relationships are also complex in a different way and here we we think about humans when when when we have relationships there are different layers of um the aspects between between two humans right we have uh trustworthiness right so somebody would have a set of trustworthiness cast and for example i know that he's a member of ietf and rtf so when we started to communicate i know who he is and he knew who i was through other sort of mechanisms we also have other ways of determining our trustworthiness and um when we need when two p when two individuals or two systems need to communicate that then creates a level of trust between them um and that basically says it's okay to have this relationship then there's issues of capabilities um custom have certain set of capabilities and so do i and when they they when they match each other there's compatibility so there's some usefulness in uh relationship between the two and then there's a state which is the current state of the the two entities um the current state of of of carson is as he was presenting it in in the opening in terms of explaining this this work group etc and i have this similar thing and there is a context that defines that there is some usefulness and actually us having a conversation and lastly we're actually having a conversation right so this works in in human sort of world the premise here is why shouldn't it work in systems and so the way we think about how to make that work is that if we go back to the same use case that we had before"
  },
  {
    "startTime": "00:34:01",
    "text": "we still have um for now anyway all of the parameters that's needed but what we're proposing is all of those can be put into one or more connection profiles one for example for trust which is one of the use cases that we we have done a lot of work in the dtc and there's also a white paper coming out on that so we can have an any number of connection profiles and again if there is a need for data to go directly then a comms pipe um could also be implemented here and what this does is it normalizes everything because the the picture on the top is normalized using cns because i now know that this line here is made up of some cns connections of a certain connection profile name connection profiles it's all modeled and each of the connection profiles is then modeled so that you is predictable as normalized depending on the needs and the applications involved and the whole thing is dynamic and and composable right so we've gone from a completely un normalized world into a very normalized world so that's kind of the the what we think is the proper value proposition of this technology um getting to some tactical level how does this work if we imagine a connection profile called test.abc where the client is obligated to provide two properties in the servers provided two different properties when the the client starts up it does a registration it publishes itself to the orchestrator to the broker with this with a note id with the context that is interested in the connection profile that it's able to um to do in the roles in this case the client and the properties for one and through two it sends all of that to the broker the broker says thank you very much i've create i know i now know what you want and what matches i'm looking for um and have a nice day that's kind of it"
  },
  {
    "startTime": "00:36:02",
    "text": "sometime later a millisecond later or a year later the orchestrator the broker finds a match and it basically starts a flow of um what we're thinking of as a subscription because it's basically connected is sent to the client the information about the the the match which is obviously a server with those properties file one and far too and from here on in there is a an ongoing bi-directional flow of information one going from the client to the server and another one going from the server to the client simultaneously so that's how the mechanism works um put into sort of json way of thinking about it this is the same flow this will be a publishing packet manifest and this will be what comes back um here is the the node id and this is the connection etc and ongoing beyond that it's just the values flowing back and forth um just sort of zoom out a little bit and is just sort of how it how this works if you think of an environment where there are two different contexts you can think of this as a factory with a manufacturing plant and an admin plant let's say when a system instantiates itself says here's me i'm system one i can do these four things these four connection profiles a b c and d a is a server and the others is a as a client right now there's nothing else in the system in the in the environment so it's not connected to anything then system two comes along it actually bridges between context one and context two which is fine there's a matching a all right so that gets connected so that's good and there's really nothing else um one interesting thing to note in terms of the composability of all of this is that both system one and system two are clients to a some kind of trust connection profile which is telling me that both systems understand a way of using that trust connection profile as a way to determine whether their connections are"
  },
  {
    "startTime": "00:38:01",
    "text": "trustworthy and the these two clients are not satisfied right now because there is no trust server in this in the environment right now so there is no trust relationship between system one and system two and what is interesting is that can then inform what data flows in this a link that actually the connection profile actually knows nothing about the trust but the system one and system two does until sometime later some system x comes along with a with a trust server and then at that point a system one and system two would have some familiarity of the trust that they each have and so that can actually change the the nature of this connection um and obviously it's dynamic so if a system x goes away it can actually go back to that state so you can then go on and there are obviously other lines here that we can we can explore later so this is kind of the interesting thing about connection profile it creates this dynamic network i'm starting to think about this as a network lastly um this is really it's got a big question mark on it we're trying to sort of figure out how this fit in fits in with it with a sim layer stack we think it's somewhere like that um but we're not sure um and would love to get feedback or you know i think that's some work that needs to be done so that's that's um basically my presentation okay thank you anto uh the the agenda has a second presentation from toby we don't have slides for that toby he's on he's on the call and um yeah okay he's just uh asking for screen sharing so we are ready"
  },
  {
    "startTime": "00:40:02",
    "text": "um we can of course eat into the discussion and maybe i can also make the anemone part uh shorter so i think we do have so i don't know if i'm successfully sharing it this time because when i put it up i just see an a hall of mirrors and when i don't put it up well i just see my presentation so so given my ignorance of this particular platform am i sharing a screen now i don't see it okay so you you are exercising the screen sharing mechanics good for that a window okay and yet i have this up why is it not showing up are you trying the uh the icon the second from the left at the top left that says ask to share slides yeah that that's all active uh but for some reason his computer is not actually sharing ah there we go okay good good good good so so first i'm going to tell you who i am because you know take anything from anybody unless you know who they are um my name is toby constand i've been working with standards having to do with the internet of things for more than 20 years uh before that i spent a good 15 years integrating every kind of control system that you can imagine building systems transmission systems distribution systems uh large fluidized bed coal plant cogeneration systems thermal storage systems and just to make it more fun all of this was on a a us state university which means every"
  },
  {
    "startTime": "00:42:00",
    "text": "building was a low-bid government contract which means nothing talked to anything else there's no standards about what the systems were in there so that made me focus very much on issues of uh integration and other stuff before i could do anything else i want to talk some about having done status for years i want to say a couple things about what good standards are i think anybody's on this card called knows this but i think it's worth saying allowed anyway so good standards are stable you don't want to have a big complex standard that changes all the time when every time something new comes uh they have to be visible people have to know how to use them and see them and build their own value on them they need to be modular because instead of of changing things getting new versions of the standard once a week you want to be able to stick a new thing in and um so to me the the the we all use mail every day which is just this pile of standards the calendar comes in as just another standard in the stack we mix and match if someone's using plain text instead of html or mail handles it a few years back people using rtf instead of html standards just handle it you you so you want modular standards that can compose and adjust as time changes and that's very much my way of thinking about this stuff and how this works complex standards are hard to implement can be used more tools to make they can to be more exterior than stuff and i want simple standards that are that that you can ease and easily use and redeploy and put in new purposes including purposes that whoever at the standard never thought of now one of the things i said ahead of time was if you guys like this sort of a a early draft of something that might be a standards track rfc but it's it needs more work but i shared it early and i don't know whether that was shared with anybody else other than"
  },
  {
    "startTime": "00:44:00",
    "text": "carsten when i mailed it out but we can talk about that later and so i said i'd talk about more detailed things i was probably assuming i was going to be talking about that too um so as i said 25 years of integrating bis i was a significant author of the us national smart grid roadmap which is a system of systems it properly done attempts to make it be a single system we're all going to fail badly um i've got multiple specifications under my belt already obex which is a internationally used standard for talking to contr embedded control systems ws calendar which is a machine to machine schedule negotiation which is important for twins and other things but it's adapted for machine to machine negotiation but it's also somatically um identical to the whole icalendar family of iatf standards as part of doing that as with the team that updated all the i calendar standards in the last decade or so i know if you've been tracking them as a group but there's a new i calendar there's a new um there's a new uh v card there's a new um free to busy there's there's an entirely new standard availability which is very important for for um digital twin kind of stuff availability is oh this is available during business hours oh but what are business hours for you so it's it's repeating patterns over time of scheduled negotiations within smart energy as the editor of the energy market information exchange which is used and was has appeared in ieee standards energy operation of which open adr which is a demand response in buildings is a standard that was a decade ago i wish it was lighter and looser than it was but now there's an installed basis car to clean it up there's now common transactive"
  },
  {
    "startTime": "00:46:00",
    "text": "services coming out which is very much lighter and looser profiles of those standards i'm working with the spatial web which is similar to the digital twin efforts it's the idea that we should put um ar and ai and vrs as primary activities in the web and also have it fully distributed right now we've fallen into a walled garden mode that we got out of when the you know when the internet came in in a big way and i was working with the internet before this stuff came out with bitmap before that but there was a while where we went to walled gardens to aol to compuserve to bulletin boards and then they got open you could go everywhere and then we've all fallen back to oh but the entire internet lives in seven data centers worldwide which is a bad scenario for lots of things so part of the goal of spatial web is how do we make it entirely decentralized again including decentralized identifiers um how can i establish an identity for this context in this place without going back and having my identity checked out from a central repository that knows where i'm going and using it so there's a whole bunch of standards in that effort which i may talk about later and i've been working with anto on connection profiles trying to get that developed um trying to get that um moved up to a point where it's light and loose and easy to use for for multiple purposes i also work with the um that started the energy mashup lab which is whose purpose is free open source software apache 2 license for fractal micro grid operation based on transactive energy i can take questions on that if there's any but now i'm done talking about me um so i want to talk for a minute about the challenge of the internet of things which includes digital twins which is one that's much more diverse than typical i.t um there are more types of things i mean at some level"
  },
  {
    "startTime": "00:48:01",
    "text": "everything in typical i.t is everything that was in a novell network you know there's a database server and a file server and a web server and clients and find the protocols have changed but that's pretty simple framework but you get into things you have every kind of air conditioner every kind of extruder every kind of factory every kind of there's just more types of things they're also longer lived which leads to its own kind of diversity whole enterprise systems come and go well one air conditioning system lives on in the building um and that increases diversity even with a product line and brand line because of course now i might sometimes be talking to the 20 year old version of something in the 15 year old version of something in the 10 year old version of something and the brand new version of something so that's another whole class of diversity that that you get in the internet of things cyber physical security is ill defined at best for most people um and you know i i could i could be hacking a autonomous car by having an led flashlight on the side of the road and hitting the sensors in the right way i could be hacking an air a heating and cooling system by taking a little lighter and hanging in a holding it under the thermostat i could be so so i could be destroying battery systems by hitting them with a rather simple to make over the weekend ultrasound generator that would that would ping the battery and cause it to start overheating in interesting ways that the control system of that battery doesn't understand so the cyber physical profile cyber security profile is much much more complex than in traditional i.t um system configuration often requires deep domain knowledge and a lot of early attempts at during the internet of things"
  },
  {
    "startTime": "00:50:02",
    "text": "came result of people who thought they understood something because they were always the smartest guy in the room but they didn't understand that other people studied what they were doing for a long time and to me with my smart grid background one of my favorite examples of that is the um the disease that we now call legionnaires disease the reason it's called legionnaires disease is the utility guys who are the smartest because their electrical engineers told the hotel how to save energy in the wake of the uh 1970 uh energy price shocks and they told them oh you don't need to run the fans after a cooling cycle's over that's just wasting energy well they didn't understand that that was it we are now really running out of time okay i'll go fast forward to faster slides that actually are about digital twins okay so that's i'm sorry i just um i didn't anticipate so much into at the beginning of all this so the the the things i'm starting to do is is have abstracted ways to break up span of control to isolate diversity and encapsulate it to let system experts publish interfaces which is the heart of our proposal on connection on the cnscp system to empower developers uh this slide right here shows that the cyber physical security challenge and it's not quite clear who that surface that published surface is securing is it securing the crocodiles it's securing the researcher who's hiding into the crocodile um mask because the server can be hacking the client just as the client can be hacking the server it's just the internet of things and digital twins is a much more complex environment so those are those i think are the challenges of digital twins and the standards that i published and shared sent to you everything um so the pro boost oh look i misspelled my slides the pro cnscp specification enables anyone to publish interfaces"
  },
  {
    "startTime": "00:52:02",
    "text": "and then creates a universal registry the goal of that is to think so maybe i'm a company that's making a piece of equipment i can publish what a connection looks like maybe i'm an integrator who does some special thing i can publish what my interface looks like i can and all those are universally available like dns you know the the actual lookups are public but the use of them is private like dns so it's um this is all designed to be a way to compose cyber security uh application gateways line protocols and somatic overlays easily and simply um we've defined a model of connection brokers to create what's essentially a control plane of services for the internet of things to enable edge-based interactions with that central uh queries and without central authorization to enable advanced logging in forensics and to me one of the most important things is that the state of the broker becomes a long-term state for maintainability if somebody takes an old service away and replaces it with a brand new version you have broken connections those broken connections tell you what needs to be replaced i was doing significant enterprise interactions between internet of things and building control systems back in the early 90s and they were wonderful and they're almost never maintained because when something changed nobody could tell what happened so to me one of the big exciting things about the cns cp system is that it it intrinsically provides documentation of the decisions you made about connections already i want to talk about this one just a little bit it's very easy to focus on connection profiles here that this thing is connecting to that it's exposing that this is connecting that and there's a one-to-one connection"
  },
  {
    "startTime": "00:54:02",
    "text": "but this node here is potentially more interesting so this node's connected to two is it adding that one together or having a voting system before it exposes to something else before it exposes to something else can you build a framework of connectivity and knowledge and actors within a scp system to to bring different connections from different places into new meta information that's got new value and i believe you should be able to compose this and i think we we've got a proposal here today that enables you to do that so it's easy to when describing it it's easy to focus on this connection down here but this connection going to that where it's translating distributed that where it comes in as one of the three voting aspects that goes into that before it comes to that that is actually a more interesting fabric in many ways because that's where you get additional value from the network from the intentionality of the network and from how it's applied so i think whatever we do we need to enable the capability of the network talking to the network being an additional new source of value um i think cnc scp which i sent out to the group before but again i don't know if it's distributed um there's a seed standard for other efforts that are trying to do it digital twins has been mentioned clearly since we've been working with the digital twin consortium for some time were already embedded in them but say p2874 the ieee is talking about trying to build distributed meshes of devices and internet of things they want to every device and thing to share geolocation and be amenable to virtual reality depictions to be ready to be analyzed by artificial intelligence machine learning and even have augmented reality where"
  },
  {
    "startTime": "00:56:00",
    "text": "information coming out of the vr and the aiml and the geolocation comes out until what you might see as you walk through it and do it all in a decentralized wet manner they see the same connection profile as kind of a seed standard one of the ones one of the tools that they use to wire this up so so we're i think we've got a light loose standard in that way right now that i proposed and sent to the group before that works just like that is one of the pieces to connect more interesting applications together so um i think it gives you an idea of what we're thinking about and what the what the pieces are i gave these slides to carson advance which means they can distribute them i have some references on the work that follow because i do that after discussion nobody wants to see them but sometimes people want to look up what i was talking about and with that i welcome any questions or comments over thank you so i think we still have a couple of minutes to get clarifying questions out so anybody who has a question please raise your hand okay good are you still in mute carrie oh sorry i didn't hear my name uh i i have actually two questions uh the first when it comes to discoverability um i would be curious to know why you have a dns system that just didn't adopt dns uh secondly is the intention here ultimately that uh these connections are composed"
  },
  {
    "startTime": "00:58:01",
    "text": "without human intervention so for example in the case where there might be more than one provider for um some some information how does the system decide which of those sources it might use so let me let me answer that on the first on the first point about dns uh we did we did think about that there is one really very subtle difference between this and dns dns is really about discovering information in real time i go to cnn and dns converts it to an ip somewhere along the line right and that ip chain can actually change and there are different components of the dns record that changes all the time a connection profile never changes is immutable forever because it doesn't describe how you get to something it describes the the function or the the information of a connection between two entities between client and server and the intent is that becomes a specification that never changes so going to toby's comment that once you install something 20 years later you could still rely on that connection profile to mean the same thing as it was uh 20 years previous so that it also has a much more diversity of information than dns is i mean dns is used for all kinds of things but but essentially once you get the name which is very dns like you have any number of name value pairs somewhere with which you're associated with the client and some with the server profile if it's three i can name value pairs i can figure out how to stuff it in dns if it's 50 maybe dns doesn't fit properly there might be a way to do it but as of yet it's not clear to me i welcome suggestions on how to do it entirely with dns i love the things that have been done with dns like real-time blacklisting and things like that where"
  },
  {
    "startTime": "01:00:00",
    "text": "they've taken code they've taken functionality already available they've taken stuff that's already been hardened for cyber security and repurposed it for a different use well there's actually so far i just haven't figured out how to do it there's there's actually a whole i ietf working group called dns service discovery which is aimed at precisely this um so the second question about composability of connections are you proposing to do this without human intervention or not not clear to me but the the the ultimate the creation of each connection the answer is yes um but really in in practice what happens is that that that connection although those connections or connections occur um after somebody or following somebody does something manually in other words i install of a piece of equipment in in a in a factory and then i install it in the system that is the orchestrator managing that factory and that then triggers the discovery mechanism that is done by the the system assistance or the broker that then starts to create the connection so indirectly it is human triggered in most cases but the the actual nature of it is is not let's let's let's to explore that let's take a very simple almost trivially simple um um connection type ambient room temperature it's only one value it's one way but maybe i want to know it i might have a complex enterprise hvac system which can tell me that for every room in the building i expose those each of the context the context might be a room number or something else there has to be some semantic standard that is developed within a corporation to apply to that profile and then i can say look i've got all these room temperatures that i could expose to you well so the connections are created to this that guy to this system that wants to"
  },
  {
    "startTime": "01:02:00",
    "text": "consume ambient room temperatures as as all these these connections are there but maybe it says i only want to see the law i only care about the lobby i'm not going to actually wire anything else to use it so then the connections are there but unused the system has discovered them and said you could use any of these it shares the context so they can be used but but whether anybody wants to use them finds any value in using them that's another thing so connections have a life cycle between when they've been discovered versus when somebody says now i want to use them to when someone says no i'm not going to use them anymore so and and we can imagine this profile being built into things out of the box in the future and connection brokers so we have this notion of connection brokers which is a private thing connections themselves in this system are universally available and known worldwide but a broker might be private might have any kind of security decisions i don't necessarily want to expose to my competitor the details of connections that i have in my internal broker so you have these different realms of security for different things and that's outlined in the the kind of early draft of the rfc i just i i send out but it it also speaks somewhat to your your question carrie have you got your answer yes thank you okay so young dollar is next on the queue jan are you saying something we don't hear you maybe it's muted well he's not on my screen"
  },
  {
    "startTime": "01:04:10",
    "text": "yes okay it showed that i was unmuted or yeah that i was unmuted and but anyway well i have a question for my understanding and that is um for you for your two presentations this is this something that is being worked on inside the dtc as some sort of agreed best practices on way forward or how how do i interpret what you just presented from from a dtc perspective so the the the answer to that is no it is not an official mechanism or technology that is being adopted by the dtc and primarily because that's not what the dtc is is created to do the dtc is really to create it to understand the broader picture of digital twins and explore use cases and explore how to make digital twins work and so what the way i describe what we've been doing in dtc is actually incubating the connection profile mechanism by um exploring um probably about half a dozen to a dozen different use cases over the year 18 months that we've been doing that within the dtc so a lot of the thinking that i i shared sort of came out out of that that work um but not as it's not formally um an entity of um of the digital twin consortium okay thanks and then the follow-on question to that is uh if the topic of interoperability how that is being discussed in dtc in context of that there might be you know different practices in how you deploy"
  },
  {
    "startTime": "01:06:02",
    "text": "deploy solutions for for specific use cases yeah so there's a paper that i co-authored called the system interoperability framework which really explored what needed to be considered when you think about interoperability at the system level between systems and obviously with a with the digital mind a little twin um sort of frame perspective um and and that that led to this paper that i mentioned earlier um on the system of systems and uh really the the the link there is that we think once you have a whole bunch of systems that we actually that you actually want to interoperate with each other the way the best way to think about that is a system of systems because in a system of systems environment the com the the constituent systems that make up the system of systems they have to interact with each other in an interoperable way so that's kind of um how i would link the interoperability topic with um digital twin and system assistance i hope that clarifies things yeah no thank you i don't know we are over time but i i could have i could pop one more question um and that is related to uh daytime information model data and information models and ontologies etc looking at some other standards work that for instance etsy is doing around context information management and smart applications reference ontology etc uh and also the work that is being done in iso iec around asset admin shells that are you know industry 4.0 digital twins how does that kind of come does that come into the picture i mean i i missed a bit"
  },
  {
    "startTime": "01:08:00",
    "text": "the input or the discussion around uh around the uh data models and and ontologies actually yeah aaas came in quite often in the dtc discussions um and the the way we sort of think about connection profile the unique difference of connection profiles is that it knows about both ends simultaneously aas is not about that aas is defining what a a a thing is by create by defining it as a shell the connection profile is focused on how two things talked with each other and therefore defining the information that's needed from both ends at the same time and and that's that's really what this thing is modeling it's modeling a relationship between things um i think um as far as we are aware all of the other sort of ways of modeling things is actually modeling a thing not modeling a relationship that that is the key difference here so so there's side questions coming to me through the uh through the um meet echo me techo whatever it is about definitions of digital twins and how they work and the question is that's such a wide topic because digital twin means so many different things to so many people some people believe that it's a three-dimensional digital complete representation of every single thing completely and you need that for some things some people believe that it's a uh a complete record of every nut and bolt that was put into a complex facility or was constructed it's static but but that way if somebody kind of bolt rusts you know where we place where that bolt needs to be replaced that's one definition others are saying i just need these five facts so i can model them in my simulation and compare them so there's a lot of in any conversation about digital twins and how it works the first follow-on"
  },
  {
    "startTime": "01:10:01",
    "text": "question must be what do digital twins mean to you because it's all over the map yeah um and i also have a question for a link to endless paper anto can you send that to to i guess carson afterwards and he can share it with the group or they have a link you can post in the chat now yeah thank you thankfully you'll be on on the uh that you know it's in the eye of the beholder right i mean there are multiple interpretations unfortunately but thanks you can easily add documents to the github repository by making a pull request okay that's the standard way of putting in stuff there good so um we are at a 1350 world time of 1550 um the time where i'm sitting and i'm going to try to to get back some of the time by doing the next two segments but pretty quickly um i i have minus one minute i won't quite make that um so one thing i wanted to to talk about quickly is the activity in the network management research group to apply the concept of a digital twins twin to networks and as i said we didn't get uh someone who who actually represents this research group because they had a big workshop last week and we didn't quite pull this off um so basically they are thinking about a network as something that is worth having a digital twin of uh for for a number of reasons and they define this as something that has data both historical and real time that has models which allow you to find out what's what uh something"
  },
  {
    "startTime": "01:12:00",
    "text": "should be doing uh what something will be doing and maybe what something is doing in a different way than you thought so maybe it's doing it wrong and of course it's a number of interfaces between the network and the children and being the between the digital and the applications and they are looking at this from a network management point of view so they really want to analyze what's going on diagnose deviations that they're experiencing they actually want to be able to decouple the digestion for a moment and run it as an emulation system to see what happens if i uh do this to my network if i switch off that link or something like that and then finally to control the physical network by actually operating the digital twin and having that synchronized with a rear network and that of course requires some mapping mechanism and it also might require some coupling mechanisms because the the twins actually might be replicated as well so that you need some way to uh forward data from one digital twin to a different digit so this is obvious an evolution of of the old idea of of having management agents in [Music] network elements where you obtain data from and put into a management station that that knows what that the network element is actually uh doing and this is adding a lot of granularity to that so right now that what they have is essentially an architecture document that contains this uh picture here so we we have a physical network which is one uh part of the twin and we have an instance of the digital twin network and"
  },
  {
    "startTime": "01:14:00",
    "text": "that uses data collection from the physical network plus a control interface to the physical network and in that instance we have various things going on which in turn talk to applications that want to do certain things visualize aid with diagnosis or use the emulation capabilities to to actually see what would happen if some control operation were performed toby very quick question i i just want to observe that this is actually at the heart of of efforts at um at service ordered cyber security right now keeping twins running having them in full emulation knowing that the relationship that things have are complex and we don't know we can't look necessarily for one particular thing happening to hack them but we can notice that somehow they're being dragged out of the right performance out of alignment with the emulation so this is a key cyber security feature that's that's going on in some of the groups i'm meeting with okay so that was my two-minute presentation of of what the network management research group is um up to now i quickly want to talk about sdf because that that's actually a date and interaction modeling activity that has been going on uh for a while and which we made use of in the next uh two uh talks so i i must admit i didn't massage my slides a lot here but i think we can can still use them so basically the sdf was created out of the need for one data model and one data model actually is an organization that is not related to the ietf but that just"
  },
  {
    "startTime": "01:16:02",
    "text": "consisted of people who were coming together from various ecosystem uh standard development organizations and wanted to make sure their data models are harmonized uh in some way because you you don't really make your money from from having great data models you have make your money from from having your devices interact uh great with the devices which actually may be from a different ecosystem and so of course the idea is not to to have an n by m problem so you have to to translate between tens of ecosystems and have individual translators but to have something that is in the middle and can be uh used as a hub to get these data models together and the data models actually are lots because there simply are lots of different things that that you want to make smart that you want to provide interfaces with and uh so um that there are already uh some some 200 data models in the repository of uh one data model so that's the the basic idea and they quickly noticed they not only need those models they actually need to come and format to define these models uh in so there are very different terminologies very different ways of defining data models in the contributing uh sdos in the different ecosystems so it makes sense to talk about a common format uh first and uh the the interesting thing what happened was that 1dm decided they really want to work on the data models so the the definition format discussions were outsourced to the ietf and that's great because the itf is very good in solving limited well-defined problems"
  },
  {
    "startTime": "01:18:03",
    "text": "which is essentially what we got from from one dm and there is now a working group called asdf that is preferring this semantic definition format specification so this defines classes of things and while things might have some some data internally what really defines them is their interactions uh with their peers in the digital world which might be a digital twin but it might also be something very different so if a light talks to a light switch that's one of the interactions we want to uh model here and we do this by borrowing terms from from the human computer interaction world where uh computers or computer based systems have affordances which are the the knobs and and uh sliders and so on that can be used to do something with the physical item and the physical item reacts to that by by actually implementing these affordances and we have three big interaction patterns here property action and event i'll talk about that in a bit and finally we do have some common data structures so if you have an rgb lamp uh you probably have some common idea of what the color is and you can define that independently of any specific property action or um event so the the sdf specification is just a json uh document and actually it can be multiple json documents linked together with uh json pointers so that there is some reusability uh between uh the specifications so when we talk about these interaction"
  },
  {
    "startTime": "01:20:01",
    "text": "patterns we have properties we have actions we have events and these these are somewhat related to the interaction patterns we have in different models so for instance in the rest model that is underlying http and co-op a property would have its value examined using a get operation or you would write a value into a property with put you would do a post to start an action so a coffee machine might have an action make me a coffee and that that would be done with post and then there are events which are not really that great uh that great uh done in such a great way in the rest environment because in the rest model the initiative is always with the client while with event the initiative is with a thing yeah and then there are input and output values but this is essentially the the overall structure of sdf here uh so for instance an action um is comparable to a rest post it's a client initiative it has some input data and some output data and we have other types properties uh properties actually in some extension of the rest environment also have observability so you can have some initiative on the server side on the thing um aside i don't want to go into the details because of lack of time but i want to talk about events uh briefly uh so an event is uh comparable to to an uh observed notification uh but it also can be uh more precious so if an event is somebody put in a coin into the vending machine"
  },
  {
    "startTime": "01:22:01",
    "text": "that that has different uh cannot use the word property yet now different characteristics then simply observing uh the vending machine and looking whether there is a coin being processed right now or not so that that might makes an event different uh from a property but they're actually pretty isomorphic on the specification level so finally we have data and the data is mainly in sdf mainly is defined by their shape we also need some way to to add semantics uh to them but we we have a pretty rich rdf environment we can use for that and the data shapes are defined in a curated subset of the terms defined by jsonschema.org and we have a few more terms that that are sdf-specific uh such as content format which is something that that is uh specific to rest uh data and so on so uh together with these data uh we expect to have uh something we call mapping information which might include protocol bindings in the next version of sdf but right now we are describing the thing independent of specific protocols one observation here is that we we are using json schema aux style data modeling but with some sdf qualities but in reality what we are trying to model here is an information model so we are slightly abusing jason schemer org to to get the information model level information that we actually want to model but it turns out that that works reasonably well so um"
  },
  {
    "startTime": "01:24:00",
    "text": "we we we stick with this uh right now yeah and then of course you can do a lot of interesting things here so for instance there is an ocf model for for types of batteries and uh on the lower right you can see what types they actually have and uh that's actually a taxonomy and and maybe having an enum for that is not the best way of doing that um so there certainly can be improvements in the long run but it interoperates with the ocf model as it is so last slide from a uma diagram point of view we have things which are complete items and these have objects sdf objects which are not json schema objects but but objects in the sdf sense which have properties actions and events and these properties actions and events then in turn are based on on sdf data so if i had 20 more minutes i would now throw lots of json at you but i think you can approximately imagine how how this looks like as a specification document so this was a really quick introduction any direct questions to this okay so i think we can go to the next item let me unshare my screen"
  },
  {
    "startTime": "01:26:05",
    "text": "so patrick can you share your slides but i think we may still have the issue with the audio video so carson if you can actually shut the slides and later can tell when to change them sure thanks so that's the experiences one right yes okay there we are just tell me when to go ahead and battery we don't hear you can you hear me now yes yeah now we can hear you yes there's a little bit exercising here to get everything working or almost everything so please if you can change the slides so that i can't do now all right so i'm peter lari i work at the erickson research in finland and uh we already got some info from the sdf part so i will go to the tool work that we have been doing to make tools convert data models between different iot ecosystems and sdf the main idea here has been that we support sdf standardization and we distribute the knowledge of sdf with tools and also the support the detailed twin work more about that in the bin's presentation soon some of the tools have been published for our others to experiment in ericsson research github"
  },
  {
    "startTime": "01:28:00",
    "text": "and yeah so in this presentation we will go more to see how we can support digital twins and what challenges we have had actually during the implementation work okay next slide thanks uh this is a very short intro to digital twin definition language so dtdl and dtdl is created by microsoft and it's used mainly as your digital twins definitions it's an open source modeling language and it can be disk it can describe iot devices digital twins and also systems of digital twins but as what's important for digital twins it supports relationships and linking data with json ld please next so here is a high level view how well what dddl actually defines so on top of there we have the interface which actually is defining the uh the entity what we are talking about usually a sensor for example there we have interaction capabilities we have telemetry for the device to send information by itself to the network a command which is used to send commands towards the device and then we have properties which are some readable or writable information on the device the relationship defines relations to other interfaces external of this interface then there is still the component that can be used to build more complex entities by adding other interfaces to"
  },
  {
    "startTime": "01:30:02",
    "text": "this interface uh on the bottom we have schemas different kinds of schemas uh there are simple ones for example integers and the strings then we have there are more complex gamuts such as enumeration and arrays please jump to next and next here we have a table that shows the general mapping between different entities in different ecosystems and sdf on top we have here now an atomic entity or sorry we have this uh object i can't now see the slide unfortunately so we have in ipso we have this object which is defining basically one atomic component the corresponding in in sdf is sdf object and in dtdl we have this interface that was actually shown in in the previous slides these are quite clearly mappable to each other and there's no not much difference in that level next slide please now each of these components consists of some affordances we have here the trivial ones we have resources in ipso smart objects which can be readable and writable or executable in sdf we have sdf property and sdf action that are mapped to those resources and further in dtdl we have property and command so these are"
  },
  {
    "startTime": "01:32:00",
    "text": "very trivial ones basically that you can easily convert from one to another then we have two uh below there which are not that directly mappable so but i will come back to those later next slide please now it's a sometimes useful to combine these atomic objects into larger units this can be exam for example weather measurement device it that has temperature humidity and air pressure sensors now when we are combining this we can actually define one data model for the whole device which makes it much easier to deploy for example tuna to an iot platform in ipso this is defined as a composite object so that we can create a new object and add their existing objects in sdf we have a called sdf thing containing multiple sdf objects and further in the etdl we have an interface again that can contain additional interfaces using component definition so basically there is a similar functionality in all all of these next slide please this is a very simple snippet of the temperature sensor ips object and here we can see that the resources two of them which is a central value and the reset min and max measured values they map directly to sdf properties sensor value and sdf action reset min and max values most of the data models are on this level that are"
  },
  {
    "startTime": "01:34:00",
    "text": "really simply mappable to each other in other ecosystems also so we all always say like roughly 80 percent of the models are this easy to do but on next slide we can go into more challenging and more interesting things there can be either incompatible affordances or completely missing affordances between different iot ecosystems now when we are talking about incompatible affordances there may be that same functionality exists in different ecosystems but for example it is not modeled expressly explicitly in the data model in another ecosystem this makes it uh in a way when it's in the data model it's easy to convert from x data model to sdf but if it's not uh in the model in y then it may be a little bit trickier to convert from sdf to y one example of this is the dtdl telemetry and that might that maps directly to sdf event in sdf but in ipso this is not modeled in the data model itself but it's implemented using a lightweight machine to machine send interface so same functionality exists but it's defined different ways then if we have missing or incomplete affordances why this would happen there may be some ecosystem specific features somewhere that are required to be defined in one"
  },
  {
    "startTime": "01:36:01",
    "text": "ecosystem but in some other ecosystem it may be that that is not that's not existing at all because it hasn't been required there so how what can we handle these cases of course sdf needs to support this kind of extension also and we have now also thought that we can actually design in the other ecosystems or request the standardization organizations if there is a need for such feature also in that in that way we could in the future possibly make the data model ecosystem different ecosystems data models more compatible with each other which would make it much easier to work or make the conversions between the data models so uh on the next slide we have one example of uh such such affordance so dtldl defines arbitrary relations between entities using the relationships this is an important feature in digital twins world and in ipso there is a limited support using object links but that's not exactly the same one so what we're making here when creating the tools uh we first figured out that okay sdf the first version didn't actually support any similar operations so we are we have been working with an extension called sdf relation to add"
  },
  {
    "startTime": "01:38:02",
    "text": "this support also to the future versions of sdf our dtdl to sdf tool actually implements already this one this feature and we are currently working on an ietf draft on that topic so in general the relationships can be quite rich we have the easiest ones are to talk about the physical relations which is something is inside something and something is next to something then we have functional relations so this device can control the other one but then there's a semantic relations so basically what are certain affordance means for the other host so that is quite rich way of describing and what we have been thinking here already that basically the same mechanism to trans transform from one data model to another we can still maintain the same mechanism to do the translation and then use some other ontologies for example to define what the relations are actually on the next slide we have uh our very short intro to the sdf relation extension so on the top right corner we have an sdf thing robot arms containing three different robot arms and on the left we have the json file and on top we have the namespaces that we are actually using the terms is basically referring to our example com relations terms which defines some kind"
  },
  {
    "startTime": "01:40:00",
    "text": "what kind of relations these uh different sdf objects can have with each other and one ontology for example where the relations are defined quite well is the etsy sarif ontology which can also be used here if needed on the actual file size the sdf thing contains robot arms or different robot arms it contains sdf object arm a which is the leftmost object here in the victor and there we define the sdf relation which is next to and we the type is next to something and the target is arm b so this is quite trivial way of doing that and the same goes for also sdf objects b and c okay then we can go to next next basically so the tools what we have been developing on top we have this our public releases they are in the ericsson research github repository which is the in the github.com and we have their ipso and dtdl to and from sdf conversions then we have their sdf thing creator which actually can use to combine multiple unique sdf objects into an sds thing in addition there's the model validator which can be used to check that if the sdf model is valid in addition we have been experimenting internally with opc ua and ngsi ld converters and also we have an open api and graphql api converters if you're interested you can go and try"
  },
  {
    "startTime": "01:42:00",
    "text": "these conversion tools there's a wishing nomadic.com link there and there are both ipso and dtdl tools from us and then there's web of things and young tools from university of braman so you can test how they convert to sdf and the other data models okay and next next so basically the two key takeaways we can use sdf with digital twin languages such as dtdl and we can provide systems descriptions on dte ecosystems we have created tools to do conversions of data models between different ecosystems and sdf and also one nice thing is that we can contribute to the standards organizations when some missing features would make sense in the future thank you there's also some references on on the bottom but thank you that was quickly the one i guess we are running out of time soon we have still been coming thank you petrie so are there some some direct questions we we should still have a little segment for discussions at the end michael two two quick points uh this is fine um and and you know i've been working with with these folks on this idea also i'm also modeling a digital twin system for my employer passive logic unfortunately i'm not able to share any of the details until we get some more agreements in place but i make a lot of use of this relation type and i found it i'm considering a property graph format where i add an additional value into the link and i also distinguish between the class"
  },
  {
    "startTime": "01:44:01",
    "text": "and the instance in the target but i wanted i wanted everyone to hear that because there's some ongoing stuff that might be controversial so um i i think i'm i'm involved in driving that forward also and let's let's make sure we get the use case for that nailed down okay thank you for the heads up michael i think we can have a look into what you are doing at our next meeting we might want to pick this up in the next wishing meeting in in two weeks from now um actually so please start preparing slides so finally bin do you want to share your slides or do you want me to do that [Music] yes i can share the slides [Music] ah okay it's better you share the slides thanks okay there we are yes thank you so uh the presentation is about building digital twins on the interoperable iot technologies so uh which we can see from next slides starting yeah thanks first a bit a little bit introduction uh what is the digital twin based on iot platform refer to so iot based uh digital twin uh means virtual representations of real world entities uh primarily the entities are primarily about ots operational technologies and pros processes based on iot platform and then synchronized as a specific specified frequency and ability to serve different industry applications so i a digital twin based on the iot"
  },
  {
    "startTime": "01:46:02",
    "text": "device platform for us we consider the enabler for various industry applications uh a broader use cases basically and the iot-based digital training is to present the uh and interconnections with the physical devices and operational technologies to capture the environment status of course iot based and then the iot and then it is also tool to provide and the user we can say industry applications with useful insights and automation capabilities and some other wanted capabilities to meet the end the user needs without to dealing with low level data and events because that's managed by iot platform an iot based lead shooting act as a layer of abstraction between physical devices and user-centric interest providing capabilities such as automation emulation for industry applications and on the small graph you could see that the digital thing uh iot based each twin platform is connecting to the northbound of uh um iot platform and that uh between that we have the interoperability enablers for example sdf working to support that we can understand a bit more in the next slide yes uh and first there are some core features that we need or information uh we need to build up a digital twin based on iot platform first is the device related information meaning this device descriptions device related environment context descriptions and so on and we know that uh the heterogeneity of device on the iot platform it has itself will make the digital twin facing heterogeneity challenges so that is something need to"
  },
  {
    "startTime": "01:48:00",
    "text": "be addressed an iot device measurement is another thing uh data we need to all information we need to put into the platform measurement of data collected from iot devices and different types of sensors or any devices connecting to the iot platform and in that case light weighted lightweight transport mechanism for are needed especially for handling those time series data for feed into digital twin components and also logic purpose for from industry applications and that is to tell the digital twin uh platform about what is the requirements or needs for for industry applications basically how we want you to serve we could go to nexus lines thanks and so so by so far you could see we we needed to address some heterogeneous challenge when it comes to the digital twin and primarily about relating to the hydrogenity of iot device platform and the data objects generating from those heterogeneous devices came into different uh templates and formats and so on and usually we prefer those things to be addressed in the early phase because when the platform scale up and the heterogeneity will getting even more complicated and handling those heterogeneity in the late phase will actually be expensive it costs extra time and resources and so on so that i i took the premise picture here with emphasizing on the interoperability enabler which is something i would say supporting these two but on the residing on the iot platform side"
  },
  {
    "startTime": "01:50:01",
    "text": "and next slide please and so what we did here uh is that there'll be some exercises and work has happened that we use sdf and the sender to to support the digital implementation and in that sdf serves as an intermediate data object translator so that the heterogeneous data objects from iot platform can be organized in your in a uniform format uh and also so that sdf work with iot device platform to handle heterogeneity in early phase before we feed all the data objects into the digital twin component so that is something to save some time and extra resources in early phase in an efficient way and besides the iot platform in text device related data objects and using sdf and other functionality modeling components functional uh functionality components in digital twin can also interact with sdf as well so those components are for example taking objects data objects using sdf and so on and providing automations uh functionalities and for simulation for emulations and so on uh and the moreover we also did using the send ml for the light weighted data measurement collection for uh digital platform and as mentioned in the previous slides as one of the core features the data measurement is something we need and better to being lightweighted and in a good sequence and we think it's a good combination with sdf as well so that's all the"
  },
  {
    "startTime": "01:52:01",
    "text": "presentation i have we can have some quest time for questions [Music] so questions for bin michael yeah i'm sure this would be a longer discussion but i'm kind of wondering um whether on your digital twin side whether you still deal with the diversity of models like um just converted to sdf but you still have you know a diversity of models or whether you also translate to a set of very simple models on the digital twin side and that's probably a longer discussion but i think it's a an interesting topic thanks a very good question so first uh when you refer about models i i here understand is about data models and and of course way way if we look at before on the slide there being let's say we're plugging our digital film platform based on iot platform so so that the models we've been looking into and pulling to the in the digital twin platform part will be more at once the functionality related or i called advanced capability automation and emulation things and so on and so that the data related models are more happening on the iot platform side so and if you have something for example uh translating mutually translating with sdf or some other stuff it's enough for us to take into i don't know if i'll answer your question in a good way yes yes thank you that helps that helps a lot i think some ongoing"
  },
  {
    "startTime": "01:54:01",
    "text": "discussion around that would be very interesting thank you sorry yes thanks michael i think like that perhaps the next wishing meeting would be a good opportunity for us to go go deeper exactly on that top because i think it falls very very well there so just a a quick plug on that so we're planning in two weeks and to have the next vision meeting and the information on that it's going to be going out any moment now so you can go in more detail on that specifics thanks so jen commented on in the chat that this is also about knowledge models on the digital twin side so maybe we can dwell on this term knowledge for a short amount of times or what what is the kind of knowledge that we would want to support now uh is that a question for for me or not for young uh have many interpretations and if we talk about data models that been explained is more like southbound uh then we can uh have ontologies that represent a higher abstraction of of knowledge inside a digital twin uh that contains a lot of different types of relations that are more related to let's say the end user facing aspects and interests that you have in"
  },
  {
    "startTime": "01:56:00",
    "text": "in modeling physical reality but i i guess that that is definitely a much longer discussion around around models but i just wanted to highlight to michael's question adding one component to that thank you that's very uh insightful to add the the internal knowledge base as as different from the say telemetry and control that's happening but knowledge also tends to be associated with the system i think more so than with individual devices so i referring custom to the fraction of knowledge that would pertain to that particular digital twin or some pointer to the system knowledge that it participates in well my question was a bit about the the issue that um there's a ton of knowledge out there and um for a digital twin uh this uh the subject said that is actually relevant to the the physical things that it manages uh would be very useful to to be accessible and i think that's an interesting observation so normally if you just uh follow the graph then essentially you just pull in everything and that may be a little bit too much to to actually do uh useful reasoning so that may be one of the jobs of the digital to to keep the relevant knowledge accessible to inference"
  },
  {
    "startTime": "01:58:02",
    "text": "first then if you go back to the to the flock of birds model um each you know element in the flock has some local knowledge but it almost seems like you need you know to stand apart or stand above the whole subsystem you know to see the whole picture maybe that's the role of the orchestrator i don't know or maybe you can just discover whatever you need to discover in order to to form that whole picture of the flock not really sure but you know obviously there's a there's a you know this uh the knowledge as it were is um distributed and you know how do you knit it all together into a whole picture that's i think an interesting question yeah if i can just chime in that's that's the whole notion of focusing on the relationship between systems and essentially essentially not just recognizing that there's value in those relationships which has been talked about in a couple of the presentations here but also to model it so they can be easily instantiated when needed and automated because if you think about the dynamics of digital twin and iot that last over years and decades you really have to have a mechanism that can model how things plug into each other so i just wanted to chime in on that so there's always a challenge in doing digital twins you want to avoid a one-for-one model that is complex as whatever it is you're modeling including all the flaws and errors and defects in the current modeled system um because then it's you've just got the"
  },
  {
    "startTime": "02:00:00",
    "text": "complexity the simplifying it the abstraction i like the notion perhaps of sdf being in between uh twins when they're talking to them that's a that's a potentially very exciting model but but you always want to step back and say what am i doing this twin for what is its purpose and how how much of a slice through the life of this twin do i want to take that's actually useful and i think that's the art of digital twin right there over okay thank you i think we have exhausted our time what we should briefly talk about what we are going to do next um so we have various pieces of input and the first step of course is collecting that input in the github repository so please send pull requests um for things you want to put there and want for other people to read ari has mentioned that we will have a wishing meeting which is essentially just a slightly lower profile uh meeting than a whole research group meeting uh so those people who really care about this stuff may be wanting to to join the wishing meeting two weeks from now we will talk about um some general work of of defining the the iot standards landscape but we also will continue this uh discussion and and michael koster has already hinted at what he wants to discuss in two weeks from now so if you have additional input we certainly can pick this up uh the week after next week and ultimately i think what we should discuss is um i mean the objective of this meeting is to make everyone aware of what the others are doing"
  },
  {
    "startTime": "02:02:01",
    "text": "uh so that that's good but we also should discuss is there something like a document we we may want to have that that collects some of this information and these documents of course start by people submitting drafts and having discussions about these drafts and maybe at some point the research group deciding that this is a useful draft and we may want to develop this as a research group draft or we may want at least one to encourage the author of the draft to go ahead with it with it even if it's not exactly research group consensus initially so um yeah and there is the mailing list uh i i would like to remind everyone that we we can have very good discussions on the mailing lists as well so if you aren't subscribed to that uh yet uh please do and yeah let's uh maybe meet in two weeks in the wishing meeting and continue this discussion thank you everyone for your contributions thanks question thank you thank you thank you everyone bye thanks bye"
  },
  {
    "startTime": "02:04:01",
    "text": "you"
  }
]
