[
  {
    "startTime": "00:01:05",
    "text": "We're gonna give people a couple more minutes to filter in after the delicious and nut nutritious snacks see if I can spot candidate it. Pinging allen would be the for. While we're waiting, if people can be sure to log in to show that there. To sign... Virtually sign the blue sheet, And we have any volunteers for note taking for the session. That would be appreciated. We won't be able to get started until we have a volunteer."
  },
  {
    "startTime": "00:02:00",
    "text": "And with the automated transcription or the transcription service that we have for Today's session it shouldn't be two onerous a job for capturing notes just really the... Any discussion... Any decisions taken, etcetera. Do have to go run the hallways and get somebody to come join us. Sanjay, you like to take notes wouldn't you? No. Maybe. Volunteer here. On this side. Or rally. I like you do it. Hey, Ali? You know, what you'll be really great, Ali. Remember that that favor I said you owe me? Would you like to be the notes taker? We would appreciate it. So I did a favor for Ali a little earlier and and I I like to pay back less than a half hour later. So that also keep you from to the microphone asking questions. See. Talk through this."
  },
  {
    "startTime": "00:04:06",
    "text": "Alright. So just some before we get going. Thank you everybody for coming. And a few if you notes and details as I said earlier, please do log in or use the and Qr code in order to virtually sign a blue sheet that we can demonstrate how many people were here since we are still in the Covid reality and it is a requirement of the It ihs meeting if you are in this room you must be wearing a mask. And if you don't wanna to wear a mask, that's fine, but please leave this room. So thank you everybody for doing that. I know we all enjoy it so so much. Okay. I think we're about ready to roll. And so thank you to begging for being our note taker, I'm sure if anybody else wants to leap into the shared note taking slides, to note taking sheet to help take the notes that would be appreciated. And Yeah. So I'm... One of your c chairs Leslie. Kyle Rose, our other c chair is is that home in the Us and attending remotely? You can say hi Kyle. Hi everyone. And Glen, our technical advisor is up here at front. Helping me with this particular session. Hello everyone. Great. Alright. Yes. So the usual please do note well, all the things that we must know well. About the idea of processes and policies. If you are aware of any Ihs contribution that is covered by patents or patent applications, you must disclose that fact"
  },
  {
    "startTime": "00:06:02",
    "text": "or not participate in discussion. As a participant or attendee any activity, you acknowledge that written audio video and photographic records and meetings made be made public. If you're wearing a red lanyard, the photographers won't come up to you and stick a camera in your face. But if you come up to the microphone and ask a question, or presenting do understand that you will be part of the the video record. And please do observe the code of conduct. If things get we're gonna do our best make sure that this session is civil and usually pretty successful of that because y'all are very civil civil lot of people. But if you have any questions or concerns, please do contact Pm team. And then all of the the requisite documents there. Yeah. I said, please do sign into to the session. And remote participants, please make sure your audio video are off unless you are Now. Presenting during the session. Next slide, please. I think you're even though it's only Monday afternoon, you're probably pretty familiar with these resources already. Great. So here's today's agenda. It is what is posted in the meeting. Materials, so it shouldn't be there should be nothing surprising here. Thank you again to Ali for being. Our minute taker. One other point of order, I'm going to ask that everybody who wants ask a question during the session do use the Mid echo tool so that we have unified queue from remote participants and local ones as well. And any other batches to the agenda. Not hearing any. Let's move on to the next presentation. So Renin, are you ready? Yes. Can you hear me? And Rita, do do you want me to run me slides locally or do you wanna do it yourself?"
  },
  {
    "startTime": "00:08:01",
    "text": "Can you please run the slides locally? Happens do it. This is the one right. Yes. Okay. So hi everyone. My name is Wayne Krishna. And I will be presenting an update to our draft. This is a joint work with. Next slide, please. So the updates to the draft are as shown in the slide in section five point one and section five point two. We will talk about these changes in the next few slides. Next slide, please. In section five point one the we have elaborated on what Xr workload characteristics can be expected by network operators. Their operational consequences and some pointers to the operational strategies that can be adopted by network operators. Our use case and of six degree of freedom video or point cloud And so we'll require two hundred twelve thousand Mbps s of bandwidth. As seen from the table, the Xr applications such as our use case, transmits a large amount of data per unit time as compared to traditional video applications. As a result, issues around arising out of heavy tail parameters. Such as long range dependent traffic, self similar traffic, would be experienced at time of milliseconds and micro rather than hours or seconds. Additionally, burst at the time scale of tens of milliseconds, due to multi factor spectrum of traffic will be experienced."
  },
  {
    "startTime": "00:10:00",
    "text": "Now long range dependent traffic can have long burst and various traffic parameters from widely separated correlation self similar traffic contains first at a wide range of time scales and multi manufacturer spectrum burst for traffic summarize the statistical distribution of local scaling exponents found and traffic trace. Next slide, please. So let us look at the operational consequences of Xr traffic having characteristics such as long range dependency, self similarity and multi fractal spectrum burst. Firstly, the end servers, which multiple xr devices are connected wirelessly could face long burst of traffic. In addition multi fractal spectrum burst add the scale of milliseconds, put end use jitter contributing to motion sickness. The operators of edge servers will need to run something like a managed edge cloud service to deal with these problems. So functional functionalities is that such, it's cloud service could operationally provide into dynamic placement of Xr servers. Mobility support and energy management. Providing edge server support for the techniques being developed at the death net and raw working groups at the could guarantee performance of Xr applications. That's the provisioning of its servers in terms of the number of servers, the top where to place them, the assignment link capacity, the number of cpus and gpus, should keep these factors in mind Next slide, please. Now in section five point two of the draft, we have elaborated on what Performance metrics that are acceptable to the user can be considered. Their are operational consequences and some pointers to operational"
  },
  {
    "startTime": "00:12:02",
    "text": "strategies that can be adopted by network operators achieve those metrics. This table shows a taxonomy of applications with the associated x expected late and bandwidth. Are used case was a round trip latency of twenty milliseconds at most. And preferably between seven to fifteen milliseconds as discussed earlier. The required bandwidth for our use case as we have discussed earlier is two hundred to thousand mbps. Next slide, please. Now let us look at the operational consequences of the desired performance metrics for Xr applications such as the one proposed in our use case. Since I use case and researchers multiple users, running xr applications on their devices and connected to an edge server that is closest to them. These latency and bandwidth requirements will grow linearly with the number of users. The operators should match the network provisioning to the Max number of tourists, that can be supported by link to a server. Next slide, please. So we'd like to invite comments from the working group regarding the following changes that we want to incorporate in the draft. Firstly, we want to distinguish throughout the draft between the response times required by Xr applications, such as our use case and the end to end latency metric used by network operators. Secondly, we propose to update the numbers as per the distinction above including stating that the latency and Throughput numbers reflect the current technology. So with the chairs permission, we'd like to ask the working group if with these additional changes, is there document ready for the working group last code? Yep. I think first let's see if there are any comments or questions about content of updates"
  },
  {
    "startTime": "00:14:01",
    "text": "that you were outlining. Anyone I'm not seeing anyone in the queue. And then as Was pointing out, our hope and expectation when we left London was we were that close to being able to put this document to last call. So it it is still the case that we think we're that close. And would like put the document to working group last call. So I I would support Question, basically, if it would the changes as propose on this slide, Any... Personal of all, any objections the changes as proposed on this slide or suggestions for alternative approaches. Not hearing any not not hearing much a proof of life in the room. Columns thinking about it. Oh, there he goes. I was gonna say I I read the document. This is a moving target. This document never gonna be perfect of course, right? And I thought the general shape and structure of, you know, basically what it said seemed about right to me or whatever close enough for close enough for last call. I don't know. I mean, I I I I... My I I have read the document and I supported going to last call. How about that? That's awesome. Thank you, Colin. Okay, and Chris lemons. So with that, then then I think Rin and you have your you have to go ahead you wanna make those changes as you've described and then as soon as we have the updated document then we can initiate a formal than last call mailing list. Okay. Thank you very much. Great. Thank you very much. Okay."
  },
  {
    "startTime": "00:16:01",
    "text": "So next up, is Yeah. T n and Lenny, I think you said you were gonna present So just take control of and and like you didn't or our I released the slides There we go. Okay. You guys hear me? Yes. Thank you. And you can see the slides I assume. Yes. Great. Alright. So since last last I've spoke one to team This document was not by the working group. Thank you. From that last draft We added a c offer some minor changes. Today what I'd like to do is just kind of briefly all today is, you know, we're about today is of just a reminder for those who haven't heard the draft or forgot what we talked about four months ago. Just a a a a brief review of what it is and it does and why it's useful. And next steps. And we'd like to hear from the working with here, you know, what what are the types of things like this we added to to folks would like to see out this trap. So the problem statement is is pretty simple simple. Live audience sizes are exploding. In in in the last few months, we've seen events with, you know, on a weekly basis"
  },
  {
    "startTime": "00:18:00",
    "text": "you know, specifically, thursday football. With, you know, twelve to thirteen million simultaneous viewers. Combine that with increasing bit rates. Four k a k ar. And the the combination of these two suggest that maybe we are an inflection point or if if not now. Will we ever be. And if if the answer to either of those questions is yes, you know, it's worth asking what should we do? And that inflection point is the amount of resources consumed on the network. By live mass audience. Events. The other thing you keep in mind is that live streaming is fundamentally different. And has a different and characterized with different demands and to on demand streaming. Specifically the latency expectations are much much more stringent. Because, you know, things like don't wanna hear your neighbors cheering or the bar sharing. I mean, it for the super you know, at the the game winning score occurs. And also things like micro bedding. Have even tighter requirements for for latency. Also join rates are vastly different. On demand. It's it's kind of smooth predictable. It's significant growth you know, in and and over the course of the of an evening. But but it's it's smooth and predictable whereas with with live events, it can be almost like a step. Everybody turns into the game at the same time. So there are tools to solve this problem. You know, network based replication been around for quite some time, you know, thirty years or so."
  },
  {
    "startTime": "00:20:01",
    "text": "And you know, specifically, multi cast has been fairly successful in some places and some, you know, financial for example, it's absolutely vital. As well as other use cases. But for the most part, it's Multi multitasking seen success. Only on walled garden networks. Internet, multi cast over the top. Hasn't been much a success. So, you know, it's worth noting, like, what went wrong and you know, are these are these the reasons it went things didn't work out so well in the past. Are they still relevant today or there anything new? So it's worth going back to look at, you know, the problems with Internet multi gas. The three big problems are the all nothing problem that is, you know, every layer three hop between source and destination must support multi gas. Which is a pretty big barrier. By the way, v six has the same problem. You know? Has also seen challenges in the last thirty years to ubiquitous deployment. Getting every single router and firewall on the internet to support it. You know, know routing protocols is not an easy thing. And proceed this way too complex, you know, with an alphabet soup of of protocols that, you know, no one a few people know or ever want to learn and understand. So the perceived benefit isn't worth at the cost of deploying and operating the network. And then checking a egg problem of, you know, there's no there's no audience because there's content. There's no content there's no audience. The good news is these challenges from the past that there are new network replication type technologies that address each of these problems. So You know, we're we're we're kind of at a good point where, you know, the the the the the challenges in the past and and the the costs of deployment have been dramatically reduced. And that's what trade is."
  },
  {
    "startTime": "00:22:01",
    "text": "There is the the the the components of Treaty are are are not new. They've get that around some time. But Treaty is really the synthesis of these of these building blocks. In a in a rather novel way. So it it leverages native multi cast combined with overlay. To deliver multi gas services. To potentially anybody I mean So the native component on net is is Ss based. For those not familiar, source specific. Vastly vastly similar simplifies multi gas deployment. So this addresses is the the complexity problem. And it turns out when you switch to Ss. You eliminate, say, you know, ninety plus percent of the complexity and the complaints that folks out about deploying cancel. Ss. Second, for those parts of the network that don't support multi cass. To address that all or nothing problem. Overlays. And and you know, it used to be. You know, tunnels where when I when I started. In this this business, you know, tunnels were seen as a sub suboptimal hack to be avoided. Now all the cool kids are doing it as long as you just it overlays. Alright. So overlay technology allows specifically automatic multi tunnel. Which essentially allows the end host. You know, think your your your your laptop your smartphone or ipad, whatever. Is able to dynamically build tunnels to the parts to a the multi cast a part of the multi cast network. That is multi multitasking that is native. So this kind solves that last mile problem."
  },
  {
    "startTime": "00:24:04",
    "text": "And maybe be all nothing problem as well as the chicken is now. All all potential internet users are our potential audience. And it also enables incremental deployment. With with these tools. Previously, like I said, it was all nothing. But now can deploy multi cast natively in those parts of the network that are natively deployed. Can enjoy the most benefits and, you know, you just tell all the parts that happened. So this is kind of a picture of what it looks like. You know, the big I Internet is the the big the big cloud. The green part is the the the treaty end provider, which is kind of a native the native components of the network. So kinda those from content provider. To the to native on net receivers. As well as to the edge of the network where these thing where there are Am relays and the A realized tunnel be content to off receivers. Those are receivers that are to cast only parts of the network. How does this compare to Cdn? Some, you know, a astute survey observers might say, well, you know, we've we've kinda got Cdn, you know, they they kinda do replicate network based replication. Except you don't need a bunch of new protocols to make it work. It just kinda works. And and that's true. There's different Cdn models, but, you know, common model is. You send content to these Cdn boxes and the handle local receivers. How's that different? With Treaty. And with with with treaty essentially, it's a Cdn use that that leverages multi multitask. One with that Am relay you know, kind of replaces the the Cdn box. And it it can be pushed further. Closer to the receivers."
  },
  {
    "startTime": "00:26:04",
    "text": "And content only needs to go to relays that have interested receivers? Also, it doesn't require a separate physical box. It it it's it can be a capability built into the existing network infrastructure. So specifically, routers can support am. And if those already support A t, you can literally, you know, think of it as cdn on the chip. You can literally deliver this traffic at zero you know, essentially zero Capex, if it's already if it's available and already to deployed hardware. And you could already zero Op fact that, you know, you're not how, you know, creating more power in space. Support So the benefits, you know, better utilization more efficient utilization. Not only does it make existing content scale better. But it enables new content. You know, question for folks, you know, could you do Ar live streaming let's say, you know, a five gig stream, we're a one or two gig stream to tens of thousands, hundreds of thousands of viewers. Is the Internet up to that? And it handle that to that. With multi multitasking. And in treaty It certainly can. It scales to support that. So these are these are things that, you know, maybe it's just not viable economically to do it. It enables service providers to offer new services reputation as a service? Again at potentially zero additional cost. To deliver this service. That is if your existing infrastructure already supports anything. This is an open standard based architecture. With widely understood and available protocols. Which is, you know, a a a difference than between that and say previous, you know, traditional immune cast"
  },
  {
    "startTime": "00:28:02",
    "text": "Cdn that may be leveraging them proprietary technologies. It also involves far less coordination between the provider. And Cd essentially, things like data storage protection, good the network is just pushing packets. So all that other stuff can be pushed out of the responsibility of the network. And middle boxes. Into something that is just handled by the content provider and the end user. So all those functions need to still exist. But it is handled between the content provider and the end user. Without the requirements of the intervening networks. Also it potentially democrat and decentralized contact sourcing, you know, is it is it healthy for the Internet in society to and four companies. Control, you, most content distribution in the internet. Use cases, you know, we we think mostly about live streaming because that's kind of the sexiest most interesting use case. But it's really about any traffic needs there go multiple destinations. So you know, the least sex perhaps, you know, most tactical use case is large file. Software updates. Things like Os updates. Those can really crushing up when they come out. This is a way to more efficiently distribute this content that won't crush networks. So just to kinda summarize you know, if you look at things in terms of supply and demand, you know, we may be hitting that point where these two, you know, supply and demand curves are crossing where you know, perhaps up until now Multitask wasn't needed because life stream sizes. Audience sizes weren't big enough we're bit ready work kinda. But you know, we we"
  },
  {
    "startTime": "00:30:00",
    "text": "with with things like there's a nice football and that's just kind of the tip of the iceberg. With more and more sporting events being handled. Know, exclusively over the Internet over the top. That this this may be a technology that, you know, all of a sudden, you kinda actually do need it. And at the same time on the supply side, you know, previously network based replication was really complex and costly and difficult to operate. But but those issues up been solved. So it's easier and more available than ever. And that's what T is doing. It's it describes a Cdn model to it's optimized handle this this use case. Alright. So next steps. So that's the review part. Next steps. Things we'd like to add, you know, plan to add some you know, basic stuff at add some diagrams, some folks have commented that know it would help for provide clarity. As to how these pieces work together. And, you know, the biggest thing is gaps you know, what else is needed to deliver a useful product, Kyle kinda things off with similarly thought comments. About, you know, the missing pieces. That that are kind of, you know, that that traditional Lu cast based Cdn deliver today. Most of the issues he pointed out are our kind of transport issues. That that aren't really unique to Treaty or multi multitask. They're really just more about, you know, non Tcp traffic. And... But the that that said, you know, this this delivery, obviously just not support you at least for the delivery of the actual content. As as the draft notes. Tcp sessions could be used for a pack channel and telemetry and you know, bespoke advertising."
  },
  {
    "startTime": "00:32:01",
    "text": "But the... So kind of the separation of kind of the critical content, critical information, metadata. Is handled by Cast, but the actual interesting content it needs to be delivered, you know, video streams. Could be handled by know, multi multitask using tri. So Kyle brought up a number of issues things like reliability and resilience. Visibility. How do you know what when there is loss and what to do if there is loss and and predictability of of the network and what It can deliver. These are things that have been traditionally delivered you know, Tcp helps out a lot. At the same time, while this Well, it's not using Tcp, while this model doesn't use Tcp. Deliver these things. Many of these capabilities can still be provided basically between the content provider and the end user. So some of this information some of this content maybe outside the scope of this document. So determining what is and is outside in this though, is one of the challenges, you know, we're having. You know, then we. As described, you know, treaty is really a network technology. And there's not much to the transport side. But it is certainly we definitely think we need to do is is is note all of these gaps. And perhaps call for for future work. To to go deeper into how specifically to solve these problems maybe we just note you know, what are the requirements? What are the issues? What are the things missing? And, you know, what would need to be added by a a a."
  },
  {
    "startTime": "00:34:04",
    "text": "A Cdn provider to deliver traditional capabilities. Using this technology and and what's missing. So That that that that is what we plan to add. But basically, would... We're looking for feedback from the the working group to see, you know, what specifically? Else is missing. What would you guys like to see added? And with that all. Kinda open it up the questions. Great. Thanks. So if anybody has any questions or comments, please do get in the queue in a Client. And somebody please have questions or comments. Alright. Break. Hi, Alan From. From meta. So I'm familiar with, like, our Cdn infrastructure, which is used to deliver some high scale live events. And I think one differences that because we use Tls either Https over Tcp or quick. Then every user has unique encryption key. And so when the traffic gets replicated out of the edge, it it's not multi cast because every packet is different. So I guess, maybe can you just comment on how this architecture supports encryption and or privacy. Yeah. So this is not my area of specialty, but I'm not gonna let that stop me. What I will say is there's a kind of the the the signature company who's is an organization that has been supporting and using"
  },
  {
    "startTime": "00:36:01",
    "text": "and leveraging they they presented at A few It ago. Organization called U met. And they talked about how first, it it it is possible to do know, multi multitasking encryption encryption with multi multitask. You know, you have to have obviously the group you know, shared group encryption. And distributing that those keys, you know, becomes challenging. I mean, it's it's you know, cable television is, you know, essentially a a a know, encrypted content that goes to many viewers and, you know, somehow those you know, group group based decryption does does does occur. So I I will say it's it happens and... But I I I'm I'm not an expert on how how works exactly. But encryption and multitask, but me say this encryption and multi multitask is certainly possible and it is being done today. Thanks. So I think maybe in terms of what I'm sorry. I'm not sure read a bunch of drafts on the plane but I'm not sure if I read. But if the doc doesn't address that, it may be valuable to add text about it because I think will be at least my when I look at this and I think about the Cpu cost that we spend like, rein encrypting every bit for every user uniquely. I mean, like, be nice to save that, but then I've happened have a way to solve that. Sure. The other question I had actually was related to adaptive bit rates and how you might envision that happening here if if we're sort of there's... It seems like maybe there's less control in an architecture like this where you're live streaming and sort of just like,"
  },
  {
    "startTime": "00:38:00",
    "text": "blasting it out and, you know, how if you're not using Tcp how has congestion control handled. How are you responding to last and you know, maybe adapting the the videos that's going out. Over different lengths. Sure. Great. Another great question. Traditionally, the way this has been done is just, you know, different bit rates on different multi multitask groups. So you can, you know, go up or down to and joined different groups. With different bit rates and so if you're if you're seeing too much loss, just join a different group that has a lower bit rate if you're if everything's working really well, you can jump up. So that that's been one, you know, technique mechanism for for handling. That with that. Just dealing with multiple rates so that you can go up and down. Okay. Thanks. It's calling James. I'm gonna follow on Alan question slightly because we both been thinking about this a ton and that this is very related to what's going on in the lock working group challenger. And I think Jay Holland was talking to us about how to use multi cast quick in this type of model to do the keying for these... For exactly those types situations. One of the other things that I think would be really worth thinking about and sort that we've been Thinking about a lot and would be interested to sort of see more people thinking about around how it it in is is the authorization and billing model on the Cdn, like all these I mean like, first of all, the fact you could do it on maybe hardware that's already there. Yeah. For sure. Great. Reducing the costs and stuff. But making sure with within Cdn business, you gotta to make sure that you've got the the right identifier in the right place us to effectively bill for the usage of the Cdn. And making sure that those were in place in the right way And I know when I talked to Cdn Vendors today, they... Some of them can can bill a lot for, like,"
  },
  {
    "startTime": "00:40:03",
    "text": "bytes out or you you know, that they feed out, but they also want to store for how much know how much they store and the people who are using the Cdn, like, I consumers an application developing on top of the Cdn. We'd like to have better of alliances about, like, hit rate and success rates and how much data was actually cash, what data was cash cost cash? And all of those things seem right dead center on the area of media operations. I mean, this might be a perfect place discuss some of those things a little bit more, but we need to see some of of those issues. That was just some some thoughts when I read after the top. Sure. Thanks. The first for for multi multitask quick, you know, a quick plug for there was a draft that Jake and and file and Next bro. We're we're leading. And know, it's it's something that obviously, would be really, really useful. So so you know, it that that could be a significant answer to the question. To a lot of the questions. You know, if multi multitask quick if those issues, you know, can can can be resolved. Get multi multitask. The... In terms of billing, you know, it's it's it's just a diff... It's a different model, but certainly just is doable. One of the nice things is there there's there really is no storage cost because, you know, you're not you're not really cashing the content and storing it So that's that's one of the benefits of this architecture. As you just push packets. So you don't have to really build storage complexes. But what... You know, in terms of how would you bill someone for this you know, you can you can bill for, for example, the number of A and t thomas. That you have us that you have created. So, you know, if if if and and"
  },
  {
    "startTime": "00:42:02",
    "text": "There is enough accounting information in an A and tunnel to be able to effectively bill you know, where the tunnel going from and two and where it's going. And and and also know, the the billing can happen between you know, when again, this is another nice benefit. That it requires less stuff less coordination. In the intervening boxes between the source and the receivers. In that, you know, the billing can happen no. I I gave kind of a hand wavy the answer on on the encryption part. But you know, imagine the contact provider and encrypt the data you know, anybody can join it, but they have to pay to get the decryption keys and then they and actually view the content Well, you know, they're they're setting up a, you know, a transaction directly between them in content provider. So So, you know, that billing can happen. Again, multi cass is uni directional. But that pertains to the actual, you know, stream. The the data stream, it doesn't mean that you can't use Tcp sessions. To set up, you know, share decryption keys, do accounting, share telemetry, you know, send back data on on user experience, send back data on loss there there's how long did you viewed metering bespoke advertising. So so you know, uni cast that can still deliver many of the things that Unit cast does speak gives you today. Just kind of out of band. And in band. You know, that the signal can be can be handle with multi multitask. Thanks. I've locked the queue after Jo and at that point, I think we'll we'll go to addressing your specific questions."
  },
  {
    "startTime": "00:44:04",
    "text": "Hello, Charlie I have a a question about what you are proposing. So basically, the current in in online video the protocols that we are using today as far as I know, are reliable. So basically the ranges we use for For instance, please based on. On the, that is based on S. But now you are proposing multi cost. But in multi multitask, we can drop packets it. Can add, so you can correct some of them. But at the end of the day, that protocol will be unreliable. So you are basic, you're basically time and correct me I'm wrong. You are asking the players the relates to to be to handle stream. So is that correct? My is my understanding. Right? Yes. You know, it's it's not using Tcp. So, you know, it's it's using Ed, Udp is unreliable. So then things like you know, norm and forward correction. Can be utilized to, you know, deliver you know, deal with packet loss and reliability issues. I will say this. You know, the this that which what you're asking is is not about multi multitasking about meeting. And how thin a service be delivered with Udp. The one thing I I can say is, you know, I'm not again, I'm not an expert, but I do know that there are companies using Udp to deliver live. Content. I don't know. Yes. It can be done. But... But Yeah. Sure. No. No. My is... Yeah. It can be done, but it seems that you"
  },
  {
    "startTime": "00:46:01",
    "text": "it's it's a big clip. So for some players... It is central reliable it's not easy. Yeah. I mean, goes... But I think that actually goes to the hardware you know, your your questions money about what is appropriate this doc and what can be feature work. Because what what I wanted to say there was that think the real value here is in describing the challenges with things like you know, real time video, real time delivery of of events not not sore screaming sorry the jet lag is just hitting. So I think that's use... Using this document to focus on here is a real problem. That isn't really addressed by either of the sort of top approaches multi cast or, you know, Cdn up w right now. And here is a way of looking at how to address it. At a sort of at an architectural level, with some pointers to possible technologies to implement it But stopping short of saying, this is this is the protocol, and this is how you do it. The reason that I suggest that and why I tied in to your question Door because then it's not a recommendation that service providers would move to unreliable transport for video. But rather, if you saying, if you discover that this is the situation in which you find yourself where you have this this kind of video to deliver and you don't have any other choices, this is what we know can be done today. Here's our choice. Not a recommendation it's an observation. Think Yeah. I I I think that's... Leslie, Think he described it very well and and and Jo, thanks for pointing that as well. What there there is a cost. You know, if you're you're you're going to lose the inherent reliability Tcp gives you, but you're gaining something and that is vastly more efficient"
  },
  {
    "startTime": "00:48:00",
    "text": "utilization of a network. And and again, tens of millions of viewers of say, four k streams, you know, that you can do it with brute force Uni cast. We've been doing it with you for Uni cast but how much further can you go? How far can you can brute force Gina as? What about a world with Ar live streaming? With tens of thousands of viewers and millions of viewers. Yes. Tcp gives you lots of nice things. But but at some point, you know, can the network handle that. So so so that's where network based replication know, gives you something but even though you're losing things like reliability. But the benefits outweigh way the cost. And and Leslie, I think it's that's a great point. I think you know, what we'd like to do is start kinda listing all these gaps. What's different? What's missing what needs to be taken account for and not and and it's kind of like we're requirements not necessarily say here's the solutions, like just... Here are the because, you know, my fear is... Even if we did know what the hell we're talking about for these solutions. You know, they may be obsolete or there may be much better techniques and we don't want to. You know, say this is the way to do something. We wanna leave room for providers and operators to come up with their own innovation, but we we we, know, we'd like to point out too you know, here the problems you wanna solve and, you know, stop short of saying and here's how we think you should solve it. It with maybe some illustrations of this is one way to approach it, but it may not be the best way just to illustrations. Sure. First. So does that give you enough sense of direction for sort of where to go next with the document or it does. Yeah. This this definitely does help. I would encourage everybody else that, you know, everyone"
  },
  {
    "startTime": "00:50:01",
    "text": "you know, we we would love more feedback and thoughts and comments and ideas. So know encourage Please do read the draft short, you know, it's it's short readable, and it's written for people who don't know multi multifaceted don't know anything about multi multitask and, you know, you want to learn how to use this to to build a, you know, hopefully usable service? This is what it's written for. So if it's not... Or that that was the attention. So if you don't find it to be accessible and understandable. Please let us know. We love any and all feedback. And and all suggestions is to what are those gaps point? We'll start working on it. And we'll we'll we'll we'll present another present one seventeen on you know, what we've added. Great. Thank you very much. Alright. And everybody as you... As you heard Lenny ask please do read the draft and provide feedback. Okay. Then we will move on. Want me to drive the slides that you can drive your phone. Were you just gonna do it a here? You drive the off. Now. Alrighty. There's a giant pink x to stand on up here. Awesome. Hey, I'm Glen, and I'm gonna source switch hats here. So I'm the Mob technical advisor. One of the things that means that I try to do is bring industry perspective in the mobs, And so those we construct agendas and try to get people to talk here. We try to leak that that because the world was full of video. And there's a lot of groups outside the idea that Are working on video. And one of them is sv if I'm here to talk to you today as I often do at It meetings. On connecting the work that's going on in. And paul the reason we do that is that Sv take stuff that the idea"
  },
  {
    "startTime": "00:52:00",
    "text": "produces. Add some secret sauce add some public sauce. Add some extra work to it. Rounds it out. Kind of the stuff like Colin was pointing out if hey, would it be really cool? If we talked about how you take these Cdn stuff out all the business go around it to make it deployable to do business work. What they us. Stuff. It also takes practical experiences from operators and brings it back to the Ig ihs. And so over time, we've seen a lot of cross poll between two groups and in growing cross polish between your few groups it's gonna get even better. Show you minute. Next slide, please. So in case you have haven't heard Sv out of the t to their name. They used to the and then we added t for technology. So that's cooler. Than just having. So this is... We became even cooler with the attitude. Next slide, please. So what is the sv? If you don't already know? First of all, it's hundred plus member companies and growing if you go look at that link, You may find your company as one of the members of the Sv. And growing. Microsoft just joined. You were from Microsoft walk through the Sv? If you wanted understand the group does, really you could sort of say, it's like an operators group. It's not quite an accurate description. But it is for video what a group like do na would be four networking. We take It specs, wrap stuff around them, do extra work, feeds requirements back into the That also deploy them. And then create best practices, specification documents Apis, interface control things, in the documents and publish them. So it's sort of, like a turning what goes on here into production stuff that people can make use of."
  },
  {
    "startTime": "00:54:03",
    "text": "And those are the working groups we have opened today open caching. Obviously, it's pretty big one. That's built on Cdn I. We have a metadata working group, live streaming. Is aka k for low latency stuff. Number transport. I happen to share that group over at the. Or sorry. Yes. Privacy protection that's security stuff right and and privacy. Edge storage, Players in playback, mister Beg here. Is involved in that. I should point out San at the back there is the cool coach one of the involved with Adobe stuff cdi over here, and I'll I'll be cash over there. Immersive Video, measurement Q, and advertising. And there's always new groups spinning up. Next slide, please. So I wanted to point on a couple key projects so I think that there's really great fashion points with the people in this room and the broader etf you may want take to look at and be aware of, especially if you're a member company, And then the work going on back here at the It for since earlier today, if you're over in Cd, there is presentations from Sv. About sv proposals and drafts that were coming back over the. So that's how the relationship works. So obviously open cash. You can find out more there. There's a a project we're not investigating your purchase of multi cdn delivery. Mister. Beg here is is one of the chasing that. And there's a link that you can find in more detail. The group eye chair is working on a quick Poc This is the interesting one it's thought what you might think. This is not a big off of quick versus that quick. This is solving a a practical problem that, you know, the there's been a lot of great work done the Front quick. But there is a lot of challenges for operators of Cdn, players and other tools, environments to adopt quick as a delivery pathway. Part of the problem is that they've got a lot of guys very skilled in Tcp architecture"
  },
  {
    "startTime": "00:56:03",
    "text": "not skilled in quick architecture. And if you start talking you about sort of high level. They can get long glazed over there's so much changed here. I don't even know where to start. This project is finding a reference test environment. So people know how to assemble the pieces, how do you build telemetry, how do you collect network and player telemetry. And how do you reconcile all that information to answer basic questions like if I build out a quick architecture, will it perform as well as my existing Tcp architecture. How do I measure that? What that quick Poc is for. And this publications and there's more and more publications can be trained out from that one. As we proceed. This distributed ray tracing. Which is you know, essentially, the question of So as dice reach racing my gosh my old days a graphics guy. Distributed tracing where you know, the challenges we you deploy our architecture end end do you know they're working? How do you determine where the problems are? And how do you go fix when they do happen. You know, this is not the world of closed end end delivery that you had in other environments is over the open Internet. And things go bump that. You can't see. How do you tell discover those and how you follow them up? What that works to. And then lastly this is a new project that's just kicking off. And that is starting to document from a video delivery perspective, all the crazy stuff that is done in the Dns to make that work. And it's not meant to be judgmental, but their probably will be things that it called out us This is a good idea. This is a really bad idea to do in dns we know people do really funky things In Ds. So there's gonna be some good stuff to har about there. But if you care about G in hear with video delivery, you might wanna to get involved in this project. Next slide, please. Okay. So how do you get in a your if you're a member company? Join up. And if you can't find who your rep is come talk to be talking to Sanjay,"
  },
  {
    "startTime": "00:58:02",
    "text": "you b those are the very last part of your world connect you. But there's a couple things I wanna point out there is a conference a brand new industry conference called segments. Never happened before were supposed to happen just prefer Covid started, that got interrupted in delayed a couple of years, we're now having it May sixteenth in Orleans. So if you're in the area, this is a public conference. You don't have for Member. You can come you can join It's open everybody and it's gonna be all around screaming delivery, B type environments. And it's gonna be great conference. Please come join. Again, open to the public don't have to you involved with Ds or a member the Sv. Following right after that for Sv members, is the spring twenty three, conference in your own as well, May seventeenth eighteenth? And then here's the really big one. In the fall, guess who's going to prague. The Sv is going to prague. The days right ahead of the. Supposed be a great opportunity for two groups to, like, c ming interact with one another. If you wanna find out more information, if you want... If you don't remember, you wanna come give me a show. We'll see if we can look up. But It's... So I think I actually starts on Saturday. This runs the week just a couple of days ahead. So come a little little bit early. Comes to with the sv, during stick around the. And we're gonna set the same pitch of reverse I Sv members, come for the Sv, they'll stick around for the. Next slide, please. So how do you contact me? There's my contact information. I'm Glenn at Comcast. Sanjay, back the raise his head. You can contact him for information. Everybody knows always so can contact Valley. And Jason, Dig? Is the executive director. He's sort of rj. You can contact him he's very friendly guy. And with that, I'll take any questions you guys wanna fields me. So while people are putting their hands up, I have question or an observation. In particular, the work that you referenced about the Dns use of the Dns and video delivery"
  },
  {
    "startTime": "01:00:04",
    "text": "occurs to me that that would be a useful thing to bring back here and talk about because I I I mean, generally here in last specifically here in Mop, and generally here in the I, because as people consider new options to ben full been to the use of Dns. It might be provide some insight into what it might trip up. Yeah. No. I I we absolutely will do that. You know, that that is exactly I think we'll bring back here and and point people to him present on. And then people say, well oh, gosh, don't do that the dna and you'll probably be right. Because people do very bad things in Indeed dns. I mean somebody once told me you aren't really an For until what? Until you've proposed putting something in that lovely global database that is the Dns. And then are truly It you go... Oh that was why did I for propose that? I so not going to respond to that. Great. Any other comments or questions? Alright. Well, if there two questions, thank you very much. Thank you. Alright. Colin. Okay. Thank you. I'm gonna be talking about a little bit about project we've been doing around hologram and some of the hologram and some of the experiences we have with that, and where we're on that. So can you bring up slides for me? Thank you. Excellent. Awesome. Oh jeez the order hang. So as as a bit of background context, we've been working on or we... You know, there's a product that's been working on for I don't know, roughly five years or so There are a bunch of other people in the room here have been involved with as well, that is about delivering Ar vr hologram experience. I'm gonna talk a little bit about some of the things we've run into as we've done that. And then a little bit about what it is and what about the sort of, you know, network bandwidth we've ended up using. So it sort of ironically sort of fits, like, right into the"
  },
  {
    "startTime": "01:02:01",
    "text": "the context of the draft that we were talking about earlier in the meeting. Awesome. Next slide. So the idea of the system when you use it there's a camera array that's capturing a a a light field of other person that's being recorded. So on figure out it's my right you're right here. Yeah. I'm I'm a right the... You know, there's a person who's presenting something that objects being captured they're being captured. The person on the far end is wearing an Ar headset and they're seeing that person as a hologram across the room from and shows few images and and bits and pieces from it in there. So next slide. That's the basic context of what we're working in here. So the capture device against bunch bunch cameras we're where primarily using light fields. I'll talk about a couple of different media types later that I think are important to this space that we be thinking about. And that's streaming up to the cloud service Aws in this case. It's about thirty megabit bit per second stream that's going up that with that light field, that's the cloud, we're we're splitting up and pre rendering it partially into the headsets, and I'll talk about some the latency. Aspects of that in a second, and we're sending them down about a six megabit stream to each individual head And then on the headsets, we'll do some additional computation particularly to compensate so that when you rotate your head, everything that you need to compute the new image is right there. Okay? But when you sort of move your head a bunch of sideways, I shouldn't move away from the mic. Then you need for more information from the cloud from a different viewpoint, and that will get updated to slower time. So next was Over the longer term, of course, we'd like to be able to use things like what's going on mock or, you know, see the entries, these types of ideas we've talked about all those sort of types ideas. In the future, but we're not doing any of that right now. But we'd like to be able to push this out to five g low compute edge. And all the things that this working groups talked about over the years up"
  },
  {
    "startTime": "01:04:00",
    "text": "getting that light field processing closer less latency between the headset and that towards the edge. And then also just ways to raise the bandwidth between the headset and the edge of that cloud. Pretty much, you know, as you your bandwidth go up, your your fidelity of these experiences can go so that's pretty obvious as you get your late down, it gets better experience too. Okay. Next slide. So I wanna talk about late a little bit The the the sort of primary metric volley systems should probably be time to feel like you're about throw up. And there's a lot of things that factor into that is not just latency of of view updates. That's one of the things But, you know, on early systems where you have bugs in the code or something where you're you're not compensating for what your brain thinks that should be seeing in the correct way. You get these motion sickness type issues. And so the latency can be fine and you can still have a crappy experience or an experience like that. When you get all of these things right, people like and and now at this point our some people will go for a long time their perfectly happy using. They don't have those feelings at all. And it was a bunch of things to bring that together. So one thing about it is definitely when you turn your head, how fast you need to update. And I I mean, it's probably more like seven milliseconds or thing it's certainly well, it's in the under ten milliseconds. So sort of ordered to. That needs to be quite fast. And we're finding that know, a lot of the things I you know, it's your brain wants that to update very quickly. Your brain is dealing with different parts of your brain dealing with us at different speeds. So part of your brain might be willing to accept that the model of the world only updated a peripheral vision that's quite fast might just say, no, something's not right here. So you need all that to be fast. Now the para issue, when I shift like this if I move sideways and and everything in the room that's behind or in front of other things sort of moves a little bit? That latency on our experience has been that latency so we can be a fair amount higher."
  },
  {
    "startTime": "01:06:00",
    "text": "Don't necessarily always correct that exactly right until we have a round trip backup cloud and down again, which is way over ten milliseconds. Okay? It's anne. So I think that when you start seeing these metrics this, you need to start splitting them up of what needs to to to be there and what's not. So the other thing too is and, you know, I some of these things I've been interactive in live too. The whole thing about it is Interactive is not an exact number of milliseconds. It's very much feeling that you're not in a turn taking experience that you can just talk to somebody, and they can answer and they can interrupt and break into the conversation. So maybe it's like less to three milliseconds for some type of use cases, maybe it's different for other use cases it depends on the context what the actual milliseconds is. But interactive is that type of feeling. And live is is that feeling that even though you're not interacting with it you're you're seeing as it happens. And so that could be much higher depending on the context or much lower depending on what other surround contacts you have like, like people cheering up the stadium as you're seeing things. Right? But live goes down to zero. I think it's one of the important things. This is a live conversation where right now. It's not like live has a lower bound. Lives lower bound is zero. I I think that those are all important to understand about this is that these interactive in live are very much user experience more than an exact number and you need to think about I'm not way we try to sign the system So let me jump to next slide. Couple different approaches we've seen in all of these Ar vr systems. And that we've played with ourselves at various times. One's Texture mount Poly. This is the the easiest one that you see lots of people start with. It's great for objects, you can take all the technology that came out of game development and our current account rendering engines to do Poly on architecture maps on them. That shoe right there is is was a scanned with the app software for scanning things. Doesn't really get fine detail very well. And one of the problems with it is on the real time if you're trying to scan this and form these models interactive real time, a lot of the problems that we see with these systems is if you get a single point wrong,"
  },
  {
    "startTime": "01:08:02",
    "text": "like a single point on my shirt scanned wrong and its steps way off. I will have this spike that's protruding out of me. Okay? And so a single piece of noise in your data creates a huge visual artifact. And that's really... You keep feeling like, oh I'll be able to filter that noise away get rid of it. It's hard. So that's that's one of the issues of these systems. Next slide. Another system we see a lot is point clouds think was mentioned earlier today in meetings up. So you the point clouds are. You've got an incredible number of points that each are represented by a color and if you have and you know where they are in three d, and if you have Instant enough cloud of them, it turns into looking a solid object. Typically, these systems are a little bit easier to hide the noise. If you have a point that's is wrong. It's like a speck somewhere it's less noticeable, less visual artifacts. And you can get down to a little bit finer resolution we've systems using this next slide. I'm gonna explain a little bit what Light field is The light field idea is simply that if you could capture every ray of light in this room. Like every ray of light through every point in every direction and take that function and be able to send it to the far side. Then you could easily s any viewpoint from there. Now the... Of course, you do that. You have to do some approximation to that function and how how good it is and what volume you capture over and stuff. But one of the things that's nice about this is it really starts to capture that the image looks different from different viewpoints. So you look at these two images of the the orange, that's under the same lighting conditions. It's just shot heads move from one position to another. And it's looking at the orange from a different viewpoint you can see the spec near the x on the orange has totally moved. And all the reflections move and everything else. And you might think... Oh, that doesn't really matter. People aren't shiny. But people are shiny. All of our skin is shiny. We have a very reflective looks on that. And so it's important to get this type of stuff right and we think that you wanna really photo realistic version of what people look like, you need to sort of do that. So next slide So this image is is"
  },
  {
    "startTime": "01:10:02",
    "text": "you know, shot from inside a headset that's representative of, like, what type... I mean, it's impossible to show what this looks like without you putting a headset on. Right otherwise, I'd be demoing it here. But This is an image that that is shot from inside of headset that gets representative what the hologram looks like of of Aaron here the person standing there and then the room behind Now I think a part that I always like to look on, this is just like how the water looks like. And the fact you can the shirt through the water and those types things. That'd be very difficult to do with the point cloud, very difficult to do a texture map all. So that's it's one of the appeals to me of light fields for this type of approach. So next slide. And next slide. That's just some comparisons so those three techniques. We're not doing this yet but I'm sort of really... I I think that these nerf are really probably going to be one of the most interesting things going forward. They can represent the same type of thing as the light fields. But with far less cameras capturing less rays of light and they do it a lot less information they can s size a really high quality images Today the ones that I'm seeing aren't really at the computation speed that we could use for real time. But anytime like something looks great but it's too slow. Like, I don't know, you know, drink beer it's faster. I don't... I don't know. You know these... I I think this is one of the hot areas are coming in should be thinking about from a a media point of view. Next slide? We also have media in this that are not about the video. So a lot of these systems use a toolkit from Microsoft for map for recognizing where your hand is and all the suggest and information this Mrt k, I toolkit. But whatever it is, you're probably interacting with this Ar vr experience, and you're often using gestures or something else do that. And you need some way to map those types of objects into the system and send to the far side too. And if you were using some virtual objects in your environment and picking it up and moving it or whatever you're doing good. You need ways to represent those types of things to. So... There's a draft that myself and and nine person been working on a little bit. Maybe"
  },
  {
    "startTime": "01:12:01",
    "text": "the right thing or the wrong thing. But we need some ideas for how to represent that type information into these systems as well for the Ar vr systems. Looks slide. And so this you know, this is my really last slide. I I think that I'm happy to answer any questions about sort of our system what our experiences with it that might, you know, impact or guide other systems or give information to this group about how we're we're running at or things we've run into. I do think that we ought to be thinking about media types beyond the sort of traditional video into other types. And I think that we're talking, you know, I think there's lots of ideas as the volumes of this data goes up up looking at ways where you can seamlessly move the compute and latency close to the edge without having to re our tech or redo your whole system, how you can move this over different things. I think Mark is, you know, plays into some of this as well, you know, those types of things. So I think there's a it's a a really interesting time in this space right now as you see all kinds of proposals going the same direction whether it was a treaty or it's the mock working group, where there's some stuff outside of atf. There's a lot of people thinking about how to have a much better media distribution right now particularly for these these should things. And part of what's driving that is the streaming late are trying to move to be less. If you look at anybody who's delivering a streaming media service, the more they can make it interactive and bring viewers content and stuff. It really connects to the stickiness. So there's a lot of driving to pull those late down. On the flip side, all the people that do the real time type stuff you know, the Zoom Web of the world Microsoft teams. Those those are scaling up to hundreds of participants and they're wishing there scaled up to hundreds of thousands of participants. Right? So there's there's all of that converging together. And I think that that makes an interesting time in space. So with that, let me just stop there and see if people have any questions or other bits and pieces they wanna add in?"
  },
  {
    "startTime": "01:14:01",
    "text": "So while people are getting in the queue, all this observed that what you're saying at least part is it everything we've discussed in terms of challenges for video delivery, etcetera is sort of geometric expanded when you get to V vr, and the consequences are potentially worse. It and so insofar as as our physiological reactions if we don't get the latency Yeah. Yeah. I mean, you know, like, your lip syncs bad on and a Webex call, you don't wanna throw up. Right. You might be like, looks stupid. It doesn't have that same sort of reaction. So it escalate that at that access. ...Escalate on the complexity of doing it. But on the other hand, I it's... You know, in my mind, we're doing it on today's network today. Like, I can run this on Lte, like, it's thirty megabits per second. It's not... It's not like we can't do this until we get to six g. We can do this today on today's network very cool. Well, thank you. Anyone? Play for a question or a comment. Oh, here we go. Go ahead. Thanks, Calling for that presentations. I just had a question regarding indication or Codecs. Do you use existing codecs or they need to be adapted to whatever technology you're using. Mean, we we do leverage existing codecs and it's... I mean, how we use it might be a little bit weird a bit that sort of meta information that tags alongside with them, but this system as we have it deployed today is largely running on h two sixty four is the baseline codec for it. And, you know, moe in the room here is like one of the key people talk to about that. But we're very much would like to take advantage of some of the tools that are in Av one as soon as we can and move to that. It it offers some possibilities that that improve things. I think that there's been lots of thinking about how to design next generation code that are"
  },
  {
    "startTime": "01:16:01",
    "text": "specifically for volumetric video in various forms as well too not taking advantage of any of that stuff yet, but but certainly you know, every one of these things can help this problem. Great. Thanks. Yep. Right. Thank you Alan you'll coming up and people here may recall that when the mock working group was being formed, there was some discussion about sort of relationship to mop, etcetera. And I know the Mock working group has been very busy or since we since we all last night in London, So thank you Alan for coming and giving us an update on what's going on in Mu. Sure. Thanks. I think it's gonna be tough to follow Cohen presentation. That was really cool. I do not have any hologram or, like, cool metrics like time to p. I am Allen For. I work at meta I'm one of the mock chairs. Give you an update on Mark. Next slide. So just a high level, like, what are we doing over in mock? If you didn't know are kind of a summary of Ted's words, but the goal of Mark is to build protocols needed for real time or near real time media that leverage quick for its best advantage. The ton of motivation discussion that went in so get two boss last year. So I'm not gonna rehash it here, but We were chartered, working group formed our first full meeting as a working group was in London. Since then we've had in person two day interim in Seattle and another virtual interim a few weeks ago. Give you a kind of update of what's happening and and where we're going? Next slide, please. So we spent a lot of time trying to understand the problem and also understanding each other. A lot of different use cases. Came to mark people with specific applications in mind that were very different. And we spent a lot of time learning. What is it what what's what's live video and just look like what's live did your distribution"
  },
  {
    "startTime": "01:18:01",
    "text": "what does web conferencing look like? And and that's led us to trying to come up with some terminology that we can all work with, and we're we think we made progress there as well, like, having in. A just terminology vocabulary that we can use to have these discussions. And we've talked about requirements and we are actually agreeing on some, maybe not all, but we're getting there. And there's a requirement draft that started last year as part of the process that's around... There's a new scenarios draft was published earlier this month. We're gonna be talking about this week. I think it does a really good job going into detail about some of these use cases and looking at similarity and differences specifically as they as they apply to Mo so check those on. Next slide. There's been some very nice experimentation going on. So our interim in Seattle, We had a few different presentations, people showing tools they built that are a lot of them using web codecs and web transport in browsers, to send media over quick in new ways. It's not http three and those all really cool demos. There's a new one that just came out it's gonna be presented this week so follow these links and and check out some of this code, if you're interested in in playing around that. You feedback. So and this is gonna help inform the working groups to right? Like, having running code and and and real data it's gonna good. Next slide? You know. So we're we're we're building the beginnings of a solution here. So if you remember before it was formed, There were there were three input drafts, that came from different places And what we did is we we took the authors of all these drafts. We, like, needed superstar All star team and said here you guys go like, write the based protocol. There's a draft there. It's been under somewhere I think just published revision four. And it's... So there's been a lot of back and forth on it. There's a very active github repo. And and we're the the working was trying to"
  },
  {
    "startTime": "01:20:02",
    "text": "get to a place where we can adopt a a baseline which is gonna be the beginning. Not the end. And we'll continue iterating on it over time. A second base protocol draft was published this month. And and I spent a lot of time on the plain reading drafts. I read all the drafts carefully, I don't find them to be so far apart in in in a lot of fundamental ways, which I think is good. But we will be discussing the delta on Thursday. Bring Next slide. So what's the... What you know, the trajectory of the group where we're going So the requirements draft actually went out for an adoption call just I think Sunday maybe, so it's running for a little bit. So your feedback there. And my coach and I were really hoping that after this of meetings this week, we have to make a lot of progress that we be in a place where we cannot issue an adoption all we don't expect that whatever document we have is gonna have full working group consensus on every issue Is it gets adopted into the working group process. But we just wanna make sure we identify clearly like, these are areas where we know we still need to work, and then we'll know that we're going continue driving towards consensus on those issues. But after adoption, I think it it does unlock instead of having a bunch of different demos running, like we can try in our offering. We can have two different implementations trying to send media over quick from one to another. And hopefully, we can demonstrate that more the single protocol can meet more than one use case. Which is I'm looking forward to it. And there's probably more interim in our future the group, I think really needs high bandwidth at this stage, there's a lot of great discussion going on the mailing list and in several github repo, but these high bandwidth conversations, I think really important. For where we are right now. And then I know it's a lot. Anyway, we welcome the participation. Next, So this week, where can you find us. So Thursday,"
  },
  {
    "startTime": "01:22:01",
    "text": "thirteen hundred and the very last slot of It. Friday at noon. We know you guys are all staying around. Come see mark. And I'll make a separate plug as much like mop struggles with finding note takers, we are also struggling. So... But we brought chocolate. So come on over phone. You can volunteer and not. You made should. Sure show us up. If you were thinking about taking notes in another session, just save it from Thursday, Okay. That's an enough. Hope you see you guys there. And I think with that, just anybody have general questions about things that are going on in Mock that I can answer here. Happy too. Anybody, anybody online? And while people are reaching for the buttons, I'll just take the opportunity to thank you for coming in sharing that and suggest everybody that particularly now that you know what it's all about. Please do get involved in the mock work and particularly if you have your own of experiences in video delivery and and business requirements for delivery death, that we get involved in Mock Yeah. Absolutely. I'd would say particularly maybe this requirements or scenarios drafts would be a great place to jump in if you haven't seen any mock work and and see if that lines up with your real world experience. It's valuable feedback us. Great. Alright. Thanks, everybody. Thank you. Alright. So that's the end of our formal agenda and unless there's any other business if anybody has else they feel the need to bring up at this time. Going once. Going twice? Launch. Thank you everybody. And thanks again, Dolly for taking notes."
  },
  {
    "startTime": "01:24:09",
    "text": "Yeah. It's good thank. There is one there is I'm gonna alright. Well, I'm gonna mean, on official"
  }
]
