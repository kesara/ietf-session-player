[
  {
    "startTime": "00:00:47",
    "text": "I'll I'll I'll comment that the mic will be in the bottom West So do we have to do something to pull the slides up on You join. Or do I do it online? Yeah. He just joined the link. Yeah. You see the preflight testing, I think? didn't see No. They they the previous tabically. Yeah. Yeah. There's a pre flight test. Yeah. I think that look above here. I'm not sure if we know it's nothing. Sure. Sure. Thanks. It's not control. just announce that we're gonna give people a few minutes because after lunch."
  },
  {
    "startTime": "00:02:30",
    "text": "it's no low. Everything's capturing. It's here. Alright. Hi, everybody. few minutes after 2. So I think we can probably go ahead and get started. After one. Sorry. I'm not on California time. So Yeah. Thanks. claim it on that one. Yes. So this is the Bpf Working Group. My name is David Bernay. This is Suresh Krishnan, where the other co chairs All the technical advisers are in the room as well. yeah, let's go ahead and get started. So the first start off, NetWell is in effect. So, you know, you're agreeing to all the IETF process season policies and etcetera, etcetera. So, yeah, nowhere else in effect here. The code of conduct is, of course, also in effect Please, you know, treat everybody with respect collaborative environments. If you have technical disagreements, that's fine. But We all have the same goals. So let's try to, you know, keep it civil, please. Yeah. So for administrative tasks, this is the the meet echo link. If you wanna join the meet echo link, you can you can do so to to press paid in chat and everything like that. We will need a volunteer for note takers. Can anybody help us take notes? Great. Okay."
  },
  {
    "startTime": "00:04:00",
    "text": "you think, Krishna? Oh, thank you so much. Appreciate that. Alright. Alright. There is a link for the collaborative note taking. So if you can just dump whatever you can over there. That'll be good. Thank you. Yeah. Alright. So this is the agenda. I guess it didn't upload the latest one that I put on, but Yeah. So we're doing the the agenda bashing now. Then Jay Taylor is gonna be going over the document logistics for for the working group. Dave is then gonna be talking about the instruction sets efficacious. So the the ISA doc, which is kind of the first major effort that the working group has been undertaking. We're gonna be talking about adopting the document, what else needs to be done, and what kind of the future of the document is. Will Hawkins is gonna be talking about our API documentation for EVPF. After that, Dave is going to again be talking about the elf documentation and for for the working group as well. And then I don't think the slide is present right now on on the the version that's uploaded here, but I wanted to mention that you do not need to have extensive BPS experience or knowledge to participate and, of course, to be here. Everybody's welcome, all ranges of experience, and Bpf itself is a very large ecosystem. So No single human being exists on the planet that actually knows how all of it works anyway. So worry about that. Yes, thank you. Thanks, I think a few words from our lady since this is our first meeting. Yes. Hello. just wanted to say welcome to ITS117. Welcome to San Francisco. Welcome to inaugural session of the Bpf working group No. we had we had a a successful buff in"
  },
  {
    "startTime": "00:06:00",
    "text": "Yokohama, and the formation of this working group is the outcome of everybody's hard thank you to everybody who made that possible. Yeah. We have, I think, lots of communities here. We got some colonel folks we got some IETF folks, some overlapping folks in the middle and from other communities. And so Thank you for for your patience, helping spread the knowledge. I'd know also that there's There are kernel ways of of of of working, and there's IETF ways of working, and we're gonna figure it out, figure it out, how this is gonna how this is gonna work. As Lorenzo told me yesterday, the best way to figure out a working style is to try to get work done. we're gonna try to get work done. With that in mind, if this is the first time you're dropping into a VPF IETF session, like, you didn't attend the the the bot for the session in London. atat this is work, basically, kind of already in progress. There's history of the stuff in the kernel, and Dave has document of work that's been going on for a while. So we're kinda try to get to jump straight out of the gate. So with that, I will say thank you to our chairs for agreeing to serve. and turn it over to you guys. Thank you. Yeah. Thank you so much. Thanks, Eric. Alright. So, yeah, with that further ado, Dave, do you wanna take us away with the document logistics? Have you changed that? So this first presentation isn't about a specific document. k. about how the 2 communities work together. So I'll have the ducks to come up. and I will use the ISA document as an example but isn't just about the ISA document. Alright. So I'm Dave Taylor. Next slide. Okay. Next slide. It is a bit easier. Good. It's not a bit inconvenient. It's coming. first, I wanna show how the existing ISA document is generated today. Now it can change or whatever. We can change the process, but if the oh, there it is. Okay. Here we go. Alright. So today that this works, and this is different from last IETF because we made some changes"
  },
  {
    "startTime": "00:08:03",
    "text": "to to to do the things that we talked about last IETF in the side beam that happened after the And so here's how it works today. So the very left side shows what happens in the Linux current repository. And so there's a a set of files that get used to create the Internet draft. And so by core files, we're talking about the ones that actually have actual instructions, the actual behavior in it. Right? The actual content, if you will. is what I mean by a core file. So that gets done today by as submission going to a mailing list that's cross posted between bpf@vitcher, that's the current Linux programming list. for Bpf and the bpf@ihf.edu, which is a working group plan Right? We once tried to have one be a member of the other, and we ran ran into some weird mailman issues. And so now, we just say, please cross post stuff to both list until we get that worked k. And so if there's a submission says, here's what the should be, here's a change that's proposed or whatever, then that gets cross posted. to both mailing lists, to both mailing lists, And then it gets merged after discussion. It finally gets merged into the Linux tree in the Bpf next branch. k? And so now you have, like, an RST file that's sitting here in the Linux, growing Tory that's gone through review and been checked in and is sitting there in the Git repository. Meanwhile, what happens is there's another GitHub repository, this one, not There is a github repository. That's the working group repository. You can see github.com/ iutfdashwgdashbpf. Right? That's the GitHub organization for this working group that was created. k? underneath that repository, there is a underneath that organization, there's a repository that contains a mirror of the files on the left. Right? So those are it exact copy. Right? Those files that are ISG files get copied over into the repository and get The GitHub also has additional files in it right now. That's the boilerplate. Right? things that actually creates the the header and the footer and the acknowledgment section and so on. So I'll talk about that. And so right now, that's the boilerplate files. So if somebody makes it change the boilerplate files, that's not current in Linux kernel repository."
  },
  {
    "startTime": "00:10:02",
    "text": "over there in GitHub. Right? So there's 2 different submission processes for different files. Again, this is current state today. k? Not necessarily what it should be, just saying this is what happened for the draft that's out there now. day. k. k. And so if somebody wants to create a change to boilerplate, like I was doing, then there's a github for worker branch, and you submit that to the GitHub process. but you're only supposed to touch the boilerplate files that way. And so the main branch in the GitHub working group repository has files mirrored from the Kernel 1, Right? Which is, like, instructions at that rrst. And there's the border plate files like the skeleton. k? And then what happens is every time that there's a push to that repository, k? The GitHub CICD runs and it compute and it generates an Internet draft from that collection of files. and it takes the Internet draft version and it checks it in to a separate branch there. So it's a generated branch Right? The name of the branch is generated, and that has the actual ill, ill. HTML and TXT and XML files that would be in the Internet so that's if you wanna say, what would it look like in your net draft format? You can go and look there. just like, you know, Martin Thompson's tools, you can do diffs and stuff, and so you can see what's the diffs between the editor's copy and the last copy submitted to IETF. in the data tracker So finally, at a particular point, like close the ID deadline, right, then I took a snap and they submitted exactly what was out of that tree. k? So if I wanted to change instructions at dot r s t, I start on the left side and then shows up in the mirror, and then and then shows up driving there. And all the other ones, right, the mirroring and submission is just, you know, process with no, like, human changes in between. Right? So that's the process that works today. Right? So all the actual technical changes happen cross posted and checked into the Linux kernel tree, and the packaging happens in GitHub and is not in the Linux Chrome free right now. k? Alright. Now people have people have opinions as to whether it's what it should be in the future, I'm happy to hear that. This is just me saying what the current process is for the document that exists today. k? Alright. So just to drill down into what the files are, So this is the file that's the draftfavorbpfisa01. Right?"
  },
  {
    "startTime": "00:12:02",
    "text": "which I am listed as an editor because, right, I didn't author instruction set RST. That's rest of the community that the acknowledgement section talks about. I just created the packaging around it. Right? Right? And so core files for that document, right, is instructionset.rst. And it's a separate file that's today on the GitHub, which is the instruction set skeleton, That's what has the header, the footer, and the acknowledgement section. things like that. k? Things that only appear that are relevant Internet drafts And then there's the in a consideration section that we will talk about in a later presentation that's on the agenda. And so we'll get back to that one, and that one is in instruction set.codes. It's running GitHub k. k. if you got comments on that one weekly at a presentation, but the point is right now there's exactly 3 files. and the skeleton, like, includes the other 2 and generate That's how it's organized right now. An instruction set that RST is in a is in a directory that we'll talk about on a later slide. Next, Okay. So when we look in the Linux kernel tray, so that was kind of the the view of the middle tier of the of the first slide. So this is the left here. If we look back in the Linux kernel tree, it looks like right. Under the Linux kernel tree, there's documentation, standardization. So David created this, what, like, a month ago or something like that. Yeah. Something like anything that is intended for a standardization that's supposed to go here. And whether it's the right set of files, but you can see this is where it's set.rstlives. That's the one that gets mirrored to GitHub among other files. And so then we look inside index dot RSTs. Now we look at that Next. Okay. So last IATF, and even before that, there was questions about how do we label things so people know that if they're kinda like submit a patch, we're gonna trade. They know that it's covered by the IU chef know it well. How would you know that? k? And so this is the initial notice that's there. Right? We can rev it, put more stuff under there, point is you're putting it in a directory, and the whole directory is labeled this way. k? So you better notice this. Right? And it says, we can put other stuff here that we want to. So there's a link to the data tracker and so on. So this is where Any notices about what you're expected to understand and do that apply this entire directory go here"
  },
  {
    "startTime": "00:14:04",
    "text": "This is not the Internet draft. This is notices in the Linux kernel repository. that says all this is under you know, everything, all the files here and here are under the or BSD 2clause, etcetera. k? k? So this was the resolution that I think David was pointing on this part, and presenting, yeah, we're just following this. This is where instruction set that RSU is being copied from. k? And so if there's no problems with this, and the proposal is this is the document logistics as to how we work, whatever. People have amendments, then we can do k? Alright. And so now process for contributing patches, and so we need to make people understand the IPR rules? And so there's already kind of a rule that says, well, you shouldn't be copying any existing code into such documents. Right? The reviewers would reject such a thing. Right? can't put code in there. You put documentation stuff in there, but you can't put code. Right? that's the job of the reviewers, and there isn't code in there right now in the job of the reviewers since cross posted to both list and so on and to make sure that there isn't any code that shows up in there. k. k. k. k. But this notion says, how do I know if every submitter has adhered to both of the rules, and that index file is least placeholders that start for it. We can keep adding to that if there's other things that we think that they need to know, that that index at RST is where to put the answers to this. k. k. k. k. So then the question is, okay. So you've got some patch that's out there. It's cross post on both lists. k. k. So logistics question, first one to answer is, Who has to act a patch before it gets merged? k? has the ability to say this thing is good. k, k, proposal might be Whatever you think the answer is, designate them as one of the Internet draft editors. k? doesn't have to be me. Right? It could be any one of the other people in this room if you the right person or set of people to act a patch. Micropose list list them as an editor of the document because they have editing permission over what's get merged. It's kind of the definition of an editor in my view. Tate. So that's my proposed list of whoever you're gonna say has to act a patch as the other people can but who's the minimum set that at least one of these people left ACCET?"
  },
  {
    "startTime": "00:16:01",
    "text": "take them and list that set of people as editors of the document. back, And, again, I'm I don't care if I'm one of them. I'm just like, that's the process that I'm proposing. And then who could hack a patch and prevent merging? Right? Somebody comments on it. and to say, what would prevent it from being merged? Okay? And I don't have a good answer to that. one if there is one. So interested in opinions on that, but at least that's my proposal for the who has to act is pick an answer, and then list that set of people as editors. k. then in IETF documents, there's always a discussion about editors, authors, contributors and acknowledgments. Like, who goes in what section? You actually have all of those or is only subset of those relevant. and so on. So if you're new to the IETF process, the a definition of those is there's different definitions. Right? One definition of editor is something that just manages what is in there, but doesn't actually write have to write text. as And so here are some of that manages the Internet draft conversion process. Like, What I was doing is I was making it show up as Internet draft, and the formatting on, I said that would be an editor role. An author role would be someone who writes a significant portion of text for some definition of significant portion of text, And an IITF is a convention that you're supposed to have, like, at most five people in the author list. It's not a hard rule, but it's a better have a good reason if it's more than 5 because your people will give you a hard time if it's more than 5. Contributor Some documents have a contributor section, where their names and stuff get listed. and well, some documents don't have such a thing. So this might be If you contribute a patch that's accepted, are you in a contributor or an acknowledgment? k? And the answer is that depends on the working group and what process you want. Right? There's no hard and fast rule. in in the acknowledgement section, you don't have to have one, k, k, k, k, If somebody reviews a patch and they suggest changes, but they didn't author a patch, are they acknowledge sure was. There's some open questions there. you look at what I did in the ISA document right now, If"
  },
  {
    "startTime": "00:18:01",
    "text": "everybody that contributed a patch itself is in the acknowledgement section. Now whether that's right or wrong, I'm saying that's what I did, and so I don't have a section. And when I as I have an editor and I have a set of acknowledgment people. one thing that that may be worth considering is on the Linux kernel side, People that act patches. It's a it's like a verb. Right? Those maybe belong in the acknowledged sex Yep. Yep. If you review it and you you actually get an act by tag, whereas the contributor is somebody had submitted a patch. So Yeah. The author and the editor is it doesn't really matter very well, I think, but the contributor and acknowledge I think really so. if we have a way that we want to work, then we should agree on that as whatever the precedent is as we get short these documents here. Right? because I'm happy to change to be whatever. That's why I'm asking these questions here. because we didn't it's not a working group document yet, but once it's a working group document, we should have a precedent and kind of a rule that we want documents to use. k? So I'm just using myself as an example here because we want there'd be a bunch of documents with multiple person thing. So So I heard David you said just on that one just to close on that one. You said you think if you act something, then you think that is something to be acknowledged part I think so. Right? I mean, there's some overlap even even in the term. I I I think so. especially because because often your their their contributions are mirrored in the form of suggestions and and stuff like that. Yeah. Yeah. Yeah. If we can Since when I did it, it was a lot easier to retroact we go back and find everybody that contributed stuff because you can look at the get his 3 of everybody that was one of the, you know, authors of stuff. Yeah. Trying to come up the list of acts retroactively. was a lot harder, so I haven't done that yet. Yeah. You probably could with a bunch of tooling, but It's yeah. I mean, obviously, all of the acts are are retained because it's all just in the get history. But, yeah, more Yeah. Yeah. But it can be done. It's just I haven't done that step. So just -- About going forward, it's easy what the do you set forward. k. Yeah. So Okay. So just throwing up an idea here, Suresh Krishna. So, like, the we started the clean slate once the document becomes a working group doc, and we keep start keeping track instead of going back. I think that could be a good bet because that's the first -- Okay."
  },
  {
    "startTime": "00:20:03",
    "text": "document under the working group. Right? Like, and then we can kind of keep the process going forward. Not necessarily to go back. to that point, but we can discuss that Larsa. Yeah. Go ahead. Hey, Elijah. I just wanna sort of maybe tell you what we did in quick just for consideration. Right? So And this is also, like, only for the base documents. I don't know what Quick's doing now because I'm not a chair anymore there. So we we didn't have authors. at least not for working group documents. We basically at the chairs, we assign editors. also didn't have contributors. We only basically had a pretty long acknowledgement section that was automatically generated from anybody who had left the comment on a GitHub issue that made it into the document. So it was pretty pretty lenient. Right? And Everybody was sort of so we we were very good at focus. So that work us. And I think there was 1 or 2 people that we added manually because, you know, they would just send email. the way I think I I peeked at your next slide. So the we basically, as chairs, we're the ones that ran the the GitHub process. So we we're basically triaging the the issues on a weekly call, and we basically set to the editors you know, you this is has consensus and you can close it and you can merge it. and the editors basically did that, and there was a bunch of editorial work, the text that they should it on their own, but anything technical was sort of triaged that way in sort of sort of sort of the the the by by the shares with the editors and the the working group and that pretty well for us. I don't know if it's gonna work well for you, but you know, it's a it's a consideration that you might wanna Right? Thanks, So this next slide is not a statement about current state. This is just be throwing out a proposal to get discussion. Okay. So this is so we've been in a number of or at least I've been in other working groups with issues and somebody will raise an issue on the list and nobody will respond to it, and then everybody forgets about Okay? And so this is not to say that you have to use, you know, track every issue. What it means is that a issue tracker is useful to not forget that have been raised? because how do you know that you have consensus? If consensus is really supposed to be about"
  },
  {
    "startTime": "00:22:03",
    "text": "if all issues have been addressed, but not necessarily accommodated. Right? how do you know that? At least having an issue tracker that helps you keep track of nobody's gotten around to submitting the patch for this one yet, but everybody agreed it need to be fixed. And did we forget about that? and there's a bunch of mails on the list on the mailing list and a lot of those 100 a 100 one of those actually raised an issue. Right? And so that's the argument that says having a get having a set of issues tracked, not that all issues have to be tracked this way. somebody raises an issue and submits a patch in the same email. why bother. Right? But having that was useful. And so my proposal is now that we have a IITF GitHub repository, that unless there's another alternative, I like, and we've done that in a number of other other working groups is just use the GitHub repository that the document is in as a way as a place to track issues such that, you know, a chair is not can easily look up? What are the things that I still need somebody to address? And so that is a proposal And for the working groups that that dumbed that, I've seen at least three different ways that working groups have used for who gets to close those issues. Right? I've seen a a a a one working group that says The issue is closed as soon as the patch is merged. I've seen another working group that says the issue stays open until being an drafts division. That was that last right line on the first diagram. one that shows up in a data tracker, then I'll close it. And until then, it's a reminder that I still gotta submit an trapped. Right? I've seen a working group that does that. And, by the way, the one that I'm in the chair on right now gives us b. And the third one is when the chairs verify consensus on the result, Right? Because, you know, after it goes through any objections on the list, nobody raised it than the chair will say, yes. I agree. You've done what the working group said, and I'll close it that way. and a working group that's deep, and I'm an author in uses that one. Right? So I've done all three of these in different work years. So alright. Right. large negative answer. So, again, what we're doing in quick is is that we we basic actually sort of from used issues in the working group to figure out whether the text change was needed. And so, basically, we would we would not take PRs without their being an issue that the working group had decided"
  },
  {
    "startTime": "00:24:02",
    "text": "it's an issue that requires text changes. And and when we did, then we basically so we always have a link between an open issue and a PR. And we also had the model that whatever the editor copy was, on GitHub at the time, had only PRs landed in it that had gotten working group consensus. So you could basically assume that what you're reading there as the editor's copy was the agreed on state of the document. For the most part, we had some outliers where we weren't quite sure which option we're gonna pick and so we implemented one and then the other was on and so forth. And then occasionally, just to reconfirm, we said, on this particular version of the draft, let's do, like, a last call in the group a working group last call, just basically a affirmation that everybody really agrees that we have been is on this sort of important because we had parallel implementations and nobody wanted to, like, you know, undo things based on an editor copy. network pretty well for us again. Thanks, Raj. Krista, Christoph Helvex Let's turn this on first. I think it's on. You just have to get closer. Okay. Yep. Christopher Sullivan. You you're just tall I I find the usage enough that I can't hear you. off things like github, issues or pull requests extremely questionable. service that requires an account that has a very questionable privacy and usage policy And there's people including me who would refused to use that and driving an open standard through these kinds of services is a very bad idea. This this does not apply to just using it just to get server because you don't require an account for that, like, whole other Git hosting I will only comment there that I've seen 2 different ways that working groups use GitHub repositories. 1 is more like Lars said, where the working group participants are supposed to use the Git repository. The other way that I've seen working groups use it is doesn't matter whether contributors do or not, the chairs do."
  },
  {
    "startTime": "00:26:03",
    "text": "so if somebody follows something on the list and it's not being tracked, then shares will go and file an issue and it's a shared resource. Right? Yeah. mean, this is basically what we've been do in for a lot of the drafts in the NFS 4 working group where it's not even a working group policy and a decision by the editors that just about everyone's maintaining it a git repository. And a lot of people being Linux people, they hosted not on GitHub and elsewhere. but it's basically a way to structure the document and have a worse control history. Yeah. So I I I think, like, from the chat perspective, I don't think this is gonna exclusionary for anybody. So, like, you know, we'll find a way to make this work because there's other reasons not to use GitHub. Like, one of them being it doesn't support V Six, protocol, and we have a bug, like, what, for, like, 5 years. So I I I think, like, we get exactly what you say, we'll figure out a way to do this, like, you know but but I think Dave's point is we need to have a place where everybody gets to where the issues can be tracked and not dropped in the ground. I think that's, like, the key point. What's in line? Akamai, Watson Ladd Akamai. My one question is You talk about when a patch is merged or That could happen from two different places. So the native support for linking merging of a PR due to the closing of an issue is gonna have to deal with the fact that that patch could have come in on the Linux Colonel side And, also, once you start getting people thinking, okay. I'm gonna open a with a pool request in GitHub. now you have to make the patches flow back. So it might be a lit you might have to hand hold people and get them to point your patches in the right place. Yeah. Both are good Good points. And the the the first one, when I authored this slide, what I was thinking on a, was that when it was merged in the Linux chronometry. as opposed to when it showed up in the mirror. That's what I was thinking. But you're right. There's actually 2 possibilities there. Right? You could say, an intermediate one is I close it when it shows up in the mirror. Right? It you know, which is after I get check language current repository. That's not what I was thinking, but that's the first part of your question. And then this you had a second point"
  },
  {
    "startTime": "00:28:01",
    "text": "And I'm not forgotten what it was. You have to remind I had to come in on that one too. yeah. Yeah. You're right there. Thank you. people will think that they should open a -- Oh, k. Today, there's no backflow. Right? There there's that hitting us because you never check-in anything into GitHub that actually shows up in the propositors. There's never anything to copy backwards. If we move the file from GitHub let's say we moved instructions at opcodes over in the last current repository. You'd never check it into GitHub. Right? never do a GitHub pull request. Right? You only do a GitHub pull request. for the mirroring itself, the mirroring process does that, or for any file that's only in GitHub. that's what I was gonna comment on. Lars So like, I had a question for you, actually. Like, one of the questions is, who closed the issues? Like, in quick. Was it the editors or the chairs who closed the issue to verify it's closed? think it was the chairs. I can't quite remember because I'm old. But I think it was the the chairs after the PRs landed. Okay. I think, like, we would appreciate some input on that because I think, I think both of them can work. I I would say I've done rats uses a, and Teap uses b. Sorry. Tip uses c, Yeah. So, anyway, I I'm I'm I'm I'm authors of documents and working groups use all three of these. So I wouldn't say any one of these is particularly recommended. Thank you. So I actually got in line to talk about Christophe's issue right with GitHub we had that raised in in in quick as well. And One thing we did is we actually set up a separate IETF meeting list. that we that was basically the owner account of the working group, and so it was automatically described to all issues and all PRs. And so all the discussion went by email to that list. Yep. And even without a GitHub user, ID, you could reply to those issue emails, and it would show up in in GitHub as well. that was on the super great experience for the people that that chose that route because I think they were, tens of 1000 of emails on that list over the I mean, we have 5,000 issues and nothing 3000 PRs. Right? So"
  },
  {
    "startTime": "00:30:05",
    "text": "but it it did work. Right? But and and, also, it's it's important for sort of transparency and archival of the process to have that on the IETF side about what was actually sort of happening in the in the GitHub discussions. And the off chance that, you know, it it ever goes under. It goes Right. That's another up. We'll get up. So that that I encourage you to set this up, and it's it's not super obvious, but it's it's doable. And It's it's helpful. But, yeah, so if you have a significant constituency that doesn't wanna use GitHub. You you can't probably do what the quick working then you need to find some other way. Yeah. My impression is that what Quik did is not gonna work well for the Linux community at but I think what you mentioned about, like, if there is something that shows up and say, somebody comments on a GitHub issue. Right? then, yes, you can subscribe the mailing list to that, and I suspect that the traffic will be far lower than the quick traffic. So I think it'll be largely. I mean yeah. And I've seen other places that have done exactly what you said. Right? Is the mailing list gets subscribed on the watch list for the GitHub repository. So if somebody comments there instead of on the list like they were supposed to, it still goes to the list. I think they there there's, like, a slight difference not the list itself, but it's a separate list. If I remember correctly, who's list. That was you know, I definitely But but that was I set it up so that you couldn't actually post to it until unless you were a GitHub You could reply, but the IETF list dropped that email, but but it showed up on the GitHub issue tracker, and then from GitHub, it got pushed again to the mail list. So mean, The the real question is, I mean, why do we eat I mean, I I guess, I know Dave does it because he's used to it. But in general, Large parts of the IETF don't really do GitHub processes. The Linux community doesn't do it at all? Why do we wanna do it for this cross section of 2 communities that usually have a different processes. and and and"
  },
  {
    "startTime": "00:32:04",
    "text": "I I proposed it because I wanted an issue tracker. And if you have an alternative issue tracker, I'm happy to say that's another proposal here. The the the meta point is to have an issue tracker. Yeah. k? And we've got a repository that has an issue tracker, so we could use that one. use a different one if you have another one you're gonna point to. I I I just want one. I I think it's important to note that because all the patches are going through the Colonel tree, we don't need, like, we don't need something like Bitbucket or GitHub. Right? We need an issue tracker. We could use Atlassian. You can use GitLab. You can really use anything. So I think Having one is Yeah. We just need a we just need a way that that somebody who raises an objection over email doesn't have their objection fall into the ether? Like, what often happens with the Linux kernel? Correct. So if you wanna propose one of those other ones, we can update the slide that says, okay, if we could use IETF, get Hub repository we could use Atlassian, whatever it is, long as we agree on which one it is, that's all I want. Working with you a big one. I guess it's kind of bit getting into a meta discussion of should probably take back to the idea here well. Well, I'd like to get on a day for technical discussion, but this is one that we gotta have this discussion once. Right? But but, I mean, I guess, this is probably a bit of a generic problem in ATF that that that that that that that that whole concept of having an issued tracker that goes beyond the Eurada tracker for working group probably be a very good thing for many work because you're at only/RSCs, and we don't have any No. No. That that's what I mean. Yeah. Issued cracker that goes beyond -- Yeah. -- the Eperada tracker. Yeah. need a tracker for in that dress. Yeah. Yeah. So we do have something like that. That's, like, kind of like, bespoke stuff done for us. There's, like, a track instance that we have and we can use. Like so we can probably explore that after. But I think it's the usability of that. It's not as good as a GitHub issue So as long as we are okay with the compromise we are making, I'm I'm totally fine, right, like, either way. Right? But that does exist something that we can probably talk about. in a bit. I have done this. It's incredibly wonky, but Yeah. It can work. Yeah. I mean, the one interesting thing this is kinda getting into a lot of hand waving because no one's done it."
  },
  {
    "startTime": "00:34:01",
    "text": "one of the interesting things happened in Linux Infrastructure is the idea of that you have trackers based on email commands, like it started in Linux with Syspa, the thrust tester, and now we have the regression testing part. where you literally have the magic commands in the email, kind of like the devian buck trick works for people who know that. and That's very interesting because it falls to the email based workflow. A lot of IETF does and a lot of Linux does that It also means someone has to set it up, and I don't know that would so this is the hand waving part which is why I just wanna briefly show large I got again. So just to comment in in in general. So the the IETF has basically some pretty lightweight requirements. Right? Sort of participant, but this must be able to follow the work. Right? So it must be transparent. I think that is given on GitHub, even without a login because you can actually read the issues and look at stuff. can't comment without the login. you Right? But but contributions to the IETF typically have made on many lists. and that is always available. And as long as the it's up to the chairs then, right, to make sure that issues that get raised by mail make it into whatever system is being used to track those issues. And lots of working groups never do anything other than mail. which doesn't soup scale super well. So with with Quik, we actually really like the ability to be sure that we had actually closed all the issues that were open and felt confident that you know nothing got lost That was that was nice. I don't know how many issues you expect. but that was a compared to some other working groups that I was involved, and that was actually a nice feature. But as long as you pick a way that works for you that has, you know, the transparency that the IITF wants and and you can sort of main manage the process such that email contributions are at this treated as the same as any other contribution, I think you're fine."
  },
  {
    "startTime": "00:36:02",
    "text": "Yeah. So what I'm hearing is I have not heard anybody arguing against having an issue tracker to begin with. And since this one is not a technical thing, not gonna show up as an RFC. I think the chair should just decide and tell us the way that they want the working group to I mean, you've heard the input from the community now. It's not something that we have to it'll have IOTF wide consensus on or something like that. I think You guys should just tell us. Okay. Alright. I think we should go on, though. That's all document logistics. Any other document logistics before getting to actual document stuff? Alright. on his Okay. Thanks. What's up next? instruction side. Okay. Alright. guess, it's me too. Alright. So this is currently an individual submission, but I think the goal is to adopt it as a work in your document, at least do call or whatever. So the chairs will do that at the end here. But first, I wanna talk about give an overview since this is an individual submission. But, again, I am not an author. Well, guess I'm an author because I've generated a a patch or 2. But I am the editor right now, but I just create did the trends permanent in that graph from K. K. K. K. K. K. So the working group charter says this. Right? We're tasked with creating a clear process for extensions, k? And that's the part that I'm gonna focus on right now because most of the document is just talking about Here's factually what is actually implemented and people use as their Right? Just now in the draft format. But the working up charter says we're supposed to create a process for extensions. And so I shorted this thread last month or whatever that's that title you can find on the instruction set extension policy that says for extending the instruction set document, We haven't written that down. And so we started this thread, and I said, well, here's some proposed text to go on the and a consideration section, which if you look at the document right now that's posting the draft It doesn't have an eye on your consideration section. The copy that I have that's like the editor's copy has a per request open with text that I posted on the list,"
  },
  {
    "startTime": "00:38:02",
    "text": "wanna get some discussion about that right now to say what should it look like by the time it gets merged. So Let's talk about that. If let's say you wanna add new instructions, let's talk about things. Next slide. Alright. So now I'm gonna gonna present what was in that thread since there's only a small number of people commenting on like, I was on there, and Alexei was on there, and a lot of people were silent. So you weren't watching it, then here's the discussion. If Tate. So first point is that when somebody adds new instructions in the future, say we have an RFC and then somebody wants to add some new instructions. What happens? k. The first thing that we say is the recommendation is don't Rev the existing RFC to add new instructions. You add an extension RFC that says, here's the RFC and the the the the instructions for blah, and you put those separate document. You say, here's the, you know, in opcodes and things during use this one right here and you specify the behavior, but you don't rev the other one. k? k? And because the code points are are a new set of code points, you don't even have to use the updates keyword. Right. Right. Right. Right. which updates is a little bit ambiguous and IETF sense as to what what what updates exactly means. But here by proposal is we don't use updates, we don't use obsolete or whatever. You just say, here's an extension document, and here's the code points of the best worth worth worth k? And so then that just means any new set comes as a standalone document. We don't have to keep generating a brand new version of the same document over and over. k? But we also don't want to make the additions necessarily gee. You can't if month those and the Linux kernel until there's an RFC. No. That's not what we want either. Right? You want some process that unblocks implementers, k, without having to wait for an RSC, but still in urges them to have an RFC for things that we want to be cross platform. Right? So that's the goal. k? So the proposal for that is to say we want to allow a way of referencing something other than an RFC in the meantime to get code There's plenty of ways to do that. Okay? the proposal is, yes. You can check stuff in the Linux as long as you have stuff that's in know, the Linux criminal repository, you got a document there that talks about it or someplace else, then you can do it."
  },
  {
    "startTime": "00:40:00",
    "text": "k? So that's the proposal, and the rest is how you do that, but this is the intent. k? The intent is yes. If you wanna create your own smart with a couple of fancy instructions for your smart deck, there is a way for you to do that. k? We don't want to to to block you, and all the rest of that the presentation is about how and what the rules might be for allowing somebody to do that sort of stuff. Well well, having the community feel good about it. large ticket. So those are the quote points that live in an AI industry. Hold that thought because that's one of the next slides. Alright. I'm holding. It's living in a registry, and we'll come to that. So next slide, please. Alright. So thank you, Lars. So you should stay for the mics. The first question is Should that I enter does that registry be on I enter or not? Yes. I've got a plant in the audience apparently. Alright. So should the registry just be an or should it just be files in the Linux kernel tree? k? branch because a lot of things fall out of this decision here. Right? the policy for allocation, like, who can do stuff, what the pre rock are is mostly orthogonal to this. Right? Where is the list that you're gonna point people to? Right? Right? because what we want is we want the original RFC that says here's the instruction set. say if you wanna do an extension, Here's where you go. Here's the process, the honor consideration section, whatever it is. says, you should go here whether it's signing or not. Here's the process for doing extension. Here's where you post stuff to to get review or here's where you look to see what the code points mean if you get a file that has these weird things in it, where do you go and you look for the references and so So do you look for a file? Is that pointer somewhere in the Linux kernel tree, or is it at Those are the 2 obvious answers. k k. k. So now if you have a comment on a versus b, now is the appropriate play time to raise your opinions on that. Looks like I'm glad I stayed in line. So If we Put it in the Linux Curl tree or somewhere else. and you wanna refer to it from an RFC there there's this thing called the normative reference, and then and then it would need to be one of those pointing to some random file on some web page is"
  },
  {
    "startTime": "00:42:03",
    "text": "require special ISG approval because, typically, we would be prone to, like, other standards, normally, or other stable documents. Right? So it can be done. It may be a little painful I would I would personally like to see, like, a really good reason to do so because it is possible, but it's a little bit unusual. If we did it with Ayanna, that's, like, the normal way the IETF does this. and there's actually a process defined called early allocation of dynamic code points. where a working group chair, I think, is the process says can go to Ayana and can say, we have an adopted document that isn't ready yet. but it's gonna need code coupons and people wanna implement. I want an early allocation in that registry and dotgets, then put in there. And eventually, you know, when it gets an RFC that Copilot doesn't change. So if that I mean, if you haven't looked at that process yet, I encourage you to figure out whether it works for you because it would fit better with the overall ICF model, but this is kind of a special hybrid sulfate working group. Right? I I agree we might need to have creative solutions here. Thank you. in slash. Yep. Christoph Helvek. So I I agree with Lars. Right? I mean, the one reason why I started kicking this whole thing off is because, frankly, me, we needed a normative reference and the commit ID in the kernel doesn't cut it. So indirectly going back to that will kind of defeat the whole person. And Ayanna really does its job well. We shouldn't interact with them all that often because we really shouldn't be adding code points all the time. I mean, yes, eventually, we will. and having a proper process to go through, which isn't actually all that extensive. is a good thing, And Diana knows how to keep registries. we don't. It's not our main job. So All in favor for be k? k? Thank you. k. Jeff. Hi, David Bernay. chair hat off for a moment. So the the big"
  },
  {
    "startTime": "00:44:02",
    "text": "question for whether I think Ayana would be would be viable whether 2 things. One is whether they could accommodate a tree style of of instruction and coatings. It's not just 8 by 8 encodings where everything is the same. You have op codes that inform different types of instructions depending on what the op code is. for the rest of the encoding. It sort similar to X Eighty Six than something like ARM But Apparently, Ayanna can have I think an expert is either on the way. Kees are update upcoming slides. Dave's giving a a teacher on on upcoming IHANA people are in the room. Oh, Well, hello. So we'll I'll I'll let them discuss that. And my understanding is that it possible. But the the other part is whether what's the process with with ensuring that new instructions and new encodings added to to IONA are are approved by the experts, are approved by the group, and my understanding is also that we can accommodate that. according to how we structure how we structure to the RFC. So I I tend to agree. Ayanna is kind of a a no brainer normative reference. My understanding is the overhead is very minimal. and it's probably gonna cause less confusion and less overhead than something in the one external tree. So it's my two cents. Thank you. And and also one more thing. There there might be some stuff that's Yeah. simply first come first serve, and that's also something we can set up. Right? Like, you know, it might be very little, but you're I'm just commenting people are diving into policy stuff, which is future slides. I'm trying to keep policy discussion separate from the location discussion because I believe you're orthogonal. may not be convinced of that, but, hopefully, you will be by the time we cover both. So Got it. not it's not it's not it's not it's not it's not Eric Klein, do you have an example of what and I had a registry might look like. Yes. -- for some sample stuff? Yes. Because we have some -- I see Okay. there's a lot of people here in the room. Yeah. Yes. Good. And and they pointed me at some other industries that I sent to Suresh. So I'm gonna go forward in the slides, and it says see anybody else after come up that I'm going to use Ayanna in my verbal example assuming that the answer is Diana. But just keep in mind through all the rest of the slides, it would be a non in a version that I could equally use a different voice over for all the rest of the slides."
  },
  {
    "startTime": "00:46:01",
    "text": "But I'm gonna sue my Anna and this. So if I keep saying INA, it's it's because what I'm hearing so far. Alright. So if you look at 8120 which is the RFC that says what you put in your auto consideration section. There's a bunch of different subsections there that you can use as INA policies around any registry you give. Right? So you define a registry and you tell Diana, here's instructions for how to maintain that registry. Right? And so here's their list of common, menu of things that they're told for different registries. Right? And so Some of them can be combined that you could have, you know, different code point areas that use on policies. Some of these can be combined. Like, you gotta have a private use section or non private use and for the nonprofit use section and some of the other ones are menu. But for everything from, like, first come first served down to ISG approval. It's like for a particular range of code points. k? You'd typically pick 1 of these, and these are roughly in order of most from least strict to most strict, maybe ISG approval was not quite from first come, first served on the standards action, they're an increasing order of strictness. Right. And so, typically, you'd write a you you'd pick your registry when defining it, and you typically pick 1 or more of those. k? And so I'm going to assume that we're going to do that. But, you know, there might be variations. And if you want some special thing, you could do this with a tweak or whatever. That's okay. 10. So next slide. So another precedent that I would show, the that's I'm gonna argue is relevant for part of this because I remember I I admit, I'm gonna to that point that says, many wants to add a new instruction that they have to wait for an RFC. k, says, I can can I do this, like, for me or for my, you know, SmartNIC or whatever? kinda do it in the meantime and get some, you know, early allocation or provisional allocation or whatever. So I was also involved with the documenting the process for your eye teams that existed before me. And so there, Some code points, you split the space, you say, well, this space, this range of values has this policy, and this range of values has that policy. URI schemes is an example that doesn't do that."
  },
  {
    "startTime": "00:48:00",
    "text": "K. It's all one master range, but each entry in there has a label as to as permanent, provisional, or historical. could say for any particular instruction in the instruction set is k? So you permanent provisional or instruct or historical. Right? If you had a different code point space, That means once you standardize it, you'd have to change, like, the opcode or change some other entry in there, and that would affect implementations. And that's why I don't wanna k. And so if you put this label on there, then you can put different policies for different labels. And so it's not a range that was just a weird label on the table. Right? It says permanent, your eye schemes, they use a different registration for a procedure a different criteria for different labels. Right? So in their example, which I don't think is correct for us. Right? But in their example, you know, first come first, sure, if you can get some there's an infinite number of strings. Right? But you gotta have expert review to have permanent. Okay? don't divide by category. k. k. k. And in fact, it actually the the document I think there's a typo 8124 or 26. It's that same RFC. I got a typo in one of my two slides. It says, if your registry does not have a practical limit on code points, Perhaps adding the option for provision of registrations might be the right might be right for that registry as well. I'm going to argue that that's probably a good idea for us to maybe follow this as the recommendation that that perhaps adding might be right. k. k. Go ahead. think Michael Tom was ahead of you, but he I join the line, so I'll let Tom go first. But Tom join the line next time. Thank you. If you wanna see the full details, you could have read the the anybody else is waiting out there online, read the thread on list and you'll see post text. So but but Tom, go ahead. I'll I'll go Michael. Oh, clarifying question. So in this context, I assume code point really means up code number something else? It's more than just opcode. That's what David was getting at when his hierarchical because there's opcode. the source value. There's the, like, IMM value and offset value in the instructions. We'll see that in the examples later. It's a it's a set of things. Yeah. Thank you. But you can think of it as just opcode. If you think of it as just opcode, You'll all get you'll ask all the right questions anyway. Michael, go ahead."
  },
  {
    "startTime": "00:50:01",
    "text": "Hi, Dave. So one concern I have with these different with with this is that there is a a situation where long term kernels get back ports of things and Particularly, I can imagine if situations where A new opcode is created because we have a security concern that we want a hatchback, and we wanna use the, you know, the newest thing. and I don't know if I think that there needs to be perhaps another category, which is Somewhere's between permanent provisional that essentially means long term relief The number might change Upstream, but that it's not gonna change in this branch, and that when this branch goes away, all those opcos essentially disappear. and it's some kind of space in between. And I I don't know how to express it well, but It's it seems to me, like, that there may be a need that like that. and I I don't know how to fit that into our our note notions, Yep. I'm gonna ask you to hold that thought, but the teaser is I'm gonna propose the things that are deprecated into the historical bucket. whether you call it historical or deprecated? So, yeah, this is essentially allocate to historical. Right. Yeah. Yeah. Okay. Hold that because just okay. Now that I teaser. The legacy instructions for that's for legacy packet access instructions and ETF are already listed as deprecated. And so I'm saying those get those opcodes registered as history That's an example. And you're saying, what would the next thing be? Right? So Thanks, Carlos. Go ahead. Yes. I'm not sure if if this needs to stay this this statically divided. So let's say we have the traditional old, you know, numeric opcode. We divide the space up into the different things. But then, you know, people bring in what starts to be experimental. Right? They take it from the"
  },
  {
    "startTime": "00:52:00",
    "text": "the, you know, provisional or what whatever we call the bucket. Right? And it has this light wait approval process. But at some point in time, we go back and say, hey. We wanna make this part of the whatever revision 19 of the mandatory set of instruction opcodes. Right? I don't see any reason of not having in the registry, a particular column that, you know, upgrades them to basically permanent at that point in time so that we don't need to change the how your ice schemes work. That's that's exactly What you just said is exactly what happens for your ice cream. So if something upgrades from provisional to permanent, it just a legal change Right. Right. Could stop there? Do you wanna say something, or you hang out in case you wanna say something? I was gonna say something, but I think Dave is already here. Alright. You're on to the next slide here so we can say, hey. I've been talking about URI schemes. It's just a precedent to say, yeah. because I was the author of the document that documented the existing process. but I created it, but I wrote the document, the document what people were doing in the process. So for your ice cubes. Okay. So here's what I proposed in the list to say we have historical permanent provisional your favorite names, but I just copied the names from the previous one. And so for a historical meaning deprecated things, I'm proposing specification required. And that starts being the set of things that are listed as deprecated in the instruction set RST right now. is just the legacy BPS packet access instructions. There could be other things that get deprecated over time, but that starts in that category. For a permanent allocation, I propose standards action k? k? means it's a standards track RFC. Not just an RFC, but a standards track RFC. So that's, like, one of the most strict ones. Right? IETF Standard Shrek RFC, and that would be true for everything else currently in the set that RST. Right? That's my straw man proposal. provisional, would be specification required. So, again, if you're not familiar with specification required, right, which historical and provisional The way that works is it's a superset of expert reviews. So specification required, the IESG designates 1 or more designated experts. k? typically, it might do that by asking the working group chairs and and authors of"
  },
  {
    "startTime": "00:54:03",
    "text": "document to recommend some, and then they'll select, you know, 1 or more people that would be designated experts. And so what happens is if somebody else wants an allocation, Specification required means they are required to have a specification. doesn't have to be an RFC. Doesn't have to be in a draft. k? As long as there are a stable document that you can point to. You then send that to Someplace that the in a consideration section says to send it to. some of them, my wife says, and it's Diana. For ones that might say, send it, pick your mailing list, like URI review. k. Here's an example. Once it does that, then Ayanna will notice it and and ping the designated experts saying, can you tell me whether to allocate this thing or not? k. k. k. k. k. so within specification required, there's still a wide variety of what the And expert does and who gets to review it, even within the policies, you get to write the rules for who you want to review it, who the designated expert can ask, and whether it has to go to a mailing list or not that's still within specification required or even still within expert review. Right? there's so many finance in the room, so tell me if I'm getting it wrong. But I'm a designated expert on couple registries. So here's specification required, and we what the rules are. It's like you have to send it to the cross post of the mailing list and then the designated gets it. We write that in the text. high level, those are the buckets that I would propose is k? At the 3 categories, historical permanent provisional, so somebody comes along and says, I first want to do some new instructions. don't want it to be standardized initially. I wanna implement and check it in right now and start using it. Okay? something goes to the provisional path. They they write a spec? They go through submitting it to whatever the right mailing list is. The designated expert looks at it and says, Sianna is fine to listen to this in the registry as provisional, and here's the pointer to the spec. then it shows up on the page as being is the point of that spec, and this code point has been allocated, so somebody else can't grab it. k? And then at some later point, you wanna put it in RFC. So then you come back and you say, I wanna upgrade this from provisional to permanent. Now I actually have to go to the IETF create an extension document. Right? Not a not not an obsolete document, but create extension stand alone document says, here's the set of extensions."
  },
  {
    "startTime": "00:56:02",
    "text": "Maybe it's one instruction, maybe it's a set of 10 of them, whatever it is. Here's the behavior of put that in the working group, or some working group. This one or or another working group in the future, right, if it's, you know, 10 years from now. And then that gets standardized, and then it flips from per from provisional to permanent. k? It's kinda how that process would work. So that's my straw man that I posted the list. Happy to take feedback or whatever. think I had another slide that's kinda walks through an example or so, but this is the main proposal as this slide right Okay. ahead and go on to the next one. Okay. So now we got 2 options for what the tree that the entry in the registry might look like k? k? So assuming it's an INA registry, then you got 2 ways for what the INA registry registry or registries would look like. So here's option 1. Before I get into this, Chris, did you have a comment on the previous slide? so the problem with standard So track, right, is that when the working group closes, then you're kinda SOL. Right? key -- No. You can still get standard track RFCs after the after the working process. Well, you can't do it through ISC. Correct. have to do it through the to some IETF process. It's either AE sponsored or, I mean, or some other working group. And that that's generally a significantly higher bar than having a working group set. -- an example. we're gonna take an existing example, right, because we're you you do the analogy, you know, 5 years from now. So let's say the NFS working group wanted to have VPF instructions for NVMe. And let's say the Bpf working your pet already closed, k. The NFS working group could do it in that working group. k? With a review by the same mailing list, the same designate experts, but not in this working is in an existing working group that's instructions for that working group. You could. I guess I I just 0. previous experiences, expert review, is is my personal period experience preferred Right? Because then,"
  },
  {
    "startTime": "00:58:01",
    "text": "you know, some set of of folks who were involved in the working group and, you know, can kind of continue. Right? That that Okay. So I hear you arguing if you go back a slide, Suresh, or David, who has got I hear you arguing that you want permanent to flip back and also say specification required. that was my personal preference for those reasons. I mean, it is a barrier we've we've heard it before on on know, kind of LaSacham, in particular, and and some -- because there's the menu options here, things in between those two. So if you go back to the to like, RFC required is in between those. keep keep going yeah. That one right there. You can see in between specification required and standard section is required That means you can go to the ISE. Right. And but I'm I mean, the problem with IFC or I I'm not favorite of that. I'm saying, are you -- You're yeah. So so No. I'm not. Okay. that's pretty much Thank you. Because gonna allow informational Yeah. Yeah. RFCs to be sufficient, which is actually a much lower bar than expert review in my opinion. IETF review the main difference between IETF review and standards action is that IETF review can be an informational RFC in the IETF. where a standard section is only proposed standards or Fc. IETF review still means it's an IETF RFC. just not necessarily a standard track. Yeah. So I I did have something to talk about here. Right? Like, there's another thing kind of, from what we desire. This other thing is about the scarcity of the court point itself. Right? Like, the lesser number of this, usually, we go higher up the difficulty chain that like, one thing and the rate at which they consume. So if you look at, like, ports, for example, like getting a port or UDP board. It was, like, Hey, dude. I have a port and it's like, yeah, to now You probably had to jump through, like, hoops on fire to get 1. Right? So I think, like, I think that's another thing. It's not relevant to, like, what we want."
  },
  {
    "startTime": "01:00:01",
    "text": "but, like, how scarce the space is that is getting allocated. So that also plays into the picture And so I could see going either way on this. like but I think that's an additional consideration. I want like, the working group would think of. Yeah. I don't I I get the desire for for Stan. I mean, I I I see it. I'm just worried about it's it's exactly the 5 years down the road problem. or as expert review, as long as the experts are reasonably responsible and sane, it they can manage it intelligently, what the sparseness is, what the allocation is, etcetera, without necessarily having to find ADs are my experience not super excited to do you know, a lot of sponsors etcetera. That's my piece now. Alright? Agree. Thank you. Yari, go ahead. So first off, I I I I like your proposal, Dave. I I think it's quite reasonable. I am Personally, may maybe also a little bit, like, wondering sometimes you know, not just in this case, but in in in general, about, you know, are are the items that we're setting too hard. It's it's you know, you'd if you don't have us you know, running out of space problem than making it a little bit more relaxed can be helpful. And I'll offer you one way of making that relaxation that I've used in previous talk documents. So in previous documents, we have something like standards action. or some such, I would accompany that with or IST approval. so that there's, you know, some set of people I can, you know, grant on exemption, and nobody has to break any rules. And it could be expert review as well, but ISG is, you know, default route for questions? I I see a thumbs up from Chris just noting that for the minutes, and I'd like that I a 2 personally. So I would like to make the argument for RFC required. because that also doesn't allow you to go to ISE,"
  },
  {
    "startTime": "01:02:04",
    "text": "for example, as long as the working group is there at any working group that says, well, we feel responsible for these things. Right? So please come to us. Sorry. Can you repeat the parity of that one? I'm not sure I got the parity right. Did you say you long as there is a working group. Yeah. That fields it is entitled to to do something about the topic. whether that's the Bpf now or later any other working group to which we offload the stuff. we close this one. Right? As long as everything's working with RFP required, will basically say somebody goes to the ISE, and the ISE says, well, need to go to this working group. Alright. So -- RFC required means that the independent submission stream is okay. ICF review means that it's not. and No. I'm saying RFC required doesn't necessarily mean that ISE track is available as long as there's a working group that is responsible for this topic. But if the working group goes away, no working group wants to take on the job anymore. then IS 3 yes. 1 of the ISE track things that needs to be done is check that there is no working group that wants to take on this work. long as there is a working group that wants to take on this work, that working group is deciding what they wanna do with it, whether they wanna do it standardized or even informational. So I think this is the right fallback. So I understand what you're saying as an alternative to what Lars said that if you write the rules right, you can get that. I hit my own opinion, but I see VARs came back as You'll also send the problems to the same thing. So that was not that's actually not correct. Right? So If you go RC required, the ISE can take it on even if a working group exists. Yeah. it bears then an ISG conflict review the ISG would probably say, hey. This is sort of conflicts with the work going on in the Bpf working group. Do you know about that but the ISE can still choose to publish even if the ISG says do not publish, and that is a situation that I would really like to avoid. So I really actually like the standards action -- Yeah. -- proposal or ISU approval that Yari made for that reason. Thank you. So so so thank you"
  },
  {
    "startTime": "01:04:00",
    "text": "you and I you and I and Joe are all gonna say the same thing. So So if as as long as we basically have preference for a working group that wants to take on the work, over ISE, I think we have the right policy. And if the current conflict resolution isn't that policy then I'm sorry. then then then I'm withdrawing the proposal and saying that that that is the policy that we should have. Thanks, Carlos. I I I think, like, Yari's point kind of gave the release file with the working group close, the ISG can either direct a group that exists or, like, kinda do the thing themselves. I think that's probably easier somebody then going to the ISE because the ISE process takes a lot of time. Right? Like so like, ISB needs to find, like, reviewers and stuff and so on. So maybe that's an easier which kind of accomplishes everything you want, but maybe slightly lighter. I think Okay. Last word on this one? Kristoff no. You, Christoff. Yeah. So I'm probably gonna come to a very similar conclusion as before, but as someone who's really just a tiny contributor on the IETF side, and it's coming from the Linux background. a lot of these internal politics were actually above my head, and maybe I'd I'd like to skin the cat from the kinda existing EVP of analytics community point of view. Right? And I think for us, the important bit is that random people don't define random extensions, but we also don't lock a self out of ever extended it again. These are kind of, I think, the 2 main goals. that we wanna reach and think that one central part of it is I expert review as in, like, the core EVPF contributors being okay with it, is I think the really, really central point And to properly do this, we need a specification that's, I think, the absolute minimum bar in addition to expert review. Yeah. And with my my little bit of IETF contribution history I definitely like the idea of a standards action as, like, the default path And I leave it to the people who understand the bureaucracy better than me"
  },
  {
    "startTime": "01:06:01",
    "text": "figure out what are the important escape wells that we still need in addition to that. Alright. Thank you. Let's go back to the slide that says option 1 at the top. So now we're into But once you have a registry and you agree on what the policies are, what does it actually look like? So here's option number 1. k? And this is what I was getting at when I said Is it just opcodes or whatever? And the answer is no. Today, including stuff that's in progress, progress, meaning patches that are in the process of being reviewed, a Bpf instruction is identified by a couple of 4 fields. k? So opcode, source, immediate, and offset being the last one that was added toupled as a discriminator. Right? And so any one of those can be wild always have an opcode. And for some opcodes, you may have here's the source. and for any, you know, I'm in value or maybe it has to be 0, and whatever. So you can create a flattened table like this with some wild cards and source immediate with source and or immediate And then a particular definition for each of those, and you'd have a, you know, a spec that references them. And right now, all the spec is, you know, instructions at RST. Right? So one way is to flatten it to say there's 4 key fields in order to ask for a in a an allocation. You say, I would like this opcode, And here's the source value where I want it to be wildcard. Here's the immediate value or it's wildcard, and here's the offset And so you say, here's these 4 fields, and then that gets reviewed, and it gets added into This is option number 1, which is a flat tape k? option number 2, Same kind of information. So you have one table as the opcode table, And so the thing is some opcodes have multiple instruction associated with it. And you say, well, here's all the opcodes, and some of those is just defined by the coat coat coat and and everything and other ones, the same opcode is is ambiguous so these multiple instructions. And so for say opcodehex18, They're all sixty four bit immediate instructions, but there's a bunch of them. And so you could say, well, I'm just gonna put those in a different table. k? And so I've got one registry. It's the opcode registry. and one registry that's the 64 bit immediate instructions registry."
  },
  {
    "startTime": "01:08:02",
    "text": "if I wanna have a new 64 bit immediate instruction, I don't need any code. I just need to create an entry in the immediate instructions 1 and add another, you know, source value as the discriminator there. Right? And so this is an example which is hierarchical. Right? because the hop codes being the top level of the hierarchy And then for some of these, you know, so the next level of the hierarchy down in this, you know, opcode 8 The next level is the source 1. And for a different part of the hierarchy, the next level might be the IMM value. Right? If you look at, like, the atomics and so on, the IMM value is the next level of the hierarchy. So you can craft it either way. I don't have a preference, but the point is you pick 1 of these 2 and you write it up this way. And right now, in my Internet draft. I took option 1. But if you like the option 2, I really don't care between those. Alright. So If nobody else cares, they're not they're they're not then then I will keep it in the existing work until somebody has a preference. So Watson Lad. Come on. I prefer option 2. I think it conveys the structure a lot better. Okay. giant table. Okay. Thank you for expressing a preference. It doesn't tell me it doesn't have a preference. Alright. I'm happy to switch to option 2 if people and if there's anybody who objects to option 2 and just hates it, then I'm happy to switch to option 2 in the Okay. I see Will giving me a 2. Okay. Thank you, Will. So I I I agree that the hierarch hill representation for the normative part is the right way to do it. And for things like the INA registry. I also think the actual flat table that that that is basically the reverse mapping that we have in his appendix can be really useful for implementers As an implementer, I could do the same thing with either option number 1 or option number 2. For purely selfish reasons, I'd like to not do both. Well, the the good thing is if you have the hierarchical table, you can auto generate flat tape."
  },
  {
    "startTime": "01:10:00",
    "text": "sorry. Option 2, you can auto generate option 1 from 2. Is that what you said? Okay. It's easier to auto generate one from 2 the other way around. Yeah. Okay. Okay. Okay. Las Vegas, good. I I thinking about the Diana side of this. Right? So so how many in in this option two thing. Right? You would have a separate table for each line in the first table. Right. No. Each lot so you can say some lines like opcodes, hex 17 and 1 f, at least today. There's only one instruction there. It it it allocates the entire opcode space. Right? This is putting aside for a second, maybe something could change in the future that takes 1 it into an industry. But at least if you look at what's in there today, Only a small number of opcodes have multi values. I think like the byte swap opcode does, The 64 bit immediate one does, the atomic one does. There's like a handful of ones. so right now, we're talking about a total of less than 10 registries total an option to. Okay. I was just worried that Ayanna to link would explode if we have, like It's more than 1000 tables on a on a somewhere. Okay. Yeah. Somewhere between 2:10 right now. Okay. If Diana has an opinion, that'd be interesting too. But, otherwise, it sounds like we're leaning towards option 2 there. Okay. And if anybody else has any comments, the actual literal tech that I posted the list and this Straumann table, which still follows jobs in 1. It's currently sitting there in that per request. You can go and browse it or whatever, and then I will update it based on the comments that I've heard so far. otherwise, it matches exactly what was on the list. So Okay. Tom Herbert. So this is great. I'm just wondering, suppose somebody wanted to add instructions, there be, like, guidance on how to do it, what the process is? That would be really helpful, I think. how to add instructions? Is that what you asked? Well, I know what I mean is post somebody came in and said, I I already have a set of instructions that would be appropriate. to put in BPL. it would be really good if there was a document that said, here's generally"
  },
  {
    "startTime": "01:12:00",
    "text": "the the process Yes. So there's obviously a lot of moving parts here. We have to deal with IUTF. We have to deal with Linux. that document would would be really helpful. other thing, Any limitations or constraints that we expect So I do a lot of work, for instance, in ResCVIVE, which is an open NICE, have added quite a few instructions They allow, for instance, custom instructions so they already give code points entry points quite useful. be really good if if those sort of things were documented. So a sense, we we wanna we wanna make it easy to do this. Right? Mhmm. And and promote this. It's an extensible -- Easy to do it right and hard to do it wrong. fine. So, yeah, I think the the the the goal of a good ionic consideration section is to actually give that process, although One of the audiences of INA considerations is, of course, INA itself. And the other audience is an potential person that wants to get an entry in the registry. Although it's not common for, say, INA consideration sections of an RSC to repeat the definition of the policy, like, you know, expert review. Right? They're not gonna copy all the tech what an expert review means. It's gonna say, here's what an expert should look at. right, in there, but it won't say, here's how expert review works inside Diana or whatever. That's in a different see. But if we can somehow say, here's what an allocator person needs to know, I think Diana consideration section is a good place to put that. So I get your point, and I agree that having it be in this section here would be good. Anything that you can come up with that's not in there right now, Send me text or send me ideas. Yeah. So you if you could take this to the extreme, right, somebody may come in with a complete set of instructions, not just 1 or 2, it may have a whole subsystem. Mhmm. obviously, we wanna make this process as easy as possible. What we don't wanna do is proposed something and then just people come back and say, this is all messed up and and we get that. So any guidance you can give on this this topic, Mhmm. That would be quite helpful to developers."
  },
  {
    "startTime": "01:14:00",
    "text": "If you have suggestions there, then, yeah, So, yeah, Christopher Helwick again says someone who's only got minor corrections into risk 5 and never any of the of work I wanted to do I at least understand how that works very differently than EVPF. Right? I mean, if you look at a real CPU instruction set like like like, brisk 5, It's got a much bigger up code space. It's got a much bigger scope where people wanna do and the scope what EVPF is kinda designed for is very limited. So I don't think we need to be quite as, like, inclusive and extensive as as Risk 5. That doesn't matter. It wouldn't be good to document the assumptions, but compared to all the other work we have on the plate, I would not consider it a focus for for the working group, and I'll try to quote Alexei from memory, and he can shout at me if I misquote him. And a lot of the interesting things about EVPF isn't really the instruct set, but, like, the whole environment, and we're not even getting to that. So maybe right now we shouldn't spend too much time on actually extending the instructions that just really make sure we can. because we absolutely have to. It just really shouldn't be the Prime Reason. Yeah. I mean, I think we do have to get the process ironed out. and and enumerated because that's what we're gonna be building it off from later. But to your point, yeah, we don't need to. You don't need to build too much of that. So I do have one question if people have a strong opinion on which I alluded to earlier, and I'll now because I don't have a convenient place to ask it later. Right? I mentioned that the Aina consideration text right now? the text itself in a consideration section is in GitHub not in the Linux chron repository. somebody has a strong opinion as to which is the better place for it, should it move over to Linux Kroner If Troyer Stan, github. I don't care either way. If somebody else has a strong opinion, I'm happy to do that. And so the stuff that I've been presenting here, is only in a github port request right now. That's the top line there. That's my reminder to ask this question"
  },
  {
    "startTime": "01:16:03",
    "text": "as opposed to a kernel patch contribution there even though it's cross posted to both lists in either case. Right? the same set of reviewers. Right? But which is get repository does the authority of copy live in for any considerations. I don't carry their way. But if somebody else has a strong opinion, I'm saying right now it's GitHub because that's what I did. And tell whatever. Okay. was one question I wanna ask before I turn back to chairs. So might not so strong opinion, but but but sick it's like I I think with this duality of the repositories is is soon as we're in a working group document, never mind a working group like, last call, don't think it really works like that anymore. Right? Because then we're highly in the IETF process and, like, minor fix ups and Eventually, the document is gonna be released and stable. Mhmm. And I suspect the back thing at that point is to just have a static copy of the ICF the terminal trees you really wanted there. and the problem kinda goes away which -- Mhmm. suggests it probably doesn't matter where we have it right now because in the long run, it just gonna be in one place anyway. I I take it. You don't care. You take you have an opinion on the long term one, and I agree with you on the long term one. I still don't really care how we get there. That that's my opinion. it's pretty easy, I think. I don't care in the short term, which is why you know, because it's gonna move eventually if it moves it when it becomes an That's fine. Thanks. Yep. Thank you. Alright. I'll hand it back to the chairs. Do you want me to stay up here, sit down Okay. Alright. Yeah. I think you can stay up here. So We do have a dealer rule for the ISA. Right? And and one of the goals Zoom all the work through forward is to have a document that needs a deliverable And right now, like, we have a Draft Taylor BPF ISA. that seems to be, like, a good fit for this thing. So we kinda wanna do an adoption call And just for the people who are not involved with the ATF, the adoption of a document. It's not a endpoint. It's a stat point. Like so that's when we actually start doing the work. Right? So there's, like, I'm gonna be probably gonna be, like, 100 of issues, 1000 of issues. I don't know."
  },
  {
    "startTime": "01:18:03",
    "text": "hopefully hundreds of issues that's gonna be there. But, like, we do wanna have some doc method management change control that belongs to the working group. right now, Dave is editing. Like, Dave can put whatever in Right? Like, you know, I'm I'm sure Dave doesn't do that. But theoretically, like, he he has control of the document. He can critically put in whatever. But I think the adoption of the document brings the document into working group control. And Dave may or may not be the editor of the document. He may or may not want to be it, but, like, something we can figure out, like, you know, going forward. But the working group takes all the document and points in the district for the document. That could be Dave, somebody else, like, you know, we we have to figure that out. Our model or multiple editors of the document. Like, you know, based on dev's proposal. So we'll do so the way this kind of works is, like, we have a meeting. So the kind of ideas to get a sense of the room but also confirm this on the mailing list after. So, like, both the our list as well as the the the weaker kernel list. Like, both of them will get, like, a notes saying, hey. What do you think of this? Do you have issues and stuff and so on? So the idea is not this is not voting. The idea is to understand if there's any concerns using this as a starting point. Like, usually, that happens when There's multiple drafts containing to be the working group document. That's kind of when a lot of the contention happens, there's only, like, one dock comment in there. So that idea would be, like, use it as a base and do whatever work we need to do on on top of that. Right? So the way we usually do it is by humming. So the idea is, like, we can either do hands or humming. But humming is kind of better because it allows people to express their opinion more freely. Like, it's a lot of a it's more of a cultural artifact and anything that's, like, Lex required, but that's kind of how how you do it. Tell. So the first question I have is, like, how many people I actually read this document? It's like linked in the materials, the Daphthaler VP of ISA. If I can hear a for people who actually read it. you've read instruction set RST, you've read 99% of the document."
  },
  {
    "startTime": "01:20:01",
    "text": "Yep. So Yeah. Go ahead. Okay. Go for it. Ray sounds is good. Go for it. k. Kathy has read half the document. Okay? So reasonable number of fans. And Okay. So, like, trying to do an adoption call for this. how many people think this would be a good starting point. for a working group document for the ISA deliverable. So if you think you support that, now. Now If you think This is not a good starting point. for the ISA document. Please, k. I don't hear anything against. So the next step is, like, since we have a meeting, we do this just to get a sense of the room, So since the sense of the room is to adopt it, like, the actual adoption happens on the mailing list. So, like, this is not a final decision. Just just like a way to start the adoption column mailing list. And and couple of things we need more than this. is to get reviewers for the document. like, from the IETF side, if you're interested in reviewing the document, Please raise your hand. k. Couple of hands. Thank you. Thank you. And if you are willing to edit those documents. So become a editor of the document. Just send a note to the chairs. either after the meeting anytime when if you're interested, just send us a note. and we'll certainly, like, you know you know, choose the edit list for the document. based on who's available Thank you. So our next step is we will do adoption column address. So Alright. Thank you, Dave. So next up, believe Will's gonna be talking about ABI Considerations"
  },
  {
    "startTime": "01:22:07",
    "text": "Hello, everyone. My name is Will Hawkins. I'm a professor of computer Science, but we'll get to that in a second. First things first, I wanted to let you know I chose the most obnoxious Microsoft theme I could possibly find. for this presentation. So that I went out of my way to do that. I think I succeeded. So you can go to next slide. I if you skip beeps? Did you go to instead of one This is the second one. Okay. We'll start with this. What is an ABI? Well, everyone knows what an ABI is. Right? it's obvious Next slide. we're we're just gonna make sure that we have the right the right presentation. Just one second. That's one. Okay. single enough 3rd slide. Alright. There you go. So, no, it's not obvious. I spent a long time trying to find a good definition published somewhere for what an ABI is. there's a lot of documents that say, okay. ABI this. ABI that, but none of them say, like, a really good definition. So I started by attempting to come up with this definition. And an application by near interface defines the requirements, that 1 or more binary software objects must meet in order to guarantee that they can interoperate and or use the resources provided by operating system slash hardware combination. So we started with that. So with that general premise in mind of what an ABI is, I wanna talk a little bit about what the goal is for having an EBPfabi, I'd like to say a little bit about who am I and why am I qualified to do"
  },
  {
    "startTime": "01:24:02",
    "text": "spoiler alert. I'm not. I'd like to talk a little bit about the early effort and how we can collaborate on this and then how we can go forward. and maybe make something out of this. So go ahead. So the goal here, I believe, would be to create something that looks a lot like the generic ABI, for system 5. But for EVPF, we would have support in that for processor specific supplements for different implementations. So There might be a processor specific ABI for the colonel. for windows. for free BSD. or for some hardware implementation of this. like, the I think I'm pronouncing this correctly. Julio, Aguilio? CX, anyone wants to give me one of those to play with, more than happy to take it. So like I said, the scenario would resemble something like the setup for the system 5 ABI, In fact, in an attempt to make it as close to the system 5 API setup as possible. The the straw implementation that I have out there now, or the straw collaboration point is named system AD. ABI, and that's for Alexei and Daniel. So that's systemad, we have the system ADABI that we're going to describe. So -- Nice. Okay. So who am I and why am I qualified? I started I gave you my name already, and Will I'm a professor of computer Science at the University of Cincinnati, And I am definitely not qualified to do this. I am only qualified in so far as I love obscure things that are heavy on the details."
  },
  {
    "startTime": "01:26:02",
    "text": "And I'm a co maintainer with Alan Joey. of Microsoft on the UBPF implementation. of EDPS. So huge fan of all the work that's already been done on EVPF I think it's was actually talking to a friend of mine, on the phone last night. He said, what are you doing out there about IETF thing? sounds like a boondoggle where you get to go hang out in San Francisco. I was like, oh, don't worry. It is. But in all seriousness, I get to get to talk about eBPF, which I think is one of the most influential technologies that we've had recently. terms of being able to really do things in the kernel little more quickly than we have in the past. And I think that's really, really impressive. so I'm really thank you to the chairs for letting me stand up here and talk today. sellers. That said, I am an incredible shrinking violet. with an incredible thin skin. So, again, I'm not an expert on any of this. I'm just trying to facilitate a process to get something that I think needs to be done So please treat me kindly if you don't mind. So given what we've already talked about in this session. I think a lot of what is on this slide is pretty much OBE. based on what we've talked about, But I will say that the early efforts are online at this GitHub URL, And the current text has been scraped together in a few weeks, But I think the the the parts that are a good start or the definition section And the introduction And I would like to get to a point where we agree on the rough structure of the contents of the document. And then follow, all the rest of the processes that we've laid out here, to get it going into the right spots, into the right document locations."
  },
  {
    "startTime": "01:28:00",
    "text": "So The open question again, we've already discussed the open question extensively, whether or not this is the right spot to collaborate. Sounds like it's not So I will work after the meeting, with the chairs, and with everyone else in the room, to get it into the right spot so that there's a way to collaborate and make those collaboration efforts available to everyone. So I think that's pretty much all the slides that I had Again, I would love to hear Any feedback that people have? end If anyone wants to collaborate, please Let me know. Christophe? Yeah. So I I was a little trip off by you mentioning, like, different ABIs for Linux and freebies team, whatever. Because I think for a lot of the users that one of the interesting use cases is that if you have a program type supported by different environments it really should be portable between these environments. And I know Dave really likes to be able to say use Linux Well, EVPF programs written for Linux on Windows and and vice versa And then I took a brief 30 second look at your document after you posted the link. And I actually think the document is doing the right thing. It was to slightly trip me off. Okay. And I'm I'm pretty sure there's a lot of fine points we need to do in the document, like, not actually talk about SIS calls like the 5 API does because the concept is slightly different, but I actually think the whole structure translates very well, and, yes, it will be a fair amount of work. I think it's very useful work, and we probably need to tie it a lot to different program types and stuff, but It's a good start. It's gonna be a lot of work, and it's probably something we, as the group here, should"
  },
  {
    "startTime": "01:30:01",
    "text": "eventually look into. I also suspect for me here not the first priority. We really want to get that instruction set document out as soon as possible including the accessibility, But it's it's it's definitely good and important work. Thank you for the feedback. And I definitely we talked a little bit about this before the session this morning. I definitely agree with you that the ISA is is definitely the place to start. Yep. So thank you for the comments. just to quickly chime in. Yeah. It's I I say it's definitely the priority, but, of course, nothing is stopping us from concurrently working on on both, but Yeah. Yeah. Yeah. They should we do exactly. But we do have to avoid the depend dependency dependency on the PSABI doc for that. Dave? Dave Taylor. First of all, thank you, Will, for being willing to take this on. Appreciate that. The on the ISA document, I think some of this stuff on the ISA document is that there are some things that are in the ISA document right now that I've heard arguments from people like Alexei that they should move out of the ISA document and end the ABI document. And so the Having a start on this one is important for us to be able to close on the k? So that we have a place to move text to without the text being lost. k. And so that's why I think that this is really good to say adopt something even if it's a skeleton that has almost no content in it so that when we move stuff, out of the ISA document so we can close it down that we have a place to put it. Right? And so things like, you know, how many registers out there and so on? So just like, So my view of the slide that you talked about where there's, you know, different instantiations or whatever, I think that the document that I'm hoping that you might be proposing to be the an editor of is one that might say, here's a set of minimum bar. You must have, you know, at least, you know, 11 to register as our 0 through our 10 and and, you know, you must whatever the you know, you must have at least 5, twelve bytes of stack space, whatever it right. So you come up with things like that, that there's text in the instruction set RST right now that should move over because they're not about the instructions per se."
  },
  {
    "startTime": "01:32:04",
    "text": "And then anything that sells, it says let's say you have a platform that has, you know, 12, 15 registers or whatever. Is it compliant or not? Well, it does. It has all these things, but you can't write a program that's gonna run on these other platforms too, but you're still compliant to the instruction this is a document to cover those things. And so that's what I see as being value in here. and saying if somebody wants to have, you know, a super set of it that says, yeah, we happen to have, you know, a mega stack space or something like that on our platform You're still compliant. Where would you put that down? You don't put that down in the common document. You put that down in your platform specific extension. So I'm a fan of all that type of approach, but I think they're super value in this. And I think it's time critical because I think it's necessary to to get a start because it it's necessary for us to close on the SA doc. Thank you very much. Am I allowed to Birthday. Okay. So, no, I think that's that's that's really great. And I think as specially I wanted to make two points on that. One is in the document text right now, it explicitly it even explicitly says, look, in your processor specific sections, or in the generic part where we say a process are specific must define this or must give a value for this, it's setting only a minimum. those can go above that. Like, okay. Look. You must have 512 sack space. Well, the press gonna be behind me say, You can have a gig or, you know, some of them are. Okay. And then the other quick question, I think, that maybe goes back to the ASA document is there were some specific spots in the ISA document that we wanted to take out. Do we actually want to do that, or are we okay leaving them in there because they're in there now. like, specifically reflecting on, I think, Alexi, you said that you would prefer not to have the calling convention in the ISA document where it is now, I've already duplicated that section in the ABI. So if we wanna just take it out of"
  },
  {
    "startTime": "01:34:00",
    "text": "that the ISA document, maybe that's now we can do that. So, yeah, yeah, that was one thing like, the the the calling conventions, like, the the register usage is definitely in ABI and noninstructions that thing. One thing where I tend to pretty strongly disagree with what Dave said earlier is The number of registers is actually very fundamental part of the instruction set. And there are a bunch of weirdo instruction sets that actually have options for different numbers of registers. X Eighty Six is actually kinda there with the newest Intel extension. But But but even there needs to be an option in the instruction set and not just in the PSABI, because you're running into all these encoding problems, otherwise. Yeah. But the actual usage of the registers for calling conventions Yes. That's absolutely API. And, actually, yep, that's a that's a great point. And, actually, Alexi made a good point about that too where they hit know, we could have r 10 is the base is a register base is a base pointer in in some instances or not. And so yeah. 3 point Thank you. And and and to go back to your earlier question and and I think Alex already said it. But, yes, we need to take it out of the instruction set document, the calling conventions. And as Dave said, we need a place to to record it. So We need to figure out if we wanna start with your quiet comprehensive, at least, instructor document or just have a little notes document well, for now, but we need We need a place to record it, I think, that we can drop it from the instruction set document preferably something that's also in the Linux kernel free right now, at least as long as there's no comprehensive set of bigger specifications to replace it which might argue against just doing a newer document because I think in the current form, it it's not really something for the kernel tree. But, I mean, those are minor"
  },
  {
    "startTime": "01:36:02",
    "text": "details. need to waste the working group time to discuss it. 100% 100 We don't I'd agree that's and the only reason I feel a little sheepish having, like, this GitHub repo even on this slide because it's not what I want. I want it to be part of what everyone else is doing but I also didn't feel like it was to the point where it would even, like, Yeah. It could be even checked into that standardization folder. You know? -- get full of soft cold, but nothing gets done unless someone starts it and anything that's committed to version control is a good start. So if if there is a consensus that we want to move what's in this repo after, you know, another week of my work with just cleaning up things that say to do and things like that, into that standardization folder, I'm more than happy to do that. Just you know, me the word and we'll do it. Yeah. I think the the natural progression would be clean up whatever you want, and then We'll send this to the list -- Yep. -- and people can take a look. Okay. you know, given that if we're gonna model it after the the the charter item for building compatible binaries. Yep. It already kind of has a fit there. And so if it's in if it's in the skeleton form, if it's quite basic, It should hopefully be -- minimally contentious. Okay. Cool. Thanks a lot, Phil. And and thanks for willing to step up and come talk here. We love newcomers, here and, like, you know, coming in and just doing this, like, really appreciate you coming to do an annual help your offer to help myself too. Thank you. Well, I'm really excited. Thank you for for letting me speak, and now I'm gonna be incredibly rude and go to the conflicting session that I supposed to be at, and so it's gonna look like I don't wanna be here anymore. But really started here. That's all I meant. Oh, I would definitely started here. Yeah. Thank you. Thank you. Dave. Paging, Dave Taylor, Yeah. So we're just having discussion that that"
  },
  {
    "startTime": "01:38:00",
    "text": "tool that I have that generates Internet draft format from RST files. should work with, in theory, any RST file, and if it doesn't, then file an issue because the tool is open source. We can file issues and fix bugs for a transform tool. So, yeah, any other document come up whether it's a PSAPI or the document that I'm gonna talk about next or anything else, use that. as their Right? because you're pulling up the elf one. trying. Yeah. It's on the road. So I'm this one is also an Internet draft as generated from RST using the same tool why the the the generator tool is not a bpf repository. It's an RST to, you know, ID repository. I just like a bunch of other tools that I do. I use that too late. I I think it was unfortunately added too late to data tracker. But yeah. That case meeting closed. I figure if we have spare time, then I can talk about this one. This one is less important or urgent anywhere in the timeline is because it's sequenced after the other ones. But if we have spare time, then I can talk about it since there actually is an Internet draft. With the number of open questions. Do you have room? Yeah. Yeah. open the thing in a new tab and k. The chairs have it up on their screen. Sure. But it's not up on open it on the title. So it's Covered. Yep. Yep. You had to get out and get in again, I guess. See if this works. Yay. Okay. There we go. Alright. Is that close enough for me? It is close enough. Yeah. Let's see. Let's let's go. So you're just going to the next slot. So, yeah, this one is draft layer, Bpf Elf. Interesting. You're gonna have to keep it on the same screen. Alright. So the working group charter says this, notably."
  },
  {
    "startTime": "01:40:04",
    "text": "Our working group charter among other things says we're gonna do 2 things. And by the way, PS means poststandard, and i and brackets means informational. we're gonna do one document of proposed standard that's on the Bpf type format. and one that's on informational, there's documents that recommend conventions and guidelines for producing portable program binary case. k? And so, notably, the document that I'm gonna talk about is in that 2nd category. Where elf is the file format that's the recommended convention guideline for our portable Bpf program binary You notice this is intended as intranational not proposed data. keep that in mind because b p f b t BTF. Right? BFF site format. That one is proposed standard. What I'm gonna talk about is informational. And I'm gonna ask a question later about his text in the right place, keeping in mind that proposed standard versus informational is statement about text, and so that depends on which document it goes in. Right? post intertext goes to her post inter document. unproposed standard text can go in an informational document. Alright. Keep that in mind. Next. Okay. So what is l? So this one yeah. Go back there. sir. Alright. Here we go. Let's see if you can get that on the synchronous screen at the same time. I don't think I can. Well, Okay. I'll talk about it. And in that case, make sure I can see one of your slides. Alright. So Alf is a file format. If you're not familiar with it, probably most are. But just in case there's somebody here that's new to k? Elba is not VPF specific, right, at Elp has been around since at least the nineties, and there are two versions of the specification that are roughly the same, So one version that you point to, which is the one that draft currently points to as a as a normative reference is in the SEO doc that's a system 5 ABI, and that one was last updated 1997. k? And then there's the tool interface standard dated 1993, and that one's published by the Lynx Foundation. most of the content is identical, but not everything, and I'll mention that in a second here. So those are the 2 references. 1 is SEO, 1 is"
  },
  {
    "startTime": "01:42:02",
    "text": "its foundation as the maintaining organizations. But, Jonas, both of those really predate EVPF as exist today. k. The l file format is used across the industry. The l file format is not just used by system 5 or Linux. Right? So even though it's SEO and Linux Foundation, it's Linux specific. format. Right? We use L file formats on EBPF for Windows, for example, and plenty of other things use Right? So it's just the the original reference and the publication place that originally happened, but then it kinda spanned beyond the original Linux and system 5 and SEO ecosystems and so on. And so this file format supports many different architecture is which they call machines and so different processor types example, are different machine values. That's just the name that's used in that in that document. k. And so what Bpf does is Bpf uses a profile or at least what I call a profile of the general l format And so the general app format says here's a machine field with a bunch of, you know, code point values in it that mean different things, you know, risk 5 and x86 and blah blah blah for between some other ones. And so BPO is just another one in that set. k? So next slide. We're gonna try to change to the other version of sharing because, apparently, we We've, like, gotten that figured out. because the question often comes up. Is this, you know, changing the elf spec or something like No. The old spec defines a code point space and a set of general things, and it conforms to all those. It just allocates another code point value out of an existing registry. k? and then defines what the meeting is that are sections that confirm So alright. Here we go. Thank you. So the machine value, right, there's a there there's a code space to find the other ones, and BPS uses the value 247. Now as I mentioned, EVPF post dates the specifications. Right? They were last touched, 1997. So if you look at one of those, they don't define, like, an anti registry. to only list of the values is in those documents as far as they're concerned. Right? So you look at the 1993 spec, and there's only, like, 16 entries"
  },
  {
    "startTime": "01:44:00",
    "text": "You look at the 1997 spec over at the SEO repository, and it goes all the way up to, like, risk 5 and stops at, like, 243. And so in that sense, BPS is not in either of those specifications. because it postdates them. k? the thing that you might need to do is figure out how do I make sure that 247 is it'd be the right mechanism. And here's the spec for it. Right? So think about when we talked about gallocating, know, an INA registry. Well, this is not an INA thing because somebody else, you know, system 5 generates How do we make sure that number 247 gets registered in the right place? My personal belief is that registering the value in the place is orthogonal to the where the specification resides for what 247 means. I say it's a profile, it's a profile that assumes that 247 is okay right value to use. k? So when That's been taken care of via whatever the other process is. And then here is the suspect that you submit that says, here is the spec for what 247 meets. k? That's what this is. And my claim is that IETF is a perfectly fine place to do that. that's my opinion. k? That's what the worker gets to decide as to whether this meets that information no document bullet for our charter. k? k? Alright. So what does the profile do? What does the document do? k? k? Well, first of all, it says the value 247 is kind of the discriminator. That's what this document saying is this. What's the meaning when I say machine equals 247. What does that mean in the file? This is what defines the rest of that. k? But it doesn't contradict anything else in the else back. Right? It says here's how you use it in ways that for what you know, to to constrain what you can do. So, for example, in the main elf specification, there's other elf header fields. that have different possible values. There's different type values. There's different, you know, class values and so on. It says, which of the 1 or ones in this case, 1, which value is it that's used by b t BPS. Right? So here's the type value that you filled this in the section header. are the menu of options in the main spec? Here's the one that you use for And for the class, here's the one that you use. They're all 64 bit and so on. what is the meaning of a text section? k? Says What's the meaning of a data section? Well, you put your b p f programs into text sections, map definitions into data sections, things like that."
  },
  {
    "startTime": "01:46:02",
    "text": "And then it has some discussion around section naming conventions as we'll see on a later slide. There's multiple conventions in use today. And it defines contents as some other special, you know, optional sections, you know, version and so on. So I have later slides and each of these. So This is kind of EVF profile in one slide. This is what's in there. I can't find your table of contents, if you will. So next, Okay. So now this one is probably the the the slide with the Moe the highest danger of being contentious because I don't know what the answer is. Okay. So here's the question. k. So I mentioned there's this relationship to the BTF. So in the list from our deposits right now, there's 2 files. There'sbtf.rst, there's ill federalisty. k? And so if I look inside those, Delta RST contains things that are not really about BTF. It's just, you know, l profile So most of the stuff I've talked about just like what goes in the header and things like that is either not in there, but it's in my Internet draft version because if it hasn't been merged up or it's the type of stuff that I talked about before, unrelated to BTF. BTF dot RST has a bunch of BTF I'll take format stuff. That isn't specific to Elf. But then there's a section that's totaled lf file format interface. you have elf.rst, and you have elf file format interface and separate files. k? And so, currently, the Internet draft, my derivation, k? Takes whether this is right or wrong, I'm interested in feedback. k? But my document right now, the Internet draft version takes all of elf.rst, and it takes section 4 out of the b t f r s t. and it puts them in the same document because they both bought enough profile, at least that was my thinking. then it wraps it in some boilerplate, and then I've made some other changes to fill in gaps that weren't in either place. Okay? And so those things need to be upstream. So yeah. Gotta do that. And so here, the real question is know, the BTF that RST should be an opinion, the thing for which the proposed standard gets derived. Right? We haven't done an adoption call, but that's my opinion. is that Internet draft should be derived from btf@rst, you know, that should be the starting point."
  },
  {
    "startTime": "01:48:01",
    "text": "and that should batch that that proposed standard bullet. k? and then stuff that is coming out of, say, oh, that RST is what goes in the informational doc now you can go back and you can say, okay. Well, a section 4lf file format interface should be proposed standard or not? if you think it should be proposed standard, it should stay inbtf. JST. If you think that, no, that's really informational stuff, and it's about elf move over to into a different file. That's the one that I don't know what the right answer is, so I thought I'd ask here because I took Straumann. I said, well, let's pretend that I'm gonna move it and throw up an Internet draft and see what people say. Right? Keep them throw tomatoes at it or people can say, yeah. This is the right direction. I don't know. So that's my real question to say because, you know, I don't know what to do with this yet. I don't know what to do with the upstream stuff if I were to submit catches upstream what approach should I take? Should it move out of there? Because it's informational, should stay in there because it has to be proposed standard. And so later slides is actually about the content. This one is in a process and, you know, organization of stuff, which document does content go in. Right? but I'll cover the details of what's in here in later slides. Christoph Helwick again. So I think what you're doing is roughly the right thing, but I always do for difficult questions, I think we should take one step back and look at the broader issue. Right? And the the b p f definitions, Definitely shouldn't be in the same document with the l sections. They are customary embedded into with the current Linux tooling. So I suspect you're actually better off a splitting this, and b, probably, like, prioritizing the BTF document because whatever embeds it is probably gonna end on it, But the whole, like -- Yes. -- elf description thing Also kinda loops back into previous API discussion that will brought up because when people talk about, like like, the l format or the p's API, they're Poncher, Boncher,"
  },
  {
    "startTime": "01:50:03",
    "text": "thinks of different maturity that are getting mixed up and there's some things that are very, very stable and in that form, in IETF would be standards track like register calling connections -- Mhmm. -- like the section names for basic text, and data as an every normal computer program. And these are, like, completely stable, completely standard track by any means. And and that's kind of, like, like, the fundamental API. And then you have, like, random magic help e l f sections people are using to optimize some workloads or or do cute little tricks. And these are things like where do I put BTF info? Where do I put EVPf Maps And those really are conventions. Right? They're not really fundamental. I mean, if you change all tools in your loader, you could use anything for it, but it really helps if people agree on something. So the answer might be what you're doing is right, but not enough. Okay. That's that's strange. Yeah. So I even if there isn't okay. So I can I can talk about what I'm incentive to do as an implementer k? may be different from my IETF hacks. I have 2 hats here, right, as implementer on one side and as a the document IET participant editor and stuff on either side. And and I reserve the right to have 2 different opinions between the two hats, but right now I don't. Okay? that I think even informational document is helpful because I want multiple tools be able to that things to be able to use to consume. Right? because I care about both Linux and Windows in the runtime side. and I care about multiple compilers, you know, Clang and GCC, maybe a rust compiler in the future that would be great on their side. And I want them talk to each other with a common, you know, minimal set of interoperability stuff. Right? I want to have The same tools be usable on Windows, on Linux, and anything And so I'm incented to say that there should be some document there. Information is fine for that purpose. Right? because from an influencer,"
  },
  {
    "startTime": "01:52:03",
    "text": "I don't care whether it's proposed standard or information as long as it's well documented. I can implement then I can implement of it. Right? So that that that that that needs that. And as far as BTS dotrst, I'm sure hoping that somebody else will step up just like Will stepped up on the on the API 1 if somebody else steps up to be the editor of, like, BTF, I would love that. I wasn't volunteering to do that. On the Windows implementation hat aside here for just second since I'm one of the people in that project. That's not the only project that I'm on. But from that perspective, It already has a implementation of Ealth, but not BTF. The BTF 1 is actually in progress right now. Some part limited. Some parts are not yet. It's right right in the middle of And so that means that Windows need the alpha 1 first, and that's why I stepped up to do the elf document first. say that's what actually we were trying to implement off of. And now we're trying to do the BTF 1 well and not me personally, but other people are. And so I would love somebody else to be the editor of that one. But I agree with you on get this is in response to you, Kristoff, saying that BTF 1 is actually more urgent. short because, yes, that's true. The LF 1 has to normatively reference the BTF 1. So that part is That's why they're sequenced that way. Right? But you should be able to have an implementation of ELF that doesn't have to have BTF only because that's what we did. That's that's the desired state, but that's the sequence we already implemented Alright. Anyway, one thing I just wanna quickly chime in to say here. I think we we should be cognizant to say that it's probably unlikely that we're gonna have, I think anabi.rscdocandanlf.rscdoc. the the the the the the salient point is that we wanna have like, how do you make an instruction an informational document and how do you programs interoperable across platform, which applies to Alf. It applies to to BTF. It applies to ABI. Right? So I think like, I I expect this isn't gonna be the last thing. Like, when we talk about standardizing map types. Like, we're not gonna be talking about where to put them. Right? We're gonna be talking about"
  },
  {
    "startTime": "01:54:02",
    "text": "is an array map type, and that's a hash map type. So I think I expect that longer term, like, a there's gonna be a lot of content going into this, like, cross platform interoperability document, I think, because it kind of it's touching a lot of different parts of the ecosystem. Right? So you are are you a lot of stuff into the same RFC, combine I'm arguing that for things that that this all sounds to me like l dotrst and the stuff that Will was talking about, that sounds to me like in a it's an interoperability question. Right? My opinion is that having multi old documents for roughly orthogonal things that reference each other is easier in timeline because you don't have to hold the first one to the last one. And if you ever needed to obsolete something or file a rata, on a more granular basis that you can obsolete and replace one of them if you got something wrong without having to touch the other ones. So that's why I like having a division that roughly matches the set of dot rscfiles that try now. Yeah. But you're you're gonna have Sure. That's a possibility. It just seems odd that you would have, like, that one talks about ABI compatibility, and this one is health compatibility, and this one is mass compatibility. Right? Like, They all actually have the same the same goal but that just wanna point I just wanna point that out specifically because the the charter also has that is is yeah. The working group can say either what. Right? The then the charter doesn't constrain how many documents there You could take every single one of those and combine all eight of those bullets into a single RFC. I would not be think that would be the most efficient way to work as a working group. the worker can choose to do that, or it can take a single bullet and say we're gonna that one bullet and have 5 different documents, 3 different pieces of that one. up to us to decide. And so if the chairs have an opinion and you want us to do something, that's fine. So Alright. So I wanna get on to the technical stuff. But if you have guidance, feel free. So different -- Yeah. I mean, the the interesting point about Christophe? I don't know. Do you have a splitting and not splitting things, what also be is, like, are there use cases to use it stand alone without the rest. Right? And -- Yeah. Yeah. there were at least experimental EBPF implementations that were actually not"
  },
  {
    "startTime": "01:56:04",
    "text": "in the implementation using ALF, usually by stripping the ALF information out earlier, but whatever. So having BTF without Alf, conceptually, in terms of implementations totally makes And and and I learned you vice versa is also possible. And, yeah, there there's actually plenty of old stuff doesn't use BTF. I know Alexia really wants to get away from it because using BPS solves a lot of problems, but that doesn't magically make it appear in place think that's a good point of saying units of of is great. -- is great now. So I granularity of what's mandatory. So, like, you gotta implement an an ISA. And and that gets to my next point, which kinda reiterates what I said the last time I was speaking is I mean, even just elf isn't one thing. Right? I mean, there is, again, the the actual l format that a compiler generates an Enveloped loader that runs a program needs to understand, which is very basic and fundamental, and then we got all the magic sugar coating on top that, usually, the compiler doesn't know because it gets inserted by tools or or or stripped by tools before loading. And that that is to me pretty strong, but not necessarily required argument that these bits shouldn't send in the same document. k. yeah, I'm gonna come back to your point because I think I agree with you. Go ahead. next slide. So I'm gonna actually talk about some No. That's mostly not necessary question. the working group. It's information to the working group if you're relatively new to BTF or Bpf I'm just gonna teach you some things. And, hopefully, I get the information wrong because if something is wrong here, I'm sure somebody will correct me, but this is question of the work here. It's just statements of current practice that's out there. Right? if you say, what's the when I talk about naming convention, for I put a BPS program in a text section. What do I name this section? There is there is just at least 3 different conventions out there in different parts of the PPS Ecosystem. prior One convention, is that the section name is starts with something identifies"
  },
  {
    "startTime": "01:58:00",
    "text": "program type, then maybe a slash, and then some other discriminator after You can look at the section name. You can kinda guess and say, ah, this one is an XDP program or whatever. So that's one convention that's out there and used by some tools. Another convention is that the section name has to exactly be the program type. It has to be exactly, you know, XDP and that and nothing more and nothing less. k? some of the conventions out there. There's an arbitrary convention. Since you can put whatever you want there, type is completely orthogonal that. You don't look at this section name to get program types. That would be silly. Right? And so it depends on which tool that you look at as to which convention but these are the 3 popular conventions that's out there. So you can't assume there's a single convention either. But this at least documents what the 3 conventions are, right, so that you don't think that there's only one. k. Alright. Next. Data sections. So data sections, is typically where people put maps. k? There's 2 types of map sections. There's classic maps, meaning before BTF, and then there's the BTF version of maps. Okay. classic sections have a name, The name is either just plain maps are in some tools. It's map slash some map name, just like there's a program type slash stuff. So that's a 2 different conventions or whatever. And the contents for the classic ones are specified in the in in at least some version of it is specified in the document and says, well, there may be later versions of that stuff at the end kind of thing. And then there's BTF maps. It uses a dot maps section. the map section is the one that you kinda like to deprecate, but there's all kinds of usage k? And out there, so it's useful to document it for informational purposes even if it's deprecated. Right? because there's so much use out there. k? And BTF maps is the to do in the document right now in my in my because that's where there were some gaps that weren't really specified at some place that need to be filled in. And that's the part that would certainly be a normative reference over the BTF document is what we're just talking about. And I this is even the text that I pulled out of the BTF document has some gaps that's in there, and that's why there's 2 dues. Right? So stuff wasn't specify meter document right now. It just needs it's it's true, but it's missing some details. Right? Joe, did you wanna ask a question? Yeah. Yeah. I I get"
  },
  {
    "startTime": "02:00:02",
    "text": "Hopefully, I'm coming through. I I was kind of curious about the interaction English and and kind of a a current understanding of the implementations that are out there today because I I I feel like there are multiple libraries attempting to converge on similar patterns, and that's, I guess, in the role of an informational RFC, we kind of say, well, you know, here are some things that people are doing that are common. And, I guess, I'm not quite sure the degree to which it's useful to sort of point out, hey. You can do arbitrary whatever you want. And, yeah, being sure, that's that's that's how we started. But I guess, how does that interact with this this sort of specification. Let's do it. So right now, it's an individual submissionist, directions, explains, so I could do whatever I wanted individual summation. And so my my opinion in what I started was to say, The job of an informational document is to explain what already exists. Right? To not necessarily invent new stuff and to say, factually, here's what people are already doing. And so if I saw 3 things were popular out there, I would write them all down. least having them written down is better than not having them written down. And so if I saw as long as they're popular, right, somebody is, you know, grad school project don't care. Right? But if there is, you know, LibbyPF does something, then that should here. And if somebody else, it's a major part of the ecosystem. You know, Cuseum or whatever does something that's different begin here just because it's such a a popular thing and just state that this is a statement of fact. And so there are major parts ecosystem that use each of these conventions. Just like Mets, you look at various, you know, dot old files that are out there in various repositories deployments and stuff. You'll see 3 different types of them. You'll see ones that use maps One's that use map slash stuff and ones that use dot maps. And we hope that the first two are on the downtrend, and the third one is on the uptrend. Right? it'll take a while for that takeover as everybody upgrades the latest, you know, Linux kernels and things. Windows started by supporting just plain maps. And now it supports all 3, depending on which version you look at, the dot map section was just recently added, but like"
  },
  {
    "startTime": "02:02:00",
    "text": "a year ago, it was just playing maps, just the first of these 3. Right? This is as we started doing more and more stuff. And so, hopefully, we want all these to be cross platform someday, and the first two to eventually be deprecated. So the we understand. Do you wanna take, like, a quick minute to summarize and do a call for action? Right of time, oh, that's cool. review the document. Yeah. Go ahead. That's it. That's it. Yeah. Yeah. Alright. So I would love to not have it be an individual submission, either it's adopted or abandoned And if there's other people wanna become co editors or whatever, that would be awesome. And so I'm just looking for input because I've not updated it between last IITF and this IITF are then maybe regenerating the Internet draft. If I did that, I'm not sure I'd buy updated references, There's no time no textual changes since last I get. So it's out of date now. So I think they've read, like, what the request discussion is, like, one document, many document thing requires some, like, cooking off. Like so I think let's do it on the list and try to, like, get it done. one would be informational on that for post standards. Right. And and I don't think we need to wait for the next meeting. So let's try to get it done before like, how it goes. So and and, Christophe, so thank you for your points. And Dave as well, so, like, you know, Let's go on the list and get this done. Thank you very much, everybody, and thanks for making it an awesome my first meeting. and no nobody got, like, you know, hit with stones or tomatoes or everything. So that's a good start. you very much, and have a nice day. Thanks a lot, Matt. Thanks, sir. plus food."
  }
]
