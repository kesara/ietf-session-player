[
  {
    "startTime": "00:00:24",
    "text": "okay with luck that's confirmation uh that you're in the right place okay I've gone and pasted the agenda into the notes page um would anyone like to volunteer to try to take notes there since I've not been doing very well in some of the recent meetings oh Ariana's foreign"
  },
  {
    "startTime": "00:02:29",
    "text": "all right let me see if I can make this work okay this is an ietf meeting this is the note well slide you're expected it to be familiar with it because uh it applies to your participation in this meeting all right um and let me go a few more few more clicks which I guess is proof my coffee's working this morning um this is the agenda um so right now you're here uh in item zero quick intro and uh time to bet time to batch the agenda uh under item one process oriented topics we're gonna have some slides on uh the tsn's queuing and scheduling mechanisms the goal is not to get through all of them but to discuss one or two of them in depth uh about the same way that we discussed uh uh CQ uh cqf in depth at"
  },
  {
    "startTime": "00:04:04",
    "text": "the last meeting both to understand so what mechanism is and equally importantly to uh in essence uh debug the requirements draft so we understand what it means for a mechanism to meet or or not meet uh the very sections of the requirements draft uh after that um Antoine is going to do a presentation on uh bounded uh on uh bound uh on his bound delay Q draft any comments anyone want to bash the agenda sure let's go ahead just to to repeat what uh if you haven't folks here haven't read the mailing list I've tried to see how we can capture um you know the the work of these meetings on on the wiki a little bit better so let me know if that's useful but what else we can do and uh um and and add other mechanisms that you think are should be in the list um and uh then also we we merge the two um cqf derived mechanisms that we've been presenting that um and and uh yeah sorry I sent that to the mailing list thanks okay great and uh we know from discussion in a past meeting uh the csqf uses the same mechanism in the data plane the same uh sched scheduling queuing mechanism on the Node but has a has a different control mechanism and passes different information uh uh between the notes but I don't know don't know yet what we ought to do about drafts to recognize"
  },
  {
    "startTime": "00:06:00",
    "text": "that yeah um I I don't know yet what what what the authors there um would like to do but I certainly would love to um try to propose some um com comparison um to to I think add further explanation about the pro and cons of either approach I think that's a good sentiment and like you I'm not sure I'm not sure exactly exact exactly what to do um okay um any other comments or should we go ahead and dive into one of the TSN mechanisms and see what happens okay hang on here uh okay um xiaofu you're gonna lead to a discussion on this oh hang on a minute I need to I need to negotiate with uh meet Echo just a minute here oh I can barely hear you thank you uh um all right hang on a minute uh xiaofu I can barely hear you can anybody anybody else hear xiaofu well all right I think you're gonna have to yell at us um all right um let's see"
  },
  {
    "startTime": "00:08:03",
    "text": "um you want to go ahead uh please go to the next page okay um and you're coming through much better now uh you're very hard to hear earlier something something just improved please keep doing that um let's see all right so uh maybe we can go to debug the knee to the TSC evaluation page so which okay this one okay this this one yeah uh uh so uh this is evaluation uh according to the requirement of uh so let me um [Music] uh uh begin from the first aid so for the item total with the time a singularly the human AC is low I'd be called that the world Terminals and the network devices needed to achieve nanoseconduct clock synchronization across the network to ensure that the GCL time of all outgoing posts is the single land singular Network for this item uh I'm not sure if anyone has some more comments uh I think this setting is obvious so I"
  },
  {
    "startTime": "00:10:02",
    "text": "will go to the next item for the item support large single propagation latency is yes because the the link delay is nationally considered during this calculation that is to determine the Tas transmission data window position under GCL is independently is stored on each node um okay if there is a low any comments that I will go to Let's quickly um they sound like easy easy calls any comments or disagreement with uh 3.1 or 3.2 okay Carry On okay if the data load any comments about these two items for the next slide and accommodate the the higher link speed uh the generation is the password uh uh more plus size timer control uh that means smaller time agent of G cell which is required that may you can see the the capacity of the device um some uh more detail of the disciplinations"
  },
  {
    "startTime": "00:12:00",
    "text": "that the the GCL operation is based on the uh flows so uh so for a specific a specific cycle of the G cello they may contain uh too much items due to the higher linger speed under the time interval is smaller so it can contain too much items is there any comments for this item your harness go ahead okay yes hello um very generic question to the presenter when you say um time aware shaper or refer to actually added 2.1 qbv um it sounds like you refer to a particular use of IEEE added to Define qbd so which is the enhancements of scheduled traffic uh because she said generous outfellow and so on but the enhancements for scheduled traffic provides you some form of programmable machine so it can be used in one or another way for example you can even with some other extensions create a cqf-like behavior with this enhancements or scheduled traffic so um do you refer to a classic tdma use of the enhancement for scheduled traffic in your evaluation here or it sounds a bit"
  },
  {
    "startTime": "00:14:00",
    "text": "to me like that or do you have some other communication scheme in mind uh so if I could you Collision clearly uh uh so the the this slide of TSC you want to see it's based on the classical one could be way uh is not contained only enhancement sorry can you repeat the last part uh so this UI AC is based on the classical TS mechanism which it does not contain any enhancement such as a single or Cisco I think it's just understood that you're using Tas or 802.1 qbv which is the project name of p802.1 qbv it's enhancements for scheduled traffic um so standard does not contain cas and it can be used in various ways but for example um in 3.7 you say delay Jitter is Alpha low and it really depends on how you use the gate control lists and my question is therefore do you assume 802.1 qbv is used in a Time division multiplexing I believe he already said yes to that question oh okay I didn't hear this yeah I'm pretty sure he said yes to that question and beyond that"
  },
  {
    "startTime": "00:16:01",
    "text": "um there's a separate uh we had a separate discretion of the prior meeting uh about cqf so if Tas were used to implement cqf um uh I would I would suggest referring to uh evaluation of cqf yeah but something I simply try to understand so if the answer is yes and I'm gonna send this slide here better thank you yeah the answer is yes curls just for for completeness are there any other you know relevant profiles of Tas between tdma and cqf that we should take a look at Uranus um I'm not aware I thought the question was yeah the reference is just a quick way call us was a question to me [Music] let's let's say it's also a question Johannes go ahead okay um uh not not in a standardized way though this classic tdma is I think it's like well it's not really normatively standardized the cqf is an informative Annex as well so people may use it differently but nothing I know from my memory from the article added to the Huang Q standard okay so it sounds like pdma and cqf are the only interesting uses of this if somebody has another one I will provide my standing answer for that send draft thank you keep going okay something so for the next item uh"
  },
  {
    "startTime": "00:18:03",
    "text": "be scalable to the large number of floats uh the humanization is depression um calculation for workflows and the control plane is uh can be hard problem may contain too many items due to too many floats uh it come between super traffic class and that's not the disability of flow until in traffic class basic case is there any comments okay for this is the calculation is complex the question actually I have a question there but my question is to uh to Ping On the requirements draft um and I'm going to apologize because I may I I probably should know this I don't paying how does the requirements draft treat individual flow scheduling versus traffic class scheduling well so I think there's no text to distinguish traffic and flows nothing in in the current version of the text I'm sorry you need to say that again you're very quiet well I mean in the current version of the text there is no result or no"
  },
  {
    "startTime": "00:20:00",
    "text": "discussion about how to distinguish the traffic and the flows all right it sounds like that might be something that would be useful to add because if I understand what xiaofu has written uh he said that Tas will not scale to a large number of flows because the control plane problem is very bad but Tas per traffic class will scale to large number of flows by virtue of traffic classes and I guess we need something in the requirements draft to talk about uh use of traffic classes versus individual flows does that make sense um yes but I have a question or concerned about to evaluate TS because in my mind as I know I don't see any extension to TS to use in a large scale Network if I'm not wrong I think in most people's mind they think it can't be used in the last skill Network so and there's no just trial or um more work on that so we can just give them inference I think I don't think there's a problem there I mean for example uh there are two clear nodes in the evaluation column which suggests the Tas and large-scale network is not going to work however one of the purposes of this exercise is to better understand the requirements draft and that's why that's why I'm raising this here because uh I would not be at all surprised to see traffic class versus individual"
  },
  {
    "startTime": "00:22:02",
    "text": "flows turn up in the evaluation of some of the new mechanisms that are appropriate for large-scale Networks well yeah yeah yes we can give some some exponential Nation but uh measure just to express my little concerns about it okay and and the concern is completely valid I um uh in in encouraging this evaluation exercise uh I'm not believing that any of the TSN mechanisms are going to be completely super large-scale networks but it does it does serve the purpose of understanding where the gaps are and where we where um some refinement requirements draft will help us work through the new mechanisms yeah I agree with that okay tourists that I'm a little bit surprised of of bringing in traffic classes so I'm I'm not quite sure that we've done that in the past or or as goals right I think I when I was talking for example about tcqf I was just saying that the scaling behavior that we achieve is similar to that what we have with with traffic classes but that was just meant as as a comparison form but not as as uh you know specifically saying that here there is a dead net idea for traffic classes which I don't think we have or do we oh uh told us I I don't understand the Canadian position but the food here is actually contained eight traffic class"
  },
  {
    "startTime": "00:24:01",
    "text": "for the top of the class it will also included uh the TS contain the gclo to assert the state of for uh the for for easy traffic class to assemble the traffic isn't that rather than um what what I would be calling what I think I've also seen in other papers being called priorities in in terms of that um an individual flow belongs also to a traffic class and then the behavior the the latency throughput or whatever it is four different traffic classes is uh given different uh parameters there so it's not independent of the per flow Behavior but it's an additional parameter of each flow well and more importantly if I understand yeah go ahead okay uh I think the policy to write the TS mechanism is actually uh operator based on eight of trump class and uh multiple flows consider a single two uh specific uh uh a publicist specific coup uh for example the flow one to a floating concealer uh the uh the the glue with a specific type of class but but the flu one and the flu return and why would the simulate at the different time so there arrive at the"
  },
  {
    "startTime": "00:26:32",
    "text": "I'm sorry go ahead okay I I don't know even my answer has uh answer the police question so I think where we are here is the requirements draft will need to say something about traffic classes and aggregation in particular if the GCL calculation were per traffic class instead of per flow that might produce better scaling I'd rather say that the calculator is actually per flow David uh the GCL is perfect class so the transmission gates are better traffic class okay but but isn't it true that um we uh uh okay so in the control plane we we need to capture um per flow um information and calculate per flow which which each flow given a traffic class and then in the forwarding plane we have like in you know the the derived"
  },
  {
    "startTime": "00:28:03",
    "text": "solution like uh cqf tcaf and so on we only have the um the different traffic classes okay Johannes go ahead yeah um thank you for your comment David what you said before this is my question I would see it and also a bit along the lines of house to be used here if you make bigger Windows to put in the traffic of our entire traffic class it's getting a bit relaxed here I've seen such use but I said not in the standard okay all right so I think the the evaluation is reasonable and I think we do need to say as this as mentioned earlier do you need to say something the requirements draft about um use of traffic classes and flow and and flow aggregation for scalability okay let's go ahead and move on to high utilization thank you okay for the item totally the heightened utilization the numeration is possible the time interval of g0 with dedicated the bundle Riders reserved for a TSM flow is inclusive so if Delta TSM flow doesn't understand the park is any comments"
  },
  {
    "startTime": "00:30:18",
    "text": "so if they are not any comments I will go to the next item uh for the item will win the flow fluctuation flow more disrupting service the illumination is low uh the recalculation of the GCL are more complicated and required to update the GCL frequently on water nodes that the flow passes through any comments so for the next for the next item uh be scalable to a large number of hooks with complex the topology the illumination is partial more complexity of G cell calculations due to MP hard problem that is related with hop count however under cone delay is negligible that means under two under delay mainly dependent on linger delay and at the same time the under under the legit is actually any comments"
  },
  {
    "startTime": "00:32:25",
    "text": "okay let's go on to uh the next one and see what will okay Chef we want to talk about the uh credit based shaper evaluation equipment okay if there's the the table to here I I I'm happy to be do it okay uh this is the color database ship uh the standard is referred to iea [Music] or 2.1 to a week for the first item only with the timer singularly yes uh because it does not rely on time signalization or fluency uh it is because it is really based Mobility for this item any comments okay for the next item support the large single hobo propagation letters is also yes"
  },
  {
    "startTime": "00:34:02",
    "text": "CBS [Music] okay for the next one accommodate the higher linger speed the information is also yes uh more perfect place is required to serve more service capacity accordingly uh it's almost impossible to quote parts of the storm by a single interfering fluid because uh speed is high so in this case it may not necessary to uh to be combined with ATS any comments for this site so for for the next one uh be scalable to the large number of flows partial the shaping of CPS is based on several traffic class for aggregated fluids you may need receiving ATS to avoid opacity needs considered for each class uh this can be found in the paper as it is indicated yes and our traffic class discussion that we we had on Tas also applies here"
  },
  {
    "startTime": "00:36:01",
    "text": "we'll need the requirements draft will be updated to address that topic okay well the next item totally with the higher utilization the illumination is yes uh it is still the pre-configuration of bundle riders for easy topical class uh the best effort flows can use the unusual portion of the result of tears and fluids any comments for this side your harness go ahead once to the item three four more than one and three four sub item two um just for my clarity three four sub item two when you say pre-configuration of bandwidth limits do you mean setting and administrative idle slope value is the Associated Credit Miss shaper yes okay thank you and the second question on three four one this um I don't know the well I don't I can't remember if it's a title but the contribution there referred to an item or in the bottom"
  },
  {
    "startTime": "00:38:03",
    "text": "line number one license is this the contribution or the the paper where CBS and ATS is combined in a single port so they are serial the first APS shaping followed by CBS shaping yes it is a paper to discuss uh to combine the ETFs and the CBS to work together a way that the positive means are considered for the the specific class yeah okay if it's just just to give you a hint if it's the paper where CBS and ATS are entertained for the same traffic class in the same Bridgeport or end station port this is nothing that is specified by electrically 802.1 Q this combination so this mechanism is not standardized this combination so just a reminder useful to yeah uh I I think the combination of eight years and CBS is useful for some scenaries uh because the positiveness because the problem is actually uh existed as the alpha C nicely to Tino has also discussed this combination to avoid this issue"
  },
  {
    "startTime": "00:40:12",
    "text": "if it helps there's no requirement that what we discuss here have been have been standardized I think what xiaofu here has done by pointing out that there's an interesting combination that improves CBS is just fine comfortable yeah okay I will go ahead uh for the next item uh okay uh I have done so for the next item will win the flow flood creation floorboard is blockchain so it's the information is yes uh each service flow of a Class A or Class B is a permitted based on the bundled silver issue under the total amount of bandwider civilization that's more that you can see that the three configuration simulator and mode exceed the worst latency so the resource distribution is based on the traditional bandwidth distribution any comments it sounds like the bandwidth reservation has to be based on worst case burst behavior for all flows occurring simultaneously is that correct"
  },
  {
    "startTime": "00:42:00",
    "text": "yes yes so cbse the reader base the mechanism so the the worst latency may be over estimated mm-hmm okay okay for the next item be scalable to a large number of hopes with computers the illumination is possible I need to know the the current delay is overestimated basically inversely proportional to the idle slope due to now work concerned Behavior that's the under delay is large this means the worst and the delay is not any comments not hearing and it sounds like you've done it you've done a good job here here thank you I want to go insert a process question here so for everybody who is proposing a new queuing and scheduling mechanism you've now seen evaluation walkthroughs of three existing mechanisms do you believe you've seen enough in those walkthroughs so that you could prepare a chart like this for your new proposal you know"
  },
  {
    "startTime": "00:44:06",
    "text": "anyway to to make it more clear the the uh each item of the table should be the same as this one or the previous one prepared by ejo or we we can list them the the item we think is very crucial to evaluate I think I'd want to see a chart like this for each each proposed mechanism and then I don't think there'd be a problem with with another chart pointing out um interest interesting and uh interesting characteristics of uh of of The Proposal that aren't captured here would that be okay oh it's okay for me it means that we can take this chatter as a beginning and we can end something we think it's more interesting interesting for some specific mechanisms if we like right yes although I would ask that that the that that that the more interesting aspects be limited to to us to a single slide because we're going to have to do compare and contrast among the new mechanisms to figure out um what saw which ones uh solve which problems and what to take forward yeah okay on this dude okay thank you shushong um Perlis or is you what do you want to comment on uh uh cqf or sorry tcqf sure let's go ahead"
  },
  {
    "startTime": "00:46:04",
    "text": "the mic button is always your friend not um no no I think um at most I'm struggling with whether these these this this list is um that we have in the requirements draft complete enough to to to do um a useful comparison so I think this the CBS one is particularly interesting and I have to sit a little bit longer on it to um see what what may be missing in terms of what the um you know new proposals that we have overall are improving on this um on but certainly I think it must be possible to to to start with this okay sounds good and if you if you if you um see something that ought to be improved requirements draft please please please send note to the list I'm sure ping is very interested but you do know that I had um proposed on at last um ITF meeting um a draft which had a more detailed list of evaluation criteria here right without making that um be necessarily each of these criteria be a requirement and I think that that's in an easier starting point than to coming up to these evaluation judgments that's that's I think what I'm a little bit struggling with let's see I need to choose words careful here I'm looking to make progress with some initial evaluation that is tractable and comprehensible across a variety of mechanisms we're going going to be looking at so at the moment I I think let's see put another way I greatly appreciate the depth of"
  },
  {
    "startTime": "00:48:02",
    "text": "the draft you wrote to our list but at this point I want to make sure that we've encompassed the breadth of the proposals uh perhaps before diving into that depth okay pen go ahead some points here uh one question that if we only use CBS uh can it guaranteed latency for example if we see the result of the chat with some of the evaluations results were yes and some of them were partial so uh it will give uh impression that it may be used into the SQL Network but it may has its own problems such as latency guarantee and also some efficiency issues I think um that's one of the point and the second one is that I recognize the requirements 3.4 it tolerates High utilization um it's a relatively relatively new points that is added into the text and I think in this slides the notes I mean the evaluation method is a little different from the previous for the for the TS and I I need to explain that for this"
  },
  {
    "startTime": "00:50:03",
    "text": "point it means if there is no more bandwidth can be used into uh for the and then that flows um how it can what more work can be done to uh to schedule a schedule uh the the um the capability and um now I think maybe there's a little problem for the requirement to draft for this point so oh it's led to the results that for example for for this one it says to set the pre-configuration of bandwidth damn it and and please go go to the previous slides so which side do you want to go to um the for the TS here we go yes um and for this point it's uh it says if the thing as flow doesn't send packages depend with his waste so um so so I mean the a different to evaluate for this point but maybe that point has its own problem and not so some major uh in uh at this stage and I will uh think more about this point for this requirement okay yeah so just two parts one for the um CBS itself and the second one is for the requirement 0.4"
  },
  {
    "startTime": "00:52:04",
    "text": "uh okay I I try to answer the second question first uh for the opponent with the high utilization for this item a single uh word of us a key is for CDs uh is similar and it says that if you [Music] I think for Tears is about but for CBS because so the evaluation result for this tool mechanisms are different okay um okay sorry I I I understand what do you mean you use the same evaluation method but I really don't get two requirements of this one but I don't mean their quantities is cracked now you mean that the to reach a high utilization of the bandwidth right but now in the text it it says if the for example more than 17 17 percent or just up to 100 and how to how to how to uh uh treat more flows of it"
  },
  {
    "startTime": "00:54:02",
    "text": "yes but we can we can just leave this point for for the next I think one of the concerns here is that uh uh Jesus discussion of dead time in cqf would uh detract from meeting this requirement I think that would be an example yes I know that I write the right in the profile text but um character comes in that um if it's fired to other methods for example artistic solves the problem of SQL so we we propose the requirements but uh I'm not sure if others proposed matter because they may don't have the original matter for uh okay um if we use the TC graph and it reached the 100 percent of the bandwidth and how to further um how to further optimize itself was there a question in there um I'm not so clear about this point on me the new proposed the requirement is correct uh of our two others because magnesiums and we think we can we can take more time to really discuss about"
  },
  {
    "startTime": "00:56:00",
    "text": "it with a Co-operative yeah yes absolutely yeah okay I'm sorry okay perhaps take a discussion to the list Turtles with respect to the requirements looking here at CBS I think the one big thing we're missing is a requirement about um Jitter that is lower than you know the uh maximum latency minus the um physical link propagation latency so because I think that's that's the the key differentiation of course between the current asynchronous mechanisms like CBS and the um most infamous mechanisms which is most of the others um so I think that's that's something we need to add in the requirements and the evaluations um and then going back to the evaluation overall here I think the problem that that we have with this which is I think an excellent you know understanding from or you know that's very good that these evaluations were done here on this basis that CBS and tests are by themselves I think not not really mechanisms in in the way I think I would have imagined um mechanisms but rather the building blocks right so in terms of um tasks being building blocks that can be used for tdma or uh for cqf and CBS being building blocks for and I think that's the question what what what are the profiles of that other than APS right it seems that the evaluation here seems to imply that you can leave out on the Hops or on the flows where you don't need it any of the ATS complexity of reshaping but I'm not sure if that's"
  },
  {
    "startTime": "00:58:00",
    "text": "really a feasible deployment model or rather just a theoretical option okay let me let me try to rephrase that into an explicit question are there any known deployment profiles of CBS other than ATS in terms of the you know configured hop by hop behavior on actual Networks in CBS is used in the audio without bridging so I'm not sure I understood the question in relation sent to it yeah so there are ABB has been deployed and CBS is used out on the field okay then we have two profiles so to speak of right ABB profile and ATS profile sorry go ahead so repeat oh yes ATS is not a profile off yes my understanding what a profile is if you put it side by side with advb it's definitely not a problem it's not a profile of CBS yeah there's a separate slide in ATS that I've avoided going to uh uh mostly for time management reasons and also because I thought that after we got through three of these examples we could have a discussion about whether we have an evaluation framework um that can be used for the new for uh"
  },
  {
    "startTime": "01:00:00",
    "text": "for the new proposals so there's a separate slide on ATS that that shelf who did prepare but then to be fair should we remove the option um of mentioning ATS here in in three four one and simply say no there um so that uh you know we don't mix up uh things when they really aren't meant to be you know at least even a profile right so three for one change that to no and remove the ATS option there and just capture what ATS can do on for ATS separately then I'm not sure changes to no but it but um it might reduce the scope might reduce the scope of partial yeah because because if you if you remove the reshaping you're effectively imposing some limits on the behavior of the aggregate which in turn propagate back to the flows that have been aggregated I don't think it changes to know but it might is yeah and I think it'd also impact 3-7 right if we remove any any shaping um then three seven will also be even more difficult but in any in any case how however we adopt the evaluation right as Johanna said if if ATS is a separate spec and the reshaping of ATS is really you know not within the scope of CBS proper then we should assume CBS evaluation without it I haven't heard from you about whether"
  },
  {
    "startTime": "01:02:01",
    "text": "you think we have an evaluation framework that you can use for your proposal any comments go ahead yeah I can prepare such as light with regarding with regard to the z-score actually I'm preparing a separate draft for z-score for the presentation of the July meeting and I will also prepare such a evaluation slide in that July meeting I think yeah and you think I think that's good um ping what is a reasonable time frame for updating the requirements draft so that all of the slides on the new proposals are prepared against the new against the new version of the requirements draft but um I guess it has some update and not really so much I think and okay one of the reasons for asking is we have four weeks into our next meeting because the two weeks from now slot was taken out by U.S holiday and so there should be time there to both update requirements draft and leave enough time for the folks working on the new mechanisms to prepare this sort of evaluation of each of their mechanisms based on the new requirements draft thank you um yeah so sorry uh what about the question okay so so the question is when do you think a new version of the requirements draft could be posted that would be suitable for doing this sort of"
  },
  {
    "startTime": "01:04:01",
    "text": "evaluation of the new mechanisms I'm sorry I'm not being clear this morning I need more coffee um I think um based on the current discussion maybe one or one to two week within one two two weeks we can solve the current problem I think okay let's make sure yeah I'm sorry go ahead uh uh so paypoints uh we I wish that um uh every quarter of this draft can really review it and get the consensus that we can it's really stable now yeah okay let's target uh about two weeks uh I'm thinking of July 5th which is the Wednesday in about two weeks it's after the just after the US holiday weekend and if we can get it done before then so much the better okay sure thank you okay Chef we're going to skip uh I'm sorry go ahead okay um I just found the uh do you think if we wanted to add a new requirement to discuss the the the high the high speed technique that the higher speed the uh yin to work with the low the lower link speed because the real network is from access application and plugable Network the link speed is different"
  },
  {
    "startTime": "01:06:08",
    "text": "uh sorry I I don't understand why we talk about lowering speed and lower than what um okay versus the higher input speed is compared to a not a local network I think uh because the traffic engineer passed the underground the the possible the access and the work that are located in the network and the bug bone Network uh I in this networks the link speed are different so the proposal mechanism should support the the end to work between the higher linger speed under the low ending speed well uh yes I get your points um the first first of all when we propose this requirement we just compare uh maybe a local network to a backbone like scale Network so if from uh it has become higher link and in fact you say when we consider about the end to end link uh the Spade links paid different um one of the matters I think we can change the name for example accommodate different links with but it will be a little have some relation to 3.8 I think"
  },
  {
    "startTime": "01:08:01",
    "text": "um or maybe you can [Music] you can provide some some text briefly to dumb trade okay yes and maybe one or two paragraphs and we we can see how to merge it into the text or if a weather it needs to be emerged into okay okay and I'll note a comment from Antoine in chat that he thinks this this mechanism is reasonable any any final comments before we switch over to Antoine's presentation okay Giannis can you share Antoine's presentation because I it should be pre-loaded I unfortunately have to leave at the bottom of the hour so Giannis is going to uh take things from here okay can you hear me when yeah yeah I can hear you Giannis uh uh can uh can you share uh the slides um uh via VIA meet Echo"
  },
  {
    "startTime": "01:10:00",
    "text": "oh otherwise I can share my own trainings yeah how yeah how about how about you share your own your own screen Antoine because yeah rely on me to do it's all going to vanish okay thank you sorry about that no problem no problem I apologize on behalf of my day job getting in the way no no problem we all have a day jobs that gets in the way somehow Okay so I will share my entire screen you get to see okay great uh uh can you see the slides properly foreign okay um so um I'm very grateful of uh the working group to give me the opportunity to present a draft that we published a few weeks ago this draft is entitled and Crossing end-to-end delay bounds they are queue resizing uh this is a joint work with my colleagues and Sebastian polos are listed in the draft and uh I will take the opportunity of the presentation today to present you uh this this draft I will use a very original agenda as I will follow the structure of the document so you know where we stand at three given points in the presentation uh with no further Ado I will go to the introduction so um uh I guess uh people in the ihcf that"
  },
  {
    "startTime": "01:12:03",
    "text": "networking group are already aware that there are some use cases for uh deterministic networking and uh for bounded uh latency over large scale networks because otherwise you would not have the discussion we had today uh one of the use cases that we see in the consumer market for bounded delay without the digital constraint is online gaming in fact in online gaming in multiplayer massively multiplayer games uh the developer of the multiplayer platform is interested in having a solution which enforces uh deadlines for actions that players that peers do and they don't really care about the Jitter as soon as uh the deadline for actions is met because the the the duration of some actions that the Avatar of the players perform in the video game come to come update the smooth and smooth the Jitter that comes from a variation in the delay for incoming packets so uh if we look at uh this the chart that is shown on the right uh uh that is taken from 3gppts 23 501 we are targeting use cases that are locating located at the top of the table those use cases uh a specific packet delay budget but they can accommodate some burst so Jitter as soon as it's controlled"
  },
  {
    "startTime": "01:14:02",
    "text": "over a default every window and with differentiate those use case from typical industrial TSN or deterministic networking use cases for instance discrete automation intelligent transport system or high voltage electric distribution which are located at the very bottom of the chart so um the thing that you need to take from this introduction is that with the cousin I'm going to present to you today we are only looking at enforcing latency bound over network but we are not interested in maintaining uh jitterbahn so uh this is a main draft ID we cover this gap between TSN or determatic IP Technologies which are used to enforce those latency and Jitter guarantees at a cost sometimes centralized management and it was synchronization in small scale Network complex screen management uh complex traffic shaping mechanisms and more traditional quality of service enforcement mechanisms that enforce latency properties on average for instance with active fuel management you can variety you in order to meet some delay Targets on average but not in absolute so we are in between those two families of solutions so in the rest of the presentation I'm going to present a draft in three parts first I will present you how we designed a dynamic Q capacity adaptation mechanism then I will present you a signaling method that is heavily inspired by a RSVP that we use was that the source and destination can use to reserve capacity and and force"
  },
  {
    "startTime": "01:16:03",
    "text": "end-to-end delay for some flows and this is done by reserving capacity in specific using the node and then I will present you how we adapted the RSVP to the signaling mechanism that we propose earlier okay so bounding a at the switches so first I need to show you what are the rationals behind our ID to to perform end to end delay enforced and to any delay bounds by acting on the Q depths in fact this is from Network calculus we know that if cues are served as first in first out and uh and the buffer as a capacity that is given by pe to the k the delay can be expressed as t0 plus the capacity overall the committed information rate so what this formula gives is that given a capacity for the queue you can express the maximum delay that the packet will experience in the queue as an affine function of the capacity if if we have a fixed committed information rate so this is a substrate only so in the following if we take the committed information rate as a static value and we adapted buffer capacity by changing the buffer capacity we can act on the worst you delay so for instance here if we increase the capacity of the queue there must be capacity delay is increased if we decrease the if you want to decrease the delay we have a decrease in the buffer capacity"
  },
  {
    "startTime": "01:18:00",
    "text": "so we took from this idea and looked at the python architecture for switches and if you look in the base architecture and you look at the packet forwarding engine you can you can abstract the packet programming engine as a set of cues that can be of variable capacity that are served by scheduler and the scheduler can adopt a set of this of disciplines for serving the different cues one of those disciplines is a deterministic from grabbing meaning that each fuse is served for a specific period of time uh over over a period so if we if we combine those viable buffer capacities and uh uh and random database from Adobe to schedule a discipline then we can have Express the maximum surgeon time of packets in use as a formula that is given at the bottom of the slides here so the maximum delay is constant t 0 plus um plus uh Factor here that depends on the capacity of the queue so now that we presented how adapting the before capacity can help enforcing the delay we we need to put this mechanism in place into a system in which the queue sizes are not static in understating and set at the at the startup of the network equipment but that are on the Fly depending on the"
  },
  {
    "startTime": "01:20:02",
    "text": "demand for reservation of capacity on the switches for flows for which we want to enforce a hand-to-end uh delay constraints so we start from a system in which the queues have a variable capacity and those skews have two thresh two occupancy thresholds nearly full occupancy threshold for instance when 80 of the queue is occupied and a minimal occurrence is threshold for instance when 20 percent of the Q that then we operate a system like this in each equipment you have a set of queues those queues are occupied by um and by and in this queue we have some reservations for capacity to serve flows for which the node is committed to respect a maximum delay at the node whenever a requests foreign capacity allocation arrive at the node either the risk capacity in a queue that and the node can respect a delay contract that is compatible with the end-to-end delay reservation that is requested so that's fine we just place a temporary reservation and we are good to go but if we are in two permanent cases we look at the thresholds uh first the first programming cases is that we can't serve the reservation for a flow because um the the delay that is requested to that the flow needs respect is too low then we look at the various cues in the"
  },
  {
    "startTime": "01:22:01",
    "text": "equipment and if one of the Q Falls below the minimal compensation threshold we say whether we can reduce the capacity of the skew to meet the delay constraint of the reservation and then we allocate the the reservation to this queue for which we have shrinked the capacity on the other hand if a reservation for a flow cannot be accepted because too much capacity is requested then we look at the queues for which the maximum the nearly full occupancy threshold is um this past and we see whether the we can increase the capacity of the queue while respecting the minimal uh delay contract for the reservations that are already allocated in YouTube so I made the schema to to present those mechanisms so this is the adaptation of the queue to meet the delay constraint so here we see that this queue is occupied below the minimal occupancy threshold we see a demand arriving here for end-to-end delay that is 40 milliseconds the qcon serves end-to-end delay for 50 milliseconds and there's been more contractors to 50 milliseconds we are going to reduce the capacity in order to meet the maximum end-to-end delay for the queue and accommodate the um your reservation that is requested on the other hand if now we have a q that is nearly freely occupied uh by a set of reservation and see your demand arriving for capacity that exceeds the"
  },
  {
    "startTime": "01:24:00",
    "text": "capacity of the cube we look at the minimal contract for ongoing reservation in the queue here we compare it with the maximum end-to-end delay for instance here there is a difference by 10 millisecond we can increase the capacity of the queue while meeting the minimum contract and push and accommodate the reservation that we received okay so um this curing adaptation system is in maybe very simple it's far less complex and queuing systems that are involved in that are used in IEEE TSM initiatives but uh the the advantage is that they can be used in more simple devices and don't require any synchronization so now that we are able to adapt a buffer capacity in the different equipments we need a signaling mechanism to Signal the requirement for N20 the reservation for capacity to serve flow with an end-to-end delay constraint so I will present the three name mechanism we put in place by taking as an example the network that is presented here so we imagine that node a wants to use a reservation protocol to send a reservation resource reservation request to node f for a flow for which the maximum end-to-end delay requirement is 85 milliseconds and the maximum capacity including the burst of the flow is 2 megabits per second so I'm going to present the signaling"
  },
  {
    "startTime": "01:26:01",
    "text": "mechanism I'm going to present the first from RSVP in two ways first we allows the exploration of multiple passengers with the option procedure to the best of our knowledge uh we tried harder to look whether a recipe um so there are some document defining the behavior or rgp and the multi-pass environment and we didn't find it I would be very happy if you have a pointer to such a document somewhere and uh in our mechanism we allow either the destination or the source to take the decision about the path to take for the reservation so compared to RSVP this is different because there are narrow sdp when you send a resource reservation message to destination the destination is on the decision only is responsible for acknowledging the reservation and confirming so um let's start so a shapes a request and sends it to app through its two ongoing nodes so A to B and a to c uh the message here has a set of parameters compared to the message format that I presented in the draft the message format that I present here is slightly reduced for the sake of PFT presentability so most information the most important information in this message are the maximum end-to-end delay 95 milliseconds the end-to-end delay commitment which is the contribution of um of nodes that that have been crossed by the message to the end-to-end delay"
  },
  {
    "startTime": "01:28:02",
    "text": "the capacity requirements which is 2 megabits per second and a record root Shield that we call the root of the nodes that have been crossed by the message then this message which is B and C here we see that um yeah for instance if I take the behavior of node B compared with the message that you see in the previous slide here B has allocated a temporary reservation it's in its qq1 for which the maximum delay is 20 millisecond and before relaying the request to its own outgoing interface to Which F which are B to D and B to E it does it has added the maximum delay of the queue for which it did a temporary reservation to the end-to-end delay commitment so we know that b takes 20 milliseconds out of the 85 millisecond maximum and 20 lay credit and it has added its identifier to the record root so now we know that those messages went through a and b and the and 20 millisecond delay is taken out of the 85 millisecond delay credit the same for C here so now we the message arrive at D and E here D only relays one message because uh here uh its maximum the maximum delay for execute q1 is 40 milliseconds and the difference between the maximum and twin delay of the"
  },
  {
    "startTime": "01:30:01",
    "text": "message from C to D is 35 milliseconds so there is no no way D can conserve this this reservation but other message can go through so they are related to F with the maximum and 20 delays delay then 20 commitment the capacity and now we have two alternatives so first uh we make it uh uh we make our protocol behave like a recipe it means that the destination is choosing the is acknowledging and fixing the password is reserved so out of the three message signaling request messages that have been received F chooses one message for instance the the message for which the difference between the end-to-end delay commitment and the maximum end-to-end delay is the largest and shapes a reply with the maximum end-to-end delay the end-to-end delay commitment it has received the capacity and the explicit route this message is relayed along the Route that is given in the reply message to A and after AO receives a message if the flow can be exchanged following this route with respect for the end-to-end delay commitment then another method would be to let the source choose the path that is going to be taken so this Behavior we ask F to reflect all the requests it has received with the reply stating the maximum intent delays end-to-end delay"
  },
  {
    "startTime": "01:32:00",
    "text": "commitment that's received and the route that is taken by the message then those messages flow to the source and the source can make its choice of the most appropriate reservation mechanism okay so um if you have seen this if you have followed this protocol uh you you know that uh the for the information that needs to be transported in those messages is very close to what needs to be transported in RSVP messages and um I agree with that but uh uh the the issue we had when designing the around the formatting of the information we needed in this protocol with RSVP is that if we want to stick to already existing RSVP objects the encoding of the information can be tedious requires some competition at the various nodes and is not really direct we looked um we looked after uh RSVP object that was suitable for deterministic networking we encountered a document draft frozen.netracy ptsn that expired a few months ago and we wonder whether it would be appropriate to have a more direct encoding of the information that we will use in our signaling protocol in future versions but for the current draft we try to stick to the RSVP formatting as it sounds today uh the other Oddities that we found with regards to the differences between RSVP and our signaling mechanism is that to the best of our knowledge there is no clear policy with regards to how a resverat is managed in a multi-pass situation"
  },
  {
    "startTime": "01:34:01",
    "text": "besides in RSVP destination decides about the reservation and whenever there is an error with a RSVP reservation a neural message is sent to the destination and sent back to the source so this is not a very quick failover mechanism so let's now look at the encoding of the request and reply messages in RSVP so if you look at our signaling mechanism the requests are mapped to RSVP pass messages and replies our map to LSB RSV messages in those messages some information are very straightforward to encode a reservation ID and through ID are carried by session.objects uh we found a limitation in the session that object about the the identification of flows because in RSVP the identification flows is based on five tuples so if you want to um to send uh IP traffic while respecting uh end-to-end delay bound that is not tied to a specific transport protocol this may be a problem with the identification of the flow uh the recall record root list that is carried in the request message can be presented as a root record object in RSVP the route list carried by the replies is completely translated as an explicit route object mapped to in the RSV message what is Less Direct in RSVP is the formatting of the maximum end-to-end delay constraint and the contribution of the various nodes to the maximum"
  },
  {
    "startTime": "01:36:00",
    "text": "end-to-end delay we found out that the best option we had was to convey the maximum delay but with a standard t-spec or a flow spec object depending on the message with a general can back at the spec parameter and the guaranteed service aspect parameter so I will show this message later and the delay commitment by the nodes is carried by an ad spec object including a set of default General parameters with a fragment carrying guaranteed service parameters so um I will present the formatting that we have for for the for those two parameters so first the maximum end-to-end delay so in the RSVP rfcs we found that there is an formula that is giving the end-to-end delay uh in a situation in which uh uh P which is the the peak data rate little r which is tuck and bucket rate and Big R which is the rate are equal so here the delay the maximum delay is given by S which is the slack term here Plus B the token bucket size divided by r so the end-to-end delay requirement can be given by RBP R and S and the capacity is given by the peak data rate P so we can use this token back at this spec and mounted service aspect parameters so here is the test taken here is your aspect to convey this information but it's not a direct read from the router"
  },
  {
    "startTime": "01:38:01",
    "text": "it needs to do some competition so it's we think it can be more simple in the aspect object the aspect object is a bit more complex you have far more parameters but the end-to-end delay commitment uh uh can be carried by setting the minimum path latency here as uh undetermined value specified by RC 2215 then we express the node contribution to the end-to-end delay commitment as something that is added to the detox and decent parameters so those parameters are so D here and the sum here while she thought and system parameters are set to zero so C Sam and C dot are set to zero uh we think that this uh this encoding is a bit complex uh but uh we as I mentioned earlier we tried to stick to the typical RSVP message encoding but if this message if this mechanism gets traction we feel that there would be a potential optimization with a thinner RSVP object carries information so um I hope that this presentation triggered your interest in this document I would be very interested in Reading from in hearing from your from you about your interest in this draft uh in the next steps uh I'm we are very very aware that there is ongoing work about the alignment of proposed end-to-end that net mechanism with requirement for"
  },
  {
    "startTime": "01:40:02",
    "text": "large-scale Nets in large scale networks so we are going to make the exercise that you that has been presented earlier to align uh to to tell how the mechanism we present in this draft can respect the requirements that are presented in the requirement plot around the follow-ups we are wondering whether there is interest in this document uh we think that uh one of the major aspects of this document is lies in the RSVP protocol mechanism that we use to accommodate with multi-pass situation or to allow both source and destination to take decision about the reservation uh maybe is it belong to this draft maybe the group thinks that there is a potential for separating those recipe protocol mechanism and making them in appear in a separate draft and also we think that there is an interest in having a cleaner rzp object to carry information about deterministic Network flows and we would be motivated to work in this Direction with the group so thanks a lot for your attention uh I don't know if we have a time remaining for questions but I would be very happy to get your feedback about the document either today during the meeting or afterwards directly by email as and you did or on the main list thank you thank you yes we have a queue so told us please go ahead a lot interesting presentation so maybe high level um I think the the whole RSVP and um"
  },
  {
    "startTime": "01:42:02",
    "text": "control plane aspects might be better brought up to the working group at large and not this team so unfortunately David our Master of Ceremonies for for this list for this set of of meetings is is gone but Janos May uh join in as well so I think we primarily want to focus on what happens in the forwarding plane and uh out that necessarily being tied to a specific version of the controller plane um and so um I had a hard time figuring out which type of changes in the forwarding plane you would want to do um let's say as opposed to RFC 2212 which would be the forwarding plane for guaranteed service which is what the iitf originally did in conjunction with RS SVP so but just let me add two more points because that that's what I would like to have an answer from but in general with what what you were talking about RSVP itself does not specify where um the RSVP messages are routed across in terms of multi-path of what the path is that is being that is supposed to be exactly the same path that the traffic would take so to do anything that you want to do um you first need to have a mechanism by which you can steer the traffic across different path and in in Native IP multi-path you can't do that explicitly right so if if you use IP multi-path it means that traffic for example for different ports to the same destination or to this different IP addresses to the same destination would go different paths so you need to rely on that the the explicit route object for example is from RSVP te so that doesn't work with IP so there is all type of I think"
  },
  {
    "startTime": "01:44:02",
    "text": "issues that that you would need to resolve going forward but you know steering the traffic to to get to different path with different bandwidth might be actually part of um a better solution for um doing the the death net forwarding plane but I think it's highly unlikely that we would want to do anything for steering other than what the ietf has already done for example these days segment routing with segment routing V6 or mpls so I think you may want to tack onto that thanks yeah uh just a remark about about this this pretty pass aspect do you think that it would be physical it would be visible or even desirable to Route RSVP pass message over IP with segment protein and different segments for the exploration of various path please foreign or I mean or should be moving in the queue I'm sorry I'm I'm I'm I'm too old to still learn that um so I think in general the the problem I have with RSVP is that we already saw um you know more than 10 12 years ago or or longer that we have scaling issues with RSVP in the network which is why we went to segment routing as a way to not do RSVP signaling in networks so I'm I'm not sure that RSVP signaling um for individual flows would ever be a good fit for the large-scale net"
  },
  {
    "startTime": "01:46:00",
    "text": "deployments but that doesn't mean that it couldn't be a good solution for a smaller scale.net deployments okay so just to move on in the in the queue let's hear from Young comment station and regarding the task uh that the tasks that are supposed to be done by RSVP that has also can be done by let's say a sexualized uh controller anyway that's that's control and management plan but I do have one question or one clarification regarding uh packet forwarding it looks like to me that when when a node an intermediate node or every node in the network when when a node receives the packet then each node needs to identify to which flow this packet belongs and packet I I mean that the node needs to put the packet to the right queue for the flow is my understanding correct yes uh in fact this is what I mentioned when I presented the issue we have with the identification of the flow uh in the way a recipe does um in fact in in RSVP you can identify a flow by the typical five-stopper IP Source IP destination soft spots"
  },
  {
    "startTime": "01:48:00",
    "text": "destination port and protocol in RSVP if I remember well as I need to check there is a possibility to use um to use the flow level in in the IP header to help with this identification but if we use a slow level we need to make sure that over the path the full label is not tempered with so I think that if we if we want to identify a flow that is specific uh that is a metric flow and not a transport layer flow and we we need to stick to ipsource and IP destination and the user it has limitations but as I mentioned we wanted to stick to the format of our SVP to try whether it was possible and probe interest in having other mechanisms in the record group okay uh actually my question is not quite related to RSVP or any any other uh control plan protocol my question is about uh data plan Behavior anyway uh you need kind of per flow information yeah uh in the in the in the node right to identify yes yes right okay okay thank you yeah in fact in the reservations are identified by the by the flow ID that is carried by the message so we need to have this flow ID uh I don't give some how to map uh the flow to the proper queue and make sure that the resolution is almost consistent okay thank you thank you yeah I actually wanted to make some"
  },
  {
    "startTime": "01:50:00",
    "text": "comments to Dollars like pretty much all each point that uh RCP is not has issues you as he explained trends and so on and we have at the first place you should uh you should get the questions or some news of ISP for that not that large in the working group but it's it's more about data plane enhancements not controlling anyway I second the points made by Thomas I would say okay um point taken uh um I maybe if it's appropriate I can present specifically on this uh with a reservation protocol aspects in the wider.net group rather than in this specific uh word open open working group or focus on like the previous question focus on the data plane part of your proposal okay and and make it irrespective of what is used in the controller okay okay in its left so shuffle please go ahead we cannot hear you actually you have not turn on the mic foreign but could you somehow make it louder oh I'll try it again uh can you hear me yes yes no okay please go ahead"
  },
  {
    "startTime": "01:52:00",
    "text": "okay so uh sorry uh um so my question is that yes according to the discussion also uh this proposal is mainly and and uh controlling so uh the data plane mechanism uh I don't know if what are the the detail about the data mechanism if we it even dies and flow recipient this isn't my first consensus um okay yeah indeed I agree that the way things are presented things is really focused on the control pin aspects because of the signaling Etc on the data plane aspects uh uh the the goal we had in mind was to that uh the management the the ways the packets are managed at equipment uh can be very simple why we have something that is enforcing them to end delay requirements and uh because we see lots of quite complex work with regard to the query mechanism and the curing discipline this scheduling and they require sometimes coordination between nodes and we wanted to have something very simple on on those on those aspects but I I agree that for now the work that we presented this monster control painting so I I've taken your remark uh also jealous and tallest in the same direction so uh if in future versions of the document we may we will be more precise on data plane aspects"
  },
  {
    "startTime": "01:54:01",
    "text": "okay thank you uh so um so my second uh questions is that uh according to your slides that the uh the formula is actually simple uh yeah but I I still be confused that maybe we just change the buffer capacity is not enough good bounded latency uh because the the password said the the buffer capacity is a node uh just an attribute of the queue but but it's the the size of a wall aggregated flows that can be permit per permitted to release to the network uh studies on my second coincidence I think yeah uh indeed if you in if you look at the the way we managed you um in the that uh RCS you have a very you have a more detailed model for the competition of the contribution of every node to the end-to-end delay and you have a part that is related to the packets processing time by the equipment the time that it stay in the queue the time that the scheduler takes the packet and puts it out uh uh on the opening interface and the propagation time on the link between the departing node and the arriving node we tried to [Music] in in our model we have a constant factor that accounts for the processing time on the on the"
  },
  {
    "startTime": "01:56:00",
    "text": "on the Node and all the scheduler and that going interface time and we made it only depending on the buffer capacity because we are in a situation in which the queue is served in uh with a fifo discipline and with the scheduler of the very skills in the plant is following a deterministic and Robin policy so um if we use more complex scheduler for instance introducing priority or this kind of things and the queue can be a fifo with a preemption for some to place at the beginning of the Q some urgent packets we need to have a more complex model for the for the competition of the end to land delay depending on the buffer capacity but we are confident that we can still have a bound depending on the welfare capacity and this mechanism can be can be used okay thank you uh on uh maybe I can provide a paper that may be related with your proposal sure just the use of file for uh to get a bangle latency sure it would be a pleasure to add this information thank you okay thank you okay we have uh a very short time lap that I would like to give a kashinata uh the word make your question yeah just a quick question uh thanks for the presentation it's very interesting um as far as I can recall the uh rspp it has uh the overhead of the regular refresh messages part and reservation in"
  },
  {
    "startTime": "01:58:02",
    "text": "opposite direction and your work did you consider using those uh messages or exploiting those messages to send additional uh information in order to maintain the guarantees of the past um in fact in those in those those messages that are used in a recipe to maintain a current reservation uh they are they are limited by the objects that are specified for sap messages and in fact our uh first and second uh in those in those interim messages or Internet messages they all follow the flow that they are sent by intermediate nodes to the destination and if needed the decision feeds backs information to the source so uh this back and forth flow is to us introducing delay if you want to react to to change very quickly in RSVP first and the formatting of RSVP can is done to to follow uh the Qs work that has been done uh several years ago but for that Nets and especially for this mechanism if you want to keep a very simple data format those objects are very tedious to use yeah there has been some work over the years on reducing optimizing or carrying some additional information but yeah that needs changes to the to the structure itself yeah yeah in fact we we try to track those changes uh but we stick to our LCP objects that were attribute the Yana page for a zp so"
  },
  {
    "startTime": "02:00:02",
    "text": "uh once again we may be wrong but and if you have uh ID for format for most object formats that we may use I would be very happy to hear from you but uh to the best of our knowledge and from the objects that has been published on the Yana page for RSVP this is the best we could do okay thank you thank you okay thank you very much everyone for the presentations and the good discussion we are running two minutes over time so I suggest to uh close this call as David mentioned uh the next one is four weeks from now as uh two weeks from nice July the fourth and we can continue the discussions on the list until the next meeting thank you everyone bye for now foreign"
  }
]
