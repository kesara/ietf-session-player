[
  {
    "startTime": "00:00:08",
    "text": "Okay. Put it on a slide for draft. Oh you did. Okay. Great. This is just like okay. They're trying to Right. Alright. Hello, everyone. Welcome to Per g. I'm chris, This is J siobhan. Sarah's here issue she here, Actually, issues she's here. She's here with us in spirit. I don't know if she's on online right now. Next slide, please. This is the nobel. Assuming mean you have all seen this before, but just in case you haven't you check it out online, but the high level takeaways are. Be mindful of the Ip policy as well as the code of conduct. Generally just be be friendly and respectful, and we should have to grand all time here talking about privacy things. So I As an additional reminder, Id sixteen does require all active"
  },
  {
    "startTime": "00:02:03",
    "text": "in the room to be wearing a mask unless you're actively eating or drinking. Please please obey the rules, so we don't have to come and talk to you and be offered about it. Thank you is our agenda. Thanks, Matt for taking notes. We're gonna start with a quick update on current drafts in the group and then go into a bunch of presentations on a variety of topics. Before guess jumping into the updates does They anyone have any adjustments or other comments you'd Like to make on the the agenda as it is. Okay. On. So Next slide. These are the drafts that we have active right now. So some of them are being actively developed. Some of them. There are some drafts that are expired. I wanted to quickly see if we get an update from Matt who's is in the office on the office. In the room on the Ip address privacy considerations one, which is a drop that was adopted I don't remember exactly when some time ago, it's gone through a number of updates, but still needs a bit more work. Yeah. If you could, please. Yet. That might is fine. Yeah. Matt Apple, previously Tore. So I haven't actually worked much on this. It's it's very high on my list. I since the last meeting, I we haven't done anything. So I don't recall what the last update was, but I I know at that point, I had recently talked to the authors about some structural changes and organization that we were planning on doing. Haven't actually gotten to doing that, but I'm"
  },
  {
    "startTime": "00:04:00",
    "text": "optimistic that that is coming soon. Great. Thank you. And don't take this criticism. We that we know everyone's super busy. So And there have been some other people I don't see in this room I have expressed interest in potentially helping with this don't know if they've spoken with you, but we can connect offline to. Yeah. That'd be great. Definitely. So thinking matt. The other drafts we have the this censorship survey one has sort of gone quite far along in the process in I review right now we do need some bert tracking down some updates before we move forward. Did you wanna say it? I think it was just a new version was just cut. So I think it's just yeah. We're pretty think it's just a quick review and we should be good to make push it forward. Great. Thank you. And then there's the safe measurement guidance draft. Still being actively developed. Unfortunately, I don't see mallory here or anyone else you're could could potentially speak to as an offer. But we're working with them to make sure that continues to move forward. Interesting in working on the stop that draft. Of course, please should reach out to the editors or send comments to list. Reviews are always welcome. And believe that's it. Unless you won't just anything else? Yeah. I guess, also I I think the chair think that this graph this safe management draft is kind of interesting and important given the work happening in the P booking group. So for... That's also why I think this would be a useful draft. And I guess the other two drafts which were the on generation of Trans Numeric identifier and unfortunate history of Transient numeric identifier both those drafts are have been sent to the auto editor. So there was some discussion about how the pipeline bills with respect to this other draft. So there's some conversation there, but cheers are working on that. Should be should be published soon. Alright. That's it."
  },
  {
    "startTime": "00:06:01",
    "text": "So on the presentations, first step we have Martin to give us a kind of an overview of sorts on Ipa intra private attribution. And we have thirty minutes queued up for this. It is I don't know. It if that's sufficient, we'll we'll find out. It's easy to make it work when I turn a microphone on. Alright. What's up. Yeah. Just one moment. I should have put that a new deck is being shared. My presence presentation. Anyway martin thompson. I'm here to talk about attribution. I'll get to what that is. In a little bit, specifically, but probably for now if Suffice to say that this is an important piece. Of how the advertising industry measures how they they achieve what they do. But Next slide? This is what I'd prefer to talk about. So that's what we're gonna do for the next few minutes. More specifically, next slide. This. There's probably a number of you who familiar with the system now, having been here a couple of days. So I'm going talk about an issue that's very pressing for people who those networks. And Next slide, please. So those of you who've used one of these systems know that a lot of these use a system of identifier that they use to manage a number of different aspects of of the way that you interact with the system. Primarily these take the form card. I think I have one of those in my pocket right now. Look at that. That's actually the one in the photo. And"
  },
  {
    "startTime": "00:08:02",
    "text": "You you tapped the car to end of the system and your type the card when you exit it And in know a lot of cases that the distance that you travel in the system determines how much you pay for the things but I'm not here to solve the privacy problems with that. I'll leave that as an exercise for the people in the room, is to how to build the system that will preserve information about your your trips specifically and allow you to do a distance based calculation. That's not what I'm talking about. Next slide. What I'm talking about most specifically is the ways in which the transit systems use those identifier to track for the purposes of capacity planning and and other They wanna know how many stations to build? How many trains to run on particular line and and other things like that. And I think I can take courts probably tweak to exactly what I'm be talking about now. There are some exceptions to that. Cash payment systems, and tracking tend not to work very well with this, but then the New York system has pictured in the slide there. Has a fixed fee you only saw when you went to the system, so that can only really track when you enter the system so there's limited information in those cases. When talk about those systems the track when you enter. And when you leave. The way that these work typically nowadays as understand is that each one of those cards contains and identifier out for you. And that identifier is logged by the system when you enter. And logged in when you exit. And all of those are collected into a giant. And you can make some queries of those logs to determine is this the busy hour? How many people are traveling between Shin and Tokyo station, all of those sorts of questions that are kind of essential for doing capacity. And performance planning."
  },
  {
    "startTime": "00:10:03",
    "text": "You can also do things like look at how long it takes people take journeys when you have into interchange between different lines and those sorts of things. So really useful for for capacity planning. But Next slide. Logs terrible. They create a record of movements to people. Through the system and can be used for purposes. Other than the ones that I described, which are potentially useful, they also provide you with means of identifying when people will say for for instance visiting someone that they maybe shouldn't be. Or that they would rather other people don't know. They're visiting. And so an important thing to note here, though these cards are not tracked. I don't think that anyone knows that this particular number is attached to me. I got a permission from a machine that I'm might have you credit card on, which is a problem. But I may have had paper for this with cash at a machine. And so then there's nothing that necessarily ties specific should to identified to me. There is still a privacy problem inherent in the system because those identifies can still be used with various then normalization techniques to identify so who are given a long history of records of of the journeys that you take. Next. So what we want to do is collect aggregated information about Journeys so that we can protect the information that individual people one. We don't necessarily care about those individual journeys. We just wanna know how things are working just in the aggregate. That is how them You think so I designed for that. So one simple design that I think has been used in a number of places is you essentially"
  },
  {
    "startTime": "00:12:03",
    "text": "had a token to people when they entered the system. They carry those tokens through the system. And at the other end, they deposit that token. Into a sort of bucket. The other end. You encourage them to do so. By very good anticipation, but almost today. That you encourage them to use the the deposit system by potentially making the the fare lower for them depositing the thing and the the system at the other end. There's a number of different mechanisms that uses to sort of layer on top of these ones in order to make sure that the system works as you expected. In one set of designs, the tokens are anonymous and we use... Potentially could use something like a blinded token much like we're doing in privacy pass. Or maybe you can just use a very low entropy fire that would allow you to sort of identify in the aggregate. People are, but but because you have to assign the same identifier to multiple people, you would have have some sort of and an anonymity property that comes out out of that because you have to share those identifies between multiple people. There's obviously a whole bunch of problems that come come from this with fraud and various other things because that token is not been bound or anything someone people can exchange them within the system and gain the system in various ways. So there's there's ways in which you might might need to slap some extra authentication on top of it so that you can cross the information to getting out of the system is somewhat reliable. And you can't open that box that people deposit their tokens in at the other end. Otherwise, you can just sort of... You can't get the information out immediately soon as on someone deposits that the information you have to wait. Form or mix them around a little bit at the other end. Otherwise, you can sort of use the timing at which that"
  },
  {
    "startTime": "00:14:01",
    "text": "token was dropped in the bucket. So down to to link it to the person that dropped in the bucket instead of learn where they came from as a result of reading that off again. So there we talk about having things like random delays before you open in the bucket. And then you have a bucket You check it up and and wait for an hour. And then after the hour expires, you can look in the bucket and then well, it's got the last hours worth of people in there. You don't know which one of those people specifically deposited at the token. Of course, We can potentially use an aggregation system to make those delays a little shorter and mix things in a little more efficiently. And we'll get to that because that's interesting part. So nice things. About these designs that the tokens are ep. You you sort of give talking to someone and that token really only exists for the for the duration of the journey and the thing that you're interested in measuring. And because the users carry the tokens and you can sort of see what the tokens are they. They sort of understand at some level potentially what it is that they're carrying for you and have some sort of say and how that information has carried them. And that you can imagine that this being sort of a consensual process in the sense that in in order to access a lower fare, people will be carrying this information for you and it and there's there's a trade of information that that trade information for value essentially. And the the token is limited in in terms of what what it calls you can imagine that the token could contain a photo of the person as they entered the stalls in one station. And they carry that to the other station and there's members of a track record that's bound to the identity of this, and based on the photo or something like that. But because the user carries it I I can sort of maybe no depending on the properties of token, what is being carried around. And so they they have some sort of control over that. But of course, the flip side of that is because the user knows one information they're carrying"
  },
  {
    "startTime": "00:16:03",
    "text": "and has to agree to carrying this information ahead of time. The system tends to be a little inflexible and and how it's put together. And of course as I mentioned aggregation. Right. But and can sort of mitigate some of the problems that we have with with things like delays and and questions about the size of the anonymity set that you'd get with limited entry entropy being identifier. Next. So. Now we got trains to advertising. This is the interesting part. So next slide, please. So in in attribution, you're taking information from one context, and you're linking it. Via a person to information in another context much. Sign yeah. And the basic premise behind attribution is we want understand how our advertisements are working. And we show advertisements in a variety of different contexts and all of those are showing with the with the purpose of having some person see the advertisements and act differently in some other context. And we want be able to understand when we showed the advertisement over here, the person taking the action over here whether or not this was... This was linked to or Maybe not consequence, we can talk about causality and correlation here, but whether this was the same person that saw the out in these other context and and able to measure this information, gives you some ability to understand whether your advertising is working. And so when you have attribution, it sort of underpins everything that the advertising industry does in terms of how they understand. How to place ads where to place them, how much money this spend how long to run a campaign for what sort of"
  },
  {
    "startTime": "00:18:00",
    "text": "things to show to people, whether it be bright flash pictures or subtle text or whatever it is that they're they're trying to to accomplish and we have a problem that, we're taking information from one context into another one. And that creates the ability to link activity for the person. And so we we would like to do that more privately. Next please. So we have trainings on the left. Quite simple. You enter the system, you exit the system. These things happen only once you won't be entering the train system more than once. You won't be leaving more than once for. And entering. That's not true of advertising people will see lots and lots of ads. They'll click on some of them. Sometimes, they will be a person who's who the advertisers think might a could candidate showing an ad not to show them an ad so they can do a randomized controlled trial. And say we've got this cohort of people that we'd like to show adds to. Based one soviets ads, These ones didn't. Has the... Has he had haven't had any effect on the their behavior subsequently. And of course when you guys said people do buy things multiple times. The things that advertisers want to achieve from showing advertising is it a simple always is showing an ad, It might be that sorry purchasing a product. It might be visiting a site, it might be signing up from a newsletter it might be that you're looking to see how far through the your online shopping process that someone has gone. Through and probably the thing that underpins all of this is that when we talk about trains, the only real context that matters is time of day and and some other relatively minor things. Whereas with with advertising context everything."
  },
  {
    "startTime": "00:20:00",
    "text": "If if you're an advertising in your placing ads on a newspaper and the newspaper has an article on Let's just say a one of the classic examples here. They have a article on a plane disaster. And you're an airline and you show an out there. You might find that the performance of that ad differs to the performance of an ad shown against a travel put food blog thing or an article about travel in some other country. And so context is everything advertising. And and I will really care about pulling a lot of. Information. Next. So private attribution has a similar design in some ways to the ones that I talked about previously. A more similar impact to the tracking system than I talked to about before but then advertisers for unique identifier for everyone. But it uses a different approach. So the idea is that in the different context, people will conduct various pieces of activity whether it be viewing ads or or buying stuff or visiting websites. Whatever advertisers care. About and everyone has essentially an identifier. How they get that identifier as going in. We go into a whole lot of detail and and the document. The thing is that identifier. Is a secret for that person. No one other than that person knows what that that identifier is and most of the system exists in all the complexity in the system exist to protect that information from ever being available being made available to anyone outside of the person who the identifier is assigned to. When a website shows you an ad? Or you purchase something, the website can request an encrypted copy."
  },
  {
    "startTime": "00:22:00",
    "text": "Of the identifier. And in fact, I should have said encrypted and secret copy of the... The identifier. Sites then gather that information into their logs just as they would any other identifier except for the fact that now we have two different sites that have encrypted blobs that do not correlate in way. There's no way for those sites. So look at that encrypted blob and say this is the same person as this. So in fact, those logs are useless to them for the purposes of linking activity across sites. Without some extra help. Next slide. Sort what of sites do is they sort of collaborate with each other and and collect all of the the logs that they have. Across multiple different contexts, and I put them into a huge pile, and they add some information is relevant to the system, and they submit to a and Mpc. And that and that Mpc will perform a computation and give them the information in an aggregated form on the question that they want answered, which might be many people saw that how many people saw this head and then bought the shoes or how many people clicked on an ad. And or any product on this website. The the shapes of the queries largely the end of the control of the sites question. The Mpc performs a computation to match items in the log up. To the same person and performance and attribution algorithm. The details of which I won't going to here, because it's boring And the the net result of this Yeah. Philip says, yes. Boring. Chris, Chris is laughing. The the the output of the system is an aggregated result which which so says, which is broken down effectively new his."
  },
  {
    "startTime": "00:24:00",
    "text": "For this campaign potentially, you have this many for this campaign, you have this many for this campaign, You have this many. And one of the nice things with this is that the Mpc components this computation without anyone saying the underlying identifier, which is critical for privacy purposes, but it also performs a computation without the Mpc even learning what the query was in the first place. So one of the one of the sort of primary concerns that a lot of advertisers have is that they have business sensitive information that they're submitting as part of these queries, and they don't want anyone to be able to get access to that that information. So it might be a competitor to them and be able to use it for their own purposes, which is also. And advantage miss. I getting through these. So in Ipa This is all I'm gonna talk about Mpc. We use a multiplied company computation. The great thing with Mpc is you can perform any computation without seeing what the inputs were. Any competition can be performed if you can add things and multiply them. Just like in logic circuits, if you can or an end, you can basically do anything or is it or a nand I think forget exactly what it is. Doesn't matter. The thing is All you need is time network capacity and a ton of Cpu and you can perform any computation at all. The trick is reducing the amount of money that you spend on the computation. And there's a lot of tricks come the trick. So far that we found is a three party honest majority npc. That is There are three entities and you trust that two of them will faithfully execute the protocol and not collaborate. To share values with anyone else."
  },
  {
    "startTime": "00:26:00",
    "text": "And we can provide information security guarantees that don't require any sort of complex assumptions on the crypto side of things. And we can perform a lot of basically, generic. Mpc. We do some sorting We do in comparison across different different lines, and we can produce an output from from that. Details linked later on then so. Next place. So probably a key privacy hook here is that we're we're looking to is differential privacy for this to hide the contributions of individuals to the system. Obviously, we're revealing an aggregate result at the other end, someone is going to learn something about the inputs that would provided, but we can use differential privacy to ensure that the information about individuals is statistically covered by by noise. In the output. In order to do that effectively, we need to find ways in which we can understand the limits of how much someone can contribute to the system. And we have a number of mechanisms in place to do that. First one which is that Why not. We're not restricting the amount of information that sites learn over time when restricting the rate at which that learn information. And so a there is a budget that sites a given, which is you get this much every week and that renew at the end of each period. That's not great. Given infinite time, infinite information will be released. But the alternative is to progressively degrade the the usefulness of the system over time as we release information you you can imagine if"
  },
  {
    "startTime": "00:28:02",
    "text": "If you use the system for five weeks, and then the site uses up the budget. They learn nothing more about that person. Forever more, it doesn't sound like a really great solution. We're gonna have to look at other ways to to ensure that that individuals are not not targeted. We have not yet decided what the the key tuning parameters are. And so the shape of the noise, how much noise and how much error resilience we need to have is very much. Open question right now. We're doing some studies to work out exactly what those values might need to be from a utility perspective, and there's gonna be a lot of debate about what what it means to to protect information with an Epsilon value of say, point one as opposed to an epsilon value of say four hundred which was the joke that was running around the other the other day. That you say that four hundred doesn't look like very much noise. Thanks, please. Right. So in order to facilitate that sort of thing, we need to make sure that when an an encrypted identifier is provided, we can sort of trace it back. And and bound the scope in which it is used. And so Encrypted identifies what we bound to the site that request them. They will be bound to when they were requested. So that they can't be used out of in in another time period. And we're also finding other information such as the type of event. And the type of event is is sort of critical here because there are two sorts queries that were asking. In in sort of generic un attribution, you might show ads on multiple sites. And we wanting to track outcomes on another halt up a whole different set of sites, but we set a restriction on this one to say, When you make a query, you have to choose one side from which to"
  },
  {
    "startTime": "00:30:02",
    "text": "to to deduct budget. And that site is on one side of the query, then you can have multiple sites on the other side of the query for which the budget does not matter. And we so we have to know which site is is involved and which sort of query will be involved for that particular event. So that we can then cap the number of that type of query for that website. In that week. Little bit funny like that sometimes. We also have capping within the Mp system them which is Second to sorting the most expensive part because you have to go through every single record and effectively compare it to every single other record. Which is massively expensive and that's a research problem. I think. And then there's all sorts of other commitments like the sites need to commit to using a specific Mpc system, they can't just take the their events and ship them around to to different Npc systems. Otherwise, they would be able to get more access to more budget over the time. And there's a whole bunch of other things that we probably don't need to go into Next slide please. So why do we go through all this trouble when we have the simple talking first thing. I think primarily from this is from a utility perspective, Ipa offers advertisers a lot more flexibility in in terms of how they process that information. With a hard backstop. On this with the different differential privacy and and all the security measures using Mpc to ensure that the identifies done like out. The ability to use their existing logging system with a different sort of thing that substitutes from identifying means that they can operate existing fraud prevention mechanisms. Without having to integrate fraud prevention into the system I mentioned in passing for the token based one, there's there's a need to sort of carry token"
  },
  {
    "startTime": "00:32:02",
    "text": "with the system to prevent people from pro mis representing the fact that there's things ads for shown for instance. Where whereas in this case, it relies much more in existing systems. And then otherwise, of course, that it it may still be the case that we want to integrate more tightly with those fraud prevention mechanisms but the idea is that we would we would not over index on that one, and it wouldn't be critical to the design to have have that integration. On the downside, however, the flexibility that we're offering here does sort of hurt of the accountability properties that we're looking to time. From a system like this. One of the the key concerns that people have raised with a lot of these systems is that they are ins screw. The information about queries is opaque to everyone involved in the system even if in in this case, even if the Mpc system published the details of every single query that was ever night through it. We wouldn't really know what those queries entailed because I just can contain a whole bunch of random goo. That has been. And don't know what to do with that. So we had do have some challenges in terms of making the system understandable and in particular, order. From the perspective of of users. And of course Mpc performance remains a challenge? We have, I think some reasonably good stories about communication efficiency and whatnot with our current implementation, but the numbers that we've received from some of the larger actors in the advertising industry. Scary. We're talking about running a trial now with with millions of records. The number two hundred billion has been raised. And it turns out that's a very large number to to handle. And I think"
  },
  {
    "startTime": "00:34:01",
    "text": "philip talk a little bit about some of the things that that that Google been working on in this area to sort of help us these sorts the systems out. But this remains a big challenge particularly when we talk about maintaining the the privacy guarantees that we're looking for. Next please. I'm making progress here. Okay. So the reason I'm here is to sort of make people aware of this. Reason I'm not in the Is the first point here. This is still largely active research. There's ongoing discussions with the advertising industry, there's some really good engagement. At the w three. We I think have have established that this is potentially quite feasible to do on at least a small scale. The scalability questions, notwithstanding. With we're working out the details of the algorithms, we continue to take five percent off the communication costs several times a week. So things are moving pretty rapidly on that front still. Very unstable, I would say. We're looking to run trials this year with real advertising using the identifier that certain actors in the ecosystem have made available to us and not removed. Thank you, Google. We will we'll see how those post Trials out. We're essentially s s synthesized the operation system without any involvement from from browsers and and use regions. So that will be interesting as well. What we're hoping to do ultimately in the future is working out which one of these proposals in the space is most interesting. And we will go from the W three when we're talking about this and and look to make some make some proposals into places like Working group and and whatnot"
  },
  {
    "startTime": "00:36:02",
    "text": "we can talk about real protocols for building these things. We're also looking at broader applicability as well. And next slide, I think has the only other thing. So that's just an encouragement to join us. Great. Thanks, Martin. Any questions for him We have roughly four minutes Brian. Go ahead. Hey, Martin. Good afternoon. Awesome talk. I have a a question about came up in a couple of places. M performance is a challenge. Are we or or these challenges primarily the computational challenges? I mean, are we talking about, like, extremely super linear performance at the multi party computation sort of there or we looking at the communications complexity. And the last time I look at all of the basic stuff of about ten years ago. There was still some low and medium hanging fruit in the sort of intern communication. There were lot a lot of places squeeze out on. I'm you guessing that's been squeezed out. So is this? I've think that you can just throw a lot of compute at. Or are there like super that make that two hundred million to two billion ba you're using a medium sized cluster somewhere to you're renting all of or favorite mod provider. Yes. So a lot of this is algorithm. So the algorithms that we're using here are for the most part which is fine. The primary challenge... Well, Philip we'll talk about the skyline in terms of being able to scale out once you get ci. I think we got some log in you know, in our Algorithms, which is very bad once you talked about very large numbers. Mh. But if assuming mean that those sorts of designs work out for us. And I think that they're showing a lot of promise. The primary challenge here is actually we're spending a lot of time on communication."
  },
  {
    "startTime": "00:38:04",
    "text": "Rather than hard cpu you time. We we do we do hit the Aes instructions, very, very hard. U. So it's not like there's no computation cost here. But when we started on this, we were looking at, I think in the order of for a million records we're talking about. Spending about forty plus gigabytes. Of communication, which for something on that scale would be bad in terms of being quite expensive, just to pay for the bandwidth with I think we improved the sort performance over the time by I think thirty to forty times And so we're now in the ballpark of, like, reasonable and we're continuing to find some more tweaks. But We're still talking sort of multi gigabytes from per million records. Which okay. But the complexity the the complexity that that needs to be squeezed out is still back communication complexity as opposed to to what's going on on Yeah. Yeah. Very much. Okay. Cool. Thank you very much. Martin, I have two questions. They're both kind of meta. So bear with me. So the first of which is the the the two two of the hard problems that this particular work set out the solve was one sort of trying to define, like, what was like the Mpc functionality you needed? To dis solve the problem that, like, the tech people needed. Or or claim to need in a particular case. And then the second one, is what you're all turning on right now is now that I have this particular functionality to find. Do I implement it in a way that's, like, performance and we can deploy it and whatever. Yep. I'm wondering if you could speak to how you went about perhaps, like, defining the functionality and refining it down to what you have now. Like, there's there's this concept of cross"
  },
  {
    "startTime": "00:40:01",
    "text": "device attribution that's being discussed in the in the chat. You can't see it. But there's like, a lot of it's not the simplest thing in the world, but it seems like it was the the result of a lot of iteration, a lot of discussion with the stakeholders. I'm wondering if, like, if you can say anything about the process by which you you converged on this particular type of functionality and why you think it, like, solves the the effectively solves the problem, boy. You have another half an hour? This this is very much the process of iteration on on these things. I think there was a lot of people who looked at this problem very very long and. And try to reduce it down to something very very simple. So those familiar with with apple's private click measurement. We'll sort of recognize a very, very simple design doesn't achieve very much from utility perspective. Sort of very pretty much clarifies the sort of shape of the thing that we're trying to do, which is we're taking information from here and we're passing across to here and and there's a single person that that represent the connection between those things, and we wanna keep their involvement in that private. For the for the most part, however there's this is really about understanding how you have advertising industry uses that information. And there have been many, many hours wasted on going through once I wasted spent on on going through the finer details of how measurement is an integral part of the advertising business. And that has happened over the course of probably three or four years. The W web advertising business group has talked about this it length and producing fairly coherent documentation on on what it is that they do. As opposed to what it is that I made. And then I think"
  },
  {
    "startTime": "00:42:02",
    "text": "various actors in the space have sort of made their own determinations of of what it is that the the sort of need first want judgments and and sort of can come to different conclusions. And so there continues to be debate about certain things and you mentioned offhand hand. The idea of doing cross device attribution. So can I take and add that I saw on my phone, across to convert on a on a Pc somewhere else and be able to to link those to events and and and have them come out through the attribution system as a as a positive result? That's that's something that continues to be under the debate because of of all of the really interesting privacy implications of being able to do that. When you can do that, is is it possible then to to connect to what you did when you physically entered a store and bought something with cash. That would be... I think for some people it look little surprising. And so we're we're going through a bunch of debates about. You know, where the line sits there. And some of this... I think it's not a boo question of needs and wants. There's a continuum and you'll find that there are people at different points and like continuum for whom the question at that point is existential. And so some of these things can get a little heated. Yeah. Yeah. Great. Thanks. And so just I won't ask the second question because there's not time I just want to patch some context to the the reason I asked it. So there's a lot of, like really brilliant people who, like work in, and they spend a lot of time like, implementing really efficient protocols for doing things are implementing a functionality that turns out maybe not to be the right functionality in practice. And all the work that you all spent. Hours like refining this problem. To sort of basically, you know, say, this is the function that we actually need. Yeah. Really smart people go out and, like, us how to implement this in a way that's performant. I wonder if, like,"
  },
  {
    "startTime": "00:44:02",
    "text": "you know, this sort of meat in the middle approach is a a useful way to kinda go about applying the the, I guess the the the the way you went about, you know, building Ipa and designing it yeah. For other types of use cases. That might use In the future. Yeah. It's it's an interesting question. I I don't know what the answer is. There's always this should be truly we build question that underlies all of these things Yeah. Right. Thank you. Hey, Martin. Thanks. My question was So we seem to me, like, three servers in the back end to to dash the. Just wondering guess It wasn't clear to me would those be the advertisers? Or would it be just independent hardy? Yep. And would they... Like who you imagining that they would be and would there be just the three in the whole world or would there be different clusters? Yeah. Didn't go in into that that much detail that the proposal talks about this at some length. The audio is that you have to trust these guys not to not to work with each other to undermine the privacy if your Mpc system, is willing to share the... What the the information that They get with with other nodes in the Mp system. He basically lost all of the privacy protections. So from from my perspective is someone who works on a browser, I I I would want to know that I can trust the three help parties call in the Mpc system not to not to do that. But that's all I need to trust them to do. And so we've gone from being able to to sort of do this computation with a great deal of trust in whoever does it, which is a practice that happens right now in the advertising industry quite a bit. I call it if we refer to clean rooms, which is where some trust is given access to all information and they go it into a little room. Maybe they maybe... Maybe it's a skip or something like that. I can do the computation and I come out with the answer that you have to trust. That they're not gonna leak that information essentially. Here we have a much lower"
  },
  {
    "startTime": "00:46:04",
    "text": "trust. And we've spent a lot of time working on who those entities would be, They would not be the advertisers. They'd probably not be the browsers there would be of a neutral party. And there would be more than one option the idea is that an advertiser would be paying for access Service. And so we wanna have some sort of competition there. To sort of incentivize efficient delivery of service. To keep the costs down. And so there would be multiple there. Thanks. Jonathan? I'll be locked the queue now, I think. Yep. Talking northern cloud. If you were having it run by a third party that's just even an option say. Does that third party have an incentive to say Or can they say Oh, I'm definitely running. Then actually in the background, they They have their nodes include, compute the answer really cheaply, and then return you the correct answer. I'm then I'll... They're not taking it to break privacy. They do need to save money. Because like, running is expensive. So we can talk about Ta if you want, which is essentially the the story that of others have chosen to to adult. The idea is that there would need to be some sort of oversight. For these entities. To to sort of verify that they are indeed, conducting things that let's in the same way that we... The model where you we imagine using here is much like the Ci browser forum where there's a collection of browsers or user agents in this case. Would get together a set set of rules that we would expect these Embassy systems would abide by, and there would probably be some sort of auditing process that would verify that that is indeed while they're doing in practice. Now could we do something stupid or well"
  },
  {
    "startTime": "00:48:00",
    "text": "semi stupid where we just say part the response they have to give is note, the last step of the Mpc computation or, like, some like proof that they actually did the work. Doesn't mean they didn't break privacy. But it means that they don't have a financial incentive to skip the steps. Yeah. So we've last week we spoke with some Npc researchers at Boston University who immediately asks so have you talked about using verifiable mpc? Which is a thing. Okay. Far more sophisticated than what you described? Also, not ready. Was their assessment? It's probably gonna before and the research on that is is limited. Decide best about about as far as I understand. So things possible. But we not at that point yet. Think we we're more likely to want to rely on that the sort of trust and trust and verify systems that we use currently as much as we we might might aspire to something better that's the best that we can manage right now. Thank you. Thanks, Juan. Thanks also for yeah. We went over so. Thanks for answering all these questions. Yeah, Next up we have built to talk about secure positioning protocols. Just let us know how you wanna advance. We can we could do for you. I think I think I have too many. Oh. Okay. Alright. Then you should do it. Alright. Yeah. Thanks Martin for this great talk and great images in the slides. I don't have as many of those. But... Yeah. So I'm trying... I'm gonna try to go a little bit more into details about how do we scale this or how do we scale any such aggregate system? Such that it actually runs on real machines that we have. Because we heard these sizes of these logs or the sizes of"
  },
  {
    "startTime": "00:50:03",
    "text": "the data is usually quite large. So if you think all of the impressions that we have across the web. Are now supposed to be running in this one single npc cluster. That's going be billions of impressions from billions of clients. And it's it's a lot of later. So just a recap. So the way we envision us in the abstract sense. Is that all the clients submit all the reports to the single cluster. That Cluster performs its Mpc and we get out the aggregate report that is Yeah. Anonymous or differential private in some way. So what we crucially need here is to have... Or to put it into train. That the tokens of a particular user end up in the same machine. Right? So if we distribute this now now. So if we want to have multiple clusters, that run on that distribute all the users across them. We need to make sure that all the clients are all the reports that belong to a particular client, end up in the same cluster. Now if we just reveal, well this is me I want to be... So this report belongs to me and we have some pseudo identifier. Then we're back to square one. So that doesn't solve the problem. That just has another identifier that we do not want in the first place. So The goal here is to have a secure shard protocol or a secure petition protocol that allows us to do this partitioning of encrypted reports without actually revealing an acute identifier. At least without revealing it without some additional privacy matters. So just a high level view of the go. So As I said, inputs from the same client should end up in the same shard. That way we can ensure that the downstream Works So the the Protocol or whatever aggregation want to run? We want low overhead. So the Is extensive as it is."
  },
  {
    "startTime": "00:52:01",
    "text": "We don't want to blow that up by ten x just to do efficient partitioning. And we don't don't want to affect the correct. So ideally, we want to have a result that is equivalent or equal to what we would get if we had these big machines that run the Mpc. The assumption that I'm making for the protocols that I'm presenting here is that we have some bound on the number of contributions from on clients. In practice, you can probably think of a very large bound. Ideally, you want to have it somewhat lower because that's gonna attack the overhead. Of of the product protocols. And again, the second of assumption is, but I think that all of these systems will share that is that we have many many clients and quite a few showers. So thousands of showers, but maybe not billions or millions. Alright. So the blueprint that I'm presenting here and I'm going to switch to a two server model now. Simply because the protocols that I'm presented here, they work quite well with two servers already. Even if the the larger system has three servers, of them could be idle for that, or you could just with one of them across two of them. Doesn't really matter, but conceptually two servers here works just fine. So we have a client who has an index or an identifier and has a value or a payload. And what the payload is for this presentation, we do not care. It's something that secret chair that's encrypted that will be used by the Embassy system, we just have to pass it through correctly so that in the right position, we have the right payload for the same. And then we have two servers one of them has an op key. So P f is a pseudo random function. That basically maps the client identify to some random space. And the key for that mapping is owned by one of the servers. And to get a bit ahead, the second server will learn the results. So the first server knows the key is the second server learn the result of of this f computation. And that will allow to do the the partitioning or the shard."
  },
  {
    "startTime": "00:54:02",
    "text": "In order for that to be private, we need the first server to also add some dummy divisions. There will be some overhead here by just adding some dummy. But these dummies will ensure that whatever the second server then learns, differential private again. So basically achieves the privacy goal that we want for the overall system. So yeah. As I said, the second server will then map the the output of the. To the partitioning to the partition that then gets sent all the values too. So I'm going to present two protocols that achieved that or two approaches. And their main difference conceptually is and how does this f look like. So the first of them that I called dense partitioning, is where the Op output value is directly the space of charts. So if you think we have one thousand twenty four charts, is a attended domain. That means we have a ten bit output from the F. We can directly use that as the short Id. So what this protocol does is it maps indexes or client identifier two a third Id directly. That is nice. So if if if we can have such a protocol, that's already solving the problem directly? And so again, so the way it work, we the client and encrypt both as index and its value. The server at Dummies, in this case, to every possible output value. So to every possible of these... Twenty four values. And then that's got sent to server two. And now server two decrypt gets the value. And directly can assign every single contribution to a heart because it's it's in the output there's gas. So if we only have a couple of charts, then this actually is quite performant. Because the the overhead that we had. So the number of dummy that the first server has to add to each of those"
  },
  {
    "startTime": "00:56:00",
    "text": "to each of those charts. Is roughly fifty times what the maximum contribution of the use is. That means we add fifty dummy users, basically per bucket. Now if we think back to the assumptions we made, we had billions of users and a thousands of charts that means we end up with at most fifty thousand dummy users, out of billions. That's not much overhead. Right? So this is very cheap. And the privacy parameters as I put here Zero point five and delta ten to the minus eleven that that's pretty conservative. So that's private, but we could make it even more private approval to pay. With a bandwidth. So that's nice already. And I believe that for the Ip api protocol, for example that would already be sufficient. So that might be a protocol that maybe it has some some caveats that I'm going to go into in the end, But overall the conceptually solves the problem of partitioning this this computation. But sometimes what we would like to do as well is to do some local aggregation two before we start the and here is one example, for example is that instead of directly passing in the values into the see and doing some, get computation on it. We might want to aggregate per client first. So if the values for example are conversion values, how much did a client spend? Maybe we want to add that up before we do the, and that just saves us more saves us time inside the. So that might make things more efficient here. But the trade of now is that if our Op value of maps client id ids directly to hard Ids. And we don't get some kind of pseudo client identifier. Then we cannot do a product client aggregation anymore. So what the spa partitioning protocol that I'm presenting tries to do is to solve this issue. So"
  },
  {
    "startTime": "00:58:02",
    "text": "allows us to get an identifier that is not just as small as the strategies ids anymore. But it's a long Id that actually is a pseudo client identifier. Now might ask how is this then private threat? Don't we now create another For the client and better to Square one. Well, here the main idea is that by adding dummy contributions again as in the previous protocol we can inject dummy lines and wave. And that ensures that whatever the service sees as it's as its components so as it's pseudo index and encrypted value pairs. It cannot be sure whether that's a real client or whether that was dummy inject by server one. And we we have the non collusion samsung here as well as in the Api protocol. So as long as one of the service is honest. And it's not... And the two servers are not including, then we're fine. So the overall structure of that protocol is similar. So again, the client encrypt under some semi encryption scheme there index and the value. The first server oblivious adds dummy contributions and performs the computation. And that gets sent to the second server. And that second server now, maps the Value on so. Can map that actually arbitrary to shutter, and then can do local aggregation. Per client. These are like the this is a more detailed version of the same slide as the previous one. Here I basically just expanded the value. So you think of the three party setting for of Ipa, we have three chairs that are separate encrypted. But otherwise, feel free to ignore the slide. Regarding the overhead that this protocol brings, it's going to be slightly heavier than in the dense partitioning. And the reason here is not due to the partitioning. So"
  },
  {
    "startTime": "01:00:01",
    "text": "if we want to assign clients to buckets or to charts, the server has the pseudo identified in the tier. Right? So it can just arbitrarily met them, however it once. And if we only add a slight overhead of the minimum that we need, So this is this m prime here. Which is Yeah. About the maximum contribution that I single client can have. So then we are actually having an overhead that's Yeah. We're having a blow up that's less than in the dense partitioning protocol. However, the number of dummies that the first silver ads that's going to be much more than it was in the dense partitioning. And intuitively, you can think here that We have a much larger f outsourced place. And in order to mask, not only the contributions of clients that appear or the the contributions clients that have many contributions also the ones of clients that only have a very few contributions, but there might be many many of these times. Those are the two cases that we would both have to protect against. And the overhead... Again, for the same example parameters here is like ten percent. So that's a lot more than we had in the dense position. It's still not x Yep. So Yeah. You're just a very high level view on how we can make this spa of computation private at all because that's somewhat une. Right? We get a pseudo identifier where we are sure that every client has its own identifier. At the same time, we don't learn anything about individual clients. And the magic here is to basically view these this collective output of this computation as a his. So what the second service is? Is this kind of multi instagram. It knows I have this value and it appears ten times. I have this value. It appears one hundred times. But I don't know which value maps to which client. And all we have to protect now is the."
  },
  {
    "startTime": "01:02:02",
    "text": "So we have to make sure that the fact that a hundred appears in this list of the server gets does not reveal anything about as a particular person. And we do that by basically adding two kinds of dummies. So one is supposed to hide the the contributions that are common. So clients that contribute many many reports. And the other is to contribute to protect conclusions that are rare. So clients that only have a couple of reports over. Only one. Yep. The details are Sorry. The details are basically we choose the threshold and Below that threshold, we do the same thing as in the dense partitioning. So every possible value below the threshold we add a certain amount of dummies. And then above the threshold, we do something slightly smarter while we take existing cipher we duplicate the the underlying client and identifier and we replace the value by zero. And that way, it affect the output of the computation, but it hides the clients that have many contributions. Alright. So in conclusion, these distributed your computations? In practice, they are quite performance. So in the paper that I link here, we actually have some performance numbers. The overhead is manageable, I would say, so for the dense partitioning, I think it's already there, especially not exist the overhead. Apart at least from from a communication perspective. So computation, you still have to do some course. For slightly larger overhead, we get this nice additional property that we can do local and Yeah. It's up to discussion whether Ipa actually needs that or what we just cannot go with the dense protocol and done with it. What So why am I presenting this here? So first of all, I want"
  },
  {
    "startTime": "01:04:01",
    "text": "would like to know a little bit. What's the interest in this research or anywhere in the of standardizing protocols like this separately from things like Ipa. So Ipa is currently being discussed in the w three. And, yeah, most of the most of the concrete discussions happened there. But Is not the only protocol that we're going to see in the space, I think going to be like, not only other other have being done currently with third party cookies but many many other things. That also might benefit from this concept of not aggregating not collecting individual data, and then are you getting but aggregating directly in the protocol And I think these as well will have to have some kind of scaling mechanism and some way of partitioning their inputs. And think if we can come up with a stand way of doing that, then that might help downstream to make other products preserving aviation functions more Yeah. Easier to develop an easy to deploy. So the second point here is what other protocols might this be useful for? And I also discussed this topic in the P working group. So they're Currently, there is this depth standard being developed and that has a nice property that you only touch every user in separation. So you don't do any computation across users, like an Ipa. Or across contribution. The only thing you do is aggregate. And that you can trivial sharp. So this is not needed for da or or vw tile start protocols, but it might be needed for. For example, I don't know what this safe counting standard is about. So would like to know whether this might need something about for partition or not. And then finally, do we need additional properties? So it's the two variants that are presented here are these enough, Do we maybe need some kind of stable sorting of inputs. This is also something that's being discussed in the. So"
  },
  {
    "startTime": "01:06:01",
    "text": "Yeah. These are the questions I like to bring to the room. And Thank you. Thanks for chris. Thanks, for. Chris. Pat. And Cloudflare. I guess yes. Supposed to say your affiliation. Yep. I think this is definitely interesting. I don't know if it's interesting as, like, an independent thing. It might make sense to say, like, take a take some Npc that we're working on and apply it to that... That's that draft. Would be my suggestion. I don't know if it's... I don't maybe I don't know if it makes sense as like, a draft that says this is a paradigm that you could apply to different Npc things. So you that basically be saying whenever we develop a protocol, we should add something like that into that particular draft for that protocol. Yeah. Wouldn't separate it out. Yeah. Yeah. As like a first step like, take the Ipa code and see if you can shard it and see if you can improve get it to scale better. I don't know. Yeah know. I didn't do this. Chris, you got first. You Chris. Chris Patton was on you get. Alright. Here. It seems like the the sort of bounds you're talking about is sort of fundamental rather than anything else is there... How confident I you that these these sort of numbers are just what you end up having to pay based on by on your analysis Or is it potentially some other approach that would produce different overheads. So these numbers are just for whatever I presented here."
  },
  {
    "startTime": "01:08:00",
    "text": "So there might be other approaches that are much cheaper or much expensive or have a different trade of between computation and communication and so on. So Yep. Okay. This is no way like, a theoretical lower boundary anything. Okay. That that's the... That's really what I wanna Thanks. The other thing was I'm not sure that in in Ipa where as confident in our ability to cap the contributions from individuals as this would require. That's something that I think we probably need a whole lot more discussion about in these context, but the ability to deal with sort of civil attack and and other things like that, really do concern me a little bit because it's great having these theoretical results sort of say that we can do this shouting under the the following assumptions, but when one of those assumptions doesn't hold. Perspective. Is very very hard duration about and been back and forth on this one. I think we should dig into that because, yeah. Mean, you're right in the sense that an Ipa, basically, any malicious advertiser or or website whatsoever can create as many reported reports as it once. Right? So you don't have this guarantee that there's a limit on the number of reports. But I think you can make sure that in the downstream You can still sort it in a way that once the second party sees all these reports, it will know whether they're over the limit or not. Right. Yeah. And and inside the the, you can start filtering and counting and saying, well, this is more or less. But, yeah, that's probably something that's in this. Yep. Thanks. Thank you. For the reason reason the presentation. That's Thank you. Right. Motor, Europe up next. Cool. Would you like... Would you like us to share your slides? No. If you can... I I can do that myself. Right one second. To that. Sorry about that people."
  },
  {
    "startTime": "01:10:01",
    "text": "How do I where's is this button? Sorry about. There we go. Perfect. There we go. Thanks. Cool. Cool. Everybody sees this everybody history me. Yep. Tell away. Okay. So my name is Oz. Currently, a faculty member at Sys, and I have been working quite a lot on deep if you forgot what Deputy was was one of of these massive academic ish initiatives to design privacy preserving proximity tracing. So just to give you an idea right this was but tens of academics where we propose something in early April sorry early March this was then up by Google and Apple sometime in April and the first apps that were using the Google and Apple version of what we initially proposed were rolled out in June. Right? So this is a timeline that is relatively tight and then What I will not be talking about today, we kept on working with this especially in the Swiss context because there was a D file at the time. To keep developing these apps and to potentially add new features or think about new features in the consequence of this. And in this talk today, I just want to give you a little bit of a few of the things that we learn from this and then particular with a kind of technical angle to this. So so If if you think about as being academics right or at least me being an academic, Right? This was a little bit different than what we would normally do. Right these were really in a setting where you have millions of users, potentially tens of millions of users and a huge time pressure to design and deploy. Right? We did this within weeks and months, right if you remember the timeline on the previous slide. We kind of got the first prototypes within, like, whatever. Six weeks including the design."
  },
  {
    "startTime": "01:12:00",
    "text": "Which is not something that you necessarily do and writing this. Nec, keeping things very simple so that we could easily verified this and kind of avoid all the fancy new stuff including... For example. Right? I don't think it ever came up in this particular context. Right, but it was not something to could really afford to do in that setting. And because we wanted to deploy contact tracing, in a digital form So quickly, we have to use existing infrastructure and hardware. And I couldn't make this blink on my Pdf f right and also kind of the want to, but it's existing infrastructure and hard where will be sort of a a theme in the rest of this stock because doing that really had a lot of consequences about what we could do and could not do So just so a role on the same page, right? What what do I mean when I'm talking about the too? So contact tracing, I mean kind of be obvious Right? Like, we want the system that after somebody has tested positive and has been in contact with some other people for long enough, then these other people that have now been potentially exposed to the Covid virus ke notification so that they can take appropriate. Precautions. Now that is all that that that that essentially all most of these systems do, there could be other purposes of this system that I will not be talking about. Right? But in in sort of essence, what we try to do while designing these systems and reasoning about these systems. We try to build these systems with purpose limitation in mind. So we wanted these systems to be only used for notifications and build them in such a way you cannot use them for any other purpose. And now you might be, like, Why are you telling wise? Right? Now if you think about digital tracing systems. And what they would need in order to function you will immediately realize that there quite a lot of risks associated with this type of system. Right? Because in order to do this,"
  },
  {
    "startTime": "01:14:02",
    "text": "notification to quarantine in somebody or to send somebody to get test or what when they have been close enough and long contact with somebody that will test positive in three days Right, this system the must embed a lot all social contact information between people This information somewhere somehow needs to be there in order for it to serve its purpose of notification. And this means that depending on how you build this, the system immediately runs the risk of one revealing the social interactions with between people, right, which we know our private sensitive revealing potential medical information about people namely who tested positive or potentially was exposed to Covid. Like, maybe nowadays this is not so sense any anymore right at that time, when we started doing this, all of this was brutally sensitive. And then depending on you how you actually build this, right, this might actually lead to leaking location traces as well as give the option to do some kind of population control. If you wish. Right? Where, why one might think about the system being used to quarantine certain people and other people not. And We were con all of these things sort of early twenty twenty that this might happen and then design systems that that have this purpose limitation by design, right? So you cannot really use them for for anything else. But at that time, we didn't have great examples of what could go wrong. Really. But now it is this as much easier here. Right? So I do. Just a couple of things from from the news just to give you a little bit of a flavor of all the things that that actually did go wrong with the deployment of various apps in this side. Right? So... Or with digital... Or sorry analog versions Right? So we have the German police asking for tracing data in their effort to fight time because, you know, you have the data, you might as well use that for something else. We have stories about China potentially using"
  },
  {
    "startTime": "01:16:03",
    "text": "Covid control apps to actually do population control and to limit the freedom of movement of activists, for example, we have bartender harassing people. And then we have like, Good old data leaks associated with these systems, but that then ended up. Making particularly sensitive data about these locations in Australia, including different defense sites domestic violence So so really these things that we that we initially sensors. really came to quotes. Right? And and and if you zoom out a little bit, what is behind a lot of this is that whatever you build, the interest structure to build really matters for what is that will be used. Right? If you build the road, people will drive on it if you build a contact tracing system with a lot of data in that people will come and ask for the date or try to use that for Right? And and And you'd be surprised kind of by by the amount of interesting shall we say with delivered care quotes, suggestions or questions that that we got while living the systems. Like, could we also use this system for eggs were acts typically was not such a nice thing. Right? So which brings me brings me back to to the previous point, right It's really important to design these systems with purpose limitation in mind so that when you roll out this system, like especially when you roll them out, at this scale, right? And then we have talked about other systems again today as well that we're also rolling out at pretty large scales right to essentially everybody, right or a sizable fraction of your population. And I really think that that this way of thinking about, okay, what could potentially go wrong with these systems and and how do we... How do we ensure that really the only thing that they can be used for is what we initially envisioned is really important in that sense. No. Let's talk about something a little bit more technical"
  },
  {
    "startTime": "01:18:01",
    "text": "Right? So so I'm presuming most of you have heard some kind of of version of this story before, but let me just so the rule on the page right. Let me quickly sketch how the initial design that was then adopted worldwide, right after some modifications. Works. So so because we wanted infrastructure that that was out there. Right we we opted it on using phones with bluetooth low energy beacon. And this means that if a user would install their contact tracing app, this app would start transmitting random beacon using Bluetooth and Other devices in proximity would receive these beacon and order in a list of things. And that is what all these devices do. Right, So phone b will receive the beacon from phone a and we'll store it this list. But maybe phone see is so far away from a that it doesn't receive it and therefore. Custom not stored. Now in practice, it will store a little bit more like like, signal strength, etcetera, but this is the rough idea. And then to prevent some tracking as a result of these bluetooth beacon Apps will typically rotate these beacon let's say roughly every. Every ten minutes. Now this by itself doesn't get you in. And proximity trace. Right? But you might realize already that this list of see numbers is kind of like a local proxy a few wish. Right? A decentralized representation of proximity to other people. So we can leverage that to do exposure notification in the following way. So once somebody positive it and receive some upload authorization from from the hospital at the bottom of my slide. They will enter this authorization in their phone and then the phone will upload the list of beacon that this phone has been transmitting. Essentially saying, do a central server, here are all the beacon that have been"
  },
  {
    "startTime": "01:20:01",
    "text": "that by this defiance that corresponds to a positive user. Now all other phones in the system will download these lists And then if you remember the previous slide, right phones have two lists. Lists of beacon that were mark that's transmitted by positive people and a list of beacon that they received. After that, it's just a simple matter of doing a set section operation phones Determine Okay. How many of these things were received, right? We're actually by if people and then do some kind of either simple or more complicated exposure notification. To determine button the user. No. There are all kinds of different varieties of this type of decentralized architecture, and a lot of them kind of differ in how they do this upload of this list. Right? You might imagine that if you're looking at tens of millions. So users, you will have a lot of positives and then particular the downstream download cost. Four individual phones will be very high. So different designs do different compression strategies on how upload. This list typically generating them from a seed or several seats rather than uploading them all So This is roughly what we initially designed. Right got it by Google and Apple as part of their exposure notification, framework with the bunch of tiny tweaks that are mostly around how this works. Now now I want to take you back to what are the consequences of choices on on let's say the hardware infrastructure. So told you kind of this this this sort of blue sky kind of story, right? And you will just transmits some bluetooth beacon and all this good. Right? But now in practice, transmitting bluetooth beacon is a little bit hard Right? So we're dealing with phones that have to transmit these bluetooth to low energy beacon"
  },
  {
    "startTime": "01:22:02",
    "text": "But at the same time, we don't want or nobody wanted, right, to design an app that would drain your battery and one hour flat. Right? Because adoption is everything in these systems. And if would build a system that drains your battery in an hour nobody will install these apps. And this trickled down in many different ways. First of all, this meant that could really only use some kind of broadcast primitive rather than the connection because doing connections is much more battery intensive. Doing broadcast that really limits the amount of payload that you have in doing your broadcast because of B restrict so think less than twenty bytes maybe even sixteen. And because sending is relatively cheap especially if you're sending the same beacon over and over again, but receiving is not you might also not be able to measure very often. Now all of this, already, right, even doing that not measure very often and then being transmitting in the background all the time, rick wired modifications on the operating system level were not typically accessible to apps, which then means that the big mobile phone operating system manufacturing really need to be involved in order to to make this work, and this is what later led to this Google and Apple version. Patient There are bunch of other things that again framework. led to the same conclusion namely obviously, this absolutely to be running in the background which was not possible an ios at the moment, which means that apple need to make of stations. Obviously also want these apps to be compatible Between Android and ios, which was for some funny technical reasons not possible So again, this required cooperation and collaboration with Google and Apple to make work, And then finally,"
  },
  {
    "startTime": "01:24:03",
    "text": "In order to... For this this bluetooth rotation to work, we actually had to rotate this daily beacon and and bluetooth to mac addresses at the same time. Which again means in doing operating system change. And and so just means that even though the design initially was simple the fact that we were building on existing platforms really meant let's say a more interesting situation. Right? So what then Google and apple Did is to say, okay. That is a lot of low level operating system changes we're going to do is build a Google and Apple exposure notification Api, that will enable this tracing functionality what it does is expose a high level interface only. So I made a very crude sketch on the right. This my mental image of this, right their documentation actually has a lot more details But roughly if you think about the previous story that I told you, what goes in from the contact tracing apps is a list of these positive identifier or some keys from which this can be derived. And what the Api will send back to the tracing app is is this user has been exposed. So this is really a very high level Api that hides all the details of the tracing system. Now this has a lot of advantages. Right? If everybody does the thing that Google apple define that their that their Api does right to kind of automatically have interoperability. It also immediately ruled out some of the very scary centralized apps that we're out there and we're doing very privacy invasive stuff. At the same time, this this design choice right to to push everything to to an operating system level Api. We don't high level, interfacing rather than potentially lower level interfacing."
  },
  {
    "startTime": "01:26:00",
    "text": "Also really made it difficult to do more privacy friendly. Like like, there were choices that we would have maybe like to do different or least that the Initially proposed to do difference. That we could not do because this was not something that was supported by this Api. And and this is a story that that happens more often and right when you think about this this service based infrastructure is that really, there's sometimes things that you want to do that you cannot. There's also caused some other problems, right, is that For privacy reasons, the license terms of this Api then apps could not use location data, that could also be only one. Information. Now, a lot of these, right, and I want to sort of I want to be frank with this. Right? Discussed a lot of positive things in the sense that it really prevented a lot potentially of privacy harms at the same of time, is deployment contacts in which all of these apps were deployed. Right really meant that the mobile operating system people really had a lot of power over what hoo could not be done. In ways that maybe nation states or public Cal Now The other thing that I want to that I want to touch on one of them this one already briefly did, right is that. Really when you think about privacy, you really need to think about privacy at all I didn't really try to convince you that that the high level design gives you a appropriate privacy, but I think if you think about this for a little bit then Yeah. Probably just that seems to to to to mitigate most of the attacks that you can think about But once you start thinking about the full layering of all these things, not just the the the single protocol layer things really start to become iffy. Pretty quickly. Right? So if you think about these phones, these phones transmitting good to low energy beacon"
  },
  {
    "startTime": "01:28:01",
    "text": "that like, kind of said, okay, they're gonna rotate every ten minutes. Right? But Underlying this is a bluetooth stack that will have Mac addresses associated. It And so this means that if you potentially have an adversary that is listening in you really need these billy to rotate at the same time that you're rotating your Bluetooth mac addresses, because if you don't, you kind of have these things overlapping and so when one rotates, but the other does not you can still track people lot. Omar. Right? So order to prevent that really, you need to rotate them simultaneously, which then required actually Os level changes was not supported all phones, but really it it it speaks to how difficult it is to really get get privacy if you if you're considering the full stack. So just to to to to tell you one other story, right where her again, things become tricky if you think about this part of of the protocol right where once the user test positive they will upload the list of beacon that they have been transmitting any network adversary that is able to listen on, let's say, the wi network or the internet connection between these user. We'll see that this phone makes this very specifically sized upload to some positive test dot I f dot org upload endpoint, right, which means that that any network adversary that is able to observe this traffic even even if this is the elastic, Right Doesn't really matter, be able to determine medical information about users. And again, this is not a protocol level problem. Right this is a stack or old layers problem that one that needs to go ahead and solve. Now we did this by letting phones least in the Swiss context, right make dummy uploads that look like real uploads And they do this kind of regularly in the background following some random distribution which then gives"
  },
  {
    "startTime": "01:30:04",
    "text": "phones plausible the or rather use possible that I am Right? Because their phones are doing uploads all time and with respect to this network adversary. These things will be same. Then again, doing so will require our background processing that in in our case, right in the case of the content tracing apps was actually available but is not necessarily available So so zooming out, right, I just want to focus on three lessons learned, but if your interested there this communication of Ac paper that goes into a bit more depth and and mentions a bunch of others Three things. Right? First of all designing with purpose limited is really important to be able to mitigate all privacy harms, then the context which you deploy, right? In this case, mobile platforms really matters about what you can even also really matters about who has control over what you Canon and camera do. And then finally, when thinking about protocols, right, it is really important to think about all the layers on how to provide protection at all layers because any of these will potentially be able to invalidate the privacy concerns that have been able. To mitigate. And with that, I'm happy to take questions. Yeah. Tell me go ahead. Tony Poly Apple. So thank you very much for sharing this definitely good to kinda hear the whole analysis and these lessons I definitely agree. With all of these lessons. More of a comment than a question for the because the privacy being hit all layers least on Apple platforms, we also besides doing random stuff we are routing it through our private relay double hop relays for everything. To provide"
  },
  {
    "startTime": "01:32:00",
    "text": "kind Ip privacy. So this type of thing also is very good candidate. For combining with other the things we've talked about and para before. Cool. That... Thanks Tommy for for for the kind words. Right. So just to very quickly, jump on this, right, as we know from from sort of website fingerprint printing, right, click routing this by Vpn or private relays really helps. In the sense that will sort of take away the obvious site channel of doing uploaded It of Dot org with Covid related stuff. Right, but it might still the the size of this interaction or the timings of these interactions might still give away something. Right. So this is like like, doing Vpn or tour or whatever is not necessarily enough. Without also doing those. Depending on what your drug is. Go ahead. Hi. Guys Tyson h k Thanks for the fantastic presentation. I may have missed this, but I was curious how do you authenticate that a device is uploading Ids that self generated. So for example, if I observe somebody else's run my date, and I want to be a bit tricky, would it be possible for me to then upload that and then create false notifications for other people. What an awesome question. Still so there are two things. Right? One is there is typically no binding between the upload authorization as a whole. Right? So if I get an upload authorization code, I could in essentially, most systems I could have given that to you and then you could have done the upload instead Now the crypto though behind how we are compressing this list of beacon typically means that you need to notice c from which they were generated rather than the beacon themselves so you can actually not upload somebody else's beacon. Easily. Right? So you're... Like like, under collusion, this was still work. Right?"
  },
  {
    "startTime": "01:34:02",
    "text": "Which is just the same as, okay. I just give the key to somebody else, but but because hud you have to know the see typically in order to do that, you cannot sort of pick and match. Now the question is what are uploading somebody else's beacon would do a lot of damage right? I think the more interesting attack at that point would just be you're trying to broadcast a lot of beacon and do those uploads and that would be more effective than uploading somebody else's, but that is an interesting question. Cool. Thanks very much. Thanks Goddard. I had one question on the sort of the integration topic that you mentioned earlier. You're saying that the sort of interface that was exposed was kind of rigid and didn't allow you to use it in ways that you might like and practice passed by tuning different knobs in different ways for different outcomes. I'm if like if you could go back in time and perhaps work with the operating systems provide by different interfaces what an ideal interface would have looked like for this particular application. And moreover How would you how much you have construct interface a way that potentially couldn't be misused So like, one of the benefits of being quite rigid was that, like, not a lot of options to, you know, shoot yourself in the foot. So I'm wondering what your thoughts are on that. I I... Look this is this is very difficult. Right? Because because I think I I I I will second all of what you just said. Right? Like, guess it was good that it will that it prevented a lot of misuse. Then this rigidity also prevented a lot of applications. And so I think also hundreds more privacy friendly questions. Right? So one potential way that you could have done this. Is to have a much more lightweight interface. That would essentially have exposed beacon, for example, And so have pushed a lot of things onto the app and then to"
  },
  {
    "startTime": "01:36:00",
    "text": "to use other processes to potentially prevent these now I'm not saying that any of these are ideal. Right? Like like like, it is sort of like, a little bit of a golden gauge. Cage story. Right? Like Like this oversight process that was in place, right it was in many ways very rigid to probably prevented a little of harm, but might also have done harm by being there. And and as with always these things. I don't think there is an easy Unfortunately, there is not an easy answer. Yeah, for sure. I don't mean to suggest there is a correct answer. Right it's the end of the day I pile trade offs and I'm just wondering how you thought about those trade offs. After you having been on the other side of this particular project but. Anyway, thank you very much. I think in the interest of time now, we'll move on to the final presidential station, which will be driven by Alexandra. I don't know if she is here or remote. Okay. Hello? Hope you can hear me. Yes. We can hear you fine. It looks like you've requested to share your screen. It's It's perhaps simpler if you just request to share your slides. Okay. You. No no. Sorry. Go. No You have access now? Yeah. Cool. Sorry? You... Yeah. We can see your slides. I think you're good to go. Alright. Okay. Give one second. Okay. So You can hear me rich. Yes. Okay. Great. Yeah. Thanks for having me. My name is Alex. I'm from Germany two Branch bike and I'm a fellow at send. So today I want to introduce you our paper. That's called block because strengthening certificate transparency against covid and. So something completely different. And it was published twenty one of pets Okay. Let's start. Yes. So Https is kind of a default nowadays. We could say because"
  },
  {
    "startTime": "01:38:04",
    "text": "I think last month, about ninety six percent of all page loads in k served using Https, so we can kind of see it as being a default. The certificates that are needed for Https in the handshake are issued with certificate authorities. So the certificates are used to bind the domain to a public key to specific public key. To the marines owner. So we can say that certificate authorities or are kind of a trust anchor of the eye. And guidelines on how exec certificate should be issued and the whole procedure and the acceptance of browsers offer certificate authorities are mostly discussed in the C browser photo. So consequently, the number of illicit certificate creations is increasing of course. So just to give you a short all of overview, These are some certificate authorities that are known for some certificate creations like Musa. It's just here. They created certificates that were or did not report loan incidents or like trip trust quite critical one. They created an intermediate certificate instead of a regular one. Is crucial because the intermediates are able to create further certificates. Or signed for the certificates. Or let's say in malaysia. Digital you search the issued certificates which we critical rough. So the list of such kind of incidence is quite long and quite old. However, all of these issues were mostly of technical nature. That means there are security vulnerabilities or some infrastructure vulnerabilities leads to this illicit certificate equations. Properly. Okay. But let's assume quite strong a checking model which tries a strong attacker that tries to obtain a more certificate."
  },
  {
    "startTime": "01:40:03",
    "text": "And A road certificate one that you chain for a domain that you do not own. So this is what call to work certificate. This kind of attack is called Https and a government, which I would assume to be a quite a strong attacker because they have a lot of resources. There are attempts from different governments who try to make Https such legal. Like, I think most of you know okay. So Kazakhstan or last few Mori you was also try to make it legal to make https to So most of those states are let's say states without weaker commitment to democracy. So the browser vendors in this case took action to protect the users five, for example, blocking the government based certificates. But the question is should be attacker stop at this point. If it's not possible to do it on a legal way, and your take to quite a strong figure so I have a lot of resources. So I should just stop here Okay. So let's get back to the taking model. In two thousand seven, R and D introduced the cover that was taking water. So this is anywhere between a malicious attacker and semi honest or on both Courier are taking order This just a take. He behaves completely is not bound to protocol. While the semi model that follows the protocol, but this quite so try to obtain as many data as possible. So the current is anywhere between those two models, And the goal is or to obtain data into tick only if the attack remains undetected. Even after the past. So The next one is the cope certificate creation. This is an a undertaking scenario that wasn't introduced in twenty ten. So We have a really strong attacker in this model"
  },
  {
    "startTime": "01:42:03",
    "text": "or the scenario who is able to compel certificate of authority you'll omit the ownership check. And the ownership chip check is what Have to do before issuing certificate for. So they have to ensure that the domain is belongs to you. Okay. So you get back to our scenario. We have Really strong attacker who only succeeds if he's able to create a look certificate for domain and their tech remains a unnoticed, but he legitimate the main order. Okay. So the notification for this time to protect the p began two thousand twelve by Ben lo, at all was called public certificate creation. When the goal was to force these certificate authorities to publish all certificate issues in any will public weight. So really really short primal certificate transparency. Let's say this is the infrastructure. We have domain on on this side. And we have a certificate authority on this side. So certificate authority issues certificate behalf of the main owner. Just red one here. And This certificate authority wants this certificate to be accepted by each capital roles, of course. So it needs to published certificate to any kind of law I mean, that means that since this certificates to one or more favorable looks. And after that, now it needs to approved for this process. So locks back something that is called an Std. You can say this is kind of sign promise from the log to the C that's certificate will be included in the locks mercury tree This is how the logs are working. And it's Miracle three within the next twenty four hours. So now the c can just send back to you the main honor of the newly the new certificate and the proof and the domain owner accounting kind of develop the website using https with a certificate and the s."
  },
  {
    "startTime": "01:44:02",
    "text": "So... And since he also introduces two additional parties. The first one are the auditors. The are mostly third parties. And their goal is to check whether all the logs comply with the requirements of the Ci phone That means something like the uptime and complying with the s that deluxe senate and stuff like this. So it's not main demand dependent. And the monitors on the side, These are also mostly opt in services of third party service mostly by. And their goal is just to in behalf of the main owner. Check all the locks for exactly this one the domain. Whether there are some rogue certificate existing. So the monitoring service is dependent. One that the are not communicating with the other. Okay. So we claim that certificate transparency is still vulnerable. And also after the people was published twenty twenty one. Came this is still the case? Because until today's date, now we're about thirty or forty such certificate transparency logs that are using works acceptable by browsers, mostly in chrome, of course. And all of those clocks belongs to odyssey. Or to the same vendors. So We can assume that taking a C or controlling equal to a taking or controlling one or multiple blocks of the C and most of the Css multiple blocks And The first compromise of a lot, I think was in twenty twenty. It was a assault illness, so it was a technical compromise. But well, the shows that yes, looks are same vulnerable ses as well. And other followed after that. Yes. The collaboration attack, which can be or which is the attack that we talked about previously so this attack from a covid advisory"
  },
  {
    "startTime": "01:46:01",
    "text": "a or forcing your stage with the ownership check, is also defined in the city threat model. So the Rf exactly defined the straight model and still state this problem to be an open problem it not solved today. Until today, Of course, we can say oh my god. You need a really strong take for that because you need someone who's able to control some heart of of the sub network in its country. For conducting a Gps perception again, we are talking about strong take look governments and especially today, there are a lot of governments for who could possibly be able to do that. So there was some work from the of two thousand eight who explained the kind of to have a really low probability because it's hard to collect them, but a quite high impact because you're able to make A reception on like on whole country or or a specific sub of a country. So one of the possibilities could be if you chinese this kind of. Certificates cases to peer split to your. So probably most of you remember the split from this option thing like that. A really short primer about split. Locker a tree and the lock can create two different views of its own work tree. So just one view here. The view will be served to monitoring service. And the red certificate, which our created previous is not included in this in this view that means the money tour who is watching for our certificates in behalf of the real do we all alone? Cannot see any kind of attack because well there's no wrong certificate. On the other hand, malicious law can create a second few, which is searched to be auditor because the auditors know about the about the scientific certificate time. And the red certificate is included in the stream."
  },
  {
    "startTime": "01:48:01",
    "text": "So the articles who only checked the technical compliance with the with the requirements. They see okay, there is direct certificate certification in certificate. Is fine. And they don't know who the main owner of the possible certificate are. So is no check for them. Okay. So this is something with this view. A quick reminder how our certificate transparency infrastructure looks like. And there was the mitigation attempt for exactly this kind of attack, which is called gossip it. Well, go is really complicated. So I don't want to go too much into detail, lots gossip involves anyhow almost each. In this small science infrastructure. So also the client of the user and also the web service So the clients collect the s and suddenly a back to other parties of this infrastructure. And by the way, reach a lot of the browsing Right and history just way. This is one of the was critical points on gossip and because it's really complicated. So All the participants are communicating each each other and this way, of course, the old tours and the monitors know about which kind of as keys are in this infrastructure, but we'll Gossip is a draft since two thousand fifteen. And even if the certificate transparency r requires all the participants and this infrastructure to gossip the Rf gossip a six expired since two thousand eighteen well because it's not really feasible in the way the Internet or the Web works at the moment. So the question is why I can't produce and I'll introduce any further trusted parties. You are doing any kind of auditing or ever... Well, because it's not working. You cannot just shift the trust from one party who could become malicious to another party. It's not"
  },
  {
    "startTime": "01:50:04",
    "text": "working. And one of the vendors of City and ben Lori also said that fixing one set of trusted parties introducing another doesn't seem to be a step forward, and I would really agree that. Okay. So Got pickup. We thought the about how to think of some kind of another approach to this issue And what kind of goals do we need to do? Or kind of an extension for certificate transparency or whatever. So at the beginning, we just talk about the desert route. Had some security security goals in advance, which first off was, of course, mitigation for this kind of collaboration attack for one Malicious C and one possible more City logs. The next one, we wanted to have more witnesses in the whole certificate issues process. And oh, by the way, we also count that publication of the certificate in the lock is also part of the certificate issues process. And we counted that. So In this malicious case, only the C in the emergency logs and possibly the ro taker knows about the existence of the certificate. For the beginning. So we wanted to involve more weaknesses on an way the beginning And of course, everyone, also the witnesses should be able to prove that this certificate exists and not only the also parties. And well monitoring The first project is this is still an not in service so it's mostly used by high level domains like Google and facebook and stuff. And monitoring also just happens after the fact after the certificate was possibly issued So we wanted to be able anyhow to involve monitoring service on the earliest state of the issues process. And further now, we have some design goals. The first one, of course, don't well any user data"
  },
  {
    "startTime": "01:52:00",
    "text": "like the ro history of the user to enroll in this protocol like case of gossip. The next one is we don't want to web service who searched the websites to need to change anything on their default behavior because well, we know that they are not good at the adopting change the bit. So Incremental deployed you ability. I think this is one of the reasons of the success of certificate transparency because They hip kind of flag, which means that each web server will have to change their behavior, like, from from tomorrow because the new changes will takes place. So it's kind of incremental process to deploy the new And we don't want any new or and trusted entities because the whole system was completely complex. Of course, it looks quite easy on my slides, but this it's horrible. So we don't want to to include any new entities to the whole process. So again, a quick reminder on how the infrastructure on Ct looks like at the moment. And this is where we end up. So the first changes maybe that you can see is just clustering and this petrol L So the clustering instead of the certificate authority contracting its favorable locks Instead, it context one specific lock from a list of locks. The law can also be malicious. It doesn't matter. So the looks, on this list, the looks that the browser is trusting. So this is at moment also this policy, which exactly files which logs are trusted. So from which locks the browser accepts S. So I will say it contacts one lock out of the slots and the other locks form together something like we call lock pool. So Exactly. And the other one is to prove, which I will explain in detail."
  },
  {
    "startTime": "01:54:00",
    "text": "What you may also can see that the auditing service is missing here Will come to that earlier later. Okay. So in first step, I was here chooses to lead a lock. Doesn't matter who is This. Just one lock from the list. It also can be it's Malicious lock. It doesn't matter. And on the second step, this leader context the whole lock pool. Because to this list of the browser public, the leader lock also know which other locks are on this list and This altogether, the form kind of a lock pool. So the leader context each other participant of this pool And from this all kind of three long protocol happens. That means that the pool collaboratively select one lock of the pool by random. This is a randomness protocol. Yes. So at least one sp well all this cool. The randomness is true. That means From this point on neither see a nor possibly malicious leader look can influence the log selection. And the one lock that is selected from all of the logs. Is in charge of including the certificate in the smoke tree. So at this point, the chance to get a malicious lock being in charge to include the certificate as really, really low for a possibly malicious C or possibly emergency lock. Just you have about five more minutes. Five five six? Yep. Yep. Yep. Considered. Okay. So and from this point on we... Each lock who participated in this protocol round can sign kind of a proof. And all the proofs are aggregated and attached to the certificate This is what we call the Lp. So this is an aggregated signature, which also cap of includes the proof by from each witness who participated"
  },
  {
    "startTime": "01:56:01",
    "text": "and can also be attached to the current data which is the certificate in the s. All the stuff sent back to c. And the C sends this back to the user, which can then kind of deploy the website and using this new material on the same way as just happened like, the moment. So... Well, on the side the chief months. By randomly selection of the lock. This is the mitigation for the malicious tech talked about earlier. We have a lot of witnesses and the witnesses can also prove the participation and they can also prove who was selected in the round for including the certificate. And up from the second round and when each of the locks gets the request, but you leader hey, we want to make a log around for some specific domain. At this point, from this point locks could also contact any kind of monitoring service like, hey, there was attempt to create a certificate for you or domain just just in case you interested. Well, we have no use that because nothing changed. Regarding the data. The web servers don't need to change anything because it's same like in. The web service just get this material from the C. I don't care about the allot approve Is this an necessity or certificate whatever. So nothing changed. And the save for the incremental deploy capability. Also the same way like Citi because the browsers can kind of deploy transition phase when lock would be like, optional or would be mandatory. We have no new trusted entities in addition because the locks are trusted anywhere. Anyway, but it browser, so they have this school. Exactly. And we don't have even only tours because the locks can make the auditing service themselves. And well in the paper, and we have some additional things like we have a lot of crypto primitives, which I explained in the protocol goals"
  },
  {
    "startTime": "01:58:02",
    "text": "and of course, the analysis of our achievements. Prob and analysis of the correctness of what we call the lp based p eye the t based I and the gossip and based with the comparison. And then we are discussing the certificate transparency policies and what should be changed for Log, We also have a prototype simulation of possible log based pic item. Well, and to get to my point, Course, the outlook we have to think about how and when could we include the monitoring service the Inter auditing which is a kind of important thing because the the locks know that certificate was issued. So they could automatically after twenty four hours. Make the auditing service by themselves. Because the know, which lock is in charge of including the certificate. So how can we include this process? Afterwards. Of course, we have a lot of critical awards and we to think about how to handle it. And well relocation of certificate is horrible still, so maybe it's possible any anyhow to include vocational of certificate in log pick protocol. Okay. So me thank you for your question. And I'm for attention and I'm opening two questions. Yeah Thanks. We're really short in time. I do have a question but I wanted to give someone else the opportunity to ask a question just in case. Okay. If not. So I guess first to clarifying question. So the way I understand this design, you fact from this pool of logs, you you you basically run some, like, election protocols or to, like, pick a a a random log effectively to sign the thing. And that's that's how you work around. I potentially, like, malicious log. Otherwise, I trying to support the system. Is that correct? Exactly. We just have a three round little electric protocol and the readiness"
  },
  {
    "startTime": "02:00:03",
    "text": "call combination to ensure that malicious lock possible malicious litter or our m C can influence the selection of which lock is in charge of including the certificate and it's more. Okay. I'm wondering if you looked at, like, perhaps alternative solutions that were based on, like, threshold, like, crypto system. So for example, say, rather than just signing by one log, you just require that you know, some threshold number of log sign and then under, like, perhaps a quite reasonable assumption that not all of these randomly chosen logs were including that the system would have the desired properties that might require other you know ecosystem changes. Of course, like this is a different type of signature, but I'm wondering if you looked at that is an alternative design. Yes, the signature that we're using at the end to for for the for the certificate proof but which witnesses. At the moment, like for the paper, we need to we took your less multi signatures. But we also discussed in the paper that we need to take a look on how exactly or what kind of single should be built at this point. So the crypto geographic technique behind whether this is a threshold signature or super sure. It doesn't really matter because the protocols self, the the lead lecture face is important. So this the the signature which comes out at the end, this could also be threshold signature. I know that's my car who has more the crypto guy, he was also discussing to a lot of people among threshold signatures. But these are the details, which to use because the paper is kind of I mean Like like abstract you on how this kind of protocol be could be made. And yeah, proper details would be the next step. Probably Understood. Thank you so much."
  },
  {
    "startTime": "02:02:01",
    "text": "For out of time, this is the end of the session. So thank you again for coming and presenting. Thank you to everyone who joined us Yeah. And thanks to matt taking notes. Appreciate it. Thanks especially to our European presenters like, it's pretty early for them. So Thanks for the few. And and I think anyone anyone's working on certificate transparency, I'm sure Alexander would love to talk to you. See next time."
  }
]
