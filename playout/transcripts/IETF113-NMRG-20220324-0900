[
  {
    "startTime": "00:00:24",
    "text": "now hello welcome everyone um it's time to get started uh so uh it's uh one of the first meetings we have in this context with uh both on-site and remote participation so please bear with us as we learn also through this process uh german myself quite sure we are participating remotely and we have so-called local backup diego lopez which uh you can see in the room sitting uh next to the screen uh so in case um there is some issues or we need to handle anything happening in vienna um we will rely on diego for that um but the meeting will happen in mythical uh see that uh everyone is connected here we will use the um uh the queue from the from miteco so uh and we will synchronize um with the queue in the room so this is energy meeting for iitf 113 and we need to go through a bit of not well slides before we go into the agenda so intellectual property the iota follows the ietf interdictory of intellectual property rights disclosure"
  },
  {
    "startTime": "00:02:00",
    "text": "rules so by this we mean that by participating in the rtf you agree to follow iotf processes and policies so please be aware of the different provisions that are in this slide and if you want to have more information you can access the link which is at the bottom of this page to have further details for audio and video recordings so the iotf routinely makes recordings of online and in-person meetings including audio video and photographs and publishes those recordings online if you participate in person and choose not to wear a red do not photograph lanyard then you can send to up here in such recordings and if you speak at the microphone appear on the panel or carry out any official duty as a member of iotf leadership then you can send to appearing in recordings of you at the time if you participate online and turn on your camera and or your microphone then your consent to appear in search recording recordings privacy and code of conduct so as a participant in or attendee to any itf activity you acknowledge that written audio video and photographic records of meetings may be made public personal information that you provide to iotf will be handled in opponents with the privacy policy that you can find at the following link as a participant or attendee you agree to work respectfully with other participants please contact the ombuds team if you have questions or concerns about this you can find the link in the slide and you can also refer to uh the two rfcs concerning code of connect and harassment procedures which also apply to the context of the rtf now a slide on the goals of the rtf so to make it clear the iitf the rrtf"
  },
  {
    "startTime": "00:04:01",
    "text": "conducts research it is not a standards development organization the iotf focuses on longer term research issues related to the internet while the parallel organization the ietf focuses on short-term issues of engineering and standards making while the irtf can publish informational and experimental documents in the rfc series its primary goal is to promote development of research collaboration and teamwork in exploring research issues related to internet protocols application architecture and technology if you want to have more information about how to participate and work within the rtf you can access this rfc and rtf primer for ietf participants so thank you for your attention for this introductory slide and now we will start officially let's say the content of our meeting uh just before uh going forward online meeting etiquette uh so be aware that this session is being recorded uh please keep your audio muted and video off when not presenting or speaking and when's thinking please start by stating your name clearly it's very important for the meeting units and for the audience thank you in the slide but also in the meeting materials you can find some useful links to access the material of the meeting we will be taking notes on edge talk we are using mythical and the recording of this session will be available on youtube the ietf channel very soon after the after the session before i go to the agenda anything too hard on your side or i can proceed with your agenda thank you okay all good so um for today we have a two hour session uh we are currently so the agenda we are"
  },
  {
    "startTime": "00:06:01",
    "text": "currently in the introduction and rich research group status uh we have a couple of additional slides uh in this presentation uh we will make a status on intent-based networking uh in this session today we will not have an in-depth technical discussion on intern-based networking but just sharing a status then we have a ai for network management topic where jerome will give a status on the progress made on the document for research challenges in artificial intelligence for network management the main topic of discussion for today will be network digital twins we have provisioned enough time we hope to have an insightful discussion on this emerging topic and we will have several presentations the first one will be from jordy and albert about how to build a digital twin comparing different approaches to that really looking forward to this presentation then we have also uh from shang on behalf of the other co-authors um a presentation on the draft on the research group draft network digital twin concepts and reference architecture and this presentation in the slot we want also to um as a research group uh to reflect on this notion of network digital twin and what research could be associated to this topic so the problem space research challenges questions and directions and in support to that we have also shared on the mailing list but also on the hdoc we have a set of let's say questions to drive the discussion and we welcome your opinion on on those questions finally uh according to the remaining time we will have there is also another topic we would like to uh to have input on is the evaluation of cooperating layered asean architecture"
  },
  {
    "startTime": "00:08:01",
    "text": "to include compute and data awareness and lewis will be making this presentation this will also serve as a reflection on the so-called class so cooperative layered asean architecture to understand a bit what would be the further development of this topic in analogy or beyond energy any comments from the participant on our agenda okay all good so let's continue um so in the research group stages we have a few updates on the progress for our documents so in rnc poll we have the intent-based networking intern classification so the irg member needs to express their view on the document this poll will end april 14 14th so it's coming pretty soon the next step will be to if this is positive to proceed towards a ietf conflict review so this is progressing towards rbc publication the second document second document is in rsg review so this is the step just before the rsd poll it's intend-based networking concepts and definition this is still under progress we received the review from the irg member and this is going through interactions with the co-authors to address the comments and then be able to proceed we have also recently adopted research group documents digital twin network concepts and reference architecture so we will have also more insight on this document during the technical topic later on in this session also you may have seen on the mailing list we have started a call for a research group document adoption for the document network measurement intent which is one of the ibm use cases of nmrg"
  },
  {
    "startTime": "00:10:00",
    "text": "the call for research group adoption will end april 8th and we welcome your insight on the let's say value of these documents and if it is ready to be considered as a research group document any comments on the status for this argument if not let me continue as you may have seen in the agenda for the topic on ibn we will not go into in-depth technical discussion but we wanted to show that this this topic is also progressing in a number of other groups beyond irtf and ietf and that there is more and more also standardization open source but also uh research activities on this topic and this is just let's say a a broad overview it's not exhaustive but we hope it's still uh important for the community in energy to be aware of those uh of those other activities and some of the research group participants are already well connected to some of those activities so we expect also to have collaborations in those contexts so what we have uh for other groups in 4r in the linux foundation the onapp project where there are several ibn use cases being developed and part of the different honor premises the link provided you can see let's say it's an overview of the different intent-based networking use cases appearing in the different releases and by browsing on the on up wiki looking for internet base you can find those different use cases and more details about who is involved and the exact topic but it's interesting to see that since several years onap is continuously pushing to have intern-based networking use cases also"
  },
  {
    "startTime": "00:12:00",
    "text": "being part of the technologies developed in onap in in etsy the zerotouch network and service management isg and hello uh i'm sorry diego has been recently i point as a new uh chair of this isd so if you have any questions on this group you can also turn to diego but there are a couple of activities also in this isg related to intern-based networking so there is a group report uh group report 11 which targets intern-driven autonomous networks it's a study to try to understand the different definitions uh techniques and mechanism of intent uh driven aspects in relationship to zero touch management and this document is uh triggering a lot of interesting discussions so i invite you to to try to read it it's a part of an open open draft it's publicly accessible and there is also a proposal for a proof of concept on automation of intent based plus lead line service this is proposal by members of this isg about using the zsm specification in the specific context of intern-based clause line service in the itu you have also a focus group on autonomous networks and in this focus group there are a set of activities which include use cases or poc also related to intent based not all the activities are related to internet but you can find a few of them and um the main document you can find is uh on the poc and proposal for builder tone where you can see the latest teams willing to propose activities related to that as part of the focus group activities finally you have also the at the tm forum autonomous network project"
  },
  {
    "startTime": "00:14:01",
    "text": "they have an interesting set of documents uh addressing specifically intern based networking uh so for instance uh ig 1253 uh intent in autonomous networks you can find the latest draft it's you just think i think to have a login on tmf to access it but it's also part of a broader set of documents which i will quickly show and this is an interesting development because they have as you see several aspects they really want to specify relate in relationship to intent so the document i was mentioning is the one here in the middle but you see that they want also to go into more modeling aspects different capabilities api development etc and this is ongoing activities as part of this autonomous networking project which i think is a very interesting development more on the say uh events or research side there are also a number of um activities ongoing again this is not exhaustive this is just some information i like to share with the research group so there is a second edition of the workshop on intern based networking that will be in conjunction with ieee netsoft in june in italy this year and there is also a plan to have a dedicated tutorial on building use cases based on the tmf specification for intel that i just saw before so i think this could be an interesting experience for also researching participants to really have a more practical use of intern-based networks also more and more papers and special issues in the literature again this is just an extract of some of the recent paper essentially published last year as you can see different special issues in different um different journals but also some articles either survey type of articles"
  },
  {
    "startTime": "00:16:01",
    "text": "or dedicated approaches for a global view on them on intern based networking so i hope you find this information useful of course everything is available offline if you want to have more insight on those on those documents and finally um for for this part of the meeting an emergency research group stated future meetings um the main thing we will have upcoming will be let's say a series of interim dedicated meetings especially for follow-ups on the intern based use cases we will have also currently discussing with some of the research group participants and beyond about proposal for dedicated interim meetings on specific topics one is about designing deploying and operating distributed ais we have received a draft on this on this notion it's also linked to the ai document there could be also two interesting projects so we are trying to see how to organize something meaningful proposition from the research group to have a good discussion on this topic um we will see what will come but we try to have something before the summer uh on this in the next let's say um plenary meeting uh currently we plan to go to uh the next ietf but this remains to see the feasibility okay this one you should have skipped it and that's it jerome i think uh you'd like to take over now yeah so if there is any um comments or questions what you're presenting before we continue"
  },
  {
    "startTime": "00:18:01",
    "text": "if not yes i will continue okay this one okay all right um so yeah the next um um next item on the island was to give you a status up with the um document regarding the um ai research challenge uh for network management um so um i i i will give you an update and from the previous um previous version that he was was a version three um so i know that this document was here for a while we so this document just maybe to to to make it clear for uh uh is a shared document that we work collaboratively but it's not uh it is just a google document actually um we we thought that it was better to work on it um so approximately what i would say is that not exactly one year ago but almost one year ago we decided to first freeze the challenge the challenges where we want to document in this document actually this was a temporary freeze because of course we are not saying that we will be exhaustive to have whole challenges because we may miss some some of them there will be news that can also came out"
  },
  {
    "startTime": "00:20:00",
    "text": "due to some context and so but at least we wanted to freeze it in order to really progress and because at that time we have some bullet points for challenges we have some idea a lot of ideas actually but not something very strict so we have presented this list and then we have asked uh some particular contributors we were quite willing to to lead the first with me to try to consolidate all the input we got regarding the different challenges so we define templates that you can see basically here we try for each challenge have some motivation a very quick state of the art not uh not a big in-depth survey but at least the quick uh survey regarding uh the challenges and in patera twilight what are the remaining problems because in many cases we have already tried to use ai for the challenges it works it does not work well and so on and try to highlight what i mean the remaining problem and maybe some really recent results or orientations that we could investigate um tobias i think it was very quite successful because we had a lot of challenges that were well documented uh so i really want to thank uh to thanks all the contributors here let's say editors that helped me to put that in the more let's say a nice way at the time we have we had let's say quite um let's say detailed description of the challenges with a lot of references and it was very good to to structure a bit of the id that you put behind the challenge we have only two challenges what we didn't had really input was one what's about the acceptability but actually it's what i will call meta challenges because we have some sub challenges that are also related to acceptability i don't think this is a big um the big issue and one is about the email in the loop i think we had a lot of discussions that we need to have the human into integrity with ai even in our domain for network for property network and we actually have not really um"
  },
  {
    "startTime": "00:22:01",
    "text": "we did not really describe one of these challenges at that time and still today so based on that i worked to prepare the four questions uh i recently prepared to be honest um so here you have the new link uh the idea of this v4 was of course to go over all the document and try to again consolidate it so before after the previous pass we have only we have challenges which are well described but of course it was description per challenge so we need somehow to to polish it to have something more current or as a challenge as object was also starting to identify maybe some missing parts some missing challenge that we would need to integrate and also try to also to identify some key people or actions that we'll need to progress in the document if we know somebody is maybe an expert in this area maybe you should reach which to help us to elaborate the document and so on so we try try order to identify some people um to to to help us um so this is uh what has been done from this v-formation i will go a bit more into the details um so here was the initial list of challenge that we have that you had in v three so version three so maybe as you remember we tried to categorize a bit of challenges we had four criterias one is more related to problems that relate to the uh ai technique itself uh saving other world it's when for example we need to really work on the algorithm of method api to fulfill the needs of a network management problem a challenge we have we have identified a lot of problems looking to data access to data or to present data in a relevant way for of needs we have although seen that"
  },
  {
    "startTime": "00:24:03",
    "text": "our maybe our domain is that we also want to you many cases want to use ai not only to to to predict some value and so but also to really take decision or at least guide or help in decision or take actions does this make a bit the focus is the constraint a bit different and also we had a lot of discussion at uh regarding accessibility why we should why what would be the the obstacle to to use ai for let's say operating networks a lot of issue we are used to to have all procedures we cannot also we don't want to let's say let an ai automatically uh around the network and so forth a lot of discussion of course a lot of uh we had we had this particular let's say criteria of what i call it a challenge but i know that's not a good term anyway so we have this list as you can see here are challenges from like the yti data management and so on i will not go for each of them of course it's not the goal here um but after the reviews what i call here the review basically the review of the three from b3 to v4 is that we just observe that many of these challenges which are the let's say the first column here uh mostly are related to a single let's say main problem or let's say with a of course for instance you can it can be the challenge may be somewhat due to some primary data maybe ai techniques but anywhere we put that it's uh it was still as you can see here we tried to somehow evaluate each other it was all quite very focused and it does not really make sense to to try to to let's say to to first the challenges to be let's say multi uh criteria maybe it's good just to say we focus on what is the main criteria that characterize the challenges and we'll try to organize a bit of document regarding that"
  },
  {
    "startTime": "00:26:00",
    "text": "and um although for the let's say ai for anim actions actually it's mostly related maybe to the ai technique that would run behind it's some kind of a sub let's say a sub level of the ai category so this was the our understanding after this between this uh let's say internal reviews that we did and um [Music] so very key it it turns into a new talk a new table of contents that you can see here on the left and on the right side is there a previous tag what is really important to see here is that in previous document on the free version we got this list of challenges which were actually a big table where we have one rule per changes we described and though we just um really a structure a bit based on the different let's say categories so more morality to the ai techniques that we will need to that needs to be extended to be worked on and for network management and here you see a list of five programs that comes basically to the to the challenge that you had before one refers to the uh problem of how we can um precisely define a network management program to be able to find the right uh technical right set of techniques we could use uh i mean ai techniques you could use to to help us one is regarding oh we evaluate the preference of produce model not only from an ai perspective from if we include some net let's say network specific metric into the a algorithm itself and there is all we can email ai include network or we can use ai to really um the challenge of using ai for planning uh actions uh for uh operating network uh not only distributed ai i will um i will go back to this a bit a bit after because we don't have actually we have it just as a"
  },
  {
    "startTime": "00:28:00",
    "text": "placeholder now but we don't have a challenge really well described here then we have all the things related to the data say that i've driven the data in ai that we need maybe specific data in our case or we collect data this is also program it's not only on using data to get data to extract knowledge uh to share data maybe these are all of that now included in this part and then we have the acceptability of ai how we can explain what has decision of network a products or we can ensure that when we have an ai or prototype working in the lab environment we can what would be the challenge is not to be sure that it would work in production system or let's have some gravities so now we have these new big big parts three four fives here that basically contains all challenges um then you can see that we keep as uh the main section of the section that will describe some very let's say what you call difficult problems that you're having network mirrors that could rely on ai not uh not always but that is that could be a good uh good potential problem that you should investigate with ai but what you can see what you can see here that's also some other let's say this structure has a bit simplified to keep worries or focus on the equipment on the challenges itself so for instance um except of course what i call what i have described now with the respection of the challenge uh we have removed some parts we don't have any more use case parts um so to maybe to recall it has never been an objective for this document to list some use cases and to have to detail some use cases and we really insist before to not fill out this section before we are satisfied with let's say a description of challenges and i think for now it we could even skip this part we don't have need to have this use cases at that time i think to have so the id now isn't about to go"
  },
  {
    "startTime": "00:30:01",
    "text": "to a more uh to reach a let's say a first level version we don't need use cases we have a lot of content that which i think is really valued and very valuable so we assume that we should keep uh at least for this first level version of norfolk use on the challenges itself anyway we have some let's say when it's got challenge we give some illustrative use case of application of course it's not detail use cases so we still in the document it's not completely it's a theoretical we still provide some some example to highlight to show to explain the different challenges so we still have some more in line with the challenges but not as really detailed use cases with detailed procedures and so on it's something that we think we don't want now um and also for directional recommendations somehow this will be a kind of another document i think if you want also to really give and it's a very specific orientation to to address this challenge or this challenge will be will be nice but i think it's also it would be a bit uh he will be losing focus of the document sorry i want to keep the the focus of the google commands on main scope which is our related challenges and maybe later we can of course add extension but at now i think we have a lot of content that is really valuable um okay of course we have known an introduction that the idea is to show that we um that the ai we cannot uh we cannot say we will not use ai for network management it does not mean that we will use ai for everything network management but somehow it's something that we cannot avoid that we need to have it and that is we highlight that with some let's say program that very briefly and because we have a dedicated section for that we try a little bit to disambiguate between ai and machine learning here the issue that most of challenges to be"
  },
  {
    "startTime": "00:32:01",
    "text": "learning in mind so uh personally i try a bit to make it more generic it's not always uh easy because maybe some are really still very machine learning oriented i think it's not a problem but at least nutrition try to a bit uh let's say um [Music] uh disambiguate obviously that we have it's not only about machine learning there are so much homogeneity challenges that can be let's say um applied to different ai fields or there are more let's say oriented to machine learning so we try to i like that i think this is not uh we are still reviewing this part to be honest and i hope that we come up with a nice nice nice version then um we have this section about the difficult products in network management so previously we have a list of basically bullet points we have a lot of problems that uh i think it was covered in documents so everyone put bullet points and then we try something to organize a bit uh this uh this is a difficult problem so i didn't have to give an exhaustive list again here's to give some examples that we could use maybe when you describe channel and then so we try to categorize them according to five uh five criteria here as you can see for example one is about the very large solution space this is can this can help to characterize a difficult program some is related to uncertainty appear on unpredictability of what will be the environment or the context your assertion will be applied some can be some or um guided by the need to deliver solution in real time or there are a problem that already depending on data of course when maybe you will need to analyze atr from different problems and maybe if i'm not i'm not personally a very fan of that if that is about the um the need to be intermittent you mind processing i think this is not really a"
  },
  {
    "startTime": "00:34:01",
    "text": "this is not a something that comes directly from from the problems you want to tackle that you need to be integrating the human process just because it comes from the procedures that you are not the problem that you want to take so this is something that is more let's say a constraint that we had on top of or let's say our solutions but the problems you want to to achieve for example here we have some example then below like a computation of optimal classification of network traffic if you don't need humans it should be should be something possible of course if it's not always the case but it's not let's say a constraint that comes directly to the problem to to so of course now we have only two problems which are let's say described in a more let's say a textual way uh we have this list of bullet points that we still have in the document so the ideas that you would uh also take some other and we'll try to detect them as well in this section so what remain uh what mostly remain because i would say that there is the first issue regarding the humay in the loop challenges um you see the current description is very lightweight it's what is uh what is in italic here so i is the question is should we keep it or should we um some or omitted in the document um okay uh they said we will not this is the goal is not to provide a full list and exhaustive list of challenges um somehow somebody's looking to come out nor these are new organizations for each let's say big category we have a kind of uh introduction for each challenge related to ai technique we have an introduction trying to give a bit the scope of this uh all let's say sub challenges and the let's say your human subcharge will be part of let's say ia techniques probably that that's most integrated as a human so it can be somewhat in putting the introduction um but of course if you want them to"
  },
  {
    "startTime": "00:36:01",
    "text": "learn more let's say uh this detailed description will need uh somebody here in the room from otherwise that could help us in that uh from my perspective i think uh we we have a lot of discussions there are a lot of contributing distributed ai but we didn't really use the document i think it would be essential for us um so being in my opinion we should need to to a bit more despite this part as well of course then you have a lot of other let's say editorial parts we need to complete introduction conclusion and so on we need to reference and so on um so the ideas that were then to i know that i already promised a bit before to transfer these google documents let me give you a draft something that is just in my mind i hope that you'll be able to to try this music document and i created with everything really for me uh also all to progress now so uh to know we have lost a lot of contributors it was really great we had a lot of the id no i i would like to go with a smaller equatorial team uh to be with maybe more let's say a focus team really working on the world document not only on specific challenge to um uh to uh totally uh do this let's say uh to do all the editorial paths to all music elements and so on and to i think it would be very important so as we already discussed we can put all contributors out towards the draft so that we need also to to to to to restrict the list to some this low number of people and of course all contributors will be listed uh as contributors and acknowledgement sections for sure um after the review of the document this is a small dot our team will really be an important challenge we will make some"
  },
  {
    "startTime": "00:38:00",
    "text": "change and hopefully mid-may will be able to deliver nice documents that we got for review from everybody but of course as a link is open if anyone is already interesting to give you to give us some comments it's really it's really open so do not hesitate and to already write comments before and yeah that's it for me any comments or questions yes i have a question if you go back a couple of slides when you have the the criteria for the electric management problems yes here i like your approach what i'm for the document itself what what do you intend to describe really a series of problems i mean what will be the focus of the of this section and document uh it will be more on the criteria or it will be more on trying to find some problems that uh that have the different criteria c1 to c5 just to understand because i think see the criteria are quite interesting and pretty i mean uh transverse uh finding problems that have uh many of the criteria etc we will be kind of going again into uh not use cases but our problem is and then it becomes a bit uh the question which one to select uh to be to be signific significant or representative of uh network management problems okay so um actually it was a bit in kind of let's say reverse engineering this criteria it was based off what has been already provided in terms of problems so yeah the idea of using this criteria is just to help us to um to try to"
  },
  {
    "startTime": "00:40:00",
    "text": "somehow have yes i have problems that fulfill different materials many criterias the idea of the document of course is not the description of the problem itself but if you have some some problems that are used and in the chinese description we have already actually we have many many people and they contribute to describe challenges and they give an example for example and so the idea that we should take this example and put them in the first section and try of course this example because many examples are similar so they are quite transversal and try to show why is why this why these problems are very hard and we actually yeah this criteria should that should have to understand why they are very hard and then for each section you can refer to this to this let's say big problem when you describe why this is a challenge for example i don't know to use a lightweight ai in network uh for example because we have we need some out to the reverse relation constraining determinative type so we need the ai and working at like minutes we put so we put so so there is more to you to to help us a bit to to describe the problems and to really highlight that's a hard problem why because of this criteria and then we use these problems in as illustrative example and we can refer it in challenge description is that clear hello yeah thanks thanks for the clarification okay thank you i think we have olga in the line can you i just wanted to ask you are you looking at it as a kind of just challenges for the green field or do we have kind of some problems in regards to the integration with existing uh network management solutions uh sorry arka can you just repeat again and then i'm just wondering i'm looking at the"
  },
  {
    "startTime": "00:42:00",
    "text": "challenges from the perspective of the greenfield ai based network management solutions or do we need to add maybe the challenges that we need to integrate or augment or expand the existing network management solutions uh [Music] i think there is no let's say let's say limit of challenges which what we could put um some more for the range of management of course um so yes we have challenges maybe to resolve some uh some problems that you have already today or maybe we want to integrate ei to solve new channels some new some new problems will have in network management so that you know we have already so this is not let's say it's not this let's say um fixed and of course if you if you need to extend it uh some solution with ai yeah it's also kind of a challenge that we should highlight but it must be i like it not not from a single problem perspective but more globally so so maybe i'm just thinking is there some criteria that is talking how to evolve uh the existing uh solutions and how to integrate the ai ml into the existing solutions i think this is part actually of the acceptability which is you you know it's acceptability uh main challenges and then you can accept challenges maybe this is a good challenge to have here um because if you have time to look at the document i try to to add this id that we have already procedures we have already solution we cannot just say from the from from today to tomorrow which change everything we need to to some way integrate incrementally ai this is something that i try to to make it uh appearing in the let's say acceptability"
  },
  {
    "startTime": "00:44:00",
    "text": "challenges and then you have some challenges uh but here in the second one which is um in production system actually this is uh we move from let's say uh uh yeah lab solutions to solution in in the real real network let's say and yeah yes there are some some challenges and we try to to figure out what could be the orientation as well uh of course i think maybe we then have questions also so is there some uh you know session and then we will go to um so digital twins that's why i think it's also a possibility a research and digital should help to integrate ai incrementally into production system because you test it in uh yeah digital twins so this is something that appears as well here so um yeah your mark is fully valid so if you are interested by this i mean you can focus on this section and you can give me some feedback if you want i will be very happy to take you to just to know if this make uh this is uh i like what you have said before that uh how to you know extend existing solution with the eyes is an issue and maybe this should be your focus support yeah okay thank you okay any further questions to before we continue with our agenda we'll be on natural digital twins and the first presentation will be from uh jordy and alvarez hope to build a digital twin um albert you want to present i will present and you just tell me i"
  },
  {
    "startTime": "00:46:00",
    "text": "want to switch right okay yeah okay here okay so uh i will start so um thanks for um i love for inviting me for for this talk i hope that you find it interesting so what we're going to talk is how you can build a digital twin and we will compare a bunch of technologies and we will try to understand what are the pros and the the cons so next slide please so this is a digital twin i think that i don't need to describe further the concept right it is a digital representation of a networking infrastructure and it has been documented already in drafts and many papers um and instead of focusing on on what is the digital twin we will focus more on how we can build it so next slide please so next one so i think that the the first question we need to answer ourselves whenever we want to discuss the digital twin and specifically when we want to discuss how to build it is what are the inputs and the outputs it's very hard to have a meaningful discussion on the digital twin on the network digital twin if we don't uh first of all discuss uh what if it's a box right if we agree that it's a box uh then it has some inputs and some outputs and that's the very first thing we need to agree on right and in particular that's a very very bad question if we want to discuss how we can build it and what are the challenges and also the use cases so uh next slide please so in order to answer the question how we can build a digital twin we have decided to go through for these inputs and outputs which are uh as inputs we have the network configuration which means this is my"
  },
  {
    "startTime": "00:48:00",
    "text": "network topology i have this type of cues i have this type of scheduling policies like stick priority or weighted weighted circuiting i have this routing protocol i have an overlay routing protocol with segment routing and so on that's the network configuration for the traffic load is exactly which is what are the packets that are entering into my network right how many users i have which type of traffic they send do they send voiceover ip within demand or data traffic for backup traffic and so on so those are the two inputs and at the output what we propose is that it is the resulting network performance so if i have a network which has this particular configuration with that topology and this particular router equipment and switches and so on and i load it with this particular traffic this is the performance that i will get and the performance can be measured through what will be the delay of the flows from the users what will be the delay of the voice video on demand traffic how many losses i will have in my network what will be the link utilization what will be the utilization and so on it is very important to note that we are not claiming that those are the right inputs and outputs those are the ones we are considering in my group uh to answer the question how we can build it and to see which are the challenges ahead um and they are relevant for the sake of the discussion i think that uh those inputs and outputs can be challenged and we can have a discussion on whether those are not the right ones and maybe there are better ones that's fine i'm open to that but for this presentation let's keep and let's assume that those are the the inputs and outputs so next night please then how why these inputs and outputs make sense at least to me because if you take the a real network infrastructure and you assume it as a box also that's super stupid what i'm going to say okay because you guys are running networks and building them but let me explain them from this angle at the end a network if we assume that that's a transient network what you have is"
  },
  {
    "startTime": "00:50:01",
    "text": "data packets that are getting into the network and data packets that are getting out the network right if that's uh that's a transiting network so we have traffic going from ingress to egress now these traffic are packaged but at the end they can be voice traffic video traffic and so on and then you have some sort of administrator which can be a network management platform or a controller which is applying a configuration to the network okay or the network is already configured the configuration is everything that it is you know on the configuration file of each and every uh network device and then if you have if you assume that you have some sort of telemetry platform what you have is a performance metrics so you can measure okay this is the delay for this type of flows this is my utilization this is my losses this is my link utilization okay so this is how we see a network of course not all some networks consume and produce traffic this is not shown here but for the sake of the discussion i think that this is a good example because this can be changed later on so next slide so then what the performance network digital twin is is exactly the same it's it's the the box is representing your network infrastructure you are applying exactly the same configuration to the performance network digital twin exactly the same as you have in the real network but instead of using the real traffic to test the net the network digital twin you input a description of the traffic okay because it's not a real network so you don't put packets into the digital twin but you put a description on how this packet looks like how many flows do i have how many voice of video on demand flows i have which is the rate for this video on demand flows um how many users i have which is the the dynamic behavior temporal behavior of the users because maybe at night i have more traffic than during the day because that's a residential network and so on so those are the two inputs to a network digital pin okay and then the output is are not the package because we are not putting packets into the digital"
  },
  {
    "startTime": "00:52:00",
    "text": "pin what we are putting is a description of the traffic and what we get is a description of what will be the performance of that network if um of for that traffic with this particular configuration right so again so it's uh for the the network this is doing is simulating let's say a network which has what has been configured with this configuration has this type of traffic and then it will tell you okay this is the performance you will get okay so next slide please so next one so i don't want to discuss which are the use cases of a performance digital twin i don't think that that's the focus of this presentation but i think that it is very hard to to to have a meaningful discussion on how you can build something if we don't see why that's relevant right so let me go super quickly over a few use cases so basically a performance network digital twin it's it's it's a useful tool because if you think about any kind of automation before an automatic system an autonomous system decides what to do with the network it is very important that it understands what will be the impact if i change this right if i don't have if the autonomous system does not have a digital twin that will tell okay if you do this the performance will be bad so don't do it it's very hard for your autonomous system to decide what to do right so basically that's that's that's that's the main the main goal of our performance the network digital twin so here we have a set of use cases but on the paper listed below you have way more use cases you can check them for instance you can and i'm assuming here that this digital twin is deployed with a traffic telemetry platform i'm a network management platform which are not easy to implement or deploy but i assume that they are already there and that's out of the scope of my presentation but you can answer questions such as what if so let's say that i'm employed in a company i'm running the network and my company is thinking about acquiring another company so i can ask my network digital twin what will be the impact of the on the network load if i if we acquire that company if all these users"
  },
  {
    "startTime": "00:54:00",
    "text": "are now using my network what will be the performance of my network what will be a linguistic or i can ask questions such as okay i have a 5g core and i have a backup 5g core but what will what will be the impact in the users if the um [Music] if one of the 5g cores fails and all the users need to be redirected to the backup one what will be the session establishing what will be the impact on the session establishment time and so on or you can ask questions such as okay can i support new user slas with exactly the same resources i do have or do i need to buy new network equipment or maybe i need to upgrade the link okay so um this is a set of use cases you have more on the on the paper if you are interested so next slide please okay so now we have uh at least we uh we will build a performance network digital twin and then we can discuss how we can build it okay so next slide so um in in what we have built is a performance digital twin as i was explaining and to be more specific the configuration that we assume is um we support topology okay which is a topology of the network we're assuming a fixed network with switches and routers which is the link capacity which is the routing that you're using on your network whether we support overlay routing like services or mpls or lisp and we support underlay routing also like very like ospf and pcp whatever you are using there what are the scheduling policy you are using uh any arbitrage scheduling policy will work like uh strict priority weighted securing deficit run robin and so on the q length um and then other features such as ecmp lag and so on i know that some of these features are very old and and and our goal is to academically show that whether this can be built then the real features i think it's up to discussion for people that have way more knowledge on how the industry works okay and the traffic load as i was saying you have the traffic matrix which is how much how much bandwidth i have from one ingress point to one egress point and then also we support flows meaning"
  },
  {
    "startTime": "00:56:01",
    "text": "that we are assuming that the performance network digital tune will support flows meaning that we have this amount of flows that start here and here and then each flow has a different type of traffic like uh voiceover ip video on demand web and so on um and we don't need that these flows are described as five tuple we support any level of variety so for instance flow can be uh from from english to egress or you can assume any level of variety uh and and and this will will support it okay so next slide so now let's build let's try to build this box with a simulator okay so next slide please so here what we're doing is we're taking this box okay and this box is actually a simulator okay it's running c code or whatever language you're using and it's implemented using a simulator so next slide okay so we have actually we did that and for that we use the obnet plus plus simulator that's that discrete event simulator uh with basically a discrete event simulator what does it simulates the propagation transmission and forwarding of each and every packet and actually the forwarding of each and every packet is what is considered inside the simulator is a discrete event so basically a simulator is a code which is which takes all these events and you know goes through all of them and tries to understand what happens uh discrete event simulators are very well known in networking um there are way more discrete object is just one of them there are them and network simulator two and three g and three cisco packet three seven so there are a bunch of them but all of them they work under the same principle which is they simulate what happens with each and every packet so if you take one simulator and you try to build this kind of box you will find that the accuracy is very good now what is accuracy and this was one of the questions that jerome was sending to the list right but i couldn't see here i mean if i take a real network and i apply a configuration and i i load it with a certain amount of traffic and i measure in the real network what is"
  },
  {
    "startTime": "00:58:00",
    "text": "the delay for instance for a particular flow and then i do the same with a simulator the difference between the the real delay measured at the network at the real network and the delay measured at the simulator that's what i call accuracy okay and the error the higher the error the the worse the the the less accurate is the simulator is this the technology so accuracy is very good in a simulator typically you get perfect accuracy or almost perfect accuracy um but what about the simulation time so next slide please so what happens is that although simulators are very accurate the problem is that the time it takes for a simulator to simulate a network it scales linearly with the amount of packets okay which are discrete events at the end of the simulator and if you think about how a simulator works this is exactly this is exactly right so for instance just to give you an idea one billion packets takes 11 hours in a quite busy computer and one one billion packets is roughly equivalent to one minute of a single 10 gigabits per second link okay so if you want to simulate one minute of attenuate per second link this will take you 11 hours in a quite busy computer so of course it is uh impractical to simulate a real network which have tens of links which are even high with higher capacitance than 10 gigabytes per second it will take you a week to do that so although simulators are very accurate they are they have a huge computational cost and they are not practical because any question you ask to the digital twin it will take weeks to answer that uh and actually if if you want to simulate a real real network with real link capacities and real traffic it's not even weak it's probably more okay and you are spending huge amount of um computational cost so that's why i believe that using a simulator for that is not practical so next slide please okay now let's go to emulation so next slide so um what is an emulator so an emulator"
  },
  {
    "startTime": "01:00:00",
    "text": "is if you take a network right a network is uh it is made a real network it is made out of two main components hardware which typically is designed uh specific for networking you have like network processors and asics and so on which are designed for packet processing and then the software which control which is runs over this hardware right so an emulator is basically taking and i'm sure that many of you already know that but let me go super quickly through it an emulator is taking only the software components of your network and running exactly the same software components or as close as possible but instead of on a specific hardware on a general purpose cpu or in a cloud okay so you take exactly the same software that you have on your network and you run it on um on a general purpose cpu so this is basically you know like a software router or a virtual network function and so on so next night so if you build a network digital tune using emulation what will happen is that you will have very poor accuracy because of course the delay seen by the packets which are going through your emulator network will be way lower so the delay will be sorry higher will be way higher than in the real network because your emulated network is extremely slow because you are not taking advantage of the specific hardware that that your network is using right because basically you are you are running your network in a general purpose processor instead of in single purpose processor which is what you have um so emulation will will not be accurate right the delay that you will measure at the emulation will will not be accurate with respect to the real infrastructure okay um this does not mean that the emulation has many many relevant use cases and i think that it has many relevant use cases which also are linked to other type of digital twin which are not based on performance for instance for training or for debugging or for testing new features okay i think a demolition has many a lot a lot of value but not to build a performance network digital twin"
  },
  {
    "startTime": "01:02:00",
    "text": "because it offers basically poor accuracy so next slide please so now analytical models queueing theory so uh next slide now we take a different approach and instead of using simulation or emulation we try to see what happens if we try to build this box with analytical models with equations and for this we use queuing theory so basically queuing theory represents our base available analytical tool uh for to model networks okay and i'm sure that you remember something about queuing theory probably from your grad studies so basically queueing theory it models the network as a set of queues as a series of skills right and connecting this set of queues is what we call network and and if you think about that it makes sense right um queuing theory was um pioneered the application of queueing theory was pioneered by leonard kleinrock which is considered one of the fathers of the internet the he laid the the foundational theory behind the internet because he was a pioneer in application of queueing theory to packet switches networks in the 70s and that's one of the reason why our panel decided to to go for packet switches and this is what we have today okay so uh next slide so what we did was we said okay now let's try to build this performance network digital twin using giving theory so we developed a model using keying theory which at the end is a set of equations okay and this is what we put inside the performance network digital twin so next slide so when you do that what happens is that um the digital twin is super fast meaning that when you ask a question you get an answer super quickly because at the end what the only thing that you need to run are a set of equations and that's computationally very lightweight and it's very quick what happens is that when you try to see how accurate is your queueing theory when estimating the delay you will find that under realistic traffic models it is not"
  },
  {
    "startTime": "01:04:00",
    "text": "accurate at all for instance on the plot on the right we you have um on the so you have three different traffic models uh auto related modulated and multiplex and on the y y-axis you have the error so for modulated traffic which i will explain what it is in a second um our queuing severity model estimates the delay with a 68 of error okay so queuing theory does not work in this case and it estimates a delay which is 68 of the real one so it was not very accurate now modulated in this case modulated exponentials can be understood as traffic similar to tcp because it has some auto operation properties and and and it's similar to tcp so for instance queueing theory offers very poor accuracy when it's when when trying to estimate what will happen with traffic which looks like tcp okay which behaves like tcp in this case seventy percent offender this is not a limit a limitation that we discovered and at all this is very well known in the in queueing theory uh people working in queueing theory they are completely aware that queuing theory only works for very synthetic traffic but not for realistic traffic so it is not an accurate solution for that um that's why i believe that it is not practical to build a network digital twin using qx3 because it is not accurate under arresting traffic although it is very fast as opposed to emulation and simulation it is super fast but not very accurate for for realistic traffic okay so next slide so now let's try to use it with neural networks let's try to build this kind of system with neural networks so how we can build this kind of system with a neural network okay so neural networks all of them they require training okay that's the first thing you need when you want to build uh something with a neural network so let's let's take the example of uh in computer vision which is an application we are already aware of it let's say that we want to build a system that identifies pictures of animals and it is able to tell us okay this picture that's a dog this picture that zakat and so on so the first thing you need is a"
  },
  {
    "startTime": "01:06:01",
    "text": "training set meaning you need a set of pictures with the the right with the label meaning that this picture and that's the doc i tell you i'm telling you that this picture is a dog that's a cat so you need the input and the output of the model and then this is what the neural network uses for training and then after training then you can you can ask the model a question okay see this picture which you have never seen before now tell me if it's a dog or a cat or an elephant and it will tell you so in networking we can do exactly the same thing right what we can do is recall that the input labels of the performance network digital twin are configuration and load so what we will do is and i know that that's complex but this is the approach we are taking is we take one network and we say okay if i apply this network configuration and i apply this traffic load what the performance will get so i get and that's the first row of my data set okay so input label and output label then i take another row i will take a different network configuration i will change the topology where i will change the segment routing configuration or the queuing policy i will change the traffic and i measure what is the performance and that's the second row of my data set and now i need thousands of rows that's complex and costly i need thousands of rows and when i have these thousands of rows then next slide so next slide please okay then once i have thousands of rows i can train a neural network okay and i will tell him i will tell it okay when you see this network configuration and this traffic load that's a performance and so on that's training after training i will be able to watch the neural network okay now now after training which is very costly but after training then you have a trained model which is very lightweight i will be able to ask okay if i have this traffic load which you have never seen in the past and you have this network configuration which you have never seen in the past what will be the performance and if i do the training correctly and i do many other things correctly the answer should be accurate okay"
  },
  {
    "startTime": "01:08:01",
    "text": "so next slide please so this is what we did and and for that we use a particular type of neural network which are called graphical network which are designed to learn information which is structured as a graph okay those are called graph network depending on your application in ai you need to use a particular set of neural network architectures okay if your information are pictures you use convolutionals if your information is like text or voice you use recurrent if your information is a structure as a graph which is a network basically you use graph neural networks okay so we did precisely that and and we call it langnet you have a paper also over there and we we basically now we are implementing the performance network digital twin with a train gnn okay so we train it and then that's that's the performance network digital twin so next slide okay so um the first thing we try it is okay what happens if i ask the performers network this is a twin which is built using a gnn what is the delay for a particular network configuration and a network which has never been seen in training so it's a completely different network and as we have seen is that if you train um this particular model in networks which are 20 to 30 routers only the and you ask after training in inference after training you ask okay what is the performance of need of this network which is 10 times larger and that you have never seen in in training then the the the error um in the worst case is 10 okay when estimating the delay so it's quite a remarkable accuracy also the gnn is very fast um it's similar to qx every so after training training is very expensive but after training you can ask a question and the gnn will will give you an answer in 100 milliseconds and that's not unique to gnns that's pretty much all the neural network and here we are using off-the-shelf computing but if you use ai accelerators"
  },
  {
    "startTime": "01:10:00",
    "text": "you can drop this number to 10 milliseconds okay so super quick um so it's it's the train model it's very lightweight and can answer questions very um so as we can see very accurately and also very quickly and next slide and finally what we what we did also was to test what happens when you have realistic traffic models not not as in queueing theory which only works with very synthetic traffic models but when you have uh traffic models which are you know similar to tcp or similar to voiceover ap and so on and as you can see the the the accuracy is also very good in all the in all the across across the board and the error when estimating the delay is always below 10 and you have all the details in the paper now gnns are not freelance right you need to build a data set and that's quite complex and costly because i was saying you need to take one network and you need to start trying configurations trying traffic and seeing what is the performance and this is your training set for the gnn so next slide yeah next one so that's a table that hopefully summarizes what i said during my presentation right so emulation will give you poor accuracy and it is very very slow um so it is not practical uh simulation the accuracy is very good but the the speed at which you will get answers is very slow um you know it will take hours to simulate one single link in a very busy computer queuing theory it is it offers poor accuracy in realistic traffic conditions but it is very fast to get your answers then you have another row which i didn't explain because of the lack of time but we also tested other type of neural networks which are not gnns and you have the information on the backup slides but finally what we have found is that with gns you have very good accuracy and they can give you an answer very fast and that's it from my site i don't know if you have any questions or comments"
  },
  {
    "startTime": "01:12:03",
    "text": "we we have uh luis first then diego thank you very much everybody very interesting presentation i have a three few few questions uh first uh you mentioned well you did it in this cnn simulation uh uh assimilation one an analysis with 20 30 routers when you comment about increasing the number of routers there do you refer to the internals of the network so keeping let's say the perimeter to certain entries and or also to increase the number of entry routers or rather entry traffic yeah you can multiply everything by 10 and it works but even also the perimeter oh and the sources okay i i uh another short question is you mentioned that you can train and you can change the the the different configurations and so but i was wondering for instance if you introduce new behaviors that could be for instance preemption in the queues this if this has not been trained before i suppose that you will not get the proper result right so you need to train let me elaborate because that's a very very good question so gnns will be able to provide um accurate answers to different values of the input parameters so if you have a larger topology if you have a different routing configuration but a new feature like this is a new protocol which the gnn has never seen during uh training then you need to retrain it okay as an example as an analogy if if you have a computer vision and you train it for a set of animals and then yes it will identify any picture of that set of animals even if the particular picture was not on the training side but if there is a new animal you need to retrain it okay and the very last question is um with this with these techniques also we could have a view of jitter on so not only delay or throughput but also yeah actually i didn't say it but it's"
  },
  {
    "startTime": "01:14:02",
    "text": "jitter link utilization and q utilization okay thank you very much next is diego please no it was simply looking at here at these um and thinking that we live in a world of composition and containers and lambdas and all the like don't you think that probably in many in most cases or in most practical cases a digital stream will be a combination of several i mean if you are not very much concerned about accuracy but you want to have a an approximate value probably using uh um i don't know uh theory but for a certain part for the core but you are going to go to very much detail in a certain part or you want emulation would you go to yeah yes i but delay has this nice property which is additive right if you take the end-to-end delay and you want to speed it in parts and you can estimate for each part where it would be delayed then you can add it up and you will get a nice estimation yeah but jitter no unless no digital losses they you cannot divide them into parts and compute them independently it's more complex yes both will depend on the yeah but but this is the kind of discussion i think it has value right because when you start thinking about okay what is my output what i want to do i want to predict the delay then the discussion is more easier to have because we are down to the graph and and that's fine if if those inputs and outputs are not the right ones i don't i don't think that maybe they are not the right ones but when we have the inputs and outputs then discussion is way easier so i'm born with less so uh thank you very much for this presentation i've been waiting for it for quite some time because there is quite a mix of you know emulation versus simulation versus analytics etc so i like it very much so"
  },
  {
    "startTime": "01:16:00",
    "text": "okay the conclusion is that your graph neural network is fast great accurate well maybe because in the end we deal with routers that have hardware limitations that have sometime bugs that have their own limitation depending on how they're connected so uh my message is i'm wondering if we're not trying to solve everything with digital twin in a sense that okay digital twin is like a copy of your network now we speak about performance network digital twin and i'm wondering how far we could go because you know you mentioned the four metric that you've got network utilization well if you put more flows in there sure it's easy to deduce then there is like a delay delay we could as you mentioned it's additive that's a great property so we could get it with a high level accuracy if we go into packet loss well it's not to be very hardware independent artwork dependence right if we go with jitter as you mentioned that's the most complex one because well we cannot add it so i actually have to test it so i slowly arrive at the conclusion that maybe digital twin is not the tool for everything because if we want to test performance which is the thing that we care about delay packet loss jitter and link utilization that's easy i start to believe that we'll have to do it in the real network so i agree with you that uh liquidation is easy but i cannot agree with your other statements i'm sorry so if that's the beauty of neural network it's a data-driven approach so if your real net hardware device has bugs that's fine they will show up on the data set and the gnn will will catch up those backs because you are training with real data from the real network it doesn't matter how complex the hardware is uh gnn will be able to to"
  },
  {
    "startTime": "01:18:01",
    "text": "model that very good so i like that answer now the fact is that you need to update the setup out of the router yes and i agree and you mentioned it's expensive yeah that's expensive yeah and so uh in your in your uh diagram you are showing that you wanted to have all packets all packet headers basically right you need to well you need to as if you want to you build this one you need like configuration a description of the traffic load and then you need to measure the flow delay jitter and losses yeah right so this is what will be as you as you call expensive because it's a prerequisite to enter into this line line with last line which is fast i agree and you convince me it could be good yeah yeah so so can i can i say something because i think that you you put a very good question that's why we make such a big effort into building models that are able to be trained on small networks and and operate in very large networks because what we believe is the commercial solution to the problem that you're putting is okay let's say i'm a vendor i i cannot go to at this network and ask them okay i need a data set please i need a link failure because i need to see a link failure in my data set for the gnn to understand what happens when there is a link failure so please throw away that link please congest the network because i need a data set with a congested network because the gnn needs to see what happens when driver is congested okay of course this is crazy right so what we think it makes sense but i'm hoping for discussion is let's build a data set uh sorry i'm a vendor i built a small test bed you know and i generate a training set there like super complex training set i can in my test bed at the vendor lab i can throw links i can congest the network and then if the general is properly trained and it has this nicest gravity property which gnns have i can use the train model to operate in networks which are larger than the test bed so and then you have like in the"
  },
  {
    "startTime": "01:20:01",
    "text": "self-driving car model right when when we expect to buy a self-driving car they give they give you the the car has been already trained where has been trained well in you know towns which are i don't know in nevada and they are facilities at the at the see my point that's what we envision that that's what works for single domain single vendor uh type of environment i'm wondering you know i like your conclusions what i would need i know it's a difficult question but uh getting all data sets it's like the starting point for uni data scientists and it's difficult yeah what would be good is what kind of accuracy if you get like flows and flows with sample data and if you get a little bit of delay but not everything and trying to see how far we could you know get into the good and fast but with some data yeah and this is where i'm trying to to match the two because right now with the small amount of data we could get from networks today that's a fact except flows right yeah then uh we're stuck to let me try it in the real world yeah i agree because so far because we are in a lab we can assume well we generate as much data as we want and we don't care and we pay the cost because it's an academic exercise but in reality i think it's very important to see actually how much did i i do need from the test bed and how accurate will be depending on the data and and because you are making also a very valid point there is a there is a new trend in ai which is called which is coined by the stamper professor andrew ng which is called data centric ai and what what he says is look it's not about the algorithms anymore we have the algorithms it's about the data okay but it's not about yeah i have billions of data if which is the minimum set of data you need to train a model and that is called the data center ki and actually um we have a challenge"
  },
  {
    "startTime": "01:22:00",
    "text": "um on the i will i will send send it to the mailing list we have a challenge on precisely what you said it's data centric ai for network digital twin so which is the minimum set of data you need to generate from a network in order to have this fantastic accuracy and that's a question we don't know yet okay so we were leading a bit over schedule um we have two two question panning we have a comment uh in the chat from uh zaid uh so i will bring it to to the audio here so training a neural network to recognize the cat is dealing with data sets network traffic pattern is not finite how will this solution deal with that i didn't can you repeat the question please yeah so if you want to trade on your network for instance to recognize animals it's an infinite data set yeah okay so they mentioned that network traffic patterns are not finished how will this solution deal with that so they are not finished but they can be characterized by uh features and the features they they have values from zero to one let's say and i agree they are infinite numbers between zero to one but neural networks what they do is if you show them the feature at value zero 20 0.5 0 75 and 1 it will interpolate what happens in the middle so the the key answer to this question which is again it's true in machine learning is that you need to represent your data with features and you need to show in the training set different values for that for those features yeah i think it also uh relates to the question from lewis that if you have new mechanism or protocols you will need to retrain if there is a new traffic traffic model which you cannot describe with the features you have created then you need to retrain it yeah i agree"
  },
  {
    "startTime": "01:24:00",
    "text": "okay uh so i i have one question and i think we have chain in the queue we need to to speed up a bit um i have many questions but i will just use one um you mentioned that you you found that you were training uh over a limited set of notes and you are trying to say okay how it applies to the to uh to network that are bigger my question is that um have you tried to assess the sensitivity of the neural network if there are changes in the in the properties of the topology you see for instance if you have a change in connectivity degree or you go to mesh to rings or different types of uh the topology uh changes do you have you seen sensitivity to that yeah very good question also so uh this is not our work again this is a standard gnns they what the the mask what they tell you is that gen end will be able to provide good accuracy as long as the distribution of the graph that they have seen in training is similar to the distribution of the graph that they have they seen during inference in operation which means that if you want to have good accuracy in ring topologies you need to include ring topologies into your data set into your training set if you want if you want to have good accuracy with a scale graph topologies you need to have those in training so everything goes down to what you put in training it's the most important question actually yeah so i agree you need to have you need to show this kind of topologies yes okay thanks a lot albert we have chang in the in the queue do you have a question for albert or are you in the queue for the next presentation oh yes uh so before i start my presentation can i uh ask one more question yes please okay uh this question is also about data set so can i know the the skill or how large the data set is in your geo and test and uh what's the cost to build that set"
  },
  {
    "startTime": "01:26:00",
    "text": "to label the data set yeah so the data set just to give you an idea it has 100 000 rows and each row is one network configuration one traffic load and the performance and each row it's it's a huge matrix because it's a configuration for all the nodes the all the flows and we have 100 000 rows so it's very large um and and that's why we have this challenge that we organize along with i2t which is okay which is the minimum data set that you can produce to have a fantastic accuracy okay since your uh your uh model includes the parameter of the configuration so whenever a specific parameter is changed you need to rechain the model is that correct yes no you don't need you need to so you don't need to retrain it if you change the routing configuration that's fine you will get good performance okay thank you okay thank you thank you so much okay so jen you can uh start your presentation please if you can try to be quick you'll be appreciated thank you okay i would try to be as great as possible hi shares and everyone this is chen from china mobile today i will present the draft update of digital network concept and the reference architecture on behalf of our courses next next live please okay our scope of the draft includes to present an overview of the concept of digital team network and to provide the basic definitions and the schedule reference architecture and to either identify use cases and the discussion benefits and key challenges of the technology the objectives of the draft uh includes to promote the widely adopted digital training concepts and uh to establish a reference that architecture and to identify identify"
  },
  {
    "startTime": "01:28:01",
    "text": "future technical research directions on enabling technologies next slide please okay after several objects and the dictators in group the draft code for adoption in december 2022 and the chapter was adopted by rgb circle and in the review cycle we received more than 50 valuable comments and here we must say thanks to our major experts to help improve the draft there are daniel chufang lauren jeremy judy lewis alex and thank you very much and we just uploaded the arch version that's their disco and the most comments were just in this version let's please okay this table shows a summary on the comments we received and the actions we've taken we have taken we have addressed most comments while either explaining in the mailing list or revising the new version time limited so i will not describe them in detail next slide please okay this slide shows the major changes we made in the in the new version and include better better structure the content strengthen the research background and more focus on the challenges and close some old issues and focus on some new future research productions next please okay for the radiation all the issues uh we uh this table shows the five and five of them and one is the new section of the new technology be added a second is a recommendation on to describe recent rtf rtf technology the"
  },
  {
    "startTime": "01:30:00",
    "text": "third is to go deep into one or two use case and the first is to study i mentioned earlier technique is related to the digital network and the five is uh the fifth is uh uh which level of detail should the document should include with without losing its purpose especially for challenging and enabling technology sections and of all the issues we have opened in the mailing list for comments let's please okay from this slides on uh i will take time to uh to to discuss some open uh item items uh regarding the detail network they are motivation challenges architecture enabling technology and the research directions respectively next please firstly what's the motivations and the requirements of for dt network we summarized the four challenges in network operation and maintenance firstly a new new uh new net network services emerging endlessly and the network scale continues to expand sadly the complexity of network om is becoming higher thirdly in inertial technology in longer time to deploy and firstly network optimizing optimization has a high cost and high risk due to vulnerable production environment and to address these challenges uh we can see uh no new network of automation and autonomous operations are becoming a new region and recently uh ibm intend-based vlan uh intern based networking uh ultra driving network network adm zero touchdown has been studied and we can also see ai machine learning technology that are widely used in network field to help achieve this region"
  },
  {
    "startTime": "01:32:00",
    "text": "and uh teach uh now we will digit here we can see that it brings a new chance to meet these challenges uh virtual real mapping and interaction interaction brings a solution beyond the physical network and network direction can help physical networks to realize a low cost trial intelligence decision making efficient innovation and predictive let's please then what are challenges to build dtt uh network first according to a sighted paper here uh the main challenge is to build and maintain uh digital twins in industrial field uh can be summarized as five aspects uh they are uh data acquisition and processing high fidelity modeling real-time two-way connection between the russia and the real trees unified the development platform and towards environmental coupling technologies and the net network field has its own characteristic characteristics such as a higher level of digitalization uh nation multiple services and complex system so uh we we think that i will summarize uh here are five challenges to build a dt network there are large skills challenges interoperability data modeling difficulties real-time requirements and characteristics of course i will here we have to work on any other input on challenges if any next piece oh let's uh go quick uh quickly uh go through the reference architecture we recommended in the dropped uh in the three layer architecture the top layer uh lowest layer is physical network there is network application the intermediate layer is a natural digital twin which is called part of the system system and an optional sub layer was added can be added"
  },
  {
    "startTime": "01:34:01",
    "text": "for data collection and change control functionalities yes please based on the reference architecture we plug in the above we recommend the file in enabling technology to build the digital system first is data collection including uh diverse exist existing tools for example smg network telemetry narration a innovative new tools for example sketch based measurement and semantic aggregation mechanism for data integration and the action translation uh the the second technology is for data storage and the services as an editor of iit technologies and the third is network modeling which is the the most important one and uh for small skill network uh we think that net network simulators uh for example uh s2 uh g and s3 or virtualized source can be up it can be an option and for a large-scale network local solutions normally based on formal methods of mathematical measures including uh what what judy has just uh described the uh for gin queues currencies neural network yeah and we think that a uh machine learning ai can be used to build complex function models into an entity and the the first is a visualization it is to display the net network topology operational status and also to uh to uh inter inter interactive visualizing uh to show better uh understanding and help reduce and explore the network the interfaces and protocols for users"
  },
  {
    "startTime": "01:36:01",
    "text": "finally is the interfaces to ensure the proper interoperability or capability of the system as please oh this slide shows a test study on the data collection there is an efficient efficient data flashing method for digital network and we know current collection method i just collect raw and four data from physical network and have problems of time cost insufficient storage resource low computational efficiency and waste of bandwidth and this this struct or this method proposes an efficient and lightweight data collection aggregation and correlation method uh for more details we can see the the draft we uploaded in the emergency data chapter next please uh this lecture is another uh case study on network modeling it is a knowledge graph based construct method for digital team network in this solution network system design referred to refer to the architecture in this structure and the base mode in in the in the solution are built via formal methods uh network device models are built based on the six circle ontology and topology models are built using a knowledge graph and a function based on that function models can be built using ai and machining algorithms for more details you can find it in our short paper next please okay here uh we we want to propose some future candidates research directories uh some of them are not limited to these jobs uh first we think that we need to go deeper"
  },
  {
    "startTime": "01:38:00",
    "text": "to to for the five key technologies listed above next is that we should get more measurements to quantify the gain brought by dtn to network management and next are how ai machine learning rdl algorithm used for network modeling and how can knowledge be injected to network digital training to help pursue vision of autonomous network and how can the digital chain network integrate and evolve with legacy network management management system and finally finally we need to define capability levels and evaluation methods for dt network voices the resource requirement and the effectiveness evaluation of a dtt system and the metrics and the measurements to evaluate the accuracy and fidelity of our geodet yes please going forward uh we are to issue stress for each of the candidates research directions and to record out then to record the outcome of this class as appropriate and we also overcome proposed proposals to enhance the document and your comments are always welcome that's all thank you thank you shane for being efficient in the presentation um we have maybe the opportunity to have information on the updates and the directions set by uh the offer of this draft activity so if not uh thanks jane let's let's use a bit of time now to continue uh on this topic of network digital tweet i think we had two good presentation in already in the in the discussion with albert and the question"
  },
  {
    "startTime": "01:40:00",
    "text": "uh we i think we started to touch on a few good points uh so what we wanted to also is um again in this notion of a research activity exploring a new new aspect uh let me share quickly something so we we had a set of questions okay i hope you can see it let me know if it's big enough so this was shared on the mailing list and also here on the hdoc the idea was to really for the research group and in general it can be beyond energy but to try to to to think more what what it means network digital twin what are the research directions uh research challenges that appears and so uh jerome and myself we we drafted the first set of questions of course this is open to anyone in the group to add questions and of course to provide your views and opinions on the already existing questions so jerome i would like to proceed do we go through the questions do we open the floor for for inputs if there are already people willing to comment on any of those i think let's open the people if they want to give something back i think we're gonna try to go each question by questions i think it's um you can go as as people want so there's a question if they want to comment some of them and so okay so if you have any inputs on that please put yourself in the queue"
  },
  {
    "startTime": "01:42:04",
    "text": "yes jerome please like i can start maybe um so i think we have we had a lot of already some some discussion before with albert talk on uh on this point but um regarding although yeah the accuracy of the model that you want to use for digital twin and the data that you have as input and but my question is that okay i want to evaluate i want a digital twin to evaluate for example preference metric or write over matrix but the um the interpretation of this metric and the let's say usefulness of this metric may really depend on on the on the um and let's say uh maybe scenario of application for example if you have preference metering that is about the latency maybe you you don't want it knowing exactly what would be the um the latency from purely metric point of view but more on the application that you may have at the end the latency will be used maybe to uh to add resources or whatever and so on and my question is is a digital twin because we have to retrace digital tree for each when you have new let's say maybe type of data feature as albert say using gen and i mean here but if you want to use for like this kind of approach uh we can sure we can ensure that we have enough cases to really have a representative model for digital twin um because okay you can evaluate accuracy but this may be very focused on the kind of metric or accuracy or use keys but if you want to promote the gita twin to be used for more uh from to actually to ask more questions even for the same kind of performance or security or whatever same kind of question but will it depend on where it will be used um does it mean that"
  },
  {
    "startTime": "01:44:02",
    "text": "we can ensure that the model we use whatever the modal activities that we use is will be uh will be enough accurate um i don't think we are representing different models with different let's say advantages and drawbacks um and with that the case that uh the models that we need somehow in my opinion it's not that we should need one single models maybe we need to some couple different models as well and this is my is that not there is not single let's say model that will fit holes that for sure um even if in a simple use case i think we we have to think that models could be combined uh and yeah that's that's really my point and yeah we we also assume that we can have data i think some things that have been said we can have data and uh i think which is very interesting here also in the presentation regarding the architecture is that even if you know that we have data that could be used is all we can ensure that we collect the right data at the right time to basically um uh evaluate the output of any digital twin i think this is really important as well and that's all for my first comment actually okay thank you let's try to have it as a let's say as a group discussion i see that um albert is also waiting on the mic you can speak if you want yeah okay thanks this is albert cabellos so i i i feel that we have sort of a chicken and a problem uh chicken and egg problem meaning that somehow we try to be very general um and we we try not to be narrowed down by a particular use case"
  },
  {
    "startTime": "01:46:02",
    "text": "or or by a particular model and i understand why because this is a research group and that's the goal of the research group but what happens when we try to be so general is that we get lost into the forest right because the discussion is very hard all the answers are at the end it depends uh and so on now when when we discuss a specific network digital twin and and again i'm not saying that the one i put in the slides is the right one i don't i don't i don't know enough about networks i have never run a network and i have never built a network so i don't know but what i know is that when we say okay that's the input and that's the output then all these questions that i believe are relevant can be answered in a very specific way and very concrete way right and then suddenly very specific problems show up like okay yes you can build a performance network digital twin yes can a vendor do it yes but then it will be single vendor right because the vendor will not train using uh equipment from other vendors and that's a real issue um and and i'm into that chicken neck problem right so when i try to discuss it at a very in a very abstract way i'm lost when i make it too specific then i understand that i'm being too specific maybe a solution to this is discussing okay what are the inputs and the outputs let's start by this if we agree that that's a box there are inputs and outputs let's let's try to discuss which are the relevant ones and which use cases enable different inputs and outputs and what are the challenges when you start considering different inputs and outputs and i'm pretty certain that there are a particular set of inputs and output for which maybe emulation is better than neural networks or maybe a simulator or maybe a queueing theory i don't know but it's very hard to discuss this without a specific goal in mind and that was it"
  },
  {
    "startTime": "01:48:05",
    "text": "thank you albert all the views for for participants we have maybe a couple more minutes to try to get feedback on those questions olga please i do believe one of the cool things for digital twin would be to encompass the the business intent as well you know on top of the you know information about the configuration and traffic uh i do believe it is important that we understand all the business including different intents for different customers some security policies in the organization any kind of other very high level policies that are not really configuration things so i think that is one of the most important thing how to connect the business intents with the digital twin in order to be able to kind of do self optimization self-correction in the right way thank you olga i think we will take digo as the last question for for this topic because we still have one presentation to go so diego please okay there's a comment on in the same line that what i was [Music] discussing with albert before my from our experience we have been trying to run well probably you could not call them uh digital twins but something that was able to generate uh realistic data sets for for training network control systems and now uh our experience"
  },
  {
    "startTime": "01:50:02",
    "text": "two things that are essential one is is about repeatability you have to have a strong control of the digital train so you know what you are deploying every time and you know where you are putting the focus what that you are interested in collecting because a network is a it's a one it's not infinite but this is extremely wide and i'm certainly a manageable uh field of different parameters and configurations etc but so you have to have a very clear view of what you uh what you want and which which is your focus so this is about repeatability and control so you can repeat the important thing of the digital training is that you can execute several conditions with the control variations and so you can derive some insights or knowledge from whatever this is one thing the other thing is precisely the fact let me say is that given the size of the network and the different technologies involved etc believing that we are going to have something that is a full twing of the network is uh jerome has said is about the uh the close coupling between the real system and the uh and the model probably we had to choose depending on the on the case and the focus we will have to choose to uh different levels of uh of us of abstraction of different parts of the network to put focus on let's say on security aspects on delays induced by radio conditions or in congestion in some points etcetera and this is important as well so i believe that those are the these two basic characteristics repeat repeatability based on control and the uh the possibility of applying different levels of attra of abstraction depending on the uh the goals of the of the twin runs so to say are essential"
  },
  {
    "startTime": "01:52:04",
    "text": "thank you diego so um we capture that in a minute um my proposal is that we have um several questions and i think quite quite important and that will require let's say iteration from the group participants about collecting your opinions collecting uh references inputs to to this to to sustain our reflection on that so our proposal will be to continue to to develop the i mean collect answers to those questions and a bit structure uh let's say a research um a set of research questions on this as an activity for the group before before i mean uh understanding a bit better what we want what we want or what we could do in in the in the research group and even if it's beyond the research group uh how to appreciate so so thank you uh to all the participants and um i mean presenters uh people at comments for this topic of network digital twin uh this is not the end of the story but just the beginning um now we have our final presentation for today it's on a different topic something that is let's say as a quite long history in uh ietf rtf uh and there is some update that luis will represent now so thank you very much lauren uh yes i will present this um idea of plus evolution um the next slide please so a bit of background class states uh by creating linear architecture for sort with defined networking this was a work that was previously uh adopted in the former sdn uh research group that was moved to a independent submission stream after the dismantling of the sdnrg it was finally released three years ago as an nfc so it's"
  },
  {
    "startTime": "01:54:00",
    "text": "publicly available and the main proposition of this architecture was essentially to decouple the the control of the services from the control of the transport network so allowing them to evolve independently and but even despite of being separated to we propose a tighter integration of both the strata in such a way that cooperates a program in a programmability manner next please next slide okay so as an overview so we defined the two different strata the services stratum and the transport stratum the purpose is clear so the service essentially to program the service and the capabilities of uh of the service itself and in the case of the transport stratum so all the functions related to connectivity to the delivery of information between different components of the of the service in each of the strata we define into three different planes uh control plane management plane and resource plane also the purpose is everything is clear so and again and despite of this differentiation in these two strata the area was to make them cooperative and in terms of programmability to interact for having the full programmability end-to-end next slide please so the motivation for the evolution of this architecture that we is what we are bringing today is essentially what you can see there are two main drivers for for this first that the network are evolving towards a tighter integration uh with the purpose of integrating compute environments so um we have seen here in in the itf this week uh initiatives like the both for the computer we're networking also another working in outer working group in this respect and so so more and more operators are deploying these compute capabilities but also are integrated with compute capabilities that are com are provided by hyperscalers by external players in such a way that networks are somehow transforming as a kind of fabric in their connecting compute environments apart from that and"
  },
  {
    "startTime": "01:56:02",
    "text": "the network operations are started to be complemented with ii ml techniques as clearly we know this from the work in nmrg so also we've seen the the need of intercooperating these capabilities into the in an operational manner to the existing network so the focus of this evolution and bringing these ideas here will be on management and control so we are not dealing with aspects about service placement and this kind of things so we were we want to focus on negan management and management and control so this is why we are bringing here this this work next please so essentially what the the way we are proposing the evolution of that former akita should be we keep the separation between service stratum and and transport stratum we somehow renamed testosterone to the idea of connectivity so thinking on how to forward the the formation between the different parties we introduce a new stratum referred as computer stratum again incorporating in this stratum the resource management and control planes and we define a new plane applicable for all the three strata which we call a learning plane and essentially would be devoted to the handling of data that could help on the operation liberating on the imml techniques that we will comment later on so next please so the idea would be for the computer strategy essentially to consider all that distributed computing capabilities and this what as mentioned would contain the the control management and resource planning related to the computing part some ideas that were probably good leverage on probably there is some previous work in alto as mentioned before but also the the some ideas of integrating compute environments at the end and then for the leaning plane this would be responsible of collecting processing and sharing relevant data for from the uh for each of the the strata for the service for the connectivity and for the compute and the idea would be to"
  },
  {
    "startTime": "01:58:00",
    "text": "leverage on iiml techniques and maybe a some interesting framework to follow would be the one in mnrg as well about artificial intelligence and also maybe considering other outcomes from itf as would be the the service assurance models and so for feeding all this stuff and helping on the operation of of the network so next please so exploitation research directions that we do for c there were some of them in the draft actually uh the ones that in the first ballot so some work could be maybe about a communication means or interfaces between the strata and the planes the preliminary scenarios including legacy ones so understand how this evolved architecture could be could fit potential use cases or the link with ongoing activities in an mrg clearly the intent-based activities so that difficult intelligence could have some some fitting here as well we we think that would be the case additional research lines maybe could be explored normal architectural approaches uh potentially maybe as an example the boost architecture like the service based architecture in 3dbp or what is what is called cloud-based architecture could be probably thing a ways of evolving architecture essentially how we in communicate between the planes a potential line as well would be in the domain apis between the different or strata or even in the within a single stratum so further developing the ideas that we already uh some of them we expose in a previous draft also in nmrg exploring the base apis or approaches for the learning plane specifically so how we could activate or consume the information that could come from the learning plan and maybe also even working on data models or even ontologies for the change for exchanging and aggregating information that could relevant for the operation of the of the system of the network at the end so next please so as last steps so we would like to set the scope of the draft aligned with the scope of nmig we think that this could"
  },
  {
    "startTime": "02:00:00",
    "text": "be the the proper host for for this uh architectural evolution so we would like to do some research in this respect we would like also to have some feedback or at least to see if there is interest from the research group on some of the aspects he had commented we already received some initial feedback i met by carlos sandiego that was publicly expressed in the mailing list but also some informal feedback from pedranjin that was given offline and the idea is yeah with all that we could collect and the the indications from the chairs to prepare new and more detailed versions for next itf and and basically understand if this could fit here or or or not at all so thanks so much thanks a lot luis for very very efficient uh and conscious of the time um general comment okay we may have maybe more time to bring this discussion on the mailing list a general recommendation like i already made it to you previously on some aspect of this week i see that there is a relationship with the topic investigating in the core in research group so uh i'm not saying that it should be handled only in the coin research group but because you put what what is the scope of energy with respect to this work but in your let's say in your iteration of on this work uh please consider to try to laze uh with activities in coin to understand also what they could bring to to this discussion and what will fit more into the scope of coin versus what could be the specific scope to be addressed in energy you see it's it's uh it's really like uh imagine that this is a this is a central topic for you uh what an energy could be the good place to do something and what could be maybe better handled in coin or elsewhere but just as a question of course okay so we have to to conclude the meeting uh"
  },
  {
    "startTime": "02:02:01",
    "text": "thank you everyone for your participation i think it was i mean i appreciated the the discussion we had today especially the topic on network digital trend that was uh uh more central to to our agenda today so we tried to concentrate on such topics in the future we have a lot a lot uh on the agenda i mean all the uh the work stream of energy so uh please continue the interactions i really miss not being in vienna but i see people in the room so please continue the discussion there uh continue the discussion on the mailing list and to all offers uh thank you for your investigative investment in the in the work and i see that we have a lot of uh future version of of the draft uh to be flowing in the research group so thank you everyone jerome if you have any last word of conclusions the floor is here just want to say uh thank you also around thank you lauren so thank you diego for local backup and yes uh how to make you a so our close future in real real person yeah thank you all and have a nice day thank you bye everyone move around yeah no you know that's the curse of the current because in the past you could say no i'm not going to join you because"
  }
]
