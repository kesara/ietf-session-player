[
  {
    "startTime": "00:00:04",
    "text": "is to be a JavaScript where is Brian okay in and fell and Tony will be taking notes thank you guys and blue sheets are going around already a our agenda for today editorial will kick us off with a job profile a with for 25 minutes M then Aaron will talk about a Roth for browser-based apps for 25 minutes Danielle will have to is a sessions to talk about the indie pop and and they push the quests and the Annabelle I don\u0027t see here yet she\u0027ll have a ten minutes and I will wrap it up with ten minutes of what a mr. Jones yeah so let\u0027s get going Victoria all right Victoria yours sorry see if it works oh yeah is this is this a PDF or is it okay so it probably I\u0027ll draw it from here yeah you\u0027ll do it yourself yeah yeah okay let me know when when the drawing all right Bonjour everybody and welcome thank you for taking the time to come here and hear about the progress we made with generated profile for both to access tokens how many of you guys read this back hey that\u0027s not bad at all thank you can we go faster so for the benefit of the ones I did not read this back and for the ones of you who read it while having drinks or other stimulants I\u0027ll give you a very quick recap of what\u0027s in there and above all why we are doing this because that will inform the various things that you need to decide and then I\u0027ll very quickly go through some of the main changes thanks to everyone who gave a feedback and induced those changes and then I\u0027ll place on the table free open issues and at least for one called for consensus all right so it\u0027s the very cup thank you great so why are we doing "
  },
  {
    "startTime": "00:03:04",
    "text": "this once again in a you know current user most for a physician service for trying to use dread abilities for access tokens arise I have made formal presentations in which have presented some research showing that they more or less every vendor uses conveys with some information they just use different syntax and so there is no in very easily opportunity for interoperability and also given that everyone did these in organic fashion very often they went through our to say utilitarian routes which led them to do things with we might define anti patterns and similar so very clearly a guidance voice is not just a problem of interoperability and finally something that I failed to highlight during other updates one thing with you observe very often in the market is the fact that more and more products are asking clients to send ID tokens well instead they should ask for access tokens reason being that in order to actually make a job they need to have a stable format that they refer to they need to have the information but we typically get in the ID token so the outcome is that if you want to use Google methods you\u0027ve got to send them your ID token there are a number of flaws in Amazon but require you to do the same so the hope is that if we create a profile but actually place in the access token where things but those products need then we will curb that practice thank you so in nutshell what we did we define a layout where we lay down the values claims that represent most of the concepts and type of information but we\u0027ve seen vendors are already placing in their existing in production access tokens we laid down some rules about for example determining what should go in the audience how you would mark certain parameters and resource into the actual content of a claim of a token then we went down with details about how you validate this talking like classic enumeration of rules and then we took finally this opportunity to advise implementers for pitfalls piracy shows the security you might encounter when you place with kind of information in the access token and if you want to dig deeper into this we have a couple of links in other events in which I covered and just to make these a bit more concretely Caesar what is smallest durability access token would look like and I\u0027m sure there is nothing surprising in there is like basically what you would find in a skeleton ID token plus one indication about who is the client ID plus with scopes and then if you look "
  },
  {
    "startTime": "00:06:06",
    "text": "at this back there are other things that can be done any questions so far did anyone have our coffee did you check all of your emails or are you still checking your emails Zack wore Facebook for walk or whatever you are using alright let\u0027s look at the open issues so very quickly what we did our way doesn\u0027t say on it Donny as a question got had a face it\u0027s just too mean Edlund so question is are you go back can you go back one slide one more so you said something you were talking about guidance on token validation if your guidance meant to be normative and do you expect to have some conformance do you expect conformance to come out of that so like certain libraries would meet certain validation libraries would meet certain conformance criterias you mean official tests to certify that\u0027s something that could be used for library conformance well I guess that\u0027s and that\u0027s it possible outcome that to me if he sees it didn\u0027t look quite all the way normative when I was looking at it I think it\u0027s fairly now maybe I\u0027m missing vien once or the semantics of normative verses but to me very spirit of visa is to help library implementers to know exactly what to do when they receive is talking and how to decide whether they should accept it or not they exactly in the same fashion as we have done for the ID tokens back here you have exact steps that you are supposed to in order to say whether this is valid or not did I answer the question all right Marquis is not having an adverse reaction so are you satisfied a mere answer you know more of a normative document to come out not necessarily just a guidance so you add you want an extra level something like open ID we\u0027d be looking for to do some conformance testing and stuff yeah well I think they got a lot of a guidance in here is definitely amenable to be turned into conformance testing so I think it\u0027s a possibility for sure great all right so summarizing the changes since the earlier episodes at first all the claims in there were mostly mapping having that source map to open ID and instead we changed visa to actually go all the way to they draw a specification which makes "
  },
  {
    "startTime": "00:09:06",
    "text": "more sense then in the place where we mentioned that that we would have tokens which represent identity I was only mentioning open ID and instead now I extended it to mention also introspection and basically explicitly opened up to any identity potential source of identity claims so pretty much and then also mentioned there clearly vector opposition servers are free to place whatever attribute they want in there as long as we don\u0027t have collisions and similar then I added more details in the privacy sections in particular as a result of early feedback and also misunderstandings thank for example people are started saying things to effect over now that I know where formative access token then I can look inside the real access token from a client which clearly not a good idea so I added language explicitly to prevent that then although I\u0027m told that it\u0027s super early I anyway already with all the restoration templates for jana and then for the off time i had an open issue so i\u0027ll hold on that and then i had in initial note which i was saying a number of existing access tokens in production carry information about whoever the user authenticated directly with a physician server or through an identity provider and a field reference up but turns out that if there was no interest from anyone to actually make anything normative in there so i just took it out and then i had a note in there about finding out whoever victorian is actually a user token or an application token and I have an opening from that but for the time being I just took out the note okay so here is a released all the things that the gardener the most interest and the most discussion but didn\u0027t end up with a clear conclusion on the list so I\u0027m how big and we can use this time to come to a conclusion so let and it basically is a the thing about distinguishing between subject type and then some discussion about the affinity of time behavior and then whoever to recommend infected together encryption or anything but to use symmetric keys for signing or securing the access tokens so let\u0027s look at the first one thank you so here the idea is existing access tokens in the market for various vendors have mechanisms that are used for the API to determine whoever this token was issued for a resource owner or for a or for an application as in does the subject represent a user or an app "
  },
  {
    "startTime": "00:12:07",
    "text": "and it very is a variant which is a was of a token obtained through a confidential client or for a public line what is a like let\u0027s simply find it just look at users versus applications and a very different ways in which people achieve this like for it identity server doesn\u0027t include a sub claim when the token is issued through client credential grant there was a discussion released and the consensus was mostly toward we must include if it\u0027s like if we have a sub sub that has to represent an entity but was authenticated and in the case of a up Israel so you\u0027ve got to have sub in all cases so we ended up saying about the yeah we do need a 12-man so we cannot use these mechanism backwards guys were using for the third winning whoever dave token is an up or not then Carla from octa proposed maybe we can have a claim a grantee type which includes the grant that was used for obtaining wins and the apology for jock already has this claim but they\u0027re in Veliz they were a number of voices saying we shouldn\u0027t burn the burden the resource server with knowledge about this because it\u0027s an implementation detail on the client and of a different server so we basically excluded that approach then there was a longer discussion about whether we should impose a but in the case of an up token you just have the sub equal to the client ID but Vento also doesn\u0027t work well because a lot of current implementations use different internal mechanisms for generating client IDs and the subjects in their own formats subject can also be different depending on the relying party so the and also you don\u0027t want to allow people to choose their own client ID because especially for entity ends up being a mess up for security reasons that we heard during the meeting earlier in a week and then finally there was another proposal but we didn\u0027t really vote on which was let\u0027s just have a claim a new claim that states the natural or the subject is in the service and represents resource owner or a sub represents a application so here basically I\u0027m asking you guys do you have any idea for solving this for me they are like I would love it whether the last one let\u0027s say having a new claim that expresses wins but I\u0027m also up the outcome of this is complicated with as bad implications and so let\u0027s not do this at all and let\u0027s leave every vendor to worry about this aspect in their own and let\u0027s not have it in the intro profile just richer so two things one if you are letting your clients pick their own client ID you\u0027re already opening yourself to be yeah we said we don\u0027t want to do it yeah yeah so that\u0027s where most of the problem of this usually "
  },
  {
    "startTime": "00:15:09",
    "text": "comes in because if the AAS is controlling the namespace of the clients you can make sure that you know the client ID looks like a client ID whatever that\u0027s supposed to look like or if you\u0027re letting your users pick you know gooood x\u0027 as their username something else is probably wrong the other thing is that okay so I guess it\u0027s three things because the other thing is that in a deployment that I did we played around with having the grant type claim there and it really it wasn\u0027t very helpful as it turned out so we we ended up dropping that and just differentiating based on the it\u0027s like the subject and there\u0027s a client ID claim that comes back from introspection so if the subject and client ID are the same then that signals that this is a direct client token Justin do you want elaborate on why you concluded that it wasn\u0027t helpful basically we we figured out that it was kind of a weird bit of signaling of like how this token showed up instead of like what this token was and what it meant so it\u0027s it\u0027s basically it\u0027s saying how somebody got this token and not necessarily what this token should be good for and who this token represents and so it was I don\u0027t know it was just kind of a weird mental jump I mean it\u0027s it is a handy shortcut because you\u0027re probably doing that the other thing and this isn\u0027t something that we ran into in production but the other thing that we thought it was that clients can use you know client assertions to get a token on their own that\u0027s not client credentials grant type and so it\u0027s not necessarily the right signal it\u0027s kind of it\u0027s standing in for something else which is that the subject is the client ID and so that\u0027s that\u0027s the logic that we went which I think is the third yeah the third option there finally Annabelle has a draft for subject identifier is that why you\u0027re here okay but we should do that I think and fantastic Annabelle thinks that\u0027s a bad idea and it\u0027s her draft so she\u0027s probably the expert but perhaps something like that that that allows a little bit more structured definition could be adopted into this because that will what allow us to have more than just a single claim can you expand on what these draft so this draft is in the second dense group and it\u0027s for security event tokens that basically says there is a an object structure for different types of user subjects so you can have more than just a single subject string in the job but it\u0027s all sort of collected into one sub "
  },
  {
    "startTime": "00:18:10",
    "text": "object so you can have an issue or an subject field within that you can have an email identifier a phone identifier each of them with a type field as well so is visa something that goes into a value of a sub claim no no there it\u0027s it\u0027s its own claim separate yeah and there are rules about how it has to relate to the subject claim and it\u0027s not intended for use in this space but from a distance there seems you know squint right and they look close alright thank you now I\u0027ll tell you why that\u0027s a bad idea Annabella Backman Amazon so I that idea flashed through my head and the idea of using subject identifier for this the reason I think it\u0027s a bad idea is that what that draft talks about is subject identifiers and types of subject identifiers so does not talk about types subject so it\u0027s saying I am pointing to some principle that is the subject and I\u0027m pointing to it using for example an email address or a phone number or theoretically a key pair or any number of things that we might define down the road it\u0027s entirely possible that we will have subject identifier types that are ambiguous as to if they could be handles to a user they could be handles to an app they could be handles to an organizational entity any number of things so I I would not it might be interesting to look at that draft as you mate maybe there\u0027s a parallel approach to follow here but I would not say throw subject identifiers at this specifically alright um now what I actually got up to up here to say is two things I agree with not using grant type in particular because it is tightly coupling this concept to specific protocol implementation details and doesn\u0027t really make sense to tie those together what what makes sense as a mapping between those two which grant types apply to which you know subject types that mapping may change over time it\u0027s going to get more complex as new grant types are introduced as new subject types are introduced it\u0027s unstable and it would be really burdensome to try and ask the resource servers to all figure that out and understand that if if you\u0027re having your resource servers understand that then at that point there\u0027s probably enough coupling between your authorization server and your resource server that you don\u0027t need a standard way to do this anyway I had a third point which hopefully says how we do it yes no no actually of course not that would be easy I was wondering if you could "
  },
  {
    "startTime": "00:21:10",
    "text": "quickly summarize what the use cases are that people are solving or trying to solve by differentiating between user and appetizer or what are the surprises where they need some specific mechanism to do that so I tried to tease these out from any people aback we\u0027re already doing these and these Kaiser was mixed with a case in which the API wants to know whether the client was a confidential or not mostly because of that gives more guarantees about better client ID actually being a client and the other case is for when they want one particular client ID to be say the one but actually they\u0027ve the one here is the only one that can call and there are certain our physician servers that can use the same client ID in a different capacity you can have a client ID but when you are using it from an iOS app is just doing the public client flow with code when you are using it on a server side instead you can do the proper kind of credentials okay that sounds like it\u0027s less about user versus app and more about how what are these circumstances under which this client and byte by client here I mean remote piece of code that is calling me what are the circumstances under which it\u0027s been authenticated and what the circumstances under which whatever user may be interacting with it was authenticated by me and I think that\u0027s very different from user and applicator versus app as two different subject types what I think of is kind of three legged OAuth versus two-legged OAuth like is there a user involved in this relationship at all or is this just a client calling on behalf of itself so I really think you\u0027re probably asking the wrong question here so yeah and if you\u0027re just gonna go in time check you have a few minutes over so see wanna try to I think you have one more point so you write yeah do I have points but okay it\u0027s a good point thank you thank you Justin richer what Annabel just said and I have a concrete example for that if people want to talk about it with medical records so great just it exists okay so on in the interest of time for this point we\u0027ll go back to release and I left week Lisa to be rather than subject type determining whoever the client was a confidential gossip actually a vindication get ladder to be okay I think Annabelle made a very good point we need to rethink the question here and maybe reach out to the guys again I think that that was very good insight great thank you okay these are is another tough one the idea is that when you use these access "
  },
  {
    "startTime": "00:24:12",
    "text": "tokens in for example a first party scenario in which the access token is way only artifact that you are sending to API there are a number of the things that you normally get in the ID token such as the time at which you authenticated and the type of authentication that you use and similar become important because you might have policies that you want to enact on top of these depending on what you receive and so basically we need to take these information and place it in the access token as well and a lot of providers are already doing this organically in the wild of course we challenge what we have in here is that the momentum of education is not corresponding to what to be a lifetime lifetime of a token so basically here we are placing claims whose value is determined elsewhere like for example the moment in which you sanidine and you got your first batch of tokens or if in the middle of a current session you have to do a step-up authentication and then we authenticate from time changes and the method of authentication changes when next time you use the corresponding Refresh token we need to reflect it into into a claim to the token and here like they need from the practical and business perspective it\u0027s very clear let\u0027s say people already do this so but at the same time when we discussed these some people on the list expressed unease so I just want to give the opportunity to other people that unease to bring their concerns and if you have alternative solutions that of course still deliver on the requirement then this is your opportunity apparent Campbell thing I one of the doubters and I continue my doubt but I accept that it\u0027s gonna be in here because yeah requirements and people are going in anyway but I get I do get really nervous about what like what you just said a step authentication in a session after token was issued should somehow be reflected in the auth time of the next token on refresh that\u0027s that sort of thing is is like drawing a lot of links between things that aren\u0027t really linked and I\u0027d like to see it at least clarified to this is this is the auth time or the AMR whatever that was used at the time of authentication that the grant was approved or I don\u0027t know the right language it\u0027s hard but creating some sort of ephemeral and imaginary link between an ongoing session and however one might describe that and issued access to friends off of some other artifact the Refresh token I think is it\u0027s super confusing and "
  },
  {
    "startTime": "00:27:12",
    "text": "potentially dangerous I agree it\u0027s confusing for the dangerous I think we should yeah expand it I think about it we lever to solve this problem somehow anyway because I get to make another example say that you have this access token tied it to a session we were certain token the Refresh token and the Refresh token is a supporting rotation and save it someone abuses the rotation and uses the wrong token and have a right time and now you have to gets a revoke all the Refresh tokens and allegedly also the access tokens that were issued as part of that so you rarely ever that link is just vector in this case you are you are using that link to reflect potential changes in the off time but in the other case instead of you use it for doing verification but the thing is this link between session refresh tokens and access tokens already exists in various other aspects part of that is when you say allegedly it doesn\u0027t exist it\u0027s potentially some link that\u0027s done at implementation time and and even if it does exist it\u0027s super weird to have a step-up authentication that happens in a completely different context and have access tokens reflecting that were issued off of a different authentication context reflecting that sort of in some magical real time sorry guys yeah yeah I need to cut the line here and you can drop oh okay sorry if we are skipping goes to the last point there so you can\u0027t you can talk about this the last point but I don\u0027t want it okay great so fun Annabelle you\u0027re good to to come soon I just want to give an alternative view of where that would be useful and that\u0027s if you are doing an oauth2 authorization request in a context where an earlier say password-based authentication happened but because of the nature of the oauth2 authorization request you need to do step up at that time then you\u0027re going to have a case where your password based authentication might have happened yesterday but your step of your two-factor whatever you\u0027re doing happens now so having having those as two different pieces of information could be valuable having said that I think given the ambiguity of the term step up and to factor and all of that and the wide variety of implementations I think it\u0027s gonna be very hard to really formalize a nomenclature for all the different things we\u0027re gonna want to talk about here so this may be a place where just having the an opportunity for the different vendors to plug in whatever they need might be more useful great tech for time reason not but I "
  },
  {
    "startTime": "00:30:14",
    "text": "think what I\u0027ll call this out specifically Melissa there is a very language image spec which is along those lines so let\u0027s look at great just perfect so Anna here I\u0027ll just present basically we Ave at the very beginning of a recommendation to use a symmetric crypto for signing tokens because it\u0027s just easier for people to have a fixed sequence of stats for retrieving stuff for metadata and similar I don\u0027t suggested that we should actually require it and I\u0027m not against it but at the same time I know that privacy conscious people were pushing to also include in their recommendation to use authenticated encryption the thing is reka indicating the corruption today the only specs we have all use symmetric kids and if that makes me very uneasy because now I\u0027m leaving as exercise to the reader something which is super important which is acquiring their stuff you use for tracking tokens and at the same time like I saw basically here I wanted to hear from you guys what that parent will be run on yeah yeah I agree we\u0027re another fan okay sorry thank great thank you Thank You Aaron my chance jwe does authenticated encryption but first by using public key key derivation so the symmetric key is a transient artifact it\u0027s all doesn\u0027t done using public key cryptography okay this is gonna be a whirlwind I\u0027m Aaron Preki great look at that so if you\u0027re who here has read this draft ever curiosity this is a fun game to play great okay a few of you so the summary of this of this draft is that it is recommendations for people who are building browser-based apps or JavaScript based apps or single page apps whatever you want to call them that are doing auth to in a browser which typically means that that the browser ends up holding the access token but we\u0027ll get into some of that so that\u0027s the sort of overall scope the read this is sort of supposed to be the parallel to the native apps best practices that that we already have this is a summary of what the document currently says some of these points are currently up for debate so the recommendation for browser based apps use auth code flow plus pixie do not must not return access tokens in the "
  },
  {
    "startTime": "00:33:16",
    "text": "front channel which rules out the implicit flow completely must use the oauth2 state parameter for CSRF protection it absolutely requires exact redirect URI matching that\u0027s actually changed from last last time we met and there is a recommendation that access authorization servers should not return refresh tokens and that one is one of the points we\u0027re going to talk about but that is what we had currently discussed before we started having discussions on the list so some changes since the last meaning exact redirect URI is new it used to say same domain redirect URI matching which yeah I did a whole restructuring of the document to split this into describing essentially three architectural patterns for this kind of app deployment and one is architecture patterns is when your everything\u0027s on the same domain the resource server the client and the authorization server and there was a bunch of clarifications and typo fixes that a bunch of you help me find so thanks for that this is one of the architecture patterns single page app with a back-end and in this case this is this is one of the things that I think we need to discuss a little bit more about what we actually want to recommend here the recommendation here is basically that if you if your single page app has a back-end then you should actually do o auth in the backend component and not do OAuth in the in the JavaScript code at all the question then becomes do we say anything about whether or not the access token should actually live in the JavaScript app or if that should be something that is not the access token like an encrypted session cookie or some other thing that\u0027s a point up for debate this is one of the architectures one of the other architectures is a single page app without a back-end which i think is probably actually a less common pattern but it is still possible to do this and plenty of people do have situations where this is necessary and that is where your JavaScript app is served from a web host that doesn\u0027t have any dynamic back-end itself and it talks then directly to the resource server in efficient servers and in this case the browser app does in fact carry ahold the access token it has to actually have access to it and you can\u0027t do any cookie level protections of it so same doing applications this is one of the ones that\u0027s gotten a lot of discussion on the list which I think we need to come to an agreement on what exactly is the scope of this document recommending here so same two main applications what I mean by this is that when everything is on the same domain or sub domains so if everything is off of example comm like resource server example API two example com auth dot example comm and app example com they can all share cookies on example com so you had end up actually not needing off at all for one and if you do still want "
  },
  {
    "startTime": "00:36:16",
    "text": "to use OAuth there are ways to protect it better than actually having the access token end up in accessible from JavaScript so right now the document says maybe you should just avoid using OAuth and do some on your own maybe that\u0027s not the best recommendation we should be making for an OAuth spec but it does but but actually using OAuth as written in this situation is actually worse because there are more holes that can open up when you have this protection mechanism that is already otherwise there so that\u0027s a first point the redirect the redirect step where everything\u0027s being passed around over redirects is where a lot of the flaws come from an OAuth or a lot of the holes come from and you don\u0027t actually need to do that if everything\u0027s on the same domain but having a separation between a s and RS and all that is useful because it lets you centralize your account management and MFA and all that so there\u0027s a couple different approaches we could do we go here I guess we could say that the scope of this document assumes that you\u0027re going to be using OAuth already and we ignore the case that you might not use OAuth and only talk about how to do OAuth in this case in which case what exactly do we say about this case is there anything unique about this case or we try to say that there is a particular recommendation for same domain applications that maybe doesn\u0027t use OAuth maybe uses OAuth in as a new way so I\u0027m curious about thoughts on this bucket this is one of the three the three architecture patterns which we discussed in the last meeting and on the lists and now we\u0027re kind of seeing that some some questions around it I\u0027m gonna look forward really quick yeah okay let\u0027s talk about this one and then I have a bunch of other open questions Justin richer yes this absolutely this discussion absolutely needs to be in scope because people coming in outside of the auth working group are going to be saying I have a browser-based app I\u0027ve heard of ooofff what do I do and if I get to an official document that says hey if your app looks like this don\u0027t use OAuth I might actually do the right thing and not use OAuth so I think it would be a dangerous disservice to the Internet if we remove this part of the document that said we do have to be very clear about the boundaries around this which I think we can continue to clean up the language there was some discussion on the list in the last couple of weeks about framing this in terms of if your back end still does oh off that\u0027s fine but that\u0027s outside the scope of this document the other part of this is that I know a lot of developers will look at their SP a with a back end and will see a back end "
  },
  {
    "startTime": "00:39:16",
    "text": "less SP a with an API that they\u0027re calling even if it\u0027s on the same domain and all of that other stuff conceptually in a lot of cases the SP a developer and the API developer are separated from each other so they\u0027re seeing them as decoupled services and therefore looking at Oh F as the solution for doing that so because this really addresses a deployment pattern and not necessarily an application type we have to be careful with how we describe that so that we are routing people to make the right decisions I think that\u0027s absolutely possible and absolutely necessary that we keep this in this document the audio of zero I agree four hundred percent that we needed to be giving guidance to people they and if the guidance is for this particular deployment don\u0027t use off use these other mechanisms that what we should say the thing right there I will be careful about is helping people to understand the implications of a choice exactly this is something that I\u0027m trying to do on our cellular product but the thing is if people do that and they write our API with some meter world which expects a cook as opposed to a talker and then maybe take miss API and expose it to other clients and now is API is expecting the cookie than the other clients will not be able to use or even in the future they make architectural changes and these deployment no longer works people needed to understand that they need to backtrack from his approach and then use the other one and then if it\u0027s likely that their future looks that way then perhaps they should use off in this particular case because otherwise we\u0027ll do their work twice so long story short I think we should tell people this is a simple and way of doing this or might not be the right tool but we also need to have them understand what are the implications of an architectural choice is moving forward yep thanks on the mic sorry I wanted to clarify it doesn\u0027t necessarily mean backtracking from from there are critical choices it might mean augmenting them it is totally possible that a API can accept a cookie or an access token of protective there\u0027s like but it might be hard repeat that though sorry Pizza Pizza us he said depending on the developer stock which is fair but I actually came up "
  },
  {
    "startTime": "00:42:19",
    "text": "here to be jabbar scribe on behalf of dr. Torsten ladder staff yes comm he says I think same domain applications do not belong into this BCP if you want to describe that pattern write up another ID we need to either describe it with all the consequences including the threat analysis and security recommend recommend a shion\u0027s so okay so I\u0027m hearing a couple different things here and possibly probably committing this analyst but possibly one of the ways to reconcile this is not calling it same domain applications and instead trying to find a pattern that describes this architecture other than the fact they\u0027re on the same domain because it\u0027s that\u0027s not a distinction that Olof normally makes so maybe that\u0027s not the appropriate distinction to be making in the spec but we need to find I think to Justin\u0027s point we need to find a what are people going to be looking for in this document when they have the situation we\u0027re trying to describe what\u0027s what\u0027s their keywords they\u0027re gonna be looking for and that way we can still cover this content but maybe not with the same caveats or same distinctions which I think would also address Hurston\u0027s point I think yeah we probably have to discuss this a little bit further but it sounded like very different advice from different set of yeah so we have to find out what that or we have to find out what maturity at least thinks which direction we should go because I thought that was actually quite good in the sense that you are recommending not to use ours but you\u0027re not saying what what else they should be using so in some sense we\u0027re not doing a straight analysis for the other solution that may not be an idea of topic at all I don\u0027t know yeah that\u0027s also also a good point if if we\u0027re gonna say don\u0027t do this we should probably have somewhere else to send people to tell them what to do okay so it sounds like we\u0027re not gonna be able to get through this one in any more progress here so let\u0027s move on to the next because I do have a bunch of other do you have something else it\u0027s fine if it\u0027s not in scope but I think there\u0027s a real opportunity for sort of complicity by omission if there\u0027s nothing no mention of it in the document people will come to it and assume that means it\u0027s the right thing to do so I don\u0027t know if it needs to be an architectural pattern or even just description in out of scope it doesn\u0027t mean this something some mention of the possibility that this is not the only way to do it I think it is necessary in the document I don\u0027t know how but in green with Justin there okay thank you any other points on this topic from people who I haven\u0027t heard from yet no okay so there\u0027s a handful of other open questions what\u0027s the time check ten "
  },
  {
    "startTime": "00:45:22",
    "text": "minutes left okay these are I think small issues but these are all ones that we were not that year there was some points on the list that I went back and forth on we didn\u0027t come to an agreement on yet so let\u0027s just are the top state right now this effect says use it for CSRF protection even though it also says use pixie security best practice says you can use pixie force tape for CSRF protection so those things don\u0027t quite match there are some issues with the fact that the the client doesn\u0027t know that a/s supports pixie but in this spec the S has to support pixie so the client should be able to know do we actually want to still say that state has to use for csr protection or should I take that out because theoretically is covered by security BCP and using pixie any strong opinions if not we\u0027ll just skip it and deal with it later I think so so we have very carefully designed the language that we have in the security BCPs or probably a reference to that would be fine that which means so you state you must also use pixie if you\u0027re actually used pixie you might want to drop state under some circumstances oh that doesn\u0027t sound good at all because right now it actually says you must use state for CSRF protection and I\u0027ll be rolling that back into like and I don\u0027t think this is special - okay really I think unless we identify something that\u0027s really special to the SPS yeah if there\u0027s nothing you need to SP a situation then it is probably better to not mention it yeah from Jabra Phillips\u0027s leave it out or rough BCP covers it okay um I\u0027m gonna come back to refresh tokens in a minute pass for grant right now there is it basically says you should use auth code and pixie but if you really need to you can use the password grant can we just say you can\u0027t use the password grant because I don\u0027t think that\u0027s a good idea for anybody I\u0027m seeing a bunch of nods of yes let\u0027s kill it I\u0027m a chopped Bradley yubico I\u0027m in favor of removing the password crap because it\u0027s just great that also means I can simplify I can make it a must use auth code and pixie which clarifies everything in the scope as well there\u0027s "
  },
  {
    "startTime": "00:48:22",
    "text": "a plus one from Torsten great okay that\u0027s pretty that\u0027s pretty raising my plus 1000 okay great section nine point eight in the document it this is I might just talk to Torsten about this there there is a list of security issues specifically with the implicit flow a lot of these refer out to the security BCP for the details and there\u0027s just a summary of them there are a couple in there that are I didn\u0027t see in the security BCP that are unique to the implicit flow and I put them in here because people you\u0027re writing JavaScript apps are coming out this with the history of having used the implicit flow and I wanted to specifically call out like here\u0027s all the reasons not to do that which is why you should be doing this instead I think it was Torsen who suggested just saying hey go read the security BCP for this but I think it\u0027s important to keep a reference to these in this document because of the baggage of because of the history just enricher plus one we need to keep in mind what people are going to be looking for and what people are going to be using this document for and that\u0027s more important than our idealistic structure of documents and information okay my goal here is not to repeat not to duplicate all the analysis and and the the content insecurity BCP I would but I do want to have a summary of when there isn\u0027t overlap I want to summarize it and then link out to it I think that\u0027s I think that\u0027s safe and you still refer to that yeah yeah refer normally refer to the security BCP when it when it mentions one of the points I\u0027m trying to make but I think people are gonna be looking for it here instead okay for the oh yeah this I kind of mentioned this for the single page app with a back end do we need an indication that the access token may be sent to the browser and I guess that would be an indication to the resource server or authorization server that this access token actually may end up in a browser which is not a confidential client which has a totally different threat model than the confidential client this is an interesting one and there\u0027s no mention of this right now in the document and I don\u0027t actually know of anything else that\u0027s sort of doing this the benefit to this is that the a s would be able to make better decisions about token lifetimes and when every prompts rough indication things like that as it is right now if you write an OAuth app and you just go and you get a client ID and client secret and then just don\u0027t use the secret the a s is gonna think that it\u0027s a confidential client the S may know that the grant happened without the secret but there isn\u0027t really an indication that whether that access token is you know held tight or ends up in a browser okay so I don\u0027t know what the solution would be here we we need to talk about what mechanism to actually "
  },
  {
    "startTime": "00:51:22",
    "text": "use for this but it wouldn\u0027t need to be some sort of communication about the access token or about the grant that says the client is probably gonna give this to a browser which is a much less trusted environment does this sound like something people would like to have a mechanism for and then we figure out what the mechanism is later some nods some nods anybody really opposed to this is anybody like think this is totally pointless not securing alright I just question do you really need to send access to a computer browser well this kind of use case that is a good question in it makes some deployments easier because you can avoid having a separate session with the server um we could also say don\u0027t do that and like force you to require to send it to make a session but then that does is like limit your architecture a little bit it requires you to do something else I wouldn\u0027t be opposed to making that a requirement for this architecture though because it does clean it up Anabelle back in an Amazon um else I think there are use cases or access tokens and other kinds of credentials being sent down to the browser and use directly from there tonight can I enter that it does it does it is the particular case of there is a back-end that\u0027s gonna be proxying API calls so this is this is this particular case for the case where the total yes in the case where the the access token is actually being acquired by a back-end but is yeah there\u0027s there\u0027s communities for acquiring it on the back end and then supplying it to the front-end for use from there they\u0027re what actually add up to here to say is that I\u0027m not strongly opposed to a signal that this token is going to be sent to the browser but I think we have to be realistic about the fact that we\u0027re handing access tokens to a client and oftentimes we don\u0027t know what the hell they\u0027re doing with them so I be cautious about creating a false sense of confidence in the client behavior by including something like this it\u0027s ultimately kind of opt-in on the part of the client anyway and if you are being really sophisticated you can probably detect things like this without an overt signal okay jabber on jabber on behalf of Torsten he says I don\u0027t believe this is a good idea without Sundra constraining which I think makes it really hard but um in a Brian here on my own behalf I I think I "
  },
  {
    "startTime": "00:54:23",
    "text": "kind of agree with that about it I feel like trying to build explicit signals here is a super slippery slope that gets hard like we\u0027re gonna have a I mean this is one specific instance but it\u0027s like you you want some kind of signal here for a client to tell you just how promiscuous they\u0027re gonna be with the access token it\u0027s like I it feels really yeah okay okay not good to me it\u0027s like you know I don\u0027t know when I set my password with a provider they don\u0027t ask me are you gonna share this with somebody else and make different decisions about rotation policy based on my bad decisions or my my signalling intent about my bad decisions it\u0027s that\u0027s a fair point right nothing that it\u0027s gonna happen it\u0027s like everything\u0027s on a protector it might be a good idea but yeah victory of zero I think we have a argument about there we can\u0027t protect everyone in every situation doesn\u0027t mean that we shouldn\u0027t when we already have some knowledge of a topology in this particular topology we know what\u0027s going to happen because we are telling the implementer how we want them to behave and at that point they\u0027re given what we said earlier about the scenario in which the resource owner the source server wants to know whether we are being called by a confidential client or not in this case it seems that having something that helps we\u0027re positioned server at least to avoid whatever would be used for signaling this was a secure client is should be a must let\u0027s say that I wouldn\u0027t feel comfortable with recommending people to do this without also telling them here is a way of somewhat defusing their potential power or this socket and then it\u0027s true where people can take your talk as simplicity and a public folder Google Drive and you cannot prevent that in this particular case I think what that we very least even if we don\u0027t make a mechanism even if we don\u0027t invent a parameter we should put in the notes if there is any way for you to tell that the authorization server a particular physicians have an implementation that\u0027s your intent then you should make it manifest okay and Annabel Backman Amazon I think we should think about what the alternatives are here for the from a topological standpoint if I\u0027m a client and I\u0027m passing an access token down to the browser so the browser can make calls directly the alternative topology there is presumably be the browser client making a call up to my end point and I\u0027m resolving some kind of session token\u0027 or something in the cookie to look up an access token and a database in my side in which case I\u0027m already dependent on something in the browser like it made it may or may not be exposed to JavaScript once again my access token going to the "
  },
  {
    "startTime": "00:57:23",
    "text": "browser or what does that mean does that mean I\u0027m giving it to JavaScript does that mean I\u0027m putting in a cookie that you\u0027d have to distinguish that but my point is that we already have to think about the downstream effects of the clients decision of how to how to authenticate their own and how to secure their own kinnor actions with the with the browser client that impacts us whether the access token is stored in the client or in the browser or in this on the server side you can kind of cut line after Brian it\u0027s actually about four Torsten again be a jobber why using a back-end if in the end you send the eighty to the browser so that is a fair question some people do it is the answer reasons is the answer and ITP okay I think I\u0027m out of time but there\u0027s this whole whole topic which we unfortunately now will have a lot of discussion time for visit but the topic is refresh tokens in single-page apps there was a lot of good accession discussion on the list reasons that it\u0027s a good idea and also reasons it\u0027s a bad idea and I\u0027m not seeing a lot of ways to reconcile this guidance right now the the document says you should not include ascend refresh tokens to browsers that feels like not enough of a guidance for the situation there are a lot of reasons the good idea reasons is the idea so some ways to resolve this situation we could say there should be no bearer refresh token so it requires some sort of proof of possession which is sort of undefined in this situation right now we could require that refresh tokens have a limited lifetime and that would either either time based or based on authentication session we could leave that part up to people but requiring that they have a limited lifetime would I think helps some of the concerns people have with issuing refresh tokens to the browser requiring that they rotate is probably good idea it\u0027s also mention about security BCP I feel like that\u0027s worth again calling out here and saying go look at the security BCP for the details if they are rotated should the new one get the new lifetime again or keep the same total lifetime of of the initial refresh token because if they extend out the the lifetime then it\u0027s essentially an infinitely long Refresh token which was one of the concerns about browser apps or do we just take out any mention of refresh tokens from this document because there isn\u0027t an agreement and you are just gonna go and figure out figure out on your own anyway so that\u0027s the list of potential decisions that came up with based on the discussions I don\u0027t know what the right answer is I feel like not "
  },
  {
    "startTime": "01:00:23",
    "text": "mentioning it as bad I\u0027m kind of leaning towards definitely requiring rotation and not like having to extend a lifetime and making sure that\u0027s clear because that helps eliminate some of the attacks people were describing I don\u0027t want to not require bearer tokens big bear refresh tokens because there isn\u0027t really solution for that right now so it doesn\u0027t feel practical I go ahead okay but right last comment yeah go ahead cut the mic spa\u0027s need a way to get fresh access tokens or access tokens for another RS with using resource indicators without refreshed hook and what\u0027s a reliable way to get those iframes rely on third-party cookie access which is in the crosshairs of pretty much every browser vendor nowadays constantly redirecting blows you act so no so does pop up since it requires in user interaction either we put forth restrictions on the ass and client to be able to get refresh tokens eg using pop Center constrained rotating on every use something else or get searching for a completely new mechanism oh Jesus we need sorry apologies no need to proxy Brian Aaron is on the same I\u0027m glad you got city okay well that was the fun that\u0027s a fun discussion I guess we\u0027ll do with that one is I will actually put the other little proposal on make a new thread on the list we can talk about that again there and keep it going so thank you very much hello Dan is that from Liscomb I\u0027d like to present two things today the first thing is the earth to zero demonstration of proof of precession at the application layer or D pop shot what do we want to solve for the solution as you might know the or security PCP and we\u0027ve just also seen the SP a BCP makes yeah good points of using similar constraint tokens but currently we do not have suitable mechanisms for sender constraints constraint oaken\u0027s for SP ace and probably also some other requirements in areas we have MPLS which is good you cannot really use that in browser and we also token binding with the lack of browser support and the future is pretty unclear of that therefore in Stuttgart at the last world security workshop we started drafting a solution on the application layer and I think Brian came up also with a name for that "
  },
  {
    "startTime": "01:03:23",
    "text": "that\u0027s on the bottom right corner he sought an es fan yeah that\u0027s our Deepak came to be what we want to do the main goal of deep pop is to prevent token replay at a different endpoint more precisely if an adversary is able to get hold of an access token or refresh token because the adversary setup a counterfeit authorization server or a resource server then the adversary should not be able to replay that token at a different endpoint authorization or resource server so that\u0027s the main goal of Depot as I already said we started discussing discussions in March I created the first draft in product during the last ITF meeting and now we are at version zero two and this is what the current proposal looks like we have the client on the left and we\u0027re in the client sense the token request to das then the client attaches a deeper proof what that looks like we see in a moment and then the client gets back if the AI supports D pop a an access token that is deeper bound this is signaled by the token type D pop and also refresh tokens for public lines at least that our two bound to that deeper key n on when the client wants to use an access token for example then it also has attached a deeper proof to that one and it\u0027s not worth a that we use the same proof structure the date token structures or two say in the token request and in the exit when the access token or Refresh token say used it\u0027s this okay this is what ad prop proof looks like in a header you can see that we have a type of epub plus JWT and we have a public key and in the body of the JWT we have things such as a token ID we have the HTTP method of the HTTP request to which the token is attached we have the HTTP URI and we have a timestamp and all of this is of course signed with the private key that belongs to the public key in the header in the token request the depop token is added to a new HTTP header called depop and when as I already said so this is additional to all the stuff that we already have in the token request which is completely unchanged if the a has supports depop then the AAS will send back the "
  },
  {
    "startTime": "01:06:25",
    "text": "access token with token type deeper otherwise if it doesn\u0027t support deeper then everything will go as normal and the client will see that the AAS does not support deeper now the resource access in the resource access there is an authorization header as before but the token type is not Vera that is depop therefore the header is depop and then the access token and there\u0027s a deep opera as before with the deeper proof belonging to the resource axis in the introspection response or if you have agile UT access token there\u0027s a CNF claim signaling that the access token is bound to some key and in the CNF claim there so Jake 80s to five six claim which is the basics before URL encoding of the JW key 2:56 thumbprint of the public key to which the token is bound that is the resource other can check that a deeper proof was presented for that access token regarding the security of PC of the pop we have server features that prevent token replay we have the jei the token ID and IIT the time stamp which together can be used to to maintain a list of tokens that have been seen and that would in theory be still valid we also have HTTP URI and HTTP method which bind this token to the access or through there to the request status make to prevent a swapping of Depot tokens Depot proofs with other JW teas that are traded somewhere we also have a tad claim which has the unique value that must be checked we don\u0027t allow the signature algorithm um and regarding message integrity which is not guaranteed by the prop as you can see there is no signature about the message buddy of course you have the transport layer of course use enter and TLS if possible but really if you want to prevent that a token resource endpoint that is manipulated or that is malicious uses the token at the same URI at the honest endpoint then you can or with changing the request body then you can also bring your own data and sign it in the Deepak token so it\u0027s extendable if you really want to do that but it\u0027s definitely out of the scope of this specification M TLS is a more rather robust mechanism if possible use M TLS but as I already said in some situations is it\u0027s just not possible okay "
  },
  {
    "startTime": "01:09:28",
    "text": "Honus yeah speaking as as myself here we have it team working group items that pretty much do the same stuff they don\u0027t have this shiny named of um and I was wondering on whether you had sort of like considered that work because one part of the work is is actually split into documents one part is the key transport which we talked about last time where it was made his comment about do we need to add a proof there and which was followed up with this formal analysis and then we have the second piece of work which Justin was asked or is be heading the assigning which of course has the very same does mean a more or less the same stuff in a you know in we have different incarnation incarnations because there were issues challenges I think that\u0027s yet to say request signing had always had some challenges in this group so I\u0027m curious on why what motivated you to come up with a completely new mechanism instead of just reusing what you already hadn\u0027t had to sort of get that finalized so I think others here my chimed in on that because they\u0027re more familiar with the other drafts I can say that depop is a very simple very concise mechanism that is we also have already some working implementations of that because it doesn\u0027t actually it actually does less like from a functionality point of view and what we previously did with the ACE working group we tried to as you remember we tried to balance this work with ace and RTC web because they needed the approved possession mechanism and they also encoded the fields in co-op and we had the corresponding but in HTTP because we said that we would do the HTTP stuff here the core there is working group does the court stuff there so there was kind of a understanding and so now we I\u0027m feeling we\u0027re doing the same thing twice even like you had in earlier slides you have this you call it a deep op pro possession I forgot what the name was in the other case because it was also finding the key to the token so yep well maybe correct okay so not so camera alright so oh you know kind of wondering the the graduation ship of this draft to the key distribution draft which is and and then also there\u0027s a draft that I wrote a while ago which is called j-pop of which "
  },
  {
    "startTime": "01:12:29",
    "text": "a part of the spec was actually taken out to become an TLS but this one is looks like trying to do more that\u0027s the same thing except that this can only be used for code for Wow in that case because we arrived Jpop is wrong on key description we can actually be useful it was the first oh yeah Brian try to put some color on on the origins and some new history here to it but these not address but talk to honest questions a default came out of I think a desire and a real need from developers using this stuff for a simplified concise mechanism to do public key proof of possession for an access token both at the authorization server and the resource server and while it bears a lot of similarity to some other things that are in progress it it it does I think it does more with less its it delivers that public key proof and for both the the delivery and binding the access tokens with the authorization server as well as using them at the resource server so it\u0027s it has a lot of conceptual similarities but I think it\u0027s it\u0027s significantly simpler has a more straightforward model and is much more concise me I asked you on explaining me where it is simpler for the two interfaces for the interface from the client or authorization Southwest more simplicity in their tedious in its both in the well in in my view it\u0027s simpler in the key distribution because there\u0027s there\u0027s not the overhead of the potential of symmetric keys the key distribution itself works the same way for both presentation that are us and they ask it\u0027s it\u0027s the authors it\u0027s the client saying here\u0027s my key here\u0027s proof of it this is what I want to use and it\u0027s I imagine it\u0027s super simple for more information implementation is quite a symmetric keys because because we worked with these other groups that asked for symmetric keys and they have isometric Easterday that\u0027s why it\u0027s in there because because we had to align with these other groups so I think you\u0027re giving that sort of a natural tension here that that you\u0027re working with those other groups and they\u0027ve taken on a lot of time just me it\u0027s like but despite the there\u0027s work here that\u0027s bits aimed at deployment and use in the wild and I know there\u0027s other groups that\u0027s building on top of all off but this is specifically geared at deployment and usage and the possession distribution stuff has taken on a role of being an underpinning for additional "
  },
  {
    "startTime": "01:15:29",
    "text": "work within aids I guess I guess other working on how to wear on RTC web so I there\u0027s some tension there but this was maybe an end-around from that work because it has a more explicit and straightforward goal including not symmetric keys because there\u0027s no mechanism for proof of symmetric keys and trying to account for that significantly complicates things as you\u0027re probably we\u0027re trying to have written it in in the document I mean I frankly I\u0027ve wondered at times whether the the pop t-distribution document shouldn\u0027t actually we had that discussion and this group decided that it wants it has to be here because it\u0027s the HTTP but so on that topic of symmetric I will say I was going to actually ask the question of why the specs specifically limits this to ace use of asymmetric signature algorithms we found that there are use cases where asymmetric signatures are still just too slow the idea was to make this as simple as possible okay so I guess a question none for the working group is is there a significant enough win in terms of simplification to warrant having a mechanism for proof of possession that is specific to asymmetric signatures or does the proliferation of pop methods outweigh the that that simplicity gain the other comment I have on this is the draft mentions being able to bring your own data piece but it doesn\u0027t really get into exactly how that would fit into it the the the job it doesn\u0027t provide any likes like III would expect to see at least some claims defined for the typical things somebody is going to want to sign like a request body or headers or yeah yeah so maybe we can draw from out get to some of why that is important in my talk yeah okay good so the origin of this came to security I\u0027m gonna cut the line sorry I\u0027m gonna cut the line no John Bradley yubico so the origin of "
  },
  {
    "startTime": "01:18:29",
    "text": "this came from the security workshop where we\u0027re specifically focusing on what could we do for single page applications to do proof of possession should token binding not come to fruition so we set out we said okay we could use web crypto and create an onyx portable key in the browser and these would be the mechanisms they that we could do it so that\u0027s why is there no symmetric keys because there is no way of protecting a symmetric key in the browser and being able to do proof of possession so this describes how we can address that particular use case if the working this lays out a way to do it if the working group wants us to refactor yes we did take the ideas of Justin\u0027s draft which is not currently active and but I believe it\u0027s expired so so okay so it\u0027s expired for reasons so it is entirely possible to profile should we reconstitute that document we could profile that document this is what we specified is a subset of that document and arguably the way that we\u0027re publishing the key to the authorization server at the at the endpoint is a subset of key distribution but we\u0027re not distributing a key we\u0027re using a very small set of that so could we do this as profiles of those documents should those documents actually be active sure but this is essentially our core use case document if you want us to refactor it to use other specs okay but those other specs have to actually exist didn\u0027t be making progress but this is a concrete use case of people something that people actually want to do to bind tokens as we talked about in Aaron\u0027s presentation there is no way currently for you to actually do group uh possession of the Refresh token in the browser should somebody use this mechanism they can\u0027t actually protect the Refresh token in the browser so this is a real use case there is I think we need to actually address the use case if we want to address it in the very narrow sense and yes we took out all of the other stuff that addresses a bunch of other use cases so that we could actually focus on what\u0027s the minimum that we need to do this we want to refactor this to point to the other specs I\u0027m perfectly okay with doing that we\u0027re not saying that the other specs don\u0027t have value but we needed to focus in on what is this use case how can we we solve it exactly how we format the spec I\u0027m completely okay II plus one "
  },
  {
    "startTime": "01:21:32",
    "text": "Mike Jones Microsoft I\u0027m actually representing right now our engineering teams who did a detailed analysis of whether and how they would use the spec and there were three sets of comments they had one was they want to use different pop keys for access tokens and refresh tokens it\u0027s my belief doing a cursory analysis that they could just use different keys in the request and have that work and the keys are not just maintained as state between different requests off the top of your head am i right yep I think some could be okay think about that but I think I was right when I told them that second they were a little bit surprised by the tokens issued being bearer tokens and then there\u0027s secondly being a perv that\u0027s distinct from the token which it\u0027s up to the recipient to check the proof using information in the bearer token that it actually is attested to you now I understand the reasons for that that all of that you could by adding this proof header continue sending the access tokens using 6750 using authorization bearer token and resources that don\u0027t understand that there\u0027s also prevents nothing that\u0027s not how it\u0027s currently in the traffic so currently we\u0027re using the yeah so we\u0027re using the okay educate the D pop this is the this is how we do resource access currently and as you can see it\u0027s not a better talker because it\u0027s not so it says D pop and then you provide the header okay they would actually be happy with that because they don\u0027t want to just add information to that existing there because some resources would break even though they\u0027re not supposed to yeah thank you I will report that back to them there and the third thing which I failed an issue on several months ago is despite some of the sentiments in the working group for years we\u0027re going to continue using the implicit flow and that\u0027s not up for negotiation so they want a description of how to use deep up with the implicit flow if they\u0027re going to use it at all so that could either happen in this draft or I could create a separate draft but if we\u0027re going to use d pop but "
  },
  {
    "startTime": "01:24:33",
    "text": "Microsoft there must be an implicit binding so I think this is something we should talk about after way if they\u0027re working group decides to adopt this item to to discuss what the working group thinks about this that\u0027s fine but I\u0027d also like to talk to you and some of the authors about what technically you think that binding should look like and I want to get it written down and it\u0027s a working of decision whether to adopt that piece of it or not but I have a mandate from my employer to create it either in this draft or as a separate draft if we\u0027re ever going to use any of this yeah and I just wanted to put that on the record okay Brian off mic said he would be happy to see it in a separate draft and would work on it with me Thank You Justin Richard to that last point I would be unhappy to see it in the same draft so plus one to Brian\u0027s point so all right since my name was tossed around a bunch I figure I should get in the mic line having tried to spec out HTTP signing and implemented a number of different signature methods I think one of which we\u0027re gonna hear about later it\u0027s really hard it\u0027s really really surprisingly hard I\u0027m with Annabel that there should be a few additional fields but I mean that\u0027s it you have a structure we can add that we can specify that that\u0027s great signing headers and signing body very important in other types of requests yeah yeah totally I really like this approach I agree with pennis in principle that having a server provided key to enable symmetrical keys and stuff like that helps a lot of different use cases embedded use cases especially because of key generation costs but other use cases potentially as well and even having the server generate a an asymmetrical key pair makes sense I know but it makes them deep hug does not have that functionality I know how does can I finish my sentence none of the documents has the capability to service I generate asymmetric keeping I thought that pop distribution allowed that okay well that\u0027s a gap in pop distribution in that style so anyway ultimately if this is cryptographically agile enough I think those are details that will fall out the mode of the client presenting and proving possession of that\u0027s an important part proving possession of the key that it is saying I\u0027m going to use is a really really important pattern and "
  },
  {
    "startTime": "01:27:33",
    "text": "that actually solves the security use cases for the majority of ways that we want this thing to get used because if the server provides a key the client hasn\u0027t proved yet that it can actually use that key to do anything so I like this pattern so much that I also invented it because this is how currently key proofing in possession works inside of X Y Z so it\u0027s the same kinds of structures and yes before Hannes asked I was aware of my other draft for HTTP signing so and I purposefully didn\u0027t use it for this because that is a really complicated thing and there really has not been enough energy in the working group to move that forward possibly because we have cabbage signatures we have a bunch of other things that have been making progress that people could use instead ultimately I don\u0027t care where that draft lives if we were to take all of the proofing stuff in here and paste it into the HTTP signatures draft and call that the new version fine you know like whatever if and I think that we might be able to do that if we extend a couple of fields with some normalization rules you know that\u0027s all doable so yeah at the end of the day message signing and four key possession is something that we need something that we have needed for many years but we haven\u0027t solved yet because it is really really really hard and we getting stuck on little bits and details instead of just trying to do something howdy roomie didn\u0027t you is the responsibility taking new technical position on what we just kind of talked about here that\u0027s for the working group to talk about what I would strongly urge before we talk about we\u0027re group adoption we make sure that we better understand the equities of perhaps other working groups put them on the table I actually don\u0027t know all those equities are we sure check and make sure we surface them as we reason about what to do here and ditto I heard that again this is kind of my first real meeting with this working group you know as we talked about past decisions the fact that we don\u0027t remember what we decided and that\u0027s kind of coming with your same vacuity and that let\u0027s just kind of surface that as we figure out what you know with the scope of it and boxes of some of these drafts and so what let\u0027s again surface what the equities might be in the other words - okay thank you yeah that\u0027s good - Mary so I wouldn\u0027t I\u0027m gonna be able to adopt this document at this time so over here take it offline okay just go ahead okay yes okay my next presentation is about this it\u0027s not right no it\u0027s not yeah that works "
  },
  {
    "startTime": "01:30:39",
    "text": "okay my next presentation is about push request objects and the aim here is to find out whether there\u0027s interested in this working group to go forward with developing something in the IGF what approach to request objects you might know that there\u0027s the JA draft that moves request object management to the a s so this is an extension that would move the request object management to the a s as I already said this was developed in the open IDF RP area based on experience gathered in open banking / BST - context what is the rationale here as you might know in JA we have a mechanism that ensures the integrity authenticity confidentiality of the authorization request by essentially signing all that stuff or whatever and the problem is if you put the signed draught for example in a you know authorization request by value you would put it in a request parameter you end up with very lengthy URLs there might be a lot of scopes in them for example and the job itself is very long if your effort so there\u0027s a method to to transport it by reference called the request your eye where you put the shot somewhere on some URI and then in the authorization request you have the parameter called request your eye that refers to that your eye so the a s goes to that your eye and takes the job from there problem with that is the client if it puts it on its own server needs to handle inbound requests from the a s which is a new thing the client needs to store a potential large number of objects and also handle cleanup for them there\u0027s might be delays in the authorization if you have problems with latency or if the request URI is not available and the a s also has to make outbound HTTP requests that is you enter the whole domain of service site request forgery problems which are a lot met there are some input from you so just clarification the jaw graft actually doesn\u0027t quiet clients to store no it does not the jaw draft says put it somewhere can be on the client can be on the a s can be somewhere else and at least open how to "
  },
  {
    "startTime": "01:33:40",
    "text": "how to do that yeah that\u0027s right so this this this is kind of left open in the draft so the post request object is essentially a description on how to do that the idea is to move the staff to the air so the responsibility for managing these request objects by creating a new request object endpoint so the client calls this endpoint delivers the request objects say with a post request the client is then provided a unique your I to that request the contents there and this is then used as the request your ID parameter essentially the jar draft already foresees exactly that I think there\u0027s a sentence somehow outlining this idea but this makes it more concrete there could be two modes the reakless object could be stored as a job if you need the features like signing encryption whatever or it could be a raw request object just in JSON format to keep it more simple this would look like this this is the post request to create the resource up they request object so you would send a post request and in a post request you will have a jason with all the parameters that you otherwise would find in the authorization request you could also have this as a dot then you just post the draw it somewhere in the response you get a request your I containing enough entropy sir that it\u0027s unguessable by somebody else and then when you send your authorization request all you need to send is one single parameter request URI containing whatever you receive before you request URI that is the mechanism as I already said it has some advantages there\u0027s no reakless object management on the client itself deployments can choose from these two options to have a JSON or jot we can have client authentication at the endpoint where the request object is posted so you can refuse unauthorized clients very early in the process and also you can have patterns where the authorization process itself relies on the identity of the client because you know her essentially proving the identity of the client and also because we now have the option to transport very large authorization request requests this is also a good foundation to convey something like rich authorization requests aka structured scopes where you put a lot of information in them sorry are not limited for example by the size of the URI while still having a defined implementation pattern so the question "
  },
  {
    "startTime": "01:36:41",
    "text": "is what are your opinions shall we bring this to the ITF or rather not correct hierarchy um I I think all these are very good points this makes a lot of sense I just wanted to point out that this is almost exactly what I implemented when Justin first are talking about XYZ last year the initial thoughts behind that I I did almost exactly this just as a plain object not with a non wrapped in the job and it was super easy to add to an existing OAuth server that I had and I made a lot of sense so I just wanna throw out there thank you john bradley yubico one of the jar authors so jar has been in flight for a while perhaps too long as it closes in on completion again shortly we prop you know things have developed over time and this pattern has become clearer and clearer as being preferable we left it open jar open to this pattern but didn\u0027t include a whole bunch of new text you know have we had the timing been different this might have gone into jar but we don\u0027t necessarily want to reopen and extend those people are some people are counting on jar finishing so that for some of the payment stuff we don\u0027t necessarily want to delay that so doing this as a separate draft make sense will probably debate whether or not the raw format or an unsigned joj is preferable so there are a few details that in it that I that probably merit discussion but yeah as an elaboration of jar this is probably should happen so that we have a consistent way of not doing it and as I say we would have done it in jarhead timing potentially been different yep Annabel Backman Amazon so I want to point out that this is very similar to what the device authorization draft defines in terms of we\u0027re pushing a request up to the and endpoint on the a s we\u0027re getting a URL back and then we\u0027re opening that up or were in this case you\u0027re adding that to an author an authorization request but ultimately you\u0027re getting a URL and you\u0027re you\u0027re opening it up the only real difference is the if the other direction how the response then gets back to the client so so it seems a little bit weird to me for us to standardize two different methods to do very potentially three different "
  },
  {
    "startTime": "01:39:41",
    "text": "methods to do this same address the same challenge of how do I securely make this request to the AAS at I know device authorization is very far along in the process and I don\u0027t necessarily want to say we should derail that but maybe we should be we should look at the fact that we\u0027re treating both sides of this transaction they get to the a s and get back as if they\u0027re intrinsically linked as if the mechanisms by which that happens are intrinsically linked and maybe we should be coupled those and look at standardizing those separately gonna cut the mic after that thank you for that introduction a development Jessamyn richer so you know obviously this once again this pattern shares a lot with X Y Z because I stole all the best ideas from everybody and puts in one thing I mean a lot of the motivation was noticing that there was a lot of overlap between things like the device flow and request object registration but I actually went to try to do the exercise of collapsing those two within ooofff - you really can\u0027t do it it it there there are bits and assumptions made on both sides that it\u0027s if we were to try to like twist this into device flow or make device flow like that it would break the models for both of them right so unfortunately I think that if we do want to bring this in as an OAuth 2 extension it does need to be its own thing and that is a shame but to me that is also motivation for next generation protocol that doesn\u0027t have those same assumptions that can actually split you know how you get the user there and how you get the user back which is exactly the structure that XYZ has I mean this this is the world that this that that project came out of right and that\u0027s said I\u0027ve implemented this I do think it makes a lot of sense it does solve some key use cases it\u0027s being very very similar things are being used today in the financial space some of the proprietary some of them sort of pseudo proprietary cabal\u0027s and so having a standardized way to do this I think is a really good idea there is an open issue about the about the request format which I have some strong opinions on and maybe some sad acquiescence about where it\u0027s probably going to go after talking with Brian but you know if we bring this into the IETF that will all obviously need to be aligned I think we should bring it in I think it fits under the group\u0027s umbrella and you know just to reiterate I think this is more motivation for "
  },
  {
    "startTime": "01:42:44",
    "text": "working on a new protocol that also does this stuff but in a cleaner and better kind of way without all of the legacy baggage that this of necessity has to deal with so just a couple of clarification game this has rated the scope of this document they\u0027re sending the request URI to the authorization so what actually is covered by char so it\u0027s out of scope this document there then it\u0027s called the the scope this document I think should be just pushing the request object to the the authorization server and just getting back a response which includes there because your repeater so small concise look yeah yeah yeah you know I just wanted to make sure that people understand yeah okay good so on so how many people read the draft show for hands please okay we want to so it\u0027s their interest group to go into that yeah it\u0027s not about process specific structures so for all the whispering for kind of everyone else I mean the specific thing is we\u0027re talking about a clarify Burundian we\u0027re speaking about is this the idea we want to bring in we\u0027re not talking about a specific document might as the documents that say the okay except history yeah okay so I\u0027m gonna then call for a hum here and see get the feeling of the room okay good sorry I really dude I just want to clarify the hub is that we think we want to bring the idea into discussion exactly correct yes right as an organization thing I was confused whether the document is an ID or not no it\u0027s not in some sense we can\u0027t really Humbert as someone is going to write up an individual document to bring it to the group I think what what we\u0027ve seen on the microphone is a couple of papers saying or that sounds like a good idea so Romi genius we can get again to clarify the hum we\u0027re about to do is that someone that participates in the IETF community has an idea and would like feedback from the community in a very concrete way that he should he and his team should work a lot harder and bring something to the ITF which then we\u0027ll decide further again if there\u0027s a draft except that you actually check charter scope and the rest of it exactly yeah so that long freeze is the aam okay "
  },
  {
    "startTime": "01:45:47",
    "text": "if you are I guess you\u0027ve heard the request here so so I\u0027m gonna ask you to harm to support this or not so if you support this bringing this work to the IDF please hum now if you\u0027re against bringing this work to the IDF please hum now perfect thank you thank you I\u0027ve heard almost everyone how many or everyone humming in the direction of to bring this to the IGF which is a non-binding yeah every way but that is your feedback thank you thank you anbal so this is gonna be interesting so just looked in like half my slides are missing so that\u0027s cool so I\u0027ll kind of wing part of this that\u0027s okay so um what I want to talk to you all about is how we do HTTP requests signing in AWS using a format that we call signature version four guess why so in brief quickly up why and what is this all about there\u0027s three specific things we\u0027re looking for the three specific things that we get out of request signing in AWS first is authentication of the the client that\u0027s making the request second we do it for message integrity which means we\u0027re actually signing a significant amount of significant number of the different parts of the request as you\u0027ll see and then we have some element of replay prevention that we get out of this as well virtually all requests to AWS api\u0027s are signed using signature version 4 there\u0027s a few exceptions like anonymous request to s3 but for the most part if you\u0027re using AWS your you\u0027re signing things using this algorithm as far as what goes into these signatures like I said we\u0027re doing it for message integrity which means we\u0027re hitting a lot of different parts of the request method endpoint path time stamp query string parameters body and some of the headers and I\u0027ll show you how some of that works in a moment and then we\u0027re we\u0027re using H Mac sha-256 with a key that is derived from a shared secret to do that which is why I was asking about symmetric versus asymmetric earlier so there\u0027s three two we will walk you through what this signature version four algorithm looks like there\u0027s three basic steps we have "
  },
  {
    "startTime": "01:48:47",
    "text": "to canonicalize a request we then use that to construct a string that we\u0027re going to sign and then we sign that string and stick that in the HTTP request I\u0027m going to go through this part a little bit quickly because if you really really want to see it you can go check it out on the public documentation but just to give you an idea of what we\u0027re talking about I\u0027m gonna go through this so so to start with let\u0027s talk about how we canonicalize this thing the top there I\u0027ve got kind of an example HTTP requests to a example service at the bottom is the format of kind of what goes into this canonicalized version of the request like I said we have the request method we have a canonicalization the docs call it a canonical URI what it really is is a canonical version of the past component of the URL that you\u0027re heading and then we have a canonicalized query string and canonicalized headers and lists of the headers that you are actually signing and then we also include a hash of the request payload in that so we just kind of walk through this make it clear we start with the method then we canonicalize the path by we provide some pretty specific instructions on how you can analyze that we do reference some RFC\u0027s for that likewise for query string we reference some rfcs we also have specifics like you\u0027re gonna sort them by by parameter name then by value etc headers it\u0027s a very similar sort of thing and then I\u0027ll tell you that\u0027s a hash of a payload and you\u0027ll believe me so that that\u0027s that\u0027s canonicalization of the of the request next step is we take that and put it into you a string to actually sign and I think I actually skipped a step my example there but that\u0027s okay oh no I didn\u0027t okay so the the actual string design has a few different components first we say we specify the exact algorithm we\u0027re using in this case it\u0027s this tag AWS for H max sha-256 all sig v4 uses that but it could change we put in a timestamp for when we\u0027re making the request we put in this thing we call a credential scope which relates to how we derive the key that we\u0027re going to use to sign this when we derived that key we bind it to the day the region your communicator but yes region you\u0027re communicating with and the AWS service you\u0027re communicating with and then there\u0027s finally that the hash of the canonical request we just created so you create that and you sign it with a derived key as I said the derived key we generated using date region and service "
  },
  {
    "startTime": "01:51:49",
    "text": "it\u0027s basically a series of chained H max starting with a secret key that both you and AWS know mm-hmm you like I said do a bunch of trying to change H max you generate this key and then you sign your string to sign and you have a signature and then you stuff that generally into a header in your HTTP request and you\u0027re good to go and that\u0027s the end of what my actual slides contain whoops now let\u0027s talk about why we do some of this stuff and some of the lessons we learned I want to start with this so minutes three minutes cool all right let\u0027s go quickly then to start with some obvious stuff crypto agility it\u0027s good it\u0027s important that\u0027s one of the reasons we\u0027re on v4 and not v1 because we had to add that so that H max shot 256 bit bear and that\u0027s important another thing we ran into over the years protocol agility we started out with a protocol that was very query string oriented and so we were just kind of signing query string parameters over time that changed we needed to put stuff in the body we need to put stuff in headers etc etc we need to extend the format to enable us to sign more of the HTTP requests in as a whole because different protocols are running on top of HTTP are gonna put that different value on different parts of the request canonicalization that was a big thing we talked I mentioned that word a whole lot of times there we are if you look at our documentation it is very specific about how we canonicalize these things because you have to be even something like URL encoding you can\u0027t just say go follow this RFC because guess what the RFC changes or the recommend the list of of reserved characters change and then you have to deal with the fact that older libraries aren\u0027t doing it that way a newer libraries are you can\u0027t just say URL encode and assume that the API is gonna do it right because if you look at languages take JavaScript for example there\u0027s like three different encoding related methods you could call and they all encode things slightly differently so we have to be very specific about that sort of thing it gets alright yeah going back to the assigning different parts of the request there\u0027s a reason that we specify what headers were signing and there\u0027s a reason we specify explicit ordering for query string parameters it\u0027s because again you have to here it\u0027s not so much an issue of how are things getting canonicalized but an issue of middlemen between the person who is actually true the code that\u0027s actually trying to make the request and your server that\u0027s going to receive it the obvious middlemen are things like proxies and load balancers "
  },
  {
    "startTime": "01:54:49",
    "text": "and whatnot even if you throw those out you still got middlemen because you\u0027ve got browsers you\u0027ve got SDKs you\u0027ve got language libraries that are gonna get in your way in case you don\u0027t believe me just think about every API that lets you specify query string parameters as a map maps are unordered how are those going into the URL you don\u0027t know so you have to have a specify how you\u0027re ordering those and how you\u0027re signing those more fun with headers going back to protocol agility I talked about protocol agility for what\u0027s running on top of HTTP but what about protocol agility for HTTP itself when we went from 1.1 to 2.0 the host header changed from host 2 : Authority and so we had a bunch of services that were expecting the host header to be signed and required you to sign the host header but now there\u0027s no more host header so what are you what\u0027s the client signing because they don\u0027t necessarily know if this request is going over HTTP 11.1 or HTTP 2.0 it might change over as it\u0027s sent over the wire so they have to deal with that as well we thankfully because of the flexibility in our protocol that you specify what headers you\u0027re signing we were actually able to deal with that just with some code changes and documentation changes we didn\u0027t actually have to Rev the format so that was kind of a positive there the the last thing I\u0027ll say real quick if I\u0027ve got one cool performance I mentioned a little bit earlier with asymmetric crypto there\u0027s two to two different places where we kind of ran into some interesting performance challenges one is symmetric versus asymmetric asymmetric would be awesome does great security properties but there are honestly scenarios where it is just still too slow and likely always will be because as things improve to make asymmetric crypto faster they\u0027re also going to be improving to make other parts of the system faster and so you\u0027re still going to be looking at increases in latency at potentially double the cost of the API call so that\u0027s something we have to think about lastly is I mentioned Rick body was saying the body of the request the fact that we sign a hash of it not the full thing that\u0027s again why we run version 4 not version 1 or 2 or 3 that was something we realized hey this is not a great idea so another reason for flexibility in what parts of the request you\u0027re signing and how you\u0027re signing those and that was my world warden to earth through AWS Sigma 4 if you google AWS signature version 4 you will find our public documentation on it if you want to dive into that and see a little bit more there\u0027s also source code for all of our client SDKs pretty much on github you could look at how we actually do it "
  },
  {
    "startTime": "01:57:49",
    "text": "there I are you planning to bring this work as a specification to the idea facilitation or um that\u0027s an interesting thing to explore yeah I think our presumption is that there wouldn\u0027t be interest but yeah ok ok thank you so I\u0027m just going through this quickly so we\u0027ve talked about a nested jaw to him last last time what was missing is a use cases so the issue was there in JSON today it defines the concept of a nested jawed but it has a limitation of that the enclosing dot doesn\u0027t have its own a claims and so the goal is to extend that that that concept and allow the enclosing jar to have its own claims if there are two use cases that I\u0027m aware of one is that native app that a interact with two different authorization servers what one is that that the native as aware of that first authorization server but not that the second one in and because we don\u0027t have time and I\u0027m not going to go through that the flow itself in the second use case is a use case actually and now it\u0027s too late actually to affect this this document because it\u0027s a it\u0027s a think already with there is G and that a allows that in or needs look at that same concept of a nested jot one inside the the other and with with two different a claims in and we\u0027ve talked about em I\u0027ll talk about the example so we\u0027ve talked about defining a content type and a new claim to kind of define how would you nest those a together range rights so I want to say too much because we\u0027re gonna have time right now go ahead I just quickly wanted to say that that passport document is just submitted from the work group asking for publication rights okay okay maybe it\u0027s doable so we\u0027ll see so who read the document any show of hands one two three okay for em I don\u0027t know if it\u0027s that\u0027s not not enough people I would say have read it to make the make a call for adoption um yeah I think we will okay yeah so it\u0027s to read it okay okay good I don\u0027t have failure perfectly okay okay perfect "
  },
  {
    "startTime": "02:00:53",
    "text": "okay and I will add the second use case that the still use case it\u0027s not in the document but thank you all and yeah see you next time I guess thank you can I have a last word so administrative leave coming in again no value judgment all the work what\u0027s really with really always excites me we\u0027re not coming off as the tight link of people have code I\u0027m doing this thing like I need this addition and kind of the fast inner you know interplay is phenomenal but from the governance artifacts we have there is a lotta lot of insight into what\u0027s actually happening and what\u0027s on deck and what\u0027s the next step miles the latest miles games are July 27 TM it\u0027s tough to tell from the Charter what working group documents yeah beyond so in the coming months we\u0027re gonna polish that on bill and let\u0027s just put that out there now that\u0027s just to make sure again my primary driver here is that we know where we\u0027re going and one of my key things is there are folks that don\u0027t participate here and they don\u0027t understand that this being Adam gate doesn\u0027t mean we\u0027re not doing work so our ability to talk about future milestones is signals to the community that we have a lot of work to do to kind of keep watching the space that\u0027s a good point thanks Roman we have planned to do this already since 2017 at myself I rebuild but I would post questions and then we can we should you "
  }
]