[
  {
    "startTime": "00:02:43",
    "text": "[Music] I think we\u0027re getting ready to start yeah we\u0027re getting ready to start and I want you to know I\u0027m noting the people that aren\u0027t here that should be this is because me and AC had sort of the gentleman\u0027s back going on how many would come I said we\u0027d be lucky for 20 a C thought 40 you\u0027re getting closer you\u0027re in you\u0027re in the right place you can bring your friends and family to well Jeff\u0027s here guess we can at least go through the know well ok ok so this is the second session the else our working group we have a shorter agenda this time let\u0027s do the agenda bashing first we are just no welcome first I yeah no well first so this is the note well supposed to read it all basically means by participating in this meeting you\u0027re making an IETF contribution okay so we have a short yeah yeah yeah it was shorter I was gonna get people a chance to complain about the agenda but we have yang some yang updates followed by a couple more presentations and first up is Tony does anybody want to bash the agenda it changes no okay "
  },
  {
    "startTime": "00:06:13",
    "text": "all right thank you so this is talk about our yang model for dynamic flooding apparently yang models are now required for everything so we attempted to jump in and do one please note that both of us are yang novices so we have no idea what we\u0027re doing please be gentle we\u0027re happy to fix whatever let\u0027s see there\u0027s a link to the current draft we are spinning it as fast as we can go which is not very fast we\u0027re trying to cover both OSPF and is is with this we are modeling all of the new TVs that we\u0027ve added all the config and all the user interface that we\u0027re dealing with so some of us have to deal with open config and when we bounced things around internally we got criticized for using IETF oriented models and we\u0027re asked to provide open config models instead and so you\u0027ll see in the comments that we try to support both IETF and open config at the same time which is a trick so I\u0027m not going to go through all of this because it gets really boring very quickly but basically we tried to cover everything this covers the dynamic flooding capability subtil v2 router capabilities relatively straightforward the config stuff all of the various knobs for the configure here enabling the dynamic flooding is this object and status information so you can suck out everything that\u0027s going on this gives you the list of paths that the system has learned from the area leader so this is a list of topology so you can just see exactly what\u0027s going on the dynamic flooding and I think that\u0027s it so any questions cool thank you ACA no I just want to make a point that this is uh interesting I didn\u0027t review it very much but this is the first time we have both is is and OSPF yang model in the same draft which so it\u0027s new new grounds but I mean I\u0027m good because we have a funding the funding draft has both of them "
  },
  {
    "startTime": "00:09:34",
    "text": "hello everyone they see eunjin I\u0027m just gonna give a quick update about some young models so I\u0027m gonna cover nine trucks in two minutes first of all OSPF and ice has base modules after five years the good news is both of them are family united her cues unfortunately we have some dependencies on the PFD module so we\u0027ll have to wait until a little bit to publish them but the model is both of them are pretty much that and here are a list of active contributors and so during the last call process we actually go through several revisions and fix other issues one major change we did see you know in OSPF and as we have lost Flags field and we used to use this field to say oh one flag another flag but we figure out those things are not augment able so we change loss from type beats to an identity this is one major change during the last CalPERS s if you are interested please take a look at the models here list somehow is done as an example so it\u0027s really just use change the type so it\u0027s easier for augmentation later so the modules can be augmented and then the next two is post OSPF and ISS module four segment routing with all the drafts related with OSPF and ISS protocols are being published these two I in the pipeline to be published so the plan is we will publish the base SR model in spring first and then this two will follow and so this give you an last opportunity to reveal them and if you have any please so the changes we\u0027ve done so far know the both of these models have been stable for some time so the change we\u0027ve done so far is basically just change everything to match what we\u0027ve done in the peso SPF and the ISS model and we expect to publish this to very soon and we have two new working group document exam did you you want to talk a little bit about that meeting we had with this rv6 young model offers on the last night so that\u0027s about the OSPF and ice ice ice our model "
  },
  {
    "startTime": "00:12:36",
    "text": "because this to augmenting the segment routing pace model and this week the author so far the segment routing the segment routing and pure ice module had a meeting with the SRA six model authors and we make sure we align our configurations and our also some comment effort definitions so then we can provides the base module we make sure everything is aligned and then we next step will be progress the protocol specific module we will start request will make one more changes make the alignment and will request the base call this module last call in spring so the new working group document the OSPF these three extended RSA this one is actually very important because all the new OSPF with these three features will have a dependency on this module if they are using the new extended error I say format and the plan is to progress this one after once we\u0027re done with the base OSPF module and then we have the OSPF young augmentation version one so this one is right now we have I think four modules included we this time we added that the new OSPF is Ricky module and we also have other modules included this one so far I think the plan is to keep these four modules in this one document if there are more features that need to be augmented to OSPF later go to another augmentation document public illusion to just to keep all the modules up-to-date this is a new document is OSPF very segmented hyung is for the OSPF III but for segmenting MPI\u0027s feature and this one well augment the base OSPF segment routing data module and all included all those theories so people who are interested in implementing this feature please take a look we didn\u0027t have this in the base segment all team model because this one needs the OSPF v3 extended RSA so we\u0027ll need to progress that one first and then this one okay so with that the OSPF augmentation "
  },
  {
    "startTime": "00:15:38",
    "text": "modules were introduced that we started last ITF and this idea is already working group document and this one is a new one with we are doing for ISS we are doing these same activities for ESS so this page listed all the RFC\u0027s published in ISS thinks 2016 right now this draft only has the minim remaining lifetime included being this module and chris has a another one he will present later was the reverse my shape Chris will present later that\u0027s in a separate document and will keep next time we next revision will I\u0027d be probably consider adding the multi instance of hot and if you see any ISS feature that\u0027s now covered yet please let us know and if you need it we\u0027ll add it so for this module that we have so far in the document is just the minimum remaining left hand i scoured RFC 7 9 87 it\u0027s very simple one please take a look and send us their comments if there is signing sorry only has like a notification to say there\u0027s something you need to repot okay so the next one the very last one is the data model for SSI sorry six so the SRA 6ss document is already a working wolf document and this one defines the young module for that document it defines the configuration how to do the locator sighting and how to you also include the faster rerouting features exact Shore please review it and send us your comments and the next step for this one we\u0027d like to request the working group adoption for this draft and that\u0027s it hi Randy I have a question for the chairs actually do we have a yang module augmentation plan or it\u0027s coming together like yeah we so I had like done like the reverse metric one before we sort of agreed to try to do this in in bunches which is where these augmentation version 1 things came "
  },
  {
    "startTime": "00:18:38",
    "text": "from yeah so the it\u0027s you know that that\u0027s what we\u0027re looking at now but you know you you also see that there\u0027s other modules there you know that aren\u0027t included in that so I think we\u0027re sort of just worth learning right it\u0027s a work in progress and trying to figure out what the best ways to do this are I you know personally I wasn\u0027t a fan I don\u0027t know if this is with my chair hat on or I\u0027m I remember remember happeh I wasn\u0027t a big fan of the Augmented but you know but other people seem to like that idea so I you know I was willing to go with the flow on that yeah you\u0027re grabbing them go ahead hi-yah asa enemy alert or not I don\u0027t know we\u0027re not in complete agreement I\u0027m in hoping to get it all done and I did not want to say because didn\u0027t work for SNMP it\u0027s a and I don\u0027t see why it would work that much better well yang is a lot easier to augment but I meant was to make anybody who did a draft also do the yang augmentations right in that draft that\u0027s the idealistic approach we haven\u0027t taken that to put such a barrier on graphs we can discuss that for future functions but because we have people doing we have people that are contributed that aren\u0027t don\u0027t know yang and now we have we have we have so separate so we are so so for better or worse right now we\u0027re doing separate drafts unless we change that with augmentation okay so what I\u0027m getting from you guys is that we have those documentation drafts which may group several features but in reality as a working group we are gonna do whatever so that\u0027s what I was gonna say is it this is our first shot at this right we\u0027re trying it out I mean I don\u0027t think there\u0027s any danger in doing it sort of both ways and figuring out which which works better I mean my general thinking is that certainly for complex features you know it makes more sense to have a standalone draft right because you know I think I what I thought about the augmentation the Augmented model was that just picking up all these little bits here and there that got left out of the base model right I still I still think it makes sense to have a separate draft like if you have a major feature you know either as AC said it might be hard to put it in the same draft but if you\u0027re not going to put in the same graph to have a standalone pairing with it right like a sister drafters Chris Bowers with juniper perhaps a reasonable compromise would be something like you know they can be in separate drafts the yangko new "
  },
  {
    "startTime": "00:21:39",
    "text": "feature and yang model for new feature separate drafts you know different expertise but you know maybe a requirement of working group last call is that at least the yang model is at a level that it\u0027s adopted as a working group document some kind of staged approach that could make everyone happy I remember that sounds reasonable to me you know I mean because you\u0027re not you\u0027re not blocking it going forward you\u0027re saying at least you\u0027ve made some progress on this other one - yeah yeah yeah well we\u0027d like to solicit other opinions on the West speaking as a working group member I think that that\u0027s reasonable to expect that for my personal opinion I think if it\u0027s a large feature we don\u0027t want the Yamada to delay the publication of that trapped at all an RFC so if it\u0027s a small feature you make more sense if it\u0027s possible to include among yamato in the same draft if you don\u0027t know how to do it you can ask any of us for help we\u0027ll be happy to provide the Yamada so speaking is a working group member last time this came around I I thought that we could have a you know sort of a localized Jang doctor you know or yang experts in the LSR group I know the problem is we get so these author lists gets so big but you know these things aren\u0027t hard to write for people that have written them and you know if you\u0027re if you\u0027re working on if there was a group of people you could go to and say you know we\u0027re authoring this draft would you like to join as an author - to put the yang stuff in there I mean it shouldn\u0027t be hard to do that but you know this is just brainstorming on my part unlike how we might do that right so the reason I was asking is because maybe I had missed the discussion and there was over here some plan but I think that it\u0027s important that we discuss and if we get to a conclusion of requiring or not or whatever it is that way you know and if there\u0027s no specific planned it\u0027s good to know that there\u0027s no specific plan - right there\u0027s not a requirement that we have a plan but if we need to discuss something it would be important for it to be discussing on the list yes thank you yeah I just have one more thing I think or with our yang models of this especially yang models of this significance this size as the LSR I think we\u0027re ahead of most of the other working groups so what we do might you know be a harbinger for other working groups in the routing area thank you "
  },
  {
    "startTime": "00:24:45",
    "text": "take your next no I\u0027ve got keep it in the tap yeah okay well why don\u0027t we see if we bring less yeah let me see if I can bring the next one this is is it just me that has this particularly bad luck with this thing okay les thank you for Oh okay I\u0027m West Ginsburg at the last ITF we had a couple of presentations talking about issues associated with increasing the rate of flooding and since there were some two different points of view that were presented since that time myself and my co-authors have issued this draft is also another draft that was authored by Bruno and several others "
  },
  {
    "startTime": "00:27:49",
    "text": "okay so going back to the base specification this is what ten five eighty nine says about flooding and the key takeaway here is that flooding was intended to be an interface independent parameter there are some special considerations that were done for broadcast and it\u0027s kind of the one that everybody remembers where ten five eighty nine said roughly 33 milliseconds between sending LSPs on a broadcast interface but 10 589 did not actually specify this for point-to-point interfaces but in most implementations today have applied this to all interfaces why is obviously 33 milliseconds roughly 33 LSPs per second on a particular interface it\u0027s relatively slow or significantly slow by today\u0027s standards and if you have a large network and you\u0027re now talking about for example if you have a node that has hundreds or a thousand neighbors and that node goes down that means you\u0027ve got a thousand Ellis bees that have to be flooded network-wide well you do the math and if your rate limited to 33 per second on on the interface it\u0027s going to take 30 seconds or more which is a significant amount of time so that\u0027s why we\u0027re all looking at what can we do to what happens if we increase this rate significantly what issues do we have to deal with convergence consists of a number of steps one the nodes that are adjacent to the topology change have to detect the topology change they then update and flood their LSPs as the LSPs are received on other notes the network they run a new SPF and then you update the forwarding claim steps 2 3 \u0026 4 need to be done network wide so what we\u0027re the aim of flooding is really to get a consistent link state database network wide as fast as possible and this quote here from 10 to 5 89 indicates how 10 589 originally thought about this and it was well at each interval you look at all of the LSPs that are still need to be sent and you keep track of this on a per interface basis and you send them "
  },
  {
    "startTime": "00:30:51",
    "text": "all ok the the pacing interval that was associated with broadcast interfaces was never actually specified to be applied to point-to-point interfaces but most implementations have done so clearly if we\u0027re going to to achieve convergence one of the limiting factors is how quickly can we get the same length state database on every node in the network [Music] so again the goal of flooding in the abstract is let\u0027s do it as fast as possible why do we do pacing well we have to deal with some real issues there are other things being sent on interface there are other things that the router is doing so we have to allow for the fact that there are other types of packets that need to be sent on the interface and it\u0027s conceivable that you know obviously pricing analysis an update to an LSB just the you know receiving it getting it up to the control plane having the protocol operate on it takes time and it\u0027s if you send them too fast it\u0027s possible that you\u0027re going to overwhelm your neighbor so let\u0027s talk about the consequences or the tools that we have to deal with faster flooding this is just a little example of bandwidth is not a major consideration here these are just numbers about what happens if how much bandwidth do we consume if we go up to a hundred per second or a thousand per second flow control so if I start sending LSPs to my neighbor at a much faster rate it\u0027s possible due to whatever else my neighbor may be doing at that time that there may be periods where he gets overwhelmed so if this happens occasionally this is not a major issue if this happens consistently we\u0027ve got a significant problem what does it mean it means maybe you\u0027ve got a no to the network that is underpowered and simply can\u0027t deal with the network at the size that this particular network is or perhaps it\u0027s configuration is such that it\u0027s doing more work than it should be doing or it should needs to be in another position the network where it doesn\u0027t have so many routes there various things that you could do but this is not a state that is conducive to optimal operation of the network as far as flow control is concerned of the position that we\u0027re presenting here we already track the put the base protocol update "
  },
  {
    "startTime": "00:33:52",
    "text": "process already tracks for each LSB that\u0027s been updated like we keep track of the set of interfaces that we need to flood it on have we received an acknowledgment for that so the update process is completely reliable if you want to do flow control it\u0027s easy enough to do flow control from the standpoint of the transmitter because you can keep track of how many LS B\u0027s you have sent out on this particular interface that are still pending acknowledgment so this is an algorithm that we\u0027ve proposed for handling flow control I\u0027m not going to go through the details but it\u0027s basically if I have too many of outstanding LSPs that haven\u0027t been acknowledged I start to slow down and so I don\u0027t overwhelm the neighbor so that\u0027s one flow control is one tool to do to deal with faster flooding there\u0027s also packet prioritization most implementations today or at least a number of them have already prioritized receiving hellos over receiving snps and Ellis B\u0027s why do we do that we do that because we don\u0027t want to if we if we get a burst of LSPs and that causes us to drop our adjacencies that means we\u0027re going to have to generate it even more LSPs so it just exacerbates the problem what we need to do here is to prioritize the reception of snps over LS B\u0027s because snps provide the acknowledgment for LS B\u0027s and if we drop snps then potentially we\u0027re doing needless retransmissions of LSPs we\u0027ve already sent it to the neighbor he\u0027s already received that he\u0027s already acknowledged it but we lost track of the fact that he acknowledged it so this is another tool that we can use to help make using faster flooding operate more smoothly minimizing LSB generation so ice is as a TLV space protocol we have in the base specification up to 255 LS B\u0027s / or 256 LS B\u0027s per level that can be generated by a given node if I have and I\u0027ll use the example here you know get a bunch of neighbors and I\u0027ve got them distributed into three different LS B\u0027s as I\u0027ve shown here only if one of the neighbors goes down I\u0027ve got two strategies that I can use to update the LS B\u0027s just to distribute this information to the rest "
  },
  {
    "startTime": "00:36:52",
    "text": "of the network with method number 1 so in this case a neighbor number 3 went down neighbor number 3 was in LSP 0 I simply remove neighbor number 3 from LSP 0 and I flood LSB 0 method number 2 I decide well gee now neighbor number 3 is gone I can fit all of my neighbors into 2 LS B\u0027s whereas before I needed 3 LS B\u0027s so I\u0027m gonna shift everything and compact it but when I do that I pay a heavy price because now I\u0027ve got to flood 3 LS B\u0027s I\u0027ve got to flood the update to LSB 0 the update to LSB 1 and I\u0027ve got to purge LSB - that\u0027s no longer has any content in this except at scale this exacerbates the flooding problem by an order of magnitude and I think we\u0027ve for those of us who have done implementations and dealt with scale we\u0027ve learned this lesson the hard way in some cases so one of the lessons here is don\u0027t try to compact your LSPs unnecessarily try to minimize the number of LSPs that you need to update when a topology change occurs redundant in flooding there\u0027s a number of mechanisms available to reduce redundant flooding when you have a highly mesh network one of them requires no protocol extensions whatsoever you just make a local decision and say I\u0027ve got parallel links to the same neighbor I don\u0027t need to flood this LSP update on all the links I just want to make sure that each of my neighbors has received the update on at least one interface we have mesh groups which is been around for quite a few years it\u0027s a bit laborious to deploy but it is a tool that is available and now we have the dynamic flooding draft that\u0027s a working group document that allows us to calculate an optimal flooding topology [Music] jumbo frames the unit of flooding for ISS is an LSP traditionally LSPs are limited to 1492 bytes because the the maximum LSP size that you can send has to be less than the MTU of any interface in the network that is used for is is why is this true because Isis does not support fragmentation if you can if you have a network that supports jumbo frames you can increase the LSP MTU size to 4k for example this reduces the number of LSPs that each node generates "
  },
  {
    "startTime": "00:39:53",
    "text": "and reduces therefore reduces the number of LSPs that need to be sent when a topology change occurs reduces the total size of the LSP database so this is a summary of things that we can do to allow us to support a much faster flooding rate and we\u0027re one I think we should be encouraging vendors to support faster flooding this is clearly needed for networks at scale we need to emphasize that the flooding rate is not a per interface parameter the goal of flooding is to get things flooded as fast as we can metric wide and not try to tune this you know to a particular neighbor used transmit base flow control to make sure that we don\u0027t overwhelm the neighbors prioritize SNP reception minimize LSB generation reduce redundant flooding when use jumbo frames when you again the the other comment I\u0027d make before opening it up to questions or comments we wrote this draft it\u0027s intended to be an informational draft as I said there\u0027s a competing draft in the same space we\u0027ll have to see where the discussion goes as far as the differences in the two drafts I\u0027m not totally convinced that at the end of the day we need a draft regardless of what the consensus of the working group is this could be something that we just it\u0027s good to have the discussion publicly whether we actually need to publish as a standard be it informational or standards track I think is also something that the working group should consider that\u0027s it muna decline orange so since since you explicitly acknowledge said so discussion is related to draft or the crime fruiting Espina so let\u0027s recap that the good of the drop is about floating point full point so I think the problem is big enough and complex enough on we don\u0027t need to to look at independent or to another point such as with reducing rhythm fooding yes I agree it\u0027s good we have a working document working on that for example I think it\u0027s off to granola I think it doesn\u0027t bring to put it in the discussion minimize the number of regeneration yes please let\u0027s do that again it\u0027s Auto canola I think we should focus on including which is already a big boy got a point on which had a lot of discussion on thank you for Jeff also big shot in in Vancouver it was really a pool were sworn many many "
  },
  {
    "startTime": "00:42:54",
    "text": "Clements on the list so I think we should focus on floating so what is flooding I have a set of information that I need to send to you that\u0027s all I think who we are in agreement that we want to do flooding as fast as possible ice are we yes okay thank you I think we are coming to an agreement that we are fine to you flow control your neighbor that means your interface okay so that\u0027s good and so it\u0027s already a good improvement if you can come to slide four I don\u0027t want to spend too much time on what we disagree okay so that that\u0027s when it\u0027s really wrong to my comment I think we should focus on on on what we\u0027re trying to do which is flooding I don\u0027t think breaking convergence in the description is AB food I\u0027m quite the contrary I think it\u0027s awful it\u0027s it\u0027s a it\u0027s a largely different subject and if we talk about convergence who are going to talk about packet loss we are going to try to order the cro-magnons in the network but convergence is about updating the Vibha it\u0027s completely it\u0027s largely very largely different about flooding and it\u0027s important because for conventions as I was proposer a long time ago but all the hot fever I knew we can see that we would like for authorship for corner drones to have an order within the network and that could be beneficial to delay the order depending on the type of topological Channel okay you know but that\u0027s not what we want for flooding and for flooding we don\u0027t want two delays of the flooding we want don\u0027t want to order the flooding we want to fruit the information on there with information we can try to do something intelligent for conversions but I\u0027d rather not discuss that subject at the same time and don\u0027t think it\u0027s helpful so with that so I think we\u0027re we\u0027re in total agreement here okay I think what we really want to discuss here is how can we flood as fast as possible okay there are other tools in the toolkit to deal with convergence issues so we\u0027re in agreement so the points we are not fully on agreement but we are going to work on it is is a doing throw controller so our neighbor or per interface an array I think that doing some explicit for flow control with your neighbor is safer on better on that we have a disagreement but I\u0027ll leave that point to Tony I have to say ditto and "
  },
  {
    "startTime": "00:45:56",
    "text": "echo everything so the only thing that I\u0027d like to talk about is the precise algorithm and I hope we agree that what we are trying to do when we say as flood as fast as possible we are trying to maximize good put do we agree with that so so it\u0027s a qualified yes I\u0027m not sure where you\u0027re going next that\u0027s do we agree that flooding as fast as possible does not mean dumping the entire LSD be as back-to-back package yes we agree good so we\u0027re trying to flood maximize good put in getting a actual transfer between two notes and now this boils down to a control theory question right how can we maximize that good book now because we are in a situation where we don\u0027t know the exact character disk characteristics and their dynamic characteristics of the receiver we have to make some estimates and the question then becomes how do we estimate what the receiver is doing your algorithm depends to depend on the lack of acknowledgments and uses no other information the alternate proposal is to provide more information from the receiver that can give us more data about what the correct amount of throughput is so if we I mean if we want to start talking about you know the details because it\u0027s obviously is one of the points of difference between the the two drafts and probably the most significant point of difference um we can do that I don\u0027t know if you do you want to have that discussion now I\u0027m very happy to have that discussion now or we can do it on the mailing list I don\u0027t care okay that the points I would make in regards to the receiver base flow control that\u0027s that\u0027s in the draft you\u0027ve co-author are two things one I think it\u0027s what you\u0027ve proposed is that the receiver be able to signal his neighbor you know here\u0027s you know here\u0027s what I could handle or you know please slow down or some kind of message to that effect which requires signaling from the data plane to the control plane about the the queue size if you will of on a per interface basis of a particular set of protocol packets I find that very challenging for any platform to implement so from a practical standpoint I\u0027m very concerned "
  },
  {
    "startTime": "00:48:56",
    "text": "that even if we could agree that this is you know they have the best solution I don\u0027t know how practical it is to implement the second point I would make is the time when you need the signalling is when you\u0027re actually overloaded and that\u0027s the time it in it requires you know sending another hello back to your neighbor to say hey slow down and that\u0027s the very time when you\u0027re more likely to be dropping packets so I\u0027m also concerned about that so your first question so I had a little chat with a number of our hardware people and as you know we\u0027re mostly based on merchants silicon it turns out that actually looking at the queue lengths coming up to the CPU is actually quite trivial it is a register read yes but you\u0027re talking about for a particular protocol there are many packets that are punted from data plane to forwarding or to control planning is that not just is eyes packets and we\u0027re not talking here about hellos we\u0027re talking specifically about LS B\u0027s so I mean there\u0027s there\u0027s a lot of detail here in terms of the information that has to go from the forwarding plot or the data plane to the control plane exactly part of the problem so some implementations have been able to segregate packets to a very very fine grain detail okay so some implementations have been able to separate LSPs from IIHS for example some implementations do not okay we need to kind of support both fortunately the good news is that an implementation knows whether it has got that level of segmentation or not and can report on the relevant queue regardless of how much that segmentation is happening okay but you\u0027re proposing an ask question with my chair hat on is there you don\u0027t like you don\u0027t like their proposal but could can\u0027t your proposal and their proposal actually live together I\u0027m thinking I\u0027m basically going off what Tony just said you know if it\u0027s very easy given your hardware to determine packet types in your queue right and to be able to get the information needed then that\u0027s easy to implement if not then couldn\u0027t they fall back to to your proposal I\u0027m just wondering obviously if you don\u0027t need if you can\u0027t provide the information you can\u0027t so yes falling back to that proposal is a fine thing right it\u0027s better than where we are today okay but I mean they live - they would live together you\u0027re not gonna get into some isolation and we would need that for backward compatibility anyway well so Chris if I "
  },
  {
    "startTime": "00:51:57",
    "text": "understand you correctly what you\u0027re suggesting is that we define a transmitted based flow control which everybody can implement and for those implementations that can support the detection of the you know received queue length and send that they can use the extensions that are defined in the other draft which are then become optional and then you have to define what happens when you\u0027re using if you\u0027re going to use the transcript base flow control by default and if you happen to get the receiver based how do you decide how they interact I suppose that\u0027s possible it seems like a reasonable compromise - your second point we never want to get into a situation where the receiver is congested regardless of what\u0027s going on we never one get to the point where our receive queue has zero free entries that means we\u0027re going to start dropping packets and that\u0027s guaranteed to hurt good book so what we know is that we want the transmitter to keep that queue somewhat full right we always want to have work available for the CPU because we can\u0027t be guaranteed of getting about the rate exactly right but we never want that queue to fill up because then we are over running congesting and wasting work do you agree with that I\u0027m after what\u0027s practical here okay I think we both have the same goal I\u0027m not totally convinced that the receiver side flow control is practical well let me ask you this if I could tell you that I could receive one LSP per millisecond could you do that for me well so you know part of you know part of what we\u0027re talking about here is the goal is to flood the set of LSB changes Network wide quote-unquote as fast as possible okay I would submit in most cases there\u0027s no need to flow control won\u0027t actually kick in there are obviously some cases where you know we get a large number of else visited in it it may kick in but I think in general we probably don\u0027t have to pace LSPs for 95% of the topology changes so if I\u0027ve got three LSPs to send are you telling me I need to pace them at the interval that you know we\u0027ve we\u0027ve somehow decided whether it\u0027s sense from the receiver or imposed at the transmitter or are you suggesting only when I get to 500 or whatever the magic number is so I "
  },
  {
    "startTime": "00:54:58",
    "text": "certainly agreed that there this is most important when there is a significant LSD be change so Am I is there something I haven\u0027t responded to yet you\u0027re looking like some I say if the receiver could specify a rate what\u0027s the problem with complying with that so I think that this goes back to my concern that I think it\u0027s very difficult for the receiver to specify a rate I mean it\u0027s even you don\u0027t need as I\u0027ve expressed I think it\u0027s difficult for a receiver even at to detect the peak conditions that communicate them to the control plane when it\u0027s needed to do so trying to pre calculate you know Here I am everything\u0027s quiet I\u0027m looking at my configuration I\u0027m looking at the size of my LSB DB I\u0027m looking at all of the other protocols that are running all of the other features are running somehow I\u0027m supposed to figure out how many is is LSPs I can support on a particular interface I think that\u0027s a pretty complex problem I think that\u0027s actually relatively easy to solve empirically given a given platform with a given Q depth and given CPU it seems like a simple task would show quickly how many LSPs you could absorb if you if I size was the only thing running on the box that used that Q then I think we could agree but there\u0027s there\u0027s countless things that that use that same Q well it should not be countless I\u0027m exaggerating perfectly okay hopefully there is some separation in this day and age otherwise you\u0027re subject to dos attacks but given that there is some clear queue depth depth then there\u0027s certainly a rate that you should not be exceeded and that\u0027s useful information to the transmitter well all right I guess the the point that we\u0027re not in consensus on is I think the problem is more complex and in order to make sure that you don\u0027t get over over overflow you\u0027re going to be overly conservative and you advertise to your neighbor that\u0027s that\u0027s my concern it\u0027s Peter from Cisco I just want to make the comment on the distributed system there\u0027s no single queue to monitor you have queue on a line card to your queue between our line card and our P you have Q and R P we\u0027re going to look at all these queues and as you said lies I mean these queues are not just for us they are shared with other traffic I don\u0027t see a simple way how we can figure "
  },
  {
    "startTime": "00:57:59",
    "text": "out the rate that we can retain it\u0027s a silliness beginners working to remember I just as just a point of reference we looked at this we had lots of problems with quiff earlier earlier OSPF implementations and in the mid early 2000s guy from AT\u0026T T Research published to draft RSC for - - - - and we did not because of these complexities we made all we made a number of recommendations but they didn\u0027t involve explicit / / neighbor or / interface flow control and since implementations have done that the problems have pretty much gone away in OSPF just I can\u0027t help but think about Hanks proposal was it last IETF or the one before just doing it over TCP I mean I think you\u0027re introducing a whole other set of issues that need to be discussed so yeah I just I\u0027m gonna you know I\u0027m thinking about saying we don\u0027t know what rate to send and then we\u0027ve got convergence yeah we don\u0027t know that right I like the way that AC as a individual contributor got up and spoke at the mic as opposed to was that an individual contributor comment or yeah I think he did that because he\u0027s on the draft right okay but even even otherwise I think that\u0027s actually a pretty good practice so do I need to walk all the way down there you know that Mike is actually a good mic as well as a substitute on camera as a presenter yeah yeah anyway so I think that would actually help a lot so Chris Bowers I just had a comment about you know when when I originally worked on the draft with Bruno the the idea was that that I had in mind wasn\u0027t the dynamic adjustment of this received value and I even I believe there\u0027s still text in the draft that it talks about that so a fallback you know even if you\u0027re you don\u0027t believe you\u0027re able to you know for whatever reason compute dynamically what your maximum receive rate should be it you know by advertising no value by saying we just can\u0027t advertise any value we\u0027re really putting it back on the service providers to individually test every single hardware platform and software release and say and vendor and set the value themselves and I think we can possibly do a little better than that you know we\u0027re they are using extremely conservative values now you know a value that says look I\u0027m on a really you know "
  },
  {
    "startTime": "01:01:01",
    "text": "a method that says I\u0027m gonna release you know limited platform I\u0027m going to you know use this current value like 33 milliseconds or something I\u0027m on a stronger platform in general and I you know I figure out I have you know only 10 interfaces then I\u0027m gonna go well it\u0027s probably okay for me to go down to five milliseconds something something along those lines and that value doesn\u0027t change over time it\u0027s like a you know configure eight you know changes maybe as you change configuration and number of interfaces that seems like a a reasonable you know advertised value it could be you know it doesn\u0027t need to be in a TLV per se but it makes deployment of this so much easier for service providers that\u0027s that\u0027s my so just a quick question if I can put you on the spot instead of me so what do you do when for example they they enable another protocol or they extend the operation of another protocol which is also going to consume some of the same resources the estimate the estimate that you would probably want to be using for this the value this static value you know should should assume okay you\u0027ve got sort of a maximum amount of BGP going on or whatever but but again that you know that we do that testing and be willing to you know publish that value in a TLV at least in some you know some some scenario is better than the current situation where they\u0027re choosing the worst conservative values yeah ii might I mean I want to reinforce what you\u0027re saying because in my experience nobody Tunes these values the vendor you know has them and they\u0027re all kind of the same order of magnitude that\u0027s right okay nobody\u0027s oh so if we want people to be able to lower them then we we have to be willing to to say okay at the very least this value is reasonably safe now you know your your flow control mechanism of you know not acting the SNMP s could then kick in for example but but at least being willing to advertise some information now so that we can at least get below the values that have been in the network for 10 years or 20 years is you know statically you know in a relatively static manner would be quite useful so I think we all we obviously all have the same goal we all think flooding is much lower than it needs to be and and we want to be more "
  },
  {
    "startTime": "01:04:02",
    "text": "aggressive I think well all we\u0027re trying to debate what\u0027s the safest way to do that I think oh good I was gonna say we\u0027d probably have to move on to the next presentation but it looks like perfect yeah we had we had some more time on the agenda today some slack time so we let that discussion go I we won\u0027t be able to do that for every presentation here each as the prism for the prefix unreached more adjustment it\u0027s narrow nice mm Senora and the solution for accents really started as a sort of the first technologies for inter area you know normally for inhaler the item video of them make the summary or test at a quadrotor are the believe me if you reporter wrote American summer Otis and the one node in my area help you in failure the know the other the other area beyond you will be notified immediately at Evo dependent the other mechanism to detect the failure of the node so this is phenomenal icing et exist in the ipv4 sick Network but I do be extra extra paid for the unit future for the IP ipv6 or s every sixth Department another scenario it also for the inner area is in for the link failure in our improvers failure in prisoner it is not a failure in certain the sonorities link leader so easier to link Allah to connect one note p.m. disconnected the amount of the ABR daughter for example you know I are true can\u0027t reach reach to reached out to the node Tito but it because it is still under ties the summary or trace you all "
  },
  {
    "startTime": "01:07:02",
    "text": "know that we all still seek reach the unreachable enrichment node so the traffic could put people in DC grandpa will be dropped by The Artful the the traffic should be rerouted to the other eight yards but you know in current current situation there is no solution to or the city or ISA the service analogies for the inter area you know in this area the the packbow area for grammar error 0 also to some snap neurologists this summer discovered the authors of the notes prefix so if the node failure can failure humidity in the same area the the iron node receives the samurai test it cover the field and notice the prefect so if you\u0027re still seeing cuz the field is Odom you will be reached so the summer some other Bank has a bank a program or the harvesting parable we all cannot cannot bypass the field note this is a traditional for the perfect and reach unreachable so based on this novel he\u0027ll propose some solution the the first thing is for the interior Irish both notion this curvy now for OSPF and the wise we help define the horrific or later theology so we went to Ulysses tell we all use this information to notify the other Luther in the other area that one perfect is unreachable for example you this is a rich graph even not t-too filled it will will be detected by the ABR rotor are poor and are harmful another right I wrote her r2 and r4 you\u0027re not we announced not only the summer days but all but also the peripheral unreachable not going to be abbreviated to QA LSA on this ratio this LSA will be flooded to other area so when the deceiver your honor earlier this year this hello si you to feel generative our black hole wrote that it is conservatively cannot reach the third node there are some condition to to discover the condition for generated in a pap POA under the under "
  },
  {
    "startTime": "01:10:02",
    "text": "the axle on the POA another solution is for the intro very here introduced to you for integer there are also some cities and some rodent your tower still the node of your link prefix so in such situation we went to the if you don\u0027t know the median the aerial receive this information his Bo and find the field know that is funny really in the scope of the summer days it also will generate automatically with the black hole Road to the fuel note of your links this such black hole will clip in Georgia service it\u0027s based on it converted so we have some discussion with Peter on the lens yesterday and and and some content for the over consideration you know control sonography just uses the most simple situation folder for the POA generate and consume you pal syrup there may be some at least complex the situation is a longer line network so currently we just and some more conservative folder for the QA the reason the first thing is the API returns for the hello value to the configure the max of the summary this is least value just the key would describe it amongst a number of the detail that we treat each ball are unreachable address of each for each one each summer root so when the unreachable perfectly is less in a mess then the API wrote reveal another unauthorized the Sam Rogers the PA unreachable address is less in mass then the AVR really instead under has the detailed reachable orders only so there are some cities and the unreachable others are and the reach modulus will post two more in the math so in such it here we make a single solution just advertise the summer days with the magnetic so decreases the value of the recent some roaches and the from receiver side the serial cable a black hole root for for predefined the time interval I am after the service based and these field note of your prefix is converted the this black hole wrote Tempe the record so for X of a which we also welcome the comment from the expert and we also will come further more "
  },
  {
    "startTime": "01:13:02",
    "text": "complex in order to be not covered and we also welcome the caller from other in there to put for this I think is such city is also exist in the in the DC Network okay a sender Cisco Systems so the the the do this effectively I mean in independent you have to know what you expect in that range because because otherwise you don\u0027t know what you\u0027re missing because because of the timing you know the sequences so are you are you gonna map that any place where you summarize that the ABR\u0027s are you know are you in a map what you\u0027re expecting so you know what pieces are missing like say you first cut when you first come up if you first come if the ABR first comes up and he\u0027s already missing around in that range he doesn\u0027t know that it\u0027s missing normally we just because there\u0027s a normal city reason not to know consider come up right there you know normally ABR account find that that\u0027s a terrific leave is him I wanted to see with LSA update you know he can it can come here which link of each node in Museum this is enormous it even maybe if it if it can come up maybe there are other artists it cuz iterate the later Isis Peter from Cisco so as you said I mean we you had a chat about this there are multiple issues here first of all you announce something is unreachable how long is it going to be there it\u0027s going to be unreachable forever if it never comes back so you have to time out the information at certain point if the address that you make unreachable it\u0027s not coming up as well you know if behavior loses a connectivity to many of the prefixes now you basically lost the summarization effect because you are going to advertise all of them is unreachable so there are multiple issues with this I I see the problem you are trying to solve the question is whether this is the right solution I\u0027m not convinced at this point Watkins Burke so I share all the concerns that Peter expressed and I know we we did talk about this privately the other points I would make is to from a procedural standpoint you\u0027re actually violating some existing protocol specifications it\u0027s currently not legal to send the router idea of zero and this is completely non backwards compatible there\u0027s no implementation today that would interpret a prefix reachability advertisement is as indicating negative reach ability so it would require a forklift upgrade I think the problem space is interesting and I think it\u0027s "
  },
  {
    "startTime": "01:16:02",
    "text": "it\u0027s good for the working group to discuss the problem space I\u0027m not sure this is the best solution you know for I think further solutions will be deployed in culture race so the mix was no the year the network is so supported such feature you know they saw them seeing scenes are seeing either this or for the for the generator on the floor that is here okay thanks our judgment obviously we need more discussion on this one on the list yeah you can initiate it okay thanks just just before you get started I\u0027ve only been fleetingly following the enhanced VPN solution but it\u0027s not yet adopted is it in other working groups Indies or in case is a firmer case adopted and in spring we presented yesterday and we caught some feedbacks maybe you make some change and ask for the adoption ok ok ok this is a update of the IGP extensions Philippian plus so some background first to the VPN pass framework is describing the t\u0027s draft which provided a layered architecture and there\u0027s a candidate technologies in each layer and the purpose is to cover the use cases of nano slicing and other genera scenarios and is the semi routing based the solution is defined in the draft in spring and which this draft basically is tennyson routing to identify the network topology and the nano resources allocated to a virtual network so this is the data opening mechanism for the which can be applicable for the transport network slice for this document its main it defines the IGP mechanism and extensions for the SR based of a pin class the purpose is to for the distribution of the required attributes to post the nettle nodes and the controller and in this version we also take the control plane scalability into consideration and for the controlling analysis we have another draft in T\u0027s we can take a look at that one ok here is the methodology first the functionality required for IGP is to advertise and track to the in from attributes of different to virtual networks and they also need to compute the routing forwarding tables for each portion network so we think for the IGP "
  },
  {
    "startTime": "01:19:03",
    "text": "the flexibility and scalability is important and we need to consider it the beginning of the design so as we can support the for the 5g network slicing deployment in different scenarios and the phases like we can have a consistent solution for tens hundreds of thousands of nano slices so basically basically the design is we provide proposed multi dimension networks last definition so that we think the nano slice is defined as a combination of a several key attributes like the topology attributes and the resource attributes we may also have other attributes in the future it can be added as needed and the second point is we can decouple the advertisement and the processing of different attributes in the control plane so that we can improve the scalability and reduce overhead okay here\u0027s an example when we can see this topology on the top based on this topology this is a neural network we can define T for the topologies using the existing technology like a multi topology of LaSalle go in this example we have two different two sub topologies define depends on this under a topology and the second step is we can use another identifier called the resource ID so I define the different groups of resources allocated to different like a service or network slice so that we can have several Metro slices have the same topology by the way it\u0027s different the group of the resources based on these two steps we can build it a combination of a topology and the resource could generate the customized virtual networks okay here are the extensions to IGP the first is we need to advertise the definition of that I would call the transfer narrow slice in this version basically it is can contains 132 page global identifier for the transfer narrow slice and it can also carry optional sub t RVs currently we have two optional sub t io is defined which is the topology and the resource here okay here are the encoding of the sub theories for the topology information advertisement we think we can reuse the audience apology and a flash I\u0027ll go to identify the topology which is power belongs to a narrow slice like we have the MT ID and algorithm filled in this sub tre we also use the flats to control which field is used as topology identified and the second sub theory is the natural resource sub goe in this one we use a new 32-bit global significant identifier to identify the "
  },
  {
    "startTime": "01:22:03",
    "text": "group of resources allocated to a in the network okay the following slides we showed how to advertise the topology attributes and the resource attributes independently the first is that we can reuse a multi topology for the topology advertisement because we have the MPR and it can be used together with a segment routing to define the network topology and advertise the topology specific C\u0027s locators attributes and second option so we can also consider reduce flux algo based to root for to define the topology constraints for a virtual network this is also applicable to similarly named eurozone as a v6 and you can define that algorithm specific assays and locators so we think for this topology ID attribute advertisement we can use either option okay for the resource attribute advertisement here we also reuse the existing technology with necessary extensions here we can see we use that hello to bondo mechanism is extensions to advertise the resources associated with a particular Network slice and we can see in this case we consider a subset of the net link resource as a physical virtual member link of a layer 3 interface so for the layer 2 a pound of mechanism we to define your flight like we flag to indicate whether the inter member dink and administrating is a virtual physical link and another extension is a new resource ID TL sub Q is defined to advertise the identifier of this subset of resource in the link and this information will be advertised together with the existing T attributes for each member Inc okay okay that\u0027s all for this the extensions and we would like to hear the feedbacks and we will refine this document I\u0027m just insurance or similar comment provided in spring I don\u0027t think you should be defined what network slice or network topology slice is you should refer government documents that\u0027s going to be the product of design team number 0 and I think you\u0027ve heard it before VPN is so much which I do not really BPL give it less controversial name VM for example might be good clarify this terms in the next version make it more clear blue burger as T\u0027s co-chair just to be clear we do have a draft on framework for enhanced VPN yeah we don\u0027t have any drafts on slicing solutions yet we do have a design team that\u0027s looking at a framework for slicing the solution "
  },
  {
    "startTime": "01:25:07",
    "text": "that\u0027s described here is nothing more than an individual draft and has no more than individual draft standing in T\u0027s as well um from entitlement for I think for the future networking the resources is OE so to be information so to be tripod or Freudian VD in the ITV network so every node can Raziel required the sauce long command for the kind of parties are interrupted I think the the follow follow you the owner follow follow Tron should be included for why and where this information come from and why why you need to fly to him okay okay I love improv avi I wanted to ask a loop worker to clarify this okey so it\u0027s for my point of view I see that the VPN placer are already defended is a slice framework why do you sing that they are some know slicing for a walk I\u0027m not sure what what what\u0027s the point [Music] Lou burger I\u0027ll defer to the chair is how much of a conversation you want to have about the teas working group but the in the teas working group we have the VPN plus or enhanced VPN framework as a working group document it does mention that slicing is a potential use case for that technology it is not something specific to slicing we also have a design team that\u0027s looking at the slicing framework and they\u0027ve yet to produce their recommendation into a working group so that\u0027s that\u0027s where it stands so yeah I mean we\u0027re gonna listen to the teas co-chair when we\u0027re hearing about like what it\u0027s an individual draft and you know this I think that we need to wait maybe for the teas working group to be selecting at least a direction technology\u0027s going and this shouldn\u0027t be us our Shin muses it like an end-run to try to present you know things that should be first decided on and teas here you\u0027re gonna be doing TLV extensions and stuff to support a technology right this isn\u0027t this isn\u0027t a place you\u0027re gonna get a blessing on a technology that needs to come out of teas hobby I wanna under one point I think addition in fact this of the BPM class offering worker two years ago we already when I assume you may know this is the history of this the draft I sing from this is a sight from Leah so the side meeting on it who that are ttw Gianna dent who the then to "
  },
  {
    "startTime": "01:28:09",
    "text": "the tears of working guru but I think at the beginning you know they say you the other beginning they see you the slice oriented a solution from that point I think that is already clarified as a beginning so I I don\u0027t understand at the point I think now they are talking about this not what I see I think this proper will help the implementation of the network strategy and butter you know it is not a point to the net for strategy and you know there are at least in other technology for implementations NATO study so we get which technology will be selected by the networks identities are topical you know it is I think it should not coupled with the networks rezian selection thanks I yeah we are gonna wait for the t\u0027s design team the other thing you you realize that there\u0027s another draft that was committed presented a few IETF Segoe with different terminology where they were using that yeah it was I don\u0027t remember the name of the the lady who presented it but it was it was also how you could do is slicing and or with you know that and then the terminology was different in that draft it might have been okay yeah I can I can look it up yeah nice you included them in the work yeah maybe another opportunity we can also look at the terminologies or whether we make it or generic and so that we don\u0027t rely on this design team or entities and make it a generic solution for set of scenarios ensure you\u0027re addressing particular layer in the transport slice you don\u0027t address all of it and it\u0027s one of the possible solutions it\u0027s definitely not going to be exposed not bound to consumer of it so don\u0027t make it more generic because it shouldn\u0027t be there\u0027s going to be more generic definition that\u0027s going to use this kind of technology below it but not this is not it it\u0027s really reasonably small parts of it right so in fact here I I problem my concern because I I don\u0027t think this is a good way to talk about the name I think we always talk about the use of slicing like this when the framework here I sing you will taller this one I think that is clear maybe later do you 3gpp you say please read for our architecture the network slicing proposed by 3gpp I don\u0027t see Melissa you look good away okay I think we\u0027re out of time right do you want to separate how you so summarize we have some I know we have some we\u0027re gonna go through the minutes and and look at what "
  },
  {
    "startTime": "01:31:09",
    "text": "we have a calls for it option and and I\u0027m I think we have one working group class called the request for working group class called I look at that and we also are looking for ways forward for first of all to make sure since we have the two giraffes in the first session the ttz and the area proxy for is is look at whether or not we actually need to do this in terms of requirements those are yeah I mean I was I I won\u0027t do the presentation I mean you know it\u0027s gonna load now it\u0027s like I was actually going to see if the ask as a presenter if the working group one she would have to reverse metric but I didn\u0027t present it so I don\u0027t think we need we could have a call on that draft without having it presented oh yeah well just do it on the list I guess but so we don\u0027t have time and nobody wants to see that yang mano presentation nobody wants a stylist a over for that so I think we\u0027re done thanks everyone yeah and again you know I\u0027d encourage everybody especially offers to move discussion along on the list about your drafts it seems like we have a lot of work you know a lot of theory of activity right before the IETF if we could keep the momentum going that we have before the IETF and during the ATF through the whole period would get a lot more done based on the bits you can use right but if I didn\u0027t think it did "
  }
]