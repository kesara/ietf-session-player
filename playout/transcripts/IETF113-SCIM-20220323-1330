[
  {
    "startTime": "00:00:10",
    "text": "okay and actress so for for those who are coming in you can use the meat echo from the phone by scanning in the barcode outside i find that it works easiest if you're on your laptop to just use the meat echo from your browser so i think we should get started i think with that we can get started can you guys hear me okay okay can can those on the remote hear me okay okay we're good nancy this is woman speaking you're loud and clear excellent thank you roman as are you okay so welcome to the ietf for you um for some of you"
  },
  {
    "startTime": "00:02:02",
    "text": "it may be your first physical those who are on site i think tim right no i can't see from here patrick um so welcome this is the skim otherwise known system for cross domain or cloud identity management um working group with me now i have a co-chair welcome him aaron crucky um so rules of engagement i don't know why i'm trying to flip slides [Laughter] who is here for the first time for those on site i'm presuming those that are remote i'm looking at the remote may have already joined so in the itf we follow some procedures that are noted in the note well in the interest of time i will not go through each of them i encourage you to read them next slide please we also have some online meeting tips we used to have blue sheets but since this is hybrid it's mainly taken off the meet echo attendance so this is where i encourage you if you want your attendance recorded to get into meet echo and there is a chat room too that you can get to through the little bubble chat in the meat echo or you can use jabber next slide please and we also have a code of conduct which is basically treat everyone with respect you're here to be an active participant and welcome the participation to this to this group all right um one more note since this is our first hybrid meeting and there are rules that the ietf is"
  },
  {
    "startTime": "00:04:00",
    "text": "trying to follow um please make sure that all of those that are here on site please make sure you're wearing your masks because it is mandatory okay okay with that um we can go ahead and get started with the agenda bash um i believe we have a couple of volunteers already for the minute takers so thank you ned um i forget who the second one is pam but you're kind of partial since you're covering the first one um and so i encourage i put the link here where the minutes are being taken which is in a hackmd hedgedock link i encourage everyone to review those as well because those are our recorded minutes next slide okay so on to the agenda um on our charter the first things off the gate is for us to update the use cases the protocol and the base protocol and schema and we have assigned editors for them so i've asked them to provide updates and progress on those we actually have elliot also who is focusing on iot he will be speaking to the use cases and applicability of skim for iot and then phil has posted a draft on how skim is a profile that can be shared using the shared signals and events so if he needs my help i will step down and aaron can take over cheering to help him present a little bit of background about shared signals and events otherwise fondly known as sse um but he will be presenting the skin"
  },
  {
    "startTime": "00:06:01",
    "text": "profiles for that um so that is the agenda unless anybody has any changes or comments it is the agenda bash time going once going twice all right so with that i will have pam come up and i of course let me bring up unless you want to share hi everybody i'm pam dingle from microsoft if you look in the chat in meet echo there's a hack md link there that is basically a an outline bash for the use cases and concepts document so my hope is today in this time we just we go through that we confirm whether this is in general the right thing and whether there's missing pieces and people please feel free to add to this better if you don't delete but if you do think something should be deleted type it in the text and that way we'll we'll reckon you know we'll cover that so just a little bit of of background uh if for any of you who are not aware and many people are not uh the rfc series for skim is actually three documents not two so there's a specification called rfc 7642 which is meant to be an overviews use concepts uh use cases and concepts however you know in the in the working group process in that last um effort that that document really served a different purpose at least as i understood it i wasn't part of that so i don't want to speak for that group but the uh you know it it helped to form what went into the protocol you know into 76 43 and 76 44"
  },
  {
    "startTime": "00:08:01",
    "text": "but it didn't get upgrade updated at the end and so the document doesn't cover all of the concepts that we believe an implementer white might need to know in order to come in and understand the specification and be able to implement to it so the goal here at least as i understand it is to describe you know the existing rfcs um in an updated internet draft you know or an updated draft um that is closer to the actual concepts that you know that are modern today so that we could have implementers more easily understand the specification so let me just check before i go further does that make sense to everyone is there anyone who wants to comment on the goal all right i'll take you're always welcome to add add more or or contact us after of course and or post to the list uh so so here's hold on pam oh we've got a hypothesis on the queue oh sorry quick question um if you want someone so one of the things that i get asked a lot is uh open api swagger um api specs for first game is that on the table have people talked about that i haven't been following this closely but sorry say that again lately open api specs for first game is that on the table i i mean this is one of the things that gets brought up a lot right today right among implementers who sort of look at scam and go ah looks like a doesn't look like a modern api it doesn't have the open api specs right i can't code to that because i have to write every all the interfaces myself right it is what it is right so i'm my question is whether that's part of the part of the charter explicitly or we we did not make it explicit in the time didn't consider it or you know we definitely consider i mean generally in the groups that i've chaired we try and use existing"
  },
  {
    "startTime": "00:10:01",
    "text": "as opposed to creating um api's interfaces so it's something we can consider right yeah that's actually a great idea um okay so when it so what you can see if you look at the heck him dean oh is there no elliott hi just um this good good afternoon good morning everyone um good evening to those further east uh just a slightly dissenting point of view on open api and swagger um i'm not sure that it actually is rich enough and stands up uh to some of these cases that we'll discuss later so leaf i would be very interested in your comments when when i come around to talking about iot okay yeah elliott is as the chair i didn't mean to infer that we would adopt those open api it's more the question as a group we shouldn't be as closed-minded right but your point is well taken i think at least we would want to evaluate right and half rationale pros and cons yeah okay so what you see here is a and it you know a first attempt to make the outline for the use cases and concepts diagrams uh or uh sorry um the you know the headings if you will for the document and so what they really represent are the concepts that we actually think implementers would need to understand in order to understand how to use skim um right now i have roughly um created some rationales around these as far as definitions go um i believe we probably don't want to redefine some of the things in the normative specs but we might want to define some of the more business-like use cases so for example i have user management and group management and provisioning listed here right so in the case where people maybe not"
  },
  {
    "startTime": "00:12:00",
    "text": "may not understand for example what group management is right it just it's just should be just enough to help people understand that that term is being used so so you know any any definitions that would maybe not be applicable in the normative spec but would be useful for the overall understanding of the concept would go here the next section is the concepts section and so i believe that these are basic concepts around provisioning right around um you know some of the industry ideas so what is us you know what does it mean to have a start of authority right so this you know being able to say that a given entity is authoritative for an attribute right or authoritative for an account is sort of the idea behind start of authority data directionality so the idea of of are you is it master slave were you just pushing things straight out or is it a bi-directional sharing because in the case of bi-directional sharing it obviously matters on an attribute by attribute basis which party in the transaction is authoritative for what um so that one's very loaded and may deserve a section of its own um just in time provisioning so a definition of what just in the time provisioning is for so that it can be used later schema and resource types so sort of the object model mutability and uniqueness so again not just what they are not just a definition but an explanation of why they're necessary in provisioning scenarios right and of course immutability and uniqueness then affect data you know start of authority and data directionality so these things become linked to each other identifiers and primary keys so in this case the understanding of for example why in scheme we have to have an external id"
  },
  {
    "startTime": "00:14:00",
    "text": "we can kind of we can put some explanation in there um api security which is typoed so under api security my thought was just explaining how a skim endpoint can be secured right just again just enough information some of this if you feel like it's too obvious please just add a comment in the document because there's you know there's just a question of where do you draw the line for what's to what's you can realistically expect these folks to know about hard and soft deletion i think is another concept that that it would help to have people know in advance when they try to plan their implementations and then privilege elevation so those are the concepts so i guess the first question i would have is a does anybody want to comment on the level right the the altitude of these concepts do they make sense you know it's sort of an industry altitude is everyone comfortable with that do you want us to run forward yeah we can run a poll um if that's not hard to do we could wait and oh there we go hi again um i i think these are good things i don't know that they're an exhaustive list um and i don't know that they need to be at this point right i think that the question you might want to be asking is does anybody object to anything in this list and i would be shocked if people did but you might want to add to the list as we develop things out a bit more that makes sense also i might not be using the right words right a lot of these have synonyms and and other uses so there might just be a more evocative term for the same network let me throw one example out you talk about um data directionality"
  },
  {
    "startTime": "00:16:00",
    "text": "uh putting this the schema aside right let's talk about uh connection directionality right which goes to the protocol right is is a restful protocol the the only way that we want to do this or are we thinking in terms of things like grpc or web sockets where we might want to reverse connectivity in some cases and i'll give an example of that later that's a great point ned i hope you caught that i can run a poll and is the question does anyone object to the use case list to the concepts concepts list as the starting point for the yes use case draft and the next step will be that this goes into a draft and gets posted and then you know we will have full editorial control for people to add i mean they can you're welcome to add here but obviously there'll be lots of steps in the future also okay is the poll running it's running i think it's good 18 answers i think you don't see it cause you started it oh yeah but it says start session oh i feel like we should have music no you don't want me um that's right yeah so so you can choose do not raise your hand if you have issues with the list i think the only issue there is if people just maybe are not connected does that mean they are by default not raising their hand okay is everybody apathetic or did i not run the poll correct i think we have 29 out of 29 so i think i think we're good yeah oh okay no nancy to help you with the with the process check this is roman speaking i think you ran"
  },
  {
    "startTime": "00:18:00",
    "text": "the poll right i mean my read is everyone you know you know universally agrees that we have a pretty great starting point great perfect okay all right so let's have your guidance great let's keep so let's keep going um how am i for time uh you're doing great you're great okay so the next one is use cases and this was uh and i think that not the last interim meeting but the one before we had a conversation about this um what does a use case mean and so the def the rationale that i've gone with here is what are the chunks of of skim functionality right that is that people might want to achieve right so it's not a business use case it is an implementation use case and so what you'll see here the use cases include negotiating schema it includes uh search and query um object synchronization life cycle and and then massive data set maintenance so i mean that's a huge like those four things are massive and can be broken down into subsections um but i don't have a sense of whether they're in any way enough right like i don't know that they're all sufficient um i do you know i do believe the massive you know that that management at scale is a theme that we want to spend time on right because that includes pagination it includes how do you bootstrap um a connection in the first place um eating you know includes how do you do bulk operations all of that um but we may want to break that up like if there's a smarter way to break that into pieces then we might want to do that right so and then you know so one is sort of a life cycle that really the idea of managing a given object in skim which is how do you create it how do you read it how do you update it how do you delete it right and then the second one is now how do you do these things across that massive scale"
  },
  {
    "startTime": "00:20:00",
    "text": "all right so i'm not hearing too many people does anyone want to comment or is there an obvious one here of all of you who are implementing is there an obvious thing that you're doing today that i that isn't even mentioned here yeah i mean feel free to come up and join the queue and we got janelle tooth so janelle you're in the queue janelle are you on mute here she comes hello there we go now we hear you hi um i think you've raised some really excellent points here i think one of the other things is that there's some data that we've come across that may need protection especially when it's a url that's being transferred like a url to a photo this has come up on occasion on separate notes danny has brought it up separately so there might be some you know how do we deal with sensitive data in the data sets or or how you know how do you gain access to it as another item okay that and that one might fit in the next section as well so i might just skip to the next section and then have everyone comment on mass unless oh wait we have another one we have a comment hi this is hansjorg um sorry for interrupting right now no no that sounds good it's meant to be a discussion so if i do a peek preview of the next section already i find actually the use cases this way a little technical so for instance if i see user self-service um i actually wonder like you know skim in the general sense for me reads like more like an enterprising math thing which is also reflected in the use cases in the technical part here but self-service on the other hand doesn't seem to be reflected in the use cases so far or would probably fit in in some way okay yeah that's a great point they're definitely pretty technical um can would you be willing to add uh put put an example in that you think"
  },
  {
    "startTime": "00:22:00",
    "text": "would be i can try yeah that would be great that this is the you know the more points of view the better for sure fantastic okay well then yeah let's go through the use cases um i so i you know the comment i think is that that it's okay if one of these two sections is is geeky but they shouldn't both be right like in some sense you want my hope for the scenarios was to essentially tie some of the geeky things together into end-to-end scenarios that would resonate with an implementer so you know i think this is where anyone who is implementing if you're not seeing a thing that resonates with you then it's clearly the wrong list so so we'll just quickly go through those example scenarios so the first one i think is our canonical example however that just might reflect my bias so um it says uh so a sas app writes a multi-tenant integration to get data from a cloud platform and i've i've set it up to be any cloud platform so that i could highlight how schema negotiation or how dynamics schema checking could work um i again don't know if that's realistic i know it's not a commonly used feature but in some sense if we can talk through some of the less commonly used things then in theory it would help people know how to use them so yeah so that so in that case that we would write something nice about negotiating schema understanding how to do an initial download you know an initial synchronization of account and group data right and then maybe you know after some amount of time perform a full-on reconciliation um to make those things to be sure those things match right so the implication i have when i say reconciliation is that maybe the service uh halted for a minute and we you know you you lost access so you weren't sure"
  },
  {
    "startTime": "00:24:00",
    "text": "if every skim command was received for example and i believe that's i mean that's a concern that we've heard talked about in the various meetings right um how do i know if i've missed something um and you know the difference in my mind between reconciliation and an incremental update is one is a brute force uh download and the other one is is a mechanism for knowing what the delta might be between what you have and what you wish you had uh okay so the next one is progressive profiling which uh you know the idea behind that is would be customer you know a siam customer identity kind of use case where you would in fact want to collect data directly from a user and then write it back uh to an authoritative source um so you know imagine you go to go to buy a car and because you've only been a you know a marketing subscriber up until that point they need to ask for some in-line important data before they can continue with the purchase that's the progressive profiling use case and then yeah the user self-service would be the idea that you go manage your profile you know web page or web portal and then that data then gets pushed through you know through the chain and then the last three so the first one is a bulk address change and my thought here is that it would be large enough scale so we could discuss pagination it would be um you would want to search with a filter right to only find users who have a building that matches the old building that we're moving out of and that you would then change the data in the address by running you know a patch of a bulk a bulk update operation uh incrementally to change only those accounts that have you know that where the building has changed"
  },
  {
    "startTime": "00:26:00",
    "text": "and then the last two um so we have no group management right now at all in the use cases and concepts so you know getting enough information there that people can understand the trade-offs for managing massive groups is a big deal so this idea of how do you replace a user or a member in a in a group that has a million users how do you do that without literally doing a get of every single user and then having to change only one attribute and then the last one is the idea of extending schema so that is again something that isn't in the use cases and concepts so just giving a story that normalizes how that can happen so after all of that so it's basically just storytelling at the end of the day um so maybe we can run a poll again you're welcome to add more stuff like either more detail to the stories or suggestions for different stories if you know anything you can do up front now just means that the initial draft will reflect it and you'll always have the chance to change it later but so is this content sufficient right to serve as a base draft sounds like a good poll oh we have someone on the queue too oh antoine you're in the queue ah hello oh you're never telling me so um i completely forgot during the for those that are on site to manage the queue they also do it on the media code i had some use cases coming from iot and cellular network background [Music] how do you manage the change of ownership on devices is something that i think could be interesting because if obviously in business use cases you have to change ownership for a set of objects from one person to another and uh"
  },
  {
    "startTime": "00:28:00",
    "text": "one thing that is also important from my perspective is to manage the the fact that company fails and objects are in the field for 20 years so how do you change the authority that manages the keys and the trust relationship for a given set of objects i think those two aspects are very important things to consider if you want to go in iot oh you you you uh i expected you to stay in the queue as i thought you might answer elliott you're back on the queue yeah i i typed something into the chat i was going to say pam um that i wonder if we could defer paul the poll on this part of the discussion until after the iot presentation because you'll probably want to pick something up i'm not going to try and tell you how to format every last thing here right i just think there's there's going to be food for thought um after that presentation and and some digesting may need to happen as well yeah that's a great idea yeah i'm happy to call this section done and you know i mean as elliott says we can run a poll to give you guidance if you still need it okay um because elliot is i put elliott next because he also has a use case right to address the iot okay great well in that case thank you very much for your time i really appreciate it awesome we got some time back all right so next up is elliott so elliot did you want to share your slides or do you want us to do do you mind if you share them that way uh i think it's probably just as easy all right so um i did up these use cases with janelle um who i will now use as an example next"
  },
  {
    "startTime": "00:30:01",
    "text": "slide please so how are these things how are these identities different and how are they the same each of these identities require credentials it so happens that janelle has a lot more capability to prove herself she has fingers eyes um and and the ability to type and um the the light bulb doesn't right there's no user interface on the light bulb there's no um means for the light bulb to to provide uh any a lot of context just visually other than blinking or something next slide so this is a big problem in in terms of just getting things on board uh to network um we want things to seamlessly be able to use wi-fi we want um things to be able to seamlessly use different connection technologies and for those people who've been paying attention to the the side meetings that we've been having and the meetings we've had in the um iot ops group um the nice thing about onboarding standards is that there are so many of them so um the the key question is right um you know here we have a provisioning thing we know we need to provide some information about the device into a local environment um we might need to delete all devices um we there may be a need to update existing devices um and there might be a need to um uh to group devices i say maybe mites you're hearing a little bit of hedging because i think we're just getting going in the context of skim"
  },
  {
    "startTime": "00:32:03",
    "text": "the the question is why not use skim and so we wanted to start with at least the concept and see where it goes next slide please so uh this is a fairly uh texty slide i apologize for that uh but the key thing here is that we want to be able to do as much automation of uh provisioning as possible so the the basic notion is you buy something um it should even be possible to automate the uh transfer of credentials relating to a device and what's important to understand is that devices need proof that they're connecting to the right place as much as the network needs proof or an or an application needs proof that a device is allowed to talk to it um the industry really wants a standard approach to that and as i mentioned there are many different standards i've listed a couple of here this has a lot of implications in terms of schema design right um the company i work for cisco uh used to have a slogan i don't know if it's still out there no technology religion well we don't want to have to make choices about technology at this level we want we want to have an expansive view at this moment in time maybe later on in life there will be consolidation but that's certainly not where we are not only in terms of l2 technology but even on top of l2 um in terms of the mechanisms that are used to provision things so as you see below right there to provision on to wi-fi you might use dpp or you might find a way to use 8366 vouchers or you might find a way to do other means of provisioning for ble you might use the oob mechanisms that are"
  },
  {
    "startTime": "00:34:01",
    "text": "defined you might do some weird thing with pairing keys which has been done out there and you might use fido fdo vouchers for any of this so um what this means is that we need a certain amount of normalization and we might even need multiple levels of normalization um and this is something that i think skim presents a challenge for at the moment um next slide so just to to put this in a more graphic view right you have a device um it might have wi-fi capabilities it might have 802.3 capabilities and you can just see this mesh of different onboarding standards that might be used in these different cases and so yeah here again it's it's no technology religion and this is sort of a use case that we expect to have happen because the console there is not likely to be a consolidation anytime soon we just want to be able to support whatever it is the device happens to support right and the key thing here is if we go down that right side what does it mean in terms of schema for dpp this is device provisioning protocol by the wi-fi alliance it's public key that needs to be gotten that needs to be transmitted into uh the deployment so that the device knows who that has the corresponding private key can do a cryptographic exchange to establish trust for 8366 this is a voucher from the manufacturer saying hey device you you should trust this deployment fido has something very simple very similar to an 8366 voucher which is called fdo ble oob is very similar to dpp in in terms of using a public key and then key pairs are of course sort of the poor man's version of that next slide please so the other thing here that we noticed"
  },
  {
    "startTime": "00:36:01",
    "text": "elliott you've got leaf on the queue okay hey uh come this might be like a clarifying question or not so you or maybe something you're getting to later and if so please stop me right but you you mentioned that this the all of the various types of key material and device types would require some sort of update to scan and to the security way we do security first game right right now it's all i think it's specified in terms of bearer tokens right and what i'm wondering is even if you have all of this complexity on the devices right you have some sort of key couldn't you like use a a a token exchange token translator approach uh to like get yourself a job token and use that to talk to the scheme server so how is this a problem for scam right the fact that you have all of these yeah okay so the issue here right is we're not attempting in the iot use case we're not attempting to modify the iot devices themselves right the use case in this case is to take what the iot device offers right and allow the local deployment to have access to the necessary information in order to onboard that device sure but understood but the iot device has some key something right right and what i'm trying to get at is exactly what how does this affect skim right because all you need to to feed to this game server in order to make it happy is a a bear token a jaw token or something right and you can get that through any kind of mechanism if you have access to some sort of key material on the on the client so why does the fact that you have a a wide range of client types and key"
  },
  {
    "startTime": "00:38:01",
    "text": "material why does that affect skim so it's a matter of what we're talking about here is creating a device hierarchy within skim if you will or device schema within skim right right so it's a schema it's a schema issue not an authentication issue it's a schema issue exactly right okay okay sorry i wasn't clear there tim cappelli is on thecube too and that trailed right into my comment i think the one thing i would say as someone who worked on the more of the non-headless device space this is not unique to iot and i think it should be positioned as devices right in a like if you look at a directory right we store billions of device relationships side-by-side with user objects that are not iot devices so it's really devices just absolutely just for the general general uh information okay i think you've called you've caught me out using the the letters i o and t together i only mean devices um so the other issue here is we see the need for directionality to be flipped in terms of who's talking to whom the use case that skim was initially designed for was you have an enterprise that's using some cloud-based service and you want to mass provision the cloud-based service based on the user base that that's in the enterprise in this case you might have partners that are providing or suppliers that are providing devices to the enterprise and in this case you actually want those guys to transmit the credentials that are necessary for the enterprise to make use of those devices so there's a little bit of a directionality issue right it's it's not add this user to your service it's add this device to your inventory is really what's being asked here and it's meant to be used in conjunction with the other mechanisms then to onboard the device on say the network or"
  },
  {
    "startTime": "00:40:01",
    "text": "in applications next slide so there's a that this is not your your uh there was an old commercial in the 1980s that said this is not your father's buick well this is not your parent's skin right this is a little different um first of all bootstrapping credential movement is required uh in these cases in the cases that we're discussing it's not a it's not something that will happen sometimes it's something that's likely to happen every time um the supplier may be the skim client as opposed to you know a a service that the enterprise calls out although the connection and the the connection direction is something that we do need to discuss in a lot more detail um and uh the device identities uh here need to be clearly scoped um especially if you have supply multiple suppliers you don't want one supplier dinking with another supplier's stuff just and this is directly analogous to you don't if you're if you're a service like salesforce you don't want one enterprises provisioning operations impacting in other enterprises provisioning operations um the device attributes are going to vary um based on the capabilities of the device and this has schema implications um and there's likely to be a desire to carry other stuff so extensibility will remain important so examples that i give are software bill of materials information which is very hot right now it's very hot topic both in the u.s and europe device type information is another thing that enterprise administrators really want to have they don't just want to know that a device is being onboarded they want to know what the device is that's being onboarded um so they can they can understand how to deal with it"
  },
  {
    "startTime": "00:42:00",
    "text": "these are some examples of variances that that you might see next slide so this raises a couple of questions right one question is um you know what is the relationship between users and devices then is there a notion of ownership here that has to be assigned and owners in the con certainly in the enterprise devices will have owners or people who are responsible for these things but it's not clear that the supplier has to actually um be the one that sets that and in fact probably the supplier doesn't so there but that doesn't mean there's no relationship the other question is uh as i went through this right it became hard to understand which schema language to use to describe all this and so we actually um did up our initial schemas in in json json schema um and i like it because it's sufficiently rich to accomplish the job and yet it's still readable unlike certain schema languages um so these are just some other things and we we do need multiple refs you know real refs to be able to call in various polymorphic like things and as i said in my initial attempts at least and i won't claim to be a swagger expert but in my initial attempts at this with swagger i i absolutely got frustrated and i did spend a fair amount of time trying to un to get through some of those frustrations in terms of having uh a fully normalized view so these are just some things that i raise for comment eliot you have eric on the cube okay uh eric norman so um from an information flow perspective it's clear that you know the the supplier is actually providing a bunch of information right credentials etc right s bombs whatever"
  },
  {
    "startTime": "00:44:00",
    "text": "when i added that but but from the perspective of who is initiating the operation to add this thing to the system it's not clear that's the supplier because yeah you can do it yeah you might want to wait until the the light bulb showed up the pallet of light bulb showed up on the loading bar dock right until you do that right so it's not clear that this communication thing necessarily changes and if you think of it that way then you have as a sort of enterprise accepting this stuff you can now say okay i'm gonna put these things in these groups or whatever other structural things you have right similar to the way you handle users and putting them in groups or organizations or whatever so i don't think it's actually that different well i think i think you can see it both ways eric that and i think both models are perfectly reasonable to to to pursue you've got tim on the cube hey tim microsoft um i think the difference i think the one thing that's different in this world is that you essentially have a bootstrap idp and then the final idp so there's really two idps at play which doesn't traditionally exist on the user that that's because ultimately like dpp for example the supplier needs to essentially send you a list of public keys map them to something and then drop them in and then at that point you can provision a new credential that's specific to your organization so i think that's the difference in the flows as well yeah this doesn't talk about what happens once the enterprise receives the information there's mere presumption that the right thing happens but i don't get into any details in this discussion about what that is right as you said tim in dpp you're gonna there'll be a maybe a dpp 2.0 exchange and then there'll be a certificate and one example would be a certificate uh provisioning for that individual device trust anchor exchange yada yada yada for 83.66 it might just be a a conversion from an idev id to ldap id communication"
  },
  {
    "startTime": "00:46:01",
    "text": "um online however that might occur um you know etc and so all that mechanism i don't think we should have to go into great detail in the skim group all we should be able to do is support the transfer of the information so that it can get there enter domain questions comments because that's it i think next slide is there a next slide okay you just posed a question you've got tim on the queue i should have said by the way as someone who's been trying to battle this for seven years prior to joining microsoft i'm very supportive of this i think i hear a co-author okay so so elliot um your last question is a draft that's kind of open-ended well yeah because i don't really know exactly how we want to take this forward and i sort of leave i'm in your hands chairs yeah so at minimum it needs to be captured in the use cases just so that you know i i do believe it's in charter as we are saying we need to update the use cases all of this we obviously need to get consensus from the group right um so we did we did defer the the pull for the way forward for the use case draft and so one potential avenue is for you to incorporate these concepts into the use case content and i can make that addition to the poll um or you could create a proposal i think earlier on you i think leif asked a question on you know what's the main update change here um and i think the use case may clarify"
  },
  {
    "startTime": "00:48:01",
    "text": "that um the second step or or similar step could be you generate a draft that shows that way forward and a proposal of what that might look like actually i'd really like to hear from pam as to as to how she'd like to proceed on this a little bit no you do not we recognize you pam um i so i think the question is if it is a draft i think are we looking at a schema extent like do we have to make that technical well leap first or do you just want to talk about the use cases there's two parts to it right it's the the solution what that may look like but then there's the recognition that this is a valid use case and that's where i'm suggesting you know we could create a separate use case draft but we said we would be updating it so for me it feels logical as you're working on the adoption that you could incorporate the content but that would be my preference yeah that makes sense to me i think too i mean there's at least three people who have knowledge and expertise here right so i think we have you know we have enough people to to flesh out something that that others could then riff on right so i'm in support so i could uh i could make one pole and if that doesn't go then i can break it up into multiple poles so how about if i do a pull of is the i'm gonna short short it into is the hack md content presented by pam by pam and elliot's iot use case sufficient oh you're getting back on the queue yeah"
  },
  {
    "startTime": "00:50:01",
    "text": "i just realized something sorry just thought of a reason so one thing is we have to decide what the use cases and concepts document applies to so if if this kind of iot work is new work then it might actually be applicable to a new version like if we're going to write use cases and concepts for the existing rfcs 76 43 and 44 then that might need to be a different work effort than than the new work that this would constitute i don't know does that i mean we we could wrap them together but i do feel like a description that is purely skim 2.0 is valuable but if others disagree so i don't know if we concluded as to the update because we discussed this i think in 112 and in the in the virtual but we didn't conclude as to whether the update would be to skim 2.0 or if we would just do a jump and the updates would really be creating a skim 3.0 so we might want to do that scope question first i don't know okay okay we've got more people on the queue phil you're next and cue phil are you on mute it's not his audio is not working so phil's comment on the chat is uh on the jabber"
  },
  {
    "startTime": "00:52:00",
    "text": "that elliot's draft is just a new schema but uh this is more on the revisioning of the draft so um phil can you speak okay while we're waiting for phil collin sure so i was just going to say my comment's really simple which it seems like these could be split apart as two different pieces of work of the the device's stuff and the the refreshing the the other thing so i i my only advice would be just everything that can be split apart split apart why not unless they have to be deeply coupled in some way and i'm in favor of course dealing with devices um i hate the word iot but i like the word devices um but it seems like it could be split apart so with that let me jump off yeah we can argue iot versus devices later it's the body of work but but cullen um sorry you might have to come back so are you speaking that it would be okay to incorporate into the use case draft and then we decide as to whether the solution gets split yeah sure i just think that documenting the actual protocol solution you may want you probably can split them up and have one be an extension to the devices being extension to the base and split that up and as far as use cases yeah put them all in one place thanks yup thanks okay phil should we give you another try no we lost them okay elliott while we're still waiting for phil yeah i i um i'm fine with with breaking up work where it can be broken up my only comment is simply that this is not just schema work um there's connection model there's data direction um we should i i was figuring we would just cross those bridges when we came to them you know flowing from the use cases that's all yeah and that's why i try to explain that first we need to recognize it as a use case in the group and then we"
  },
  {
    "startTime": "00:54:00",
    "text": "determine the path forward and the actual technical work um danny you were on the queue and you disappeared i'm presuming you're back danny you had a comment it was uh pretty much just to say uh once you get into my section this is one of the key things that i want to cover which is essentially what's 2.0 what whatever the next is like 2.1 3.0 okay and uh specifically that use cases saying that pam step back up can you hear me now yes we can phil yeah okay thanks so danny i think you got your point thank you okay phil we can now hear you i'm worried because i have to talk later sorry yeah i was like i cannot do all the slides phil it is uh breaking up a lot so hopefully we'll have success i just wanted to say to elliot go ahead i think elliott's could be a new draft the big part of it is new schema and it also occurs to me that along with devices we need authentication authenticator schema as well so that might be two drafts and then the reverse flow might be accommodated with the security event tokens and we'll see more about that later okay so phil just to clarify you are speaking to the technical solution um the question that i want to put on the poll is whether we should incorporate the iot slash devices as a use case in the updated use case draft are you speaking in favor again can you say that again are you okay incorporating the iot use"
  },
  {
    "startTime": "00:56:01",
    "text": "case in the base use case draft its use cases not technical solution hello can you hear me now i'll put in the chat i i just type he hasn't typed uh no no no private chats okay well he can vote against it let me just run the poll because we are well over time sorry i i yeah um so we are well over time so let me run the poll and then we need to move forward so um start the session come on my machine crank the bits come on can you see the code come on there we go okay so this question is since pam presented the outline that's in the hackmd for base content it's not final it just enumerates some but it gives us a starting point and then elliott also produced a use case that goes to iot slash devices can we incorporate both of them and can that serve as the base for pam and elliot to start the use case draft so raise your hand if you believe that to be the case or not"
  },
  {
    "startTime": "00:58:12",
    "text": "okay it's not just my connection okay we're gonna give it uh ten more seconds and i'll close it while we wait for that can i just jump in with my okay so i mean you're still gonna do an uh i still have to do a call for adoption so yeah all right but pam wanted guidance and you know ellie presented the use case so okay so pam you have rough consensus julie you have good consensus 24. um so what you can do is we can give you a public that's not adopted yet in the skim working group and you can put stuff there and you and elliot can move forward okay with that we are running well over um danny and janelle protocol and schema did you want us to share the slides or did you want to use um present them yourselves uh could you please share them and it's one it didn't yeah it was loaded give us a second we loaded them but oh it's there ah yep there it is no but it's there it's this one this one yeah"
  },
  {
    "startTime": "01:00:03",
    "text": "and now you go back and then yeah you share okay that's what i did in team there's something about this room well that's what happened when i was in this room we're getting there okay danny we even though we see them we can't seem to share them can you try sharing them second yeah i had the same problem uh on monday and i was in the same room okay i'm going to give sharing uh a shot welcome yeah did he get access yep should be coming any second okay we can see them okay cool um so yeah my name's danny zolner uh i also have with me uh janelle allen and we are the currently uh like nominated for tribute uh editors for uh schemas and protocols"
  },
  {
    "startTime": "01:02:00",
    "text": "uh next slide please oh wait i'm presenting so uh i i have to do the next slide um bear with me um so yeah just uh a quick sort of run through things uh so the current charter that we have i provided a link um and one of the things that's been uh proposed and discussed uh especially i believe in itf-12 but also in the interim sessions that we've had in between is uh the topic of progressing uh skim 2.0 standard from proposed standard which is where it sits today uh into uh internet standards sort of its final form uh and there's sort of a floating question of uh is there significant value there uh like do do we polish up scam 2.0 put a bow on it finalize it uh or do we just sort of leave it as proposed standard and uh work on 2.1 or 3.0 or whatever we may call it i think i refer to it as v next in most of the remainder of the deck um and then there's another floating question of what level of error correction clarity enhancement etc is permissible without issuing a new version an rsc series it's uh sort of like what is it the ship maker's problem where if you replace um all the wood on a boat one board is high at what point does it stop being the same boat like how how much can we change it with actually still remaining 2.0 and to that i strongly look towards the chairs for guidance uh but i want to just just you know put that out there it is one of the big problems that we're trying to wrap our heads around today of how much of the charter that we have today um yeah how much how much of it is a charter today sorry um thoughts are getting doubled uh how much of it is doable today versus in uh in a future version um and then uh so the try to propose a lot of schema and protocol"
  },
  {
    "startTime": "01:04:01",
    "text": "enhancements virtually all of those are too big to be um part of 2.0 uh if you know we're looking at that as error correction and whatnot so there's um that a question that i would like to be uh discussed which is uh do do we go towards 2.1 3.0 or do we finalize 2.0 and just throw out a litany of extensions to cover the you know 20 plus topics that the charter would like us to cover so i'm gonna move to the next slide and uh just quickly here's all of the work related to schemas and protocols that's uh listed in the charter it's available at that link that i've also previously shared i'm not going to spend too much time on this but it's everything from uh you know sort of clarifying and expanding on usage of things like external id uh changes and expansion to account state um you know completely new concepts like multi-value query filtering and paging uh and you know a couple of other things as well and uh it's just there is no conceivable way that we do this inside of 2.0 so i really want to get like a a group consensus uh and figure out how we proceed forward uh and one quick thing to share also we have uh set up uh with the chairs help a uh a github uh organization and we have a couple of repos containing uh the current xml versions of the uh the schema and the protocol apis and we're going to be working on uh sort of tracking the various issues as github issues uh to easily facilitate uh certain discussion and propose solutions throughout that uh which we we will still also then recap uh and bring things for discussion uh over the skim mailing list as well um and there's just a couple notes on uh the plan of how we proceed here uh i'm not gonna linger on this unless anybody has questions i'll send this out via"
  },
  {
    "startTime": "01:06:00",
    "text": "email as well so uh i guess one of the the big topics and i'm trying to get through this quickly because this is a discussion really i like the goal here is feedback um one of the things that um if we were to push 2.0 to be internet standard we would need to do a survey on the implementation of concepts and uh honestly even if we're not pushing it for 2.0 there's probably still value in figuring out are there parts in the survey are scott uh sorry uh are there parts in the uh in the 2.0 standard in the schema or protocol that just aren't adopted you know either at all or widely or in an interoperable manner uh and so we'd like to get feedback on that and sort of start the ball rolling on uh either cutting or uh resolving issues with certain parts of the uh of the existing standards uh i'm sorry let me go back a second uh and so yeah just a couple of examples there um you know basic auth in the uh in 2.0 you know skim was you know skin people was published in 2015 um at this point in time just you know i i think it's sort of inexcusable to use basic auth unlike the you know an internet facing implementation of scam versus something like a bearer token or some form of oauth uh there's also uh you know passwords um if the the common law of the land nowadays and you know industry standard is uh federation uh between uh you know in idp and something else is their value in uh the core schema at least containing passwords uh i i'm aware that there are certain uh mostly we'll call them like legacy uh concepts where um you know you might be provisioning into some you know like a"
  },
  {
    "startTime": "01:08:02",
    "text": "mainframe or something where you must provide a password uh and that makes sense but whether or not those are sort of internet facing and whether they line up with the uh sort of the the goal of this game standard is um uh up in the air if we look at the name it's the system for cross domain identity uh uh management god i'm yeah i'm not uh my game today sorry uh and uh there's other things like photos as well um which we've discussed in the interim which from a sort of cross cloud standpoint um are hard if not impossible to implement due to security for concerns um so just you know very it's a non uh it's not an entire list the goal i again you know we want other people to get involved rather than just being uh janelle and i uh trying to figure things out on uh on the feminism protocols uh is anybody seeing this slide correctly it looks incredibly i just solution it looks looks uh bad i don't know what happened there yeah um okay well i happen to have this light up on my other monitor so it's a very short slide um so the title of it is xy problem um and uh i have a bullet that says are some concepts useful but potentially outside the scope of what the skim standard aims to address uh with a sub bullet that says some decisions on cuts and edits to 2.0 should wait until after use cases are revised and then there's a question that sort of came up when uh when pam and elliot were speaking as well uh which is is the work to revise use cases targeted at 2.0 uh at the v next of you know 2.1 3.0 whichever or both which i i thinks are good now i was"
  },
  {
    "startTime": "01:10:02",
    "text": "going to say uh phil has been on the queue he just dropped from the queue i didn't know if he had a comment on your slide phil feeler oh no comment okay never mind sorry um yeah and so finally just bringing it to a recap i really just landed it to the question or the questions that are floating and at this point i anybody who's here i i want uh opinions because i i've got my own but this you know the skin standard is not mine and i don't like i want feedback please on what my people's thoughts are on uh really each of these big points we actually had allocated 40 minutes so that we could have a discussion so any feedback for the protocols or the schema or the combination of both paul i think you're in the queue go ahead paul i am in the queue good morning um so my perspective on this is that we should do the right thing so as implementers i think looking at a long series of extensions can get really complicated and so the more we incorporate into the course back i think the better likely the better the likelihood is that we'll have full compliance with the the intended outcome of this working group in future implementations okay thank you janelle janel you're you're a presenter so you don't have to get in the queue by the way i know i just didn't want to interrupt anybody um one of the things when we've been"
  },
  {
    "startTime": "01:12:01",
    "text": "schema and there is a lot in the core schema comprising an identity and there's a lot of questions that come into play regarding that like for instance it may be valid to keep passwords around for some use cases but perhaps driving that into its own extension or sub-schema of the core and and same goes for some of the other schema elements but if we start breaking apart like that and take them out of the core then you know what does that mean for those who've implemented 2.0 that sounds like more like a 3.0 thing um which is kind of where some of the thoughts that we've had have gone when we've been discussing like how do we just put a bow on 2.0 like should we just do light edits say this is it and and give 2.0 the credibility has lots of people have implemented it as it is um with some clarifications um fixing the errata some really clear use cases of of how to work with the spec as it is or just say that's it this was a great standard it served its purpose for its time like let's drive forward on 3.0 i think that's that's where we wind up half the time that's where danny and i are coming from is just how light do we want to be or you know how quickly do we start coloring outside of the 2.0 lines before it's not too low anymore i mean doing the survey and and eventually once you get a draft out there with reviewers i'm sure you'll get feedback just as the tls working group did although they also took a survey before they deprecated 1.0 phil you're in the queue phil's having audio issues i can relay his comment he says questions regarding photos photos is just a uri there is no obligation to import or pass an image into skim is that the issue"
  },
  {
    "startTime": "01:14:00",
    "text": "uh so yeah photos came up in one of our uh or i think this is our most recent uh interim session as well and i never got a chance to follow up on it over the working group email uh so the the problem with photos from uh sort of like a sas or like a cloud internet scenario is uh you if photos in the spec right now is described as a url and at that point uh you're communicating the url and the other side would just uh so you know the client communicates the url and the server would then have the url on hand to go pull the picture from uh there's problems there though of how does the client especially when it's over the internet rather than on an intranet uh where there's you know firewall rules and you know just security is a little more easily managed uh how does the the server come back and retrieve that image uh to use and it's it's in its own service uh sort of like hot linking to it and just pulling the image every time it needs to be loaded isn't necessarily feasible and just uh from being my own experiences which color my you know my thoughts here um any like fast implementers that i've talked to who have service providers who want to consume pictures they want to be able to receive a picture and store it in their service so that there's no meaningful latency when they go to show it in somebody's profile and so that whole like approach to pictures uh isn't something that's really uh doable today with what's described in the skim spec sort of a question sort of a comment so um with respect to that question now how to deal with making this skim 2.1 making it skim 3.0 something like that my observation is somebody digging into"
  },
  {
    "startTime": "01:16:01",
    "text": "skim very recently and discovering skim very recently is that there is quite some wide adoption actually in a quite specific use cases like identity providers provisioning star services and this is actually very widespread so a lot of services are supporting that so i wonder if there would be some major breaks or major changes that it probably would be very difficult to to change all these implementations and so far it was very difficult for me to identify other users or use cases so far so i'm a little bit surprised or it's new to me to see there's so much interest in iot at least i didn't easily stumble upon that while introducing my or myself to to skim before so my question a little bit is also is there some um i mean which i think would be helpful for casting that decision about how to go forward with a uh with the update of the standards is basically does anybody actually have an overview of which different domains exist and use cases are already implemented and if not that might be i think very helpful in order to cast that decision yeah pam i want to say in the buff we had we had a cursory it wasn't complete um [Music] so we could try and bring that up in an introduction [Music] perhaps in a virtual interim yeah to help with that go ahead pam yeah i think there's some interesting question about um so the use cases that we did see that were new often they were characterized as schema extensions um and they included hr um hr use cases um we can definitely go back and look at what those are but i think we have a starting point for that kind of um overview if you will that there were two main categories there was the updating"
  },
  {
    "startTime": "01:18:01",
    "text": "of the protocols for scaling scalability and then from a schema it was i think we used the word modernizing um relating to the the fields that an hr database might have but as pam said we can you know we can bring those back um they may actually be noted also oh no it wasn't about never mind but we can bring those back up your point is well taken thanks um so danny i i should channel philip's response to your response to the uri and photos is um there was discussion before but maybe it was on a virtual um but anyway there was consensus from before uh that implementers wanted to choose how to solve the problem as opposed to addressing so that was phil's feedback um yeah i uh from my own experience uh there's a lack of adoption for specifically photos because there is no standardized way to approach it so it's really i think a question of uh is the current uh photos uh just you know sticking with this um fleshed out enough to actually be adopted at all and i suspect that the answer is yes based off of what phil said in the previous interim uh however uh this in turn i think brings us to the third bullet point on the slide that i'm showing right now which is uh even though it's not really milestone related but um for things related to the scheme and protocol um should we like try and get the use cases to cover things like to uh to cover"
  },
  {
    "startTime": "01:20:01",
    "text": "uh essentially to describe the problem that we're going to solve because well the the uh description of how to do photos in skim today works in certain scenarios but it doesn't really work in like the the internet the sassy scenario uh which is uh yeah i don't know why there's an echo um but uh so yeah the photos work somewhere but does it work for what skim is actually trying to solve i guess that's the question and this then expands out to a whole bunch of other things like passwords yeah so absolutely for some of the new work you'll you'll be guided through the use cases i thought in the charter we had some examples of the updates that needed to happen vis-a-vis the schema i'd have to go back and look at the charter so danny you you put this the schema and the schema and the protocol is going to be gated somewhat by the use cases but i felt that there was enough of an understanding that some of the work not all could be done in parallel if that's not correct then i stand corrected i i think some of it can be done in parallel um we if i still need to lan like figure out and do a vote or whichever on how we proceed whether it's the 2.0 or a v next just so that we can have consensus so i'd like to i just figure out how we were that and put it up to a vote here or a show of hands on uh do we finalize 2.0 and build out a series of extensions or do we work straight uh like do we just move towards 3.0 or you know use 3.0 as a placeholder when i'm speaking sorry for whatever the next version number may be lasers in the queue so i think the current version the"
  },
  {
    "startTime": "01:22:00",
    "text": "current published specs are 2.0 that's how they've been described um for a long time right so i think whatever this is is 2.1 or 3.0 um and i would i tried to i split it up into individual github issues and have a discussion i mean maybe starting with the you know any identified fundamental stuff um that actually changes the protocol you know in a way that breaks maybe breaks backwards compatibility compatibility but it's certainly sort of there are stuff here that maybe is challenges underlying assumptions from from the point of view client implementers and that should probably go first in the discussion queue to figure out sort of you know what their what the implementation community is thinking about it um that's i guess what i would do and and then you know yeah there are plenty of extensibility hooks in scheme there there's no need to push everything into the core brother goal if you don't have to thank you elliot you're in the queue thank you i largely agree with lei over what he just said um that that having like an issue tracker will will help um you know the i think the more important thing to get to is understand what good looks like rather than what the version number is and as much as you can increment i think it's good to increment the question is where do we need major change and what is incremental and those can even proceed in parallel in some sense if if that's what people want what um where i i slightly disagree and only only slightly disagree with life and it's"
  },
  {
    "startTime": "01:24:02",
    "text": "such a small matter that i probably shouldn't even mention it but i i think it's important to understand core protocol implications what needs to be there what in the core what what needs to be in the um in extensions i'm not sure that that that skin is perfectly extensible i think a little bit of elaboration in whatever follow-on specifications happen should be a lot clearer about um for instance uh how do you fully normalize right because there there isn't a lot of example in that in skin and it's something that wasn't really con i mean i think it was contemplated but at the time that skim first came out right it needed to get done because people were waiting for it so now we have a little time it's worth at least making sure that you know things like normalization schema language choice all these things need a little bit of discussion thank you um janelle you pass on me to say yeah well thank you for your feedback everybody um who's provided it and i think yeah we're just you know trying to do what's right for the standard um the standard as it exists and as moving forward there's certainly areas that are interesting too um and it comes up with regards to the identity providers you know i think prior when skim.2.0 was coming about as a standard there's this notion of the single authoritative source of identity data pushing that data the service providers can actually choose experiments that of course you must provide to them"
  },
  {
    "startTime": "01:26:00",
    "text": "and um in part of our discussions was well should we have the service providers report back which attributes they're willing to accept from a from a client so that because they may not take them all they might not take the password for example or they also may not take any of the other attributes if they're you know if they feel that they're the authority of the phone number um and not the client they might say well we're going to ignore that phone number and so then this provides a notion of well then if you send that back and the client is expecting to then read back that data and match it with the data they have and there's a mismatch and how would you reconcile that um or how would the client reconcile that or do you move to more of a notion of a composed identity profile which might have data from multiple sources comprising the true identity of that individual was some of the other things that have come up and it comes up to when we talk about you know who's the authority on the device side uh for that device data and things like that as well so there's some there is definitely some overlap in that area um and i think it'd be great to get feedback on those thoughts given the guidance danny and janelle you could put you could put a first rough draft together and give that as a start because we still have to do a call for adoption for it anyway and i think you'll get more interest that way given that you have more substance there for people to discuss and say well this may be missing or we're not addressing this part or we don't believe this part should be addressed and the question is do you have enough now to get you going and then at the next virtual or or"
  },
  {
    "startTime": "01:28:02",
    "text": "at the next face to face or hybrid you can do it that way okay yep okay uh well yeah we're at the end of the slides uh so i think at this point we'll uh sort of try and cut apart what can be accomplished uh without waiting for use cases what we think should reasonably we waited uh for to make sure that it aligns with these cases like is it a solution to a problem that you actually want to solve um and then uh we'll we'll work forward from there all righty well thank you thank you okay so we keep bringing the mic back and forth just for you guys to know we're trying to do our best is there may be some feedback but if i don't get it close then some in the remote can't hear me um so next up is phil and he was going to present skim events there is a draft up but he's having audio issues he did send me a transcript but my last question is phil do you want to give it one last try or do you want me to just read the transcript what's that okay he told me to go ahead and read it so you guys bear with me stay awake okay if you could share the slides great okay so thanks everyone for coming out today"
  },
  {
    "startTime": "01:30:01",
    "text": "this presentation is about security events profile that i recently published as an individual draft what are security events and what are the propos what are we proposing for skim you may be wondering what a profile is i use that word to indicate we are not space specifying something new we're simply taking an existing set of specs and profiling them for use within skin so what are the security events then next slide oh that was the agenda slide next slide sorry okay what is a security event token it is a specialized use of jots profiled or exchanging secure event messages between systems in 2015 several groups inside and outside of the itf were all planning to do the same thing morteza and serie of cisco and then co-chair of skim william dennis of google and myself not me phil hunt then of oracle put together a draft specification in the skim working group that extended jots for skim events this draft was submitted to address skim's charter item of being able to send trigger events between systems because so many groups were thinking about the same thing there was quick agreement for oauth 2 open id connect and risk incident sharing groups i forgot to reset this risk incident sharing groups to work together on a common spec which later became set or in the itf rc 8417 under the working group sec events so why use dots for a couple reasons we wanted a json message format that could be signed and or encrypted we wanted a form that could be secured independently of the medium for transfer"
  },
  {
    "startTime": "01:32:03",
    "text": "so what is the security event and what makes it different from the skin protocol one way to think about this is that skin describes a set of synchronous http requests along with a message format that work as api and quotes commands however events are simply signed statements delivered asynchronously enabling a receiver to take some independent action in skim protocol control lies with the requester though the server is free to refuse while in set control lies with the receiver why is this important well in cross-domain scenarios the users and group entities represented may not be the same population and when they are they may not contain the same attributes what often does require coordination is a need to link life cycles of resources across domains for example a user disabled in domain a needs to ultimately be disabled in domain b in an event system the event receiver which has full knowledge of its local domain is able to take an external event request more information if needed and then reconcile that event to determine what local action should be taken if any next slide okay so the security event token spec rc 8417 is the primary specification for skim events for those who want to implement set tokens you can create sets using almost any jot library i hope to have a new library shortly with some convenient builders for java shortly under the sec events working group two basic delivery specs were defined the set push delivery rc"
  },
  {
    "startTime": "01:34:02",
    "text": "8935 specification allows a publisher to post an event to a registered web callback endpoint and the set pulling delivery spec rfc 8936 allows a receiver to initiate http requests to retrieve new events to enable real-time delivery set polling also defines use of http long polling one aspect of these drafts is they do not require the set event publishers to guarantee long-term ability to recover events instead the specifications require the receiver acknowledge each event received after the receiver has securely validated and secured a received event when an event is acknowledged the publisher is free to forget every recovery is left to the receiver receivers why the heck did we do this well i believe it was because some set use cases like oidc risk open id risk called for some publishers to have hundreds of thousands of event receivers there were critical concerns that the ability for a publisher to retain past events for each specific receiver that recovery may not be possible is each event would take hundreds of thousands 100k copies persisted for a long period and if you have a few thousand ops per minute that can be a lot of data in these cases it's far easier for the receiver to accept and maintain the event to its own needs i note that in skim scenarios we likely won't have an out of balance cross domain relationships with event receivers i would anticipate relationships to be one to a few or more likely one-to-one exchanges of information between domains fortunately the set delivery specs do allow for longer event recoveries they"
  },
  {
    "startTime": "01:36:01",
    "text": "just don't mandate it all this brings me to the issue of how can we implement this is there something that manages event feeds and implements the set transfer methods for that i want to turn to the presentation oh crap he's turning the presentation over to nancy that's me um as i can share some of the work that we're doing um with the cisco duo team um and it is open source so next slide please okay so basically we've so hard talked about the sets um there is a new working group in the open id foundation called the shared signals and events it is a framework that defines an api or interface if you will and i've put the link in there that does leverage the use of the delivery streams using sets using the set push and the set pull to manage effectively these streams that phil has been mentioning there are currently two schemas that are defined in their risk isn't quite going through last time if i recall but the one that has been approved is the continuous continuous authentication and evaluation protocol fondly known as as cape and so what i listed in the table is the different event types that are defined in each of the schemas um and cape is the one that the working group is mainly latching on next slide please and so i i think i lost the link there we do have um cisco did implement a reference implementation so if you're"
  },
  {
    "startTime": "01:38:00",
    "text": "interested to see how it gets used um the link is uh shared signals guide dot io and if you guys are interested did i put it in there oh thank you i thought i'd put it in there it's there um basically the flow of um the flow that's defined and the shared signals and events are in steps two and three that are being described there um the one and two is basically an endpoint um doing the service request to a relying party and then the actual meat of getting the the event of um i'm a security so more like a security event like in cape your authentication token has been revoked is where that registration and pull happens in step two and three that's the shared signals and event work and then the actual enforcement or remediation um action is in step four so this is just like the stratospheric view of what sse does um we wanted to give you that introduction um so that you would know about it as we now bring it back to skim next slide please and so the major use case here that has been talked about since the beginning of skim keeping resources between skim servers coordinated and or in sync the specca that identifies two variations the domain-based replication has the objective that a single domain has a common schema and a common set of resources the idea is that coordination messages be sent to enable each skim server to stay in sync with the rest of the domain with some minor exceptions an event message simply repeats the skim protocol"
  },
  {
    "startTime": "01:40:01",
    "text": "request that is received it contains all the data necessary to process the request as if it were received via rc 7644 the base scheme okay coordinated provisioning allows the receiver to know that a publisher's resource has changed what the type of change was and the attributes changed in this case a set does not contain any raw data except for the id and or the external id which already which are already shared between domains when a receiver gets an event it can mark its own resource as stale and take action for example after receiving an event the receiver can perform a skim get request from the publishing service provider to see the current resource representation and the receiver can then do a reconciliation of the change resource the reason for this two-step approach is that it avoids sharing of confidential information in scenarios that may involve out-of-band relays or otherwise more importantly if the domains care about different attributes a lot of data may simply not be necessary because replication is not the primary goal in coordinated provisioning mode the receiver only needs to act when an attribute it cares about has changed then when the receiver does perform a skim get to obtain the changed resource the server's normal access control can be used to filter attributes appropriately another advantage is that a receiver can wait to do reconciliation by simply marking a resource as stale and then update periodically either in minutes or hours in order to avoid repeated get requests for a rapidly changing resource such as a group we could have sent filtered data in the event for each feed subscriber kind of like a limited dvr but i believe this creates a number of problems one"
  },
  {
    "startTime": "01:42:01",
    "text": "more event processing is events have to be specialized for every receiver and also the publisher has to know what data the receiver is actually interested in it has to have more awareness of the receiving domain this may cause demarcation and control issues next slide please okay and here what he's showing is that a client performs a normal skim protocol request via post put patch whatever to a skim service provider the skim provider responds with a successor fail if successful the provider then issues an event to replication receivers who in turn repeats the operation locally to stay in sync in the slide i've shown only one replica but it may be many to hundreds okay in the next slide for coordinated provisioning a series of skim operations are completed at a skim provider and then for each request events are sent out to registered receivers depending on the event a receiver may issue a skin get back to the publisher for the purpose of reconciliation once the modified resource is obtained the receiver then decides what reconciliation action to take further because the event simply marks the resource has changed a receiver can opt to wait like a minute turning multiple changes into a single get reconciliation this two-step approach treats events as triggers to take a future action or to reconcile the differences between the providers next slide so security yeah security signal events have been talked about by the skim working group prior to the risk or the shared signals group formation in essence these are higher level events that draw"
  },
  {
    "startTime": "01:44:01",
    "text": "conclusions based on skim schema for example a password has changed or reset i should point out that these events in the draft as they are somewhat duplicative of the openid foundation shared signal risk events the reason i put them in the draft is that the identifiers used in skim events are the stable skim identifiers the ones used in the shared signals are somewhat more complex allowing different subject identifiers to be used i think we need to explore these events more thoroughly thoroughly to decide this skim should define its own signals or reference the external specifications like sse next slide because skim is actually a profile of http one of many http features are http respond async preferred requests as defined in rc 70 to 40. if we were to support this feature this would be one way skin providers could signal request completion event results this just seemed like a no greater no-brainer to include but i must confess i don't have a strong use case and i'm curious if anyone would have a use for this uh next slide okay so this one is just showing an overall flow of how we could do asynchronous events next slide please so uh this is to the meat of the draft the skim event profile defines a number of common claims jots use the term claims instead of attributes by the way of concern for skim are the following toe the time of event this is useful because as we consider how events are collected"
  },
  {
    "startTime": "01:46:00",
    "text": "and arranged into streams some time will pass toe allows set to convey the time the actual event occurred as the skim service provider which may be earlier than the set issuance time which he's calling iat yet toe is important because if events are received out of sequence the toke can be used to reorder events txn is a transaction identifier which must be unique for each event that occurs in the skim service this value may be used to catch duplicate event messages that might occur depending on the delivery mechanism event of course is a claim kind of like skim uris the events claim is a json structure carrying event uri attributes against which a json object can be attached in the skim event profile each event uri contains the transaction details of the event inside an event schema object we define four attributes for skim an id external id attributes and data id and external id are obvious attribute lists modified attributes when raw information is not to be shared whereas data is used to pass the raw skim request eg for replication finally in the current draft i'm recommending that the jot subclaim be the uri of the skim resource that changed in most cases this gives the receiver quick access to do a skim get to obtain more information in many cases the receiver need not parse any other information other than the event type uri next slide please okay subject identifiers before i show you what an event looks like i'd like to talk about the sec event subject identifiers draft that's the draft that the ssc work uses"
  },
  {
    "startTime": "01:48:02",
    "text": "by the way this draft defines many different types of identifiers that can be specified like email ip address telephone etc this draft was spawned out of the oidc world because of the way id tokens were used when an id token was issued the subject was not uniquely identified by the subplane it was always within the context of an iss claim and the subclaim together it turns out the iss claim was doing double duty it was both the issuer of the toker token and the issuer of this sub value this created problems for the openid clients that wanted to issue events they needed to be able to specify the originating issuer for the sub but the jot spec is defined as the issuer of the dot rather than the subject in order to do this the subject identifier spec came out this spec has been in process for about six years and has been difficult to obtain consensus that said they seem to be getting close and are still in last call in the case of skim i don't believe we have a subject identifier problem for a couple reasons skim clearly defines the id and external id mechanism for this purpose when resources are created there is already agreement on common identifiers two in a case where a skim client has forgotten an id the event provides a skim uri for the resource in the event and third the event receiver can finally perform a skin get to obtain any additional claim it needs to locate the corresponding local entity i recommend against using the skim subject identifier draft as this would open up skim receivers to having to process identifiers not typical of skin this optionality would decrease interoperability in order"
  },
  {
    "startTime": "01:50:01",
    "text": "to align with a problem domain with unresolved standard agreements on identifiers next slide so in this example this is a typical event in this case a create event is being shown note that inside the events object we define a common set of attributes you've got the id external id data and attributes typically in dbr cases we show the actual transaction using the data attribute this attribute corresponds to the original skim request when this event is done for coordinated provisioning the data is not provided and instead attributes is provided with a set of attributes issued note that the create event actually includes an id whereas the skim create request does not why well remember set is an event that has already happened so the skim create event shows the id that was actually assigned okay next slide in addition to repeating the skim crud events there are a few other events that are important the feed events are about a learning a receiver about a new entity that they may not be aware of this happens when the user population in one domain is a subset of another for example users provision to sfdc might be users in azure that may have the role crm when sally has the entitlement of crm added sfdc is alerted of that the sally resource is now part of the fiend sfdc may need to first obtain the sally resource in order to provision sally into crm since no sally create event will have to will have been previously observed by salesforce sfdc in addition to the skim create put patch"
  },
  {
    "startTime": "01:52:02",
    "text": "delete events i've also added activate and deactivate events because different service providers may have different meanings regarding regarding active and inactive etc a more generic event is defined so that publishers and receivers can better coordinate um on activation for now i've only defined two risk-like signals auth method change and password reset we should keep talking about how we want to approach these events these are different in that the audience of the event may not be a skim system client or provider finally as previously discussed the async response event is also included next slide in the event profile i've described a couple different delivery mechanisms in part because i felt it important to describe how events might be exchanged and how it might be managed looking at this i saw two road categories for delivery bus based systems and point point systems nancy me i've already spoken about the shared signals event framework and the set transfer specs but the other i wanted to point out was message buses many companies may have large investments and message buses in the skim case they're useful because you don't have to describe complex hierarchies of server interconnects that mandate master servers all barriers to global infrastructures and scale instead message buses become convenient for a number of reasons a bus can implement infinite event recovery if desired each skim server only connects to one bus rather than each other the bus takes care of delivery recovery and fault tolerance having each server connect to one bus rather than each other dramatically simplifies configuration credential management and the number of event transfers finally a bus can also act as an auditable record for changes in systems"
  },
  {
    "startTime": "01:54:01",
    "text": "still with all those benefits when we go cross-domain we want to control the flow through a limited set of connections or gateway in this case ssc becomes advantageous next slide so what's out of scope because events are statements of fact of what has occurred rather than commands the spec doesn't prescribe what a receiver must or should do other than the message itself the breakthrough of set is to avoid prescriptions and to focus on triggers or signals that enable independent action because there are many delivery systems the spec will only talk about the basic mechanisms and any privacy and security considerations that flow from those systems thanks okay i was slower than phil sorry we have five minutes before we're done we can take comments questions so tim tim capela microsoft and just uh disclosure i'm the chair of one of the chairs of the ssc working group um can you go back one side i think the the statement around commands i think is super important here right so when we look at sse and what it's doing it's it's a statement of fact that in the view of the transmitter right so my only concern here is to take a dependency on ssc in a protocol those are more commands than signals right your in my opinion at least the way i understand it right you are you are using this method to convey protocol operations versus observations by a single party if that makes sense so that's that's my only concern i i'm super happy to see sse getting visibility here um that's just my only concern right because that's been a super important distinction for sse at least as its kind of position say doesn't mean it can't change but all right uh leslie was on so"
  },
  {
    "startTime": "01:56:02",
    "text": "i guess i'll echo that and also say that that like the implementation complexity of this worries me a little bit um in like the way if i were starting from a white sheet of paper i would probably limit myself to just signaling that something has happened to a schema resource and let the receiver figure out what to do with that information whether it means re-synchronizing the schema resource or not sending along a lot of data with the the event adds a whole bunch of complexity around stuff like item potency and you know access control and the security model is affected there's there's so much complexity in this that i again i i worry about implementability i i would maybe like ask the working group to think about sort of whether this is actually needed or whether we can get away with a very very simple event-based model for synchronization you're saying that something has happened and let the skim client figure it out okay um so i'm just gonna echo phil here from the chat but i'm not sure tim it might have been to your comment uh of that's why i anticipate dbr happening over buses versus cooperative arrests yeah i guess i guess i i don't think you want two different skim is supposed to be very authoritative correct so i don't think you want two different pieces of skim for the operation of the protocol that one is do what you want and one is authoritative like that that's concerning to me right if you're ultimately yeah i don't know that again i can be easily convinced i'm just that was my first reaction should be a question of clarifying the applicability and use case yep okay um"
  },
  {
    "startTime": "01:58:00",
    "text": "did he have questions that i didn't okay so phil actually had questions that i i failed to go through so in the interest of time perhaps what we'll do is solicit more feedback over the mail list and then we can talk about applicability and adoption at a later point based on on the questions that phil has posted um okay we have a minute and a half left any other orders of business questions we actually stayed on time all right thank you um oh one last logistics does the group want to continue with the uh every four-week virtual for progress every six weeks i'm going to say every six weeks um let me put a poll do you want to continue with an every six-week virtual ver if i could only type that would be dangerous okay um can you raise your hand if if you want to continue with every six weeks we'll have a virtual how many participants do we have yeah no i was looking at this to see when we kind of have rough consensus so i i can put that on the mail list as well and we can try and schedule a virtual"
  },
  {
    "startTime": "02:00:01",
    "text": "for the next six weeks and then we'll evaluate after that all right with that i thank you for joining and participating and we are right on time thanks everyone [Applause] yeah it was funny because you kept telling me closer but then it's like because i was watching the chat and you're like there's a hey so i actually think doing maybe i need to read the it's the notion of hey you need to synchronize jesus christ now you sure"
  }
]
