[
  {
    "startTime": "00:03:42",
    "text": "take a seat excuse me may I have your attention please so excuse me good morning everybody so we are going to start our session over a week at IEP f-100 and welcome again so first of all so because after last ITF we so we have done some announcement mr. Robert Koch who has been serving this working group since is forming a stepping down as the working group chair co-chair and this is our new co-chair Mohit and do you want to say something thank you to Robert thank you - then thank you - Suresh for giving this opportunity still learning taking baby steps so please give feedback if I make some mistakes or in general any feedback thank you again thank you Mohit for taking this job and then I will go to the note well please be a well these if you are not yet and we need the minis takers who would like to L realistic okay thank you um thank you and yeah please use the ether pad and we already have one Java scrubbers thank you pass that thank you a lot and we already hand of the blue sheet along the two lines and please sign then thank you so this is a brief update of the working group the document status so after last idea we finished the IOT director 8vu and the internet area director review thank you for cherry and the police view and for the crypto document so we we finished the working room last card and we have finished IOT security and the Internet Directorate with you and because this is Marty what Marty area you know cause area work and we have the TCP port constraint network document and also the labor management policy document which is still in progress and we have we present today and I\u0027m also happy to see the update of the air week coop document although is not presented today but I really like the document and probably we "
  },
  {
    "startTime": "00:06:44",
    "text": "can seek for working class court after this meeting but first world so if you are interesting in the coop details please help to view this document I think there are a lot useful information in this document so here comes our agenda for today so we are basically have two three presentations first one is the TCP for constraint from colors the updater of document since last time and we actually have a lot some discussion on the many knees about details of document and because of the coop TCP standard also in progress in parallel I think more and more there will be more and more implementations of a co-op or a TCP and will report OC issues to the air week or co-op in the coming this and the second one is the one track from the was submitted to the call walking guru which is about security all head of the coab which also quite related to Eric so so we asked coach Jones who present to this working group as well and see how we can possess this document in future the last one is the labor management work document from Rahu and he will give a pre updated document and I already see some discussion on the 6th each working group or so on similar issues so any questions to the agenda yeah please hurry nice ideas okay it\u0027s cheaper which browser I use sorry yeah I know any other questions so I was switched to the first presentation yeah please okay good morning everyone my name is Carlos Gomez and I\u0027m going to present the last update of the draft and title TCP usage guidance in the Internet of Things so first of all let\u0027s take a look at the status of the document so the draft became a working group document after Brad so thanks to all for the support and the last revision of the "
  },
  {
    "startTime": "00:09:44",
    "text": "document is version - little one so in this last revision we intend to incorporate the feedback received in the in the room in Prak also there was a comprehensive review by Hanna\u0027s so we tried to address his comments as well things out for the review and also there have been many on list comments by Rahul jilted Abidjan another so we also intend to incorporate this feedback in the document so thanks a lot for the feedback provided and let\u0027s go through the updates in this lab revision so first of all we have a change in the title itself so the previous version of the draft was entitled TCP over-constrained node networks however the the new title is TCP usage guidance in the Internet of Things so first of all there was a comment by Hanna\u0027s that this document had escaped from his rather because of the lack of the term Internet of Things or IOT in the title so we agree that whoo I\u0027ll constrain node networks is a well defined term in RFC 72 28 it\u0027s true that the Internet of Things term will allow for a better visibility of the document and also we have added the term guidance in the title because it somewhat reflects better which is the purpose of the document so the next date is in the abstract so the old abstract was still following or according to the original approach of the document which more like trying to define a TCP profile for constrained devices however the new abstract is better line with the current approach of the document we explained that the the goal of the document is to offer guidance on techniques that may allow simplifying anticipate implemented and which other related trade-offs and the idea is to help embedded developers to with their decisions on what they can configure choose for their constraint ECP implementations so we have updates in the introduction section we have added that there are there exist optional tcp extensions which increase code size and RAM requirements however many of those are not really required for interoperability therefore it\u0027s possible to have some careful tuning which may allow to make the implementation more lightweight and also we have added in this section that TCP implementation following the guidance in this document is intended to be compatible with a TCP endpoint which would be combined with TCP standards although possibly with lower performance in some aspects then we have reorganized some of the the "
  },
  {
    "startTime": "00:12:46",
    "text": "early the first sections in the document so now we have section 3 entitled characteristics of constraint node networks relevant for TCP the the new structure for this section is as follows we have three that one which is networking link properties which corresponds to the former section two we have three the two usage scenarios which corresponds to former section 3 and we have 3.3 which is communication and traffic patterns which is a new subsection that has been added this time and we now explicitly indicate which are the traffic patterns that we consider in the document these patterns are unidirectional transfers request response transfers and bulk data transfers by the way there has been also a terminology change because previously in the previous version of the document we used a term like transactional type of traffic however that was somewhat ambiguous created some problems so now we are using these terms that can be seen on the slide which we believe are clearer finally we also stayed that even if possibly that the typical scenario will be that of a constrained device talking to an unconstrained device it\u0027s also possible to have constrained device to constrain device communication in this case using TCP then there have been other updates for example in photo 2 which is entitled maximum segment size they have been at least however at an editorial level so the content is basically the same however there has been some redundancy that has been removed so hopefully the text is now more efficient and clearer for the reader and section followed three focuses on window size now we have also added some details here because we already explained before that devices that support a TCP window which is larger than a single MSS window size may benefit from mechanisms such as fast retransmit and fast recovery however that requires a window size of at least five MSS and we have now provided details on which is the reason for that and also some numbers so assuming that the MSS is twelve hundred and twenty bytes the the window size of five MSS would correspond to six thousand and one hundred bytes then we have also added that bulk data transfers may also benefit from limited transmit which is a mechanism by which a receiver sorry the note that transmits the segment\u0027s is allowed to transmit new data segments upon receipt of duplicate acknowledgements and this allows to reduce overall transmission or transfer "
  },
  {
    "startTime": "00:15:47",
    "text": "latency and it also increases the probability that we can avoid RTO expression and trigger fast retransmit and fast recovery then we have also some updates in the section for that for which focuses on RTO estimation first of all in the previous version of the document we pointed to some trade off which appears there\u0027s some fundamental trade-off with the RTO algorithm and we basically pointed to some reference however now we explained which is this trade off more explicitly within the text itself and we basically explained that we can have an aggressive RTO which will potentially reduce transfer delays however at the cost of increasing the probability of incurring spurious time out and wasting and necessarily energy or bandwidth resources and on the other hand we can have the opposite behavior which is having a conservative RTO which will possibly reduce this unnecessary waste of resources however at the expense of a longer transfer delay then in this section we have also explained that the RTO algorithm can have some significant impact on performance especially when a single MSS window size is used and we now explained that there is an example on this which is the RTO algorithm called Coco which has been defined for coop over UDP taking into consideration the specifics of IOT scenarios and there\u0027s some empirical evidence that at least in some scenarios Coco outperforms some of the the RTO algorithms that have been designed for TCP however not specifically considering IOT characteristics therefore this is just one example that there\u0027s a margin for RT algorithm tuning then we have also made some updates in the delayed acknowledgement section so there\u0027s a problem when we have a single MSS window sender that transmits data to a receiver that\u0027s using delayed acknowledgments for example this receiver might be outside of the constraint node network outside of the scope and not under the control of the entity that manages the constraint devices and in this case the problem is well delayed acknowledgement is in place therefore the receiver will contribute some delay to the RTD typically up to 200 milliseconds but it could be even up to 500 milliseconds so we have added that there\u0027s a workaround for this problem this is called the split hack which is a technique used by the Micra implementation by which a sender may "
  },
  {
    "startTime": "00:18:47",
    "text": "split the data into two segments of smaller size and it is we transmit the first segment then immediately transmit the second one and by doing this we can really minimize the delay that would appear for the acknowledgement however the downside of this is of course we have the overhead of transmitting two packets so this is something that needs to be considered then we have also added some content to the security consideration section we now explain that best current practice for securing TCP such as using TLS also applies in constraint node networks and we also state that security considerations of the of the mechanisms being discussed in this document also apply okay then they have been also some updates in the annex which is the section that as you may recall tries to collect details on the characteristics of implementations of TCP for constrained devices and we have some updates in 7.1 which focuses on mic repeat we now explain that micro-p uses this split hack which is now described in the delay that knowledge means section in the body of the document and we have also some minor correction here because in microwave P the application is responsible for retransmissions however the previous worse version we said that the application must be able to reproduce the same packet however that\u0027s not correct what\u0027s correct is that the application must be able to reproduce the same user data and we have also added now for the first time content to the subsection on tiny OS so we explained that the application is responsible for buffering there\u0027s a send buffer available and tiny OS supports multiple MSS window size so still in the annex now we have added more content to this table and now as you can see we have basically added the details on the rightmost column which is the one about tiny OS however there are still many details which are missing basically those related with the code size the data size of the implementations so please don\u0027t hesitate to let us know if you are aware of any of the details missing here or even if you think we should try to include some additional TCP implementations for constrained devices go ahead so this is very useful in the table the code size is it just for the TCP part of that or the whole you IP implementation yeah that\u0027s a good question I think we need to have all check because some of the numbers may refer to the whole protocol stack some others for just TCP so you\u0027re definitely right that "
  },
  {
    "startTime": "00:21:49",
    "text": "we need to to make sure that this is clear and in the document and the stars are missing data or well that the stars mean data that we might ideally find however or we would like to to be able to provide this data however let\u0027s see if we are really able to do so I am dishonest thanks for the update it\u0027s really useful on this table one of the things I thought was missing or could you could potentially add more rows to this or more criteria because there now you have a couple of the implementation look very similar although in in practice they aren\u0027t for example if you add one that talks about the ability to set up multiple concurrent TCP connection that could be a distinguishing feature also the issue that you raised on an earlier slide on who is actually responsible for maintaining the buffers I think that could be a difference and also what I was puzzled about is from the description was that pretty much all the implementations claim that they are for 18 and 16 optimized for 18 and 16-bit microcontrollers and I was one of wondering by whether there\u0027s anything that is optimized for 32-bit architectures human eight and sixteen what did I say 18 and 16 ok 8 and 16 not 64-bit 64-bit IOT devices um yeah yeah otherwise I think it\u0027s it\u0027s really great thank you well thank you so much for the feedback so yeah I think these are very useful suggestions and we\u0027ll try to incorporate them in the table and make clear make make sure that it\u0027s in the description of the implementations also a Ravager who are we so one of the things that I feel is missing here is whether the stack supports socket interface on top of TCP for example for I know for sure that you IP doesn\u0027t support the standard bsd-style sockets that is a big consideration for any implementer yeah right so I think that should l WIP it\u0027s much easier for applications to to write on you know applications to be written on yeah thanks a lot the yeah so I agree that this is something useful and will also include it yeah Ora Caroline also things very useful work thanks for doing this and um few things maybe would be interesting one is also REM use of course it depends depends how many packets buffers you have etc but some let\u0027s say rough numbers on that or intuition would be very useful to understand like what kind of things can you actually do with TCP if you have a small amount of RAM and another thing what about TCP over very constrained "
  },
  {
    "startTime": "00:24:49",
    "text": "network very low bandwidth thinking like LP one scenario some cheek compression thing do you have any numbers on that are you planning to yeah that\u0027s a an interesting point I don\u0027t have at this moment experience with TCP over something like I\u0027ll be one however yeah I am aware of some proposals for coop like to better support timers and so on over LP one so I guess something equivalent might apply for TCP but I am not aware of any particular effort in this area so we might want to consider this maybe at some theoretical level or something like that okay and then also I mean there\u0027s no one TCP but the very variety of different offices but also very different algorithms you can use it there\u0027s having some more recent one that may be more suitable for that current networks exploring what\u0027s the impact and when can you even run TCP because the classic other you start to break when you have very low bandwidth all wrong are titties and what algorithms would you use and what doesn\u0027t use what what doesn\u0027t work when it would be very interesting okay yeah thank you so this is Michael speaking in general TCP should work well or whatever constraints you have even for pretty low bandwidth simply because the mechanism was designed in a time where you had 10 kilobits per second or less been pressed so there there yeah there are a lot of things where TCP would work for sure I mean you can pay can be cases really for example you really run into time also think like this and then you need to chew in certain parameters so that\u0027s for sure clear we can possibly document it but by and large as I did least be interested in better understandings of what the issues are because in general they all the TCP algorithms are adaptive so they should at that ok thanks and yeah I was really thinking about let\u0027s say less than a kilo bit per second kinda networks good could be let\u0027s say for X on your at the edge of your envi IOT cell you are going very low on your bandwidth still have a reasonable n to you but it\u0027s just gonna it\u0027s gonna take some time um goes there you get a lot of retransmissions etc so how does TCB behave in this kind of environment as I said I mean keep in mind when TCP was developed that was the typical network did you hatch solution and so there\u0027s a couple of answers like so if you put everything into the LP run bucket like there\u0027s like a quite a bit of variance in LP ions and some of these links I don\u0027t think we\u0027ll ever have TCP right like so there\u0027s like stuff with like twelve by time to use that\u0027s probably not gonna run TCP okay and so I think like if we can investigate it but unless "
  },
  {
    "startTime": "00:27:52",
    "text": "there\u0027s like some kind of amazing compression stuff that we can invent like in the near future like I don\u0027t think it\u0027s gonna happen so III take our ease point but there\u0027s like a subset of LP on technologies where this can run and the subset very it won\u0027t for sure I would like to add that any adaptive technology does have a range in which it works and as sort of said probably not necessarily down to six million bits per second what the speed of sick folks in certain cases is so it actually would be interesting to see what is the adaptive range that that we can cover um did you did you check what TCP stacks are used for example by free autos and metrium okay sorry used by did you did you have a look at what medium or free are those uses for India sort of like SNS TCP stack because that would be interesting to know maybe they already have one of those listed up there but maybe they have something is like covering one of the some of the big IOT OSS would be uses or I don\u0027t know what surfer uses for that matter so that would also be so for example in with Kyle the lightweight that\u0027d be the original it--but IP is used and I think the same is true for the embed OS but yeah so that may be a way to find out whether the table actually covers a wide range of existing operate the operating systems yeah thanks a lot so I didn\u0027t check so but it just came to my mind and when you had this light on a tiny ways out there yeah so we\u0027ll check it and consider it as well one one last comment I think one issue that could potentially still be useful to add in the introduction section is to talk a little bit about where this perception about the DCP heaviness comes from because you you present you talk a lot about the different options and clearly they\u0027re the ones that you talk about they add to the bare minimum but then of course there the there\u0027s a trade-off between you add code and RAM size but then there\u0027s also the better performance on the other hand but if you just stick with the bare minimum I think it would be nice to say like that\u0027s what you what "
  },
  {
    "startTime": "00:30:53",
    "text": "you really buy you buy yourself into the table provides some of those answers maybe double check the numbers I think they are correct on the code size data size is not really I think you meant RAM size here but I believe the the numbers here are correct of course they\u0027re not complete but I think that\u0027s good yes yeah I agree we we may provide some more insight on this in fact there has always been this criticism against TCP and in reality many of the of the arguments against TCP are not valid or somewhat are issues that can also be found in other reliable protocols so I agree with that and yeah we we will try to make it clearer okay which aspects are going to increase complexity so what is contributing to that that\u0027s right a little bit like moose busting because for example I read the recent article about why Els is so happy or DTLS is so heavy on IOT devices and they also claimed you have to support all the 100 cipher suites if you need support hundred cipher suites then it will be very heavy yeah but nobody says you have to like it was a complete misconception about the way how it works but the other things that indeed contribute to the size so I think it would be very similar it could be very similar here I think it would be informative for the reader for the audience yeah I just want a second that thought you know of putting the design rationale in the document explaining the trade-offs for the implementers if they are going to implement a TCP on top of two devices because some like I mentioned before socket interface not having a bsd-style socket interface is a good is not a good thing but it reduces Ram but you know it has other implication so yeah I would second that thank you yeah thank you like a Samoan harness what you said is of course true but there\u0027s a flip side to that which is when somebody says support TCP people think oh this is going to be a second able aggressive cubic congestion controlled whatever thing and if all the advantages of that but when we say support ECP we mean something very different and that\u0027s obviously true of TLS as well one of the advantages of TLS is that it can interoperate in a number of situations but when you cut down the support for options like surface feeds then you also cut down those situations so that benefit that you actually get from using standardized protocol is reduced it\u0027s not going away but it\u0027s reduced so I think it\u0027s really "
  },
  {
    "startTime": "00:33:55",
    "text": "important to keep in mind what we mean by saying support is a peer support unit yeah so well before there\u0027s one last detail about the references section which now has been little bit reorganized with a better distinction and what is normative what are informative references and then we\u0027ve started to consider potential change for the upcoming next version which will be 0 - and there\u0027s some ideas about possible reorganization of section 4 contents section 4 is the one that actually provides the guidance of tcp over these scenarios and at least we have identified that maybe we might need to change the order of some subsections for example the one about delayed acknowledgments is possibly more relevant in the end then the EC and one so possibly should appear earlier in the section and we are also considering although this is not well developed yet other approaches on how to structure the kind of guidance such as maybe guidance for single MSS situations guidance for multiple MSS window size and so on so well these are just some early ideas on possible changes for the next version so that\u0027s all from my side I don\u0027t know there may be any further comments thank you thank you and for I see a lot of valuable discussion during the presentation I think probably rahu can contribute some text or handy if you like to the point you just raised thank you so I\u0027m John Watson from Ericsson this draft was has been committed to core as an input to the birth there has never really be in presenter they\u0027re just maybe seeing a slide in some other presentation okay yeah that better yes yeah can hold it yeah that\u0027s probably best good yeah so this is an analyst and analysis of the overhead of different security protocols used to protect co-op and analyze protocols are DTLS one or two GLS 103 TLS Oh score and then DTLS and TLS are "
  },
  {
    "startTime": "00:36:55",
    "text": "analyzed with and without compression and two different compression algorithm the diced generic header compression and and also another suggestion from Raza that was never standardized included for comparison and then DTLS is analyzed with and without connection ID and also how compression works when you include connection ID connection ID is a recent quite new draft for DTLS and what\u0027s analyzed here is the till snd TLS record layer TLS handshake is not analyzed and here is the major overview table we\u0027ll go through all the pouch here as you can see DTLS one or two as you probably know as 29 and the analyzed Sipho suit here is a SCCM eight honest i\u0027m i\u0027m curious on why you specifically focus on the sequence number aspect like just to give an overview it obviously they decompressed over here depends on the sequence number TLS and details uncompressed does not it to give a good picture of how the compressed then it\u0027s heavily dependent on the sequence number of course I\u0027ve yeah I would have started to slide by saying like here different algorithms and the size of the the header obviously depends on the algorithms rather than focusing on the on a sequence number or there is a single algorithm this am eight I think that\u0027s what basically people are using so basically if you choose a column here you get good comparable numbers for overhead for death algorithm so yeah and here\u0027s an overview of how why TLS and DTLS 1.3 gives less overhead uncompressed here is their TLS 1.2 header gives 21 bytes overhead when you have 8 byte Mac D TLS 1.2 that epoch and sequence number and additional 8 bytes but did not remove anything because the norms is needed for for example CBC surfaces DTLS mando tree as it only uses "
  },
  {
    "startTime": "00:39:56",
    "text": "a alias will move the norms again and we only have a poking sequence number and there was active there are so two types of content types or as there had a type Cindy TLS did you look at that this one why is that in a subsequent slide I these are only header type okay version definitely okay because there\u0027s a new in the latest this of the DTLS document as a optimized header format which removes version and content type and compromises the compresses the epoch and the sequence number okay that I am not looked at means that I will have but that\u0027s a very good comment I will add that to the next version of the documents that\u0027s heavily relevant added so yeah as you can see DTLS 102 has quite large overhead chile\u0027s and DTLS wanna tree has significantly less but not really small but the good news is that compression works quite well and then you get significantly lower numbers so what you get first we have this this is a stateful compression algorithm is a little bit more better compression than the generic header compression but on the other hand it\u0027s has state is also not generic it does now Ross updated it for ETL s103 but it doesn\u0027t work for TLS for example it doesn\u0027t work for connection ID so we\u0027ll focus more on the generic header compression and typically value for and these are somewhat dependents on different parameters here the parameters are shoes to give representative values for sequence number of one byte for example if you take one the number one you get significantly less which is not representative but this is close to the very close to the average can confirm that Dirac header compression works very very well for DTLS 103 you get even less overhead just 14 and the reason main reason is that TTLs 103 uses to say version number s DTLS - and basically the dictionary in generic had the compression a sturdy TLS header for a handshake on vacation you know kettle compression also works it works quite well for TLS but as you can "
  },
  {
    "startTime": "00:42:56",
    "text": "see you get to your four extra bytes and the reason here is that it\u0027s dictionary in HD as a DTLS includes the Detailers version number and so on you could probably get there\u0027s no theoretical reason why you would get so add another dictionary to year G would probably squeeze it down to this you could probably come up with a dictionary that does both but yes Carson yeah we had a lot of false ID when we did this because we put the TLS 1.2 version number in there and that\u0027s now eternal so TLS 1.3 has the TLS 1.2 version number and no it does okay order the deal the TLS working group has taken the generic error compression into account now that was actually not the reason these are the numbers you get I use some there\u0027s an implementation of the inner carry contracts on github from prior University of Berlin which are used for this CNN see if I have some more things now then Oh score new security protocol currently will is in working group last call in core has built in from the beginning very compact format gives compared even smaller than TLS DTLS NGLs compressed and responses or similar size they don\u0027t depend on the news number can you explain why that is yes that is because Oscar reuses features in it relies on co-op so co-op matches the request and the response based on the token and then Oh score uses sequence number it finds the context based on the token instead of sending them in band as DJ LS and TLS us and then also Oscar uses goosy goosy we inclusive uses see bore and see bore encodes numbers dynamically with a small length and value so you don\u0027t have this fixed six or eight byte sequence numbers which mmm without compression takes a lot of his base which of course it\u0027s it\u0027s a little slower like here "
  },
  {
    "startTime": "00:45:57",
    "text": "Oscar seems good for traffic analysis because you you can church from a response that it\u0027s a response like from the size of the response that it\u0027s a response you can probably see that from the direction you\u0027re sending the packages well don\u0027t say that because you can you can send it in both directions so here\u0027s thinking running out to turn here\u0027s an example of the Oh score header not going into that and then I also tested pls compression with connection ID as TLS game much more I was afraid that ESC would not work optimally with connection idea what I can happily report that it does basically the compressed overhead the only increases with it so connection ID includes in you there it includes a new field in the DTLS header and i did some tests and it seems like it always the compressed overhead always just increased with the language of this connection ID which is optimal yeah yeah a cousin again I\u0027m not sure whether that was meant as a joke serious thing but I think we cross that line I think we actually have to take this as a serious comment and look at what the the impact of compression is on on visibility of information so of course when you compress parts that are in the clear first of all it looks like it doesn\u0027t make a difference but if there is a lower layer compression below that lower layer encryption below that then then this means you still might see something through that encryption that you are not supposed to see so that that\u0027s maybe actually worth a little bit of attention yeah that\u0027s definitely worth attention shown that orgy compression of variable bit codecs you can basically find out what people are saying with like 70 percent of the birds so that\u0027s you know has been some padding features added to TLS 1.3 to make traffic analysis more difficult so that\u0027s what I have to say and this is currently in core would be happy to translate for l we if there is any interest Thanks like maybe maybe you should change the title of the document because it makes like it gives the the feeling that security adds a lot of "
  },
  {
    "startTime": "00:48:58",
    "text": "overhead like oh what\u0027s the best way to get rid of that overhead okay I have some ideas yeah good point the absence you said yes you know I don\u0027t know but you know I can I can just I can already see some articles that say all its all the security is just yes yeah comparison yeah comparison of person yeah yeah that\u0027s good you know I don\u0027t want this definitely want to say that Ali I suggest no honey yeah it seems there is interest in the group for this work yeah Carolyn yes I think these kind of things are very useful outputs of this group I mean like having a numbers actual numbers you can point to in lot of discuss and so what is the impact of doing X on this kind of IOT scenarios so I think it\u0027s very useful work and I\u0027m glad to have finally a reference with comparison of the numbers cuz these got questions you get asked a lot okay if I wanna run TLS detail as something else what\u0027s the impact not overhead impact Thanks okay so the next step for the authors is to submit as al Vig document yeah so maybe one comment on exposition that it\u0027s related to calling this stuff overhead I mean there is some useful information in there it\u0027s not all overhead and I think the numbers would be easier to understand if you would separate the information that essentially cannot be compressed such as the authentication tag from the other information so I mean you need to send those eight bytes there there is no no wait way around it unless you use a different cipher suite so I think it would it\u0027s not right to say there is a protocol overhead of 13 bytes that particular overhead is much smaller but then there is also a security cost and that\u0027s those eight bytes yeah now if you stay exact the I just copy pasted from 7400 there\u0027s a good point Oracle and also the handshake was not analyzed in this document right now that\u0027s not included there are some work on compressing TLS and ad hoc in ace working group I knew that Jim shod has done some analysis but that\u0027s not public at the moment and I have not been okay so maybe I mean maybe having a pointer to whenever that document becomes public in this document would be useful so getting the full picture cause use of the handshake is "
  },
  {
    "startTime": "00:51:58",
    "text": "the dominating factor I think just having numbers of how large Sheila\u0027s pack I don\u0027t think there is any easy to find numbers on just what\u0027s how large or the TLS packages in normally in the handshake or what can I do to slim it down um well one problematic thing is that you included this sort of work by AUSA it is it\u0027s great work but but it didn\u0027t go anywhere so it may lead to the wrong conclusion that it\u0027s it may actually be available somewhere but I think it was it was not just proposed but then it was not picked up and was not continued yes um the other thing on the handshake the handshake comparison are more complicated because here you are comparing efforts against apples because different you you want to accomplish the same thing they had some differences as you pointed out and I\u0027m not sure I do sign the drafts we\u0027ve and also that the remark that are consummate is quite important because most of the overhead is actually caused by the security algorithm itself but the handshake challenge day is you quickly compare Epis against orange juice because if you have different properties and different design goals then what does that actually mean as we have seen in some of the discussions you want to have certain backwards compatibility with existing middle boxes if some new work the the middle boxes are not yet there but maybe in in not soon distant future and so it\u0027s really a trick so in the interest of time can we be concise we have one more presentation and I don\u0027t want you to keep me here for lunch okay then quick comment on should we have a document documenting these trade-offs with different kind of handshakes different other algorithms you know it will be published in some other group I I\u0027m not planning to add it to this document at the moment but I think it\u0027s useful I think it will come out of ace in some form yeah okay all right hello hello everyone I\u0027m Rahul Jadhav and I\u0027m presenting the 6lowpan neighbor management policy it\u0027s specifically applicable for multi-hop networks on it not Tudor 15.4 networks in last IETF after last iet of this work was adapted and well renamed the renaming the document we also made some changes to the text but essentially we we stripped out some text which was which was some detailed explanation so we thought it might not be necessary but there were no technical changes as such "
  },
  {
    "startTime": "00:54:58",
    "text": "to the document so before going into the details of the updates here I need to I wanted to give this background about you know how constrained operating systems are getting developed most of the times the consideration is given to reducing the number of packet buffers while designing a constraint operating system for example let me take an example of quantity where you have a single send and receive buffer to reduce the amount of memory size what I am trying to say here is there are other other things which are occupying more memory and has be also a bigger impact especially in multi-hop 6lowpan networks and which has to be dealt with when you give design consideration for such implementations you know so if you if you see here an example of routing table well routing table does not come into picture for a non storing mode of operation but still the is one of the bigger compare one of the biggest component so till the moment you are trying to work out with likes more smaller networks like 10 20 or 50 hundred there\u0027s no problem but the moment you go into sub key guards were there and with large number of net nodes in the network the density increases and you need to have a bigger neighbor table and if you see the neighbor table size can actually reach something if this is this is what it has reached in our implementation so it has reached almost six and a half KB while the packet buffer is like one we have a packet buffer which is which is used for both send and receive it\u0027s only one zero one two eight zero bytes so why neighbor management I just want to go into the details of this so if the network density increases especially in case of multi hop networks you have lot of neighbor cache entries getting filled up because of the routing routing child\u0027s routing parents because of the authentication sessions and how do you manage these entries so well if you don\u0027t if you\u0027re not able to manage these sessions this interest properly you\u0027ll end up losing routing adjacencies eventually increasing the routing convergence time and the network will simply keep flip-flopping between the paths and there would be a lot of overhead added the the control overhead in the overall network will be very high so this is where so currently if you see then most of the implementations are the they use trivial policies are you and ofc FS which are not optimized so here is a sample so this shows the kind of network density in some cases that network is really dense in some cases it is sparse so here if you see this particular node is taking all the load but it might be limited with the space and then eventually all the node might flip-flop to another another parent node and you essentially want to get a network which is sort of balanced wherever the memory is available the network should switch to that place so with the specification or the the "
  },
  {
    "startTime": "00:57:58",
    "text": "current draft takes into consideration the authentication session as well which is very important because authentication of sessions also occupy neighbor cache entries so there\u0027s so these are the cases where the neighbor cash interest so these are the cases where the neighbor cash entries will be filled so it\u0027s a routing parent routing child authentication in progress and there might be some other sessions also which might be needed so there is an others session section that has to be a that might also show up here so we have some signaling repeated recommendations for neighbor cash management well we don\u0027t provide any new changes to the protocol so the in case of non storing mode of operation in case of storing mode of operation do you really need to send an S do you really need to send an S with aro option or with the recent update to 675 do you really need to send er option so these are all the things that have been discussed as part of signaling recommendations in this document the proposed policy is that we have reservation based scheme so we have so the basic principles on which this draft works is if at all there is an eviction how much is the how big is the impact so based on the impact of eviction the categorization is done by I\u0027ll give an example here if there is an eviction offer outing child in the parent then all the subsequent child\u0027s grandchild\u0027s are also there\u0027s an impact to those nodes as well so that\u0027s a big consideration there the insertion reason needs to be kept along with the along with the neighbor cash entry this reason will help eventually to decide the lifetime of the neighbor cash entry for example in case of pre authenticate or in case of authentication sessions where the authentication is still in progress to avoid dos attacks you might want to keep we want to reduce the amount of life time that is for this neighbor cache entry so these are some of the so this is the basically the proposed policy so whatever I\u0027ve just discussed and whatever is been talked about in the draft is reactive we want to go to a prac there are some problems with the reactive policy the product the primary problem is if let\u0027s say for example you advertise some information the the child loads joins a parent node but after some time and it sees that the parent node doesn\u0027t have enough resources to join but after some and it switches to another parent but after some time the same parent sends a new di oh and then it switches back to the same old parent and that does a failure signaling again and then we go it against gives the status saying that it is not the resources is not enough and then switch backs so there\u0027s lot of flip-flopping happening happening there which we want to avoid but we don\u0027t see any other way other than to change something in the routing protocol for this there is some proposition already in the working group role "
  },
  {
    "startTime": "01:00:58",
    "text": "working group in context to this but right now I don\u0027t I don\u0027t know if it sorts of takes into consideration this this particular factor yeah please watch through the air sorry alright okay I just have one more slide I guess okay we already have a proprietary implementation in place Quantic implementation is in progress quantity lead authors are part of this work and we intend to I mean the current draft already whatever the current draft says it\u0027s already implemented we our proprietary implementation takes into consideration even the proactive part that I just mentioned but it\u0027s not part of the draft so we that is something we would want to work upon that\u0027s all from my side and really I would appreciate some feedback from some reviews from the working group towards this problem statement thank you that\u0027s all from I said equations so we are running out the time in questions okay so we head over to the raised central role thank you the meeting Joan nobody wants to tease perfect you "
  }
]