[
  {
    "startTime": "00:00:01",
    "text": "Neil? Awesome. Thank you. The link is in the agenda. For the notes thing, both our agenda and the IETF. And and and again, just the high points and especially the the decisions made would be very helpful. Or discussion. I can see how Okay. Let's go. Alright. group. Let's get started. This is the HTTP working This is the note well on the screen. Fairly fuzzy, but hopefully you're familiar with it by now. These are the terms under which we participate in the IETF. Regarding everything from intellectual property, which is very important for some reasons. Also, competition law, which is also important for other reasons. And your behavior, which is very important. And we we do take all of those things seriously. So if you're not familiar with this please do, take a look. The best thing to do is to go to your favorite internet search engine or No. Not LLM. Just search engine and and ask for IETF note well. And and that will give you this information. I'm now know what I'm doing after this session. Our agenda today we have 2 sessions. Today, we have 1 hour. And then on Friday, we have 2 hours. So today, we have what we're doing now, which is, scribe selection. Thank you very much, Neil. We just did the note well. Blue sheets don't exist anymore, but you do need scan that QR code over there. That we know that you are participating. That's actually how you raise your hand, virtually using the tool that you will get from following that QR code. That you can go and speak the microphone. It's a little more complex, but it's more equitable and reliable. So there you go. Our agenda for today, we're talking about 4 different things for we'll an update on the cookies. Draft effort."
  },
  {
    "startTime": "00:02:03",
    "text": "We then have, unprompted authenticate from David Skinazi note I'm still not using the name that you used for that draft and maybe we'll talk about that. We'll talk for just very briefly about the query method and then we'll finish with talking about resumable uploads. Do we have any agenda bashing? Any changes to that? Yeah. Yeah. That There should be a pink box. Is it an x? Okay. So I should be on the Yeah. don't know. Oh, be on the end. Yeah. Oh, no. Don't. Oh, I We can meet and meet No. Fine. Yeah. Okay. She'll be right. So let's go ahead and get started with cookies. Can you take over and or should I? We don't have slides. Oh, we don't. That's right. We were gonna do this from the issues. Thank you. Something a little bit more free form. That's right. It's good. And select I just need to the Yeah. So you wanna 6 265 this and then minus defer. Because there are quite a few diffused furnishes. Indeed. Gonna try and make this Let me this up one more time. Maybe if I make it bigger, it'll be high resolution. Let's find out. get Hi, everyone. My name is Steven Bingler. I'm one of the, Google. I'm one of the editors on the cookie spec. Which, at lunch today, I was looking up, the first draft of the spec was published October of 2016. So we are coming up on its 8th birthday in October. Almost. This. So hoping to get it published before it turns 8, but, you know, we'll see what happens. So anyone who was paying attention these last couple of times noticed that the cookie spec had sort stalled for a while, because of one particular issue, which term the same site redirect chain. Click, rehash on that frame when he's unfamiliar. Was a bug on the initial same site"
  },
  {
    "startTime": "00:04:05",
    "text": "Same site specification where if you redirected site A to site B and then back to site A, we didn't we never considered that little middle jump to site b and we'd say, okay. That entire request was same site. Well, that's not same site. So, I wanted to So we went back and fixed the bug. Pro implemented it. Firefox implemented it. We both turned it on. And chrome at least started receiving bug reports within a couple days. And we have to turn it back off. Firefox also to turn off because it's just breaking sight. So the spec stalled for a little bit as I was looking into how we can sort of mitigate this while still keeping the security protections. As you can see, the issue is no longer up there, and my solution was reverting the language so we no longer consider the same site redirect chain. That's not great. But in the interest of getting the spec moving and getting the other positive changes out there. I think it was probably worthwhile. And the reintegrating the same site redirect chain is already planned for our our RFC 6265 bispecifics, Sure. So that was the last major remaining major issue. There were a number of smaller issues that were I would I either resolved or deferred until next time, I know that there's a lot of deferred issues, but like I said, this business is coming So the remaining issues are up. fairly, fairly small. There's a summary of changes from the original 6 265, which I haven't started yet, but we'll get on pretty soon. And then, recently, IANA emailed us and let us know that our INA section was out of date, so that needs to be updated But but We Once those are closed, I'm going to, I think we're probably ready for, working group last call. I don't know what the chairs think. I mean, I'd be willing to start it even"
  },
  {
    "startTime": "00:06:01",
    "text": "you sooner than that if if If publish a a a draft, yeah. if you wanna with a current set of Ethermite, with a current set of changes in it, and then, you know, this is roughly editorial work, I think, because I I my My inclination on this would be because it's been out there for so long. And because it is such a complex and important specification, working group last call should be a substantial one. Oh, on the order of well, it I'd say at least 4 weeks. I'd say. Yeah. Yeah. I was wondering, do you just say, like, a year? Well, on on the big scheme of things, it's, you know, Okay. Yeah. Great. Great. That sounds good to me. Alright. Sue, It's from not forgetting anything here. No. That's it for the cookies back. Any questions? Anything can't. on the I need you to watch the queue because I Oh, it'll it'll be okay. Okay. So and and you mentioned that this, this, to our next steps, whatever that's we're gonna call about that. I this has been talked about in the community for a little while now. Anna, I think it was Anna Van Kestrin, was talking about, relaying the cookie spec. And I think that's the next discussion for the community. Whether that happens, you know, if if that all happens here in the working group, or whether there are other venues that it might be good to coordinate with that's all TBD, but, we were talking, I know, on on the side about the possibility of, you know, keeping this specification more of a a heartbeat where it's continually evolving. Yeah. I, I agree with that. There's There's a lot in the future plan for cookies. So having more regular smaller and more regular updates is probably a good decision. Yeah. And and hopefully, less painful in getting those iterations out. We would have Yeah. Yeah. Great. Any discussion? other"
  },
  {
    "startTime": "00:08:00",
    "text": "Fantastic. Thank you. Alright. Thanks all. Great progress. I'm I'm very happy to see that. Next up, David on prompted authentication. Wanna share your thoughts on me? Can you do it? 20 to Okay. Okay. Homes. All the slots. For me. Alright. Hi, everyone. I'm David and I'm here to talk about signature the HTTP signature authentication scheme, formally known as unprompted authentication. I'm away, Kasuire. Alright. Next slide. So, If this is news to anyone very quick summary, So The idea here is that we want the client to authenticate to the server using a keys, and we want the server to be able to hide the fact that it serves these authenticated resources. So the way we designed this, we used a TLS key exporter. Adopted this a while back, had some churn figured some things out and pretty much kinda Got decisions to, for, outcomes on all the, open issues back in Prague. Next slide. So since then, we decided the spec had finally stabilized, we decided to, interrupt So, the folks over at the Guardian Project did really cool work, built 2 implementations, one in Java, the client in the server. And one That's a, plugin for NGINX. And then"
  },
  {
    "startTime": "00:10:02",
    "text": "Francois Michel, who's, the author of s h 3, wrote 1 and go. And, I built 1, use in Google's quiche, C plus plus. And then we tried to interrupt and it worked. The only ones that didn't work was that Java, the the job implementation only supports be 1 and 2. And mine only supports HTTP 3, and we haven't figured out how to make those interoperate yet. If we put that one as an intermediary, we might be able to do it. So so that was great. Like implementation, No, like, serious issues were found in the spec. Quite a few editorial things to clarify and, improve, said, were found. And also we have a security this in Temoran from Jonathan Holland. Yeah. So we're we're in good shape. Next slide, please. But, of course, I was here, okay. We're done. And then people got excited. Oh, we have a question. Habin. Yeah. Do you hear me? Yes. Okay. Perfect. So someone from to you, Justin, so I can you see a bit more about the formal analysis like what exactly was the model? What were the kind of main features that you modeled and what was the kind of property that you verified just to get some intuition about what exactly is verified here. Jonathan, can you take that one as he looks surprised? All the Wow. I feel like this is more of a question to ask at Yohan Margie. Sorry. Not Plunk my own boss. boss. Research group. It's a thing. Yeah. So basically, I just proved the authentication properties because this doesn't really have any other properties. And, I was proving how it binds to TLS."
  },
  {
    "startTime": "00:12:03",
    "text": "The model assumes that TLS is secure. And doesn't try and reprove TLS because have better things to do with my time. So, yeah, it just says, assuming TLS is secure, does this provide correct auth or strong auth if you're looking at the low hierarchy of authentication. So maybe I can refresh my I mean, if you assume DLS to be already correct, what was the need for the former wave in the first place. So so what triggered this formal analysis Can you see a few So HTTP auth is different from TLS. HTTP auth set so TLS the client authenticates potentially with a certificate. But this doesn't have to be the same certificate. Right? You could have a completely different identity at the HTTP layer if you so felt. If you so chose if you so chose So this would be a Can I have a second identity and prove that the second identity and the first identity are controlled by the same actor? Okay. Right. Thanks. And is the report available? It's is it in the report already? Can is it can you point a link in the chat? Maybe can put the link in the chat. Alright. Thanks. Awesome. So, one thing we noticed when we first built this, the initial two use cases we had didn't, didn't care about intermediaries, but this is HTTP. We all care about intermediaries. So what we said is here's how you would build this live intermediaries. You would wanna Take the key exporter for the intermediary and send it to the upstream HTTP server. But how you do that, we just left it as an exercise to the reader. Have 2 implementers who are actually interested in building that part. So we said, well, then maybe let's just define a header that says"
  },
  {
    "startTime": "00:14:01",
    "text": "Hey. Here's how you send the exporter. It's dirt simple. It uses structured fields because we all love structured fields. And that's kind of all there is to it. I have a PR. The PR needs a bit more editorial work to really like tighten up all the things, but it's just that idea. I figured it made sense to do this since there was interest. Is I just wanted to run it by the group in case someone was would object to the idea of defining header for this. There's, of course, a bunch of must, so, like, you obviously accept this unless it's coming from a trusted intermediary and all that because, like, he was the properties, otherwise. It it's very similar to the client cert. That's what we had earlier than exactly. No. Did someone just boo? Oh, oh, yeah. I I I gotcha. Yeah. Yeah. I gotcha. Okay. So disagree that it's similar to clients, sir. Because, in the client cert draft, You're sending the certificate itself and telling the origin that, yes, I verified this client legitimate this held by the client. In this case, I think you're taking The thing that the The server as far as the client is concerned. That the server knows and is secret and nobody else is supposed to know. And sharing it with somebody else so that they can do the application that the intermediary Would have done has done whichever We're without going into the detail of how we compare to something else. I'm No? I'm a little cautious about exporting that if that's the case. Dun, does this give you the information you would need to then falsify it over? If it were luke direct, No. Okay. No. No. It really doesn't because"
  },
  {
    "startTime": "00:16:02",
    "text": "It's just the exporter. Okay. And you still need the signature off of part of the exporter. You know, And, Well, so just to be clear, if the interpreter was compromised, they could replay things, but you're with all those things, you're assuming that the origin trust the, or, sorry, that back and back and trust the intermediary. And with that, it cannot like, the you can't reuse it on Thanks. Yeah. If the origin trusts the intermediary, they could just tell you what but everything's proof, though. Yes. And the request was that people don't keep the database of public keys and users on Martin. Yeah. This gives me the Squeebleys too. So you've got the intermediary presumably? No. No. So the client, why why can't I do that? They don't have the public at all. That's right. Mhmm. Because otherwise, all you need to do do the entire protocol between the client and the determined area and the intermediate turns around and says, yeah, I still don't like it. For all the reasons that the client cert thing was awkward. This one essentially removes the purely informationary informational nature of that signal, which was validate is a certificate. And here's the certificate that I validated. That's one thing. This is please validate this but you've got no means of knowing that this bite sequence is Just like you don't have any means of knowing that this hasn't been transplanted from somewhere else. certificate it's sending wasn't transplanted for something else. Exactly. You're just making my point for me. Well, 8 Yeah. That's kind of the property of something like this is that the intermediary has the TLS private keys for the domain, like, you you're trusting it to to to some extent. Can you do mask?"
  },
  {
    "startTime": "00:18:03",
    "text": "It's Jonathan. So to directly address both those points, the security assumption here is that the exporter contacts would sorry. The exporter Key. Which has a context string injected into it. Is a channel binding, And therefore, you can publish this completely without damaging any security. And and and The one thing I I think I pointed out to Dave is that If that if your TLS connection between the clients in the intermediary is broken Your toast, But, like, at that point, you have we, bigger issues, your TLS private keys have been leaked. Like, So, like, I think of that's this is a property of any system where you want the back end to be able to To determine the authentication, with something that it happens between the client and the intermediary. So true of client certs. That's true of this. And the only way you can possibly do that is by the intermediary. I think I think you can probably prove this property. Unless you do a 3 part thing, which no. Yeah. Yeah. the Yeah. Yeah. Join and between the client, the intermediary last group Like, this, this is just a practical solution to this, honestly. Like, it's, Yeah. It's there, but, like, if you don't trust your intermediary, don't do Anything with an intermediate area. You know, it sounds like you're saying. Yeah. Okay. Alright. I was next speaking personally. I I Personally intend to agree with you. And and what I'm concerned more here is, just just just just just just things like injection attacks of of, you know, traffic being forwarded and the header not being properly cleansed so that someone else can, you know, can"
  },
  {
    "startTime": "00:20:03",
    "text": "claim control of it. In theory, that simple and in practice operationally, that's sometimes very gopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcgopcbccgopcgopcgopcbccgopcgopcgopcgopcg Yeah. Yeah. So, And, Tommy, Alright. And then my comment, which I kept going. Further back in line because it is taking us in a different direction. So up. I I have some foresight that we have some bike sheds coming And, what's about They don't even know about gaming. And so I just you know, when we're talking about a new header here, them, them, them, this particular header that you're proposing Does seem somewhat generic, like, is to what degree is this header bound to your off scheme name I so the next slide will discuss renaming the auth scheme. And if we rename will rename this too. Absolutely. that, we Just just just just just a quick question. You you struck out header there. Is that purposeful? Is could this be a trailer too? Oh, sorry. I I what I meant is to find a new header. Oh, no. Field. But sometimes not everyone. I was just trolling you, Mark. And it worked. But I throw up it, but never. Through Plus. Let's see. Interview, Jerry, you forward the trolling. Alright. Thanks. Okay. So Thanks, Justin, for pointing out that we hit a name collision. And what really, like, drove the point home for me is I went to go check something in my draft. So I used My favorite search engine by which I mean the one that pays my mortgage and typed in the name of the draft and then the other one came And I was like, damn, I think Justin has a point. So, anyway, There was this draft CABG shipping signatures that was replaced and eventually went into what became our C9 421 It used, an, an issue payoff scheme called signature."
  },
  {
    "startTime": "00:22:00",
    "text": "9421 doesn't use that anymore. But that draft got implemented and deployed So that value is still kind of used out there. And Collisions are bad. We've implemented this. We haven't deployed yet. So this is the right time to rename if or going to my take is let's just rename, make our lives easier. So Next slide. Gonna have a content warning on these next slides. If you are triggered by bike sheds, close your eyes. So I wanted to make next slide, please. sure that this Out of everyone's system before we actually formed a queue. Next slide. I also discovered, like, AI LMS for making wide. It's actually really fun. My I don't know. Like, it's not bad. That Yeah. I put in a creepy one. I forget one's creepy. Yeah. what I have this is like, bike shed by MC Ecker. Sure. That's different. So Thank you everyone. I hope we all got that out of our system. Then instead of signature, how about we just do signature and move on with our lives. Mark. I'd like to make the suggestion that we name it something that is not the proper how it gets there, which is signature. But what it provides to the user. And to me, the first word that that comes to mind is unprompted is maybe a little vague. It just hidden? The hidden authentication scheme? Just putting it up there. Yeah. We so so so the we were to discussing that in the early days of this draft. So the reason I did unprompted it was the previous name."
  },
  {
    "startTime": "00:24:01",
    "text": "The reason we didn't do hidden is that we didn't want people to think too much like, oh, this is a bad thing. Like, you know, like, hiding is bad. You don't, like, What are you trying to hide, Mark? So that's why we kinda kept this Do you list? Yes. I mean, want a I wanted to call this mask authentication, but everyone thought was too on the nose. Mass signatures perhaps. Yeah. And then Jonathan thought it would be really cool to call it client initiated authentication, which has a really fun acronym collision. Justin. hard. Hi, Justin Richard. Naming things is Yeah. And, so So first off, I just wanted to reiterate the point that the authorization signature isn't registered by anything. It's not in an RFC. Annabelle and I very explicitly dropped that from what became 9421 because of all sorts of problems with using message signatures in that space. That said, there are tons of implementations of the cabin share app that actually use the including an entire banking system in Europe and Mastodon. If yeah, if you, you wanna have an idea of how how widely a, and a completely unattached ID can actually, make it out there in the world when it wants to. There. Regardless, and this is, in line with the the thing that I wrote to the list. I agree with Mark that I think getting away from signature is a good idea because signature is how it does it. It's not providing a signature of the message. It's using a signature to do something, tell me what about the thing that it's doing. Not what it's made out of. And I think that with that, I I don't have something in my pocket that's that's a perfect name for it, but I think that with that type of,"
  },
  {
    "startTime": "00:26:03",
    "text": "construction around it, would be a lot clearer and a lot less ambiguous about kind of where it fits. They're they're they're These are brilliant, but Yeah. I think side note. We could just look the next 20 days. Yeah. Yeah. This is Get chat GPT to name the header and we'll be fine. Right. Oh, on. So I I said hold I had it explained the note well. It actually did a really good job. Yeah. I'm surprised. talk. We anyway, So, before we progress to the queue, this is your last item. Uh-huh. I thinks so. I just got distracted by making these Well, there's a Okay. quick last slide, but it's just a recap. So just setting expectations to the room, I do not think we are going to choose a name by consensus in the room today. Generally, I know. I'm sorry. I'm sorry. Usually, when we have this sort of thing happen, the working group gives some input for the editor to consider, and then it's an editorial decision tempered by the chair's wisdom and oversight because sometimes editors choose some interesting names, don't they? You're actually looking at this time? Yes. It was a bunch of people in the fondue bar. I know. Talk about the general termination of faulty operations, frame, and H2 or something else. That that that They were a couple of things to discuss. Let's let's not dig up too much history. Yes. So, let's get to the queue, Benjamin. Hey. Hey. So I look through the draft and old Javier. Of course, I couldn't find anything in the draft that actually says why We shouldn't just use HTTP basic authentication for this. And I know that we've Discuss this at great length. And, And, like,"
  },
  {
    "startTime": "00:28:01",
    "text": "you have a bunch of reasons for that, but none of those reasons I think are in the draft. And I actually think that, like, going through those reasons would help to help to figure out what to name it because that would help to understand why it has to work the way it does. So that sounds like some editorial feedback. Yep. I'll take it. Thanks, Ben. But also on the on the name of question. My my comment on the list is that I think the think what makes this special is that it is a TLS channel binding, and I think that has been Yeah. Jonathan. So other other than clients initiated or I really do like unprompted off because that that's the name of the draft at the top. It's great. I mean, honestly, from this conversation, I'm leaning towards just unprompted. Yeah. Yeah. But it's not just unprompted, like, anything. Oh, no. No. but The name of it will be unprompted authentication, string that we register and then the HTTP auth scheme registry will be just unprompted. Authorization of Yeah. Jonathan. A Sorry. It's not. Peter. Hi. It's Peter from Dsick. I'd like to suggest unsolicited or unsolicited SIG Oh, thanks. Mhmm. Okay. 1, Alright. And, I thing. So we have some input. The 3 editors will discuss, and then we can Oh, you couldn't go through all of them one last time. what's left You have about 30 seconds left. So Perfect. So, Apart from this name, is editorial work. Which we'll do. We we wanna do a full pass because now that we've landed a bunch of PRs, it'll be cleaner. And then I think we're Kinda ready for working group last call probably because Like, this was the last remaining issue. So,"
  },
  {
    "startTime": "00:30:00",
    "text": "I think that's it. Give us a chance to do the HR work you're planning on doing a full review because We think it'll be better. Post editorial work. Otherwise, we're terrible editors. But that's that. Great. Cool. Thanks. Thank you. Can you, let me you can take We wanna share a screen. Oh, thank you. Thank you. Thank you. Jill or I I highly encourage you to continue that development, Janet. Yes. Windows. Sorry. One moment, folks. Why isn't it? Is it working? Try one more time. Except up here. Yeah. Just content to share. Pender window. Oh, okay. That's intuitive. Sure. I don't know what to do now. To of see a lot Oh, yeah. It's working. Okay. So next up very briefly, the HTTP query map it. This is a draft we've had open for a Yes. I'll You need to Yeah. Alright. It's very Right. Right. So we have this document. It's it's been, in the working group for a while, and it's a little bit stalled. We are going to have a side meeting on Thursday afternoon at 5 PM local time in 1 of the rooms nearby. There's an announcement on the mailing list. If you're interested in helping to to move this forward and discuss the issues there, we're gonna talk about it there."
  },
  {
    "startTime": "00:32:00",
    "text": "And Julian will be, remote for that. So we're gonna try and as a little design team, I think some folks volunteered for design team a while back and If you forget, if you did or not, come talk to me and we'll we'll remind you. But I I think, Mike, you were that as well. And then, Martin, I think you were part of that as well if I remember you may or may not still be part of that design team. Yes. That's fine. It may have been just you may enjoy, but other folks are interested. Please come along. And we'll try and get that moving because I know that there are some folks in the community who would like to be able to depend network. So with 5 PM on Thursday. Which is not during a session, so it should be okay. And next up, then we have resumable loads. Let me stop sharing real quick. And, that is, if I remember correctly, Maurice, do you wanna do you wanna control the slides from your end? I have other numbers that may get confirmed that you do it. Hold on. You're you're way too loud, unfortunately. Is it better? No. We Still far too loud. Hi there, Richard. West We have controls over But no. No. The other were fine, so I think, hopefully, speakers tilt tilt tilt rearranged his end. the meantime, we have some slides of bike sheds for you to look In at. Is he trying to rejoin? He's very man. Is it better? Yeah. A little bit a little bit less would be even better. You can also just maybe, yeah, quietly, and it'll be fine. talk"
  },
  {
    "startTime": "00:34:02",
    "text": "Anyway, do you want to you can control your slides if you request the slide permission And that way you can move ahead when you want to. Is it the the ask slides button? The, you. yeah, the, yeah, the ask slides button, and then I'll grant it to Okay. Okay. Great. Yep, I hope you can see the slides. This is about resumable uploads. Maybe as a brief reminder with Resum Mobile uploads, we try to provide a mechanism that clients can automatically resume uploads if they are interrupted. This means that the client can query to current, upload state from the server and then just transfer the remaining data without having to retransmit all of the data that went before. And we also already have a few implementations. Namely we have server implementations in net and go. And even one in swift that I missed from putting on the slides. Sorry about that. We also have client implementations in JavaScript that work in node and the browser we've also one running on iOS And, there's also some additional tools for load testing, upload performance, and, even a tool for checking the conformity to the current specification. But they're not all entirely published as course, the property is still evolving. But if you wanna find out more or test a bit, with the existing implementation, there's a github repository where we collect information about all of those and how to get them running We recently published the draft version 3. There's a few changes in there, although nothing too major. We added a couple of progress notifications. We're information and responses, So that"
  },
  {
    "startTime": "00:36:00",
    "text": "the client regularly gets updates on how much data has actually been saved. We, explained the use of empty requests a bit. Because they might seem a bit odd, but they are actually useful not quite in a few scenarios. So we clarified on when those should be used or how this should be supported. We also allowed it to o status codes for offset retrieval, added a few more items to the security considerations. Thanks to everybody on bringing those up. This brings me to some of the stuff that's still open. That we still have to figure out and discuss. One of those is, the media type for pet requests. As we all know, pet requests must carry a content type. That describes how the as document, should be applied to the resource. And, for upload requests where you just take the data and you append it to the upload resource might make sense in the first fought to use application up to stream for this. But this is not really applicable because it doesn't describe the test document properly. And also it's term is probably a lot overloaded. So we need to have something more specific. And, one of the proposals is to use a new media type something like application slash partial upload that specifically describes that the data included in the request, actually, it's just a part of a bigger file. And then in our resumable uploads drop, we can then say, okay. You apply this patch document to the upload resource by appending it to the output resource. Something similar has maybe been done before. In the media type registry, there's an tree from Adobe. Called application vendor, Adobe, partial upload, I have some time more information on how it was actually used or if it was actually used,"
  },
  {
    "startTime": "00:38:00",
    "text": "but people seem to have been experimenting with this or or So, this would be a potential media type that we could use for resumable uploads. I have, brought this to the, media maintenance mailing list, and they seem to be support it or at least didn't have any big reasons against this. So I also wanted to bring this this working group, if there are any files on this media type, pros or cons. Yeah, let me know if there's any comments about this. If not, then, we can also move on to the next point. That is about, upload limits. So most servers usually put some limits on the uploads, like much data you can upload in total. How much data can be included in a single request also how long an upload can take especially interesting with future mobile uploads because They are split across multiple requests. So in theory, you could even resume them after a day or thing. And maybe in the future, there might also be limits on the number of concurrent upload requests to go to one resource but this is still pretty much hypothetical talk because we don't really wanna talk about parallelized uploads right now. But the general gist is that there are some limits that apply to upload resources it will be really handy if we had a way that clients can cover those. In a standardized way. And the current draft doesn't really address this. It just says, like, or it assumes that the client knows these, by heart or some out of bounds method. But it would be handy if we had some way to put them into the standard. And so one of the potential ideas is that the server"
  },
  {
    "startTime": "00:40:01",
    "text": "announces those limits to decline whenever an upload is created or whenever the client queries to upload state. So there's two possible ways we could have different header fields, that say, okay, for example, the upsell upload size limit is about when we can buy it. And the upload expires at this time stamp. And then you could have additional headers that specify the minimum or the maximum size can be included in, individual requests. These are options. Of course, upload expire might also be replaced by another header. I think we have a sunset header that might be something similar. But there was a one options. Another option would be to have, like, one upload limit header, but as a dictionary, so you have, like, multiple entries in there. This makes it nice because we have one header, but of course, this requires us to define a new registry, which might be a bit too much. Yes. So those are 2 options. Are there any comments on those? Yeah, Mary, it's it's Mark. I I first of all, I would not recommend using sunset there that has, specific semantics that aren't really applicable here, and so that'll be overloading those semantics. So We generally try not to do that. I'm minting your own header is fine. But but of these options, personally, I I'd prefer option 2. I think it's more compact. And because all these things are are closely related, it makes sense to put them in one field unless, for some reason, know, if you're sending it a lot and you get compression, efficiency out of it in in or H3. Maybe there's an argument for splitting it up, but I don't think that's gonna be the case. It does not necessarily imply that you need a registry of upload limits can do something like define the header in your RFC and then say if you want to add a new attribute here effective, a new property, you need to update this RFC."
  },
  {
    "startTime": "00:42:03",
    "text": "And so that that's a a kind of a lower impact way to do that. If you don't really think that this is gonna this probably isn't gonna be extended by random implementers. Assuming, or users, it's probably only if the protocol evolves. And so that that might be a more appropriate approach here. Lucas. Lucas. Yeah, thanks, Mark. I think we're probably looking for your input the most out of this. So you beat me to it. I think I posted a question on the the the issue or the PR. Some of this seems a bit similar to the rate limit headers. That were going on in HBP. And and I know that had some difficulties and challenges, for their own reasons. I just wanna make sure we weren't repeating any of those of things, but but really my own sake, I wanted to like, make sure that this idea is is something that the working group would like or not object 2 So if anyone thinks this isn't something we should do, I'd really appreciate bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike, bike tapping, tapping, mention now or on the issue itself. Right. So I I was speaking to how you spelled it, not whether you should spell it. It sounds like you want Yes. Yes. That is correct. I'd Yeah. I saw first in my home. I wonder a quote expires is specified in unix time stamp, but doesn't seem to be consistent with regular daytime notation in HTTP Harris. Is there a reason why we want to use Unix time stamp here instead or maybe better option would be relative time. How much client has to upload rather than giving absolute value. So I'll I'll respond to that. There's been a lot of discussion about that and this is, because you're not using a structured field there. I noticed But, if we're a structured field, it would look a a little bit similar to that. And that's where we've ended up in that there's there's I can point you to a very long discussion about why this the case if you like."
  },
  {
    "startTime": "00:44:01",
    "text": "Part. Yeah. So I got in line to say, I, I would very much prefer that this not use absolute times. I think wherever possible we should avoid using absolute times in protocols because, there are there are always two clocks in a protocol, and they never agree. It's a little easier if you have deltatime, it'll also be a bit smaller and easier to put on the wire. And it also means potentially that you end up with this, in, in a better, better state with respect to having a static expression. Of what your policy. Is. You just say this is the policy. I keep it around for 30 seconds or 2 minutes or or what have you, alien, and and and you've always produced the same answer, which compresses really well. Okay. Perfect. Thank you very much about this. I think we can integrate those points. To be explicit. I I didn't hear any pushback on whether they should be done or not. It sounds like there's general Like, it's fine. Yeah. Alright. Doesn't seem like there's any pushback. Then I would continue with the next point. This is about Sorry. Yeah. If I may, These need to be all optional. I take it. That wasn't really covered in the thing, because there are there are aspects of this that I I think some servers may not have a policy, or they may may not wish to express a policy. And so if they're if all of them are optional, this is, this is fine. Yeah. It's good to make those assumptions explicit. And, sorry, I I should have been clearer on my point one of the questions is is is this Is this something that should be done solely for resumable uploads. For any kind of upload to over HTTP. So the,"
  },
  {
    "startTime": "00:46:03",
    "text": "entire upload size limit might be something more general where you could say, okay, what is the entire limit that a single request can carry? But the other ones, especially when you're talking about a pending to an upload, the minimum and maximum size that you can append. I think that was a very specific for resumable uploads. The upload expiration thing You could make it into a bit more general thing, you're like saying, okay, what's the lifetime of a resource I think there have been other attempts in this and those haven't been very successful. So I'm not sure if moving this into a more general approach is actually helpful here. Yeah. I I just just wanna avoid this trying to do the right thing and doing it wrong and then regrading it in a when it comes to working group last call or something. So I don't think we need any more time right here, but Those are the kind of things I wanna see answered really before we merge this, just to avoid churn, Chezmaris. Thank you. Alright. And next point, might be a a pretty simple question, but has been one that's been bugging me a bit. So the RC for patch request says that the patch documented is included in your quest must be applied atomically. And not partially. This makes sense if you're thinking, for example, about a JSON API, where you supply adjacent patch document and you want to have this entire document applied and not just some state of it. If resumable uploads, this brings us into a bit of an odd state, because with resumable uploads, we explicitly provides support for applying partial changes. In a sense that, for example, if you transmit 10 gigabytes, or you want to transmit 10 gigabytes in a patch request, but it aboard and halfway through. You can still save the first five gigabytes and without any issues,"
  },
  {
    "startTime": "00:48:02",
    "text": "and then the client can just query the state of the upload and then resume. In this case, for us, it's totally fine, or for the use of original uploads, it's totally fine. To have the hedge doc you've been applied partially, like only the first part of it. But this might not really work with the language that is in the RFC for patch requests. And I just wanna bring this up now before it comes in, like, a working room lost call, that we might be doing stuff that's not compatible with patch. Are there any comments about this? Lucas. Oh, We we didn't dig sorry. dig So I think, you know, the the strictly correct way to do this would be to update the patch RFC because that wasn't envisioned, but I don't think that's necessary here. I think you just do a little bit of sleight of hand language about what the definition of complete is for this particular media type. And that should be fine I I don't think anything more than that's necessary personally. Martin, Yeah. I I, I might even go further than Mark and and say, if you read this carefully, it it basically says that any any change that's in flight you should never see part of that change if you're querying that resource from somewhere else. And in the case of a of an aborted upload that is then continued so It might take a very long time for that to reach the point where it but it the, the state of the resource flips, will flip atomically at the time that you finish up loading it. And, that should be relatively straightforward for, and within the, the bounds of the definition of, you know, pet charity. Sir, sir. I'm I'm okay with with the these both existing and coexisting. It's not okay with it too. I don't think you're quite correct because because remember we're talking about a separate patch resource now, and we're updating its state. And then when it flips that"
  },
  {
    "startTime": "00:50:00",
    "text": "updates the, you know, true resource. So, know, from a strict you standpoint, that's not quite true. But I think in spirit, we're out there. I think okay. Yeah. Yeah. in spirit, it's It it might be worth putting some language around this in in the document saying, this how we think about it. is And this is the expectation that we have around how resources will behave when interacted within this way. And I think that'll that'll help. And and it might be even worth raising a technical arena against patch to say that, you know, that that, you know, subject to the semantics of the upload media type is the intention of that requirement. Right? Alright. Thank this. you very much. We will definitely incorporate One of the, last points that I would like to bring up today is about the use of content coding with freezer mobile uploads. For example, let's assume that wanna upload a big JSON file And because JSON is pretty much text, you can compress it pretty well with So you start an upload and you say content types application JSON, but you also use content encoding gzip. To compress it pretty nicely. And then you start doing your upload and maybe in the middle, it gets interrupted. And so you wanna resume it. But now if you resume it, Do you what what how how do you handle the content encoding? Do you wanna use in the patch request to use still wanna use content encoding gzip, or do you wanna use something like content encoding identity or omitted entirely. Idea might be that you still target the same representation that you did when you started the upload. But then again, if you just cut off a decent stream in the middle, Then the remaining Part might not be like a valid gsip format itself because you don't have the header But in the end, you're still trying to modify the same representation."
  },
  {
    "startTime": "00:52:03",
    "text": "So this might be, falling on my my short understanding of representation is there any feedback on how content and coding should be handled when resuming uploads. So I think another people can come up and correct me if I'm wrong. Even though we often do produce it on the fly, Content encoding is technically saying This resource is g zipped JSON. So if you've uploaded half of it, you're halfway through the GZIP cents. When you go to resume it, You are continuing the gzip and the gzip thing and the gzip JSON. You are not gzipping a portion of the Does that make sense? So you so you have to be you have to gzip it and then upload pieces of that. And so, and the second one you that's not content including GZIP, because you have not g zipped the partial upload. 2 media types, sir. Okay. So it will be more appropriate to omit the content and coding had a Yeah. that So, the way to think about this is the the representation that you're sharing in the second one, is just the bytes of the of the thing that you tried to complete previously. And so there's no content coding there. There was content coding on the original one, but there was there was no content coding on on the second one. And, and that will work. That does also suggest the option you can put content coding on the patch. In addition to the content coding that you had on the original, and its totals all the way down. But I would not do that. Yeah."
  },
  {
    "startTime": "00:54:05",
    "text": "No. No need to specify you can't just say, like, if you do it, It will have these unintended consequences. The Well, it system, one of those Herebeebdragons kind of situations. think it's it's pretty well well defined is that when you receive this request, the the content needs to be decompressed or or processed using the the the content coder to or the the decoder for the, for the the coding type. Before you do anything. And, and in the context of continuing and upload, you're, you're just continuing to add to the bytes of the original. But this is gross, But just don't. Today. Look. Let's go ahead. I think we have a a a solution to detecting that grossness. Like, you tried to do that, and you did encoding of the patch wrong. And you pieced together the object badly, and you would then check the digest of the object you uploaded and it would fail. So at least you could detect this thing. But we shouldn't shouldn't be doing it, but there are ways to detect if you if you held it wrong. This could happen for like I know. Just focus clients out there that do the wrong thing and at least if they get a strong signal back, this has suggested me that the ability to take Check digest of these things is useful. That's a separate issue and a separate PR. Just as an aside, this this kind of makes me wonder, and I haven't thought it through fully, but you know, that we have this thing where we're kind of creating a new resource effectively. And and maybe we need to send some instructions about how that resource is created regarding things like Oh, You should probably create an undecoded okay. I mean, I mean,"
  },
  {
    "startTime": "00:56:00",
    "text": "Right. Unencoded version of this resource or, you know, conversely, if I upload a plain text, know, maybe you should, you know, be able to configure that it it should be content coded. I don't I don't know. Something to think about maybe. Almost like a remote configuration protocol, though. I mean, how far do you go with Alright. Thank you very much for the feedback that's very helpful and well we incorporate it. This also brings me to my class slide, there are still a few other open issues but most of them should be easy to close We have been discussing some of those. There's some PRs open for some of those. So I hope that will be finishing this up mux2 late into the future and then maybe can move is across the finish line. In the next next coming time. But, yeah, thank you very much for all of the feedback. And I wish great remaining, you a tell you. Okay. Thank you, Marias. So that's our last item for today. As we said, we're gonna meet again on, Oh, wait, David. It's in queue. Dave? Just really quickly. None on this draft, but On the topic of retiring the old signature HTTP scheme, was thinking, should should we mark it in the INA registry as deprecated so that someone doesn't step on the landmine next I went I was just gonna put in a request, but it's a ETF review. was thinking I could just Yeah. So I add that to the references of the new draft with a reference to the old one is you don't need to reference yourself. I just What do you think? I also just can yes, for this register you do. I know. So that's why I was like the only way to do it would be added to our intersection of, like, by the way, there's also this thing explaining the history. Or we could just say, we don't care. Alright. We we that. let's let's have a we can have a chat about K. Right."
  },
  {
    "startTime": "00:58:00",
    "text": "Alright. So Friday, we'll we'll talk again. I wanna congratulate everyone. We've managed time very well today. Just on time. You have 2 extra minutes. Right. And and for people who are making slides for Friday, You can choose to include many pictures that are, AI generated or not, I'm not sure what feelings I have about that, but I have feelings. There are Did not know I was gonna be exposed to somebody by chance? Did you get the picture out of that? Yeah. Yeah."
  }
]
