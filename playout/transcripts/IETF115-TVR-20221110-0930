[
  {
    "startTime": "00:00:05",
    "text": "good morning uh welcome to the TBR off um I'm Lou Berger this is Russ Wright we're co-chairing and we also have uh uh uh here with us uh who's uh volunteer to act as our secretary thank you um all the material is online and if you're interested in the topic uh please take a look at the material we also have uh the standard web page available that summarizes the purpose of the boss we'll of course go over that here um and we have a couple of drafts even though they're a little bit early next this is an ietf meeting all of our meetings uh are governed by uh that our note well which has rules regarding our participation basically everything you say here becomes a part of our permanent record if you're not familiar with the note well please go to the ietf page and take a look and familiarize yourself with our rules of participation next we also have rules related to conduct and basically we ask you to always treat each other with respect and professional and be professional with each other of course it's okay to have good technical argument but uh please keep it uh at the at the technical and professional level and of course we have a document governing that too TCP 54 next for those in the room we ask two things the first is please scan the QR code joining join the online Tool uh whether you use the phone or the the computer it's really important because of two things it gives us our blue sheets it also allows you to participate"
  },
  {
    "startTime": "00:02:02",
    "text": "in polling and we will conduct some polls later in the uh the session and we'll do that versus raising hands or humming so that we are Equitable to the people who are remote so they can participate at the same level for remote participants you're here thanks so much for joining and please meet your mics if you're not speaking the only additional piece of information on on this slide really is uh come join us on joint minute taking so we use Hedgehog ether pad whatever you want to call it it's a it's a collaborative tool where everyone can make sure that we're capturing the conversation and the discussion that happens you don't have to capture the material on the slides that's already on the slides and we have YouTube available but for the discussion it's really important to help capture um uh the uh capture the discussion going back to the um going back to the uh scanning in for on-site I forgot to mention the other bullet that's on here is the ietf requests and requires that you wear a mask in the room and the only time you should take it off is if you're at the front talking when you um speak at the mic please make sure you give your name before speaking because the people who are taking notes and people who are remote often have a hard time distinguishing voices in their current environment and we are going to use the meat Echo queue for controlling uh discussion so if you want to come speak at the mic please enter the queue and that allows us to make sure that we're taking remote comments at the same levels in the room comments next please so what are we doing here uh you're going to hear in a moment about the uh problem we're trying to solve but from sort of the administrative side we're trying to"
  },
  {
    "startTime": "00:04:01",
    "text": "answer a few questions um first what's that problem uh Rick is going to talk about that um and then we also are going to follow up the the problem statement with some use cases that really drives our requirements helps us better understand the problem we're solving eventually we have to figure out what new work is to be done where the gaps are in the existing Technologies and that's those two are sort of the main purposes of the discussion but from a uh management standpoint from the isg from the IAB a very important question is is there sufficient interest in working on this problem at the ietf so at the end we are going to have a poll that says are you interested in in this topic and are you willing to work on it and ultimately those are the questions we're here to answer so yes we want to understand why we're here what problem we're solving but from an ietf standpoint do we have enough people to work on it yeah not not just what you're interested in but please if you're willing to work on it if you're just interested in the problem that's not really useful to us so it's really much more useful is yeah we're willing to write drafts edit drafts do code whatever is needed next so we have a posted agenda the agenda is a little different today than it was uh yesterday or the day before um uh basically we got a little more information um uh and some additional contributions that's always really appreciated as a contribution-driven organization one thing I want to say about the time here these are approximate times we have a good 30 25 minutes for discussion if that discussion happens earlier uh in the session that's okay we don't have to"
  },
  {
    "startTime": "00:06:02",
    "text": "be completely rigid to these times we will sort of manage the cues manage the discussion so we can cover all the topics but if we have a lot of discussion let's say on the problem statement will you can we'll let that go over and we'll just take from that open discussion time and with that we're going to jump over to the next Rick Taylor is going to talk about the problem statement morning all oh that's very loud good morning all um so I have a published problem statement which I'm not hugely proud of it was pretty much a stream of Consciousness done pretty quickly and off the back of that had very productive meetings with a number of people who picked up on that there was good correspondence on the mailing list and I want to call out Adrian for taking me to one side yesterday and saying let's drill this down to something a bit more short and tight and that really hasn't been updated yet and is kind of the content that I will come up with at the very end of this slide deck but meanwhile uh can we have the first slide please so I'm going to jump straight into the meat of it as I and several other people we have chatted to see it there is the following problem we understand that in routing you have nodes you have links they come they go you need a protocol to try and build some sort of topology so that you can build end-to-end paths across these Networks we can do that fairly effectively at the moment but in general we believe as we're building those protocols that we must react to failures in these links in order to recover in order to maintain this topology"
  },
  {
    "startTime": "00:08:03",
    "text": "what we are discussing here is the proposal that maybe there is another case here which is these links and these nodes may change in predictable or scheduleable ways so you can know with a certain degree of confidence in advance of a break or a restoration in link adjacency or whatever that it's going to happen therefore as a routing protocol implementation or a protocol design you don't have to react to it happening oh my God my Link's just gone you can say oh at 12 pm on Wednesday that Link's going so I can pre-compute an alternative or I can keep a backup topology ready to apply or I can do smart things and I'm not entirely sure personally what all of those smart things are but I would see that as an interesting area to investigate so that when that scheduled event occurs you are ready to do it and you can move swiftly on without losing end-to-end connectivity your traffic can flow less disruption Etc so next slide please so I'll give you a second just to read through this a little bit but the obvious answer to that statement is people come back and say well actually routing protocols already handle convergence when we lose links when nodes fail and in general that convergence is fast enough and fast re-route mechanisms exist and they're good we've worked on this for donkey's years within the IDF we've got a good Suite of protocols that will pretty much do this but as I've said before rooting does not currently handle the potential connectivity represented by root nodes and links that are scheduled to turn up in the future or are scheduled to disappear so you know it's going to"
  },
  {
    "startTime": "00:10:00",
    "text": "happen it just hasn't happened yet and I personally see that as a critical difference so and that third point is basically an extension of that which is not only do we uh we don't handle the fact that we know a node is going to appear or links are going to become available we also don't handle the fact that we know they're going to disappear as well by extension next slide please foreign so the problem is if we think there is a use here for having this a priori in advance knowledge of changes to the connectivity and the adjacency and the availability of the individual nodes that make up the network over which we're building an end-to-end a set of end-to-end paths how would we solve that do we understand that there is a problem to be solved here because again this is problems so how does a nodal link that is not up have its presence advertised how do we inform a routing protocol that something is going to occur in the future and how if we can say it's coming can we also include how long is it going to be up for and equally the converse so can you say at this point in time something is going to happen either an availability is going to arrive or a link is going to disappear so therefore service will not be available across that adjacency how long is it going to be for and will this repeat will this recur how long does this whole description of forthcoming events going to be valid for so we're sort of starting to talk about possible to describe a schedule and that's the word I'm using at the moment I'm not trying to impose any words onto any any future solution to this problem but can we talk about schedules forthcoming events and is that of use to routing protocols"
  },
  {
    "startTime": "00:12:02",
    "text": "do we see advantage of doing that the follow-on question for that is if we see available and unavailable as one of the things you would describe in that schedule could we say well availability could just be seen as a Boolean metric up down could we say change link costs you know whatever the waiting you're using to build your your shortest path across your available graph could we say at some point in time the cost of this link is going to change so you can go and run your dixtra algorithm well in advance of this and say well I know when that time occurs I should probably my shortest path tree is now something completely different I could pre-do that work next slide please okay so this is the full text and I'm not going to go through it again I've broken out the key points in the previous three slides but that's there so please grab it read it through my intention is to um work with Adrian to reintegrate this text into the existing problem statement and to update it if there is a general consensus that we want to continue working on this and there is such a thing I apologize I didn't have time to get this back up onto GitHub etc etc and I believe that is the last slide because I've split this to talk about existing Technologies and a bit of scoping to go later in the agenda Kevin is heading to the mic call one uh hi Kevin fall did a little work in this area about 10 years ago um I just wanted to just some comments uh observations so interestingly uh you know we can trace rooting we do in sort"
  },
  {
    "startTime": "00:14:02",
    "text": "of internet and whatever to some work that had been done you mentioned dijkstra algorithm for example so 1958 there's a publication flows over time for Ford from Ford Fulkerson which is the same origin story that we have for you know regular kind of rooting protocols so I think when I first came across that text it was interesting to me that it was really so old um but just some other comments that I would concur with you it's it's sort of a different problem space from a kind of the graph theoretic point of view because you have a time Dimension and all of that whether it's useful in this context that that's an important uh sort of debate to have but uh I guess I would just say that there is a lot of academic work in this area but it uses words that we don't tend to use here and it also just one other little thing sort of meta thought about rooting you know when I went through school and learned about rooting it was presented like you know here's link State here's whatever distance Vector Etc but there's another whole world that looks at the same problems which was the operations research community and their research and its optimization problems and they're they're duels they're really the same kind of problems in many cases and so if you the the other kinds of interesting work that relate to this that probably is not an ietf scope but just to give you some thinking is like Dynamic transshipment problem things like this is where you have um you know warehouses and highways and the highways are fast or slow and the way arrow and the warehouses have so much capacity and you need to get certain you know Commodities from one place to another and and those were the types of work that we were thinking about whatever 10 years ago when like oh we have links that come and go but what's going to happen with the data we care about if it has to go a long way maybe it has to camp out somewhere and so if you know that's a pretty different thing than what internet architecture usually"
  },
  {
    "startTime": "00:16:00",
    "text": "does but you can imagine a world and I think Dave Clark said this one's like oh at one point we were thinking that packets could just live in a buffer for a day okay so just I don't know if any of that's going to be but I just want to sort of throw out there's a rich area that that we don't normally tread in here in this place two quick answers first off I think the the presence of existing research in this area is a really good thing because I always worry when I think of something and everyone says that's unique no one's ever thought of that it probably means it's really dumb so the fact that other people have been spending eight years decades researching this stuff I think that's really useful and second of all I'm gonna come back to a bit of the technology piece and look at some of the Gap analysis stuff in a later presentation it's we've scheduled it in Fairly bite-sized chunks and you're right there's what we do in the internet area particularly in pretty stable networks that we're all pretty familiar with there's the whole Mani piece I want to talk about where there's a different approach and you're right the the kind of generic traveling salesman problems the resource scheduling across routes that are not traffic based there's a whole wealth of stuff there and having some kind of timetable I mean think about railway systems they have a timetable so you know where to get there get to the station at this time because that's when the train is going to be there see if the internet goes on strike don't go there just as a heads up we do have some extra time for discussion but okay so do we have eight people in the queue so we should keep things moving along it's good to get the points but let's not spend the whole time on one so this is Alex Clem futureway I have one question to the problem statement so I understand the basic premise of this but I think the second part is missing namely what you're actually planning to do with this information so assuming that you had this solved how will you leverage it how will this be better what problems do you solve better by knowing the schedule Advance versus having to reconverge or or what have you so no I did not really see this explicitly mentioned maybe it's implied in your"
  },
  {
    "startTime": "00:18:01",
    "text": "mind but I think it would be helpful to be explicit about that Fair criticism you're right that first off the problem statement can be much better but the quick answer is I think there is an opportunity if we know something is going to change in advance then we don't waste time and possibly precious resources trying to work out why it failed trying to bring it back because you know it has gone no need to try and restore that peer link no need so that's one opportunity to not waste scarce resources and the other opportunity is if you know something is going to happen in advance you can do that calculation as a low priority because you know how long you've got to do it if particularly when we look at iot anything in space you know General resource constrained things anything we can do to save on conservation so if we know something is going to change we can do the calculation now rather than have to rush a reaction to something happening we can be sensible about the resources we allot to make making that change because we knew it was about to happen right we're going to move on to Tony go ahead Juniper um sounds like we've got an echo sorry about that go ahead so my concern is something we raised on the mailing list which is are we covering Dynamic topology I think if we are not covering Dynamic topology then the problem is relatively straightforward we already have techniques for dealing with links that we think we're going to take out of service and being able to do that on a schedule is sounds like it's pretty straightforward if we are planning on bringing links up then"
  },
  {
    "startTime": "00:20:01",
    "text": "we have a question that was not dealt with on the mailing list which is do we wait for actual liveness information to propagate a if the link is scheduled to come up does it actually come up 100 of the time at the scheduled time so that seems like an important question focus on the dynamic topology question thanks Tony I'll try and answer some of those quite quickly so I'll start with the second point which is if a schedule says a link is going to be up do we always believe it I think would be a mistake um I think experience tells us that you always have to deal with exceptions you always have to deal with unpredictable failures we do that with all the routing protocols from across the entire spectrum of dynamic to to very stable environments so I'm not suggesting that you that you don't expect failures if you have a schedule I think that's naive um the dynamic question so that's a scoping question um my gut tells me you try and start with the simple cases and then expand out to the more complex ones whilst when you have a better handle about your approaches but that doesn't mean you don't discount more complex cases while you're looking at your simple solution that is a very politicians answer to that question yeah I think that you might have uh missed each other because you have on your slide I think the answer to his question which is dynamic topology is in scope and that's represented by that T2 and T4 is at T2 you had a break along that path and then at T4 it comes up to a different technology goes somewhere else so and Tony you can jump back in and answer if I get that wrong but I think that's what you meant by Dynamic topology so there's a chain not only is there a change in"
  },
  {
    "startTime": "00:22:01",
    "text": "link status that's scheduled that there's also a change in who you're talking to yeah no no if if that is our definition of dynamic then yes absolutely I come from a Manet background where Dynamic can mean almost chaotic and those edge cases I would suggest still remain out of Scope when everything is moving at such speed or your schedule is talking about nanoseconds and the predictability of this stuff becomes very low probability I think we disappear into a corner case we shouldn't go in but yeah links up links down nodes coming online nodes moving relative to each other within a potential topology that level of dynamism absolutely if it is if it has corresponding predictability ah thank you yeah I just wanted to make a comment from a really a comment from a colleague of mine which I think echoes a comment that was made at the mic earlier and also by you Rick that uh it's like a bus scheduling or train scheduling or you know using a Maps app uh it's related to driving directions but it you know but it's also sufficiently different that it warrants uh a special look and so for the purposes of like buff working group formation I think it's uh it's worth recognizing those differences and and uh having a dedicated space to concentrate efforts on that brilliant thank you Julian Julian luchak so this buff is actually quite timely for me because I came across a situation recently as follows so you have a network um in which there are a number of remote sites and so um in the main particle Network let's say you've got a router R1 which is connected to a remote site and in remote sites you've got routers R2 and R3 facing the main network but there's only"
  },
  {
    "startTime": "00:24:02",
    "text": "one fiber connection into that site and so what you've got is a um a fiber switch in the site that connects to fiberlink normally into R2 on that site so I went up is normally connected to R2 but if R2 should fail there's some automation that makes the switch flick over to R3 now while two and R3 are connected to each other and there's some other reasons behind so R2 sorry R3 knows as much about the topology as R2 does even though it's not connected at the moment to the main site and so it with current you know know protocols and so on it's frustrating that um you know to take a vote of a few seconds for you know R2 to come up the protocols to come up Etc so this you know sort of chimes in you know very well with that scenario in fact thank you so that's that I think is yet another example of of reducing the the loss of of data transmission capability when something has happened if you can know it's happened in advance then you can say well as soon as that goes I know what I it was expected that's due to R3 r3's warm standby and ready for it rather than coming from cold it's and I know that existing protocols have mechanisms to make this work and I it just genuinely I don't know if this isn't solved and if sufficient people stand up and say we've got solutions to this I will be very happy but I don't think we do or I might not understand so thanks Andrew hi Andrew from liquid intelligent Technologies so I live in a part of the world where power is not always the most stable um luckily in Kenya it's more stable than my colleague from South Africa I think he brought the parachute load shedding with him with it when we arrived but here's the thing"
  },
  {
    "startTime": "00:26:01",
    "text": "yes I can say the thing's going to go down we've got the fast reroute Etc however if I get an outage and I know that this is power or has a good probability of being power based on the schedule and I'm just interestingly enough was looking at the load shedding for my parents house and they three to five thirteen seven o'clock to nine thirty blah blah blah how I'm going to react to that based on is this power or something much more temporary how long that power outage could be could potentially be very different um and if for example I've got someone at the knock in India or in the UK picking this up and looking well it's just another outage I'll quickly balance this here that's different to saying I know this is power my schedule says it's going to be out for eight hours it's going to hit a peak time over here I may want to rebalance this traffic in a very very different way and that makes this really important that I do have a way in the network to pick these things up Etc and then make decisions on that that aren't necessarily related to some guy's impression in India who just saw that the router went down you know so there are a lot of possibilities here to get pretty interesting with how you do this the other thing is if I've got algorithms that are learning how to balance traffic when something is down I can tell that algorithm this is because of power outage learn something different versus this thing has just rebooted itself and may come back at any instance"
  },
  {
    "startTime": "00:28:00",
    "text": "so there are a lot of possibilities I see here and yeah I am extremely interested in this thanks Andrew um yeah I think when it comes to the what's in scope and what's out of scope if people do think this is a problem we need to balance um I personally don't think we should get too caught up in how do we create schedules I think that's kind of beyond the scope of what's achievable in a in a reasonable working group schedule um there is some really cool stuff we can do once we have a schedule and I would and I'm going to get on to this later but it's more about trying to keep that scope down but that doesn't mean other things can't be built that we consider to be particularly at the scope of something like a routing working group but yeah once you've got this data and you can work out how to get it around your network and and get it in the system there's a lot of cool stuff we could do with this I think sorry come on yeah um the cross and Huawei I asked the question on the on the on the chat and I I thought I might relay this here it's called time variant routing but but I feel there are different variances we we may want to consider it came out already before it may well be energy it may well be locality you know there's a fine time variant the the focus on the schedule very limiting if you will and it turns you know link is up and down schedules I put a schedule into the router you're done but if you have Dynamic conditions that may be predictable as well um upon which you actually want to change your routing I think this you know creates a much richer space for probably very very innovative solutions in the world I take your point um I'm really trying to stop boiling oceans here and I do wonder that um I don't want to disappear down to a generic uh uh expression evaluation condition causes effect"
  },
  {
    "startTime": "00:30:01",
    "text": "network I think that's still very much the work of the irtf I think if we say time things change at a point in time can we prepare ourselves in advance that reduces our scope to something achievable which will have noticeable benefit I'm not saying everything you haven't said is not really cool stuff and would be great to do just don't think it's achievable particularly within one bath from a from an Administration perspective not from an intelligence or an ambition perspective thanks Fair Point and just for clarification I believe it either comes up later or you've said it earlier that at the time change other parameters may change like bandwidth yeah yeah so a scheduled change in energy consumption I think we've got use cases talking about in fact I know we've got use cases coming talk about that it's not just on and off it could be we know that uh I don't I don't know the the atmospherics are such that our satellite links are really good until there's a rainstorm coming in at 3 P.M this afternoon you you can do a lot with the schedule I do agree I mean if you if you provide an API in the scheduled building that's how we solve some of the problems in the past but obviously the conditions for the schedule can be can be exactly along the dimension that I just mentioned it could be driven by Energy prices in order to do carbon aware routing it could be based on expected movements I think on the mailing list I sent the paper around we published 20 odd years ago on using contextual information I walked down the house we walked to the left I walk to the right right you can boil this down into the schedule if there was a proper API into the schedule making then you can probably go down the route that I'm suggesting I I completely agree and I think that the carve Point here should be let's say we have a schedule let's see if we can Define what that schedule should have inside it and let's discuss"
  },
  {
    "startTime": "00:32:01",
    "text": "the kind and I'm getting beyond the problem statement into what I think the scoping is so actually I'm going to stop can we revisit this in my next slide or my later slide deck and last question so when a uh a node or a link changes the network transients and during that transient a lot of innocent traffic is disrupted yeah because the formation of micro Loops so we're going to do this can we include in the base technology micro loop prevention in some way or other to try and minimize this uh this very disruptive effect the Technologies for knowing are for doing it are well known absolutely I've seen no reason why that shouldn't be considered it's that's just the sort of thing that we can attempt to avoid if we knew it was coming up we might be able to use different techniques to say when we have to make this change because it is predicted we can avoid that sort of micro loop formation or whatever because we can all look at we being a set of of routers or whatever we can pre-agree a an alternate topology to have prepped without those micro loops and we can pre-agree to make no no it's not it's not quite as simple as that right so because you have to deal with the uh lack of synchronicity in the changing in the fibs which can take quite a long time so actually it's not an instant event changing the topology but actually a topology change process that you need to do that takes you from the old topology uh to the new topology via a number of short-term virtual topologies usually and that sounds absolutely like something that should be addressed as part of a TBR working group I think that would be absolutely a charter item to say can we in um general terms describe how one makes this change such that we avoid these things and the reason I say general terms is I don't think it's right that a"
  },
  {
    "startTime": "00:34:02",
    "text": "potential TBR working group should tell link state routing what to change in ospf we should go to ospf and say these are mechanisms that we talk about go can you integrate it the the techniques were investigated quite some years ago now in um the transport in the routing area working group so a lot of the techniques are already documented great let's have them let's use them yeah perfect uh thank you all for a really good discussion and hopefully we have a good picture of what the the problem is we're trying to solve here um that said we're going to look at some specific use cases and I think they'll Echo some of the conversation uh Ed hi my name is Ed and Rick is taller than me okay so when when Rick and I started talking about what would time variant routing uh look like obviously a problem statement was good but everyone has in their in their mind a mental model or a problem that they've encountered and that they're trying to solve and trying to bring that down into a series of use cases was an interesting Endeavor because we could have two of them or we could have two thousand of them and how do we scope and understand what differences are important to talk about so what I want to talk about for the next 10 or 15 minutes or so is an initial take of how we carve out use cases to identify what we think are the unique differences that and the expected benefits in those use cases of something like TBR time variant information next slide so to do that I wanted to to just go over some background the approach that I took in laying some of these out based on the conversations and the working on the mailing list uh talk a little bit about some formatting and then go over what I call sort of the three use cases which are kind of categories and I'll name them here and we'll go into them uh"
  },
  {
    "startTime": "00:36:01",
    "text": "in detail in just a moment uh the first is cases where nodes change their functionality to preserve local resources local resources like resources local to that node it's battery power thermal environment local storage where preserving that is more important than some other node functions another set of use cases are cases where a node wants to adapt to changing external conditions power is really expensive right now data is really expensive right now it's not a matter of node survival but it's a matter of reacting and and working better in an external environment and then the last one which is which is one that is probably very familiar when we talk about things that change over time is what happens when nodes in our Network are moving when they're moving far away from each other or when they're moving through a difficult environment or when one just turns a little bit and can't talk to the other so next slide so before we go into those three how did we get to those three and how are we going to talk about them so how did we get to them well obviously we wanted to constrain anything we talked about to the problem statement that Rick had just talked through because this is the problem that we're trying to solve but then when we talk about use cases it is categories of these problems so we say use cases but the three things that I just said I believe are categories of problems or characteristics of problems and the idea here is that again I don't want to worry too much about two or three or four instances of the same kind of problem and calling them different uh another way of saying it is what we think here are from a use case perspective these three are such that a solution for one Exemplar of that use case could be a solution for any other Exemplar within that use case"
  },
  {
    "startTime": "00:38:01",
    "text": "so the format for this is we want to Define what they are we want to list out what the assumptions are and assumptions here because the use cases are again a little bit abstract are what information do we think would need to be present in order to yield deterministic benefits from having a predictable schedule and then the next part is okay well assuming that we have data that we need to key off of then what are those benefits and when we list out those benefits it's not a and then there will be a list typically two or three or four or five it's not that we think we will get all of them all at once all the time but maybe you get some combination of them and in different cases and then last I'll end each use case with a quick Exemplar just to try and ground the thinking but then afterwards we have two more presentations following this one that will go into deeper detail on some more specific exemplars next and we probably will wait for discussion until all three presentations go if you do have something that's just like a clarifying question that's great but uh for discussion let's hold it until the end of the three use cases thank you I will happily defer discussions until I'm not on stage so use case number one uh local resource preservation I mean this is the idea where we have nodes that just operate with limited uh resources either because they're in a very difficult environment or because there is some nature of the node itself uh where it is meant to be small it is meant to not need a lot of power it's meant to not have a lot of storage uh typically smaller things may be more susceptible to Thermal changes and more importantly the management of local resources is going to dictate the function of the node so cases where we have nodes that will pause non-critical events to allow the node to stay alive and on battery life longer to extend the life of the node or if we know that something interesting is coming up and"
  },
  {
    "startTime": "00:40:01",
    "text": "so we want to power things down so that when that interesting thing happens we will then be able to do data collection data exfiltration or if we have to go into a thermal safe mode or more interestingly if we do have a relatively small amount of storage and that storage is filling up maybe that is the time and the predicted time when storage may fill up when it's time to turn on things like radios and start transmitting again and then of course the possible benefits of this are that if we understand a little bit about the future particularly as it relates to when links may be going up and down we can do a better job of our own Resource Management next slide so for this and the other two use cases there are sort of two columns here again the assumptions which are on the left say the better we know these things than to the right the possible TBR benefits the better we would be able to achieve these other things so if we assume that we are a resource constrained node and if we assume that that resource management is important and in this category of use cases is sort of dominant to node function then what we would say is it's important in these cases to know that our resource expenditures are knowable the amount of resources consumed by node functions can be known in advance if I'm managing my node functions based on the amount of battery life left and I know how to transmit a data volume I probably should know how much power it is going to take or average to transmit that if I'm making decisions based off these things so we assume that that's calculable on the Node or knowable on the Node and then the next piece of that is we assume that the re uh the accumulation back of resources again using the example of power how much we tend to expect to get back a battery charge from things like solar charging when will that get us back to good should also be calculable and then the last is that if we're making node"
  },
  {
    "startTime": "00:42:00",
    "text": "function decisions based on the resources at a node there is an assumption that that set of decisions and those rubrics or those metrics aren't changing so rapidly that within any sort of given period of time we're not um we're not changing our internal cost functions because if you're if you're always looking at a different way of managing resources every few minutes or every few hours throughout the day it becomes more difficult to get deterministic benefits back from adhering to something like a schedule however if if knowledge and we've only Goods in these situations they do understand these things because that is their resource management job then you get better power savings uh you can get better thermal savings you can get better storage um management uh and and really honestly just the data delivery because that's what most of this is about continues to be a little bit better because if you can manage your resources better if you can stay active in the network better if you're not wasting Power by having a radio on when you don't think there's a likelihood of having a link for example then you are you're able to eventually get more data through your system next slide so a graphic uh one here is to to come back and say and these are taken from the use case documents which are published uh as well if we were to look at a very contrived example of say a three node network node one node two node three and we were to put a very simple plot that says with power on the vertical and time on the horizontal that a node would choose to keep a radio off until such time as it accumulated enough power to want to transmit something or listen for something then you could put some very different plots together for nodes that maybe are distributed in a particular way and you could see how that would change uh underneath of that the topology of the network at different times time one time two and time three"
  },
  {
    "startTime": "00:44:00",
    "text": "so this is something that's uh while generic I think we can all come up with or understand how this would look in in actual deployments from an assumptions perspective we think you know these power graphs are knowable both accumulation and expense the resource the radio management that sort of horizontal line of how much or how little isn't changing over time and it looks at uh places here where the topology itself is is predictable scheduleable and likely also communicable across other nodes in the network all right use case two which is now not about resource management and preserving node function is instead about adapting to external conditions and and the idea behind this is that there is likely some cost some external costs associated with participating in a network and a common example of that is use of infrastructure use of power infrastructure use of data infrastructure nodes that are Wireless they will for example use cellular infrastructure I think all of us understand the idea of one Peak and off-peak usage times and what happens uh with overage rates if you go over your one Peak minutes you know it came out in the in the news what three or four days ago that starlink has come back and said you know if you go over a particular cap then that will be problematic and you will have an overage however our off-peak time is you know 11 P.M to 7 A.M uh I guess your time and so that means great if I have you know low priority data then that's when I should choose to send it so if we look at that and say if you're looking at the cost of electricity if you're looking at the cost of data rate if you're looking at things that are changing in the external environment but the overall total cost of operation of the node then that is additional predictable scheduleable information that may impact how you want to make routing decisions"
  },
  {
    "startTime": "00:46:00",
    "text": "or just generally handle your data not all the costs are strictly financial and the benefits here may be that we choose to rank or associate cost functions with the use of links in a different way with the extra information next slide so again assumptions and benefits we would assume that if this were something that would benefit from TBR schedule like information we would say we can measure those external costs we understand our data rate usage or our energy usage uh the the changes in those costs are either predictable or scheduled or scheduled because they were predicted uh and that the cost differences persist for long enough and optimizing them has a savings that is big enough to justify the extra computation or work to figure out and make use of this additional knowledge but of course I think if you do that then you can come back with some benefits and say well wait a minute we can filter links uh that is a very this link was very low cost five minutes ago but now we're in on peak hours where we're about to go into overage and now this link might have a different higher cost either Financial cost or logical cost and maybe we want to think about it differently because of that we can also come back and say in certain cases maybe we want to plan and accumulate Data before we use a link based on its cost maybe we even want to look at the fact that if a link is high rate but we think that the good good put might be relatively low versus the throughput if anyone's ever looked at nodes who've spent a lot of energy trying to punch an RF signal through a storm for example maybe we wait on that for a variety of reasons and again all of this comes back to trying to get better data delivery and make better data delivery decisions next slide again for this one a contrived node one node two node three where we come back and say if we were to Simply on the vertical say cost High Low Time T1 T2 T3 across the three node Network those can change over time in this case maybe it's"
  },
  {
    "startTime": "00:48:00",
    "text": "spatially distributed nodes with the cellular backhaul and we look at how the topology does not change the links are still there but we may come back with things like well Node 1 to node two can be either low cost or high cost at different times and even perhaps in in this third case at the bottom you may wind up saying if I want it to be low from Node 1 to node 2 and low from node 2 to node 3 and it's something that's reasonable in your network you may actually hold on to it for a little while waiting for that node two to node 3 cost to be lower next slide then the last slide is sort of these mobile networks uh and obviously uh Leo satcom is is an example of that but there are others and and there are really three cases of Mobility but again under the idea of a solution for one might be a solution for many so we don't necessarily perhaps see them as three distinct use cases are cases where I have two nodes have moved far enough apart that they lose the ability to talk to each other or two nodes have not moved too far apart but they together are moving through an environment or an environment is moving through them such that they can't talk to each other or one of them has pointed their antenna somewhere else and they can no longer talk to each other all of those are Mobility based or motion based losses to a link next slide so again from an assumptions and benefits point of view if you understand the motion if you know where things are going with some predictability uh with Leo we tend to know where they are but we maybe don't know what's powered on or where things are pointed and or if you understand the environment which may be also impacting you then that is knowledge you can exploit to understand when an adjacency would go away understand when a link could come back maybe to even include that the resumption might be a different link than the one that went down which would be a useful thing uh that you can understand how your data rates would be adjusted and generally"
  },
  {
    "startTime": "00:50:01",
    "text": "you can use all of this for better filtering of the links as well Leslie so again in our Network Leo constellation if we have a couple of spacecraft and we assume that they have a different uh ground coverage over time for example spacecraft one is over ground at time three spacecraft two at time two and so on then we can sort of understand as this train goes by over the ground station in minutes uh we need to understand handoff and we need to understand that certain links are going up and down and as one spacecraft leaves the ground you then need to go for example to an inner satellite link to the spacecraft behind you so that it can keep that going back down to the ground and that's something you do because you can predict and you have a schedule to deal with that level of dynamic topology so that's 15 minutes on some high-level categories of use cases that we think would benefit from TBR and then I think after this we have a couple of deep dives into more specific examples okay great thank you sure uh thank you sorry I turned the mic off um Kevin is going to present uh next and he is remote Uh Kevin you don't need to share your screen we'll just pass you control so just hold on one moment Kevin can you uh say something to make sure we you we know you're here Kevin you may have to unmute your mic here we go Kevin wrong Kevin short"
  },
  {
    "startTime": "00:52:02",
    "text": "but Kevin we don't hear you Dan will you no different Kevin that's fall we're looking for short or to say that backwards um it's we need audio he needs audio don't worry about the slides just get your audio working and Dan if you would come up to be prepared to present just in case short yeah Uh Kevin you need to unmute we can see that you're muted I think maybe Dan if he could take over and then if we get Kevin if you get your mic issue sorted you can just start talking and we'll let you run cool um so while while we figure out um the audio and some slides um my name's Dan um with Kevin at Airbus I'm at Lancaster University uh we are introducing a use case next slide please uh there's already been a couple of mentions to sort of emerging satellite Club constellations you know the space-based use case it sounds extremely futuristic but of course these Networks are being put in space there are several large constellations with tens hundreds thousands of nodes whizzing around the planet at the moment they are um extremely small they're increasing in size and number they have multiple link types next slide please that we can choose in order to set up the physical connectivity so in some of the constellations there are high bandwidth interfaces uh on the order of"
  },
  {
    "startTime": "00:54:00",
    "text": "gigabits per second using free space Optics operating actually at speeds that are uh sufficiently are significantly faster than traditional sort of earth-based fiber-based systems there are also radio interfaces and uh uh those radio those RF interfaces are also evolving over time up to sort of gigabits and tens of gigabits per second in terms of building the the space topology we can continue through various space segments using uh interspace links isls but we also have the opportunity with some constellations to Bounce Down to the planet uh using base stations and in sort of several major countries there are often multiple base stations that can be used next slide please so what we need to kind of figure out is how we build this network topology given that there are several space-based uh segments that we can use as well as sort of dropping down back to um uh terra firma we know that these links offer different characteristics so there are bandwidths latencies uh potentially Jitter as well if you're a starlink user and and I am as well as a tester you'll notice that we have a lot of bandwidth and availability but actually uh there are cue issues and latency and unpredictability for jitta can cause a major problem for certain low latency applications next slide please so we need to figure out in advance how we're going to build our physical topology given that there are multiple links bandwidth constraints potential cue issues and also the amount of power available on some of these satellite nodes as well as of course the bandwidth that's going to be potentially available at a given point in time now this is a uh a network path computation problem"
  },
  {
    "startTime": "00:56:01",
    "text": "that can be solved with a combination of traditional techniques we've heard earlier sort of some linear Solutions like dijkstra you could of course use a control center with humans sort of biological path computation to do some offline planning to try to optimize your network what what we're looking for next slide please is potentially a method a process of building a network topology virtually in advance that can then be overlaid so we also need to consider that this isn't just a planning problem but it needs to react potentially uh to changing real-time conditions but real time is relative so real time for a fixed Network might be a few seconds or tens of seconds when you start losing an adjacency to a particular sort of next hot neighbor in your igp but in space sort of a real-time change might be over uh several hours as you're recharging a particular node in order to sort of uh gain power and then be able to light some new interface uh there will also be uh connectivity potentially coming Online predicted uh though that is not space-based but is high altitude so there are sort of UA UAV uh unmanned aerial vehicles that potentially can augment uh your network next slide please so we will need to build this kind of network graph including some sort of online capability with the ability to consider offline and maybe the definition of online and offline needs to be clear here for people essentially it's some kind of um uh entity that is talking directly to the network I suppose that's what I might consider online offline would be to pull out the traffic engineering"
  },
  {
    "startTime": "00:58:01",
    "text": "database run some uh evaluations uh create a candidate topology that that might be done in an offline uh instance and then I want to apply that at some point in the future but something has to kind of merge these two databases at some point uh and if we had Kevin online he he would probably talk about uh conops which is a form of sort of operational uh management that's done by a team of people augmented by heuristics or sort of non-heuristic technology so I suppose for some of these use cases the time Horizon is very different you know for a satellite Network we might be talking about minutes hours you know days during the chat someone was talking about uh deep space connectivity as well for for other use cases it might all be happening over several minutes uh or or hours and I know that you know we we get excited or I get excited about space-based communication but but the same Concepts and requirements also apply to things like rural internet where essentially you've got microwave links or indeed free space objects where you've only got these links available at particular times of day because that's when you can get enough sunlight like to power the interfaces as well but they're highly predictable because generally the sun will rise and set in the same location if it doesn't then we're probably in trouble next slide please uh and the Network Discovery building the topology analyzing the topology making the predictions uh building some future candidate technology and I mentioned in the chat that this this feels like or sounds like potentially a scheduled or excuse me scheduled virtual Network topology uh needs to apply to a variety of service types your users that are"
  },
  {
    "startTime": "01:00:00",
    "text": "actually attaching to the network and those you know those are listed there for sort of space-based marine uh high altitude uh unmanned aircraft next slide please so what would we like from TBR and of course this is sort of walking into a toy shop and saying well Dan you know choose anything that you want I'm going to try and grab everything I can knowing that there is a kind of reality um question that we need to apply here and wanting to kind of minimize potentially the amount of state that gets created and potentially injected in a in a routing protocol that's going to be used in an online function so bear with me we've just kind of Kevin and I have put everything potentially that we would like here but there has to be a method of exporting or retrieving information from the network discovering capability understanding what metrics we will need to consider and it's all of the standard uh sort of routing metrics that we might want in terms of latency bandwidth Etc uh costs but cost might also have a physical element to it in this case so there'll be a network cost and maybe a fiscal cost of powering a unit versus choosing a particular link uh we will need to consider the sort of the resiliency here as well there's a restoration uh consideration uh not only does the generation of a virtual Network topology or some candidate future topology need to be considered but it needs to potentially uh uh react to changing Network conditions in the event of some kind of catastrophic failure such as um uh the removal of a node or degradation of a link we may need to switch over uh and that that could be I think someone mentioned earlier uh occlusion"
  },
  {
    "startTime": "01:02:00",
    "text": "you know which which may be weather or or or some other sort of debris that's getting in the way uh okay so I'm just looking at the time here as well so maybe our stock because there are going to be commonalities with some of these requirements across the other use cases are we taking questions now are we saving them for after the I would prefer to save them but if you have a clarifying question please come on up or come to the queue and Eve if you get ready for the next one thank you I I think we're going to have some good discussion on the um gaps and mechanisms so I want to make sure to reserve some time for that all right Eve okay can you hear me yes you sound good thank you perfect okay so I will extend this conversation by talking about something we've begun to call carbon aware networking uh which we believe uh solidly Falls within this discussion around time variant routing as an example of an environmental impact use case and I will tie it to um one of the use case categories that Ed so clearly talked about next slide you have control Eve oh I have control I do I don't think I do oh I see okay here we go I do have control all right so the backdrop here um is that uh for anyone who's been following the UN intergovernmental panel on climate change um there's pretty dire urgency to uh try to meet these thresholds that are out there after which you know we really can't even model what the consequences are going to be and uh in the most"
  },
  {
    "startTime": "01:04:01",
    "text": "recent reports uh those recommendations and reports have been called you know code red moments you know we're really at a Tipping Point and so what can all of us be doing to um uh be more considerate uh about uh climate change and greenhouse gas emissions and if you look at the information communication Technologies contribution to those emissions uh it's fairly sizable and growing and some estimates are that at least the electricity usage by ICT is between will be between two and it's about two percent now but by 2030 will be about six percent of all Global electricity which in turn has a carbon footprint although data centers get all of the attention in terms of their footprint the network impact Rivals that of the data center and in some estimates from the itu which typically makes these reports and Publications on a regular basis the network is at least as large and as uh sometimes as large as one and a half times the size of the data center in terms of its footprint carbon footprint um there's also the recognition that there is um an increasing tidal wave of data that gets generated by all the things that are connected to the network and it's almost as though the only way we could get to a situation where we have carbon neutrality or Net Zero impact is to not just consider Energy Efficiency of our products and components but to really think about the coupling of Renewables with all of our infrastructure uh and additionally when you think about what is so disruptive about this is that if we're going to be moving to clean energy to address the issues of greenhouse gases I'm hearing an echo I don't know if others are hearing an echo"
  },
  {
    "startTime": "01:06:01",
    "text": "we're not sorry oh okay um that uh to move to the electrification of Transportation hopefully clean electrification and transportation we're going to need about four times the amount of electricity that's currently being generated and some estimates are that that's going to entail about 20 times as much infrastructure that's already out there so we're at this very interesting uh moment we know that there's going to be a long Arc of rollout of this infrastructure and so in that time and and we may never get to a fully renewable or clean energy oriented grid um and and even if we could there was going to be this long Arc of infrastructure rollout and even longer amounts of time than uh how long it takes to roll out Telecom or Internet infrastructure and in that time we want to be thinking about well how can we steer our usage of electricity to be uh the least impactful um and there is this metric that is quite interesting which is uh carbon intensity which is a measure effectively of how green is the electricity and we've been talking uh Rick and I and other colleagues at Yale University in Oxford um about the what-ifs behind could we add to the performance metrics of networks which are typically uh described in terms of their packet loss their latency and their Jitter what about if we could describe the performance of the network in terms of not just its energy usage but also the greenness of that energy and carbon intensity is better when it is lower um and so if you were to think about sort of sustainable networks you'd want to be thinking about how do you design them so that they"
  },
  {
    "startTime": "01:08:00",
    "text": "consume less energy how do you decarbonize the electricity that they do consume and then there are other kinds of actual environmental impacts which we're not going to get into today um that are other concerns um that are things like around water and waste and uh chemistry and things like that um now we're inspired here because uh many of the hyperscalers are adopting techniques called that they are referring to as carbon aware or carbon intelligent Computing where they are physically time and space shifting their workloads so that we place them in places where there is the least carbon intensity and the attempt here is as stated earlier is to maximize the usage of Renewables like solar and wind alongside of other things that are considered clean energy when we look at them from a greenhouse gas emission or carbon standpoint there's also another interesting phenomenon happening that um if you look at places like California and Germany parts of the globe where Renewables are being integrated at uh um accelerated pace and consume or at least deliver over a high percentage of the electricity in the grid unfortunately there's a mismatch between the supply and the demand for that electricity and so sometimes there's excess Renewables being generated um and that go wasted as a consequence uh and so what the data center community has begun to do is to use the data centers themselves as a virtual battery of sorts so that in moments where there is an excess of Renewables that time elastic workloads are sort of on the ready to absorb that excess"
  },
  {
    "startTime": "01:10:01",
    "text": "energy um so naturally the question is well how does this relate back to what we could be doing with networking and we do believe that there are carbon aware techniques um that we should consider adopting um and that when we started to look at this problem we naturally thought oh well clearly we want to take routes and we want to Route our data Transmissions through parts of the network where there's the greatest carbon efficiency so where the carbon intensity would be lowest uh but there's also dtn like uh time shifting that we could also leverage here um several of us who are part of this conversation also come out of the deterministic networking community and uh there is the um ambition that uh for this kind of traffic engineering we'd like to also be able to guarantee that we stay below certain thresholds along Pathways in the networks and even go so far as to Ponder could we be reserving resources whether those are battery related resources or predicted availability of Renewables along those paths in the same way that for example uh in the detnet community we talk about uh or at least in the time-sensitive networking Community we talk about reserving buffers along Pathways in order that our our packets don't uh confront to any kind of congestion along those paths so that's the equivalence there and then finally in order to do some of this we really do need Telemetry and how do we make that Telemetry itself as a workload be carbon aware so I uh I was inspired by Ed slides and so I um you know I I kind of I took his"
  },
  {
    "startTime": "01:12:01",
    "text": "example of you know sort of providing this overview of you know I believe that the carbon aware networking Falls squarely in the operating efficiency use case um and that we could comprehend carbon intensity as part of a cost function for links uh this the the reality that we have batteries uh in many situations uh not just virtual batteries but actual batteries also means that there's shades of use case one about resource preservation that we could leverage because it may be the case that um you might want to opt for battery operation when the battery has a mix of electricity whose carbon intensity is less than the carbon intensity coming out of the wall socket and something I won't really get into because I really haven't thought about it really deeply enough but there is this cons this possible shade of use case three about mobile devices that we can dispatch mobile distributed energy resources whether those are energy generation or storage in the places where they're needed and this is something commonly uh that commonly occurs in the event of emergencies for example but um how it relates back to TDR is um we recognize that there are causes for the loss or reappearance of adjacent lengths that are related to external environmental factors such as the sun is shining or the wind is blowing or these thresholds that we've talked about either those have been exceeded or were staying beneath them for carbon intensity and clearly there are benefits because the expected loss of links are not seen as errors but as optimizations and that the resumption of these links is not about the ReDiscover rediscovery from scratch but they are waiting um on standby this is of course I went back to Ed's slide unfortunately a slightly earlier version of head slide uh but but the"
  },
  {
    "startTime": "01:14:02",
    "text": "point is that um uh it is really to ask the question whether this use case meets these assumptions and I think to a large degree it does uh we believe that there's measurability that there's predictability in scheduling um when these cost changes occur and we can communicate that in advance um and uh that you know here's something to to consider is uh how often are these changes to the topology that is in part a function of how often something like carbon intensity is shared uh by the utilities um and uh what we can come back to that in a moment um but there's also the question about is the cost of the savings uh does it justify the effort or the work that we're going to do to enable this um one data point is that uh in the recent California temperature um uh during the summer in California that we had a Spate of temperature and weather that the utilities you know reached out to the to the populace and said could you please not use your electricity and someone turned around and you know did a Model uh given the amount of electric vehicles that we have and the battery of availability could we avert blackouts and the cost of that to in the you know to the economy and so something like that might be a way to quantify is what we're doing um beneficial enough uh I think it's hard to to uh specify completely what's enough but we can also come back to that but um the in terms of the possible benefits um I think that it also matches up quite nicely I didn't I don't believe that it uh has this property about first planning"
  },
  {
    "startTime": "01:16:00",
    "text": "um one interesting facet in terms of the environmental measures is we are going to face some regulatory pressure so again there's going to be some carbon taxes and so some of this may be around um are there um are there actual costs Financial costs that are can be associated with this problem that also were part of the link state not just Environmental um as I uh intimated uh carbon intensity is not something that Network operators own it's really the utilities own this and uh there are issues about how granular uh the areas or regions are within which carbon intensity is derived and actually exported and shared the frequency with which it's updated and what parts of the world it is actually being openly communicated to uh Beyond just the utilities um there's this subtle interplay between the batteries and the electricity generation that we'll have to deal with an SI intermitted the justification of function is something that needs deeper analysis I think that is it um there are a few other resources if you'd like to read more about sort of the whole state of carbon responsive Computing and uh towards carbon aware networking and um I think we are now uh we can open up the mic for all three presentations yes we have about uh seven minutes or so for discussion on this topic we're going to reserve time uh for discussion we can't hear you I think you had turned off the mic because of the echo foreign can you hear me yes I can't I can't but"
  },
  {
    "startTime": "01:18:02",
    "text": "you're very quiet thank you very much I think I think this working group is uh interesting and I'm willing to uh to help in working in this group but I still see that the the solution or the proposed solution is not clear I uh from the beginning or the first presentation it considers only or saying that that it's varying the metrics or changing the metrics for the a routing protocol uh it's not much clear I think maybe I can propose that either we say that changing or or a scheduling change of some kind of algorithm is it are we changing the algorithm or only the metrics at least we be clear on that also because and also we need to clear on the conditions or that we can say initial conditions for this kind of variation uh to to and also we should consider the stability of the routing routing mechanism so that's my comment and thank you very much uh things I think that in the long term what we'd like to do here is to Define models and stuff of course it's up for the work group to decide what the actual scope is but to figure out what the models are and what needs to be done and kind of push it back to the routing area routing the specific routing protocols to figure out how to represent those things and how to deal with them although there may be offline components as Tony has"
  },
  {
    "startTime": "01:20:01",
    "text": "said in the chat and other things that we need to deal with but I I think that you know we're trying to just get to the point where we have a good solid set of use cases before we deal with Solutions so uh danbogganovich so this topic is starting to show up in the ITF for the last few meetings now and uh it's a big multi-dimensional problem I'm not sure that the ITF as a community is the best community to deal with uh all those because we don't have the expertise in some of those dimensions but maybe putting that into the irtf I think it would be a much much more uh much better place to deal with that until the problem has been defined at the technical level what we could go down and solve being like much more specific Miss luberger speaking as contributor I I completely agree there's there's a a lot of issues here and one of the challenges for the routing area is going to be what does a routing area do I think another and there was a side meeting from the transport area yesterday is from the transporter area they're going to have a question of what do they do you know so it may not just be one working group but it may be multiple because as you said it's a really big problem it's a really big problem you have to define the policy and how to enforce that policy over the network but what is the policy that you want to enforce on the network Dan uh Daniel King so with the greatest respect I have to disagree with Dean it wasn't actually my intention for coming up here but I don't see this as an iotf problem I see this as a an engineering problem and I see this being applied to existing infrastructure that's out being used commercially so that that's just my"
  },
  {
    "startTime": "01:22:01",
    "text": "thoughts there the the point for coming to the mic was um thank you Eve for your presentation I see um some sort of commonality in terms of requirements for the area the use cases um that you mentioned there we we've got a internet draft it's actually in the I think the routing area so I wonder if we can work offline to kind of sync um some of our requirements and figure out the best way to kind of publish that I suppose some of that may be dependent on the conclusions that we reach at the end of the session today as well thank you Mallory okay hi Mallory noodle Center for democracy and Technology I just wanted to support this work um and thank you Eve for your presentation um I do I'm also agreeing with others in saying that I think the these topics have to be mainstreamed and a lot of the ietf and we shouldn't imagine that they should only happen in one place so that this work is happening here makes a lot of sense I did want to also point out that in the irtf we have had we at least had one and recent presentation although we've had some in the past from barath ragaven who came to talk about the ways to reduce the footprint so I think some of the metrics that are given around to you know how much electricity is needed and so on I mean it doesn't really address the fact that sometimes the source of that electricity is also potentially um a problem and so accounting for that I think there just needs to be a general approach to reduction and minimization um because that's probably the best direction of travel so but thanks again thank you Lars hi uh Lars Eckert so um since we're going down the scoping discussion rule I I want to suggest to a a principle that"
  },
  {
    "startTime": "01:24:01",
    "text": "we might use to scope Auto narrow the scope and and maybe see if that sort of has some agreement or not so I heard the Monet use case being brought up so in my mind right so the internet we run routing and then we run transport on top and transport basically operates on rdt time scales and if routing also starts to operate on rtt time scales we actually don't really have a transport thing that we know of that will operate on top of that so I wonder if we could limit this proposed work to the space where changes to the topology happen on you know time scales that are a factor X for some number of the you know 90 percentile rtt or something like that so it's you know there's a certain expectation that the topology isn't crazily changing all the time right it's it's generally stable and maybe you can predict when a change will happen and so you can when you have a path you can run a TCP style transport over it I think that might sort of get us in a box where we might know what to do about for standardization thank you yeah that's a helpful comment uh Joel Halpern made a similar comment in the uh chat that you know are we talking minutes microseconds nanoseconds and you know the general discussion there is as we're talking longer periods and scheduled uh scheduled items that are maybe minutes hours longer depending on where you are um so that's a helpful comment with that we're going to move on to uh Rick he's actually going to be the last sort of formal presentation and we've reserved an extra 10 minutes we had more when we started but we were served after 10 minutes of discussion and um it's probably best just to integrate it into uh his talk into the later slides uh Rick over to you thanks Lou for saying formal I I rarely do anything particularly formal so um yeah this is almost a continuation of of where I started and and I hope addresses last Point directly and I I think I'll try and make comment to Dean as well"
  },
  {
    "startTime": "01:26:00",
    "text": "well what we go through so down while we go through this uh next slide please so I started this this kind of goes back to to where I started with my thinking of my discussions were there and various others about this too I believe there's a kind of a spectrum of of routing environments which goes from the very fixed never change doesn't actually exist environments where we're talking about um ISP backbones cloud service providers that kind of stuff it's big it's stable it's manageable it's expected when you put a link in somebody's actually laid down something physical and plugged it into something else physical you expect it to still be there and at the other end of the spectrum you've got swarms of uavs buzzing around in an uncontrolled environment in the middle of a thunderstorm in a war zone you know that that world's worst ad hoc everything is in complete chaos contested environment but those aren't just two use cases that I believe there's a spectrum and I just want to kind of look at the two extremes of that and introduce the idea that I think there's a there's a either a second dimension to this or there's there's another environment where I think TVR lives so next slide please so really if we look at the fixed environments there's some general assumptions which is nodes don't move around if you put something somewhere it's going to stay there things have a well-known connectivity to their peers um yeah the links to the peers May Fail but appear on the other end of that link is going to be the same pair it was when you started because that's how you configured it or your auto configuration system kind of found it and found it was there um and Link service is maintained by reactive re-routing and the key point is it's it's rerouting so something fails we'll go around the problem and we will"
  },
  {
    "startTime": "01:28:00",
    "text": "maintain those end-to-end paths but we will react to that failure and this ties back to what I was saying at the beginning and the fourth point is links are expected to come back so there's active monitoring to say is it back yet is it back yet or and yes there are more Advanced Techniques around that but fundamentally when your link fails in these fixed environments the expectation is it should be there so let's let's try and work out when it comes back so that we can reactively reroute to it when we spot it come back nice and promptly and and get back to that stable thing that the sysadmin wanted to happen and it's it's kind of the mindset that has influenced the design of those protocols and you could say it goes back to the early days of of arpanet and academic networks where people built it in a lab and you knew box one two and three because you put them there and plugged them in it was kind of that mindset behind it and yeah we have a much more mature Ops derived view of these things and say yeah things do fail things do get swapped out through things do get upgraded but that General assumption about stability permeates the thinking of of the routing protocols in that area and without I'm not trying to to say any of these things about I think they're fantastic by their their persistence and Longevity you know we're talking bgp and rspf and Isis and and even I'll point the finger at BFD here to say it's a great technique for getting prompt recovery but you are reacting to a failure and trying to recover quickly and BFD helps you do that so the key issues and I kind of touched on this earlier but I'll repeat is that when you're reactively re-routing you will always have loss even when you knew it was about to happen because you are reacting to something happening and going oh God it's gone right oh we'll go this way it's fine or luckily I you know there is"
  },
  {
    "startTime": "01:30:02",
    "text": "still that loss while you switch they're an opportunity to do something seamless because you knew it was coming is missed and the other side of it is that proactive monitoring piece if you know it's not there and it's not going to be there until tomorrow why are you monitoring to see if it comes back yet it's just it's just a bit wasteful and using going back to some of the use cases that the aired and and Eve and and uh Kevin it is Kevin isn't it yeah uh the Kevin presenter and Daniel presented um some of those environmental resources are really important some of those environments the fact that we're even burning these resources is is important in a larger sort of global scale and I'm a computer scientist I don't like wasting compute you know why have I got an inefficient algorithm doing something let's just be purist about this so there's lots of lots of reasons from different aspects about wasting resources is is not a good thing let's go to the other end of the spectrum so next slide let's look at man a and this kind of comes back to lars's point where there are environments where everything is wild so nodes move randomly within the topology because they may be physically moving they may be doing crazy things at the link there which causes all sorts of stuff to go on links are frequently break that's a general assumption in in the world of mobile ad hoc networking your links they're not going to be stable they are pretty much uh you know as I say links are considered ephemeral effectively so your network save service just like the fixed environments it's maintained by reactive rerouting I found a new opportunity I've lost an opportunity I'll quickly rebuild my topology I may do it in very exciting and funky ways because many tackles this environment um that may be considerably less efficient than link state routing but it"
  },
  {
    "startTime": "01:32:00",
    "text": "will work in environments where link State just doesn't um but it's still fundamentally reactive rerouting you are reacting to some break in your current assumption about your end-to-end path and you are therefore desperately trying to work out some alternate way to re-establish it and links as I said are considered ephemeral and therefore adjacencies are proactively discovered so you'll see if you do sort of read through most of the many protocols instead of understanding that the peer on the other end of that link is expected to be there and let's try and keep that establishment going BFD style or or you know however you want to do it your TCP keeper lives Etc um you'll see a lot of the man a protocols will do things like uh active discovery of oh there's other new peers are the peers I was expecting still there have any peers disappeared since I lasted there's a lot of helloing a lot of two hot neighbor Discovery it's a very interesting things but it's active there's no idea of stop looking your radio is silent between now and Wednesday um and therefore you have the same problems which is the reactive rerouting and this is more important to many environments where you probably are talking constraining devices you've got that little loss because you've lost that link quick rethink oh oh it's that way there's a loss there and to go back to the point of you could accidentally form micro Loops because several things could spot that link fading at the same time which means that initial stab at oh it'll go this way could well be wrong and then you get corrective and loop avoidance and loop back off kind of algorithms which are exciting but you haven't got a stable network service while all that's going on and again you've got that proactive Discovery rather than proactive link re-establishment which is wasting resources and particularly in the Mana environments that's not a problem so you'll note that the key issues have"
  },
  {
    "startTime": "01:34:00",
    "text": "kind of been copy and pasted between these two environments because I think they are common problems to both of them next slide please so third answer that came out on the list is people said oh well dtn can solve this if you've got link outages we can do store and forward it's great we don't have to worry about the fact we can we can while we try and work out what the next thing is if something goes off for two hours dtn can save us dtn is great I am a chair of dtn and I can tell you dtn is great but it's a transport protocol it's for delivering data it doesn't do routing in fact we it's actually out of Charter at the moment for various iotf political reasons but well for scoping reasons not political reasons there are problems we still have to solve before we try and solve routing and if TVR can come up with some of the routing problems dtn will use it dtn isn't an input to TVR dtn in fact would like to see the outputs of something like TVR so that kind of implies why I've started having these conversations at all um however there is some interesting research that is not happening with the ietf and experimentation and actually I think field it I'm looking to see if anyone who knows this is willing to nod if any of this is live uh particularly around uh what they call contact graph routing so that's an understanding that at a certain point in time two neighbors will see each other and therefore we can start moving dtn uh bundles their sort of jumbo packets between them and that's now become uh documented by uh ccsds which is the space governance community and called saber because it's a great acronym um schedule aware bundle routing and the reference there for anyone who wants to to look at it and it's what I find interesting is other communities they are aware that having a schedule and trying to move things"
  },
  {
    "startTime": "01:36:00",
    "text": "around based on the schedule is a good idea so again this is underlining going all the way back to Kevin's point which is this isn't new and I think that's a good thing because it kind of underlines that I think we've got a problem here so Keys is about gtn it's not a routing protocol and the second point is it doesn't actually deal with IP um for those who are unaware of dtn it's got its own sort of jumbo packet format called a bundle because because of the nature of what dtn is and please come to our session at one o'clock it's great and learn all about it anyway so that brings me on to really the potential work items because if we're talking about forming a working group we ought to have some kind of discussion about what we should do I think we should have a formal use cases document it makes sense uh I am a huge fan of um putting fence posts around the scope is how I like to describe it so you know quite clearly what's in and what's out because it's written down somewhere because it kind of allows people to have a common view about what we're trying to achieve here so problem statement use cases that kind of thing to make sure I just speaking as a chair it's really helpful within a working group to be able to say great conversation not in scope let's get something to describe this bit because it most definitely is in scope so I think use cases document is useful I think we should look at a general purpose solution for time variance and coordinate with other working groups who have the expertise on particular routing protocols I don't think it is correct or effective for a TVR working group to say we will write a bgp extension of some sort I think that's completely incorrect I think the TVR working group should look at"
  },
  {
    "startTime": "01:38:00",
    "text": "understanding time variance and its impact on routing and there's already discussions going on in the chat about what is a schedule what should go in a schedule is a schedule a good concept how do schedules get merged between nodes we can solve that without looking at the particulars of individual routing protocols but once we understand that and we've got information models we have an understanding of what we will support with these schedules um are we talking about link stuff or are we going to talk at the end-to-end service you know there's some interesting topics here once we've got that we can go out to the next date routing groups um Pym if we want to touch multicast you know some of the many groups uh whoever and say if have you considered time variance as part of your protocol stack if you have not here is some information models that we and some functional operations around the creation ingestion introspection updating whatever of these information models that you might know an elegant way to include into your routing protocol using your relevant LSA tlv whatever you're using within your protocol stack so it's don't do it here don't boil the ocean in summary so I just I know I'm running late and I'll be quick what I did want to write down is what I think is out of scope because this again is part of putting some fence posts and this is personal opinion it's a routing problem yeah it'd be great if applications knew all about it yeah it would be great if we could get into all sorts of other things but I think we have to start with step one which is latter three let's get let's get the routing working because everything else will build from that um and therefore I think the following things get chucked out and it doesn't mean that they're not really cool things to look at I just think they're part two or three or four"
  },
  {
    "startTime": "01:40:01",
    "text": "store and forward uh gtn's doing great stuff at the transport layer let's not go there that doesn't mean talking about buffers and understanding the transition when something scheduled happens isn't in scope but let's not talk about oh we could hold data for a very long time and then move it please leave that to transport and dtn at the moment I have the discussions but I don't think I don't think it's go anything to do with making transport protocols schedule aware should definitely be a part two in my in my opinion I don't want to start touching the transport stuff tuning um tcp's behavior when you know you know something's going to fail in in 20 seconds please don't go there I think I mean great fun but we won't achieve anything you know it's a hard hard topic and I think we need the groundwork before we can sensibly start addressing that um I don't think it's worth getting into and I've said this earlier how we create the schedules how we do the prediction I think we should start at let's pretend we have a a prediction let's pretend we have some kind of schedule can we talk about that and then other people go back to your day job and work out cool techniques to create new schedules great fun stuff but I out of scope almost for the ietf definitely out of scope for a for a working group who can achieve things I'll go and quicker multi-custom multipath personally they seem really hard love what's the last bullet these are really cool topics but I strongly suggest we focus on the basics first the end yeah yeah no no it's absolutely fine I was repeating myself uh hi Kevin Paul um so I after lars's comment I it struck me"
  },
  {
    "startTime": "01:42:01",
    "text": "a little bit that given what's happened in this kind of area in the past we when when dtn work was a research group topic we intentionally confused the acronym in its definition so that the D could be delay disruption whatever we want to have some research on would sort of be in scope and I think what I'm hearing here is that oh that's like we don't want that for sure and so what is the scoping definition so I think Lara said was sort of on the order of an rtt maybe and and so I guess to maybe try to refine that might be useful what what is this covering and so just to throw out a couple uh you know so there was the use cases we had space and so on there's been underwater networks the prop the prop delay is five you know five orders of magnitude worse than it is on RF propagation so that's going to affect you know if you had rooting updates it would affect it would that be the type of thing would be in or out of scope because that's a world where you could have an end-to-end connection from the sender to the ultimate receiver but the properties of the network underneath are pretty different than what we would normally do so I I guess what I'm I'm not saying that's the one to worry about but there's a few other features when you say you know rtt that needs to be decomposed a little bit to mean like well really what what is that and and then if you're going to separate out the storm forward layer which is okay I suppose but then uh it would be interesting to to know what the communication if you will API is between those because scheduling you know back to the dynamic transship and all that stuff that's very interested in knowing what paths what links what places there are what storage facilities there are along the network and one other one that I don't think we heard about is like properties of nodes along the way and so at some point we had discussed some nodes being more reliable or more secure or located in certain geographies we trust or don't and so on and that would affect the routing"
  },
  {
    "startTime": "01:44:00",
    "text": "decision as well and maybe that's an out of scope but all these a lot of richness had been discussed over the years and what you might want to use in your routing decision it's all right I think we're not going to have time to go into all the questions but I think we should capture them and say these are items that we need to address as part of the working group or in scoping the working group so uh thank you for that I think I got some good notes on that please check the the notepad to make sure we we got it correctly uh Brian hello um one other thing that hadn't been discussed so far and is more of a gap analysis than a use case is on the management side uh there are things like netconf that have a candidate data store versus a running data store so there is a variation that's allowed but you can't schedule it and you only get one of them and so when the concept of multi-tenancy management comes into play um it really throws a wrench into things because you don't want to have to have a separate management Organization for every single time something might change in the future so just to ground some discussion in why you'd want to have a schedule for multiple things changing at their own at their own time rates yeah good comment uh in one of the earlier working groups this week someone pointed out that uh there was a a working group that spent a lot of time talking about how to document schedules so you know there are good building blocks in other working groups that we definitely can can Leverage uh next doorless yeah thank you very much um so one of one of the questions we usually or I'm trying to web out my mind is how do we get from here to some running code that does something useful right and I haven't seen very little unfortunate in the presentation that would give me a"
  },
  {
    "startTime": "01:46:00",
    "text": "really good hint for that if the you know way to get there is really mostly building a system out of mostly existing components in the ITF plugging them together the magical sdn controller that solves 99 a good amount of data models and then some app use of the routing system um that that would be something that would be really good to show in some examples that that's the goal and then I mean we've got the example working groups that have done this kind of trying to use some build something useful with minimum additional work combining what we've done in the iitf my own animal working group probably is something like that right so 99 of was just plugging together things still a lot of work um so I'm not sure if that would then go into routing or Ops like they put enema into Ops right if this is really a little bit more fishing and we don't really know if we can come up with a such a big uh you know system design or um something that really we are very certain will give value then now we also have fairly good experience I think by now with the special interest group model that we're using in so far primarily in Ops with Mobs and iot Ops right so but that puts you into more constraint about what your supposed and able to write in rfcs so just as process recommendations of where you might want to look into going the next steps making proposals toward some form of a working group yeah thanks for that Toro us certainly after this meeting we're going to take all the feedback work with the ad the isg um and needed the IAB on what's next what you see here on the screen actually came with input from Alvaro of make sure that what we come up with is attainable and actionable right you know we we can go deliver something and it's a probably a a Yang model or an information model uh and we get when we succeed at this we can talk about what happens after that"
  },
  {
    "startTime": "01:48:00",
    "text": "yeah so just as a personal contributor I like the components right but I'd be a lot more happy if is there some place that says and here is how these components can be mixed together to build a system that actually delivers value because just starting out throwing components you know against the walls I see that it's required but not sufficient right I I would see that as an objective you know it that comes under the approach framework result it shouldn't just be here is some stuff it should be here is relevant pieces and how they go together this is almost a recipe for you so um I I like this this is really cool stuff and uh we should definitely do this has a lot of um interesting different use cases and uh yeah I mean we should go ahead um the only caveat that I would put on this or a sort of little worry um is that there may be some sort of a chicken and egg problems hiding here and I I actually cut on on the line before uh before the statement was made about uh schedule creation being out of scope and that's a cute thing and um indeed like the like you have this local and Global Optima and you deciding what you're gonna do with your node may not actually like your local optimization may not be what you actually want for a lot of these cases particularly when it comes to things like energy and energy is also sort of an interesting complicated case because you have so many like it's it I suppose noted it's pretty broad so you have you know different aspects to worry about um but also that you have different techniques you have um for instance implementation techniques where you can put nodes into a relatively low power sleep states where they can still act as part of the network you don't have to tell anybody that you're sleeping but but you can still save a huge amount of energy or you can be sort of totally off and um and not"
  },
  {
    "startTime": "01:50:01",
    "text": "um not respond to anything and then you have to tell the rest of the network so I think some of the use cases are sort of really straightforward that like a satellite is forced to go on a rotation around Earth and you exactly know what's going to happen some of the other stuff where you start to compute that well you know there's these criteria and these cost and and so on and they interact in interesting ways across uh parts of the network then that gets more complicated but uh yeah so my advice is to stay as focused as possible don't try to solve everything just like the really simple case and deal with that and let's move on thank you Adrian hi Adrian Farrell thanks to the uh proponents and the chairs for really putting this together um I want to agree and disagree with Lars I want to agree that um there is part of this problem space is the time variant provision and awareness of service points and uh um direction of Transport paths and I want to disagree because I think this is about packet routing and um reaching inside the network uh and you know the the transport is an overlay over pocket routing and um we need to look at both of these problems or maybe all three of these problems in our analysis and work out which ones we are solving and then work out where to solve them and not just use the existence of one problem to say well you can't talk about the other problem uh thanks uh they are more Dynamic so just to clarify my previous Point time variant routing is an interesting problem but let's not it become kitchen sink for everything else"
  },
  {
    "startTime": "01:52:03",
    "text": "very clear problem that you want to solve and that we can solve for mesh networks so as long as you have a finite topology that you are managing that's a single management domain then having a number of variations of your topology that will be changing on the schedule whatever their schedule might be that is being defined by that one management domain owner that's a problem that can be pretty well defined but if we try to and all other possible things in we were getting over can I respond quickly yeah I 100 agree with you for two reasons that's about as quick as you guys oh no I'm going quicker we're out of time so you can't schedule the whole internet and second of all we only have bandwidth to achieve something achievable so let's try and Achieve that yeah in full agreement uh Colin and I saw Lars come up and I don't know if you want to preempt the queue blockage okay okay hi uh Colin Perkins um conferences with no hats let's be clear this is an area where obviously there's been a lot of previous work and a lot of previous research um I um agree that it perhaps seems reasonable to try and explore uh whether we can do a focus standards activity here it's time to maybe narrow this work down and see what's feasible um I think I'd Echo uh I think it was the comment allows me made um think about the amount of time variance and the amount of Link latency you have in the network and draw bounds around what you're going to consider because it makes the scope fusible it also tells you whether you need to solve the transport problems or whether you can use existing transport"
  },
  {
    "startTime": "01:54:00",
    "text": "um I'd also say there are obviously many different types of time varying networks um you know the lower phobic satellite someone which seems popular these days um Kevin I think mentioned underwater networks um some of these have a radically different properties and need ready you know radically different amounts of domain expertise so before picking a particular scope over the edge the group to make sure it's got people with the relevant domain expertise just in case you accidentally missed something yeah that's certainly a pretty important point about make sure we have the right people so we have uh six minutes left the plan is there's we're gonna do three polls they're already in the chat if you want to see what they're coming them coming and then we're gonna turn it over to uh ask the ad and our IAD advisor if they have anything to add and then we'll probably close out no we definitely will close out sorry I should say probably so I'm going to get the first poll going foreign could you put the polls on the screen yeah getting there sorry so the first question should we be working on this in the ITF um we're getting I think a lot of positive response certainly more than half the room has said uh yes a few have said uh I'll take the lower the hand as no but I think that's uh that's pretty pretty clear we're going to move on to the next question"
  },
  {
    "startTime": "01:56:04",
    "text": "the next one is is do we need a new routing working group routing area working group to work this problem that's not to say there won't be other working groups in other areas to deal with like transport but we're focusing on the routing piece which actually I agree I don't remember who said it might have been Adrian we're about delivering packets new group and routing area is the question do you think there should be one so again we have a good percentage of people responding that's always a good thing but this time we have um more of a split but still the majority are saying yes we're going to move on to the last question which is almost the most important one if I can find the button foreign are you willing to contribute and contribute can be a reviewer it could be an author but basically show up and do work if we don't have this there's sort of no point in the other two questions oh so I think here too it's very similar"
  },
  {
    "startTime": "01:58:00",
    "text": "although there's um I'm actually a little confused by the results um because the previous one it felt like there was more opposition and this one we have like more people say they're willing to show up and do work so uh I guess this is the the most important item so um with that uh with that I would like to so um so I see a iesg member getting up at the mic I'm going to ask if he's asking is is he coming as iesg or okay if you're coming as isg go right ahead if you're coming as a contributor please sit down sorry um I think we just need to be to remember that you know obviously these aren't votes you know they are an education and I think my reading of this and this is from what I'm seeing here is that people are saying maybe it shouldn't be in routing for the lost one but at the same time if it is we're still prepared to work on it that would be my how I would read that um yeah so that's just from you know from an ad perspective how we're evaluating this that's how I would read that reasonable because for example I think the answer is we should have multiple working groups because I think there's multiple problems so I could see if someone thought it was either or uh that so with that I with that I'd actually like task Alvaro and I think Valerie I think you're our uh IAB advisor if either of you would like to say anything and if you don't that's okay too um sure um unlover the Thunder Road Andy uh first of all thank you everyone for coming today I think uh 134 people still at the end as uh a lot of people it uh confirms one of the reasons why we wanted to do this buff is their interests in the problem and of course"
  },
  {
    "startTime": "02:00:02",
    "text": "the poll have demonstrated that there is interest people think there is a problem to solve people are willing to to contribute uh thank you to the chairs of course for running this to the proponents um everyone I'm gonna just say the the obvious that everyone has been saying uh we need to scope down the problem uh this was a non-working group forming buff which is precisely to gather use cases to gather interest the area of potential application of TBR as everyone has said already is very very wide we need to narrow down we need to scope whatever we're going to do or can do in in the routing area or potentially elsewhere to things that we can deliver that we can work on they're going to be clear um so that's what I would like to see being discussed in the main list going forward what are the I don't know one two three whatever deliverables that we can go uh and try to move forward um and as we see that discussion we're going to evaluate that and figure out what what the next steps are going to to be after the discussion so again thank you so much thank you Mallory noodle Center for democracy and Technology um I think Russ also was here from the IAB and so um it's not only me um but I guess some of so because I'm not a domain expert um as I sort of look at the baf um some of the questions I recall from the things we evaluate are gonna I'm going to focus on where else is this work happening I I saw earlier in some of the presentations some of this is itu related um all of that is going to be really helpful information um for for me as I go through that questionnaire so anyone who wants to um yeah I just I would say I will appreciate anyone who can respond for to some of my questions maybe I can talk to you all as the um delegates"
  },
  {
    "startTime": "02:02:00",
    "text": "um about about those sorts of things that I don't quite understand but that's sort of the nature of the review that we do but it's great to see all the interests I think that's a strong sign thanks uh thank you certainly I'm uh we're happy to talk with you offline and anyone to follow up I put in the chat the link to the group area you can find there the archive as well as how to join the list uh please join start contributing uh it'd be really appreciate to continue the good energy that was here today on the list and we'll work with the isg and the IAB on on next steps and uh thank you all for I think a very successful uh session of TBR hopefully see you in Yokohama [Applause]"
  }
]
