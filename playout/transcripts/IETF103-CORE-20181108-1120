[
  {
    "startTime": "00:04:35",
    "text": "Oh just to show you how it usually looks like okay so we have many shuttle decides which means we can start the meeting and we we should that\u0027s actually some feedback going on okay so this is the second meeting of the co-working group and not well and everything please reach RC 81-79 and this slide this is the the agenda we discussed on Monday and we actually managed to move some of the items around so we will take up the parts of us call we didn\u0027t manage to do on Monday first then we go through a number of active draft like cinema fetch and observe and so on and the last 25 minutes are for discussing congestion control and in particular the new submission called phaser that we didn\u0027t get to and what we are unfortunately and if we have a little time left at the end and I have another draft to just point out anything else missing on this agenda either what\u0027s missing you sounded like you look like something was missing this is okay good "
  },
  {
    "startTime": "00:07:47",
    "text": "okay everybody and you\u0027re not slammed it I\u0027m gonna present the update on not score so the status is that we are in version 15 that was submitted in August there\u0027s one discussed left from acre and we got a few comments from him channeled through Alexey this Sunday so that\u0027s what we\u0027ve been working on now unfortunately it got congested in ad space on the way but anyway we started in this meeting to work on on the comment basically there are three three high-level comments or related to the the unprotected message fields so as you remember we introduced an appendix need to handle on a record previous comments and in particular the four is looking at if you like a residual risk type of scenario where you have protected the message and you still have unprotected message fields and what\u0027s the consequence of that so for example out there code can\u0027t be changed so which actually is it\u0027s not a problem because our code is a dummy code and the inner core contains the the actual method that the same trend integrity detect and then so that does probably here misunderstanding then we have a comment related to proxy operations that proxies are allowed to change things like like options it could change your I host your report and scheme and so on and that was the question why that is okay and that\u0027s essentially what co-op and forward proxies are allowed to do so that\u0027s I think that suppose should be quite easy to answer as well and the third comment related to messaging layer so as you know our score is not protecting messaging layer it\u0027s only protecting the request response layer and rest operations and that\u0027s because it won\u0027t application layer security that could could work on another transport so the corporate TCP doesn\u0027t have a messaging layer so that\u0027s not protected by an explorer and then we can protect over TCP use Morse code and again that\u0027s also I think related to the understanding of all exactly what are we protecting with all its core so we had a meeting with actor on Monday to discuss this and and he\u0027s missing a threat model basically framing that part so the what what do we protect so that\u0027s the proposal for resolving these comments is basically make a few minor clarifications on these points and we add this appendix T which is a threat model and we have time to do that based on why should we have done that and "
  },
  {
    "startTime": "00:10:47",
    "text": "based on one RFC which is model so those two three comments and then was a forced comment which related to which was actually a comment from Varga one Karkat Bartek Varga one related by Edgar and Alexei and arrived on Sunday which was about storage to non-volatile memory that was a good comment we think so we have me some super slide so this relates to how we handle loss of mutable security context and this is not mandated in aw score but in section 75 we give examples of how you could use non-volatile memory in particular writing sequence numbers to non-volatile memory there is a simple write scheme is basically saying that if the sequence numbers are divided about by K then you write it to non-volatile memory then you do the operation and if you happen to reboot then you read from non-volatile memory and you add the interval K now the issue here is that writing to non-volatile memory has and may have an unpredictable completion time which means that they might not have the - you might have lost this right operation due to rebook and the proposal is also indicated by acre is that you look at other ways for or handling lots of security context and there are various ways to do it so the proposal is that we expand on the alternatives one alternative is obviously to make a key exchange protocol which would happen a lot overhead and require good random number generation and another example is that you involve in a trusted third party assisted key provisioning like like one of the age profiles and there is also a third variant where you you still have the shared key available although the context is not it\u0027s not up to date so you could use the shared key and you could introduce a random number and derive in your context all these are perfectly fine examples so we\u0027d like you added those and we also like to keep the case of storing to non-volatile and memory but we wanted we will emphasize the the issues and update the right scheme so that we in addition to adding K we also add some upper bound for completing the right so that means additional safeguard against reuse of sequence numbers but we like them to allow the application to decide because in some devices handling the right to non-volatile might actually be more secure than they\u0027re lying on ran around a number a bad random number generator "
  },
  {
    "startTime": "00:13:49",
    "text": "so that\u0027s the proposal yeah any comments on that so just to clarify this is not a change to the protocol or anything it\u0027s an addition to the security consideration that it and implementer should be keeping in mind I mean we you all this but writing it up for people who don\u0027t know this is very useful yes I mean this these are all these are examples and the application has to decide and exactly how you set up as you know our score is assumes to have secured keys in place and how you get those piece in place is supposed Ella gated to other protocols like and the ACE profile in our score or like ad hoc or likes another okay so that that\u0027s it from from the in terms of comments we have we\u0027re made these updates as proposed here please look at them on the github and we see if there any further comments right now then we will make an update and then we wait for further comments from echo we plan to have another media Decker this wiki see if we can pick something from a sharing or document shepherding perspective the problem really is that that we are giving a little bit of you that this document is unstable because we are generating so many new versions but the reason is that we get the comments and piecemeal fashion and we are trying to react to each of these and now that that doesn\u0027t really look very good it requires some some explanation to people who are looking at this process and asking why do we need ten revisions to get this through the iesg I know from Nokia my question is as a chair of BMS II working group from Omaha we have quoted this 41.1 specification and we have approved that likely time to a 1.1 I hope this gets completed and moves to the next stage as fast as possible because I thought this would have being then sometime back we thought it would be done in March okay so next next draft or any more comments you have about - 20 seconds to do the other ones thank you ladies I try to use them well so echo request tag is in version 3 we have updated according to all review comments we got we got really good comments from them so we think this is ready for working group "
  },
  {
    "startTime": "00:16:49",
    "text": "last call and I think do you match agreed on that so there is a normative dependency from request from Proctor state if you request tag which is yet another reason why this should progress you want to take that separately should I go on to actuators I\u0027m done with requests are the usual quick questions who has read a recent version or take a requester all so that this is going into Gordon last call now so please have a look at it and find out whether there\u0027s something in there that that is horribly problem before we issue the breaking glass cause so this is the time to actually look it up okay this is really quickly first explanation of this craft is so a cone request I go to separate drafts having separate problem description and solutions we took the solutions and put in the draft we talked about recently and this draft is about the problem statements and the question is what was the working group want us to do with it so it\u0027s an informational draft should we complete the problem statements in that case I think that\u0027s a really good time to do now when we are moving to working with NASA before the solutions or should we drop it yeah custom boiler from from the floor head each ahead of this is essentially what remains is essentially advice for implementers there is a problem here you do the right thing and we have a word move that collects advice for implementers and we actually have a document called a reco app that has advice specifically for Howard implemented so that that would be one potential way to get this into a publication so to contribute to that document of the submitter sector partner where we would just copy the text of this document into a record and that would be one way of making this information available so another way if we think some of this information is really important enough to consider to be a correction or clarification we might push it over into that account so I think that that\u0027s a good question we should ponder and then make a decision on the next couple of these are we do this thank you "
  },
  {
    "startTime": "00:19:55",
    "text": "so we now had the the gong show of active draught we\u0027re going to go to half dozen active drafts quickly hop limit that\u0027s something that we owe to the dots people we promised we would solve their problem for them and there is a working group document that has been around for a couple of weeks that was discussed at interim meetings and apparently we have been pretty slow to relay our concerns to the office so right now there are still some clarifying going on whether the concerns are actually addressed in the conduction and are we needed ever one before we can go forward in the spot so just to remind people this gives us a way to limit the number of hops the number of proxy hops the request takes from the client to the origin is our veteran page both senators are you okay thank you so this is a most recently out of the suburban top line so we\u0027re now at version with zero zero here\u0027s what happened on updates uh since the zero three the key thing was we clarified their security consideration section that there even though you are able to address outlaw names in the single parts you are not conceptual reaching to different resources that was very prescient hidden in there in the earlier version there was a small change we did there but the bigger question is do we want to do new media types or or not so as a crystal pointed out in his review there are some challenges with the way using reusing the existing sentinel media type even though the current way of reusing that maps nicely with a couple of different operations using the same cinema constructs however if you do patch or if you do fetch they are issued that said ml RFC said you must have the value of those records and what we\u0027re proposing for the fetch method was that you seem to keep the names so we had a conflict on how you\u0027re using they send no current media type so after some discussions on the list and also with my DM it seems to be appropriate that we actually do have different media type or veteran patch so then we don\u0027t have these issues of being fully aligned with the existing cinema seminar see we are still using the same constructions which says that we don\u0027t have this issue with having an for example something different for the B "
  },
  {
    "startTime": "00:22:56",
    "text": "value that would expect otherwise so the proposal here is that we would go back to media for new media types and key questions if we go that way do we have the same media type for both fetch fetch or do we require two media types for that and then I also Jason or do we also do seaport so having at least the JSON and seaboard seems to be reasonable way you don\u0027t want to have XML and EXI ways of doing that some parts so any questions or comments on this one I felt much more prominent here so I believe the same media type don\u0027t have a class right and obviously need to go for an immediate end yeah they say media type technically you could define different semantics for a different method but it was a bit stretching so having a separate media type seems to be more in solution and then the other reason why the media type may be more correct is that there are pet documents that are not village sentiment documents yes so if it was the same immediate Anthony would need to know basically also the method that it was used in order to be able to interpret later on so it\u0027s a separate media type those issues go away the good thing of course would have been then we would be able to use all existing media types as such now we have the register depending how many we end up with two or for an example so plus one for the different media types and also over the question of you know trying to support many different surahs Asian formats I would say like you knows stick to the minimum thing that works and then you know stand in the future if someone wants that so see bolos really really a great way to encode them the daily thing everything else is okay but MCMAP from okay again it earlier soon as well I got the same kind of discussion but I want to make it here with the Seabourn so whatever we are doing in terms of in Nydia we are looking at things what is needed for next plus two years plus three years so if we are going on extending and supporting legacy formats content types or whatever it may be I think that\u0027s not the right way to go "
  },
  {
    "startTime": "00:25:57",
    "text": "so in this case he bar is the way to go for sure and we should not look at things from backward similarly even for the suit I had the same commanded don\u0027t look for legacy stuff look for what is going to be produced in the next two years which may not even be the same boat as we\u0027re looking at today what kindness is carrying it on okay so I\u0027m here that Seaver makes a lot of sense here so but I guess we could also still keep the Chasen one just not do the xml on EXI those we can leave for our just planes and I know it\u0027s actually yeah I\u0027d agree that you should keep JSON and I see this used in other places in the infrastructure more back-end to move information around that\u0027s been done that\u0027s been done with Sena now so I think it\u0027s worth keeping both but I agree that EXI and how about the same immediate approve it\u0027s a batch is there a reason to have separate for those or can we just have a single one that is for both action touch we were all we almost have the same for all of them so having a single one perfection pack seems reasonable unless there\u0027s something we\u0027re missing here I see people not England one media type or both is good okay then the other issue now when we have the new media type how do we do a deletion so all the other operations are quite straightforward except how you indicate that you want to believe a record from a patch and at least these three different ways are our options for us the first one is what is currently in the draft so you will indicate a that value is now that\u0027s the Chasen merge but spread style deleting living things from Jason contract it is kind of clean there is an issue that I sent an RFC said okay use it all well instead of RFC that we have different tax for different kind of values and now you would have a be used to have only both now we could also have a no it\u0027s a different media type so it\u0027s that big an issue but some parts are could be confused an alternative that that Christian was proposed in his review was this video equals true or something similar basically a flag in the record okay now indicating a record with a name and I wanted to be deleted the cool thing about this is that it doesn\u0027t have the problems of variable types on the other hand this we could buy a new tag on another big cost and it\u0027s slightly more verbose in Jason cause you actually write it through in with four letters I can see bore of course it becomes pretty compact and the final option is "
  },
  {
    "startTime": "00:29:00",
    "text": "to have this chasing ax type of arm operations so you have a defining operation that says it removed you can save parts and Jason called the same X as my reaction is like slide the coin um yeah I mean I think Oprah move is sort of more readable for people are not necessarily worse than this but I think any of this is fine as you said you already defined in your media type so V now it\u0027s sort of a bit hackish but it\u0027s what Forks yeah so the thing is I have not really thought about how this fits in Sena now so probably some of the things that I might say they will not accents to you but I look this to the point of view of kamae because there will be a lot of things in fashion patch and I mean he considered this from the start and then there we did it with the node so but it makes sense right it I mean by looking at the scheme and I think it was really clear that you knew that whenever you get to know them you know like the operation was removal removal the element I have not thought about you know the variable things but that could be a question here right but you know maybe one thing to look at is this as comidas the pageant edge and they\u0027re one of the points over there is that we really we also said that okay we need to have two media types just so that we differentiate between patch and patch because the structure is a little bit different of the payload that goes there because the operations there a little bit different but then I mean as I said I have not really I mean probably have much more feedback on on that point so if I mean if you don\u0027t risk your your code you know just by some chance of you get your fetch method or some payload get gets rather to the patch and then some strange stuff happening you know if you have a different media type then at least you\u0027re sure that\u0027s not going to happen the thing it just don\u0027t say well I don\u0027t know how to handle that thing so did you discover in the comic works I mean some cases where you have this confusion that you would actually have to know from the media type whether it\u0027s a fetching or fetching it so all those documents somewhere would be good develop or actually we had big discussions at the time were like okay do we go with everything you just see bow and call it stuff and then we look at the method is it\u0027s patch patch get peep toes delete and then on based on that we can do now we can infer how the sea were structured so that was like the one end of the spectrum and the other end of the spectrum was okay we have to mediate at for every for every type of payload and because there were several "
  },
  {
    "startTime": "00:32:01",
    "text": "times several things that we can encode we can encode individual elements we can encode collections of things we can encode hatch collection and you know how do you form the fetching of things how do you do the patching of things and then actually it was much more readable with having several media types because I mean at least in the Khmer otherwise it was like okay well in this case I can have like a the list then if it\u0027s a list then this means that if it\u0027s not that than this means that so it\u0027s it actually started getting really difficult to to read this the standard in the draft so there it made quite a lot of sense to do this so just like you like a feedback thank you so yeah well have a look at you got that background so but it seems all of these options are no no one has that I\u0027ve strong known any of these so we\u0027ll have a closer look that may be following the oh my approach V now it could be them would be a sensible one good that was also the plan is now to submit a new version addressing his comments and hope to get this into an RFC soon cause again like with emblem spec is expanding on this and would need to get get this out on on that timeline when deal one of the things this could be going for last cause it will now address these comments it\u0027s the anything resembling an implementation of this well there\u0027s gonna be focused on why with emblem early next year so there is gonna be implementations of nested so in this table can be implemented in the possibly two hours so maybe somebody should put in these two hours just to get some feedback whether that\u0027s nice yep thanks sir so yeah so let\u0027s say requests for all you have at Sentinel incrementation please spend the two hours on this and let us know and yeah send to the mailing list so we can agree that this is cooked and we can thank you thank you Michael your room okay can you help me be able to yeah okay great whatever order you want okay Court yeah so basically he\u0027s got it since there haven\u0027t been a lot of changes but the god Smith had feedback and basically what we need to do is rework the examples to confirm to be different practice for and uh now and link upon that I think there are some fairly minor changes to make there but "
  },
  {
    "startTime": "00:35:03",
    "text": "sort of comprehensive throughout all the examples and just to make sure that we\u0027re up to current practice and we can probably do the review of that in an interim meeting as we continue listed the schedule on interim meetings and I\u0027ll I\u0027ll spend some time on doing the update that as well as bill so if people be able to get into the review cycle again and up true in the interim before the next meeting they can see on this one so mixed didn\u0027t mean yeah dine link so basically recently I\u0027ve done a reference implementation of the condition will observe attributes and see and also they\u0027re learning interesting learning about that and it turns out that there\u0027s really it\u0027s a fide logic of expression and also there\u0027s some learning from developing LCF version of dine link and with OCFS we\u0027re not using the conditional observed for just using the timing pattern itself so I\u0027ve got a couple of sides to sort of some examples the next one being the next one okay so basically there\u0027s this is the C code that just two pages a second page next yeah okay then there\u0027s some definitions and then a couple of logic expressions that cover scalars strings and GUI and so on take a look at that that\u0027s referenced in the github and actually in the current draft now as well let\u0027s see next slide please yeah okay well basically we\u0027re going to add a state diagram to make it a little more clear along with the code there\u0027s some good feedback that we got and essentially what we\u0027re looking at doing is Christian analysis gave us in the feedback that you know we looked at and I think we wanted to basically do that and then provide these observe attributes in the example document as query parameters to the observe request there are some questions and issues about that but looking at all the options that what seems to make the most sense then doing that we could structure the draft where we introduced the observe attribute and then talk about dyeing links and then we have this binding table implementation so it also agrees to the action of restructuring the draft was simplifying it streamlining it this way and also that there were some comments that we want to address when I had some implementation notes about how the link state tracking works which I\u0027m doing as well in the OCS version and I think you note that the implementation might just reuse the "
  },
  {
    "startTime": "00:38:04",
    "text": "observers that coop has and use updates I think to make sense as well so we\u0027re looking at sort of putting in those notes and completing that sometime in the interim before the next cycle as well okay next slide please ah okay so you also take any comments and questions after the whole and so pub/sub not a whole lot of changes recently but we\u0027ve got some some good feedback from from Peter stock I believe and we want to track what\u0027s going on with the 429 although I think that things are looking fine for that there\u0027s no big deal we wanted to get some implementation experience with pub/sub as well and I don\u0027t want to maybe set up an interim the mini plugfest and I\u0027ve been talking with Federico at interrupts on the sort of GTN modes we might need to do that and so I I don\u0027t know how quickly that can happen but I think that\u0027s that\u0027s an approach to getting some implementation experience and I\u0027m going to produce some kind of implementation of them and we\u0027ll see how that goes who in this room has an implementation of up sub Jim has one has an older version so when do we do this podcast I\u0027m not I guess we have some interim the next the next day ATF is going to be in March so I hope that you do it between now and March but you know Jim Jim shot well we can\u0027t really do it any faster than when the next version the draft gets published that\u0027s right I don\u0027t think though there\u0027s going to be a any big any more big changes so I think what we\u0027ll need to do is you know put together roll up the changes that we have they think Jim we\u0027ve addressed most of your comments in the current version of the draft already well I already actually I know I\u0027ve got a batch of five review out there okay you\u0027ve got it well then since the last since the last meeting uh okay so yeah the other thing too is is just an FYI mom doing at the Interop is a little bit hard for those of us who run our windows so that may not necessarily be the best VPN oh okay sort of looking at some of the ways of using Open VPN and also but what we want to do is use make a V Allen and sort of have a standard little router box that people can you can do that\u0027s a little "
  },
  {
    "startTime": "00:41:05",
    "text": "ambitious but it seems like that\u0027s really the way to make it work right anyway separate topic but maybe you want to try to enable that by the way yeah so we have to figure out those blackfist logistics I think we can do that on the mailing list and apparently most of what makes next step is to get that document so Michael if you could press the button at some point okay good I have signal ready to go okay great great this one no comment no no come on thank you thank you Michael this is a very short meeting sorry for rushing you through this but we have some some more items on the agenda the next item we have is a congestion control and while a PO is coming through the front let me just report from a meeting we have had yesterday between the two groups that have congestion control proposals out there and as I said on the Monday meeting we have some some interesting observations about the the cohort document and we had different understandings we noticed this in London and ran out of time resolving this in Austria and this time we finally made it and by nailing it the authors of the Coco draft noticed that they also have different understandings of what\u0027s in that past and that of course puts the validity of the simulation sent experiments that are referenced by the stuff in question so for us it\u0027s back to the drawing board and I have asked Maria who is the responsibility on this document to just push this document back to the working group and if we manage to fix this we can do a new work last call and handle this again so that\u0027s the status of cocoa and figs are yes so one point talk about this new consistent control proposal called fastener and it\u0027ll be out there so what pass or tries to balance between between there are this two contradictory calls so so in the random lost case you would want to trick at the RTO very fast fast because the targets are not lost due to congestion and then then in case of conscious and you need to slow down so so there are you need to do both ways and it\u0027s hard to know which way it is and we realize that in the IOT people\u0027s composition mostly this expected to occur when you "
  },
  {
    "startTime": "00:44:05",
    "text": "have very large number of devices so so we wanted to test test its at scenarios and this is the way we can came across these problems and we discovered that both the default co-op and cocoa have had some issues that lead to congestion collapse collapse these were reported in the London like cotton called constants a then they will be fixed for cocoa hopefully and part of this design such that it is not vulnerable to the same issue despite handling the conscious of well it\u0027s it is also able to and of the random lost case so you don\u0027t see the strengths like titles at all so so what\u0027s the problem with or problem with this congestion control proposed or so so there\u0027s first of all those discounts algorithm for TCP it uses exponential back-off and keeps the back of RT or until it gets an onion because RTD sampled and on the other hand we have this cop Co efficient control others which they do exponential back-off and there is this think in many many many people think that this would be a not enough but even in the transport people we have seen seen that people think that this would be enough and then the problem show up when when the RTO is not weak engine like it comes out there and I will not go to the details because how how to how this is manifested in the devout carbuncle cards but you can read it from here or look back to the slides and tears and references to this London presentation and one other paper but on the same time we learnt from this from cocoa and effort crop that it\u0027s it is cool to good for the random lost case to actually be able to to get out of your fast so this is what we try to do in France or so we try to find a good middle ground between the these two extremes so they try to invoke the random loss but still handle the congestion cases safely phosphor has two ways to calculate RTO there\u0027s first order which is basically the same as the "
  },
  {
    "startTime": "00:47:05",
    "text": "normal TCP RTO there is only minor modification do that and then we have this new thing called slow RTO and then track of what which selects which of these audios to use so first idea like I said is like this TCP Artie Artie T computation we have destroyed the small modification to the utilization with slowest RTO for short exchange we have the disk a gator so the Alpha T bar becomes smaller so if you are sorted chasing helps and then then the slow RTO is analogous to this consequently skips the RTO on today on because sample so we see there\u0027s this figure so we have this original transmission here then some audios and finally we get the ack ack so we they take a measurement how long it took to actually get there so in the in the in the most case this is our RTT and then we apply some additional multiplier to that to make it even even safer and so on the next slide slow how we use these so we add additional state so normal cars only has these two states so just the state where it\u0027s music normal transmission and then the second state this which is using using the longer longer RTO but in fossil we have this intermediate state state where where we start with the first RTO and only then use the slow our deal and after that we again can use the fast start here because we her handle it congestion if there was was such already quite well and then the last last state starts with slower cue in order to ensure that we can always need to take a oddity measurement and these state transitions or shots that always if we could get on am because uh we will end a pact that is passed first RTO or the first state which is using only first diagnosis so this is the normal RTO back of service the point point of all this is to avoid about the slow about using slow RTOS much as possible because it has inherent "
  },
  {
    "startTime": "00:50:05",
    "text": "cost if you need to actually wait for that so if that particular pocket for which you have are armed the slow RTO if you need to wait for that it takes a lot lot lots of time and in random random closed cases it\u0027s of course not very nice - wait wait because the pocket was not lost due to congestion this is mostly what I already say so then then we have this optional feature so there is possibility to always get awkward RTP estimates so that it\u0027s retransmission ambiguity problem is removed using this option so option resource which of their actual so when we send retransmissions we don\u0027t know which of those request copies actually trigger the acknowledgements so with this using this option or other entities the option can be ended or the ordinal number of the transmission can be angled it to the Tolkien - since it\u0027s the client can decide but not to put in the token so it has this possibility so it doesn\u0027t need to always use this option it doesn\u0027t want then I will show some of the rest also so we had this romantic idyll a environment and their work is coins perform with the exchanges per each client and in order to simulate simulate softly coins reverse at the congestion control star state after one to ten messages and for Coco we have disabled aging because we have discovered a problem problem with it and it was is up like this pussy pussy floss this has been reported in London so you can probably get more details from that presentation so we have to test scenario so we have this heavy congestion which includes also buffaloed quesiton and we have best it up to 400 power potion or well it\u0027s parallel class we call a flow one one one of these quiet quiet quiet or this set of clients is perform perform 50 request responses in total they call it a flow flow even though technically it\u0027s not a flow and a large buffer sizes in finite so that there won\u0027t be won\u0027t be any congestion lawsuit adjusted playing buffer protein "
  },
  {
    "startTime": "00:53:06",
    "text": "also tested some smaller person and it 400 clients and infinite buffer the base RTT will be like 10 10 seconds so so if it\u0027s each of the flows or each of the clients I have a just just one pocket in flight they started he will be dislodge so and then then there other cases this random losses case where there is no competition and parallel clients and the error models are also mentioned there so it\u0027s quite thirsty thirsty element so this is now with 400 clients so we have the heavy : congestion and buffer bloat and in in here the this congestion collapse problems is sewn sewn with a purple co-op and cocoa and because fossil is able to handle the consistent well that it gets much better performance and this problem is mostly due to unnecessary transmission so so the Pissarro logic is able to reduce the number of unnecessary Francis\u0027s very dramatically it\u0027s reduces the RTP RTP and with ten sources the flow completion time did you have some question yeah one question which is the network topology you are considering in the evolution well we have have shared certainly link link from this server server so so so and the Paulo photonic buffers buffer sorcerer circuit we know this okay so it\u0027s just one lean and other close group go through this same link yeah so then the wrestles with random loss so here again the median median for fossil fossil is significantly smaller smaller than their falco for Coco and on the RTO side we might need it\u0027s probably not well visible in this but if you look on your own screen the know know that the right hand side figure so so the initial RTO is two seconds and "
  },
  {
    "startTime": "00:56:10",
    "text": "the taste oddity for this case where there is no competition is this six 660 milliseconds and yeah fossils able to lower this even though there are only very very few few request responses before the congestion control state is weathered so this is very challenging form from functional point of view because you thank you for getting your RTT state so so we need to always be learn it very quickly here take token talk at Maryann\u0027s so so state test performance because it can immediately always learnt is even even when there were some losses to to link errors and one interesting detail from coke coke wised also visit Tokyo Celtic artists actually crow because they went there there are enough enough errors or enough random loss is the peak estimator collects this noise from the ambiguity samples so so instead of converging Thomas the reality it\u0027s actually increasing it and in fossil we avoid this because there is this fast RT always only update it on onion because sample so we never take this on because samples in the day and first RTO measurements or computation then we have some items which this might not make sense to you unless you have worked more to the motive the details of their algorithm so but at the end we both go through them now so occasionally stir fast slow fast state backup services it may actually be more accuracy than what what goes on in in the first state we have also tested a more conservative version version but it has small small measurable impact but we are not sure whether it\u0027s actually useful to add this extra conservativeness to the audience\u0027s lower ph self is already quite conservative then we have our own teetering out it might be useful to consider using the same detailing other than just the other Constitution control approaches have been using so then my conclusions so first of all to use this balance between having random losses well and and also "
  },
  {
    "startTime": "00:59:13",
    "text": "handle function and traditionally it has been in thought that the handling congestion automatically means that you will lose some performance in random loss this case but pathologically such that it is able to mitigate most of this problem so it doesn\u0027t have that high impact and on this this vessel so so so so so the other is this think that since the others are too aggressive in congestion case they benefit in the interlink error case so if we if the consistent case will be handled correctly it\u0027s likely effect Steven Pinker\u0027s case or this random loss case performance somewhat and we think that the faster ogron\u0027s complexity is not significantly higher it might even be slightly lower than what\u0027s the complexity of Coco and because of the promising results we believe that would be beneficial for the whole ecosystem we don\u0027t know if this group maybe has some interest to work on this item so I leave it as a question for you well I would actually cover the next slide which I have on the back of that up slide so we have better yet also also with this Union already over our time and instead of point I have to make sorry so look at the slide and be impressed so this is interesting stuff this is good stuff and at some point we would have to decide whether we want to adopt this and one very important question that came up when we looked at this is there is an Ikea declaration on this so generally this is the second IPR declaration we had in this working group and this Burger has been around for a while generally we do not discuss any patent claims this is a patent application at the moment on in meetings on mailing lists but the the procedure is that working group members form an opinion about this and decide whether they think this is an obstacle to working group adoption or not so please read this IPR declaration and see "
  },
  {
    "startTime": "01:02:16",
    "text": "whether that would be an obstacle to adoption from your point of view and you have to form your own opinion we cannot have any any reasonable discussion about this patent law makes that generally impossible so the one thing that might happen is that the patent claim owner chooses to speed up the discussion by providing more information right now the IPO declaration is very basic it\u0027s essentially the information that you have to give but not not not much more but sometimes I get owners choose to provide more information to make it easier for the working with to understand the impact of this idea declaration so right now it\u0027s very hard to understand because the actual patent application probably won\u0027t be published before January 2020 so right now we are here pissed in the dark so let\u0027s see whether that happens but independent of that you can form an opinion on whether this would impede adoption or not and when we think we are ready for regular production then well what you say about will be influenced by the position that you have created on this point so sorry for this little announcement on how to handle the patent claims but again we haven\u0027t had one in this working group we had one before which was a seven-year submarine thing more about that point this time it has been properly cleared everything is wonderful point of view but we still have to find out how we want to handle this thank you any more comments on this so who has ever read any congestion control document that was owned by this working group oh wait a few that\u0027s good okay so maybe those of you who have done that please have a look at this and form your opinion on whether this is technically good and form your opinion on whether the patent stuff is an impediment or not thank you thank you so the the meeting is officially ended I have a another small announcement here that it\u0027s officially now outside the meeting and perfectly most of you will think that scientists surgeons in this universe are expressed as x.509 certificates so if you go to a random "
  },
  {
    "startTime": "01:05:19",
    "text": "sto which one do we take care they will think if they need anything that is signed this takes on the form of often X of x.509 certificate and that was probably true for about 30 years but it no longer is because we now do have those RFC\u0027s that tell us how to do it in a different way now is you still may want to use certificates because you have the infrastructure for ending them and so on but it\u0027s important to note there is another way of doing that and there is a document that has been submitted under the name of this working group I have no idea whether that\u0027s actually a good fit let\u0027s see Iran has another document I should have put it on this side sorry I\u0027m kidding can you just say the draft name it\u0027s called draft Raza ace Tibor certificates thank you so there are two drops out there taking different stances on this problem so the Raza draft is more x.509 compatible this draft is more clean state oriented have a look at those and see whether that might be solving your signed clean problem that you thought you had to solve it with experimented a bit so this is Hank speaking and concert that Lauren and I think we that\u0027s a migration path yeah so nobody will suddenly jump to CW T\u0027s and and and drop everything that was x.509 is what I think that is the heart Corinth may be a few words about exactly so I mean this this graph this is a it\u0027s a profile of x.509 but it can still be parsed right by the back end I mean it can still be generated by the ca so have the X file on our infrastructure in place so basically take an x.509 certificate and you could put the front end which converts this to seaboard you transport it in seaboard then you have to do in the device the reverse operation to expand it into x.509 again which is a burden but this is a migration path to have a format which could be natively Seaborg eventually and it also offers the SI CA infrastructure to be part of that transition path from X 5 minus negative so that\u0027s a purpose and the other benefit is that the thing is much smaller than the original experimental definitely yes think again and then the concise identity documents we\u0027re talking about here just a flavor of the possibility how to package assertions scientists surgeons in the future there are other objects testing "
  },
  {
    "startTime": "01:08:20",
    "text": "graphs that already do use CW T\u0027s in the context of searching something about the device for example or something else and and there will be there will be multiple flavors of this and this can be we will be built on each other but from size identities there\u0027s a identity document could be a stage that we arrive at and therefore workers like an EXO but more about this might be happening in the future interim of this book we might talk about this in ace this afternoon we might have a revival of the cosy working group which is mainly going through on cosy into an Internet standard but which might also look at formats that make use of cosy so it\u0027s up tight but not quite clear where this will be done but there are a lot of people who want this done and so I\u0027m quite confident that it will be done and with that thank you all for sitting here 10 minutes later than longer than then you should have and yeah see you on the Friday meetings and tomorrow there are various interesting meetings and see you in the interims and see you in Prague "
  }
]