[
  {
    "startTime": "00:00:28",
    "text": "nice from he's like okay we can start the meeting and welcome everyone to the session of the co-working group with atf 114 and marco tyleka my co-chairs are jaime jimenez and karsten bormann and of course we've seen people in the audience that have read the documents in the channel today we make use good use of our time to discuss open issues and progress to work uh in a working group uh blue sheets are collected"
  },
  {
    "startTime": "00:02:01",
    "text": "automatically uh please if you attend on site in fact access the meeting through miteiko on the live version the chairs will take care of looking at the chat we have evo and matthias the volunteer to take minutes thank you very much anyone is welcome to help them and christian thanks this is an official itf meeting so as usual then not well applies we've been recorded and this is not just about ipr patterns and so on it's also and especially about our conducts so be nice and professional with each other uh also for the participants inside please ensure to keep the mask on all the time also when you go uh to the floor mike to give a comment ask a question and so on thanks a few practicalities again keep in mind to join through the on-site tool of miteko for the on-site participants um if you want to go to the mic to ask a question please join the queue first uh on metecolite and then go onto the mic and then leave the queue when you come back to your seat okay this is the agenda for for today it's pretty packed so please do your best to stay on time and the chairs will will guide you through um about that uh we start with the two rule 80 document and href and coral then we cover two documents related to group communication as a group comfort co-op as such and multicast notifications um then we have two documents related to uh all score the profiling available for oscore and the key update for score and then we have a number of non-working group documents meaning dns over co-op performance"
  },
  {
    "startTime": "00:04:01",
    "text": "measurement and copper gut for ble does anyone have any comment or want to bash this agenda in any sense kirsten yeah i just wanted to point out if we do have time at the end we could briefly talk about something that came up during the anima meeting on monday the co-op s plus jpy uh uri scheme uh let's see if we have time for that okay with five minutes work in the end from the flex time i think so let's try that thanks okay so let's get into the uh working group and documents those updates from the chairs so since the uh vienna meeting in march we actually had um three documents published as rfc uh so many congratulations to the authors the working group and everyone that helped out with that uh they are in order i think strictly in chronological order of publication the resource directory was indeed an achievement uh 9176 um sentimental data ct 9193 and young seabor one of the four uh corcom cluster documents now rfc 9254 congratulations again carsten yeah so um i think uh the the two of you weren't there when this work was started at least on uh the resource directory and on uh yang ziba so maybe i should just quickly uh remember people what this was about um excuse me i need to reconfigure my audio"
  },
  {
    "startTime": "00:06:01",
    "text": "ah that should work better um the resource directory was started in 2011 from a contribution by zac shelby out of the eu product uh project that that i for already forget the name for but that actually created the the company sensing note and uh yeah it took us a while to to finish this and 92 54 was started in 2013 uh by peter wenderstuck and then that's came and added restcon for that because peter really wanted to do this with snmp at first then there were discussions whether we would need to start a new working group for this then we had the discussions about whether to do hashing uh to create the identifiers and at some point uh michelle villette and alex uh pilaf joined and came up with something they called cool so some of the people in the room are a member of a telegram list called cool that's the origin of that telegram uh list um and um yeah so we got lots of help from andy biermann and and young schweinweider uh we invented the differential coding then we had several submissions in 2016 that explained the best way to register these sits would be using blockchain michelle actually wrote code for for p yang to support the the sids and in april 2016 we actually adopted the the draft and then yang 1.1 was published so our basis actually changed and we had to"
  },
  {
    "startTime": "00:08:02",
    "text": "react to that and yeah it took another four years until we finally made it to work new blast call in 2020 and then we had the pandemic disruption so it took us to july to have a second working group last call february 2021 to have an itf last call and then we had to to uncouple the drafts to get at least one to advance and in april young sibo was approved and now it was just a little bit of auth 48 before we finally got it published in in july so just as a reminder how these things work so if you want to congratulate anyone do congratulate peter and all the other people who made this stuff happen it's been a long time thanks a lot yeah by the way i i know that you're cause of all these three rfc discussions so but i think you played a major role indeed in many senses okay uh moving forward with the update uh we also have another document and not published that yet right now in the document queue in the rfc rescue and this is indeed an achievement considering what has happened in the last few months following the vienna meeting during which the document was still dormant and then was resurrected in april for a rush to completing it due to the urgency um in in 3gpp and the result was great i think thanks again for all those who contributed that too and then in ist processing we have um another of the qualcomm cluster uh documents uh corseed there was a resubmission uh earlier today uh of"
  },
  {
    "startTime": "00:10:00",
    "text": "version 19 following discussions uh among the cultures as 180 customers to say something yeah just this document is officially out of the hands of the working group but the the feedback we got from the isg was pretty substantial so there will be substantial changes uh to the document and uh it's important that the working group actually pays attention uh to this so formally this will probably take the form of second ietf last call but that's for the isg to decide i don't know that but yeah please follow the github repository which by the way is the yang ziba repository uh for historical uh reasons and uh there are two pull requests in there right now uh one is mainly editorial but it's a long per request and the other one is very short but it's technical and we want to merge these two pull requests and get feedback on on this 19 and and submit the dash 20 to finally lift the discuss that that is open here thank you yeah we have also a number of documents in post-working group plus call meaning the other two kirchhoff documents uh combining a library that uh just have to wait for corsair to be completed before uh being brought up on service to work on them and then we have the ripple score document which is currently in shepherd write up we also wanted to mention other documents that are not in the agenda for today there are two have been recently adopted attacks on co-op and transport indication for which there was also a recent uh resubmission with a little"
  },
  {
    "startTime": "00:12:00",
    "text": "update so the version one and then we have another one uh pending workforce adoption group com proxy uh carson is fine for you you can take this one uh yeah now if i were remembering what this was about um sorry it was presented um again at an interim meeting um in may uh basically requesting for adoption yeah and and we yeah we made a resolution there and i probably should repeat that resolution here but uh i i must admit i don't remember what that was too many balls in there i'm sorry well uh trying to remember the means for me that there seemed to be interest and energy to work on it but then it was up to the chairs too uh to consider a call for adoption that yeah since then hasn't started okay so maybe you can say something at the end of the meeting so i refresh my memory i'm sorry all right uh and we have a few more uh individual documents around there are four that have been um are submitted with some um updates uh meaning restoring cash ability score protected responses and using all score um also with proxies possible with multiple layer protections extensions for the resource directory and everything on co-op as kitchen sync we also have around two new submissions core parameterized content format was presented at the recent inter meeting also and then a new co-op option uh for early data usage of tls or dtls 1.3 equivalent to the corresponding http"
  },
  {
    "startTime": "00:14:00",
    "text": "header basically and so we encourage you to read through these documents that couldn't make it for today's agenda okay that concludes the introductive part and we can actually start with one minute of advantage with the first actual item on the agenda href and that's carsten okay so this is mainly a report we don't really have time to discuss this and i think this is really the stuff of which interim meetings uh are made so just as a reminder cris are concise resource identifiers they are the the concise equivalent of uris and ui references and essentially what we did is we looked at uris extracted the generic data model that your eyes have and made a structured representation um of that um so the the current status of this is there hasn't been an update of the draft because we are essentially done we are finding occasional little nits that we have to fix but most of the work at the moment is on test vectors and implementations so we want to make sure that our various implementations actually work with the uri implementations that we find on our platforms and it turns out if you want to do something that uses the the entire envelope of of the uri data model you are fighting with your platform and that's something that we have found out"
  },
  {
    "startTime": "00:16:00",
    "text": "so we have much less of a problem with actually doing the cri part but doing the the uri part in the bi-directional translation uh so there there have been two pr's lately which are in on github but not yet in the internet draft a short lamentation about percent encoded text because that really is a syntactic feature of of your eyes and doesn't fit at all to the semantic structure of cris so they are best avoided but if you want to be able to write a translator that works for any uri you have to include that and the other observation was that we forgot to put in a rule to prefix a relative uri by dot slash if the first path segment in the relative uri contains a colon because that colon will look like uh the whole thing starts with a scheme so you have to prefix that with dot slash to make sure it's recognized as a relative ui so that's on on github already uh what is on github as an issue right now is the question what do we do with the uri foo colon um so the uri foo colon is could be um a uri for the scheme foo that does not have an authority but has uh zero or more path segments so it could be full colon slash bar slash but we have zero of these segments so um in this case the representation would be the scheme foo and a null and the null can be taken away so it really is just an array with a scheme so this this fits with what you"
  },
  {
    "startTime": "00:18:01",
    "text": "actually see but it also could be a full colon opaque something like a metoo uh url uh major ui and that actually would have exactly um the the same ui syntax but a different ci uh representation um so uh we need to decide which of these two we don't support and this presenter is leaning to uh say we support the zero segment uh path based uri but not the zero length opaque ui and one reason for that is that i have never seen a zero length opaque ui and i don't know how to do the proper research to to actually verify that uh but i i think it's relatively unlikely that somebody just wants to use a ui scheme and nothing after that um but allow opaque uh stuff after that as well so that's the decision where we could flip a coin um probably because the practical effect uh will be minimal but for consistency i would go for uh number one so if anybody in the audience has ever seen such a uri and has an opinion on that uh please send email to the list or speak up now so we can get some some help in making that decision uh sorry cars then there's a comment from brendan on the chat that is your eyes or urls um hi brendan moran here since the the questions coming up at the mic i figured i might as well do it myself"
  },
  {
    "startTime": "00:20:00",
    "text": "um the the the slides thus far i haven't been able to tell whether we're discussing urls uris including urns or something else entirely um i can see one obviously is a url that one's clear um two looks to me a lot like urn um but you're calling it opaque stuff and your ends are not opaque so i'd like to be absolutely clear whether things like urns are in scope here okay the terminology in this space is completely confusing so there is itf terminology and there is what wg terminology and what we call uris are called urls in what wg and in other uh daily vernacular so please excuse if i'm not always clarifying this very well but these are all this is about your eyes so cries are supposed to cover your eyes and actually iris as as well because but not url well uris is the overall term that includes urls and even urns okay so cris are supposed to produce like i don't know what you would call it a crn um well um they're all tries and uh actually a uhn and that's another problem there is um uri scheme called urn and half of the people who say you are n mean a uri that uses the uh scheme qrn and the other half means the the foo colon opaque stuff that is number two on this slide and uh for uhn of course opaque stuff is the the registry uh and and uh all that structure uh behind that but it's not a hierarchical uh ur i like what is number one on my"
  },
  {
    "startTime": "00:22:02",
    "text": "slide which is by the way not a url because it doesn't have an authority um so oh fair enough different again so that's really not helping very much to try to use these these terms you best think about uris with certain specific properties like having an authority having a segmented path and all that yeah okay thank you good i have two minutes left so please send things to the list that you think about these things let me just quickly talk about curries we talked extensively about curry's at an interim six weeks ago and i just want to report from that essentially curries are an opportunity it's not something that that we need to do but uh when we do this we might as well make sure that we handle curry's queries are a way to to do some lexical compression of your eyes that also looks good on a whiteboard so it's used by by a lot of formats that that need to look good on a whiteboard and um curries are a compression scheme that is based on uri syntax so there is no relationship between queries and the structure of a uri you can just cut up your eye anywhere and and put the different parts into different places that that amount to a curry so um that was really hard to support um the the mechanism that would best support this is sibo pact and sibo pack now has function tags that can be used for reconstructing a uri out of a query so we are kind of in a position to"
  },
  {
    "startTime": "00:24:00",
    "text": "do this now even though it's way more complicated than the other things that sibo effect does uh for us uh but in the the interim i talked about we decided to do this in a separate uh specification and we didn't quite decide whether this needs to be done in coral or in a separate document we still can do that we need to start writing uh that uh document and we need to start uh which of the the potential carriers we actually support so two of the ones on this slide are uh in strikeout uh font because they are probably not easy to support while the other four probably are so let's talk about that but the the point is that whatever we come up here and and define as a better uh carry or a concise uh compact cri or whatever it doesn't have to to cover the entire carry space so in summary the the plan is to complete the test vector implementation work decide the full thing and do the working plus call with the next version of this document and in parallel start work on on a cri curry kind of thing that would fit into sibor's super packed framework and would fit together semantically with what we have done on the ci side and now we have zero minutes for discussion i think thank you very much just a question when do you expect the next submission more or less that depends a bit on how many other bugs we find in our implementations but we are down to a small number now so"
  },
  {
    "startTime": "00:26:03",
    "text": "uh i would think this is not months but weeks okay great looking forward any last quick question for kirsten anyone you know thanks again kirsten and next item is coral presented by christian [Applause] hello so this is the next part coming from we now have uh cries uh now that we have a way of expressing your eyes well in a compact and embedded friendly way we can use this to build structured documents that talk about resources um i'd like for today i'd like to pick up a few um of the of the open issues and outgoing things um that are around in coral for that i'll briefly for everyone who is not familiar with coral so far i'll just summarize very quickly um this is a way of tell of making statements about resources similar to 6690 um but with the extended options to have really real structured data in there um to build larger trees of data and to better guide interactions by using forms properties that are relevant for today are that this is in its structure similar to our in the information model that is behind it similar to rdf so we have statements that link one resource or one uri through some predicate that is also expressed in a uri with an object that is either another uri"
  },
  {
    "startTime": "00:28:00",
    "text": "or a literal if you look at this example statement my temperature resource supports the serious transfer pattern um you'll see that in uh the so neither of these is what it looks like in sibor obviously um but this is a more of a diagnostic uh notation here and you'll see that often here in the slides i'll be using the very queries that carson just talked about because full your eyes behind those are lengthy but if it says core colon here this probably means something like http colon slash slash ayanna.org slash registry slash something that leads into into core um two a few things were changed recently and one of those is that literals are now much simpler so if you've been to the to the interims there has been discussion on what identity means if literals can still have properties the the current direction in which coral is going and this is already part of the latest draft is that we do not need properties of literatures because we can use uh things uh we can use the expressiveness of zebra tech so for example in earlier versions of coral a lot of um a typical metadata on the literal was the language or the text direction this is no now all uh covered in sibor tags thanks to uh also thanks to carson uh for covering that inside problem details because this is now where the relevant zebra tag that we'll be using is defined what is um what is the longer um what is also ongoing and is in part part of the current document but not in in full is how we use siebel pact now in order to express all of these statements clearly so uh concisely so what you see here is an example translated from"
  },
  {
    "startTime": "00:30:00",
    "text": "uh from the proposal on the pubset broker and everything that is a query here in in this diagnostic notation would in a [Music] um in a binary representation be expressed through zebra packed now this is also this is a part that's already in in the document it says we're using zebra packed and no custom mechanism anymore frankly i think that that simple pact was re from a not very old idea uh reuptaken partially because it is really useful here what is not yet in the document but being planned for the next update is how we do set up this um how we to set up this dictionary so some of those statements would probably would ideally be loaded with a document type so when you receive a choral document um then there is already a dictionary set up that says that we can use all these chord terms so the title statement could be in in seaboard diagnostic notation could be as in the second line here and have the whole http iana.org something slash core slash title compressed down into those two bytes of a version packed tag extending this to to cover a larger variety of subtype of of problem spaces this can be applied to is um not quite trivial because um if we only set up one dictionary then this would mean that we have to register every term in the dictionary and the plan that i pl that i'd like to go with here is to allow setting up additional dictionaries using a mechanism very similar to what is already in sibo pact by stating that we are loading a particular number of"
  },
  {
    "startTime": "00:32:01",
    "text": "terms from a well-known additional dictionary this this means that we don't have to lug around the weight of those so um if i said dictionary um earlier my apologies i meant tables terminology has changed here that means that we don't have to lug around the weight of having those tables we don't have to let our numbers grow incredibly large because we have so many entries in the table but we can use them selectively and by utilizing um well-known table tables we can also express this selection concisely as is shown here in the fifth line again using just a few bytes to select that to select that table that set of tables if an application really goes outside of the scope of what is known to be a round core then they can still ex load those by identifiers named named through a uri another item that is actually being worked on is the security model um coral will definitely need something some we need to say something about security but we plan not to um not to redu reduce redo things that are already described in security models such as ace but what coral will provide is for application authors a way of expressing what the application needs from the what the application needs the coral agent like this like a browser to enforce and for the choral agent there will be rules that say how those how those statements from the application are applied and what they mean in the context of loading for example a document with a dictionary that is externally referenced because in"
  },
  {
    "startTime": "00:34:00",
    "text": "essence every piece of information that goes into assembling an action from a document will depend and security wise depend on the integrity of all the resources that go into making that statement so these are um these are the errors that are being worked on um next steps that are that will be taken up is that the binary serialization will need to be revisited but in order to do that and this is part of what i'm asking the group for input is that in order to evaluate that we'll need real world examples so whatever you would like to use this with um please let us know please send example documents that we can then translate and based on that decide what good just choices for the serialization will be problem details is something that will go in here um a non-next step in a sense is the topic of pruries patches and provenance as much as i'd like to have those around at some point i don't think that these are good items for the first version so i think we while we should keep them in mind i wouldn't want to have them around in an initial version because i think it will slow things down too much and i think i'm just on time to ask for the working group for comments and questions and for whether this is direction that we should follow before time's running out thank you thank you christian any comment question anyone i don't think we chat no one in the queue i have a question just to be sure you understand correctly so i suppose in the short term you want to focus mostly on the items you had in slides six and seven while possibly working in parallel but in a at a slower pace on the items on slide eight correct yes six six and seven are are"
  },
  {
    "startTime": "00:36:01",
    "text": "ongoing items and items in slide eight are being started and are held back by the lack of examples um but both yes both will be addressed in parallel sounds great thanks no one in the queue nothing in the chat okay you know we can move to the next one yeah i'm it's great if you control that thanks [Music] okay this is marco i'm presenting as an individual this is an update of the group convince document next slide please thanks so in vienna we presented version six and after that the document entered a working row plus call we received uh quite a lot of comments uh all very useful thank you very much uh most of them were from uh reviews from from kirsten um well a summary of the review was actually posted on the list but then the authors got a lot of detailed comments uh to address in fact there were also more more replies from john shallow basically concurring with karsten and pointing also to lib co-op as an implementation that also supports group communication uh rick are confirming that the document is good and john matson started um a pr on the github so far only with editorial fixes that we already adopted in the latest version but i'm aware that more comments um are coming there uh next slide please uh so for the cutoff we submitted the the latest version seven uh to the best of our knowledge it is addressing all the received working groups called comments um i just summarized the main updates here um we have revised and extended the the list of updates or actions that this document produces on other documents especially"
  },
  {
    "startTime": "00:38:01",
    "text": "the absolution of 7390 and the update of 7252 we also had a figure providing an example on an example of how you can combine the different types of groups meaning co-op application and security groups we were just requested to build a real-life storyline around that examples and we did that considering a building automation use case to make it felt more real next slide please uh yeah there was quite a lot of work to do also on improving uh content related to uh the the naming of the different group types and as to co-op groups we highlighted also with examples that it is possible to name a cop group in different in different ways playing around with aliasing based on the on the subcomponents of the authority component of the group uri and then we we used to have a lot of examples in the document body showing how you can name in different ways application groups and how you can discovery groups of different types actually at the origin server so we moved all those examples with the necessary editorial adjustments um out of the document body and and to appendices and that i think improves readability quite a lot also as to security groups we clarify that well yes they have names uh as invariant identifiers but they are not exactly used in the protocol defined in this document or in the actual co-op group messages exchanged they are useful in in other protocol and mechanisms defined in other documents especially in ace as supporting uh security for group communication and since we had the opportunity we also clarified that it's a bad idea to use no sec or its variance lowercase uppercase as a name of a security group because well you'll be very misleading if it's"
  },
  {
    "startTime": "00:40:01",
    "text": "an actual security group while if you use the nosek mode without security that just no security group adult name uh next slide please thanks uh and more was done also um on proxies uh this was also mostly uh from from comments from kirsten uh we better clarify the limitations and issues that you have in general if you introduce a proxy in this kind of setup and again that they are possible for the rest by using the method in the group proxy document that by the way defines also how you can deal with these issues where you consider specifically an http to co-op proxy and we also clarify a bit of terminology related to this and we also describe what happens in the case where the client sends a group request for instance over ip multicast to be received by multiple proxies at once uh each of which in turn forwards the request um to the group observer uh discussing separately the case with and without security um it was also noted by kirsten that we were a bit too strict in saying that group communication cannot happen with reliable transport uh where multicast cannot happen but we were already discussing a case uh when using blockwise uh where a first group request can be sent over multicast with the blockchain option and then the following requests to request the following blocks from the origin servers can be sent individually via unicast to each of those servers and well those unicast requests can in principle use um reliable transports and this kind of transport switching within the transfer of the same body can also be facilitated by means of the work in the core transport indication document and there was also a revision about the interworking with other protocols especially related to multicast routing and referring to uh"
  },
  {
    "startTime": "00:42:01",
    "text": "most recent itf documents especially in six though next slide please and finally to wrap up on the updates uh we revised again the phrasing around the use of the nausic mode trying to be uniform and assertive all over the document the nalsec mode where no security is used is highly discouraged it's not recommended there are a few exceptions mentioned up front like early discovery of devices or services before you can do anything better so you basically you have another choice uh but still even so you need to have very well understood the security implications of this editorially we are also using that without quotes now just like rfc 7252 does and we have also revised the number of security considerations related to properties of purpose core possible fragmentation issues in in 601 and and purposive monitoring uh especially highlighting highlighting how that makes a difference in group communication plus of course an overall editorial revision of the whole document uh thanks uh yeah to wrap up uh this last version addresses all the comments we got uh so far but we expect at least uh one more version to be submitted because we expect a follow-up from from kirsten uh with counter comments on how we addressed his review and yeah i i know that that john will follow up also with uh more comments on spr and who knows maybe more can come but yeah we expect at least one more version and hopefully that can be um a final one really incorporating all comments in a stable way and finally i just wanted to give a reminder that francesc at some point recommended that when it is ready uh this document would be better um sent to the isg together with other two related documents at the same time"
  },
  {
    "startTime": "00:44:01",
    "text": "one is gripple score now in shepherd right up another one isn't a document in ace describing how to provide keys for group of call and actually that line in the slide is not correct anymore i i've just found out that a few hours ago the document moved to waiting for shepard right up doesn't change the fact that i was expecting a few more comments uh coming to address and i have also in the queue um some more points to add in this very document and in another related one but i discussed uh this part already also with daniel and his co-chair he definitely agrees with the need of thinking about a single bundle to be submitted to the isg so this is the status and that was my last slide any question comment christian christian um i was a bit one when when you mention that um the the the way that um block one second and and later blocks are pulled out that those happen with unicast i suppose this is based on the statement in 7959 that says that this is how it works um was there any evaluation on whether um getting a response getting the later blocks with a multicast as well so just a get with the block 2 option um would make sense because the 7959 says that other uses of block options with multicast are fulfill the study and now that multi now that the group communication is revised this might be a good point yes and to clarify the the the switch to unicast for the following blocks was already in the draft for a while was what carson noted was that well at that point the switch can also include"
  },
  {
    "startTime": "00:46:00",
    "text": "switching to a reliable transport altogether i see thank you okay if there's nothing more and knowing that we should expect the next version thank you the next one is christian again with observe multicast notifications you're muted christian just trying to find the right uh buttons we stay with the topic of multicast and so for um original co-op um as well as the uh the updates that are that were presented right now only describes how multicast is set how multicast packets are used to send requests and responses that are sent to many clients were so far not described this is what observed multicast notification does it allows sending responses to a group of um to a group of clients whose token space is managed by the server as a steward of of that multicast address this was envisioned as part as part of discussions around pubs the pubs model which is why the the illustration here shows this as a broker finding out the responses but is really applicable to all kinds of of observation situations in which a large number of devices in a network that supports multicast well is"
  },
  {
    "startTime": "00:48:01",
    "text": "observing a single resource as with all modern multicast components uh this is supported by grouposcore in only to get uh actual actual cryptographic protection of requested responses responses mainly here since this was last um presented at the eye at the at the last session um we've made a few updates um in particular we are now elaborating on how a client can obtain the necessary configuration information that is what is the precise request on which token was it sent uh at which multicast addresses from which multicast to which multicast address is the response being sent etc that the client can not only obtain these from trying to set up an observation but also through other means because in a sense it is just a piece of information about a state of the server that is around um a typical way of obtaining that information is because it is part of a pub sub discovery step the current document also not not only describes that this is possible but also what this means for the server because if the server is not handing out that information on a short term basis but as a general statement that means that it must have the request already running and must be sending out multicast notifications for as long as that information is around which still doesn't freed from looking at whether it is necessary uh to still send it up so that to still send these notifications but it has to keep track it has to keep track of both the number of participants and whether it has that statement still in a valid form somewhere around a few updates were just editorial being that terminology was adjusted or changed but there were also um conceptual new input like"
  },
  {
    "startTime": "00:50:01",
    "text": "or at least yeah there was there was a lot of new text for example um all those prerequisites that are listed in the introduction that are um we have to have a multicast address that is managed and we have to be on a network et cetera are now listed explicitly this also takes input from reviews that we've received on some prerequisites where we were previously a bit sloppy about describing them another new section also based on input from previous reviews now lists the various modes in which this can be used because we do have a lot of examples and the document was previously a bit confusing as to which configuration is now being used so for example if there is groupos code being used if there are deterministic requests being used all these change subtle details of um of what of what this means for the for the precise packets that are being exchanged a current point that that that we would like to change in a future version is the handling of deterministic requests because so far uh we haven't been fully clear on what it means for uh for a deterministic client to be in a group on with respect to whether clients are required to implement deterministic requests the proposal now uh previously this meant that a server could need to run both the two notifications one was deterministic request and one was a regular request created by the server itself the proposal now is to just say that given that already there's so much pre-configuration required for this all anyway um [Music] that it makes sense to just state that the group has or does uh has or has no"
  },
  {
    "startTime": "00:52:02",
    "text": "support for deterministic requests and if there's if there are deterministic requests being used then the clients have to support these and the server doesn't have to run to parallel observations for the different kinds of clients this should be a reasonable implication another change that is coming up and there's already a part of a draft branch but not um but not yet ready to be merged is that we have a lot of information in the phantom requests and in the in the informative response or in the informative responses that relate to addresses of co-op um addresses of core endpoints and given that uh now uh cris are becoming stable enough to reuse them in this document we are slowly switching all these occurrences over to just using cris so instead of using our own list of what what if what protocols are around that support multicast we just use the schemes that are part of the cri um that other part of that are registered as part of cri and those that can do multicast are usable in this place this is also lined with work on on prop on proxies that has a similar field that previously listed both the protocol and the ip address and now just list the cri and so in in in practice this means that just a number of fields are renamed and that information moves a bit between fields that are now grouped together or i'll split up between split up from what used to be b1 field yeah that being said we've also processed a review from from ayana um some of which does not fully apply"
  },
  {
    "startTime": "00:54:02",
    "text": "defined um how we previously defined those transports which is now using using cris or we will now be using cris but the rest of the review is still very valuable and will be part of the next of the next iteration i think that's largely it from me and i think i've made a good time so thanks for uh thanks for your attention and do you have questions comments thank you anyone for a common question hi christian one question how do you think this draft could affect the pops up the existing pops up draft on the pubs of work in general made your modifications minor what do you think um it does not i don't think that this will influence pops up in in any way in that a pops up broker can still be set up as it as it always was it just has an additional option of using this feature um and using it through a lot of places so it will it would um ex it would advertise additional information about the resource um but the basic pops up would not change and this is purely opt-in for applications so it it just it just matches well [Music] okay more questions comments you know thank you again thank you very perfectly back on time uh so now it's ricard's turn with two documents in a row starting with uh profiling add-on for co-op"
  },
  {
    "startTime": "00:56:00",
    "text": "underscore yes let me share the slides start to find it in the list okay right so yes hello everyone i will be presenting updates on this draft profiling profiling ad doc for co-op score and i'll jump right in so just to go over a recap about what this document is about so first of all edoc that is a lightweight authenticated key exchange being developed in the lake working group and one of its main uses is to establish a score security context between two peers typically when you run that doctor you need two round trips before you can actually start using os core and the point and the the scope of this document is the main focus is how can you achieve an optimization where you actually combine the third adult message with your actual first oscar request as you can see in the blue box there to the right um so it's essentially defining an optimized workflow for edoc when transported over co-op with the intent to to use it for os core and [Music] it defines um some uh all score specific processing of adobe messengers and it also extends this add-on application profile that has a number of let's say configuration settings related to that execution to take place and in the document we also define"
  },
  {
    "startTime": "00:58:01",
    "text": "parameters related to web linking for discovery of adult resources and their application profiles uh so yeah overall the scope is um transported over co-op um and the main item here again is this optimized workflow to reduce the actual amount of round trips before you can start using oscore communication and uh yeah to go over some of the updates then since itf 113 some of these things were presented already at the core interim during april and the updates now in these slides are because of changes that happened in that book draft which is now in version 15 right so the first point is that there's no more special conversion of identifiers needed and instead there's a simple identity relation where before you need a more elaborate way to convert from all score to adult identifiers which is now no longer needed because of the changes in network so that could be simplified and another point that was changed is that the text and examples now reflect usage of the new content formats so you have this application synthetic or sec and application and dot class c per sec and but the actual combined edo classic request still has an unnamed media type uh some other things small changes updating of the terminology and the replica applicability statement was renamed to that application profile uh more things uh yes some rephrasing here changing a um i must i must not to should not based on feedback during the core interim that"
  },
  {
    "startTime": "01:00:00",
    "text": "was in relation to let's call good behavior expected from the client otherwise the processing of added messages was revised and simplified um when it comes to how you select your own endoconnection identifier which then is practically offered as uh score your own oscar recipient id that you will receive for oscar communication uh also consistency checks on incoming documents yes was revised and things are now also consistent with requirements from section 33 of uh rfc 8613. to yet continued updates the consistency uh and the text about edit application profiles templates was simplified again no need to say anything about diesel squad dock identifier conversion before there were parameters in there about like which conversion method do you want to use that's no longer needed um and then it's about [Music] signaling like if you support the other cluster request the application profile should signal that support and you then cannot signal to use another message for because you can some compatible use another message for together with this optimization um yeah the web linking port was also revised uh removing the target attribute related to the conversion of identifiers and also admitting multiple instances of ed target attribute uh to support uh basically because you you haven't can you have an ead in in each of the doc messages right so you can have an ed 182 d3 etc depending on which other message you're talking about um yeah some security considerations were added like you could uh for"
  },
  {
    "startTime": "01:02:02",
    "text": "instance uh this planning attack if you want to flood this or without the crossover combined request that's actually not the security problem because the server does not process the same electricity multiple times and server performance replay checks on those core protected application requests so this kind of flooding will not give you any practical attack then we have some considerations on block wise so the question is when can the endocrine request get too big because of ed doc so that essentially you're forced to use block-wise well one such occasion is if you have a very large id credit like a big certificate chain or if you have large items in the ead in adt specifically like just a big big amount of data there um then we covered the basically client processing to say that well to clarify that only the first inner block actually conveys endocrine and the other option and if this endoplasmic request exceeds the max max unfragmented size you should stop but this maximum fragmented size is a parameter defined in those score rfc uh to provide particular attacks uh like for instance a proxy injecting blocks in the middle of a block wise um so that's for security reasons that should be obeyed uh also server processing yeah that's just the rfc 7959 and 8613 uh we have new section six guidelines on not using clockwise or using clockwise together with the other crossover request so when should you use it um so the client might use inner clockwise but in this section we assume that it's actually not using outer block wise because typically a client wouldn't take the"
  },
  {
    "startTime": "01:04:02",
    "text": "initiatives used out of block-wise there will be something approximate so it's possible to fragment application data you wish to send but not the actual whole adult class oscar request continuing on more about the block wise and optimized workflow so basically there's a limit here which is the practical maximum size to exceed before you you should use clockwise so there's a lot of logic here to follow and considerations on what you should do but basically depending on certain parameters it may or may not be okay to send those core plus add a request um so if the end of data is below this limit [Music] um if block-wise is not used uh then that means the application data plus the analog data is below the limit and if blockers is used that's when uh one block plus the add-on data is below the limit so i'm a bit long time so i probably don't have time to go into deals and all these considerations but check that section in the draft and it goes into a lot more details on these uh aspects there's also some corner cases and kind of trade-offs when um you actually you you basically you end up having to use block price just because of that the plus also request yes because the fact that you're combining that into a single request and we concluded basically that the optimized workflow uh [Music] can be no worse than the original one but it could also be um basically that uh in this case in some cases you should actually not consider using um their adolescent request if using it means that you end up having such a big"
  },
  {
    "startTime": "01:06:01",
    "text": "request that you're forced to use clockwise but again check the section in the draft for more considerations on this going into some next steps well we want to add more security considerations so about when you should use the other cluster combined request and the relation to access control enforcement and we do have running code on this based on eclipse california and aligned with endoc version 15 of course implementing endocrine and this optimization to do is renew this order registration we did after the option and that the option signals usage of this optimized request uh and if there are no big issues we do feel that the next version may indeed be good for a working group last call and it may here be good to sync with the leg working group and basically take it in parallel with the working group class call of duty makes sense because these documents are very much interconnected and again yeah any comments or reviews are very welcome on this document thank you thank you rickard we are slightly over time there may be time for one question or comment maybe anyone i see christian saying yeah casting yeah i just wanted to to make the point that we we have to be a little bit careful about uh not stuffing our specifications with uh too much informational uh content um there are many reasons why we don't want to do that uh one is that we are essentially dosing isg um but uh also um people who look at this specification and see oh my god that's 28 pages do i have to implement all that um might think this is a complicated"
  },
  {
    "startTime": "01:08:02",
    "text": "document to implement well actually it's not very complicated so i'm wondering whether we have a good way to to put things like these considerations um is is it actually an improvement um to to use this or not uh into a separate place so we can clearly separate the standard strike part which which actually is relatively simple from the how do i use this in the best way possible informational content so i'm not saying that this draft is is the one where we absolutely have to do this now but that struck me as just another example where we are getting into this uh trap of providing too much informational uh content or where we may be getting into this trap of providing too much information and content so i just wanted to to set this this flag here that we should be thinking about that i don't want a response right now but when you work on this document uh think about is is there maybe something that could be exported into an informational document meaningfully um so the the actual specification stays crisp okay i see what you're saying right so to consider it that we don't have a too wide scope and too much content possibly some things could be extracted to a different document or i don't know the appendix as an appendix or something yeah yeah appendix is certainly one way the the informational documents cause about one-third of the isg overhead of a standard strike document so putting stuff into an informational document is an effective way of both reducing the the"
  },
  {
    "startTime": "01:10:03",
    "text": "appearance of this being a complicated document moving things into the appendix if you label it as non-normative then maybe some reviewers won't read it which may be also another way to reduce uh the load but still when the people first look at the document they see this has 28 pages and they won't see that that only 10 of those are in the body at 18 are the in the appendix so actually splitting documents may be something that we may want to do a little bit more than we have been doing and by the way once you have an informational document this can also be used as a little bit of a road map so you explain how the normative documents that are being created here actually fit together and it can be on a different timeline so there are many many benefits that can be had from this but also of course it makes the management of those documents a little bit more complicated during creating them thanks for the thanks for the feedback yeah and i saw by the way christian had a point also agreeing on uh syncing with lake uh as a comment in the uh chat yeah yeah about that just to be sure to understand christian you you would prefer this document to follow up after edoc right i i think i could only make a reasonable working group last call document on this document if ad hoc is also in around working group last call stage okay one possibility was to have them in parallel working robust call in fact but but your comment sounds like uh you'd prefer to have them strictly one first and then you know it doesn't have to be strictly in sequence maybe my comment was phrased lovely just parallel would be great green sync thanks"
  },
  {
    "startTime": "01:12:03",
    "text": "okay in the interest of time business just continue with the next slide set yes indeed i'll change text then yes i proceed right away so now i will continue on this draft key update for oscore which we named kudos as a short title and yeah so again just a kind of a content recap an overview of this document so it essentially has two main parts one part is about a way that has been defined uh to provide a lightweight way to perform key update for score and that's what we call kudos and this is loosely inspired in the appendix p2 procedure already defined for all score and where the goal is essential to renew your master seeker the master assault which in turn makes you derive new sender and recipient keys and this procedure can also achieve perfect forward secrecy and at me uh various reasons why you would like to re-key but uh one particular reason that this draft covers is uh that you may reach limits in how many times you have used your keys for encryption or decryption because there is a para there's actually work going on in c4d where they have the terminal defines some usage limits for aad algorithms so essentially you need to follow certain rules on how many times you encrypt or how many times you failed fail i decryption with your keys before you have to rekey and if you do not rekey and have this excessive use of the same key can enable breaking the security"
  },
  {
    "startTime": "01:14:01",
    "text": "properties of some aed algorithms uh so the second part is about these limits but the focus on today will be the kudos part and the key update procedure the limit sport has has not had any uh major updates recently um so again uh an overview of this key update procedure is basically a message exchange you have a client and server let's say the client is initiated or you exchange a number of messages as you see on the right hand side the key thing here is you want to actually exchange nonsense and using those dances you want to derive new or score security contexts on both pairs using announces as input and we define this update ctx function basically that takes the announcers and the old security context and produces a new security context we also extended the os core option so to have a bit that indicates the presence of this nonce parameter and an x byte that signifies both the length of the nouns but also some additional signaling flags which i will come back to later and we got some comments from ayanna about if in particular like notes on the language if this bit 1 and 15 can be once yes then 15 suggested but we do actually need them before exactly 1 and 15. and by the way these nuns were previously called id detail we now simply just call it nuns so that field in those corruption is simply called nuns now and yeah now i'll go over some of the updates that when we've done practically to draft since the last uh meeting and uh one thing we did here is we defined or rather"
  },
  {
    "startTime": "01:16:01",
    "text": "uh revised and moved uh text about an alternative kudos mode that does not provide forward secrecy um to the main body of the draft uh so the whole idea here is that you need a way to do stateless key updates because some devices may not be able to store uh information to persistent memory and the method the the main method of kudos the main mode we have defined really requires that you're able to store information to retrieve it back after you're rebooted and if you cannot do that you couldn't use that main mode so we because of that we define this mode that doesn't have uh forward secrecy but then uh the benefit is that it's stateless and these devices that cannot store the persistent memory can still use it and well there's then the need for a way to signal this and the way we define that is we defined a bit p that we placed in this x byte in those corruptions so again the x byte signifies the length of the nonce and some of the signaling bits and well the p is zero the sender indicates that it wants to run kudos in the forward secrecy mode the normal original mode if you set p1 you wish to use the no fs mode and basically both pairs need to agree here so that both need to set p to 0 or p to 1 in their respective request response to align and agree to use a particular mode and if they don't agree there is a possibility for a negotiation to downgrade to the capability of the device that has the least capability so that you can still agree and actually be able to run kudos and when you're using the forward secrecy mode basically your security context uh"
  },
  {
    "startTime": "01:18:00",
    "text": "that used to drive a new security context is just the latest security context that you have stored and it's also a key point here that if you are capable of storing to disk and if you're capable to use the forward secrecy mode you must use that mode the uh no fs mode is a fallback if you absolutely cannot use that or if the other pair cannot use the fs mode so when you're using the no ifs mode again you sacrifice for secrecy because one player cannot write to persistent memory and the the difference here is that before you run kudos you the key material you can see there isn't your latest key material you consider your bootstrap key material which is what you were pre-provisioned with during manufacturing or commissioning or recommissioning so that's like a fixed key material that that you you have stored down and you can still remember that even though not being able to write to persistent memory since that's something hardcoded on usa device um so again this is agree downgrading if the initiator sets p to zero the responder may not be able to you know follow up on that because it cannot actually use the fs mode in such case the server can respond with an error response setting p21 to indicate no i want to use the no fs mode or if it's a client that's a responder you send a request with p21 but essentially you use this pb2 to signal to each other and agree on which mode to use but if both devices are capable of using forward series they must do so continuing on so another thing we moved up was the text about preserving observations so this was also a text in an appendix and basically we identified the problem here that there is this risk of um to"
  },
  {
    "startTime": "01:20:01",
    "text": "basically this is a scenario a client can start an observation observation one by sending a request with the request partially x after that the peers run kudos receptors and sequence numbers back to zero and later while this observation one is still ongoing the client will send a new request request to also it requests partial avx um and the problem is that basically you have two kind of ongoing in in progress requests with the same partial iv and this gives you a problem that responses or notifications by the server will cryptographically match both request one and request two so what you need to be careful about basically is that do not reuse the same partial iv right because like the thing is after you run kudos you reset your partially back to zero so you cannot reuse the same partial v that you already are using for an ongoing observation and to solve this we device this long jumping solution and essentially what that means is that after kudos has been run you jump your partial iv forward to the value of the highest rec piv among ongoing observations uh with your client plus one so it's just jump over the highest partial maybe that's already in use for an observation to avoid this accidental partially reusage um and that is basically that i mean that's of course if you if you wish to preserve observations um so to be able to signal if you wish to preserve observations we divide defined one more bit uh which is this b bit um again it's in the x byte of those corruption and if the b bit is set to zero you're saying that you're wishing to cancel all common observations if the bit is set to one you wish to keep all"
  },
  {
    "startTime": "01:22:00",
    "text": "common observations and this is an all or nothing approach both players have to agree and set the beat to one to decide to keep them if one or both of the periods set to be to zero the observations will not be kept and again it's a key point here you cannot just if you wish to keep observations you cannot just like silently forget observations you must explicitly use cancellation requests and um only purged observations if you get a cancellation confirmation from the server because otherwise if you just forget observations you may again run into this problem of accidentally using a partial av that is in use uh for an observation on the server side um and uh one thing that was pointing out there is that if uh two players actually don't want to run kudos in the for sake of key update they may wish to use kudos just for a way to quickly cancel all ongoing observations with other peers uh yeah so another part was about the updating center recipient ids uh this was basically triggered by some discussion on the mailing list and an issue in the os core uh draft guitar well oscar rfc guitar basically and the intent is that due to privacy reasons you may actually want to switch uh identifiers for instance just after having run edward to prevent like if you if basically if you switch network for instance you may not want to be that an attacker can correlate your identity through this id between the old and new network you switch to um and yeah this procedure can be run standalone or part of acute execution yeah this has also been moved up from appendix to the main body and it has a number of properties here basically we define a new option where you indicate your new decide recipient id and that's a classy option so it's also"
  },
  {
    "startTime": "01:24:01",
    "text": "encrypted and using oscar then um and there are some considerations on when you when and when you should use this and when you should not use this and some things you should be careful about in terms of remembering all the used recipient ids some more updates well this is kind of going over the signaling bits right so we define now the signaling bits are placed in this x byte so we have the four least significant bits there that define the length of the nuns minus one we have the normal forward secrecy p bit and then we have the preserve observations b bit and with two of the bits still absorbed and i mean one point here was to place these bits in the x byte and then what we did is we defined the update ctx function to take not only the nouns but x bytes also as input so because these are now involved in the key duration they end up being integrity protected which is a very nice property and for the actual update ctx basically there's two like internal paths it can take one is if your original context was was uh derived using ad hoc you used edo key update to drive your new context uh with advanced as input and x quite a simple the other method is let's say you didn't use addok at all well then you use a simple hkdf expand to derive the key information for the new context so this kind of allows you to use the nice educate if that's available to you but if you didn't use edok you're still good to go and can use the other method uh or when yeah when using method one we have now aligned the text so it's uh up to date with uh edoki update which uh takes uh silver by string as input basically and we also define some rules on when you can like overwrite your prk out and prk exporter"
  },
  {
    "startTime": "01:26:00",
    "text": "keys which are keys uh edo keys that you use for deriving the final key material massive secret master um yeah so this is a bit more details on the update ctx basically we needed to kind of define a way to handle x values and the nonsense so here in this figure x1 and x2 are the row values of the x bytes and n1 and m2 are the row values of the nonsense so we have this like way of blending x and n x and n values into just standalone x and then parameters so you can see here in case of message one x is simply x one and n is n one but in message two you have a bit more complicated construction you have a wrapping zebra wrapping of x one supply string concatenated we see the wrapping of x2 is a byte string that's x and n is constructed in a similar way i mean the point is that we want to do this wrapping because we want to maintain and keep the length information about the nonsense uh in the concatenation so there's no risk of this kind of attack where you just have two concatenated byte uh robot arrays where possibly an attacker could try to splice to do some attack where like the concatenation ends up being the same so in in other contexts it was pointed out that it's important to keep the length and their zebra is very useful because it has the length in the hand the right and then we actually invoked update ctx with this x and uh values and we thin update ctx we do some more wrapping because one key property we want to achieve here is that educate should be taking a zebra byte string as input and lots of feedback on this uh from charleston with some suggestions but that's really the reason we designed it like this we won't have a key update to take a um to take a sip or by string as input"
  },
  {
    "startTime": "01:28:00",
    "text": "because that's how it's designed in that draft yep open points i'll go through this a bit quick so there are a number of issues on the github prep but we'll go through those and fix and take care of those we are proposing here to split up the ctx into two actual separate functions because like i said it basically has two internal methods method one relying on that dock and method two relying on an hqda hkdf-based approach and and we also want to have a signaling way so you can signal to use the method too because what if your context was defined and derived using edoc but for some reason your addox session is not around anymore so you cannot use that key update practically well then in that case you would like to fall back to the hkdf way and we need some signaling for that and one easy way to signal is just add one more beat in the x pipe to be able to signal this and we also want to produce an implementation of this based on those coryova california implementation we already have and of course yeah comments feedback very welcome [Music] anything you have to to mention yes thank you thank you christian if fall back to this method 2 is something that can just be started by one party do does the mechanism lose any relevant properties because if it doesn't uh why do method one after all um well we would like to follow sure but we would like to run use method one if possible if you can use the key update we would like to take advantage of that if possible um and i would say that the this signaling on the fallback that signaling could be done by either party because it could be that the initiator has its education still and wants to use better one but the responder can't or it could"
  },
  {
    "startTime": "01:30:00",
    "text": "be the opposite so both have it has to be kind of a mutual bi-directional signaling the both have to agree to be able to use metal one because if one can't use method one they both have to fall documented but but is anything valuable what is actually lost when falling back you you basically think like what what is the the which properties does this lose any valuable properties comparing method to the metabolism yeah that's uh that's um that's a good question it's basically like they have the key update and the hkdf-based way they're they ask the security they may have the same security properties regardless that's your point as if i understand it correctly um that's the question yes that's the question yeah that's uh that's a good point if if there is a um a concrete a security property that metal one has that meta2 does not have i cannot answer that right now without thinking more about it i'm just thinking about i mean in the spirit of carson's comment here on on uh size of drafts is it possible to split out some parts in separate drafts i was thinking about it changing recipient ids could that be a separate separate draft wrapped yeah i mean i would say it could because practically i mean this is a standalone procedure you can understand alone um without kudos but you can also run it embedded in accuracy execution so it it could be if if that that it could be a way to go i mean yes to split this out into a separate document it would be that would be feasible and what about the key limits and the kudos protocols"
  },
  {
    "startTime": "01:32:00",
    "text": "i mean yeah i mean i think i would say same story fundamentally they could practically be you could have one draft that's about kudos to one that is about the limits relating to score that that could be like that for sure um i think it grew out like this through due to earlier discussions and feedback it it ended up being disrejoined in the same document and they are related relevant in the sense that okay one reason to do key update is because reaching the limits but fundamentally if the desire is to have a like more but smaller drafts yes i believe they could be it could be split yes okay thank you thank you uh rickard and all your comments we're gonna need to move on we're 12 minutes late please follow up presenters try to save one or two minutes if not more from your presentation thank you hi martinez um martina you're muted i think sorry can you hear me now yes great okay i tried to make its quick air then um so uh yeah i want to talk about dns over co-op uh so i give a quick introduction for those who weren't here the last few meetings and give you the changes since the last interim i attended and then go a little bit into some discussions around dns push and co-op observe which came up after we pushed the current release the current version of the of the draft"
  },
  {
    "startTime": "01:34:00",
    "text": "um and yeah the basically we want to save dns requests from iot devices against each dropbox so the typical solution for that is to encrypt the name resolution and our proposal for that and other approaches don't work in the iot scenarios we are looking at is to use dns over corp which is able to encrypt the communication either via dtls or oscar and we also have additional advantages to um like blockbuster message trends where to overcome past mdu problems which you encounter for example with dns over dtls and we can also share system movements with co-op since we can use the same socket and buffers and also reuse the co-op retransmission mechanism since last interim and last draft version i presented here we made the we made basically some ranges to reduce restatements on core behavior among other things we try to be more precise when a confirmable message should be used we cleaned up the our paragraph on error behavior we moved we removed the block-wise recommendations completely because they basically represented what co-op request rfc is telling you about we removed the sentence that states that fetch is sent to server uri and we removed the configurations on proxies on caching especially we provided an algorithm to synchronize up the co-op max h and dns ttl so that not some timed out dns records are lying around in some co-op cache somewhere and we remove the e-tec considerations since that also just restated core behavior"
  },
  {
    "startTime": "01:36:00",
    "text": "um then we did some kuby buns we recommended oscar usage and basically just stated okay use score if you want to use dns over co-op but you don't have to and we drafted out already the observed usage but as i already said in the beginning this still needs some work and uh we removed the tv duns on issue four which was about uh having some repetitions in the dns format uh which uh we want to in some at some point uh go put into a separate draft for a compressed content format which probably will be sibo based um and yeah and left to be done maybe we can just discuss this here also is the jana consideration uh where we didn't pick an id for the application dns message content format yes uh the main reason is uh because the up probably with dms some nice numbers we want to use and i wanted to maybe discuss this first and so after all that i go into the dns push and how to implement this with co-op observe so first a brief primer on how dns push notifications work according to rc8765 [Music] they are based on the waitful operations and i can basically very organize with the query response paradigm so you send the dso stateful operation with a subscribe uh message in encapsulated for a certain record you want to query uh that then is uh for that then you can get an basically a subscribe ack and then the resolver can start to push also with"
  },
  {
    "startTime": "01:38:00",
    "text": "dso messages if there is an update to the record and also you can unsubscribe via a dsl dsl option so uh the problem with that is that with uh that the rc eight seven six four five basically just states that we require dns over tls for that and there's basically a must to that and we also need additional state information so to not uh soften this requirement and also to make the implementation on the client side simpler is to use rather use co-op observe as a signal to use subspace instead of a query at the doc server which would look a little bit like this but we have it just a normal fetch with a normal dns query encapsulated within an observe option that the doc server takes to do the subscribe that we saw before and then when there is a when there is a push the observed response basically also comes and there's an observed notification oh there's a little arrow but i leave that to the reader um and for unsubscribing just also a normal unsubscribe with fetch or like when there's coming a reset back from the client so as an example there could be i put that on the mailing list maybe some comments there could also be given basically i i worked out how dns uh service discovery could work when using uh doc and basically if you would just ask for a powerpoint of your co-op services in a network and then get respond back and this would be the push and if there are new services"
  },
  {
    "startTime": "01:40:01",
    "text": "joining those this list would be just updated so um yeah that's basically it for my part at least what i uh drafted out so if there are any questions or comments you're welcome to give them now thank you martinez any comment question anyone none in the queue in the chat in the room so yeah this draft has been received pretty well as so far especially the the previous idea of meeting with also a few people supporting uh the work and committing to review so the chairs believe the obvious next step is starting a call for adoption on this is there any comment on this any objection then we'll start an option called the mini mist okay thank you very much martina thank you also for saving time next presentation is giuseppe performance measurement for co-op hello everybody can you hear me yes we can here to see you hi okay hello uh i will share the slide uh it's the second from top uh second left second from left icon on top to request sharing the slides no yes and if you can please speak a bit closer to the mic okay"
  },
  {
    "startTime": "01:42:06",
    "text": "okay i guess you can see the slide now so uh okay let's start so yeah this is an update about the co-op performance measurement option so this is the 0-2 version and i'm presenting on the alpha of the quarter so yeah just a few words about the motivation this is not the first time that we presented this work um so we also presented at last at the interim meeting in march so the motivation is to find the mechanism to measure the performance in code to meet the operational requirements and of course since we are talking about constrained environment we need a simplified simple mechanism for for network diagnostic since it is resource consuming to read id sequence numbers store time stamps for constraint nodes of course the methodology needs to be straightforward and simple to be implemented regarding the changes from the 0-1 version it's it's important to clarify that most of the changes are to others the comments and the inputs received during the last entry meeting from carsten chris and marco in particular then i want to highlight the main points and the main changes we apply to the to the latest version so first of all we clarified that the co-op option is of course selective safe to forward and it's not to be included in the cache key so then we specify the detailed scenarios and the use cases in particular we described the use of non-proxy endpoints or"
  },
  {
    "startTime": "01:44:03",
    "text": "proxies or non-collaborating proxies and also we described the application in case of oscar then we also included a new subsection a new section on management and configuration aspects even if these aspects are not fully in scope of our data and then we also improve the security considerations part uh by adding the new consideration on gtls underscore as well the the methodologies that are used by this mean the option that is introducing this draft are not a new methodology but they are already defined in ippm working group there is a diagraph the working group plus call that is called explicit flow measurement and these techniques employ a few marking beads inside the other of the packet for los angeles in particular there is the spin bit idea to create the square wave signia using a bit the length of this square wave signal is equal to rtt and it is optional in the quick specification while the square bit creates square waves of very low line so for example 64 64 packets and this can be used for packet loss measurement these are the two basic mechanisms that are also defined in sdpm so the the goal of this draft is to apply these methodologies to a new co-op option i cannot speak a new co-op option carrying these"
  },
  {
    "startTime": "01:46:00",
    "text": "performance measurement leads in particular the draft defined two different pattern if we use the square bit or the this and the spin bit together or if you use a sort of combined square bit which reinforce the square bit with also delay information in order to measure everything with just one bit and we also extend the possibility to have the the option with also other event beats that can be used for signaling the proxy or the gateway that maybe do not have the capability to apply the algorithm for split and square bit can read these event bits to understand the different levels of thresholds and so on for delay and loss okay now um i want to describe of course the the addition one of the main additions that we we did in the last in the latest version about the details of the scenarios and use cases so the main usage of this option is for end-to-end measurement but split measurements are also loud and this is an important point because the intermediaries and numpad observer can do the measurement as well and they can be a network function on probes that can act as an important server or gateway or proxies that are tasked by cop client to perform a request from their br as i said there are different cases the non-proxy endpoints the collaborating or non-collaborating proxies and your score in case of non-proxy and points uh the co-op the cop option can be applied end-to-end between client and server since it is elected it can be simply ignored by an endpoint that does not is"
  },
  {
    "startTime": "01:48:00",
    "text": "not configured to handle this option the the enable measurements are end-to-end of course between client server home parts uh botup strip and downstream on the observer and also intra domain because if you are more if you have more than on one observer that can be the borders of a domain they can also do the measurement between two observers so you can have a sort of intra domain on path measurement all these measurements are defined in the fppm draft so are not new let's say for this for this option for this environment then we have a scenario with collaborating or non-collaborating toxic in this case the the option can be applied end-to-end between client and server or also between proxies so if clients and server are not configured to to make the measurement maybe the proxies can do and they can apply the option and in particular in case of non-collaborating practicing since this option is safe to forward it is of course it is safe for forwarding by this proxies the enabled measurements can be also can be different depending on the case of collaborating proxima or non-collaborating proxies uh in case of collaborating process of course the measurement can be end-to-end and on path the intradomain as the case of non-proximity endpoints while in case of non-collaborating proxy they can also be end-to-end and on path and intra-domain but cannot be between proxies and also the proxy cannot act as an unpopped observer"
  },
  {
    "startTime": "01:50:02",
    "text": "the the final case is the application with oscar in this case of course if the crop up option is sent as an outer option it allows bottom to end a non-part measurement otherwise only end-to-end can be allowed yeah final slide so yeah this draft as i also mentioned before is based on these methodologies that are also optional in um in the quick the specification and also in another c that is also applied to ipv6 so it aims to meet the limited resources of constrained environment since the mechanisms are quite simple so we believe that at some point maybe uh core working loop can consider to adopt this this work for performance but of course for now we welcome questions comments and also cooperation on this work thank you thank you unfortunately there is no much time for discussion just please pay attention to the comments uh in the chat from uh on carson and christian um yeah i also wanted to add a high level comment um i was doing the draft and i still have quite a harsh time in navigating the the many alternatives that are possible to use the way you can combine them and which limitations possibly or drawbacks you have depending on which combination you go for so i think especially the central sections of the draft should be yeah revised to to highlight the limitations of the different alternatives presented in a very systematic way but to further help i plan to send out a review to the list after the summer break of this document where i i will also raise these points yeah i will try my best consider that"
  },
  {
    "startTime": "01:52:01",
    "text": "regarding the limitation there is the draft in ippm that i reference and in that draft there are a lot of description of all the possible measurement and the and also the limitations so maybe i can refer add more reference so the reader can can go to the ippm drop if you want to go deep to the to limit to understand the limitation and the trade-offs of different solutions i will i will i will improve on that thank you for the interview okay again i'll come back with a review anyway and yeah i encourage folks to read the document and also comment on the list quick question what is the target status of this document is this going to be a standard or the informational document or an experimental document uh i guess since yeah for now it is a standard because yeah we are asking for a new option so i guess they should be standard but if maybe if we want to i don't know what is the procedure for defining a new option in the car but you just register one um so this this could be a registration that you make uh we have uh space for for um expert review so i'm not saying that this is what we should do i'm just saying that's the gamut of potential outcomes that we have and an experimental protocol for instance would also be um a possible outcome so i think we should have a discussion on the list because for me if you look at the chat there's also the question how much of this is an interoperability requirement and how much is just informational content about how you best"
  },
  {
    "startTime": "01:54:02",
    "text": "use this so let's have that discussion on the list of course okay okay thank you thanks thanks a lot so let's move to the next and last item christian yeah take your time of course it's great if you can spare some minutes in the interest of the final recap [Applause] so what i'd like to present here is how we could transport co-op or gut and i will digress uh at the end a bit into the transport indication draft which is not really on the agenda for today but it is something that that interacts a lot uh with this document now um i i've um the original design for transport for co-op or get which is co-op over the get protocol that is part of bluetooth low energy so basically it's co-op over political low energy um comes from 2020 uh when also an itf-109 i've i've described this briefly to the working group and proposed it for the experimental track in the course of 2021 not 2001 i've worked more on transport indication which provides a lot of background for co over gut because cover for cat would register a new co-op scheme and there is the um [Music] there is this this open item of finishing that making something usable with respect to protocol negotiation before we register any additional schemes now this in early 2022 um some industry interest"
  },
  {
    "startTime": "01:56:01",
    "text": "has sparked up on on that topic and there are now uh people from both assa abloy and edf that are interested in furthering the specification using it uh for example in combination with the ace framework so um they and i have started um filling uh filling out some gaps in the specification uh which i'll come to in the next slide and here i'm giving the status update of this on this so what is um what has happened in the document already in the version that i've uploaded before the cutoff is that it is now more explicit in differentiating this from other from from alternatives that are around in particular um pick um choosing to go directly over gut versus uh choosing to go over the ipsp profile on ble which exists and is established um is something that is um limited to a particular choice or a particular to that is shaped by limitations of particular environments so when you're in when you're operating a cell phone you do not have the option uh to even reach the com the necessary components in the bluetooth stack to implement uh six lupon over ble or ipsp you're limited to basically taking gut everything else is not as easily accessible as as get from um from an application implementation point of view there is one alternative that is also being considered that is the golden gate approach that fitbit presented some time ago which is taking the accessible components up to get and then building an ip transport on top of this but given that in practice this would mean that applications are starting to implement an ip and a udp stack and given that this is introducing a lot of overhead i think it is not the right approach for for this partic for the particular use cases"
  },
  {
    "startTime": "01:58:01",
    "text": "that we are looking at here that is getting from your end user device into a cob-enabled device even though they are not on the same kind of even though they don't have a routed network between them and even though you can't just join this yearly network from the from the phone things that are happening as part of uh that are ongoing and that are not part of the document yet are about fixing limitations so the original draft was intentionally very limited um there were no concurrent requests there was only one role described of what was the servant who was declined there were not even tokens in there because the original idea was that there are different characteristics in in in get so maybe you these could be exploited to not even send a token at all around some of these um turned out to not work exactly that way so these are being reshaped now some of the assumptions didn't hold and some changes are just necessary to for example get bi-directional transport the reason we can't just take plain cobalt gdp and pack it into get is that it has vastly different properties from the from the udp layer that is underlying code so compared to that for example we have complete ordering reads and writes are never reordered by the network but then again the reliability this provides is highly asymmetric so this needs this needs a few changes but i won't go into details of those changes because they are essentially something that um that is being hashed out with people that are experts in budget low energy um and outside of the scope for of this working group's expertise what is very much inside the scope is uh speak is at how things would be addressed so the"
  },
  {
    "startTime": "02:00:00",
    "text": "natural choice here is to have a new scheme and put bluetooth mac addresses in there um the hard thing is that we don't always have these mac addresses visible at all for example because different platforms has different takes on what it means to not uh to preserve the user's privacy so in essence we are down to the platform will provide some identifier and that identifier might only be meaningful to a partic um to on that particular host and while this sounds strange for your eye it's not completely unheard of because we are in the very same situation whenever we have linked local addresses um their uri form also also only makes sense on that particular host and is not usable across the network but the bigger question this sparks is when do we actually need those addresses because sure if we had a mac address we might um try to get some routing via proxies in there but that's not what typically happens what typically happens are two scenarios one is that the device is sending a request out through the typical case the the end user's phone up to some service and in that case the phone acts as a proxy and the request goes uses forward proxying to some address that is not even core plus bl uh core plus gat but something completely different like code plus tcp and translated by the proxy on the phone and the address of the device never gets into the whole game and the other scenario that we often see is that the device registers itself at some service that is like operates like a resource directory for example in lightweight m2m this is what happens and only when you start thinking about more niche use cases like after having registered still doing p2p contact then you start to think about what scheme can be used here"
  },
  {
    "startTime": "02:02:02",
    "text": "i think that this um these considerations for what addresses we can use for the um for for and when we actually need them should shape the direction which transport indication is going that is that nodes whose local addresses are not particularly meaningful might not only want to use a particular endpoint identifier when registering at a resource directory but start using whatever their a more semantic identifier is in the first place and just of proxying through these and transport indication is document that provides all the building blocks to make this um to make this um this practically usable but i think this should be not only part of the result of of me applying the particular problem but the particular solutions to that problem but part of a larger process in which we re-evaluate how we do addressing in a non-traditional setup thanks carson that's a great keyword here and i think it also highlights out highlights the the troubles this is having because this is not how we've been doing things before um but then again maybe we just hit what we are doing in things like approximate resource directory going forward with cope of agat i'll be working on this on the on the details of how is this transported over over over the cat side um but i'll need input from this working group as but um as to how this would interact with addressing um also to not only to for this document but also to further transport indication and last but not least um this might be a candidate for a standard"
  },
  {
    "startTime": "02:04:00",
    "text": "track document now given the way uh people want to use it and for and this too means that we should have more of the discussion on this here and not just um working on this document alone thanks comments questions i think we're a bit over time but if we can go five minutes over time there might still be room for a question and you're probably going to close the room in a few minutes less cars then yeah i just wanted to to say a plus one but i also wanted to create a local discontinuity in the space-time continuum so we can continue talking for a couple more uh minutes uh so a few people are have to go that's unfortunate but yeah so um i i use this this name non-traditional addresses here just to point out that this may actually be the interesting uh question uh how do we work in environment so we don't where we cannot make the same assumptions about addresses of course nets already provide one such environment but we pretty much know how to manage those but these addresses are weird uh and and we want to understand how to use them in places like like directories and proxies um and so on so yeah let's let's do that thank you and as mentioned in the chat let's bring this to an entry meeting until then it's good if people read the documents and comment on the list of course we need that too okay we are at the aob five minutes late uh carson you still want to very quickly mention that item you had yeah so i looked at the the core group"
  },
  {
    "startTime": "02:06:02",
    "text": "com proxy thing and actually i had it on my to-do list in line 175 and i definitely will get to this but maybe not next week um so yes the the idea is that that jaime and i have to come to an opinion on on what we're going to do there next but definitely this is a document that merits the attention so expect to hear from the chairs about that soon um the the corp s plus jp y thing i wanted to mention um in the anime meeting it turned out they want to use resource discovery for a resource that is not your grandfather's core s resource but they have a special tunneling protocol installed there and our knee jerk reaction to to changing anything in the transport uh of course is to add a plus transport uh to the ui scheme and we should check whether that is actually what we want to to suggest to the animal working group to to handle this because right now the the resource type registration they are making is a little bit icky because they are advertising a resource that doesn't exist and marco you wanted to say something about the interim schedule right the very last bit we still have to confirm with the seaboard shares but we plan to resume with interim meetings for core at the end of august on august 31 31 we'll confirm it to the list and that's it any very final comments remarks anyone"
  },
  {
    "startTime": "02:08:01",
    "text": "and then thank you for your time and extra time keep up the good work enjoy the rest of the week talk to you at the internet thank you all thank you bye it's almost like that"
  }
]
