[
  {
    "startTime": "00:00:17",
    "text": "Hey, folks. We're just gonna give it a couple minutes because people are still on their way back from lunch. Good morning. This email are you also here? Hear me? Hi, Angela. Yes. We can hear you. Yeah. work. I'm great. And at least that will And I'm used my microphone may worked. Sure. Working on this. No. Just because of the video, Yeah. They're trickling it now."
  },
  {
    "startTime": "00:02:12",
    "text": "Minute order. Maybe right now. Soon. It's true. Just just just how's that? No. Actually, you could just press next Okay. Yeah. No. No. I mean, I could also do that myself. That's I was saying. what Sneaking, I think this a killer killer app. Yeah. Screen. Since flip phones went away. Oh, So I didn't mean to flip 2 k. We're starting at 5 past. So that's 2 minutes."
  },
  {
    "startTime": "00:04:03",
    "text": "Thursdays, senior like, just Yep. Yes. Roughly 60 seconds to relax. Thanks. No. Great. Yeah. Indeed, the name. Is Alright. Right. Yeah. There we go. Hello. Welcome Okay. come to the congesting control working group. My name is Reese Engel, and I'm co chairing with Eric Kinier. This is a hybrid doing, and also being recorded. Just a reminder to use the buttons in the media code, chances, or you've you have a bit of experience with them already, This is the Northwell. You might have seen a few of these by now, It's the terms under which the IETF, operates. Please make sure you act actually do read it at some point. We also have code of conduct, and it's because we, we're here to make this working group a success. Right? And part of that is making sure that our working group is a friendly and inclusive space. That people actually like to participate in, and they feel, you know, invited to So, let's make sure we're being professional and respectful to each other And when somebody, if and when something comes up, please reach out to us as chairs. You can find us here in person. If you're here in person, you can email us we can talk via email, video chat. You can also reach out to our ADs or, the onboard team. So here's a couple of helpful links mostly for people who are reading those"
  },
  {
    "startTime": "00:06:00",
    "text": "slides, We're not in this meeting already. And, Right. And here's our agenda for today. So we already have a scribe. Thank you, Matthews. And, we have a couple of agenda items, is there any agenda bashing? By any chance, Okay. So If not, we're gonna briefly talk about 50. So this week, this. Which has matured quite a bit. And then we're gonna spend some time talking about other items. And at the end, we're talking next steps for CCWG. So I'm very excited. And I would like to invite Martin up first. Thank you. Good afternoon, everyone. I'm Martin Duke. I'm one of the editors of, 5033 disks, along with Gordie Fairhurst. This just concluded working a group last call about a month ago, that we got a few issues, which most years of all, I think there's still one open PR, but It's not frankly, a big deal, I think, to to resolve it. We didn't get a ton of reviews. Given this is the only this deliverable for the group right now, there's a little disappointing as punishment, I'm not gonna read the drafted verbatim to you. I mean, I'm just kidding. I I I I am, however, going to kind of run through kind of the the I would hope that maybe a few of you would read it, in the next few weeks. Before we move things forward. And so I wanted to give a little kind of high level Here's what you should expect. Here's what you should be looking for. A kind of points. Next slide. Wait. I have a thingy. Never mind. Okay. So, Many of you know this already, but, the"
  },
  {
    "startTime": "00:08:02",
    "text": "The main purpose this so the 5033 is is a is a series of of, criteria to evaluate a congestion controls for for standardization. It was written in in, I think, 2005. Was a very different, internet in a bunch of ways, in particular, Could you certainly, could you ask control space? Usually, proposals would come from the academic community, just because the resource is available to academics in general, you would have maybe some simulations, maybe very small scale deployment on a campus network or something. That is not, the the situation you face today. We have hyper scalers proposing new congestion controls, deploying them globally and getting, like, enormous amounts of data about them. The the kind of flip side of that is those people don't feel like they need to come to the IETF for any sort of standards approval for the deploy, which maybe shows in some ways the system is broken. We had an ex we, had a very recent experiment experience us standardizing cubic, which was not I had seen at least one of the co authors here. He he did not enjoy that experience. He would give it very few stars. Which is in some ways absurd because, obviously, keeping the default in in the internet among other other platforms. So anyway, so that sort of informed all this. So so hopefully not only can we make that less painful, but also, the other sentiment that was kinda driving this we think the current standards, Acubic and Reno, are the only current standards. Have some bad habits in them, particularly related above buffer bloke. And by being sort of conservative about about our interaction with the stands for perpetuating this bad habit. So maybe we can up with something better. This document also has a lot of non goals, and, one of the tasks of us as editors, which kind of beat away PRs and other suggestions that were kind of good and correct in their way, but also maybe orthogonal to the purpose the draft. So this is not a congestion control"
  },
  {
    "startTime": "00:10:02",
    "text": "tutorial. We will try to limit the extent to which we teaching people how congestion control works. Expressly did not want to be cutting edge or innovative here. We got some really good ideas for, like, new metrics on how to think about congestion control very clever, very interesting but maybe a little too bleeding edge for what we're trying to do here, which is to encapsulate our our current understanding of the space. This is also not to create barriers entering the ITS. After reading it through a few times, we realize that someone could look at this document and say, oh, this is a checklist of things I need questions I need to answer. I come here. And that is actually an an insight. That's not what we wanna do. And so I added that paragraph in the intro there, gosh, probably 6 months ago with a part bolder there just like, no. You do not have you don't check all these boxes when you get here, just please be prepared to engage with us on these as we go. Also, multicast is not a topic. AQM is not a topic. Except to the extent they inter that they directly interface with with a congestion control. Okay. So let me just run through some of the highlights of of the various sections, section 2 just talks about Experian model versus PS and just has some some principles that should be applied here tries to say, well, what does it mean that it that that an RRC is experimental versus PS, what are kind of what do we want to what what kind of congestion control is maybe best done as an experimental one first, which one might which ones might be comfortable to go straight to to PS post standard? Okay. So there's, a few sets of criteria this is really complete reorganization 505033bis. I found the way that those, points were laid out to be a little bit confusing and not, not, not, not, particularly well categorized. So we, we took another shot at it. So our first set is just single algorithm criteria. So these are These are, know, taking a congestion proposal and how does it"
  },
  {
    "startTime": "00:12:00",
    "text": "how does it interact with itself, in a number of different and do a different metrics with different sort of models of, of flow lengths. Then we have mixed algorithm criteria, which you would expect what the the, you know, Internet, of course, have has a number of test accruals that that are widely deployed. And you should definitely look at, how the new new proposal interacts with those. There's some some very, like, vague language about real time congestion controls. I think last session. Actually, last several ITS. We had extended discussions on what can we say here. Given that what is deployed is often not documented and what is documented is not deployed. Least in RFCs. I do wanna call out here that we are not, the one, I think, real intentional softening of of the language was on this idea of renoch and cubic fairness, that was like a very conscious decision. We definitely cannot starve those algorithms, but we want to have a little space to maybe nudge them out of the internet as we go. Zahad, you had a Question? Or comment, Jahaida's individual. So the real time condition controller, has published some requirement documents While how have we looked into that one, can we generalize something from there? Because they I I know, like, the what is documented in Aramcat Right? It's not deployed. And what is deployed is not, like, currently a documented somewhere. But the requirements remains same. I'm 95% sure that that we we name check the the RMKit documents in in in the draft. So, like, it was not like we're ignoring them, but, because because our statement is running around, let's make sure we test against the things that are that are widely deployed. It was kind of hard to say. Like, well, okay. I'm out of the position that I'm not 100% sure that we need to That I am not sure what what guidelines to play. About."
  },
  {
    "startTime": "00:14:01",
    "text": "How fair and how fair our non starvation we need to you need to be with respect to the RMCAT algorithms. Given the level of deployment right now. Now that that environment that could change as, like, they if they gain wider dot people start applying. Those algorithms, then it would become more important. But that's, to me, that's a difficult normative statement to make right now. Yeah. That's my personal opinion. That one. Next whoever's next in the queue, Christian. You now. Okay, Christian, please. Yeah. I mean, I just want to reinforce the point that you are making about general purpose condition control, comparison, etcetera, being fair. 1 of the big we had when working on this document. Is that being fair as multiple dimensions We used to measure being fair by looking at, okay, we do a simulation with Pete Aggregates, a against Abroid B, and we verify that they're all after some care of the bandwidth. That's one dimension of being fair. There are also dimensions of being fair, like, if you pit algoids a against algoid b, Do you suddenly increase the packet loss rate for outgoing B? Even if you do have equity of bandwidth, And that would be bad. So you you don't want to do that. Oh, Do you suddenly increase the long trip time experienced by are going to be That will be bad too. So The I think one of the value of what we're doing there is, say, hey. Be careful when you analyze Because there are several dimensions and it's okay. To Be a bit fuzzy on the bandwidth equality. If in return, You get lower rate and see all lower packet losses, for example. I mean, this idea that there are multiple criteria's and there is no strict thing."
  },
  {
    "startTime": "00:16:04",
    "text": "If you have to control what you are doing and you have to understand what you are doing, that that's the real point. My opinion, Excription, Lars. Last day, Greg, to follow-up, I came up to that something else I'm gonna say later. But to follow-up to a question, maybe something that we could put in a document would be that you know, Ummy. Just the mic. You're running against this is even on, I guess it is. I just have to go real Maybe we put something in a document that would say something that you shouldn't impair the path so that other protocols are outside of the operating region. Or I'm making this up as I go in, but you know what I mean? You're basically talking about but, about throughput, but sort of creating a path environment where where others are Yeah. We we spent a lot of time words missing that Christian made significant contributions to it. I I really invite people to, like, just read what is there and and and, coming on it because it is it is a pretty delicate way, the purely delicate thing to express. Yeah. The the thing I came up to talk about is the real time CC stuff. Which is sort of different. No. In in in the sense that, I mean, a, typically real time work flows have sort of an upper bandwidth cap they're not like bulk transfers. They will just use like home every much they want. Right? So that is nice. Right? So the the harm potential here is lower because they will only, like, interfere until they get there. Happy to the happy place, and then hopefully, gonna gonna stop running back up. The other thing that's different is that, They're typically deployed in in in in interactive conferencing systems, which have pretty tight feedback loops about how the quality is because the deployers of those systems wanna you know, not make your users unhappy. And those feedback loops are probably much more real time than the ones we see for, like,"
  },
  {
    "startTime": "00:18:02",
    "text": "traditional TCP and other pedestrian controls for bike transfers. I mean, hyper scalars have that too, but it's a very different kind of control loops length, then a video conferencing system where basically you get frame by frame almost information about how how am I presenting this to the user. So those two things together, I think. Don't make real time CC as problematic as we thought it might be when we did our MCAD, which, like, with the rise of WebRTC. Right? We were wondering, like, what the hell is it gonna do to the network. And I think In hindsight, right, the the problem is probably more controllable and more controlled and not as bad as we thought. And so it's okay maybe to not lump those in here. So thank you, Lars. So I think some of the sentiments you expressed on how the dynamic the properties of Real Time Care's control are in the document very concisely, but to go back to my point. We're not trying to write tutorial and trying to focus on what do you actually have to do? What do you have to show. And and so and so the language on what you have to show in this regard is pretty soft for some of the reasons that you describe and also for the practical reason that there's just it's hard to define a good test when no one's written down what the important protocols are doing. In a in a stable way. Okay. So, talk a little bit about criteria. Now then there's also scenarios there's a set of mandatory scenarios, which are kind of the the general internet, I would say loosely. And so I mean, I mean, these are kind of the the canonical cases. And so you really, really gotta have you really gotta look at this before you standardize something. Preferably you have real data about if you if you deploy over the you know, the general internet, you will generally also get results that are relevant to these these particular scenarios. Then we have special cases, you know, nontail droppy QMs, and all these other things you can read these are things that are kind of rare enough that you might not"
  },
  {
    "startTime": "00:20:04",
    "text": "get good data just by having a general internet deployment and of aggregating everything together. So you probably have to look at them separately. You could do them with simulations with analysis. You should be prepared to talk about these. It is in many cases to exclude, a particular scenario from your applicability statement at the beginning of of the document depending. So, this this is a little looser to a lot of sheds here instead of musts. But that's this is just another segment of the document. So yeah, as I said earlier, working last call is complete is not too late for reviews. Please have a look. The chairs decide they've had enough, then we'll move it forward. To the AD. If there's something that seeing this outline, you think, boy, you really missed the boat and you need to either change or something, this would be a good time to bring it up. And if anyone thinks that this document ready or not ready, this would be the time to say so. is And that's it. Thank you, Martin. hello, microphone. And Corey, Yeah, we've seen some really good engagement from a number of folks with with great feedback coming back. But that number of folks has not been a super large number of folks. So the the feedback that we've been getting been really in-depth and and is greatly appreciated. But this is very much a good time to if you have not recently read through the latest version, perhaps during the last call, This would be a very good time to to do so. See Corey just joined to the queue. Yeah, everything Martin said, I agree with. Page. So the reason for joining the queue was, Jonathan Lennox said in the chat, should data center really small RTTs included among the special cases, Martin. Booking group, what do you think?"
  },
  {
    "startTime": "00:22:02",
    "text": "Yes. I'd I'm I guess I haven't looked at it a minute. I'm a little surprised I forgot it. Because, certainly, data center is in scope for the working group, when we wrote the charter, So, yeah. A good point. Can you can you add an issue, Corey, while you're in front of the computer? Filing one right now. Oh, excellent. Thank you. And I guess It is important to ask something on this topic because when the original spec was produced. Data center work was explicitly out of scope of what the IETF would actually standardized, that was thought as being a different area, and wasn't really the internet. And I think that has changed now thinking over the years. So Yeah. It seems a good comment. I think we should do something. Yeah. We'll make an issue. need people to comment should be straightforward. We That on the issue. In GitHub as well because Martin and I are trying not to make this up ourselves. We We we need people to have opinions and to help us make the right text. Strikes you as a straightforward section ad. So, yeah, we can try to put something together. But if you have to offer, we will definitely accept it or look at it. Christian, Yeah. Regarding the data center, the premise that we have to be very specific but but but mean by data center, There are some data center scenarios that are uniquely data centers. Like, for example, sending a hadoop query to 1000 nodes I have 1000 notes coming back at the same time. Research and trying to organize that I mean, these kind of scenarios are not typically found on the internet. We do something with data centers, Please join in, and also I want to look at that. Please Give some details about the scenarios, the data center scenarios that you want to Take into account."
  },
  {
    "startTime": "00:24:00",
    "text": "Lars Negra. Yeah. Kristen has a good point. The other thing that special and data centers that typically you see these co designed, forwarding plan, condition control proposals, right, that are really relying on on the fabric doing something non internet y. And and those are interesting, right, but you gotta sort of, like, describe both of them together. And that that's the thing that doesn't make them usually applicable to the internet. But they're still interesting, and we should still, like, people can present them, but they should be tell us what the the data plan is doing to. Thanks, Lars. And is your incentive too? I I know a lot of people assume we're actually here to standardize scooters controls rather than argue about process. Your incentive for reading this document is then we are completely deliverable. We could reach out over something that might be more interesting to you. A little bit more concretely so we're dumping in. So so did have a bunch of site meetings with, people who are unhappy with Rocky, for example, which is a non IETF InfiniBand Trade Association Technology for doing RDMA over 802 one is p f the PfQ stuff. Right? And and there's DCQs in, but there there's alternative propulsion. There's a desire to maybe come up with a solution for those type of ethernet fabrics the IETF. And that would work. That would be very interesting to see here Right? And and that would need to be described in terms of what do you expect from your fabric? And then also what do you then can do at the condition control level? I look forward to that draft. Jeff, I'm just considering video. So than this on daily basis. So, tipping a couple of discussions and some spillovers from IPPM, but it doesn't work on the Internet. It's not meant to. The specific use case for data centers. Yeah. There's, number of, congestion control mechanisms deployed today. So DCQCNS must well known as combination of ECN marking forward and PFC backwards."
  },
  {
    "startTime": "00:26:01",
    "text": "Practically designed for storage, not really for like, yeah, type of our clothes, So you do replacement. You do improvements. There is, you know, what's going on in this Tuesday. I clusters, from, like, 1000 GPUs last year, we went 200,000 this year. So it's a 100,000 endpoints talking to each other all the time. I'll choose most of the time. Alright. So Special congestion control is very much needed if your GPU is idle, 20% of the time, you've just lost 20% of the value. Right? So UC presentation on HPCC. There's similar efforts with different signals. Practically, we need something that's very within order of 12 FTTs. Something that 3 Lee. Makes difference in terms of how network behaves Whether they're done on the endpoints or nicks or on the switches. It's kind of secondary, but we are looking at the large ecosystem of things that need to happen, and I believe CCWG is the right place to do the Yes. So this this document does have some language about yeah, well, I broke things as usual. Okay. I might just have to check back on. About your mic. Okay. This is not good this is not good video, but, just briefly. So this document is intended to and I think has language in it that says, you know, it's okay to standardize something that is not use for the for the general internet. You just need to state specifically, like, this is data center only or IoT only or whatever your whatever your case is. So hope hopefully, that's well written and, you know, I'll be who will will love any comments that that help make that clearer. And, yeah, I mean, certainly, the the CCW charter, has that absolutely in scope. As it is today. Is it fixed? Thank you."
  },
  {
    "startTime": "00:28:04",
    "text": "So, if there's no other comments, thank you very much. Look forward to your review. Hang on. I would like to do a show of hands to see who has actually read the draft also to remind everybody to join the meet echo if you haven't. Very strategic. So no opinion means I am reading right now. It is open on my window. I think you've you've read more than more than 0 words. Well done. One one of the 2 recent river revisions, maybe. We might as well use the no opinion point because I don't think I think everyone is opinion whether or not they've read it. Oh, it looks good. We have a bunch of people read it. We had a discussion. So, yeah, let's give it a couple of weeks and then shipping. Yeah. It's good. 12 is is more than the reviews we got. So that's I was glad we got did that. Thank you, Reese. Alright. Next up, we're going to talk a little bit about rate limited sender. So one one of the things that's that's worth thinking about here, and we'll talk about a lot at the end of the meeting is as we after we ship the best here, as we take on new work under our new, guidelines for how to handle type of work. We've got a number of presentations that we're all about to look at that different areas in which we could choose to spend our time as a working group. So the questions that we want here are both. Let's have some good discussion about the content, but also be keeping in the back of your mind. Are these things that we'd want to consider as a place that that we'd want to spend working group time actually moving forward and and publishing documents. So with that,"
  },
  {
    "startTime": "00:30:00",
    "text": "Gory, you are up, Feel free to request slides control if you don't have it yet. Oh, good. Thank you. Okay. Oh, the panel tilt on the speaker's camera. That's good. But I am Learning how to do slide controls. So let's go back to the beginning. Okay. So, right. ID furniture. Sorry, Gori. I'm gonna just bring it back. I put everything in one slide deck. You need to really just express the, arrow to the right? Yes. Non insurance. Right. Okay. This draft, is one that originated with Michael Veltzer, and going to visit Tom Henderson and speak with him, and then I got involved slightly later. The reason for having this draft is because some people actually read the specs that are produced by the IETF. In this case, the an s 3 community implemented exactly what was in the RFCs and they did this. This is a plot of, Of Seawind, for an application or rate limited sender, the sender, stops sending faster. And see when it continues to grow and grow and grow and because the current TCP specs say you can do this So I came and joined the crew because I'd worked on congestion window validation, but this is not the congestion window validation problem. This is simply a growing sea wind. So, like to fix this. We'd like to make a PS. We have an internet draft. And, and"
  },
  {
    "startTime": "00:32:02",
    "text": "like it to be adopted by the working group. But let's go on and explain a little bit more about the story. Next slide is here. What we're trying to do is write a couple of simple rules and basically restrict the size of seawind that can be accumulated when you don't use it. The starting point for this is you don't actually want to say don't grossly went to all, Just keep it stuck at the size which you actually use because That doesn't caught with transients and pacing. It's not a great idea. So you have to let see when you grow above what flight size was. But, How much do you let it grow? And, baby, you should allow growing seed into two times. Pipe, pipe, flight size in slow start. Which seems in general quite close to what was needed, to make, so start me here normally. When you have a burst descender, are when the time which put packets on the wire really depends on what the senators busy doing otherwise, rather than, what the arrival backs are. So So we propose 2 rules is must include a limit to the growth of sea wind when flight size is less than sea wind. And 2, should limit the growth of seaweed when flight sizes less than Sewing the next grant, of Mike's, flight size. What what what what Let's cut to the next slide. When we did this, we thought, well, just a minute. Do people really do? And, It was fun to have a lit what limits did because Linux. Linux. Actually did what we hope to, well, near enough. It it had something that represented our 2nd rule."
  },
  {
    "startTime": "00:34:00",
    "text": "And it's right there in the court. Oh, good. We don't need a a proof of concept for the proposed new text we actually have running call in Linux that does this already. But the RFCs are messy. Maybe we do need an RFC. 9438. Says Cubic doesn't increase CRM where it is limited by the sending application or Ahwind. Kind of true. 9260. When the wind is less than or equal to assess thresh, less CTP endpoint must use the slow start algorithm to increase seaweed, etcetera. So We have something in the RFCs But it's not that clear what exactly, a sender should do. And we think It should be clear. We have in the appendix more confusion. There are several sees that almost touch on this topic. They don't quite say what to do. But they kind of hinted, and they're not quite consistent. So Basically, We're asking, Can we preacherous, RFC that actually clearly captures what a sender ought to do. When they have a transient could we 5th how a sender knows that the app is rate limited. I think that's probably useful. Or maybe just turn our rule number 2 into a must and and actually declare a limit to the growth of seawind when the flight size is less than sea wind. With an increase of maxFS. I guess we were hoping that people would, give us feedback on what they thought was the right text. And We would hope to produce a small document current document is quite small,"
  },
  {
    "startTime": "00:36:02",
    "text": "and just update the relevant RFCs. But that might include ones, apart from TCP, Of course, which is why I brought it to this working group. And perhaps could even comment on some of the other are in cut congestion controls, etcetera, which you just mentioned if people wish to. Michael added multicast to the list here. I'm not so sure. I'm so certain I know what to say with multicast, but if someone comes up with a good suggestion about how the same as other things, then that would be alright as well. So, that's our That's all we gotta say. I'll put back to this thing and ask the question well, I'll let the chairs get the right side, then we would like take questions on this, and we have a clear Christian. Yeah. I am always uneasy. When I see your document equating concession control, we see wind Because there are number of protocols that do not use the C Win as the primary way to control to sending. Hey. Most of you six employees, BBR, in which to see when is set to about twice what you need. Because the limiting is done But on the passing light, So, basically, you set the best in red that your primary viable And you only use the c Win as some kind of safety belt. So you please Christian, did Christian? Yes. Sorry. There's a long delay between us. Yeah. And so So I'd like that when we do an RFC like that, we first expect a neutral term What the goal is?"
  },
  {
    "startTime": "00:38:02",
    "text": "And then we declined that goal into what it does to the values It control protocols have been implemented. And, you you mentioned, you mentioned, we know and Cubic I would like to mention high start as well. Because I start is, very much in that category. And it's But, but the the effect, I'm not gonna say the So so Hey. All these kinds of documents, I'd like to separate the principles and the implementation. See when is the implementation. It's not the principle. Yeah. Okay. I mean, the thing being that, this proposes is small change to several RFCs that update them. They are defined in terms of seaweed. No. I understand that. That's fine. That's fine, go ahead. That's fine. That's number 8. Clearly, if you if you say And for Vino, we shall change Vino to do this and that. That's fine. Yep. But the answer to be a first principle before that says You know, if you are basically not fully using your capacity and you can measure that in various ways then you shall not augment it. And that declines differently for different algorithms. Does it? Do does BBR do something different to this? In reality? Is it not cut by 2? I I'll let Ian speak about that because he is for me. It's based solely on the implementation but in general, that you need to be app limited either for the entire nonapp limited for the entire round for at least some portion of the round."
  },
  {
    "startTime": "00:40:01",
    "text": "In order to increase the, the rate typically, unless you happen to get a sample that's just straight up higher. But but, yeah, especially in the Upward Growth. Growth phase, growth phase, Yeah. There's quite a number of app limited checks, but they take into the account that it's pacing. And so you we There's a number of ways of doing it, but, like, the point is you have to have some code that doesn't just check, are you using all the sea wind? You have to have check a check for, like, have you been implemented? And is a little more subtle, but obviously that's just the nature of BBR. First deployment renewing, it would be different. For well, actually, I read it and keep it I think it's the same thing. Because we also pay for those. So I know. You're right. My Ian, do you have a different question? Oh, Sure. Hi. I think this is an important point. Think this should be written down somewhere. I think we should try come to some sensible set of principles. I don't think they need to be overly prescriptive. Like, I don't think we necessarily need a number, like, 2 or something based on my experience of BBR and such, but I think we do need Like, the key thing is, like, are you app limited? Like, the congestion controller sending as fast as it wants to send for some reasonable enough period of time that you think you're, quote, unquote, using the pipe, and exercising the congestion controller's ability to, like, detected there's more bandwidth and such. So that's, like, the absolute critical thing in my mind. So, RRC 2002 has some text around this. It's not I wouldn't say it's perfect. It's it's quite big, big, but I I think it's heading in more of the right direction than not. So that's helpful. One question I have is where does this belong? Like, does this belong in document we just discussed, like, 533bis, as a general principle about, like, How congestion controller should be made? No. Okay. Wherein it's like, I don't want I I'm just asking this question. I don't know if this needs really"
  },
  {
    "startTime": "00:42:03",
    "text": "I think we should update these RRCs as we update them. I am not sure. It's worth an update just for this one thing. I guess, sir, man, I thought. Okay. The the the the the last thing I'd like Swapton is that I'm The motivation for updating in a separate RFC and doing updates is that it touches several RFC seas, And so if you wanna keep any of this in any consistent form, we probably Would be well placed to write a document which actually does an updates line for the small bits of text in various places rather than wait for each of these to go for a document revision. I'm not sure we have appetite to update all these documents as a new best. So, Back to the chairs, Thank you very much. Alright. So for each of these, we're gonna do a quick poll. So again go scan that QR code, which was totally there a minute ago. There we go. And, essentially, what we're saying is, and this is a 2 parter, but we're combining them in the interest of time. So we're saying this is something that we understand well enough to take on. And then is this something that we're actually interested in in working on in this working group and and are we willing to contribute to So with that, we have a poll Go click some buttons. None of this is deeply binding at this point. This is mostly just as chairs, we're trying to gauge the interest of, of the working group and, and where we wanna try to our time because we have a large list of things we could do next And it is very likely that we will end up doing most of those things. The question is, which of those things do we wanna do Give that another few seconds. So go click buttons quickly I see an Ian approaching the microphone. Slightly ahead of a lars who is not in the microphone. Oh, did you are you"
  },
  {
    "startTime": "00:44:03",
    "text": "Speak. I was just saying I've I've owed yes, but really what I think the question I was answering is Is this a problem worth addressing I think the answer is clear. Yes. But But, I mean, how to address it is, is a more open question. Very much. Yes. Thank you. A lot of seconds. And that was actually talking to the the the bottom bullet that's still visible there. So we should remind ourselves that an is also to declare something historic. Because it doesn't have deployment. And for Mcat, I think that's a pretty strong contender for just saying rather than trying to update these documents, maybe we'll just say, you know, we tried that as a product of its time it didn't pan out and and make it historic rather than, like, waist, waste, waste, effort. Caring it forwards. Gotcha. Thank you. Thank you all. I think we can close that poll now. Okay. Well, I think this brings us to Inghammar k. Thanks. Hope you well. hear me On the well, I guess we have a song check at the beginning too. So, I'm able to chance to slide myself. 4 We can try to take the next page here on And this is about the screen congesting control that has been around since like to 2,000, 15 or so, and, it has only gone Changes is all all the times you or the 80298. What's the most are ready and I'm going to present this. I'm going in. Give some background, about the"
  },
  {
    "startTime": "00:46:02",
    "text": "use case that that's been it has been mostly useful, and it's, 4 g arginate process. Have been using it on and a little bit about the the properties and cellular networks for your networks and something about the video coders and the quirks and ports that they process on than going into a grim version too, and, finally, some It was a bit of a experiment that we have been done. The thing is I'm up and also the actually, the source code that has been, evolving or time and first, we talked about the property and, I'm new. I'm not sure how well known this is, but I can take it, And when If you have a 5 g network, you have a if you have a take the simple of case, or if you have one radio carrier. You have actually resource allocation in frequency and time. And that is a typically even evenly distributed among, the users that are all active for the moment. So so so If you have 2 years after you, split the resources served, 5050 more or less. 3 years afternoons, we complete the issues or get, start to see 3% sort of one And but that is a resource, sir. We call it a resource blocks. That does that itself doesn't really, given a measure of the throughput that you actually get. Because, you have, modulations and the coding seems that varies with the channel Shall I have a quality? And in some cases, you can have, a power limitation uplink that will also remain served. Actual throughput that you got. This throughput can vary quite quickly and it can vary on the mills. It can scale on, typically get that, for If you are close to your given"
  },
  {
    "startTime": "00:48:05",
    "text": "throughput limit for for the moment. You actually get on the delay jitter. That you need to, that is something that is a given by the both the general variations on on central you know, this And to visualize this more, like I said, a picture on the upper and this is actually not the measured throughput. It's just a visualization of what it looks like. And as a terrorist, transport is subject to false fading for and then that means that you fail through, but can vary, on a short time time to get into can vary sometimes. It's quite a long time. And in order to get, low latency, for instance, for real time application, me to actually accept that the throughput that you every free throughput that you could prove is a bit lower. So you have to pick 1, actually, in in typical case, if you will tie Throughput, you need to accept some queuing. In your network. The cellular network. If you have want to upload latest in rejects up a bit lower. And the additional can't give a really good numbers, but, so for If you move re reasonably slow, you cannot have to accept that accept after our car. 10 to 20% lower throughput. On that bridge. If you move really fast, you need to grab a Have a load your headroom, actually. And On top of that, you have access to call dynamic public study log of the intermittent data. I know in typical case where if you have real time bitter encodes that we actually produce frame, video frames of the, even, the, you know, the, 18th, not every 20 minutes ago. So And that means that the in order to keep the queuing delay low in the network, we actually run out to date occasionally."
  },
  {
    "startTime": "00:50:01",
    "text": "For for a couple of minutes to cancel. So that means that the you don't have any data to transmit on our brink. And for for the modem, or the u user equipment that you also call it. Do you need tax or center, scheduling request? Up to to the base station. I want to have something today transmit And then you typically get a grant, and it's, like, just a couple of hundred bits that this scheduling growth indicates Let me and then you transmit data along with the buffer status report. And when you open up Basically, I've received that office data report that can indicate that you have like 50,000 beds to transmit. Then we get the grant. That is So paged according to a general capacity under through tell, okay, the, or the resource allocation that you have for the moment. So that this, ping pong is a couple of times we are transmitting your date. And, The effect to that is actually guest on increased delay, actually, in the means it will be because you need to understand the federal request first and then getting wrong get above the state, there's reports, and that's tool. And also, it's kind of give a reduced link to it, say, because you actually on do you device your first shattering your first transmission, opportunities. You can also have additional delay due to congestion, of course, scheduling hand over, you can either increase because you get the gap in the transmission in typical case on Also on battery saving, if I was like, discontinuous reception. The Rx. And, also, of course, submission on lower bay due particle stack layers, and then you have transmission on the Mac layer, or you can occasionally transmission on the ROC layer. That's one."
  },
  {
    "startTime": "00:52:03",
    "text": "So, the this is a kind of reality with cellular, a trial network reality. Dotcom to you. Address when you decide your congestion control, Good afternoon. Okay. And video code is to have, but live there, love life on their own. And the the case of people who will frequently talk about it. The iframes can be relaunched And Iphones are a pain. And, for that purpose, in order to if you're close to your Network. Capacity delay, it it's actually highly recommended to use to it's called a gradual decoding refresh. Because that will spread out diaphragms in some sense and make your congestive control, easier to manage. Because you don't have away from that can be like a factored 5 to 10 long times logic on the long run. So that's And also importantly is where the p frames vary in size, if you have instance, if you have remote control core and they are You know, for instance, speed of light, right to left or something like that. And if accident for the temporary bit rate can change quite a lot. And, this means that in order to cope with the battery frame side, you me to the give your control a bit a bit on additional headroom to avoid that you get increase queue and delay for their case. It's one of the frames or become larger. And this is, visualized in the growth below. You have different The frame's 1 to 7 that are varying phrases. It's only you should ideally be able to should transmit. One frame. Before the new frame is generated. Revolve this used packet pacing or not. And as a reference to the presentation, yes, the the video encoder typically has it. You have a maximum bit rate"
  },
  {
    "startTime": "00:54:04",
    "text": "And, the congestion control then becomes, application they made it. And if you have a login networks and some kind Can we have Come back. Can have, like, a 100 megabit per second throughput in the uplink if you're alone in the sun. You can be pretty often, application limited, actually. An experienced congestion, when you run off in the port coverage from there, we have, increase of number users in the cell. And find the info in this, context. We have some old features this this call, but I don't know. You can assist not to get an output right Brake. When you asked the video coded to produce video at 20 megabit per second. You might actually get 25 megabit per second from the video encoder. So, I need to cope with that, the old son. This and some of you doing colders can be you. Sluggish, which means that you don't If you request a reduced video bit rate, You actually may not get that because you have internally internal rate control loops in a video encoder that can make it take. 200 milliseconds for the video too. Stabilize I need some special occasions if I'm Hopefully, historic cases, some video coders Cannot change the bit rate until the next iframe a group of pictures. This call, it was a cold or And then I have to read the idea for a real time. Media, if you want to have a congested control, Let's have one more Hello, sir. I just like your, sir, rate control will come still work. I don't wanna come to the screen, worship too. I'm not sure of the screen that that actually stands for, 3rd clock trailer rotation for multimillion And It has to be it was a"
  },
  {
    "startTime": "00:56:01",
    "text": "North Sea, I mean, 2000 not remember anymore, but 2017, 'nineteen or something like that. And it has seems that this has been, updated several times. So after a couple of years, you didn't, recognize, the the original in Rfc 8298 in the running code that has been public hasn't done. On the Reasons have been, simplifying quite a lot on It's actually now a lot easier to All of that, what is actually happening on the of the older version contained some what I would say, like, yeah, magic wants that, did, things that a bit more like the sometimes with spaghetti hacks. To, fixed, post open issues on them. And, also, and for us was, originally patched in somehow in the code and now it's more just lined into the, actual continuous control and A lot of work has been actually on working, getting me, it's working with Ella Forest and because delay based congestion hazardous is one also one part. Is that the you only get given the Delayer. Properties that we have in in networks, not only cellular networks, but otherwise, it's really hard to get the delay based control. It could just, it could all work well. You have too many different degrees of freedom and I'll delay it. And for us to give some kind of a more combine signal that you can use utilize. And, boneless if that is becomes accepted as a working group item. I finally on that more, Steve, if that's kind of actually approval, Hopefully, some kind of a best kind of practice on how to do congestion control from multimedia. I'm"
  },
  {
    "startTime": "00:58:02",
    "text": "If you go into the congestion control, it's based on one with delay similar to, led back packet loss detection. Classic easier, and, help for us. And they worked on kind of in concert today, at least with, if you have delay based packet loss on l4s or delay based can close all these classic easy ups. So when, for instance, self arrest doesn't work, you know, you don't get any packet more you still have see that you bill. The queues are bill locked because I'm gonna rely on delay based. On the SD controller packet loss. So it's not like a mold switching, what's in there? Something active in, in the broader sense. And one important thing here is that the The transmission control, hit it doesn't impose strict limit on the Firestone flight. It's more like a soft limit. You can exceed, the, congestion control limit. And the, rationale behind this that you actually may tough, rape, video rate, or a meteorite, more stable. And, but still you have congested window as a kind of a circuit breaker when things go the wrong. And if you're afraid that if you use feedback or something like that, And the meter bait, right, it's actually based on, a simple relation between, conditional window and entity with Zumburg variation of the terminal. Explain later. The packet pacing is done faster than the media bait rate. All the time. And the portal here is a congestion window validation it's, very needed for, in this case, racism. If you go for an rate limit is scenario to have good throughput limited scenario. The feedback is, or c8888. I don't know."
  },
  {
    "startTime": "01:00:02",
    "text": "Quite useful in that spirit Much y'all still on the prime minister left. Because conditional window update. You you have a update what maximum wants per entity on the left hand side If you're packet loss, or if you have a delay based, an increased delay And the delay based congestive control is some kind of virtual or l Freshmark, and when you exceed of, target delay divided by 2, you start to Virtually, Mark Packet Smith. So for them, in that purpose, but you have to target delay and that is that is that is that is A bit higher than January. Could we target place, like 60 milliseconds to cope with, clock drift, for instance, and you have sometimes you have clock skipping. So we can't Juned up to narrow. So, because you don't want to all all the react based on the real life issues like clock clock drift. And also, you don't talk to Ulrich on, Non congesting grounds that can be quite frequent. It's on coast. I don't have a LFS page control, and it's very much, like, know, how prong does it. And, and return in the southern in addition, if you have very small congesting window, congested in terms of packets. Actually limit your reduction. And that that's actually complimented if you the with the increase of the congesting. I mean, if you're a very small the actual limit, the increase and that makes it more stable at the very small congested windows. I'm not so sure if it's on the left right hand side of your you always try to increase your congesting window. I don't talk about that. If you are con con are congested"
  },
  {
    "startTime": "01:02:02",
    "text": "a longer time, you actually have this, multiplicative increase, Yeah. And on also for, if you're not, that phrase is not working. Just stabilizing the congestion window with an inflection point. It makes things a bit more stable. The target bit rate, the update is, best is simple relation between congesting and no other entity. And on top of that, you need to downscale a bit more if you have a largely varying frame sizes. That makes things a bit more stable. And, also some extra if you don't have, Yeah. If you don't have valid forest work, you actually need to going down a bit more if you have a burst of light that we exceed the know, that makes it the control system is a bit bit more stable. We can text Lex slide in here. And this is an example of a if you, have don't have inference working or if you have the fresh working, and it you actually get most stable to put down the and actually, the network latency. So 2. Oh, and also the important areas that imposed in flight is ready can exceed on just a million dollar. So Quick time check. You've got about 6 slides left and about a 120 seconds. It may be worth picking up for you that you think will promote the best decision. Yeah. And we have a multiplicative increase Doctor make it possible to increase your ramp up to a higher higher link capacity up the increases. So packetizing, default is, like, 50% higher, but if you have a lot frames, then you can actually speed up a bit more toward being able to, empty the transmission"
  },
  {
    "startTime": "01:04:00",
    "text": "offer. Good afternoon. That kicks in if you are rate limited more or less. I know. And, but do you still have this, if you haven't, won't you call slow start of what they'll recall. You can actually hear the increase by in this case, up to 2 times the margin flight Some sources? 3, Understood. The screen has been developed since March 2015. That should be continuously, There are some, code that you have a test application is more like a plumber say that there's been a good use quite a lot when I'm developed in for So, a lot of aspects on lots of multi camera functions. Here, complete Eastern on the multi time support also. And some experimentations that we have done. And that is not, you know, the DM on, my mobile with congress. Nothing. I mean, could, support up to 4 cameras, and there's some towel, you know, towel driving the game in the email that they've kinda left your way. One instance, On a wish list, it's actually to get supporting my MTC. To And This is an example for the for the mobile world team on the impact the well for a small lesson. So Okay. I'll bring Right. In time. I guess with a bit of a hurry then. To to Alright. Since we are at time, if you wanna jump in the queue. Now is the time to jump before we close it. And otherwise, we will start our, start our poll momentarily. So go fast in. Also, thank you, Ingram. This was a great introduction to media CC for a room full of people who might not all have the same context. Now, Ian,"
  },
  {
    "startTime": "01:06:00",
    "text": "Yeah. No, this is look really nice, and thanks for all the explanation. I have one kind of pedantic knit, which is calling it seawind and then saying that it can go above it. Is sort of like Blowing my mind right now. And I get, like, what you're trying to convey. Like, from an algorithmic perspective, I have no concerns about the implementation and that it works. But what what Like, maybe we need another variable. Because there's no at least Typically, the concept of max bytes in flight exists. Usually, C wind is that the limit on that thing. So maybe if we could come up with another name for ideal by itself. I don't know. Not sure. I don't really care. But like, that's that sort of, every time I heard him, like, wait. What does this word mean anymore? So you wanna respond to that one? You were, I am not sure if I got the question on them, to be honest, else. Okay. There was no question. That was just, like, and idea, like, because I also saw that condition window and then blowing it up. I was like, kind of like, okay. What's going on? So maybe you you would you need to see, like, what to do about it. But previously, you saw show some results. Like, Did you how is the scream Russian 1, like, screen work working on the same kind of scenario. I mean, Can we get, like, some comparison? Like, How is screen is doing? And screen pass on 2 is doing in the same scenario. Hold a comparison between, scream and scream version too. Like, just to see, like, we understand, like, how much we are We're getting back. I'll be with. Perhaps some answer is given here, actually. I wanna fun. The floor with the earlier versions of screens. So this is actually the scheme where we still didn't have washington 2. So you can see, for instance,"
  },
  {
    "startTime": "01:08:00",
    "text": "Understood. You know, that at that time, it was, like, a harder limit. But you need to blow up the congested may know a bit more to cope with the very piece. I'm gonna change it. Now, whether if you keep it as a soft limit, I don't know how to do, more strict do. What's called what's called validation of the window. I'd be more of adapt it to a thing in case, or if it's a throughput drops, or you as you go from an application limited state to a non application limited state. So that is a law law statement. On top of that, and I do. Computation of the video, rate is much, sim more simple and and more stable and more comprehensible. Okay. So it's a it's a a combination number in it's implementation gain that we we learn. Yep. And also, like, the new kind of, like, transition indicators that we have. That's that's Okay. Yeah. Pretty much a Repair of a past mistake. Mistakes, Phil. Alright. Gori. Thanks. Thank you very much for bringing this here. This is this is really interesting. And, I enjoyed the talk. I I was gonna come back with a similar thing to Ian. I don't think I think Seawind Is and limit the maximum number of bikes in flight So, How can target rate go above that? But, maybe this is just a wording thing as you explained, but I wondered if you wanted to say something I know some, perhaps One should rename to something else than a congestion window. Because That's all I understand is can it come? Caused confusion in the audience. Don't I'm not sure what it should be, but I'll"
  },
  {
    "startTime": "01:10:01",
    "text": "I I'm sure I'm sure people can help with that. I I don't think we need to take up working group time to discuss it. I love the talk. Thanks ever. So much for bringing it. Bishop? Abhishek, a couple couple of questions. One is, the results on L4S on on on on of were they on a cellular network where the congestion information congestion indication was being added at the scheduler That's question 1. And second is, I saw a mention of, moving to 75% on an operating point, if the the relative variation and frame size between I and P frames is large. So my question there is on a in on a real time video stream. How do you know this beforehand? When the feed is coming in and you're the encoder is working So do you know this beforehand? The what what would be the relative variation of your iframe b frame sizes. Okay. Can I take the first question? And, in this case, it's a very simple that wireline bottleneck, actually, with a with a with an ACM that, does some for us working or no? I'm gonna pick some, I believe, so that In this case, it's, like, 4 minutes ago today. We're gonna just talk about packets. But it can be a dual queue, a camera as well. And in the second No. I'm on you for for salary. Actually, you, you do the congestion in the the tech on the lower layers on what you mark on the PDP layer. To to So I'm gonna as for the Yes, sir. This is actually based on Hey. You. Computer here a histogram. On the, frame sizes"
  },
  {
    "startTime": "01:12:00",
    "text": "and it's a leaky histogram. So if your video properties change over time, you actually get the new histogram on It's relatively simple implementation on It's not documented in North Sea, but perhaps it should be a bit is is I mean, is it somewhat documented in the in the a proposed RFC or the draft, but, Soon. K. Hope that they answered the question. Thank you all for the comments. So for a quick poll on this. Thank you, Ian, for some of our wording updates. Like this better. So this is something that's worth addressing and the working group take this on. So again, this is a, help us prioritize what do we think we wanna talk about this something that we shouldn't be talking about at all? Is this something that we wanna spend some time on? I know we've talked a little bit about, how we want to handle congestion control for media related things. And we'll talk a little bit more about that. At the end of the session. But go scan some QR codes if you haven't scanned them yet. We'll leave this open for a minute while we get set up for the next 21. Alright. Thank you all. And Next up, we're gonna talk a little bit about HPCC plus plus. Is Okay. Hey, Roy. This is Carlos yours. Should have control of the slides. Okay. Got it. So, since people talk about the data center computing control, so this is a proposal, we have to adjust this issue"
  },
  {
    "startTime": "01:14:02",
    "text": "First, we talk because we present this idea, in the previous IETF. So this time will work give a very quick recap on our basic idea And, and also, we won't provide our deployment. Experience and the more test results. First of all, we want to recap on the scenario targeting. So this condition control where where targeting for, data center applications. So A typical, emerging data center application is like storage data database and the Ocean Non applications all required, network communications. So for example, those storage application. When users send a request, those requests actually been spread too much for servers, and the all the server need to response. Based on the a part of the request and then user can, only get a re reply once they aggregate all the results. And that latency actually, and as throughput also become very, very important. And also for machine learning applications, Today, we have a 10,000 GPU training that the 10,000 nodes need to communicate, and this number keep growing to 100,000 this year. So which means that, the the all the nodes need to communicate and synchronize typically 100 times, you know, within a second, So if, any notes gets low, whole job get were get it stacked. And wait for their 2 finishes so they can start next iteration. So so just give us this idea how important, data communication will be in the data center scenarios for those emerging applications So, in this center, we have those"
  },
  {
    "startTime": "01:16:00",
    "text": "very fast transport layer, for example, like RDMA, they can allow the client to send the traffic in a line rate. Actually, So the issue becomes like you cannot allow all the centers in the traffic arbitrarily than without ending orchestration. So that's a very bad phone, the network. So that control actually become very important in this scenario to schedule the the communication across multiple, centers so they can coordinate so traditional condition control, previously we use Oh, so for internet that actually rely on heuristics, So for example, if you see the packet loss, And then you guess, probably, there's a condition in the network will reduce the sending rates, but you don't actually know how much you need to reduce some some gas will be there. Like, you can cut the throughput by half, something like that. Right? So in the early stage in data center, also rely on something like ECN to notify and only a single bit that only provide very limiting information So the whole idea of, SPC is is we rely on some precise information that we can get from network. So based on those precise information, The sender know it is actually how much they need to reduce but also when they need they they they will know how much exactly they can increase So, hopefully, we have this capability in our today's hardware. Today, the never switching AC. Provide this inbound telemetry information and also provided by many vendors. So Here, shows the basic idea when the traffic, when the packet, goes through the the pass each switch in along the path can't attached to the telemetry information into the packet"
  },
  {
    "startTime": "01:18:00",
    "text": "headers, headers, and all the way to the receiver and the receiver is in the the reply back to a sender, and a sender based on this telemetry information, and to adjust the Sydney rates. Those telemetry information including What's a the link bandwidths. What's, colon, current equivalents in terms of bytes. And also, how many bytes that link already been sent So you can so sender can calculate because actually what's the utilization of the link If it's overutilized, how much by how much we can reduce or increase the bandwidth precisely. So that's a basic idea. Instance, we have a couple of benefits. First, we can achieve very fast convergence typically just one round trip time. We don't have to use her wrist to to get to adjust any rates, like, course, multiple around trip time. We just it just directly jumped to the correct as a new rate. Within one run trip time. And then we can potentially, maintain 00q because those feedback doesn't rely on earning a cube build up the o because that would be too late. Then we can, Literally maintains 0. We will show some results later. Slight And the last week, we only have only a few parameters. Because we don't run any heuristic. We know precisely, what's current status of network and which which help our as primarily tuning also maintenance of our network we have 2 proposals for this specific idea. Why is the the standard draft draft to talk about the So that as we talk about how we can use what's what information we want to use. And how we can use it"
  },
  {
    "startTime": "01:20:03",
    "text": "And then we believe connection control is a service. Can plug into ending trust, transfer protocol you can plug into RDMA or or TCP if you like. Suggests a, your choice, but basically we, we, we, we see Canadian Country is a is a service can leverage. And a second, a proposal is more about the the The packet format, and how you can encode a 10 minute green information into the packet. We right now, we have a support, those 3 format. But we can extend many other formats as well. And here, we show the our deployment experience, we, today, we have deployed HVCC to, storage AI training and the database application in 1 of the major cloud providers. So, this this diagram showed that the typical storage application. It's a elastic block storage. When the user generates requests, this request actually being spread to main name storage server. And then the the user can only get a response once all the servers send a response a response. So in these scenarios, network communication become very critical. If you have one specular get delayed and hold the request to get delayed. So by using HPC, we actually increase that both throughput also reduce the latency, security committee. That that's that's the experience we we found this conundrum control. It's very helpful for this, additional application. And we also did an intensive, extensive experience testing, in both hardware based"
  },
  {
    "startTime": "01:22:01",
    "text": "implementation and also in simulation as well. So this figure shows the hardware results we compare with the, Although, so disaccusing is the conjunction control use primary in RDMA. As a signal, indicate the congestion. So, We we compare the performance in 99 percentile flow completion time across multiple a different flow sizes. We can show that across different flows that we can achieve up to 95% latency reduction in the in the small flows And, and the the figure in the right show that cube build up. In our experiment, we can shoot we can see that, disaccusing activity have a land land held distribution in the queue lengths where in in our case, we we nearly maintain 0q. Basically you don't have to maintain queue in in the network, we can see as the 2023 kilobytes in the 99 percentile, which translate to only in 7 macro second qing delay. Across the entire experiment we have. What we also did more extensive experience and evaluation in our simulation to compare with other conjoint control mechanism. Because we don't have a hardware implementation for each of them, we compared them in sim simulation. We we showed that, which is the act plus plus can actually outperform those different convenient control algorithms, Yeah. So that that's all for"
  },
  {
    "startTime": "01:24:02",
    "text": "for today's uh-uh presentation. So we we highly appreciate your feedback And feel free to contact us you're having more questions, Alright. Great. Thank you, Roy. Does anybody have any questions or comments now? We have a few minutes. Chairman, Hi, shopping from ZTE. I have a question about your HVCC info dropped in that draft, you, provide the 3 options for the congestion notification. Right? So, I n t, IFA, and the I'm yes. So for for these 3, options, do you have any, comparison. I'll Is is there, The similar in the performance, performance, about his, HVCCZ. So those format are just the way you can encode the information into the packet And, the information actually would be the same across all the different format I mean, They may have some, difference in accuracy, like some format that may have a base, some format may have 10 bs, something like that. But the the the point is that you you capture the necessary information We specify in the algorithm so that you can can run the algorithm correctly, so that's why we we think the performance will be the the same. Across different format, but it's just a a different vendor they have their flexibility, choose which format to support"
  },
  {
    "startTime": "01:26:00",
    "text": "and and and that's that format is the orthogonal to the to the algorithm we propose. So that's why we want to decouple this dependencies. So they make a a 2 different draft for the purpose. So have you tested all the 3 options in your Testing. We have deployed and testing, the Some of them, but not all of them. But that that should be our, future work to test the performance across all the formats. That's a good point. Yes. As I as I understand it, the 3 options, they use, different Layer. To encourage the for matter you, provide, So maybe, they have a different performance, Performance is Yeah. So I I think Yeah. You have any, path pass the result this is this is that that's great. And if you you can show us That sounds good. Yeah. Thanks for the feedback. Okay, Lawrence. Lawrence Stewart, Netflix. Hiroe I was wondering if you could speak to whether the switching fabric you were using here, did, virtual output queuing or was using sort of regular queuing So, We I think that's, the the way the switch using a query mechanism actually is independent or or subordinate to the algorithm, But the, the, the key key point is that switching may have a multiple queues and then then if you support multiple queues, especially for this virtual queuing stuff,"
  },
  {
    "startTime": "01:28:03",
    "text": "And and then if you have traffic in other queues, then the computing control become more complex to support this multiple queuing. And we actually, in our draft, do we have a proposal. Or or or agreement is on to To address that, that that will be, part of our work as well. Thank you. Alright. Thank you, Same question as Ruth. we've been asking all along. So this is a problem that is worth addressing, and the working group should take this on. So, again, this is one of those things where, we're looking to gauge the order in which we tackle things and what there's interest in pursuing. We'll talk a little bit more about criteria and deployment thresholds and things like that. And a little bit, right now, this is mostly just What are we interested in? Where do we think there's problems that we need to solve? Do we have the right expertise in doing that? While we're doing this, let's get set up for jump all the way through. This. Up, we're gonna talk about some BBR Would you like me to go ahead and start, or you are we doing? Okay. Great. So thank you. Yeah. So my name is, Neil Caldwell. And, I'm gonna be talking about VBR version 3. Sort of lightning fast algorithm overview since we've talked about it, before. And then just a quick update on the deployment status And this is joint work with the, VBR team at Google, which is composed to the, TCP folks and quick folks."
  },
  {
    "startTime": "01:30:04",
    "text": "And then let me try the next page. Yes. That works. Okay. So, I'll just start with the overview, talk about employment status and plans. And the goal here was basically just to respond to a request from the chairs for a quick refresher and overview. And, you know, and we're inviting folks to offer feedback on on what kind of plan makes sense. For, you know, whether we want to pursue a working group item, and, you know, of further documents for for BBI So if we had to describe VBR version 3, in a nutshell, I think we could say that the the design goals are basically, number 1, to be able to achieve high throughput even with some targeted level of random packet loss. We also, number 2, want to be able to bound the amount of queuing delay that, we have even if the bottleneck buffer happens to be quite large. And then 3rd, we wanna have some sort of usable coexistence story. When sharing a bottleneck with Reno or Cubic, congestion control. And the the basic mechanisms that we're using here are, a model based approach where the algorithm dynamically probes the network and then builds an explicit model of it. path Where the main parameters are, the the maximum recently observed a delivery bandwidth. The minimum round trip time, recently seen maximum degree of aggregation that has been measured recently. And then the maximum amount of, data that we've been able to put in flight and then get delivered without experiencing too much easy on our our loss."
  },
  {
    "startTime": "01:32:02",
    "text": "In in return. And, as you could guess from from model parameters, the signals we're using are basically bandwidth and round trip time. As well as ECN and loss. And here, the the ECN flavor is a shallow threshold to ECN, like DC TCP or or l for us. So, just to give us sort of quick architectural, picture to have in mind when you're thinking about the algorithm. Is kind of the way that we think about it. The algorithm takes as inputs, you know, these signals that we've been talking about, feeds them into the model, and then the model generates its estimates for the various parameters we just mentioned. And then those go into a probing state machine. That makes decisions about speeding up and slowing down. To sort of explore the network and try to find a a decent operating point And then the output of those, decisions is basically 3 control parameters. The pacing rate, the congestion window. And what we could call the quantum or or burst size. For any, offload mechanisms that are in use at the sender such as in the Linux ecosystem. They're called TSO and and GSO. And then those 3 control parameters go into the pacing engine, which takes the stream of input data bytes from the application in the form of socket rights or send message calls. And then chops those up into MTU size packets. And then paces those out onto the wire. So, just a quick overview of the various versions of BBR that you we've talked about in the past and you may see references to was bbrvone, which is the original back in 20 16 2017. Then there was version 2, which we talked about in and open source in 2019. And then version 3, which we"
  },
  {
    "startTime": "01:34:03",
    "text": "I talked about an open source last summer, last July. And then there's also BBR Swift, which is a a version of a BBR that we use inside the data center, which is using, an estimated network round trip time. As the main congestion signal. And that's something that we just we we just use inside data centers at Google. Where that extra signal, is it available because of the, what we know about the expected trip time within a data center You know, here, we probably don't need to spend that much time because we've sort of talked about this, implicitly And folks are pretty familiar with Cubic. So in the interest of time, I think we can skip this. And folks are interested in the comp direct compare can can kinda take a look at the slides, And then in terms of the deployment status, it's similar to what we discussed last July. VBRV3 is used for all of our internal WAN traffic for BBR Swift is used for the TCC traffic that's within a data center on for Google external traffic that is TCP we use pbrb3forbothgoogle.com and now recently YouTube, public internet traffic. And then on the quick side, there's a quick implementation. And that's currently under AB testing for a small percentage of users Yeah. So we've we've done an open source release. Here's a link for the the TCP implementation on GitHub. And, as time becomes available, and our our team unfortunately has a number of other priorities that we, that we have to work on, but as time becomes available, we plan as soon as possible to replace the Linux TCP, PBR version 1 code in"
  },
  {
    "startTime": "01:36:00",
    "text": "with this v 3 module. And the motivation there is that we think that makes sense. Given that it has better coexistence behavior with Reno and Cubic, which is an important goal. It gives us lower loss rates, provides actually lower latency for short web requests and starting video streams, probably because of the lower loss rates. While having throughput that's pretty similar to a VBR version also 1. And so here's some links to the internet traffic. Which we which unfortunately is still reflect version 2. They're the differences between V2 and V3 are relatively minor. So there's if you're interested in reading them, you know, it's still your time would not be wasted. And then, you know, we're always looking feedback, obviously, You know, I think I I do wanna say that I think a BBR is sort of a work in progress. There are definitely a number of ways it could be improved. And so, you know, to be honest, my initial inclination thus far has been rather than spending time polishing the document to try to focus time and energy on improving the algorithm or coming up with better algorithms, But that said, I gather there might be interest in in in moving a document forward. So if if that's gonna happen, I would definitely elect to be involved. So, yeah, thanks, thanks for listening. Appreciate it. Thank you so much, Neil, for refreshing our memory and sharing some exciting deployment updates. We have a queue in Inghamoras first. Okay. After the brief hold. Thanks. Wait, like, one question about this, 2%. Is it based on some kind of, empirical, studies that you pick a tube, something called 2% plan can mean quite the difference between depending on the battery delay product"
  },
  {
    "startTime": "01:38:00",
    "text": "Right. Now it's it's been based on our experiences. Both on YouTube and and google.com and our internal LAN. Obviously, if we're gonna turn this document into something, a working group item. I obviously, I expect that that particular magic number will receive a fair amount of attention and we could put some more science and engineering into it. It's it's basically that if you're talking time scale over, which that's measured, that's over a single round trip time. And And so the average loss rate that's generated is is typically much lower than that but that's sort of the the maximum that is willing to tolerate over the time scale of a single round trip. That answer the question? Yeah. Alright. Perhaps one more if I'm allowed. What shall I get? Yep. I've been using the the dimensional fluorescent, This is still limited. Like, you you have the BBR version too. You have, like, 5,000,000 limit before using those could load. Make the choice. It's not lifted or is to allow Right. That that magic number is still in the code. And within Google, we've only been using the ECN support. At low RTTs. And I think for using shallow threshold over the public internet. I think that should probably happen in the context of doing something that's cokes as well with a a prague. And then that support is not in the in the code at the moment. Okay. Alright, Martin. Duke, Google. Martin Neil, can you speak at all to your knowledge of what, non"
  },
  {
    "startTime": "01:40:00",
    "text": "Google, entities are using BBR. Any version of BBR, really? Alright. Yeah. So you know, others can, chime in here off the top of my head. I think I think Amazon's, cloud CDN uses BBRV1. I think, Akamai uses PBR Some version of BBR for a significant percentage of their traffic sure if it's v 1 or V2 at this point. Think Dropbox uses bprv2 I'm sure there are some meta folks in the room who could chime in on on what whether and how it's used. Yeah. Cool. Yeah. That's a lot. And and the fact that all these versions may be to make me as a compelling argument to standardize this. Thanks. Okay. Alright. to Allison Rodriguez, Martin's questions. We also do, we also use VBR for TCP and we're sort of sort of going through the basis of trying to implement that for our quick stack. And something that we've sort of discovered is the One thing is, you know, defining the, the BBR algorithm in the draft and another thing is actually implementing it. And you know, making it performant, and there's There's a number of situations where we bet to sort of go and try to reverse engineer the Linux implementation to figure out some of the, the gotchas and implementation details that, are probably not that uncommon to other people. So I would definitely be interested in seeing like, the working group work on, the BBR pro the the BBR algorithm itself, but also figure out what sort of of of work we need to do to actually be able to implement it properly and and make sure that we don't, you know, deploy some broken implementations on the internet"
  },
  {
    "startTime": "01:42:02",
    "text": "I do have a question about the the Linux patches, patches, So you said you're gonna, replace the current BBRB 1 in Lena Upstream, which I think makes sense but it would also be useful to keep having, the the the out of 3 changes with both BBRB3 and BBRB1 to be able to sort of tested better, like compare. Was wondering, do you have any thoughts on whether you will be able to maintain that out of 3 for going forward, for some period of 9 that. I mean, as a sort I think that I think we could do auto tree, something on GitHub or something that has the old BBR V1 code. For folks that wanna do AB testing on on large sites. Is that what you had? Yeah. Basically, I mean, we could, deploy our own you know, Linux patches. And ideally, we wouldn't, you know, maintain that patch ourselves I imagine some other folks might be interested in the same kind of changes. Right. Okay. Okay. Colin. Colin Jags. So, in This is largely with work that's in the context of the the mock working group where we're doing media over, over quick. We're we're using this a lot, and this is work that Cisco's doing in conjunction with, Krishna. I'm really interested in what sort of results you're seeing sort of testing is being done on particularly and the type of, wifi network characteristics you have over wifi. Is that has that been a a focus and Can you say a bit more about that? We've done that. Yeah. That's definitely was a focus at one point. We had we talked about that work. I think it was an idea of 101, I wanna say"
  },
  {
    "startTime": "01:44:00",
    "text": "I think that was I wanna say does have, It's maximum aggregation estimate. Which is, particularly important for wifi but it's also relevant for cellular and docs cases where which also have significant aggregation. Yeah, There was a chance that you're not getting any audio from us. Yes. Oops. I was not getting any audio. Let me I see someone's pinging me on chat. Let me find that tab. Neil, I can hear you. asking me with You're that. to echo to help Community rather than Yeah. Okay. I'll make one comment to the community here then, which is, like, I mean, like, I find it shocking given the huge deployment and all the stuff going on that's not already a a working group draft. I think we should adopt this and and figure out what we need dex Thanks. Go ahead, That's showing up in the transcript, so we may be good. Now here, Neil, Can you guys hear me? Success. Okay. Hey, guys. I I hit the reset button. Is there anything saved from what you were saying that you want to repeat before I start my question?"
  },
  {
    "startTime": "01:46:00",
    "text": "Part. I don't know where I caught up, so I'll just let you go ahead. Okay. So, to the question about deployment. I was conveniently in queue. Meta uses Correct. Bbrvoneish with our quick deployment, which is the vast majority of our egress traffic and rest of our internet traffic uses BBR. We won in Linux with TCP. And we are currently working on what maybe is like bbrv2.5plussomeother stuff in our quick implementation and we're experimenting with it. We have so we're we're working on that. And we echoing what Colin said is that, we think that this should be something that the working group works on, and we are happy to lend support to that in terms of you know, edit editorial work and things of that nature. Great. Mosenady Mosenady Sisco. To echo what Colin said. We're experimenting with this and, and media over quick. And we've tested the BBR V3. It's performing better. Than V2 in in our experiments, but we still have a lot of impedance mismatches with, with media. And so, I'm wondering when you said, it's on by default now for for YouTube traffic, does that is that only about YouTube, or does that include YouTube live or YouTube TV or anything that's more real time or latency critical, And are you testing for media apps specifically in making design changes for media apps specifically, or are you trying to model media apps as just, you know, typical elephant flows, so as far as I'm aware, BBR is used for all of the the YouTube, TCP connections. And I'm, I guess,"
  },
  {
    "startTime": "01:48:02",
    "text": "I'm not maybe Ian actually could speak to what transports are used for some of those live services. And in terms of testing, I mean, I think, Again, Ian has done some work in this area. But I think our experience has been that BBR is not great for real time stuff because it was nimmer sort of designed for that. You have ideas about how it could be improved. Make him a better fit for a real time stuff, but haven't deployed anything like that. So in terms of YouTube, All products I can think of. That our user facing serving would be TCP or quick BBR. Certainly. TV and all those things. And Justin, we do I guess, like, 5 different ingestion verticals, like, Webberts, Steve, the whole whatever someone wants. So that's, that's kind of a different ball of wax and obviously a client's position to alert is is with us. But for delivery, I I can't think of a single thing if it's not some variant of BBR. Oh, yeah. And on the real time stuff. Yes. There are challenges, with most of them are around the app limited nature of it. And that's, that's kind of the critical challenge. I don't Yeah. We'd love to see it adopted and and be able to contribute some of the changes that we're considering for media and app limited flows because rather than having scream and something else and something else. 5 or 10 different rate controls for different applications, it'd be better if we had a common rate control that worked well for most applications. Beautiful. Thank you. Alright. Time to click some buttons again. Everybody race into your browser of choice. Same question. This is a problem with addressing, and the working group should take this on. Thank you, Neil, and Thank you all for some of the really good feedback and comments as well. It sounds like we've got a wide variety of people who have either deployed or interested in deploying and may learnings that would be great to talk about and share."
  },
  {
    "startTime": "01:50:03",
    "text": "With that, Let's talk a little bit about where we go next. Ask me. I see we've got a a no vote in here as well. Would anybody who said no, like, to come to the mic? I didn't send it. I just I said yes, but I put a little snarky comment in the last I got a snarky comment in a chat that I not so snarky after all. So the first step to standardize something or work on something here is to get rid of some of these versions and options and plus plus and and merge this and other. So I'm really interested in BBR. We definitely should be doing this in this space. Is this the right group for it? No question. But the plethora of variants is making it real hard to understand you know, what's working, what isn't working, and I'm The way I understood Neil is that at least in Google, it seems to be there really at least strongly, like, deprecating v 1 because they were, like, putting v 3 in the Linux kernel. And so maybe if we could all agree that maybe we'll sort of focus ourselves on at least on the v 3 ish variants that would make me slightly happier, but it's it's a proposal, but I'm just confused because I don't follow BBR. Close that you actually know what all these differences are and Thanks. Thank you. Alright. I could grab the microphone that I don't have to eat quite as much. Let's talk a little bit about next steps here for CCWG. So, extra thanks to our authors and editors for the best document. As we wrap that up, we believe that we've defined a new set of criteria and processes for what it takes to specify congestion control within the IETF. And a big part of the group talking about this the whole time is to make this a space where we can actually make progress that is significantly less painful than some of the previous efforts. We've got some text on here, which you're welcome to read in your copious amounts of free time. But essentially, we wanna make sure that we're best fine congestion controllers so that people can interoperate"
  },
  {
    "startTime": "01:52:03",
    "text": "and interoperate as kind of a weird term here because, of course, what I choose to do on my client both does and does not impact those around me. So that's been always a challenge, and it's going to be a fine line that, that, that, that, that, that, that, that, that, that, that, that, that, that, we're going to be walking. What that tends to boil down to is we've got 2 criteria that we've been talking about and proposing. And this is essentially part of how we discuss what venue we want to bring different documents to. So this is do we have empirical evidence of safety? Is this going to harm others going to prevent others from being And then the second one is do we have a stated intent to deploy by major implementations? Notice that that is a plural word. So this is both a, Can we take things and make sure that we don't make anything worse? And also, are we putting our time and energy into something that that should be a standard in in where the people actually are. So have a little bit of a litmus test and some some interesting questions to to ask ourselves for each piece of new work. And we've been, working very closely and in some is, in the mirror with the chairs of ICC RG as well as others around the IETF and IRTF. To talk about where do different documents belong, where do different talks belong. And the informal version of that is Right now, we're thinking of ICCRG as an incubation place. So we take different experimental work. We take things that we're doing research into where we a lab and we're testing some stuff and we want some feedback. And have a wonderful group of experts. Many of whom are also in this room to talk about know, hey. Did you try tuning this in this different way, or did you take this signal into account? We then also have CCWG as a place where we can have those same conversations in a direction towards let's actually publish standards. For those who have significant deployment and are demonstrably safe. What that's turned into is this, nicely"
  },
  {
    "startTime": "01:54:01",
    "text": "colored set of boxes, which are essentially, there are potential to have starting on the right. We have the independent stream editor, and we we can potentially publish algorithms that aren't going to change based on an IETF review. Right? And so this is review for some of you. But if we have a thing where we want to say, yep. And this is what my implementation does in what I called it and it would benefit others to be able who see it and review it and understand how I'm going to behave on your network. There is a place for that. If we are willing to update based on IETF and IRTF for few. Then we have both the CCWG and ICC RG. And so we have kind of, for less mature documents in where we're incubating new work, new research, things like that. We discussed that in ICC RG. And at some point, we graduate from that when we've actually proved safety. And when we have ideally data from major deployments already. But at the very least stated intent to deploy, then we start talking about we move some of these things more towards standards? So I see Lars hopped in the queue. Is that a clarification question? Yeah. Cool. Uh-uh. Yeah. So so the I reacted because so you said we can put stuff on the independent stream and we actually can't. It's up to the, independent stream editor. And if if So so the the proponents of a reduction control scheme can choose to take your thing directly to the and get an RFC number and and the working group need not even hear about it. Right? I think if the working group decides to publish something It is possible to publish something for posterity on the IRTF and IETF stream where we basically be up any of documents that where say, you know, Microsoft's blah, blah, blah, or Comcast, congesting with your manager, or something We at least believe that whatever they're doing is interesting in that, you know, we wanna make sure that the description has been written such that it's understandable and can choose to publish that through the working group. If we want to. And I thank you for a a deep"
  },
  {
    "startTime": "01:56:00",
    "text": "past the present and future that you didn't put the AD sponsored route up there because we should have already started. Thank you. Yeah. That that is a very good clarification. That was an extremely a broad we here. But, yes, the the we that is in this room have paths towards publishing experimental and informational documents and and other things of source as well that aren't just the independent stream editor, and you can, of course, hop directly there without talking to anybody else. Yeah, Ruth Enghart with my ICC RG chair head on, ICCOG can totally have presentations on ag words instead are in CCWG. Right? There's nothing stopping us from accepting, like, a a research y presentation on VBR in ICCRT. Just wanted verify that. Yeah. So another big part of that, is this also means that you get to have more than one to our block in an IETF week where you get to think about and talk about awesome congestion control concepts with other people who are also similarly awesome. But a a big part of that means that we're coordinating, very closely. As we kind of build out agendas to make sure that we're doing something sensible and sane. So we would also love feedback on that if you've gone to both say this morning and right now, and you're like, wow, that second part was a complete waste of time because saw it all in the first part. Come talk to us and, like, we'd love to know that. So that brings us to kinda what where do we wanna go next? As we've been talking about future work and this comes back to what we've been saying the whole time. A big part of this is can we talk about new congestion control algorithms Standardizing those within the IETF. We also have another kind of category that we've been seeing work proposed in, which is basically, can we update existing specifications to reflect reality? There's a number of places where we've published things either recently or very not recently, that differ from what people are actually doing so we've got a a number of different places where we're talking about, hey. Can we update this to to make things make sense. And then as we go forward from there, there's a whole another bucket of congestion related topics like delay and queuing and pacing and multipath and all kinds of cool stuff there."
  },
  {
    "startTime": "01:58:02",
    "text": "That we can open the doors to depending on where there is interest in actual again, intent to deploy. So with that, we filled in kind of, some of the things that we've talked about either in this session just now. So that should be very fresh in your memory. Or perhaps you need to go page in some stuff from from previous IITFs, we've talked about BBR, some variant of V3 and we wanna handle versioning there. Prague, we just looked at HPCC plus plus and screenv2. And then we've also had some conversations just now. We talked about rate limited senders. And then previously, we talked a bit about reno and potentially updating things to reflect the reality of what's going on there. So We did some polls already this session. The goal in the next two minutes is not to suddenly say yes and particular one on this list is my absolute favorite, and let's do it. The real the real place that we're looking for feedback is what are we interested in working on? Does this make sense? Even if you don't have time to get feedback right now, grab one of us in the hallway, we'd love to talk about where that's going and how this is working for you. The real goal here is to make to do this kind of work in the IETF in a fairly low friction manner. I see we have Martin Duke in the queue. Oh, that's This is the end of I I didn't know that that text was a lie. Yeah, I mean, I'm curious what the chairs thinking of as a timeline. I mean, I I would be very disappointed if 5033. This hasn't gone well before Vancouver. So, Do you want, like, a draft charter before Vancouver? Via the list, or we gonna have another kind of menu, kinda like we had today in Vancouver or or what, or what, plot to us. I said this was the last slide, but we've actually got another one. You have a very topical comment. So, yeah, so we've actually already started talking about and working on what would updates the charter look like. We're actually chartered right now, and we'll obviously talk about this in more depth. To talk about pretty much everything that's on this list. The main updates to the charter are gonna be reflecting the fact that the"
  },
  {
    "startTime": "02:00:02",
    "text": "is actually out the door and and going. So timeline wise, yes, I think exactly what you said. We're we're trying to move that along before Vancouver and and have everything in in good shape to move from there. Alasandro Giddini Cartler. So, sort of remaking a point I made earlier about you know, one thing is defining the congestion control and other is implementing it correctly. I wonder if there's any room for you know, work related to testing, implementations of congestion control, swords you know, things to look for, what sort of scenarios people should test. So we have 5203 bids obviously is a starting point, but we just now in ICC RG. If you missed it, we talked about testing, congestion control, and I brought up the idea of a hack on in Vancouver, But, yeah, just quick thumbs up, thumbs down around the room. Is that a thing that you'd be interested in seeing here as well? I mean, we'll coordinate where that goes. I see a couple of thumbs up going on. I think a big part of this is we're talking about empirical evidence of safety and one of the challenges we've had in the past is that whenever, say I were a proponent of a new congestion control algorithm. If I showed up and said, hey. Here's my evidence that this is safe. The response is great. Here's 3 more things to go try. And you can repeat that essentially, infinitely. So if if we were all pretty on the same page with what kind of tests and and how we wanna do that. Would be a beautiful thing to also make easier for people And automate. Yes, please. Beautiful. Alright. We have drained the queue with that. Please do grab us in the hallway and and give us more informal feedback as well. We're here to make this pleasant and happy for everyone. Wonderful. Alright. Thank you so much. That is the end of congestion control working group at IITF 119. Thanks, everyone. Also, thank you for taking notes. Yeah. Very appreciated."
  },
  {
    "startTime": "02:02:01",
    "text": "Good job. Oh, I'm very happy now. Place its foot docks that was"
  }
]
