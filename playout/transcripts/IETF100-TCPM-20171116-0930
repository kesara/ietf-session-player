[
  {
    "startTime": "00:01:11",
    "text": "hello we will start the meeting very soon before we start the meeting could anybody take care of each other it\u0027s very simple so could anybody for interior if we someone who can take care of each other please raise your hand oh media thank you like this like this okay okay let\u0027s get started hello so welcome this is TC p.m. working group meeting just you make sure you are in the right room okay my name is Yoshi from in Ishida one of the co-chair of the TCP and working group and this is also Michael show and a coach of disappearing working group and unfortunately Michael Jackson cannot come to this meeting but we expect he will come next meeting okay this isn\u0027t user not oh well um I think you are in the middle with it basically what you say in this meeting will be governed by is not well and if you want to take a look kaveri you please go to the ITF webpage or you can google it on the and then you can find a notable very easily and not taking and i appreciate no gory to taking of note taking and the media thanks for each other and before we start a meeting one thing we\u0027ve tried to reminder is ave news pick up at the microphone please say your name beforehand so that\u0027s no no think i can track your name also when you submit your internet draft please include TC p.m. in your draft name so that Machias can track the status of the you addressed okay moving on so this is the agenda of that state meeting at first cheers we\u0027ll talk about working group status and after this we have for presentation for working group items first name we\u0027ll talk about our the back off drug after this Marcel and "
  },
  {
    "startTime": "00:04:14",
    "text": "Bob will talk about generalized ECN and after this Bob and the media will talk about accurate easy and draft and after this are you tuned we\u0027ll talk about TCP rap and after this a we will talk we have a to presentation for individual document Marcelo and the user will talk about ESN draft extended seekest numbered draft and after this Praveen will talk about update on Windows TCP any questions or comment on this agenda okay moving on a status of document and so recently the CCP draft has been published as RFC 82 57 congratulation and they are we appreciate your cooperation and then for cubic draft we got approved from ISD resv yesterday so we were soon this stuff has been published okay and we appreciate your cooperation to process these draft and then we have several active working group document um so first one is alternative back off easy and draft and this is one of the today\u0027s agenda and in the last meeting we cuts several reviewers Ferranti reviewers for this draft and then we started receiving the reviews from the reviewers and which pretty nice so I think this Trust is getting very much worth and so after you know we received another one my review was something and then we can think and device a draft and then if everything goes smoothly I think we can proceed to the working group last call so our expectation is you know within a couple of within a month or so we maybe able to proceed to working with rusticles that is our expectation and the next one is accurate EEG and draft this is also one of the agenda of that today and this drug has been updated very recently so I think you know let\u0027s discuss in the meeting and generalized issue yen this is also one of the other end of the today and this also has been updated two weeks ago or something so let\u0027s discuss up late in this meeting and LOC draft and this draft has been quiet for a while but he also seems to have some updates on this drug and then this is also agenda today so let\u0027s discuss in the meeting and II do draft I think this draft has been quiet for a "
  },
  {
    "startTime": "00:07:16",
    "text": "while but according to the authors also has some plan to do some experiment and so we expect they also will come back with new bottom of the track with some result um about our P or consider I think this draft is getting very matured but in order to finalize this drought we have to sort us some point and the main point of the discussion is to keep consistent consistency with the related dogs because RTO consider had some related dogs such as RFC 80 85 or RFC 62 98 or RC 793 or 793 B\u0027s so we have to make sure each drug do not contradict each other so we try to make some no we have the chance of starting discussion with on this drought and then try to make some proposal to the authors of some that text that do not cause any conflict with our document that\u0027s about you know right thinking right now so and then if that doesn\u0027t work well I think we might think about other brands but right now we try to focus on to make some proposal to the authors so which can also agree that\u0027s the plan for the chairs and then about the 2040 based draft in the rest meeting well we did working a working group adoption code and then as a result I this draft has been adopted and so right now we are trying to prepare the - form of this draft and but there are some discussion between the author and then Cheers and then the chairs know made some type of proposal and then I think they also you know agreeing some one of my our proposal so our expectation is they also will update trust based on our suggestion that\u0027s the current status any questions so far okay moving on and then um 793 B\u0027s draft unfortunately ways general come to this meeting but we got some text from him so I will talk about it on behalf of the author so as you might notice their 3d button has been submitted about four days ago and there are several open discussion item in this draft so always open this start opening the thread on the mailing list with the following entitles so the straight will "
  },
  {
    "startTime": "00:10:16",
    "text": "if you try to open for straight I think and then after you know we settle down or opening open discussion items new budget will be submitted in pin saber closing all the item mark to do in the draft that\u0027s the plan okay any questions so far okay moving on and then finally I would like to talk about MP TCP combat a draft so right now chairs are having a plan to run adoption call on MPT CP combated draft so to be clear um we are going to run adoption core and then we\u0027re an adoption call on this draft and the if it\u0027s accepted well supported and participate combat the draft will be a working group item of booty CPM working group that\u0027s the prong so really briefly describe the background of this draft and so this draft first name is a draft of phenomena and PTC become butter this drug has be presented in the rust MPD CP meeting and then this draft is mainly designed for to assist the deployment or multipass CCP but if you look at this throat carefree if you look at the architecture in the draft this draft has a certain generic architecture so to be clear I don\u0027t say very January quite i dont say razer generic no because this will be a part of the decision so it has some generic mechanism so and if the architecture in this raft is a generic winner we can apply this technology to other tcp extensions such as this think maybe we can apply the same technology to this thing that\u0027s maybe very interesting use case so if this draft can have a generic mechanism it will barely make sense to have this draft in TCP and working group and so if you are interested please see or via the email which he sent very recently several days ago like contains lots of you know useful information to understand that or his draft is the intention so please check and then right now you know we cannot discuss the technical detail of this draft but know we would like to share some opinions on learning adoption code in TCP and working group so there are several options of the shooter direction of the job so she would like to understand what people think so if you have some openers please say please speak up me I could have its "
  },
  {
    "startTime": "00:13:20",
    "text": "own right yeah me a cool event M s ad for both of the groups so I would just like to repeat once again the request for reviewing this document even so the use case is MPT CP and that\u0027s a use case that makes most sense I think what\u0027s needed here is like general TCP expertise which is in this room so please have a look okay thank you any other opinions if there is no specific opinion in this room we will run adoption core on the mailing list and we try to get feedback from people David Parker\u0027s TCP Inc chair yeah definitely double plus one the question mark there I realize TCP Inc is trivially man in the middle of all however publishing a draft that encourages that to be done TCP Inc is probably not a good move so what\u0027s your preference what is your preference on this track so Dave back so to be clear I would not I would not try to make this draft applicable to teeth applicable TCP Inc I think that\u0027s a I basically if you make us write a factor a little TCP Inc you\u0027re describing a man-in-the-middle attack as a feature I think and that\u0027s not good I prefer just leave looked at each being left probably left left alone so it\u0027s not a man-in-the-middle attack it\u0027s like if two or both of the inputs would not support you see peeing there could be a middle box that would still support you spitting and encrypt the traffic over the rest of the path it\u0027s definitely not a middle man in the middle and then TCP includes not only options there may be another TX extension that we might be apply this one okay any of other opinions okay so yeah in order to get more feedback we will run adoption cottage on the mailing list thank you so much okay moving onto the working group item presentation so first one is our something back off name box so okay so let\u0027s try it "
  },
  {
    "startTime": "00:16:26",
    "text": "so this draft is basically an update to the to the alternative back off with EC n so next please in the last ITF three persons were assigned to do the review the Valen volunteer to do the review so we\u0027ve got feedback from Roland and then we\u0027ve got also a couple of days ago we got feedback from Lawrence and and thank you to them thanks to them and and we have incorporated these these feedbacks that we received from them so we have submitted two revisions over the course of the time between the last idea from now the revision 0-3 was submitted a while ago and and I just submitted the revision zero for last night so what has been basically happening we have tried to incorporate all of the comments from from the two reviewers basically we\u0027ve got more consistent terminology and definitions so there were things that were basically a bit more hand wavy and then we changed them and we make them to be more precise and and we define the stuff that that were there more precision in the language we distinguish for example between what is a buffer and what is the cue because both term terms were used in the draft interchangeably so so we provided a more accurate wording there also everywhere where we we for example I mentioned loss now we wrote as an inferred packet loss so the language of the draft right now is more consistent with the RFC 56 one and RFC 3168 language and the formula style that they have been using for setting the SS stretch and Seawind next please so we also provided some clarifications one of these color if occasions were on the safety of the mechanism we explained that the worst case scenario basically with with alternative back of it ecn is no worse than the standard la space DCP because anyways let\u0027s say you basically don\u0027t react to to ecn signals you are still bound to the to the reduction based on the lost space ccp\u0027s behavior as its described in the in in the 3168 and in the in the in the previous RFC and also there was some ambiguity about the scope of the document because we somehow in the previous revisions provided some hints or recommendations that this could be used for other transports now we have a more clear language in the draft that says that this beta Sen that we are recommending normative language is only for the loss based standard TCP and also we removed "
  },
  {
    "startTime": "00:19:27",
    "text": "the normative language for other transports and now we only basically say that it\u0027s applicable for other transports that that that have a per our TT e ZN response so if there is a future draft for example and specifying a CT piece condition control behavior then is up to that draft whether to adopt the alternative back off with e CN with with their specific better value that they might want to use or any other type of congestion control so the scope of this draft is basically limited to standard tcp the references are updated there is no change to the to the technical content of the draft yes please next it was gory fairest and I was commenting as TS VW GTI rather than co-author and I think that\u0027s the right thing to do with things like SCTP and other transports we can\u0027t make a normative requirement on future specs but we can say that this is the right process whether we\u0027ve got quite the right words we can tweak them a little bit if we need to but I I think that\u0027s the right thing to do from TSV WGS point of view unfortunately these the ec inspector for SCTP was never adopted largely due to a lack of progress with ecn at the time it was brought up so that could have become a future item perhaps if that happens that other moment there\u0027s no reason to cite that old internet draft sure so so I think we agree on that so this is basically limited to to what is in 3168 and so the references are updated there\u0027s no change to the technical content next please and so we have as we mentioned previously in Prague we have submitted a patch to the freebsd upstream over the course of this time this patch was being reviewed now the review is complete we expect that it appears and the FreeBSD s main long kernel quite soon in the matter of days if not hours and we\u0027ve got also patch for Linux which is been there for a while so this is kind of becoming available in Oasis eminently and I think that\u0027s that\u0027s all any questions I have a question on the implementation so the draft says the value should be recommended values point eight right what is the recommended values yeah so we recommend for the standard TCP we recommend to use beta 0.8 0.8 so my question is are these implementations using 0.8 sorry are these implementations yes by default has "
  },
  {
    "startTime": "00:22:27",
    "text": "there been any experimentation done to see if after applying the value of 0.8 is there a loss in the subsequent or DT sorry can you speak a bit louder the mic is not working as it should hello yes after applying the reduction factor has there been any experimentation done to see if there is a loss triggered in the next our duty and would it make sense to make the back of more aggressive for subsequent buyback of more aggressive you mean to reduce yeah yeah so we haven\u0027t been looking at the loss behavior but of course the aqm mechanisms they have got a protection mechanism so so if you have an unresponsive traffic so you anyways I guess my question is you don\u0027t know whether there is a cure so if you make this change I need I need some clarification here and okay but the fundamental basis for the aid work and this go affair has does an individual off this time and was that if you see loss ever you use the standard TCP Bally\u0027s for better this the change is only when you see an ECCN mark if you ever see lost you behave as a normal standard TCP would repair I think like yeah but my question is even if you get an easy n mark so this is deviating from what the original RFC said that is there is a potential that you might get more easy on marks or even a packet loss in the very next oddity so my question is should we be more conservative in such a case what happens if you get easier marks and loss in the same round-trip time you take loss you do the loss reaction and the reduction that you would do for loss usually you only reduce once per round trip time right if you get the easy and marking first you reduce by 0.8 and then you get a loss later on and you could you would reduce further yes so it\u0027s implemented well I I can\u0027t say it for sure but with your question yeah yeah ok so check make sure it maybe clarify in the draft as well I don\u0027t I can clarify that so you\u0027re saying is the reduction by half of a half of what you did after ecn or a half of the original right it\u0027s a half of point eight or the only change that we make is that whenever in the previous like like everything else is the same in RFC\u0027s the only thing is that that "
  },
  {
    "startTime": "00:25:27",
    "text": "whenever you receive an e CN mark basically you go by 0.8 so so either normally you would react once per our TT so so if that\u0027s the case we didn\u0027t touch anything else so then then it should happen that you would go down by this by 0.8 and but then of course you may subsequently receive a packet loss in the next hour TT so but I can definitely check against the patch and see this is not something that is explicitly in the patch so I can see what happens to this behavior david black let me let me sharpen melius point because you can very close to it but what you\u0027re subscribed was easy and mark in one RT t loss and next RT t what I understood need to be concerned about and I sure the concern is you get an easy and mark in one RT t and you react and then the stack says and I\u0027m not going to do anything again in this RT t and while the sack is not doing anything again a loss shows up okay that\u0027s that\u0027s some tact you did that\u0027s gonna be careful about every see and marking actual at masking actual losses sure Michael Wetzel so there\u0027s not command that\u0027s a question because this isn\u0027t really about Abe it\u0027s about ACN I mean in general you know if you have an EC and Mark and then you have a loss in the same round I don\u0027t know what is he and us as on with when ecn is lost equip is loss equivalent ie before you do this it doesn\u0027t matter because the reactions are saying you did it once you\u0027re supposed to react once per RTT I think we agree it\u0027s time to go and read the code normally see a nun for a because it\u0027s a separate bit of cord surprisingly and let\u0027s just check we Abe does not Abe does not change it that\u0027s all I can guarantee but the question is what happens and I don\u0027t know what happens when you get them the two bits of cord interacting one Maricopa AZ which is what you do you read the EZ and papers that sallyboyd has written she has been very carefully specified what to do Lawrence Stewart as the one of the people reviewing the freebsd code and literally with my finger on the commit button as we were having this discussion I\u0027ve just held her for a second but the code does hold essentially it said sin recover on in response to receiving EC and Mark and does not apply an additional back off if a loss were to show up in the period so we can alter "
  },
  {
    "startTime": "00:28:27",
    "text": "that if we think that\u0027s appropriate but as currently implemented it would essentially do nothing until the semi recover was reached and then if a loss showed up after that we\u0027d have a 50% back off but at moment it\u0027s only 80% yep sir david black wax rep did this say is that I was third reviewer I finally got the review done just in time ie in the last 12 hours it\u0027s on the list it\u0027s almost entirely to troller the only thing that might have a little bit technical content to it is the draft has a very strong focus on recent modern atriums like pi and coddled however this is also going to be deployed with whatever eight terms are out there and a little more discussion of what else is or might be out there aside from dismissing read would be a good thing sure any other question okay thanks so much okay the notes will be easy in prosperous you want to study yes yes hi Marcelo annular here speaking for the authors of the EC n plus plus draft next slide so in the last meeting we basically have one open issue left that is what to do with respect to Purex so there is a strong motivation for actually ECT marking pirogues because if we don\u0027t when there is there are episodes of congestion Purex will be more likely to be dropped which will result in performance impairments so it would be useful to mark them to avoid this type of drugs the problem is what do you do when you actually receive a C I mean when the pure rock is actually marked with C and you get an ECE back how do you actually respond to that congestion signal the issue that was noted in the previous meeting is that if we in the case that there is an endpoint that is only sending pure acts and you actually respond to that congestion you have a bias a biased response because the only thing you can actually have is response of your acts having congestion and eventually you reduce and reduce more the window and you have no opportunity to increase the window on "
  },
  {
    "startTime": "00:31:28",
    "text": "the other hand not responding to congestion to a congestion signal that you actually receive seems like a like the wrong thing to do so the question is okay okay so so the question the question is how do how do we handle the situation right so after some discussion the proposal that that has been done in the mailing list is a next slide please is to only ECT marks pure acts in the case where a key CN has been enabled in the connection the reason for this is because easier occasion actually provides a more accurate information and reports the number of packs that of packets that have been see mark but and also a number of bytes that encounter the congestion right so that allows the congestion control algorithm in the sender to actually be able to respond to a match a finer-grained signal because in the particular case of products the number of pack of bytes that encounter congestion will be zero right because the pure drug doesn\u0027t contain date right so this is basically the the proposed way forward we have mentioned this in the mailing list there was no negative feedback there was little positive feedback but no negative feedback so basically a question is if the working group feels happy with this and we can close this issue this way comments oprah\u0027s goes as co-author and we also need to make the point that the occasion option isn\u0027t being stripped in order to do this response because you need it to get the bite because there\u0027s there\u0027s a case in you know if a middle box is stripping it you haven\u0027t got the information right so this is my from the from the floor as individual so I wonder in general a little bit about the tight coupling between tests this draft in the ekor dcn one so because some of these things in principle could be separable and but we now have two cases where we actually make a dependency on those two drafts so and really personally I\u0027m wondering whether that\u0027s really necessary because from a high level perspective if you look here at corner cases I\u0027ve been a to a one-hour iltf meeting this week in one I H F meeting where there has been pretty fancy discussion on congestion control that is not only about Asian and in those cases I\u0027ve seen pretty aggressive proposals so I\u0027m really wondering whether we need to deal with all corner "
  },
  {
    "startTime": "00:34:29",
    "text": "easy on cases correctly so to me I think there could be ways how we could better decouple that draft here and the equities you want there\u0027s a risk probably that some information gets lost some odds may be get lost the question is why would we do we really have to care about that if other transports are doing completely other things and as I said I think this draft could be simplified if we make clear how this could be deployed independent of the collision and how it could be deployed with segregation but I personally would suggest to clearly define a mode where accurate easy and it\u0027s not the newest so m-michael it the draft I think currently contains that information right so the draft will basically say at this point that you clearly separate once at one part of this section this is how to use this without a hurt issue then another section and this is how you do it this accurate issue and it is digitally separate it this is essentially the toriel right I mean yes it\u0027s a datoria but I mean it could maybe simplify the document a bit and change things it\u0027s it\u0027s it\u0027s mostly editorial but as I said I I would look for clear guidance how to do this without acquisition and as I said for the purer part I\u0027m still not fully convinced that you\u0027ve only enabled it if you F extradition maybe you can just do it so how\u0027s it let\u0027s wait wait wait there are too many things here so the first thing is weather okay so the the current draft clearly defines what to do when ecn is negotiated and when is not right there is a table that actually describe which situations are this is perfectly describing the draft I think is I mean maybe it maybe there is some editorial effort needs to be done to convey it more clearly I\u0027m happy with that but the information inside there whether it the best approach is to actually have two documents back-to-back one with accuracy and or another and another week without accurate CC and or to have the integrated version that\u0027s an editorial discussion that we can have and I\u0027m happy to do that right the first thing that I would like is to close this issue and then talk about the more editorial part so the thing is we have the discussion about how much to mix this with accurate CCN especially for the scene right the scene is much more problematic than this one even even for the soon I think we could reopen the discussion because I\u0027ve seen as I said I\u0027ve seen crazy things here so why the hell do we really have to care about an ECCN mark in the cinema this is really something I think we have to start to discuss here in this working group what sorry I didn\u0027t understood why do we have to care about a single ezn mark in the sin why do we need to care about why why does this matter because if the scene gets lost you don\u0027t get a new connection "
  },
  {
    "startTime": "00:37:30",
    "text": "oh but why do we have to care about transporting TC and signal if it got marked why do we have to care the congestion signal because this is so I think you have the person who is going to answer that right now right behind you all right I mean the thing is I and I agree with her she has made a very clear statement that is an architectural statement that you should not avoid responding to explicit congestion signals that you receive it\u0027s a bad practice I actually subscribe what what what her what her statement right now it\u0027s not okay to just make discussions that it\u0027s okay to ignore loss and so that\u0027s why I\u0027m us good question why why does it matter but people don\u0027t agree that it\u0027s okay to ignore loss right well a bunch of people these are particular people doing it but people don\u0027t seem to agree yeah let\u0027s open the discussion here if this happens another working group whether we have to care about a single ecn mark and my statement is no okay so let me yet to respond to that yeah okay and that was the very first and that was uncanny because my review which I\u0027m going to try and send to the authors and I haven\u0027t yet typed it in came up very similar it seems the document was complicated because we have accurate easy and not and I wonder whether we set the bar subconsciously high in terms of quality in responding the right way and made a really difficult document to pass when the concept is very very clear but we\u0027ve come difficult in the document to read so do we really need to intertwine it with accurate easy n-no but but the problem I disagree that yeah I disagree that accuracy supporting accurate CCM is a is an is what complicates the problem the problem is complicated in some specific cases like in particularly in this case all the bias about the negative feedback this is not a problem of accurate ecn this is a problem right accuracy and actually provides you more information that allows you to go to a better solution to the problem I could easy an is fine and we have to do updates to implement this we have to update student accurate easy and could we roll the 2 into 1 yes ok then we don\u0027t have to just focus on the case we\u0027re actually easy and is not enabled because we don\u0027t have to do the stuff but let\u0027s just think about so the equity CN bit but myriad Mira\u0027s going to talk about that so I\u0027m I was only rippling up the same thing and saying I\u0027m at the same level as Michael I think I\u0027m sure I understand what you\u0027re saying you\u0027re saying that we need to drop all the part that are not accurate again I\u0027m saying that might be a possibility this document should be easier to read it is it is a thing we want people to do and it\u0027s quite simple so either we say just use equity CN and then do this because that makes it all this simple as one update I\u0027m ok with that if that\u0027s the right thing or somehow we make it simpler because the current text is hard to pick out what really you have "
  },
  {
    "startTime": "00:40:31",
    "text": "to do that\u0027s fine you live in so I agree I think it would make the document simpler if we would only use accurate easy n if you only discuss so it\u0027s a little bit the opposite from what Micah says but I think that\u0027s actually right thing to do because first of all you want to deploy accurate easy and we want to deploy accurate easy and as a replacement to easy end it\u0027s a change so we can do these two changes together and it makes it much more safe so suddenly in the initial proposal from micro makes much more sense right now made perfect sense to actually have two documents back-to-back one without accuracy and the other the other one with accurate CCN and both of them is simpler to read for whoever wants to read it I want one document where so the document already says if you put marking on the sin you have to negotiate accurate easy and right yes right so what I\u0027m saying is any if accurate easy end is negotiated then you should further think about marketing control packets if accurate easy and is not negotiated you should not mark any control packets that makes a document very easy I may agree with that I mean given that probably you know probably the most important packet is the sin that you want to get mark and you only can do it with accurate cm so just the mess just as well go for and just do it for accurate CN I\u0027m okay with that just for the record I don\u0027t buy that argument but I might be in in the rough which which which III don\u0027t buy the argument that for the sin you really need expertise yet ah no you don\u0027t know you don\u0027t really need that good I agree I mean as of today what the draft says is the solution for the for feeding back the con the congestion signal to the to the sender is using accurate EC end because we don\u0027t want to waste more baits and blah blah blah there is a bunch of arguments in there all right you could try to do something else I agree that\u0027s more the second point like do we actually care about inserting being marked like there is an indication of congestion do we need to react to it is it important that\u0027s your question right say the difference between easy and losses that\u0027s an explicit signal so it there is congestion for poor loss you never know for sure you don\u0027t know why the sun-god loss you don\u0027t know if it\u0027s congestion you don\u0027t know what it means you but you also have a timeout right if you\u0027re soon as gone you have to wait for other so it\u0027s kind of a penalty if you want to say it but it\u0027s also kind of there is some time where you don\u0027t sense anything on Lincoln so the condition might resolve in this case you get an immediate signal that there is congestion so just not reacting to it is just just ignoring it is wrong what the reaction is is also a different question well I mean as I said I mean in conceptually it\u0027s radically you right in practice what happens at this IGF tells that this is a totally stupid conversation if people don\u0027t react to "
  },
  {
    "startTime": "00:43:32",
    "text": "loss which is clearly a congestion signal so okay okay let me suggest a way forward so I understand we all agree that if there is accurate CN what isn\u0027t written in the draft is the right thing to do so what I would suggest is let\u0027s limit the scope of this draft to a cure edition if someone wants to do this for something other than a cure it\u0027s Ian please write a draft and do it right I\u0027m doing this for accurate decision and and whoever works will do something else it perfectly fine it\u0027s open it\u0027s not incompatible with this it\u0027s perfectly fine yes go for it well the Pope co-author the the whole issue is though that there are two ends and sort of I think most people in this room know that about TCP and so the way the draft says it is you should only put ET and capability on the scene if you implement accuracy n but you still don\u0027t know what the other end does right and then if the other end comes back and says it doesn\u0027t support accurate ecn then it says you know conservatively no we\u0027re still going to have to say that even if we say you only do this all right but we also said that\u0027s where the complexity no no no no no but because we also say that for instance doesn\u0027t matter if any of the endpoints support accurate a support accurate is yen I don\u0027t know retransmission you should mark it anyway right and that doesn\u0027t matter whether they are or they are not accurate is yen I so basically what I\u0027m saying is let\u0027s drop all that which is pretty minor part of the text just keep the case that it\u0027s accurate is yen the sender is accurate is yet right we deal with all the compatibility of the other endpoint of course but but we drop all the part of both endpoints being non accurate is yet right the sender being not accurate is yet and we we explicitly said that this only covers the case of the sender being accurate is yen cable and we don\u0027t talk and and we don\u0027t mention I mean and how the behavior is for an endpoint that is not accurate is yen is unspecified and whoever wants to specify that can do it but that would mean then this second response to Michael\u0027s point I\u0027m reasonably okay with being a bit more liberal about responding to loss you know rather than treating each one as sort of each loss is sacred and and all as to it however very much different on the scene absolutely no non response to loss on the scene I will fight tooth and nail to stop that because the internet collapsed because of that and it can do again and and "
  },
  {
    "startTime": "00:46:32",
    "text": "there are people here who are saying oh we might even see an internet collapse and then we\u0027ll get more research funding [Laughter] yeah but now and and the reason is that if you that the back off on the to loss on the scene is what stops new flow is coming into the network and that\u0027s what causes collapses we mustn\u0027t forget that well again my comment is on the East End mark on this or Anderson not the loss I mean fault for the loss we all agree so but the key question is of why to care about an ECCN mark on the scene and my point is I don\u0027t really see the point let\u0027s I mean if if the if the router is really congested she will drop the soon and we\u0027re done I mean it\u0027s not the way we\u0027re saying anything we\u0027re just saying what the response has they you know it is Finizio mark on the scene is it\u0027s not so let me see if if we agree on the way forward so we\u0027re going to limit the scope of this draft to accurate this yen and the case were non accurate is en sender is not going to be considering is going to be left open for further future specification that make everybody happy and as a projection obviously idea okay thanks next slide I hope I don\u0027t have any more slides but okay so okay this doesn\u0027t really apply anymore so I will change the text to reflect what we discussed and send it to the workgroup for consideration and see what happens okay thanks so much Angora I promise I will type my review up although I won\u0027t dwell on that particular issue we\u0027ve now discussed I have a few other points which might help okay thank you my next presentation please so this is a presentation regarding some measurements that we have been doing regarding this experiment so this is accepted to to appear in nitrile communication magazine soon so but you I will have a link at the end of the slides with a version that you can download in case you\u0027re interested next slide please so what we wanted is to see if we can actually do some measurement to get some initial data for this experiment and then in particular we\u0027re looking for is to find out whether Sen market TCP control packets barracks "
  },
  {
    "startTime": "00:49:33",
    "text": "are treat or NP racks are treated differently when they are is ECT mark em sorry or differently then a Sen mark data packets sorry so basically what we have done is we started a measurement campaign to see how easy n mark or ECT mark data packets are treated by the network to get some ground troops on some baseline and then measure how TCP control packets that contain ecn marks are treated by the network and compare the results right so that\u0027s basically what we did next slide so in order to do this we use two measurement platforms a one is planetlab that I guess you all know so we use 54 planetlab nodes in 25 years and 22 countries and the other platform that we use that you may not be so familiar with is a platform called monroe that basically is a platform that allows you to measurements in mobile networks right so this basically what the mantra platform has is monroe nodes there are devices that you can program that you can that you can put some measurements in there and they connect to one or more providers through seems right to mobile providers and you can execute measurements against servers that you have on the internet right so in this particular case we have 11 ISPs which are the ones that I show here next slide please so the experiments that we did basically was as I said getting data packets with ecn code points and getting the different control packets with ecn code points and see whether they are treated in the same way by the network or not so what we try these all these type of packets with all possible ecn flag combinations right including both in the TCP and IP header both for rating for based a basic EC any CN + ec + + + + accurate is here so the tool that we use is we use trace box that is I not sure if you\u0027re familiar with this tool this is a tool that the people from UCL Leuven has developed that is basically like a trace route that increments that it L but in addition what it does it compares the flag from the original packet to the packet to the pieces of the packet that you received in the error in the TTL expire so that allows you to see at which hope Flags has been changed right so we executed this bit from the mantra node to Alexa 100k servers and from the mantra note to our own servers in this case we actually control both endpoints and we can play with for instance the cynic next slide "
  },
  {
    "startTime": "00:52:33",
    "text": "please with the emergent campaign between January and May of this year we use to port 80 and 443 with the 25 million measurement blahblahblah okay next so what have found so the first thing that was kind of surprising that we found is that for the data packets in particular but also for the for the other control packets but for the data packets ecn regular ACN we found that seven out of the eleven mobile providers actually clear the easy until when you send ECT mark packet so that basically means you send ECT zero one mark pocket and what happens is that the first hope of the mobile providers actually clears the ACN fields and turns it into non ECT right because we found seven out of 11 which seems quite a bit we find we tried other few mobile carriers we actually try seven more and we actually found that three of them have the same behavior yes Emily Watson I was going to try to clarify the uplink packets problems yes so it\u0027s going from the client to the server in the other direction we actually did not observe this behavior so it is not necessarily the mode it\u0027s not necessarily the mode mobile the service provider doctor cleared it could be a mobile modern ship such sorry I\u0027m it could be the modem shape start clear easy on bit as well the more than chips bridging the first hope you\u0027re it\u0027s a first stop on a tour to so the modern chipset is usually they come in you decrement the TTL or it could be before the okay Stuart sure sure Apple if I\u0027m sound the question correctly you\u0027re asking you\u0027re speculating that maybe the mobile phone handset itself is clearing its own ect base before sends the packet but if it succeeded in four out of eleven mobile providers that suggests that the handset is not clearing its own right so it is it Eastham is that is the same sorry so I understood the question answer so it is the same device that is actually is using for the different I mean the same means the nodes are all the same right okay so so we found out so we also find that is one mobile providers only clears it in the port 80 and not in the four or 443 this I mean this is a case of a proxy and as I said we didn\u0027t find evidence of clearing the the ecnv any the ACN fields in the traffic from the servers to the client and for those who didn\u0027t clear we find evidence of little bit of clearing 0.53 percent which is somehow similar with "
  },
  {
    "startTime": "00:55:35",
    "text": "the current literature on the fixed networks which in this case for the planet that knows we find 0.23 percent of clearing deeper in the networks like five hops away or something like that okay to make sure it\u0027s not a common idea taught right sorry zero come not come all right in the text well I usually use comma but but yes point dot zero point zero point of 53 yes yes so comparing EC and EC n plus plus so what we did is we tried as I said ec n + e ZN plus plus all possible flag combination and what we observe is that they do not cause any packet drops right so you don\u0027t get packet drop because you set any of these flats which i guess is a good thing and the main conclusion probably for this graph is that easy and plus plus support is exactly the same as e CN plus CC n so basically that means that if you get clear you could get clear both in contour pockets and in data packets if you don\u0027t get clear you don\u0027t get clear for none of them so basically it doesn\u0027t seem to matter the the boxes that do this doesn\u0027t seem to look whether it is a senora control packet or a data packets basically everything works the same right so probably from this limited set of measurement we can basically say it is probably safe to or a safe a CC n to deploy ec n plus plus you know just go back yes quick question so did you also test this on not mobile networks yes so i tested in so we use with 54 planetlab nodes that are fix it and that\u0027s what we use so another result is 61% of the Alexa top 500 K support CC n and only three point 51 percent support DC n plus however interestingly enough none of them respond in the way it is defined by RC fifty to sixty two fifty five sixty two right so we\u0027d have not been able to detect any server that is actually implemented what it\u0027s in there so they actually do respond to sin with sin acts with ECT in the cynic but they don\u0027t do not behave in the way that there is supposed to be okay so Bob already reported is before next life yes sorry what does RFC 5580 to or what was it say yeah what does it say so that\u0027s hot that\u0027s hot that\u0027s maybe you know better so actually a fifty five sixty two defines a very weird behavior right so basically says if you receive a mark in the Indus in a city mark in the sea not correct me if I\u0027m getting this one "
  },
  {
    "startTime": "00:58:37",
    "text": "and I think what you should do is start over again the the the exchange correct so you need to you need to resend this that the scene without and and see if you can actually get the scene as in act back without without the mark right that\u0027s that\u0027s what it says so if you end up with like a 508 handshake the the 5560 to set the old Sally document which said how to try and negotiate you expecting it wouldn\u0027t happen and then falling back and doing it again so you end up retransmitting and a multiple level handshake rather than just normal three-way I I am contacting the author\u0027s to try and find what the intention was what they were trying to do and the original intention was just to put a CT on the syn/ack so that you got ACN coverage of that which is an important packet but then while it was going through the ietf so there was an academic paper written on that and all this expense was done like that then when it went through the ITF there was this that it had to be exactly like a loss and and so they they tried to make it like two round-trip times worth of of delay like by bouncing the packet back off the client and back again and and it was all a bit weird miracle Levin again do we need to update that so that that we actually discussed that I think in the in the last meeting and what were we said is that ec n plus plus spec would actually update that behavior also yes so all the stuff that we found just fast so we found that all the servers that actually support this yen respond to EC EC flags in this exactly the same way that I respond to three duplicate acts which is a good thing and we did some stats on initially wind initial window as well and we found that 51% use initial window of ten ten percent user initial window of to ten four and funny enough 0.4% usual initial with no much larger than ten actually they some of them actually sends the whole file in the first around take time no matter what that is yes probably pravin Microsoft what is the 14 percent not applicable bucket and why is this not adding up 200 sorry wants idea what is the 14 percent not applicable but I don\u0027t remember I think it was other values then then then two and four okay and this is all of this is not adding up to hundred percent so all of these are not adding up to hundred percent so ah "
  },
  {
    "startTime": "01:01:44",
    "text": "I don\u0027t remember sorry it would be good to get the right date on the mailing list maybe yes I will okay next slide please so you here you have the I mean you have the the URL to the paper but I will actually send respondent to make the question in the mailing list so final remarks it seems forth from for this that Sen plus plus is a safe a CC n so probably that that\u0027s a good news there is more work to be done in order to get ACN through and the question is whether it is relevant that we found evidence of EC and clearing does it matter I mean it\u0027s not that it\u0027s dropping the packet it\u0027s just that they are cleaning the thing and the problem is if you have something like a more a multiple Hopf path behind the the same access right that are actually using easy n for something that signal will get lost right so any potential benefits that you may have obtained like smaller buffers I mean smaller queues or anything like that that you have implemented before the our cellular access like for instance you have our router that is using a seem more something like that this will get lost so this is the impact of off of GCC and clear okay and as I said the paper can be found by that sorry for not being able to answers praveen\u0027s question and and that\u0027s it thank you next accurate is here before we move on come in um before we move on I wanted to Marcelo I wanted to make a comment on that I\u0027m wondering what it is that you\u0027re hoping to achieve with this paper because titles and how you present things have a big impact and journalists love they\u0027re clickbait titles about how the world is coming to an end and the vegetable that may be killing you tune in later to find out what it is your title is bad news for ecn and what I\u0027m concerned about is there are many many people who will not read the paper will not read the slides will not remember where they even saw it but they\u0027ll just remember that yeah ecn has failed bad news frisian not safe to use and if that\u0027s the message you want to send which is like forget about easy and it\u0027s not worth trying that\u0027s what your headline says and I\u0027m concerned when I\u0027m talking to my management chain at Apple right if my VP says yeah I saw something about ACN is not safe 11 out 7 out of 11 "
  },
  {
    "startTime": "01:04:45",
    "text": "mobile operators drop your connections if you try to use ezn and he won\u0027t remember where he read it he won\u0027t know the facts he\u0027ll just have internalized this this idea that the ACN is bad so that that\u0027s my feedback if we act I would call this title fantastic news for ecn completely safe to use 100% at the time causes no broken connections and if those mobile operators want to upgrade their networks to suck less in the future then that\u0027s even better news right so I would cast this as good news not not catastrophe and calamity for easy Anna Microsoft I would actually concur with what Stewart said this is actually good news because I\u0027m going to present later about TCP fast open and here the failure mode is just removing the bits right it\u0027s actually very safe to deploy and you know make incremental progress on versus some of the other things we are trying to do with TCP so I would also classify this is actually very good news right um I guess I\u0027ll respond on behalf first pose and say well think about that yep I\u0027ll respond on behalf of us the co-authors and say well think about those comments yeah right accurate ECN there\u0027s the co-authors and we\u0027ve got changes in affiliations next slide right I\u0027m not going to go through the recaps this is just in the slide pack for those that are new here maybe so they can read these slides in their own time next again a recap of the solution which I\u0027m not going to go through next all right so this follows on from the previous talk and I asked for the agenda to be changed so that they would follow on in in order to respond to the measurements that we\u0027ve just heard about we have altered the accurate ecn draft we\u0027ve actually taken stuff that was in an appendix waiting to see where the measurement studies would would find problems like clearing a CN and we\u0027ve put it into the main body of the document now because there are those opportunities they\u0027re not problems right and or issues and the so what what we\u0027re proposing is if you just look at the picture on the words for a second is to have full feedback of what was in the IP layer on the cinema Cenac in the TCP header of "
  },
  {
    "startTime": "01:07:45",
    "text": "the cynic in the next stack alright so the you can see there the way that goes so that and that means that both bits are fully fed back rather than just feeding back whether there was a see mark or not we get full information on what the network has done to the IP layer at least on those first two packets right now we could get that information later in the connection by a bit of heuristics and I\u0027m watching what\u0027s going on but particularly because it\u0027s an experimental protocol we thought let\u0027s measure it accurately and report those measurements as part of the experiment and it also makes the code easier because you\u0027ve got a clear indication of what\u0027s going on rather than having to do heuristics right so that that I think summarizes everything on this slide how other than if you if you find that the IP ACN field has been mangled when you get the feedback back of what you sent then you disable it for your half connection but you can\u0027t there\u0027s no mechanism to tell the other end so it\u0027s a half connection thing the other end can continue using it and that\u0027s fine because in indeed in the measurements we found it was an asymmetric clearing and so it\u0027s okay to use it on one half connection even if it\u0027s broken on the other right okay next so the way we\u0027ve done this these are that the top table was already in the draft we\u0027ve added another table for the syn ACK so there are three ec n bits used in the TCP header and we now use four different combinations of those to feed back all the possible values and this is this is during the three-way handshake and so it was already defined as being a code point based feedback at that point it\u0027s only one that when they think it started after you\u0027ve not got Sydney it was one on the packets but you start just having a counter counting the number see marks so this is how we do this feedback and and actually the encoding we use had to fit around other uses of them in other versions of ecn but essentially you\u0027ve got if you look at the numbers in binary they would be two three four and six for the for the three values err on the field so it\u0027s reasonably easy to do in the code we view the same in the in the other direction two three four and six for the same code points in the IP header and there\u0027s loads of detail in the draft about how you can still support sin "
  },
  {
    "startTime": "01:10:47",
    "text": "cookies and things like that so even if the server hasn\u0027t got any state when it gets this third act back it\u0027ll still all work okay right so that was um the main change to the draft the the next main change was to write in the summary of the discussion that we had at the last ITF on change triggered acts now there was concerned that this might not be possible with offload hardware what we\u0027ve done is we\u0027ve changed it to a must from a shoot to a must with the get out clause because we wanted to ensure the receiver could rely on this behavior but given its experimental we have described a possible experiment that people could do there isn\u0027t the mast you know that so it allows people who are having this problem to it gives them a hint that we\u0027re happy to see experimentation on this and then it says because of this problem with needing to rely on the behavior that it\u0027s then their responsibility to deal with the other end understanding this behavior you know that\u0027s it\u0027s an experiment right fun but it\u0027s their responsibility that\u0027s the fact right so one and the one put possible compromise is that instead of not doing change triggered acts because your offload hardware can\u0027t do it in or you you\u0027d lose your performance cause you can\u0027t use offload hardware to do change trigger tax during slow start and then the gotough off load off load once slow start has ended right and that means that most of the performance of most of the server\u0027s most of the time he\u0027s using offload and it\u0027s just for the slow starts that you\u0027re not and I\u0027m told that there\u0027s very similar code to that already in place next right we did some minor edits as well someone wanted to just check that we weren\u0027t relying on a certain type of ecn in the network it wasn\u0027t related to l4s or something and we made that clear we added that deployment itself should be an experimental success criterion we added that you don\u0027t use the congestion window reduced signal so it just in case anyone thought you still had to use that and we also made sure that we defined the behaviors of all unused values so that it would be clear in in the future what "
  },
  {
    "startTime": "01:13:51",
    "text": "the behavior would be for forward compatibility Michael yes so this is again Michael speaking from the floor so thanks a lot for addressing my comment on the experiment success criteria unfortunately I don\u0027t like the new grading leader so I think I owe you something on the mailing list you still have wording in the document that refers to the TCP I\u0027m working poop and I think this doesn\u0027t address my comment from the last working group but instead of saying it on the mic I probably have to write it and or maybe I have to produce a maternity wear at their place yeah so regarding the the last point one very naive question so I mean this is an experiment so assume that we move this to standards track at some point in time and assume that we have to change something how would the negotiate the standards track version right I think this is something I mean you don\u0027t have to necessarily document this in an experimental thing but it\u0027s something that in my opinion would variant thinking so how would the standards track version of this be negotiated right what one one technique we\u0027ve written into the draft is that the the countess starts at a certain value and if I started a different value it could employ a different version right and and we say that the current version should be able to cope with the counter starting at a different value yeah as I said in general I think it\u0027s require thinking I I haven\u0027t thought about it and but I actually would look for an abstract version of this at some point in time and this why it is this why even in the experimental design you should foresee that in my opinion how the upgrade parts to standard strike could look like under the possible assumption that the protocol has to change so me I think that\u0027s not a thing that is any specific to accurate ecn like there are a lot of cases where you have the experimental thing and then some things you can\u0027t change anymore or like it wouldn\u0027t work anymore so like the things that we just described in the experiment are things that we can just change without no gate negotiation for example not using change triggered X you just change your fermentation so that\u0027s the questions we have I don\u0027t think that there\u0027s actually an issue here well it\u0027s something on the wire changes some encoding of the bits for example I mean we don\u0027t know how the standard strict would look like it\u0027s an experiment all right so that\u0027s why as I said I think the I don\u0027t understand it I\u0027ve not looked at it I don\u0027t have a solution but as I said I mean at the end of the day I mean this consumes a bit in the header which actually should happen one standard strike at the end of the day so we have to think about the upgrade past in my opinion early and you don\u0027t have to document it it all cost in the document but I think it\u0027s something that you should at least keep in mind so yeah I I mean the response I gave you works fine it\u0027s like a version number the only "
  },
  {
    "startTime": "01:16:51",
    "text": "problem is it relies on the option being there and if you know the standard strike version doesn\u0027t have the option and it only uses the three bits in the header or the middle box and strip them or whatever we can do very little with three bits because we\u0027ve with work you know we\u0027ve used as much as we can out of those three bits and then we can\u0027t be much more you know yeah yeah okay next I think we\u0027re done on the next slide is so yes it\u0027s been implemented in Linux it\u0027s all the open issues that were written into the appendices are now closed with delete people to appendices so we believe we\u0027re ready for luck working during law school I don\u0027t know whether you want your edits done during RFC you know a later stage or whether they want them done before the working group law school but we\u0027ll certainly willing to do them you just submitted just tweaks all right so we have to review it some explain yeah and the after that we will think about how the procedure oh yeah so basically this draft has been submitted in two weeks ago so someone need to review it and before we go to the parking garage score so if anybody want to volunteer for reviewing that would be really great couldn\u0027t I review it in working great law school yeah so I mean this has been around for a while but I think we have seen a lot of reviews over the whole time of the lifetime of the document so there will be additional reviews in the working group last call so let\u0027s just start it and get those views in Praveen Micra I would volunteer to review this and I think this is useful work we have been trying to get easy and deployed on the Internet and this is I think a step in the right direction I had a question on one of the slides where you said about something about hardware offload I\u0027m assuming you\u0027re talking about like full TCP offload to the hardware yeah it\u0027s it\u0027s the point is that the the acts like with DC TCP in fact are triggered by a change you have to send an act when there\u0027s been a change and that has some people have complained that that makes Hardware offload my understanding is that full TCP offload has not really been widely deployed if my understand is correct the other point I would make is this is some of these issues are relevant to LRO as well and it would be nice to call that out in the draft because at least when Windows does LRO we specifically required that when the core point changes you don\u0027t actually group those package together so I think he said it\u0027s relevant and I think attach the word allow like yeah so I think we should make a statement in the draft about that "
  },
  {
    "startTime": "01:19:51",
    "text": "and I would be happy to give you the information on that on how we specify the rules for that for any coalescing engine okay yeah probably thank for or uncaring reviewing thanks so much um video you want to say something yeah me actually went to the offloading case I think that\u0027s mainly aggregation cases where first remark the the offloading case it\u0027s mainly egg aggregation where the Hardware decides to not send out all the eggs which was concerned and that\u0027s like that\u0027s like specialized hardware that is used in like whatever starch networks and stuff not sure if that\u0027s real concerned for like a general purpose implementation don\u0027t I think this stuff to get in mature but we still need to get some reviews and they\u0027re also one of the chair we take no big you know detailed every reviews and after that nobody think about if we can go to fucking River ethical okay is that likely to be between RIT F\u0027s or the next idea book yeah thanks hi Liza go this is not on this draft but it\u0027s more than a general topic of EC and um so we do quick write and Ingemar is actually bleeding a group of people to think about how quick can benefit from easy and information and um I actually carry horford quick than TCP these days so I think if the EC and people wanted to make an impact and wanted to make an impact quickly you should look at quick because it\u0027s going to push a lot of bytes in a very short amount of time you can keep looking at TCP - yeah I\u0027m involved with the quick thing as well yeah for those of you who already involve you already know about the dimensioning for the people might not be involved in it yet and might wanna get involved because I think ping Amar\u0027s team could probably use some some help so quick is incredibly pressed for time that\u0027s why we break off all of these things into little you know design groups that can can work out a proposal for a group and and um if if you want this to go in to be one of quick which will hopefully ship sometime next year it needs to be ready sometime next year which is not necessarily a timeframe that is very um you know normal for the TCP folks Praveen my question is for Lars actually like is this in scope for v1 is this in scope for v1 off quick if nothing is ready right is it\u0027s it\u0027s certainly you know did there\u0027s no point in having a discussion if somebody had a proposal and there was some evidence that it might be useful we can certainly talk about it but without without anything to discuss it won\u0027t be if there is something to discuss it might be just to "
  },
  {
    "startTime": "01:22:54",
    "text": "give some specifics if those people that are interested in what last has just said about adding ACN to quick there\u0027s a forming a design team meeting at four o\u0027clock this afternoon I believe in some room beginning with H and if I can\u0027t remember how I don\u0027t know but anyway if you if you look at the quick mining list and look for any Mars my little tell you okay yeah thank you so much Bob next will be Rock TCP uten are you in meet echo can you hear me Yujin hi guys can you hear yeah I think I can see you yeah and you see mice right yes okay um hi everybody I\u0027m Neutron to present Rock update and this is work with my colleague Neil car well Nandita and we are at Google next slide peace so just a quick recap of what rock is so rocky essentially is a time-based detector in our packet loss compared to the ode to batch ratio we all know about and the best way to describe rock is that conceptually think of that every same packet has a timer has a timeout and this timeout is constantly adjusted by all the recent RTT simply collected from Mac either the practice said before the before you or the Pakistan after you and then basically the time I was set to about an RTT plus a we all during window and if he I can translate that into a new batch ratio is that the reordering window simply becomes zero if you have more than three dewbacks and you can sort of have a sort of a 2-pack special equivalent implementation of rack in that way and the implementation takes care of how you don\u0027t really implement a per pack head timer and that\u0027s really the details that doesn\u0027t need to be ended here but the basic idea is every packet is retransmitted after Artie T plus sum or window some settling time next slide please and the other thing is tail loss probe because we rack you still need some ACK "
  },
  {
    "startTime": "01:25:54",
    "text": "in order to trigger the recovery but sometimes you don\u0027t get yak and the idea of tear loss probe is well if you wait a little bit and you don\u0027t see instead of this long conservative timeout instead of just you know we use window to 1 and then declare everything is lost you send a scout pro packet out after an RTP or two to trigger some information and that information will tell you either okay the pro packet has been delivered and along with other packets or the packet has been lost of course there is always a possibility the pro packet is also lost then then you wait for this for long time out and then you declare everything is gone like the whole in flies come even the scout have said this get killed um and the whole idea is you have this quick timeout just and a little bit of traffic to see what\u0027s going on so you can react quickly and that\u0027s the essential idea of GOP next slide please so quick status update Linux upstream google netflix windows all use rocked EOP by default another one is also quick but currently they all use rock as a sort of additional mechanism to the classic Cubase racial and I\u0027ll talk about how we plan to retire to backs ratio if we can and but before that I\u0027m gonna talk about the major changes IDF nightly how we optimize pass who is very large be DP and also frequent reorderings and we found some you know issues with middle boxes not setting the sequence what next slide please so first thing we found the large PDP packs so this is a snapshot grab on taking from google cloud transfer this is our TT second and I\u0027ll attend beach EVPs link and this cloud user is using cubic in that case and you can see that as it\u0027s slow starting getting faster and faster that you start seeing some losses actually quite a few losses so the wine line here is the data line the Green Line is the act line and all this purple stuff is the stack packets that\u0027s getting received and captured on at the TCP dock at the sender then you can see that okay very quickly stars with transmitting packets which are marked as "
  },
  {
    "startTime": "01:28:54",
    "text": "red color but it seems is when transmitting it really slow compared to what he has been sent right that doesn\u0027t quite conform to what cubic is designed because you know our losses if we use the rate or see when by about thirty percent but it\u0027s sending a hell up slower and of course this is being reported and so what happened so I don\u0027t know bdp like this you got about three and one hundred and eighty five megabytes of PDP which translate to about two hundred fifty seven thousand packets in c1 right and we\u0027re talking about even this congestion control working very properly which has a c1 relative we close to the PDP and but the Linux back and wrap processing engine is essentially skinning a link list with some hint pointers which basically he assumes that okay the next tag is usually somewhere close to what my previous tack is in terms of secret space but unhappy losses and especially when you have second-order losses that means you\u0027re retransmitted get lost again then is having issues because he has to reset this hip pointers or the hint point or don\u0027t work that well anyway in the worst case we know is the same vo in and what happened is the CPUs complete saturating by processing this ACK every outcomes skins this humongous queue even with a lot of optimization going in and is simply not able to retransmit fast enough and most of the work he spent is completely kind of duplicated because it\u0027s like okay I have to scale all this since you know large queue thank you but all I found is oh there is a one new packet that needs to be retransmitted so it\u0027s really that bad um and essentially this is not a protocol issue is simply an implementation issue but this doesn\u0027t really happen in most of our things he only happens when the cloud user which is smart enough to use a much higher receiver window because Linux before receive a window is only couple megabytes Oh most of the case you would never see pollinate next slide please so what we did is a religious input from a better data structure back instead of a linked list we changed that to our v3 for all our chemistry improves a lot the other is the word processing needs something more than an R because for rack oh here it is "
  },
  {
    "startTime": "01:31:57",
    "text": "about the time you either you sit attack it or we transmit a packet it\u0027s all about when when what\u0027s the last time so you need to build this that\u0027s sorted by the good news is that is the constant in this list when you transmit a packet take it out front and you stick it to the back and when the packet gets that you simply remove it from the queue because you no longer need to care about it it has been delivered only in case of sacramen I give this list but it happens very well so then for every act accounts rack only needs to look at packet that was before the most recently act packet all right so that\u0027s usually means looking at SRI packet packet it\u0027s really that you in thousand package and one shot happen that often so both some optimization linux really we use the sack processing by a large and feel like BP is now more equal or super logical it\u0027s like so another challenge has with frequency we haven\u0027t seen this in real life network yet probably because we often go past it so this is really a fabricated we just want to stress this how blacks written under very high degree we ordering so here\u0027s a test link was we sort of randomly delay the packets between 15 to 25 million and you can see that using the VBR congestion control and again a lot of sacks and a lot of red nummies we transmit the only difference is that all these retransmits arsonists transmit these are not real so this are just who is recoveries and the reason for that is that the current version of references static we all know which are TTP and in this case the wielding window is just too small right so you get reloading outside of us who "
  },
  {
    "startTime": "01:34:57",
    "text": "just so even the Linux yes implemented this because undo I felt that you can detect buoys recovery it can really help in this case because sure you know Africa we I just think was false though I we good but what happened is after you neighbor this would the very next act cost me again though is they\u0027re probing the Penguins they\u0027re making forward progress all you do is equating that is you know you hit the brake you lose the brake then you hit the brake pedal again and never able to make up it don\u0027t we just make up its per second and the situation will get worse if the RTT gets longer this is not specific to our we can write up key as well and it\u0027s essentially the same problem congestion control is simply not functioning so the next slide on the solution is too difficult we need to make the reorder now the question is how do we know the reordan window is too small or too big and survey I mean we could have used like a time stamp that will help us detect food recovery but we\u0027d use these act because this egg is supported by Linux Mac and also Windows and it has been supported for a very long time for all these three operating systems and so that\u0027s good time is you know most of the receivers that support this we can have property back so what what is these you know that yuck is just you know when you get the squeeze transmission on the receiver you simply tell her the same where I receive this sequence wrench again and please stop sending me this I already got it and the obvious they say in said the weilding corner of the Minotti then for every run that we we see some defects that means okay you have we transmit something then we just sort of progressively increment that until who SRT and we don\u0027t want to make a wielding window too large because the rack is "
  },
  {
    "startTime": "01:37:59",
    "text": "really designed to do is sort of reorderings an RTT so that\u0027s why we so then we will keep you always want to how do we discover that and now that we Alden widow is too large right and the simple this way we can sink off is okay after some a high volume 60s is that free recovers then we initialize the reordering window and then you try okay and we think that\u0027s sort of acceptable and really the intention is to cannot keep make the algorithm too complicated and just and here is the exact same dish you know this new adaptive we are the window algorithm and you can see that usually if you have such belief in transmissions and but eventually the rack wielding widow will you know get big enough so you start making those mistakes of you still get a lot of facts because you\u0027re doing is you\u0027re happening but the real damn window now is big enough to prevent you from doing that and if I can extend this really zoom on I love this grab you see that after a while he will repeat this process because it has reset reordering window and then of course you but I think a balance between keeping it simple and getting a little bit performance penalty once a while a question could be that okay so we have this reordering window based on tea sack why don\u0027t you just make sure that we ordering three correctly your time the problem is that it adds quite a bit of state because in Linux when a packet is that it\u0027s true to a previous packet that\u0027s also exact in order to keep the manual and to speed up all this because step blocks are and this make the time in the sack blocks are quite complicated if you need to track ok for the tumour stacks what\u0027s sort of your time of individual the individual that gets there so that\u0027s why we describe next slide please so now we "
  },
  {
    "startTime": "01:41:00",
    "text": "have to deal with middle boxes that\u0027s as we reported on the Linux development they people are funny are mighty she is not making any progress and that\u0027s the time it keeps sending LP pros but nothing is liver or anything essentially the connection just hints so what happened the middle boxes we wrote the TCP header sequences but he forked so what and connection is t.o.p is the arm the timer and that solicited that has white header sequence but the wrong or invalid stack sequences and as a result t.o.p wasn\u0027t really able to pass it because it\u0027s considered and duvall attack so he army the time and then I think the selling in the foil so we often do some medications just to make sure that if you are MCD Valley sack really you have to break this piece and that kind of works out it\u0027s not a complicated change but what happens in real life even when you are doing all this probes is it supposed to ask a question sure yeah what was invalid is it just random numbers in the sequence space yeah so in the in it\u0027s not Rendon lumber so essentially these middle boxes is applying an offset that he kept or whatever we say to the sequences yeah but he doesn\u0027t do that for the sack so you can\u0027t see the sack sequence here because it\u0027s all just you know offset by some random number that middle boxes do next slide please well sack is so new you couldn\u0027t possibly expect a middle box vendor to have heard of it okay so next step I think our vision is really make TCP resilient to reordering certain degree of reordering and trying to keep the last recovery simple by using the time information I think this enables some ideas like flow LEDs or fast forwarding like you don\u0027t need to keep reordering buffer that much in the in the routers and our really the next working item is "
  },
  {
    "startTime": "01:44:01",
    "text": "to say Kimbrough EOP the stand-alone recovery mechanism and without using this to back threshold so that\u0027s what we are working on and doing experiment to say if I don\u0027t use the tube a threshold I and to trigger fast recovery to virally we seek any performance energy because intuitively you will have performance right after three acts fast recovery starts and you are saying that okay we have to wait a corner of an RTT so but even if we have to use the do pass ratio it\u0027s as we trivial to implement in rack because all you do is you introduce a conditional test to say if I receive through backs that the wielding window to zero bouncing but this is something we are experimenting and we hope findings in will have more data about it and for the next thing I really old the community is to update the expired draft this is all just in the presentation nothing this update is in the drive and I try my best to do that you know this months okay that\u0027s all for my presentation happy to take questions question Praveen Microsoft so you said that the reordering problem was theoretical I\u0027m I wonder if you have any data showing watch the you know highest reordering degree you have seen in practice I understand the need to make it more resilient but my understanding is that we go out of our way to make sure that TCP packets don\u0027t get reordered in the network using ecmp and making sure you know using RSS that we process all the packets on one core so we actually try very hard to minimize reordering so I\u0027m wondering you know is that data showing that this is a real problem yeah great question so on all the tests on all the connection that in looking it seems a 1/4 of RTD is released sufficient and even the the key is really they say for most of the cases the reordering is caused by narrow forwarding and these are like in the links are very similar a delays come but we start seeing a problem if people are trying crazy idea like a packet spray okay I want to spray across all the 27 links I have available from A to B and we are going to be in this case around a quarter of our tea tea so and that trigger has to say okay we need to "
  },
  {
    "startTime": "01:47:03",
    "text": "prepare for this kind of cases but right now the short answer is I haven\u0027t seen reordering that\u0027s that Karate tea cannot handle well yeah okay thank you the other question was so replacing rack rack TLV as the only loss recovery mechanism what are your you know is there any data showing how it works on really low latency links like you know tens of microseconds so yeah I mean the problem here is that fine grained timers are a problem so I was wondering how we would not have you would completely get rid of you know dope yeah I think there\u0027s also a question I think here in Linux particular the Google version of the Linux we have some of the last story of high resolution timer microsecond timers so that\u0027s fairly sufficient for a data center even you\u0027re talking about 10 micro second audio the real challenge will come from first the operating system cannot support this find current timers they say is still using millisecond time stamps then redo back this has its advantage so but I think in also the day Arsenal cases with assuming powerful servers rack is in my Sarah in my mind probably is just as fine sa the RTD is 10 micro second this code go to the extreme in microsecond are fast retransmit we\u0027ll start about you know with current setting two point five millisecond two point five microsecond and it\u0027s all triggered by acts right so we don\u0027t really require a high resolution timer in that case and I would consider that\u0027s almost as good as most of the facts ratio which will trigger probably at zero microsecond but the case of that it\u0027s more concerning on much longer altitude links let\u0027s say one second RTT not that uncommon right then rack would trigger after 250 milliseconds while Dewback might take three millisecond to trigger so none of those cases Rock could indeed be slow and then we might have to change with how the wielding window it\u0027s all about how you set the wheel right and I don\u0027t see this is like rockin really advanced just be smarter about the reordering window I think we "
  },
  {
    "startTime": "01:50:03",
    "text": "can we can deliver that and the obvious and change is simple it\u0027s all about just changing the wielding window instead of having all this different heuristic of how many backs do we really need to count for that yeah my only feedback would be that the packet based detection is actually not that complicated so having either it has a complementary solution is actually not that bad I had another question another question on one of the earlier slides maybe it was slide number two or three further back I think yeah 70% of losses recovered by our timeouts can you please clarify that okay um yeah so essentially on google.com a lot of transactions or you can say HTTP response is really just one packet there is not much you can do with one packet in rack we will send yo P after the TLP timeout but it still again it\u0027s a timeout and that\u0027s why you can say basically it\u0027s probably 70% of the HTTP response are just or this single packet stuff yeah and that\u0027s really the reason yeah boy Advent I have also seen similar similar numbers from other other server territories meap\u0027s from which you can see see see what what is the actual reason why the Linux recovery was any little stack was it when initiating the recovery and it\u0027s also also seems seems to occur on other people\u0027s servers so so this is quite typical number actually this roughly 70% of the recovers first indication about about that there is some problem missed an RTO timer expiring so are using the reason we have this high percentage of timeout based losses is there some bug in Linux stack or it\u0027s not just that problem it\u0027s just that you you lose lose or they telltale of your window so so and there is nothing new to transmit so so basically when you when you when you don\u0027t have anything anything more to send you and the polarize into this condition that if there if the tail is tail is lost lost and it seems to be this 70 percent is quite quite close to the number that typical servers get good yes I agree I have to admit that I think that\u0027s why I "
  },
  {
    "startTime": "01:53:06",
    "text": "literally copied it from the people I which is copy from people slides and that lumber may be outdated it could be happening this could be a lumber I coded for HTTP to was actually coid very largely though and vb2 does change that lumber I\u0027d lower that lumber quite a bit because he tend to use his one connection and of course the per connection volume and it does all this pipeline suck right so it\u0027s a lot less it\u0027s sort of one packet RPC chance now I would be happy to update that lumber well but HTTP to does help this case a lot he might want some as regards to this oddity divided Bob for sort of a reordering window and sort of a if you look at the foggy technology with the dual connectivity sort of pinch functions where you can switch to packet transport between a millimeter wave and another frequency bands and then you can you can expect to I will get the reordering depth larger than a quarter or TT I don\u0027t tell if I don\u0027t have the real numbers but they\u0027re obviously a good addition to language TCP and now the TTP of reversion to be able to have to cope with a larger reordering window yeah so I think depends on the network it\u0027s a little bit like iw said it\u0027s definitely one size fits all but you also have to pick and I hope that it will be experimenting with some other value but you know about an eighth or so and I was thinking even stuff like ok you could have a per route we open window to say okay if on this particular guatrau you are really sure I want to accommodate her we ordering more aggressive about weeks I said I could have come bigger it could be an option also in just for the notes how much sort of reordering did you say I was typing when you said how how much eesh I\u0027m afraid to say yeah anything any number at all yeah I don\u0027t I can\u0027t say it right now sure oh now recorded it and I couldn\u0027t understand what number you said give it a toss see some number okay any more question okay thank you now we are working on the individual draft presentation also know "
  },
  {
    "startTime": "01:56:20",
    "text": "so parcel on you again so okay here better okay so Marcelo and you\u0027ll again so I\u0027m here to present this new draft that we submitted about how to I mean about increasing the maximum window size that can be reached with TCP next slide please so as of today the maximum window that the Center can use to send data is determined by the receiver window field in the TCP main header and the window scale option actually the maximum window is reach when the window scale option is set to the maximum allowed which is 14 which results in roughly a gigabyte of data in the in the sender window and that essentially imposes an upper bound to the maximum speed that TCP can send right so a simple example here if you are round to town of 10 milliseconds and a maximum the maximum speed that you have available will be something like 8080 here a bit and the rise technology with a hundred gig already of course we\u0027re talking about a single connection but nevertheless we are in the orders of reaching that limit next slide so doubling the maximum window possible is is easy right because actually today there is an unnecessarily restriction of having the maximum window scale value of 14 the original motivation for that is they wanted to be able to distinguish the old and the new packet so that basically allowed a maximum window of a fourth of the total win sequel TCP sequence number space well you actually what you need is only to detect whether it is the packet is in the window or apps out the window so basically you could actually easily increase to a double of this isoh allowing a value of 15 in the window scale option would be would be okay right and that will allow you to essentially double the value that you have so far so we proposed this I mean a few a year ago or something like that right and the feedback basically was well if you if you if you if you consider this is a problem actually doubling will actually fix will buy you a bit of time but not really much so you really should start looking into how to enable larger increase of this right and that\u0027s basically what we did right so we we went to and take a look about how to do to actually increase mark more than this the the tcp maximum connection a window and this is then this is this draft right next slide so if you want to "
  },
  {
    "startTime": "01:59:20",
    "text": "go beyond two to a power of 31 that implies that you need to increase the TCP sequence number space right and because you need to be able to to increase to identify a larger number of packets that that will be in flight okay this will be much more painful than than the previous approach right so this will require additional changes next slide please so ideally basically what I mean the idea for this would be essentially to include in to include a prefix of the sequence number and lock number somehow in the TCP packet right there are essentially two ways you can think about this or either you define a new option and that is what the ref loonie is doing or to repurpose somehow an existing option flux last I got it tell me why this is a stupid idea but sort of if if you had the bit 15 or well sorry once again if so for if if value 15 in the window scale meant multiply all sequence numbers by some factor would that not do what you wanted you can send shorter segments anymore it comes with all kinds of sort of things right but if it just means you don\u0027t multiply everything by 64 no but but the problem is that so the problem is that you have ah the sequence number space is that a the sequence number today 32 bits right so yes a bit above thing is if bit 15 equals 1 or valium me is 15 means it\u0027s not anymore and you need to carry the sequence number somewhere else no you just will you multiply by console figure that problem is a fundamental you need to identify no no no no no but the thing is you need to identify the white Stuart sure sure I think what Lars is suggesting I\u0027m not agreeing with it but I want to clarify the suggestion the sequence space would no longer be counting bytes you\u0027d be counting chunks of 16 or 256 or 4k but then but then but then you couldn\u0027t write a one byte segment you\u0027d have to have chunks of 4k Yeah right yes that\u0027s another way of doing yes that that\u0027s another way of doing it agree this is not a pi/2 swimming it services its kind of pocketed talks about streaming or something it\u0027s not by stream okay no go back please so no next slide so there is a slide in the middle that you need to stop in there so go back one yes yes so as I was saying is we need to we need to if we want to add "
  },
  {
    "startTime": "02:02:20",
    "text": "this extend the sequence number we need to be able to carry more bit so the sequence number and the way of doing this is either you define a new option that is what treflan is saying or you somehow repurpose an existing one and we thought it would be interesting to explore whether you can repurpose the timescale and and the timescale or the and the and the timestamp option sorry it\u0027s a type of er for this okay next life so why we think that the time stamp option is a is is a is a good is a good candidate for this so the there are two defined use cases for the time stamp one is our TT measurements and the other one is pause if you actually have a larger sequence number space you don\u0027t really need pause right so actually one of the uses of the time stamp option is already subsumed into this this new form right so the only thing that is left is you somehow need to accommodate the other define use that is our that a measurement yes Michael yeah actually referring to what you have further down on the slide but the time stamp option is one of the options that you don\u0027t necessarily need in the soon there was a long discussion on that in the scene yeah the times the options is one that radically you could negotiate after the soon if we don\u0027t have it as of today but it\u0027s not impossible to do that yes okay it\u0027s tricky but it\u0027s one of the candidates where we could get space in this and so we as the arguing that the soon space is crowded and then you were seeing the timestamp option yeah I mean it\u0027s not impossible to discuss that but you could also just push the time stem option out of this one in my opinion and do something new okay um yes well actually my mind okay my argument down is it\u0027s not really relevant to them well yes maybe so one argument for okay so I let me let me state this and then we discuss what you just said so one argument for the for using the the repurposing the timestamp the timestamp option for this is because you have limited number of space in the in the scene right so here I have a short list of different options that usually go in the scene there are there are considered I think useful and the result is that you almost use most of the of the of the available space if you want to additionally add a new option that carries that carries the the the prefix sequence number you probably don\u0027t have enough in order to carry all these existing options and in the new and the new option so what you\u0027re saying is that you you could actually substitute the the time step option by "
  },
  {
    "startTime": "02:05:21",
    "text": "the new option and you don\u0027t really need that maybe possible I guess the problem is that you actually do need that I mean the reason why you actually do need the time step option it is likely that you need the time step function in this type of connections because these type of combinations are likely to send a lot of data so you probably need at least pause if you are unable to get the if you\u0027re unable to get the extended sequence number right that\u0027s the reason why we think that if you actually can embed both meanings in the same in the same in the same option you achieve somehow graceful fallback because you either end up using either post or the extended sequence number that kind of both of them solve the same I mean are in the same direction right I don\u0027t know if that makes sense then the other argument for using an existing option is that there are some measurement that have shown that unknown options are more likely to experience problem than existing options alright so actually reusing an existing option you benefit from the fact that current middleboxes kind of unlikely to be more gentle with them next slide so the main problem that the time step option has is that it\u0027s basically an opaque a sting of off bits that don\u0027t have any kinds of the flags or bits reserved so you need to be able to signal that there is some other place I mean that there is some other meaning in the timestamp option and what we are proposing here is to use the available bits that are left in the window scale option to signal that the time stop option will actually carry additional I mean will be carrying the the sequence number prefix rather than the timestamp the reason why these kind of make sense is because you if you want to benefit from the extended a sequence number you actually need to also include a larger a larger window scale and this basically move would achieve both purposes okay next slide please so the if you repurpose the time stop function to actually carry the the the prefix sequence number the sequence number prefix the problem is how do you manage to still use it for a round-trip time measurements and I here running in the draft I\u0027m not sure it worth going through all of them but in the draft there are several options in ways that you can actually repurpose I mean you can improve both the prefix the sequence number prefix M sometimes sporadically timestamp information yes Mike this is Michael again from the floor so the time "
  },
  {
    "startTime": "02:08:21",
    "text": "stamp option to the best of my knowledge is also used for my monitoring tools to estimate the round-trip time of the TCP connection there\u0027s this is widely used things so that would likely break right that would likely break I mean unless the middle boxes are updated this is not really a middle box it\u0027s just a monitoring system that reads the timestamp of well unless you modify the monitoring system to actually understand which one scary times times and which one don\u0027t which means that you add that monitoring system for example has to see the window scale option in the Sun yes which is pretty difficult if it does sampling if it if it\u0027s if the monitoring system only operates on a sample of the traffic which is pretty common for those monitoring systems it might only see the time stamp option but it might not have seen the soon yes okay so you break that yes in my opinion yes which is I mean this is pretty commonly deployed and it\u0027s it it\u0027s a monitoring system it\u0027s not a middle box that breaks TCP right I guess initiative from flora yeah basically that\u0027s what we try to exploit this is the experimental sea so we try to experiment know how how much impact we have okay so as I said I have in the draft there are several ways you can actually still encode RTT a time some information in order to still - still measuring art the rtt I don\u0027t think it\u0027s worthwhile going through all of them just move on so next slide so our next slide actually so in particular there is one that would allow I mean there is essentially two options here either you encode from time to time RTT information I mean times time to measure the RTT information in the options or either you so that basically requires for you to reserve some beats as Flags to indicate whether you have prefix info information I mean sequence summary information or time some information in the option or you actually include both of them all the time right in which case you basically have less bits so this is the option where you in to you you can call both of them all the time right so here you will not with 16 bits for extended prefix sequence for extended sequence number and 15 bits for having a time stance right I mean there is a draft by by Brian and media that actually allows some variable precision encoding of timestamps that would basically tell you allow you to encode original timestamps "
  },
  {
    "startTime": "02:11:23",
    "text": "within 16 bits right so these are kind of options that we have next slide so I guess the first question here is do we actually need to increase the maximum window available right so that I think that\u0027s the best the first question for the working group right the next question is do we need to increase it the double or more to double right and if the answers to both of these questions are yes the question is whether it is this is the right approach or not but I guess we\u0027re still need to figure out whether we need to increase the receive win I mean the the window the maximum will window that it\u0027s that is achievable in a TCP connection that\u0027s the input that I would like to to get from the from the working group at this stage I guess any opinion ah Praveen Microsoft today the receive window I think by default we only grew up to like 16 Meg and we haven\u0027t had like any real customer problems resulting from that so far so one of the options here would be to just run multiple connections when you it\u0027s such a limit in terms of the approach I\u0027m not really sure if this is safely deployable like we have to worry about sack and we have to worry about like Newton\u0027s presentation like middleboxes rewriting sequence numbers so anything that tries to modify and increase the TCP sequence number space I think is a very risky and very difficult change to actually get deployed on the internet safely so that would be my treatment so I I am happy to try to conduct a measurement campaign to try to assess some of these problems I\u0027m happy to do that there are some things that won\u0027t be able to measure like what Michael was saying I mean I I really don\u0027t know if a monitoring system will break I guess what what he saying makes sense I don\u0027t know how widely deployed these are so but but I suddenly can measure McCain campaign can actually find out how much rewriting off of sequence numbers and time stamps are out there so we I mean I think we can get some some of these data I\u0027m happy to try to do that but I guess the I mean the first question is we we actually I mean this makes sense to actually work on this or not um yeah I there again like I\u0027m a bit ambivalent because I really haven\u0027t heard this to be right a real problem so far so 0.1 that this thing I mentioned earlier right at those I mean me think about it and see if that would make it easier the other observation though you know again quick why do it is for TCP quick doesn\u0027t have this problem why do all of this heavy engineering are you a Salesman or no I\u0027m serious I mean the "
  },
  {
    "startTime": "02:14:27",
    "text": "nice thing in quickest this is really easy and it\u0027s already not a problem right so if you have that problem you know before you actually have a TCP before you have worked this out in TCP you just run quick I\u0027m going here um I wonder if quick already has the problem because it presumably messes up the measuring infrastructure we just talked about you can\u0027t measure it so I mean if the thing we\u0027re worried about here is lack of measuring it no but not right that the thing is worried about is that that your window limited and your performance is therefore limited that problem we don\u0027t have in quick whether the measurement infrastructure is messed up I would assume that for UDP they don\u0027t even try to look for time times things like so yeah and and that\u0027s a known problem with quick but but whether or not they can measure does not affect the throughput you\u0027re getting yeah okay I mean this will go on for a while I guess it\u0027s got some type of quick on TCP a lot of regazzi so there\u0027s a snake oh speaking from the individual fewer fewer and so our charter says that we should maintain his EP usability and utility and that also means that we have to think about certain things even if an other protocol that it\u0027s not in scope of this year could meet it as well I think the technical question is this matters really at high speed at probably 4,100 peak and that order of magnitude and the the key question in my opinion bill if that\u0027s if a dead speed for example other protocols will really work because for that you need heavy hardware offloading typically and I think one of the interesting aspects for something in that space is how it interacts with offloading and if the offloading forced some tcp extension is easier to get than the offloading for some other protocol that I don\u0027t understand about and I don\u0027t know that but I think the e and at the end of the day the offloading and they question which is easier to implement in offloading seems to me an important question so I would like to add the comment about quick so quick does have a little bit of a limited reach ability when compared to TCP so in a general statement that you know we don\u0027t need to improve TCP it\u0027s probably not okay if this particular problem I think is is not a real problem because you can always run multiple connections is my opinion but very quick vehicle even I would like to propose a very much easier design so why don\u0027t you just if you use a higher scaling factor in the receiver window why don\u0027t you just also say this "
  },
  {
    "startTime": "02:17:27",
    "text": "implies the scaling window for a sequence number as proposed by us to use some of the of the bits in the window scales as prefix for the sequence number no just say a there is a larger receive window scaling factor announced that also implicitly means that you have to scale the sequence number as proposed by us yes as proposed by Lars okay understood yes Lauren Stuart could we use multipath TCP and essentially strut data across multiple connections as another way of solving this it\u0027s already got 64 which sequence numbers essentially built in I\u0027m not listening what you\u0027re saying I mean I\u0027m not he\u0027s like um could we do this with multipath TCP and essentially striping data across connections given they\u0027ve already essentially about 64 bit sequence numbers at the data sequence layer that\u0027s another possibility okay thank you thanks so much Robbie you hello everyone this is a series of talks I\u0027ve been doing in TCP I\u0027m just to keep the community updated with what\u0027s going on in the Windows TCP implementation is this better so this is a series of talks I\u0027ve been doing on to inform the community on what\u0027s happening with Windows TCP next slide please so this is a quick recap so from the Chicago IETF where we basically we just had enabled TCP fast open by default in the edge browser in the creators update of Windows 10 we had experimental support for Kubik rack in tier be enabled for connections which have greater than 10 millisecond initial handshake RTT and let bat plus plus was being used for internal workloads in case you missed ICC RG I would recommend that you catch upon the light Pat left us details so newer deployment updates so fall creator\u0027s update is rolling out right now and service 2016 has an update as well which is available for download and these are the updates that I\u0027m going to be talking about today thanks slightly so yeah so we turned on TF o in the creator\u0027s update and turns out that our fallback algorithm was not good enough so the failure modes actually ended up impacting user experience and these are some of the verbatim user feedback we started getting from different geographies so this wasn\u0027t limited to like a particular network this was actually very widespread and you know there were cases where the user would turn off faster one and the issue would persist that slide please so essentially we had to roll it "
  },
  {
    "startTime": "02:20:31",
    "text": "back so we had to roll it back on retail bills then we decided that the only way to kind of make forward progress is to kind of build our own middle box which interferes with TFO and we call it TF no these are some of the things it does so it drops all tier 4 segments it can strips and data drops in segments with data black hole the connections after they\u0027re established do some filtering based on source and destination IP these are basically all kinds of you know test cases that so other implementers might find useful for testing their own fallback algorithms which is why I listed it here so and then we worked on improving our fallback algorithm which would pass all of these test cases and you know preserve user experience for for the browser can you go to the next slide please so the algorithm that we decided to go for is passive probing so essentially we we do not want to do active probing so we are still using user traffic to do this but we want to be as conservative as possible so what we essentially do is the one thing to realize is that to fully determine whether TFO works on a given network you need multiple connections to the same server because you know the first connection to the server would would get you the cookie but actually access is the key cookie you need to go to the same server again but we did not want to actually open the floodgates when the user starts browsing so essentially what we do is we only allow one probe connection at a time to proceed on a particular network so when you connect to a network initially we would start probing but then we would not let multiple connections start probing TFO simultaneously a given probe connection whenever it\u0027s closed we look at whether there was no recert in response to the syn there was no send timeout no full connection timeout data was exchanged in both directions the connection wasn\u0027t cancelled by the upper layer and there was no certainly RTT increase so essentially if all of the following hold it means that the connection succeeded but remember that we needed multiple connections so the the the state machine actually progresses towards whether we just caught the cookie or actually exercise the cookie once a probe connection actually succeeds succeeds in exercising the cookie which means it used data in the syn packet and none of these bad things happened we declared the network as successful for Tier four if our network hits fall back for any of these reasons we persistent and we never attempt Tia for again until the next operating system update which means you know every six months this state would get reset and we will start probing again if a networks hit success then we stop the probing process and basically for the entire boot session we would just remember that if it works on this network again this is us being conservative that we don\u0027t have persist in this information so if "
  },
  {
    "startTime": "02:23:32",
    "text": "the network for example added a metal box later which you know caused problems we would still be able to back off so the good news is that so fall creators update is actually rolling out worldwide right now it\u0027s been rolling out for about a month and this is the first retail release where we have successfully shipped efo and not had to roll back which kind of demonstrates that this fallback algorithm is very effective question under the clarification question general inger what data do you send in the in the in these connections these are actually not so these probes are using user traffic so they\u0027re not active probes so it\u0027s basically the edge browser for example going to google.com so you know if you go to google.com twice essentially those would you know two of those question connections will end up acting as the probes so I see so when you say multiple connections they\u0027re on multiple simultaneous connections so yes you\u0027re choosing some connections arbitrary perhaps yes but it\u0027s basically one connection in ordered by time so essentially it\u0027s like a semaphore so only one connection is acting as a probe at a time and the advantage of doing that is that if there\u0027s a real problem we don\u0027t sacrifice too many active browser sessions for being so determine that TFO works cool Thank You Stuart Appl your third bullet from the bottom you talk about if a network hits fallback so when you say a network is that the local link like the Starbucks hotspot is one network and my home Wi-Fi is another network yeah so we have a network identification scheme and windows so for example you could use the default gateways MAC address there is a way to determine that the network is unique so even if the interface is the same when you connect to a new network we are able to identify that it is a new network okay that\u0027s what I thought so what happens if there is a particular website that I access which is behind some kind of simple-minded effective firewall that breaks all TFO so that gives the appearance that TFO is broken for me on 100% of the networks I visit but only for that one site that\u0027s got the defective intrusion detection system in front of it that is correct so in that case yeah the assumption here is that the problem is closer to the user rather than closer to the server and the goal here was not to be increased coverage of TFO but was rather to unblock deployment which is this is the first time we are able to you know do it without having to roll back so be as conservative as possible and start out small and kind of improve coverage over time two more slides yeah next light please this is some preliminary data again because this algorithm is extremely conservative at this point we find that around 26% of devices successfully used "
  },
  {
    "startTime": "02:26:32",
    "text": "TFO and do not fall back one of the problems that we have the current algorithm is that if you notice a sin timeout it actually results in fall back which could we do to bad connectivity so we and because we don\u0027t persist success it\u0027s possible that over time the number of devices actually reduces because now you could have a device that succeeded on tier 4 reboots and then next time it\u0027s a sin timeout for bad Network conditions and actually turns of tier 4 so this is the preliminary number it\u0027s possible that over time this number may change for the worse we did an a/b test as targeting a retail population with TFO on and off one of the success criteria for us was that there should be no measurable increase in page navigation failures and that turned out to be true which means the algorithm is actually working as as designed the failures that we are finding are correlated with geography so we certainly find that there are certain countries where TR for success rates are very poor we also find that they\u0027re correlated with specific networks so there are certain networks were you know TFO again the data here is I cannot present here but if you have any more questions about that I\u0027d be happy to answer offline yeah as I said the same time out heuristic right now makes this algorithm extremely aggressive in terms of falling back so one of the future improvements we\u0027re looking at is only fall back if you know on the subsequent scene retry we essentially remove the option so fall back only if the subsequent syn actually succeeds which would be the case where it\u0027s not really a network connectivity problem I wish we had made this improvement in the current release but we\u0027ll have to wait about six months to get this data the other thing we are looking at as we are removing some of these criteria and see what happens in like an a/b test and of course we would also want to work with all of the networks where we are finding these problems to kind of improve the success rates over time next slide please so this is a basically breakdown of kind of failures that we\u0027re seeing the black one doesn\u0027t show Creely where it\u0027s actually a reset in response to sin so if you notice the same timeout is the bulk of the thing here and and that\u0027s likely because of networks that are you know poor connectivity so I was like one point I missed earlier in the slide was that we only do this probing on a networks that are determined to be connected to the Internet so that is done by an active probe and which determines that our network is Internet connected so same time out after that means that the network is actually you know has choppy connectivity it\u0027s not like we are doing this without determining first that the network is actually connected to the Internet do you have a question sure so I\u0027m one of your previous slides oh it\u0027s our iPad McManus with a firefox and the one before this there you go we talked about full date a time out I\u0027m curious if you can talk a little bit more about what what that is in the role "
  },
  {
    "startTime": "02:29:33",
    "text": "it plays so we\u0027ve spent a bunch of effort trying to enable this feature and the the good news is we actually see I think a somewhat higher number than you you report on the next slide of people who successfully use it and it has a good impact and we have a lot of mitigation strategies to to the point where we\u0027re currently deployed they reside mostly in the things you\u0027re talking about here you know resuts sins timing out no data being exchanged so on and so forth the one case that\u0027s killing us though is the combination of TFO successfully negotiated and TLS 1.3 seems to have a very high error rate in some environments and that that error rate is unfortunately not in any of these handshake scenarios like application data records flow for actually like several seconds and then just like no data it\u0027s in it\u0027s infuriating suggestions you have about what you can do about that other than you know a timeout strategy which has tons and tons of false negatives right oh yeah so I can explain the full data timeout is basically not the same time also essentially you send data and then you hit retransmission timeouts and you could not recover so you basically essentially the the middle box black hole the connection completely so that would be the full data I want case your point over TLS one three we don\u0027t have experience because we haven\u0027t actually turned TLS 1.3 on on in any of these experiments so right now experimentation is limited to TFO and we are not experimenting with either TLS 1.3 or ECM so yeah I don\u0027t have a good answer to that where did fall there is a China show up in your percentage graph if your rate of errors can you please go to the next time one more actually turned that we the the timeout is that case so it\u0027s it\u0027s after the same time um so there are a lot of cases where we are again this could be due to bad network conditions it might not really be due to T fo Jenna Inger so how does this so first thank you for doing this it\u0027s it and bring the data to data here this is absolutely is very very useful continuing along the thread that Patrick just started here I think it would be useful to have some baseline numbers obviously doing a/b comparison but the number of remotes is part of the total failures but it\u0027s not clear how much of this is due to network error that could that would affect other connections as well so normalizing this by that and showing if it error rates go up might be a good way of looking and seeing if PFOS in ordinarily being hit by this I think this there\u0027s a different kind of error also that I heard from I believe it was Apple that encountered some other errors also there was similar that would have caused it to look like a full data timeout after the handshake was completed so I think the the full data "
  },
  {
    "startTime": "02:32:33",
    "text": "timeout after a handshake is completed is actually a particular pathology that we may want to look at more carefully sure yeah good feedback we\u0027ll work on getting those numbers can you go to the next slide yes I\u0027ll rush through them so quickly an update on cubic so we did find that compound TCP is actually very sensitive to delay fluctuations we find that especially in data centers with virtual networking that there\u0027s a bimodal latency distribution to which compound PCP reacts very badly so we are switching to cubic default that\u0027s already you know shipped in both the client operating system for all connections and for the server operating system one high latency connections next slide please next slide just a marginal improvement for client upload connections not really much to say here because most of the client connections are not really like high bdp you know large condition window connections next slide this just demonstrates one of the problems for C TCP we hit losses going from one region to other is a high latency link with lot of losses and CDs B sometimes gets into the state Wade doesn\u0027t ramp up because it finds that the latency has increased a lot maximum cubic on the other hand is able to successfully ramp up regardless of you know variations and essentially end-to-end latency so this is just demonstrates that cubic is kind of working better for our service in areas overall performance wise next time any other questions steel chair sure Apple just wanted to echo what Jonna said thank you for doing this I take the point you made earlier that at this stage is not important to use TFO in every place that it\u0027s possible it\u0027s important to be able to use it safely and not have the customers worry about that and if we can get 90% then then that clears the cobwebs from the internet and then we can fight for the next 10% by fixing this broken middle boxes so I think this is great direction thank you yeah thank you wrapping session okay see you in London "
  }
]