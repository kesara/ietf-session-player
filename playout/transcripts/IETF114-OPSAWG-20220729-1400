[
  {
    "startTime": "00:00:14",
    "text": "to escape okay please excuse me my my rough voice this morning welcome to the friday first session in the morning ietf114 this is the opsah working group welcome everybody my name is hank i'm one of the coaches next to me it's joe probably you know each other our third co-chair is online and with us and uh i want to remind everybody this is the itf so everything is being recorded so didn't care there's something about this called the notebelt probably everybody of you is uh pretty aware of this right now i just wanted to highlight that uh be nice to each other so we're talking about tech stuff and i don't think that has to be personal so uh a quick reminder about that otherwise if you haven't read the note well there are a lot of links in here click them um we have a few tips how to do this you see a qr code on that side if you never use that before gives you a voting tool or a queue tool um so if you don't want to have a whole meet echo experience just want to raise your hand to get to the queue everybody in the room must follow that otherwise it's unfair to the remote participants who would raise their hand earlier that's relatively simple um you can also do this on the meat echo through the website the icons are not always really self-explanatory that's why we have a explanatory icon here on this slide that shows you that the left one is the full tool and the cell phone one is the on-site tool you can just raise"
  },
  {
    "startTime": "00:02:02",
    "text": "your hand so we have also a basic guide about all of this that's the second link for preparations probably too late to a look at that but if you have issues with anything here please click on the last link on the slide and help us improve we decode as i already said we are just the upside chairs um do we have a scribe yet rob wilton has generously agreed to be scribe i'm going to try to back them up where i can if anyone else would like to help we use hedge stock now one of those buttons in the agenda is it looks like a notepad and if you mouse over it says notepad if you click on that you will go to the hedge dock and you can click edit and you'll see there's an agenda point for everything we're going to discuss and if you would like to fill in or help fill in notes that would be fantastic that's odd okay is this any better sorry okay so i i guess i have to be really close um uh so yes we use hedgedock click on the link in the uh in the agenda log in with data tracker and you'll see the agenda items if you would if you want to please help fill in uh rob and i to fill in the notes uh for this meeting yeah and the media echolink basically is how redundant probably you have found that through the other guidance we already had on the previous slides welcome everybody um this is the status of the working group right now um in the past iteration we were able to get something to rfc great it was a small typo in the beginning of the slides we fixed that yep it's rfc 92 32 or the amenity framework that's actually well done thank you to all contributions and the"
  },
  {
    "startTime": "00:04:00",
    "text": "uh reviews uh enabling that uh we actually have uh two uh items going to isc right now i don't know actually what the status is on there but in progress so that is effectively done and give handed off to the isg um we have a just recently finished last course for when i said that for the assurance work both the architecture and the yang id are passed last call and uh moving on uh will be submitted to isc uh as soon as we are done with the logistics there's an ongoing working group uh adoption call right now uh so if you are ever heard about tacacs and that rings the bell maybe chime into there i think that's the time to have an opinion about that on the list and we also plan a working group last call after this meeting it was a little bit of a timing thing so uh uh uh wait for that uh announcement on list that's also ideas on statement maybe joe you want to talk about that uh yeah liaison statement came in from the itu-t uh concerning concerning telemetry um i encourage people interested in it to uh to read it i still have to digest it myself after this meeting and after the network uh working on the network but uh i will that i think was last week so it's fairly recently that we saw that come in thank you so uh we have um agenda that is also of course visible on the meat echo so we'll not go through any every item we'll just quickly uh show you what's up for today starting with uh adopted work and then related work which to some extent is a"
  },
  {
    "startTime": "00:06:01",
    "text": "report that has been presented in other working groups as well which i like actually this cross presentations and then at the end we will hand over to the 80s to give them their deserved time at the mic actually and uh so uh and if there's time that's all the ultra introduction concern is there and then we will um have remaining time as open mic as usual so going from here real quick any uh a bashing of that agenda or any other business which seems agreement that does not so let's share this and start with a first presentation which is the details for mud hello good morning everyone can you hear me it works fine to me yeah thanks uh i'm thiru i'll be presenting updates to uh mart tls profiles for already with this trap next like this ah this truck is an extension to mod to uh define iot uh tls profile parameters in addition to what the mud specification defines with regard to l3l4 acls and dns basically to help identify a benign flows and block malicious flows which would be using uh malicious dtls profile parameters uh next slide please so so the major updates for this draft has been uh to deal with the behavior of middle boxes especially acting as a tls 1.3 proxy so that it it acts as a compliant als proxy to adhere to the uh uh discussions behavior"
  },
  {
    "startTime": "00:08:02",
    "text": "discussions that have been specified in tls one of the specifications uh we have also updated the graph to address the privacy concerns some of the private sequences that were phrase where uh it's strongly recommended not to act as a tls proxy uh in certain scenarios for instance when the iot device is connected to a well-known service it's exchanging pii data or sensitive data in this case the tls proxy could just do the tls handshake and and not look into the payload inspection or completely bypass doing any handshake inspection or payload inspection on such flows the iot device itself could be configured to uh bypass uh using the proxy server to well-known uh services so that way uh uh for services which have higher reputation you don't act as a proxy but for services which have uh no reputation or unknown services you do act as a property next like this yeah the draft also has been uh if the traffic is relying both on uh the base mod specification and dls so it pretty much requires uh the middle box to have access to the dns uh request responses so uh one of the key requirements is to have the iot device to use the network signal encrypted resolver it could be a dns or https or dns or tls uh that would help the middle boxes to enforce mud policies uh to work for uh discovering these kind of resolvers is already being done in ad working group so we just pointed to the right uh specifications for that uh next like this uh one of the key changes was to deal with encrypted client hello encrypted client hello is a new uh extension for tls 1.3 to encrypt the client hello so that the sensitive uh information like subject the domain name is not visible to for pervasive monitoring"
  },
  {
    "startTime": "00:10:00",
    "text": "the specification goes back into detailing how middle boxes could uh could disable easier so we just pointed to that uh specification how how to deal with encrypted client hello uh there are other ways where uh if the middle box could even start taking the ecs record so that it can start looking into the uh decrypting the inner glide hello so it would see those sensitive domain names uh the other possibility could be to uh strip the ech record so uh if the iot device will basically start disabling uh the use of encrypted client hello but if the client uses uh uh dynastic validation uh uh for it there is a full dns of validation in that case uh uh spoofing the dns responses would not work so that that as we have seen the iot specifications uh with regard to the tls1.3 talking about the concerns with regard to encrypted kind hello that though it increases the privacy of the iot devices it puts an extra burn on the iot device to perform a public key encryption which is which is quite a bit an overhead on iot devices uh it's life is i think that should cover all the comments and the updates that we're planning to do for this trap and we believe it's ready for working group last call and we welcome any comments and positions and i think uh we would like to get uh more reviews from uh security area directorate at iot and other ops reviews review servers so are there any in-room or virtual comments and questions about this work right now um comment from uh medter on chat should dnr be cited for this part of the draft a network designated doh dot server is necessary to allow mud policy enforcement on the local network"
  },
  {
    "startTime": "00:12:03",
    "text": "yes we would we could update the draft to refer to both dnr and radio specifications and we can uh we can start those directorate reviews for you as well that's great thanks uh before we uh uh go on to uh are there first are there any other questions on the dtls mud uh thank you tara thank you um before we go to the next presentation just real quick uh two corrective points um one med raised a point that the working group last call on sane hasn't been formally concluded yet there are some comments to address and that will happen i've added that to the minutes the other thing is the service attachment point the sap work we concluded some issues on that yesterday and i will be submitting to iesg so it's not yet in the isgq but it will be very shortly thanks okay thank you moving on so just uh so which one would you want for first the forwarding path delay or the other one okay good morning everybody there you go thanks um enabling insights in as a okay"
  },
  {
    "startTime": "00:14:05",
    "text": "sure so uh enabling insights in srv6 forwarding plane by adding segment routing dimensions in ipfix i've been introducing this uh in the last itf to ops awg and spring and would like to give a short update next slide please here a small refresher so that it's mainly about exposing the srh information into ipfix and it's related dimensions from the control plane next slide please these are some of the fields we are exposing from the srh mainly the the the segments left that attack the flags field but also from which uh routing protocol the the locator length and the endpoint behavior next slide please uh regarding the exposing the the seedless there are several options uh either by exposing the entire srh section or only the the segment list in a section or actually decomposing that in a so-called ordered basic list next slide please so we received various comments from uh spring and ops awg and i also presented this week that at six man and got some feedback there we addressed all open issues and double checked with diana in the consideration sections and with the ipfix doctors we received some feedback last time regarding compressed sit and address this in the operational considerational section we added the so-called srh segment locator length and srh segment endpoint"
  },
  {
    "startTime": "00:16:02",
    "text": "behavior so with that we are able uh to express how the forwarding is being done in srv6 and on the other hand both elements are needed for doing the compressed sit decomposition we aligned the ipfix entity naming according to rfcc 1712 and updated the flex registry and now the uh the example section is complete and covering also the list section and the srh section next type please so missing srv6 data plane visibility is a recognized problem we have two vendors which validated the technical feasibility and currently working on an implementation the insol university in lino is working on the running open source code in bpp and will be shown at itf 115 hackathon we believe that the document should go progress quickly through itf uh since there are already sov6 deployment and we want to avoid that private enterprise code points are being used therefore we requested that the last idf adoption car that's all for this draft any comments questions well there's at least a comment from the from one chair i think we just tell you uh that there seems to be no big blocker here and yes uh um given the grace period after this uh week after the itf i think we can definitely go into the attempt working group adoption excellent thank you very much not directly related to this thomas but the other ipfix yang work that that rob"
  },
  {
    "startTime": "00:18:02",
    "text": "is now ad sponsoring um have you i we're looking for people um who are working on ipfix related things to cross review and i know rob would appreciate some some reviews of that if you have the time or people working with you on this would also have the time i'm sure it would be appreciated if you could look over that work as well yeah sure thank you of course good so this craft is about extending ipfix that we can export uh also delay matrix uh which is being measured by inband telemetry next slide please so just to give some context from cisco as a network operator so today we have onboarded approximately 3 000 devices in our iphix data collection and we are steadily increasing and by end of the year we expect about 10 000 devices steadily streaming data from the from the network that is about today about 100 000 packets per second which in turn after the aggregation process goes into uh 700 000 apache kafka messages per second and it's being heavily used by engineers doing their verifications in network windows but also in troubleshooting customer incidents next slide please so uh so just to go a little bit back in time so one of the key features from a data engineering perspective in ipfix is aggregation and sampling so with that uh basically the amount of data being exposed can be drastically reduced"
  },
  {
    "startTime": "00:20:00",
    "text": "and therefore allowing us to get a statistical view from the network or also some people call it the so-called connectivity matrix today ipfix measures the packets and pipe counts and give device and control plain context with invent telemetry namely iom power stressing and ifit delay can be measured either actively or passively and matrix can be exposed either on every node which is called postcard or only on the last note which is called passport mode uh ipfix itself uh lacks the ability to export delay today uh which is a key element for so for customer service level agreements and uh invent elementary on the other side lacks stability of uh flow aggregation uh and therefore uh we believe that the scalability is currently drastically limited in invent telemetry with this draft we basically enable the export of delay matrix with iphix and preserve the ability to uh to aggregate next slide please so there's the question on the queue do you want to check it now or yeah let's do it now okay sure and greg is up sorry okay um greg mursky erickson so i have uh one terminology question and one on your statement so uh what in band signifies so i think indian telemetry enables mainly two things one no i'm sorry i probably was not clear on my question so you say in band does that signify that there is some outband telemetry"
  },
  {
    "startTime": "00:22:01",
    "text": "uh i use just in-bench telemetry as a synonym for the different drafts currently at itf which is called iom pulse tracing and high fit uh we had a discussion when the first iam came and yes indeed they use inbent then we agreed that this is misleading and because if we look at so irm is characterized by ippn working group as hybrid oem method that combines passive and active mechanisms and it's not different from active because active to be useful is in band as well so which means that the test packet specially constructed must be uh treated the network and cross the same set of nodes so in fact i can offer probably something for consideration like on path telemetry yes a second is that um you uh um i see that they're saying that uh the telemetry or on path telemetry rocks flow aggregation uh i think that uh for example the alternate marking method is one of the methods on path telemetry that is uh fundamentally based on flow aggregation as you batching uh four packets and then you mark some packets on you which you do uh delay and uh loss measurements and then you export them out of band meaning that outside of the data flow aggregated metrics and at the same time iam direct expert method allows your local policy to do"
  },
  {
    "startTime": "00:24:01",
    "text": "experts on aggregated metrics as well so i think that this is not accurate statement so here uh for the direct export the decomposition of the dimensions are not happening on the node uh why so the draft itself does not require that the transit node that processes iam header and the header instructs it to use direct expert trace option that raw values must be immediately exported the local policy can tell it to aggregate raw metrics and export for example mean value periodically percentile or any other metrics so that's it's an aggregation would you agree um not in the sense that uh the entire basically uh provide a customer data plan is not decomposed so therefore you cannot do aggregation on the node itself right so the draft specifies that basically the entire section is being exported no no no draft that's that's not that's a nice part of the direct expert the red expert does not command how data are exported and what format and what transport is used it could be uh protobuf it could be kafka it could be pigeons and it does not define the local policy how the raw measurement that are generated on a node based on iom header on a data packet that"
  },
  {
    "startTime": "00:26:01",
    "text": "traverse the node how they have to be processed yes you're right they can be immediately or almost immediately export it and actually that's a nice uh another quality of direct export because it allows for more accurate uh transit delay measurement but at the same time this data we can imagine can be uh stored locally and then consecutive data for the same data flow aggregated and some uh secondary performance metrics calculated and though those secondary metrics like i mentioned percentile mean or something then they can be exported so direct iem direct export draft does not dictate how uh their metrics to be processed and exported okay and maybe let's let's go on the list sure thank you sure burn one class so uh greg do you believe there is a problem or not because you know even if you're demetering as you suggested with your draft we still need to have the ipfix information elements in this case do we agree with that yeah again i i i just was about one statement here that uh existing methods do not allow aggregation fair enough okay fine okay and regarding your suggestion about energy i i fully agree there is a distinction between what's in the title which is in ban okay we're going to improve that and the technology within the draft which is taking the iom terminology for the nodes again um i i think that we can agree to use iam as a acronym without opening it especially because we have uh in ippm working group developed alternate marking method which is another interesting on path"
  },
  {
    "startTime": "00:28:01",
    "text": "method so we can combine them as and refer to them as on path telemetry makes sense absolutely good next slide yes yes you have false including this one okay so just to uh give insight how it works so basically packets are captured on the first node ingress with an optional sampler uh the data plane dimensions are extract enriched with device and control plane dimensions and added with a new unique flow id so that aggregation can happen on the node the data patient the data plane dimensions answer which uh which packet while the control plane gives context to the service in the network and the device dimensions tell us basically where in the network now in case of invent telemetry or on path telemetry a time stand and optionally a direct export tag is added to the packet header when entering the the domain each subsequent packet for the same flow increases the byte and packet count and each flow creates a new flow id in the flow cache now in case of england telemetry each node in transit or only at the last node delay is con is calculated by comparing the timestamp in the packet and when the packet is being received on the node and then delay is now additionally besides the packet and pipe count populated into the the flow cache next slide please so this is the entry we're gonna add in the performance reach history so deals are the one-way delay hybrid type one passive registry entries it's about a minimum maximum sum and mean of the delay next slide please"
  },
  {
    "startTime": "00:30:00",
    "text": "in the ipfix entry uh the same entries uh will be populated as well there in micro and in nanoseconds granularity next slide please do you recognize the the problem statement network operators want to understand where delay with which network and device dimensions is being accumulated and that at highest scale for statistical network delay view ipfix entities are defined independently how the dna is being met we have currently two vendors who are validating the technical technical feasibility also showing interest the insa university in lewin is working on a running open source code in vpp and we're going to present that as well at the idf 115 hackathon here a small typo so in the draft version o2 uh we will add also the data records and the template examples and we're looking forward for the review and comments in ops awg and ippm thanks yeah thank you any comments or questions from the room or from the remote or on the chat i didn't think so if the uh this was discussed but basically on terminology maybe latch on to that discussion uh reviews are welcome and i think uh latest at the hackathon we will have some good reasons to adopt but maybe we can do it before pending interest on the list and yeah again if this if you see this terminology discussion latch onto that sure perfect thanks a lot next up is"
  },
  {
    "startTime": "00:32:13",
    "text": "this should be your slide deck this is excellent good one for friday morning so this is combined work between uh thomas from swisscom nacho from upm in madrid diego from telefonica jean and myself from from huawei so it's about data manifest for contextualized data metric data next slide please so what is the end goal whenever we are in a big data lake or in data mesh we want to analyze the data right the thing is that without having the proper context it will be very difficult to find the anomalies in your data as a consequence going to be very difficult to find the closed loop action that you want to do to correct the problem assuming there is one so what we want to do is we want to get the the context and how the data were actually metered and under what circumstances and we want to keep along with the data all the characteristics about data platform so we don't specifically want to push new information via yang we want to define what needs to be kept as metadata and this is what we call the data manifest to make sure that you could still interpret the information the right way if your data sent this at the end of the spectrum if the source is not available we'll still want to have information so we could not always query the router and also if the router was upgraded we still want to get information before and after the upgrade next slide please"
  },
  {
    "startTime": "00:34:00",
    "text": "the example i always give because i deal with networking engineer and was data scientist engineer so if a data scientist is looking at time series database and it's looking at this time series which has just one thing in there a counter which is 42 at time t1 and t1 was yesterday and there is no more entries like right now what should this data scientist conclude first of all you could say well there is an issue with telemetry i'm not receiving anything or you could be telling well the router is too busy and he cannot send anything maybe it's a bug right i could say well there is actually no problem because the cadence that on which we requested telemetry is like every day right or maybe we just configure something which is called unchange unless it changed well don't send me information or maybe a feature called suppressor don't see i mean the router is monitoring i'm telling it's the same i'm not sending it somehow it's the same thing as on change so the end goal is that if we have a data scientist and he's looking at time series without knowing the context on how it was metered there is no way to deduce the right action to do so next slide please so here is a proposal this is a data manifest it's composed of two things all information about the platform so all the information that characterizes the platform placing the data i'm going to come back where it means and on the other side the data collection manifest or information on how and when the telemetry was executed so it's expected that the data manifest will be following you know whenever you go from a router into a collector into"
  },
  {
    "startTime": "00:36:01",
    "text": "kafka into a timesheet database into the analytics it's expected that this context info will just follow the data idd it should be sent directly from the router right in some cases whenever you don't have it on the router it's not yet implemented the collector could combine information and streaming along the data and whenever the data are moved somewhere else we want to keep these metadata this platform manifests this metering manifest along with the data because otherwise you're losing something so the data manifest must follow the connected data all right next slide please oh joe you've got like a question yeah joe clark cisco as a contributor why would you have to stream this all the time with the telemetry i imagine some of this metadata doesn't change and would just add more bulk over time that you don't need i understand why you'd want to keep it there but i'm not clear why you would always have to stream this with the telemetry versus just having a a well understood snapshot that assuming the metadata doesn't change this is a very good point i want to address in the open question and can i just pose a question that will make more sense with some more background but it's uh it's a right question uh i can see that some of us okay okay so on this uh data collection manifest what do we have we've got the information about subscriber id the data store the past the requested period versus the actual period okay i requested micro second gravity well somehow i could only do one second i need to mention that the unchanged as you press don't see fine on next slide please"
  },
  {
    "startTime": "00:38:00",
    "text": "in terms of characterizing the platform we need like a couple of things everything about the platform itself this is like the the vendor the platform id the software version whether it's licensing that limits something in yang and deviations whether it's a feature set or something like that then we ideally want to have the uh list of supported modules along with deviations right because it's link if i've got a tuple which is a vendor a platform an os what you call a flavor it could be license feature set whatever this is actually a fixed set of yangon durian deviation and we want to have as suggested last time maybe there's no young package in there because if you get the package it's somehow a set of young modules so this is the high level stuff uh on next slide what we did there is that we add the revision label coming from the versioning draft right and then there is no grouping in the revision draft that we could reuse with to include that revision right so we had to copy and paste this from the itf young library revision so this is not ideal but anyway we need your information this is the like the biggest important point and now on the next slide uh we did other updates like we said whenever there is like request periods an actual period it's only whenever there is no unchanged sets okay and on the next slide i want to address maybe just one point the one that you brought up joe which is actually uh"
  },
  {
    "startTime": "00:40:00",
    "text": "this bullet point here many ways to identify which young modules are supported by server would a pointer to a specific location be more efficient here is somehow what you mentioned that we said initially want to stream like the context information along you know from the router to the collector time series analytics and all this but in the end maybe we don't need that if you got like a hash id or an id and we say this is at that location that these are the metadata for you know the context for the data in the timesheet database we are good so we're not here to say and i agree with you that streaming this along with the data is not the right way potentially but keeping the pointer on where the data is is potentially the right way and just to conclude on this point is that that's something we see that we've got multiple ways to get those young modules we've got the lighting library we've got query the router we've got the package we've got the yang catalog and we are not here to define new information but need to organize it so that we could have a pointer to that specific set of young modules and deviations for platform os vendor flavor make sense i might give you a better example for that i have a uh yes i'd like i'll hand it back to the queue again okay so hi dan bogdanovich so the question here what is the router and i see use for this work in the case you are an iot controller and you are receiving different types of data from different sensors and you are connecting them so you have the controller that is transport but it has to announce the same different types of data that the controller is connecting to different types of sensors different"
  },
  {
    "startTime": "00:42:02",
    "text": "type of mobility mobile automation devices or fixed automation devices because those physical devices are connected to a controller can have different type of roles depending on the time of the day depending time of an event providing the telemetry update with the roses they are changing using a model like this it is very useful because in this case the iot controller is the router and we have to know what has changed in the role of the end device and that device can give us reliable information on the router what we consider a router that is a little bit different but having it on a iot controller slash router i see this as a as a very useful uh tool to be added to it thank you thank you okay thank you uh greg mursky erickson um yes it's telemetry information correlation is very important and if we go look back in the previous discussion on using iam so iem a native mode of tracing when their telemetry is collected in the same data packet that triggered the telemetry information so the correlation is easier to do comparing that to direct expert of telemetry information that is more challenging so there is another method of collecting telemetry information called hybrid two-step that combines direct export and in-packet tracing"
  },
  {
    "startTime": "00:44:02",
    "text": "because it collects telemetry information using the same encapsulation as a data packet and it happens out of band so not in the same physically could be the same but not necessarily at the same class of service so i think that uh this is very useful uh and that can be used by the node that exports it so it could be an egress of the data flow of their onpath telemetry domain or it could be at the nodes that are directly exporting individually so to simplify the correlation of information at the data collector and yes thank you for bringing this work i think you're hitting the right point it's all about creating data in order to take an action in the end we are this stage in the industry right yeah thomas graph from swisscom regarding one of your open questions should we include encoding i think there are three possibilities either in yang push to uh have the uh to declare that the encoding another possibility would be in the notification header or what you uh basically suggesting here we could also had it in the data manifest from my perspective it makes the most sense to actually include it either in the transport or in the notification header because i think you always should uh explain the upper layer what is the the encoding of the the data of the upper layer very good thank you thomas sure so actually i just addressed one open issue from that slide so thomas you address this one should we"
  },
  {
    "startTime": "00:46:00",
    "text": "include the encoding and i tend to agree with you that maybe we don't want to have this manifest to become like a capability manifest because it relates to different contexts again in this case like what can we do for telemetry encoding absolutely so uh in terms of time alex and of course if you could ask a question on the chat so we identify a couple of open improvements include the source of data somewhere and some level of self-assertiveness you know knowing if it's the the router or the iot or the controller etc is important to to identify it's always a network what is the truth right this is the network is the controller is this uh an nms etc data integrity potentially use the private enterprise number so whenever with the young catalog the string for the vendor i recall the the the reason why doing that right maybe that's something that we want you to improve with the the pen uh some open question do you want to understand alternative values like ip fixing snmp i would say let's try to keep it simple to start with right because otherwise we're going to have something too broad uh how to properly specify device and virtual devices are sourced this was somehow what diane mentioned with iot that's another one handle miss collection and more counters well we could be telling like this telemetry is like as miss collections but we don't want this to be like a pure telemetry monitoring type of young model so maybe it's best to do one thing and to do it right an mdt subscription is a collection of xpaths but nescam subscription is an xml filter what to use as key for substitutional commands and we keep everything open in github so feel free to address also your feedback there and i believe this is the last"
  },
  {
    "startTime": "00:48:01",
    "text": "slide plenty more plenty more let me keep talking five three minutes over so can i just go i think it's the last slide really yeah that's that's the one so basically we're not here to go no no no just the previous one that's the conclusion that's the one the rest is back up the only thing is that i want to understand from this group if there's survive from to work on we got two feedback or three already and and somehow is this like the right place to work on this and if this is then shall we just do it that's the main question so any industry comments from the room all right oh the queue is okay so um i think this is a valid problem at least from the space where i work in and uh it's um if it's a vital for the group i don't know but from my perspective uh i support i see it as a wild problem and i and i support the the adoption of the of the draft so yeah i i recognize the validity of the problem but i'm not quite sorry your name uh alex clan fishery um so uh yeah so i recognize the validity of the problem i'm not quite convinced of the solution approach and one question that i would have since you're busy integrating this with the general subscription um to also push basically the context of metadata why not take your yang model or maybe this is what you're intending to do put this yang model with the context as uh"
  },
  {
    "startTime": "00:50:00",
    "text": "basically instrument this on the device and just subscribe to that have a separate subscription to this would that address the problem we could yeah that's a good solution now here's the thing your router is upgraded right so the contacts change so it means that somehow you want to keep it somewhere else linked to your time series database because you know times your database if the platform change well maybe you solve the bug you introduce a bug you you increase a line card so you anyway ideally you want to export from the device but you anyway to keep it somewhere else but if it's an outside observer the same thing applies still right you could do this there subscribe from from from this yeah sure okay all right yeah and maybe for this topic on the list that's a good discussion for review apparently there's a well final or not final comment but the second time oh yeah final because my name was at the first slide but let me let me remark one thing and it's something that we diane and i was talking as well before is that the is about the problem we're talking we have been talking about whether this data has to be um push every time or can be kept and can be sent once and you and you just store it the important thing is about the data store what you do with another register the data set sorry the data set what you can do with these data sets once it has been consolidated is part of whatever the mechanism you're using afterwards for troubleshooting for auditing for whatever and it's important that you keep this information which is the source of the data apart from the data is where it comes from and this is something i believe and this is why among other things i we started towards this idea i was really happy to see it because it's something that we have been"
  },
  {
    "startTime": "00:52:00",
    "text": "facing a real operational problem okay um just a quick um question through the room um is there any interest in reviewing this because i assume there are these discussions can i see some indication of interest for review can you post it online oh on online on there thank you on the chat of course thank you just one last comment i agree with diego i don't care about the mechanism if we put it in a hash if we're streaming along data i care about the data set itself that's a key thing for me and i would raise my hand there i know so we have 15 healthy hands in the air 16 17. okay you're good so uh if you see a fraction of that on the list i think uh your path to adoption is uh is a good one thank you it's up here right moving on to the next are you in the room or you're online let me check the list these neither well okay so we'll remove that topic then and go with a similar one complimentary yeah let's call it that okay yeah so yeah my name is alex clemso i'm presenting on management and operations for green networking this concerns"
  },
  {
    "startTime": "00:54:00",
    "text": "two drafts actually mainly the first one in the context here this new work with a number of co-authors you can see the names and links here um next slide please so basically this so basically what we are exploring is basically uh opportunities for new work that basically needs to be done and busy in the area of green or sustainable networking obviously this is a big problem of our time right reducing carbon footprint is one of mankind's grand challenges and networking applications are of course a play key role in this and however basically networks themselves are also obviously con contributors to power consumption carbon footprint and so forth so hence the question is what can we do to basically to to reduce these items and we believe actually that there are a couple of items clearly there are many aspects which are outside the scope of idf but the question is basically what are the network management operational factors and suppose that can be and that that can be impacted here even if it's just a small part of the overall pie um next please so yeah i'm very busy a lot of this is actually an operational problem i mean i think there are many examples of this you think of for instance deployment and network optimization where energy usage is a great parameter to optimize just like utilization other cost functions service levels etc there's work on vm and vnf placement where should you place them in optimal ways again you can ask the question where should you place them in ways to optimize the utilization uh efficiency uh same applies to planning of routes segments paths and so forth and with all of these you of course always need to moderate trade-offs because this is not the only parameter that you're concerned with"
  },
  {
    "startTime": "00:56:00",
    "text": "obviously but this trade-off supply second is basically that for a lot of the solutions involved management and management involves fundamentally control loops so on control loops in so basically some versions of a observe oriented side an act type of concept and one part that is fairly common true to all of these is that you require visibility as a common enabler for many of those opportunities and things that you want to optimize next please and so within this well the two drafts basically do two things the first graph maybe just to to explain here for context structures the opportunity space basically what are the challenges and the opportunities in general and we're looking here on the draft basically describes what are the problems chinese opportunities at the device equipment level what things apply at the protocol level at the network level and also the network architecture level next one and perhaps briefly just to mention on the devices equipment level and getting to the point for ops awg is as mentioned a key point is you need to provide visibility into the current energy usage potential energy usage and so forth before you can do anything else pretty much because how else would you be able to assess the efficiency of what you're doing and if things are actually working and how big a problem you're having and so forth and you do need to basically enable these control loops for energy optimization schemes and this requires instrumentation for energy metrics which is the topic of the of the second draft and which is basically uh actually potentially this year well this is one of the items for discussion if this is the right landing spot for this um next one um i think we can well this is perhaps less relevant to the discussion here just very briefly for context in addition to instrumentation and the metrics at the device level and the equipment level there are things that you can also"
  },
  {
    "startTime": "00:58:01",
    "text": "there are challenges opportunities at the level of the protocols at the network and at the level of the overall network architecture if you will and i'll leave it actually for you to look at the draft for the detailed challenges and opportunities so in the interest of time we go perhaps to the next one and this is the one which is of specific relevance perhaps to here or where we would also learn to solicit feedback review comments and so forth and this concerns uh network energy metrics and again well the enabler for sustainability in green management management it's about is visibility there's this famous quote from peter drucker you cannot manage what you cannot measure um well or by extension or that you cannot observe into which you have no visibility and this of course requires instrumentation and instrumentation in terms requires the right metrics so that you know basically what your what the yeah what the visibility is that you're looking for and so this draft goes forward and defines a number basically a starter set of important energy metrics at different levels so for instance well related to equipment to close the path into the network at large um and so basically at the equipment level you have of course items such as well like power consumption and idle at various loads and so forth basic principle then of course the current consumption consumption since restart you can you can have the absolute values versus normalized values relative to the amount of traffic that is being passed and so forth and this is basically kind of like where this may be going is well think young modules what would you basically represent as in this uh yeah obviously as an energy utilization map and or or yang module but this is not part of the draft yet it defines just the metrics you could also"
  },
  {
    "startTime": "01:00:00",
    "text": "put the same type of metrics not just in the yang module but you could fonts and put them into control protocol extensions that were appropriate then related to this not quite yet sorry related we have a few other metrics again described in the draft related to flows where you basically want to where you want to basically increment and basically have the energy over the flow duration edit across the floor path etc so basically this is a another source that we were talking about telemetry earlier telemetry data earlier in the session clearly busy energy related telemetry is another big topic that is actually open and waiting to to be addressed um then related to paths clearly basically if you want to optimize your network there are things such as path energy ratings that you would need to be aware of and then finally basically the end goal is of course what you really want to optimize is the network at large so basically total energy consumption and the network energy efficiency metrics such as megawatt hours per petabyte of production traffic and so forth and these are basically the aggregates by which also network providers would be measured and they need to be optimized also potentially for where regulation kicks in and all of those topics so next one please and yeah so basically the purpose here is to raise awareness of this is a topic um we did post two drafts as a starting point plus trolls draft as a complimentary who who describes the work that has been done in the past at iitf for this topic um we're looking for collaborators and proper landing spot for this for this work and the green network metrics is something that we believe could be of interest to ops awg so i think this is an obvious candidate and this is something that we would like to solicit for this feedback on and otherwise well um yeah"
  },
  {
    "startTime": "01:02:02",
    "text": "please contact us if you have comments questions and so forth so thanks and i see dane has a comment ah hi damn bogdanovic i have so many things against this proposal and i to be honest i don't know where to start so number one this is an area that is so vast and for us to be able to address of that we have to define what do we really want to solve which part of the energy consumption do we want to solve or let's see what would be the requirements that the operators are facing to reduce their energy consumption number two not all energy is the same there can be a surplus of energy in the system that is already being generated that is producing the carbon and being about emitted so it's better to use that energy versus the energy that is coming from renewables but you can store that one uh because it has boiler access to storage so what i see is that we should first find the requirements uh find the requirements on what things the the operators are being asked to meet see how they are we have no idea how the operators are getting their energy sources because they have their own energy sources they are feeding into the system they're getting back out of the system they have battery backups they have diesel generator backups it's a enormous mess that we have more or less reusability visibility because we plug into the"
  },
  {
    "startTime": "01:04:01",
    "text": "we plug our system into the into the plug-in the electricity comes out but we have no semantics what that energy is number two on that one you are trying to decide adding a new semantics to the routing because we will add under the energy semantics into the rounding decisions i heard several semantic semantic routing proposals so are you trying just to define a new semantics that would be taken into the account when you're doing the routing so this is just too much part of my language a hodgepodge of everything which is now very popular to talk to to talk about in the media but i haven't seen anything actual in the in the media or in the publications that i'm following i haven't really seen any actual definitions except very high level oh we have to turn green thank you so to respond to this and i hope i remember the popping the stack if you will on this for one clearly this is a large problem space i agree we cannot tackle everything in here this is really why we're dividing this actually into several things but the the first round is generally framing the thing framing the overall opportunity space but then of course we do need to i agree we need to identify specific aspects specific specific specific problems and use cases and identify also the pieces that you would need for these which you probably which are commonly required and it would appear that having a proper visibility into energy usage into power consumption is a good starting point this is a common denominator pretty much anything will need this i agree with you this is not the only thing that that will be required um but again we don't want to boil the ocean here right i mean"
  },
  {
    "startTime": "01:06:02",
    "text": "if you say sure we can take into account also the energy production the sources how is is that that is all true this makes actually and now actually you're starting to make the problem bigger even bigger um than what was stated here obviously these are things that you could uh add here as well but again you you need to kind of like start uh start at some start at some point and that is essentially if you are the pro and with some of the other items that you said well regarding routing and so forth well i mean these are things to be explored the opportunity space but this does not make a proposal for routing specifically i think you're jumping a little bit at the conclusions here this is basically specifically to start with the metrics that you would require basis for any of these so the biggest consumption energy consumption sources by the operators a radio optical those are you know the two really big ones radiant optical are the systems that are mostly using and then the next thing is come about reliability and redundancy because you are providing real reliability and redundancy and the systems are up and running the radio and the optical part that we're doing at full speed all the time they're very rarely being run at at lower speed because then the variability comes into the question so the question is now what would the operator say can we reduce the redundancy in our network to meet the lower energy consumption and i think you're dropping a little bit at conclusions here um i i agree that all of these things you you need to consider them and you of course you don't want to do you don't want to have energies uh so at the expense of at the expense of those things at the same time again going to the visibility it may be also"
  },
  {
    "startTime": "01:08:00",
    "text": "interested for provider to see how much it costs you and for depending on the thing are you also having over redundancy or basically if you want to have that that is fine too but again what does this basically what does that uh cost you in terms of this power vision and today you have it's very hard to be even be able to tell to quantify what these things are and this is that's this kind of like this is why uh we believe that this is a good starting point anthony some said liquid um i think it's very important to measure you're totally right i mean we don't know what we don't know this is just a vast area and i think we do have we do have to start somewhere um it's kind of tricky i mean the measurements we've got today are crude at best in terms of and it's because it's more the energy side of things rather than devices um can you slide go back one slide i think um we're talking about metrics her paths and flows i'm a little bit i'm curious to see where this goes because i'm not quite sure how we would even measure this um to be fair but look i'm curious to see how it develops i think the other thing is green is a i'm not going to say it's a buzzword but you know energy is there's there's so many kinds i mean oh we could reduce power consumption at the expense of heat generation and then that's a global warming problem um or noise and then now it's uh you know it's a never-ending cycle but at least i think we need to start measuring at the very least thanks thanks i think it's the remote i just want to say that there are other people working with this problem as well and we'd like to connect with you"
  },
  {
    "startTime": "01:10:01",
    "text": "okay great thank you perfect thank you so warren kumari with no hats um so i think that one of the things we also need to look at with all of this is what are people in the energy sector actually doing and using right like there was some mention of like green but is there a way currently to find out what the current power system is generating the power with like if there's a way to know currently 80 of the power is being generated with coal but in this area it's you know mostly renewable and i think we need to find out also what bits are actually important to power companies right like power factor something that's not mentioned anywhere here at all but that's a massive thing for for sort of what the usage of the power ends up being um and then also just another note not all operators have optics and radios as being their biggest biggest draw right they're different types of operators different types of equipment and so i think this is worth looking at but i think we need to make really sure that we're speaking to people in other areas so we're not like we've got all of this data and like well that's pointless it's not useful to us and also sort of keep in mind that different types of users have different power requirements and sort of flexibility i agree thanks for the comment okay thank you um if there are other um you know um more precise metric scopes uh you want okay continue on the list all right okay thanks so tall has arrived i think i was missing in action yeah somehow um you have a five-minute slot do you want to compliment this here i think if you keep your five minutes that's okay"
  },
  {
    "startTime": "01:12:02",
    "text": "go right um so this slide is meant to complement the work that alex was showing with a look into the past what the itf has done next slide and it's meant to become an individual submission draft to give a summary of what the ietf has done for energy um in its in its history so that we can educate the community ourselves and also the users of the technologies that we've built next slide so um when when we started to look what we've done um it kind of seemed like oh no we have nothing we have done nothing for energy um in the past and oh wait a second wasn't there this you know iot stuff low power networks oh wait a second that's you know lots of different working groups um and when you start going from one point to the next point and oh we did this other stuff and we did that stuff so you come to think of um a little bit how varied and distributed um across time and um technologies the things are that we've done for energy a little bit like this um monty python life of brian uh running joke with what have the romans ever done uh for us um and and it turns out that's exactly a very long list and that kind of a little bit what the document is trying to summarize next slide so what i've been trying to do is not only include what somebody explicitly thought to be related to energy but also what ultimately turned out to be related to energy by being implicitly changing the way that you know society works from for example primarily a non-digital to a digitized experience so all these workflows starting with email group communication http html right replacing things that had been done physically like somebody delivering a mail to email as as maybe one of the first starting points and looking into"
  },
  {
    "startTime": "01:14:00",
    "text": "the whole basics of the internet how it's being built a lot of the aspects like specifically what i would say energy saving through scale right the tcp and internet technologies primarily being something that you can summarize with respect to energy as saving through scale we built one large internet to replace them all a lot of networks and a lot of technology involved in that diffserv inserv we merged voice video data into a single network and in result each of the individual technologies power consumption was reduced because we've just gotten so much more efficient in terms of joule per bit next slide um and of course they're opposites so i mentioned them as well like the crypto mining right so the internet is the enabler of that proof of work use of energy um and there are things like the energy saving versus sustainability what's the difference and so i i started trying to figure out what are actually the metrics the differences um and i think what we're having is a more complicated metrics for what has to be considered good or bad um i think one of the interesting stories that i included is the whole thing about telecollaboration and what we've been trying to beat ourselves up about the fact that well when you travel in the air that um each each bit of carbon you're creating there is worse than when you burn the same amount of carbon on the ground so that's kind of where sustainability becomes more difficult than just looking at the energy consumption and likewise in the way you have other factors that where you know the metrics become more difficult next time okay so then there is this whole wonderful uh world of low power lossy nest network so"
  },
  {
    "startTime": "01:16:02",
    "text": "we have a lot of working groups giving overview of what those working groups are doing that had already been done a little bit in before in prior rfcs constraint node and networks is what fairly much the same area is being called in the higher layer working groups low power guidance working group implementation co-op ace constraint security and so on right so we're trying to really summarize more than what has been done in the past next slide and then of course also looking into specific technologies so my favorite ip multicast of course was meant to save energy has produced uh recently in the iot airspace especially a lot of problems the way that it's often been misapplied sleepy nodes one technology that we've seen trickling up as a driver for various incremental enhancements in protocols to save battery consumption benchmarking finally also looking into the energy production consumption management networks meaning where's the power produced what um of uh the its technologies do they use smart grid being one of the biggest buzzwords that probably everybody knows but i think a lot cooler the synchro phaser networks where within the power production they're really measuring the latency of packets on the power lines to figure out uh how warm the power lines have gotten in summer so that they can continue to keep them operating without brownouts next slide we had a working group energy management snmp-based mibs to allow management including things like power over ethernet but also simply just to get into what alex was saying and looking into metrics to allow yeah doing various workflows based on the consumption and"
  },
  {
    "startTime": "01:18:01",
    "text": "what uh we stopped to do maybe uh 2013-14 power awareness and forwarding routing protocols so i'm listing the things that we started there but then didn't finish and why um which really was driven by well can we reduce the power consumption of um a nationwide network like in india when we do have brownouts and we can't you know afford the same power consumption that we usually do so um sdn of course being one of the new technologies that i think we've developed since then that might come to help to solve these problems easier but ultimately the reliability of the network whether this power consumption is still one of the big challenge we need to resolve if we want to make progress in this next slide okay so um would love to engage with the community please provide feedback if you're interested to help um to become a co-author get in contact with us there is one nice mailing list that i think we could revive to do discussions about this it's called recipe reducing energy consumption with energy product called exploration it's kind of formed around the time uh 10-12 years ago and so maybe uh we can start have good conversations about that on this on that list thank you um bulletin uh this is a contributor or not contributor participant so just some things to consider is also i'd be interested in what the impact of say encryption that we're using a lot more heavily and whether that's increasing um and whether the use of law encryption is sort of driving up energy usage and things like that so i think that would be worth considering the other one that i think is interesting is we've seen a lot more centralization happening both in data centers and um in terms of uh cdn nodes and things like that and it's and those probably uh make reduced amounts of energy but they have other negative effects potentially in terms of uh making the internet more centralized so there's different trade-offs here that would be quite interesting to potentially look at um as an ad a couple other things i want"
  },
  {
    "startTime": "01:20:01",
    "text": "to say is the iab is planning to do some sort of workshop in 2023 related to energy and things and the effect of that network so that's pretty a related area and um one and i and the writing ads met this morning to sort of discuss again this wide area not specifically this draft but this wider area as to whether we should try and do something like a some sort of side meeting maybe to see if there's sort of interest uh but what it is but i do have a concern that this is as other people put out a huge area it's a massive thing and i'm trying to work out exactly what things the itf could do and what's in our scope i think is sort of tricky to see at the moment thank you well then thank you i think our other um cube guest disappeared um the question about which email is to use i would answer with uh go with officer first and we talk about recipe on upside and figure that out my i got mike on okay and there we have the next slide jack and our presenter wonderful you are visible not audible hello i'm not sure if you can hear me ah could you repeat that sorry okay yeah thank you go ahead okay thank you so"
  },
  {
    "startTime": "01:22:00",
    "text": "uh well my name is cyril i'm going to to present uh to talk a bit about my my draft the draft morris iotops issue version zero zero one and it ensure means uh internetwork exposure analyzer utility so next slide please uh well uh with with this dress we are trying to to give one kind of support to to solving one of the problems uh one of these ongoing issues in home iot insecurity which is uh we have many small attacks that targets our exploits uh home iot systems and we still take a long time uh looking in a community with a community review uh to respond to these new vulnerabilities new attacks and only example of this is the murai batman which i mean six years it has been six years six years that we have the source of code we know well uh the attack signature and so on it's a and it's a pretty much easy vulnerability to close and we still have problem to that so next slide please uh the idea of issue is to give support on on speeding up the the response uh process by giving third party support and still giving to the end users to the home networks and still keeping the privacy of the endurance so next slide please so we have this proposal structure where we we can use the signatures of well-known attacks well zero day attacks that we know the signature or some or something like that and to cross this information of the attacks of these signatures with the mud"
  },
  {
    "startTime": "01:24:02",
    "text": "information but from rfc 8520 and we can find potential attack attack paths and also assess the threat of the attack attack paths and how it can can be exploited in our network to then can block that information so the idea here is to have one one security team uh that will keep the signature up to date and share this information with many home iot networks that will use this should block the cross disinformation rate mobile information and then block potential exposures of vulnerabilities next slide please so one of the things that we're proposing besides the the architecture we also propose a new data model for describing the signatures of malwares of attacks of vulnerabilities which is pretty much similar with the mud data model and we use [Music] access control lists to describe malicious traffic instead of describing the the expected traffic of iot systems but we also uh have uh information about uh a kind of the requirements to or something like that i've been at a effective risk so we have on one context information that that say that if i have this traffic this traffic and this this other traffic this is this can become one one risk and then uh we should block it or take pay more attention on that so next slide please and this is the the data model or as i said it's pretty much similar to moderate model uh but we have a few different differences"
  },
  {
    "startTime": "01:26:00",
    "text": "here we have uh four kinds of access control lists the incoming and outgoing outgoing traffic that is related to uh specific attacks as it does attacks as uh infection and so on and also we have uh the possibility of describing traffic that is not related to when one attack uh for example the comment control uh traffic of the mirai botnet which is not exactly one attack but it is still malicious because it's related to the botnet so we have two big morphines here uh we have uh we can list the specific devices that can be attacked for that malware for for new vulnerability and we we have also that that context information comes here in the in the way of uh the critical acl so we are going to describe the the requisites that the requirements for uh one mower can can attack one network can infect new devices in this uh critical acl set and in this case we also augmented the acls data model where each access control entry has one associated risk that we are going to discuss a bit more uh later and uh the access control which has one alert and one uh his threshold that you're going to take into account and the moment of taking the decision of blocking blocking something or new next slide please so this is the basic process and mud can give us one one graph of that represents the network communication in our network this image"
  },
  {
    "startTime": "01:28:00",
    "text": "was to us depicted was adapted from uh from the visualizers too so departing from this information next slide please uh we are going to compare we are going to have two uh analysis phrases so we are going to compare all the edges of the of the communication graph with any one of with all the entries uh in the malicious traffic description file and we are going to compare the source and destination addresses the protocol that comes in sequence the tcp initiator uh in case of transport header uh we are going to compare sourcing this destination and the in case of icmp the type and code of the message so if we have one match between the edges of the graph one edge of the graph and one entry of the excess complementary we have one kind of exposure but after that we still need to to understand if this exposure can become a trap or not so in uh in each device we are going to to check uh and stop the value of of the of the risk of the exposed uh access control entry and check if in the context of one access control list sum of the of the risks goes uh bigger than gets bigger than the the the risk threshold and then the the access control list can represent a risk and after analyzing the device by device access control list by access control list we are going to check if the risky"
  },
  {
    "startTime": "01:30:00",
    "text": "access control list can become a set of critical acls so in this case uh that our attack can become a real threat and then we can take one action that that can be blocking all the attack traffic blocking only did not attack traffic the operation traffic or bending back sorry blocking and blocking any traffic related to that malicious activity and next slide please and then we can have uh one specific communication being blocked and reducing the the possibility of one attack or on or one mower or something like that uh next slide please uh so we have some some next steps so we also want some collaboration so some support or something like that that the community that the working group if someone wants uh support the development of issue so we are still doing some tests to use issue instead of using it as a kind of uh so i forgot all but uh directly blocking the the potential 30 traffic uh to use us as a input filter of one anomaly detection uh algorithm uh and we are uh also thinking about you to give some features in future to give one specific protection to dns systems was there for example that that most of the details uh a lot of plan does mowers or something like that exploits the guinness traffic [Music] to to make some attacks and we also"
  },
  {
    "startTime": "01:32:00",
    "text": "still need to make some real-world tests uh we we had made some laboratory tests but it's not the same thing so that's all for now please feel free to make any comments any question and next slide please thank you very much thank you and there is a sorry already hand up coming to the mic anthony sunset liquid um we've got some experience of this pain point as an isp particularly in the retail business um can you go back to the slide that just kind of went to the communications between the cpe and the and the rest of the solution i think it might have been the first or second slide um i kind of got a couple of questions around this and the first was how are you proposing or intending to deal with communications between the cpe and your controller i think the in the in the central location yeah that's the slide oh well thanks [Music] your voice was a bit uh bad to understand but i think that i got your question but the idea is to have the basic uh this properly is pretty much similar with the working of mod so we are going to have one one https communication with with the server that will serve the malicious traffic description file and well uh this this thing can be configured in the mtd manager uh one on one url and we are going to to make uh many requests uh timely requests to update it into updates uh or for that file so this is pretty much similar to um okay um i just want to point you towards um broadband forum tr69"
  },
  {
    "startTime": "01:34:04",
    "text": "that's the usual protocol for cpe management um and i say that as an isp because then you can push it down rather than wait for the cpu to pull it which in the case of you know vulnerabilities and that kind of thing the delay of waiting for a cpe to kind of go and get asked for an update is can be a long time it's an hour on average you're looking at me with evil eyes one um yeah so i mean that was just my comment and then i'm assuming here in this context home gateway is like your cpe your router that sits in a in a customers you know in a home unit i would be concerned that these devices don't have enough power to do what you're suggesting at least in today's iterations a customer's home router that's doing the nat and the internet and all those things okay i'm sorry i i really could not understand so the home gateway is that are we working on the same assumption that that is the the router that the customer has at home that is doing their normal internet okay i'm not sure if i understood but uh the point here is that well uh in this in this we we started the the issue inside the home gateway but we can think in any kind of applies networks a part of the home battery and we it only makes a"
  },
  {
    "startTime": "01:36:01",
    "text": "sense the rules that the the new definition of allowed communication in the uh appliance outside the whole gateway i'm not sure if this is your question but i can see this kind of possibility yeah no i just wanted to clarify that if that's the the home cpe the router that's providing internet access for your iot devices i just wanted to put it out there that the the compute power of those devices don't tend to be that great especially which is what's deployed in your average home and that's kind of half the problem here um and if it's a separate device there needs to then be that communication process between your cpe and the imxe modules and everything thanks thank you so uh this point is basically we still uh are trying to make some some real world implementation uh but we i i'm going to implement one one one one prototype to run in a raspberry pi or something like that to check and how it is going to work and to make this workflow of computation computer power from the from the cpe uh so rob bilton i just going to ask if you've looked at the dots working group and the ddos protection work that they're doing because some of it i'm not sure it's quite the same as what you're proposing here but it looks like maybe it's related or closely related so it might be worth also it's a bit late this week but then presenting this sort of work to them and see if there's any overlap there i don't know well thank you for your comments i have i have set these breaths actually"
  },
  {
    "startTime": "01:38:00",
    "text": "through the to the dots mailing list but i don't remember to get any comments from there but well i am aware that there's one kind of overlap but i'm trying to i i still did not get any many comments only i can remember now only michael jackson who made made some comments and also suggested me to to send this draft to to the dot's mailing list as well any any version of proposal or any access discussion is pretty much welcome and thank you very much for the comments so in the interest of time make it quick so are you in room can you give me oh yeah yeah this is a great uh hello can you hear me yeah slightly i can yeah so i was saying that uh we have been deploying network security services on home routers this is the next generation home router's capability to provide network security services and on these home routers we see this kind of capability being supplied so we don't see such a problem where we've been shipping such routers for on millions of home routers for multiple isps point of view um float this uh one good comment came from rob maybe this is uh related to dots i think communicating"
  },
  {
    "startTime": "01:40:00",
    "text": "this helps you finding more review more feedback on this but unfortunately we have to continue that talk and discussion on the list because we have 20 minutes left and that's a bit tight so uh before i hand over to the aeds i unfortunately have another tiny topic from the chairs which is our chapel needs more cherries and i wanted to take the opportunity to uh ask for uh everybody to maybe consider taking on this uh actually interesting challenge and uh and if you are not really um sure that sharing is for you you can become a document shepherd that that that's getting you into the mood of it that's that's not the whole thing but it basically moves you through the process and also there are chairs and ladies to help you with shepherding so yeah you're not alone and so whenever there is a call for shepherd from us uh maybe consider that and from there i'm going to uh my dear ads i have one chair and one mic but you can also have my chair i can stand here for a bit so actually thank you the comment on chairs leads nicely to what i was gonna say um i've been doing this a.d job for a while now and my term is up in march i am still having fun and so i will probably run again but i would also really like it if there's some other people who are willing to run so the community has some choice so if anybody's interested in running or finding out more about what the role is actually like what the time investment really is you know anything like that please come along and chat with me um or rob if you'd rather talk to him um and i think we're both happy to explain what it's actually like i mean i'll happily say i'm running again or probably running again because i actually enjoy it and it's fun um there's a bunch of work especially some working groups"
  },
  {
    "startTime": "01:42:00",
    "text": "um but yeah come chat i'll just stand here what are we doing next there's no point in me standing here if chins can also be standings can you just have a quick comment to your statement yes please so uh just to give some additional insights there the itf prefers for an ad to have two terms and then for the third term if there's not a better candidate for if the candidate is still willing to continue so go forward but the itf community encourages other people to step up especially the working group chairs that have done you know the work over a couple of years they've learned the process to become an id and get uh to that process those works are fairly complimentary but they help steer the overall you know community not just the specific area it helps steer the overall community into the right directions because they exchange which problems are being addressed where and as you know we are pretty much a vertical stack that depends in each areas on each other so you can get nominated with somebody else but the best way is if you nominate yourself and you have an experience of working group chair it's a good experience and even applying first time it's a it's a good learning experience because you will be learning a lot how the itf works you will get you know uh familiar with their processes so yeah thank you dan that's all really good points um related to that i've actually been trying to appoint third chairs in many of my working groups just so that you know people can gain some experience what it's like being a chair etc and if you aren't quite ready to consider"
  },
  {
    "startTime": "01:44:02",
    "text": "being a chair at least step up and be a document shepard it's really helpful um you know both to the chairs and the ad but also so that you gain some sort of experience and as an extra set of eyes on the document often working group last calls you know it's really useful to have somebody go through and be like did everybody actually really follow the process was consensus judged correctly blah blah yes hello everyone okay so just before chin starts is there any does everyone have any open mic questions for either one all right if you do come to this mic you know don't see anything okay thank you so uh this is chingu i'm here to talk about the auto introduction so uh actually i labeled me as a network application degreasing evangelist at this time actually i'm a chair of the auto working group and so we make a lot of progress since the last item meeting so this is actually one of the big moment divisions raise awareness of this auto worker so people can take advantage of this so the name we list here are auto design team members and also we are auto problems so we i'm happy to uh on behalf of them to present these topics so auto actually really you know you can use this to you know steal the traffic improve the nano aware application performance next"
  },
  {
    "startTime": "01:46:01",
    "text": "so this is outline for my topic so i want to uh tell people so what auto is and how auto can be used where how it will come from and how they can be involved in the future and and also we have working cool auto working working group actually i will give a quick working goal status update and and then we can wrap up next so what auto is actually auto is a provision of the application layer transport optimization so this is a very old working google actually started from 2008 actually it's a working group in the transport area and originally actually is you know more designed for the peer-to-peer application or content delivery network application and one of the uh typical application uh protocol is a virtual actually it is one typical example of peer-to-peer application can be used to transfer fire and distribute the data but the big problem is when you application doesn't know the network uh status so application we randomly to select route in the network so this may cause long latency or better user performance so that's why you know we introduced the author to address this challenge to use auto not only just improve the network performance but also improve application performance so you can see actually auto protocol get open source in 2012 actually at that time you know many open source like open daylight get very popular and so auto get integrated in this kind of open source project and later actually there's a lot of iep worker to discuss how to integrate with auto so one of what i want to mention is"
  },
  {
    "startTime": "01:48:02",
    "text": "to discuss actually carry auto inflation uh using jose uh data format actually they can tackle some some kind of cross-domain scenarios uh and also in routing areas there's two typical work one is pgps the other one is abnormal application based network optimization so for pgprs actually this has been developed in the rdr working group actually they you can use bgbrs to connect the network topology information and fade into the auto server so auto server can expose the abstract nano information to the client to have a client to make a network traffic steering and uh avalon actually this has been developed in uh this working group actually they discussed how to integrate with pce protocol rtis protocols and we also see actually ping id actually they first focus on pass aware networking actually this is a really boring concept from auto and form a research who would tackle some you know research uh challenges and uh recently actually the there's a lot of auto problems actually they wanna you know uh use auto to tackle some of new use cases like edge computing network function virtualization and uh and and service function chaining such kind of use cases next so this is a uh auto portal overview so you can see uh the auto protocol just the query interface so you have auto client you have auto server so usually auto client can be the host or can be uh some of uh network device in in the network actually you can you know query the network information is kind of abstract information from the auto server so all the servers usually you know co-located with nms or sdn controller so they can interact with"
  },
  {
    "startTime": "01:50:00",
    "text": "various different data sources using bgbls use smp use telemetry use rpfx kind of protocol and also it allows actually server to server communication in a single domain or in multiple domain so you can you just use auto protocol so in server to server communication one server will be see as the client the other server will see as the auto server so next so actually two key component components for auto protocol is one is network abstraction the other one is transport framework so for network abstraction you can you know compare with like net topology you know usually now topology will comprise node link and the termination point the link can be see as a connection between two network node the termination point can be seen as a port for the network node so similar to the the network topology actually uh auto network abstraction also comprises the similar information for example we define a settled entity so the entity can be the endpoints can be uh can be a settled endpoints one example is autonomous system in the bgp domain or it can be the easiest ospf area id and also it can this kind of entity can be the abstract network elements so one example is you can see actually whole data center network uh as a action nano element so some other example like a link or node or port or firewall actually can also be seen as uh abstract nano elements so in addition they actually comprise like a set of paths actually the path will be see as a source detonation pair pairs so for each path they will comprise the basic path property so the typical property is custom"
  },
  {
    "startTime": "01:52:01",
    "text": "metrics so one typical example is a hob count routine cost that you can use this to uh to measure the past performance so some other you know past property may be more complicated like a market cost or canada or pass vector multi-course that means in the http request you you may carry multiple cost metric values and for canada actually you similar to the cost actually you can carry a set of cause the value in an area actually each value in area will cos respond to a specific time interval uh for path vector actually this is a actually uh a work in uh auto working actually they can represent a set of the source destination pair that you know share the same abstract uh network element for example firewall or load balancer and next so you see this figure actually just you know share uh tell you how uh nano objection look like actually you can see we have actually entity actually can be see as uh the the the node actually you can see uh the device uh within the dot circle actually and also between the entity you have some link or paths actually so you can request the network uh map or custom map and also you can uh you know uh represent some calls between two entity or between any two source destination pairs next yeah this is a actually another key com component in auto protocol we call the transport framework actually you can see in the left bottom you have these figures for"
  },
  {
    "startTime": "01:54:01",
    "text": "if you are auto client you need to first know where i can find auto server so usually you will you know rely on the bootstrapping server to tell you where the auto server is located and later actually you if you find the right auto server you need to know how what the information results i i can get from the auto server so uh so auto server can use actually they build the concept they call the information resource directory they can you know advertise information resource as a capability choose all the clients so all clients know how many information results i can get for example you can provide network map or cost mapping this kind of information results to the client so client can take advantage of it and make the decision next so we give some example how all the portal can be used so this first is you know end point cause actually they just so uh assume actually a client send a request to the auto server it will you know ask uh from one source to uh one uh destination uh uh does that what is the cost between these uh between source and destination and so this kind of uh uh message will be carried uh uh by the hdb101 this kind of transport and uh in the response actually i can you know return some the cost for example routine cost actually i can uh provide a list of the rooting costs between source at destination pairs so you can see actually we support a various different performance matrix when we delay or run triple delay or pass variance and uh essentially next so you just have uh four minutes left because then we have a hard stop the slides sure another one is entity property"
  },
  {
    "startTime": "01:56:01",
    "text": "actually we actually use a different uh transport we call the uh server uh service and event incremental update actually this as a new transport so client can you know uh to uh tell the server i want to add a new resource new information results for example property one property two and in response you can see uh so the new result has been added and also you can add further add some uh another two uh two uh two information results for example properties three and probably four next has is the more complicated case actually you uh you know exchange between the client and server you can you know uh really tell you uh the pass information from source to the destination they may trans traverse a set of intermediate node or linker so you can see actually we can express these use any point across the map actually so we have for example net three error one and then one actually this further can be you know represented by the property map tell you the uh the result bandwidth or that bandwidth for for each elements next so this is ongoing work or already published work you can see in green color we already published 14 rfc actually and currently work on we work on the auto om and auto new transporter auto m actually is defined as a young data model that's why we come here because they are here we have a lot of expertise hopefully we can request young doctor review for this auto mom when it is ready uh to to do that auto new transport actually really you know do the transition actually move from http 1.1 to hdb2 so we got a lot of review from other areas so this you can take a"
  },
  {
    "startTime": "01:58:00",
    "text": "look at that actually you can see we in this auto protocol actually we have two key components actually we have transport online we have uh auto uh network abstraction provide uh provide as a network map service or cost map service so you can build on top of this you know introduce more auto product extension next so this auto deployment update actually we uh already have some of deployment actually for example for comcast and ben logs actually the blocks they actually uh integrate uh they are not uh you know they focus on cdn scenario they use the author to uh expose the nano abstract information to the client and they publishers that work in the connex uh conference paper and we also attach it to some new uh deployment actually by auto design team member they focus on some like a specific research platform and and a certain loser yeah this is some future work we uh tackle if you are interested you can feel free to join next so this uh just again actually show unlocks the workout the they their idea is they call uh these can auto tip learn as a flow director so the idea is you can use rooting protocol to get a nano topology information using uh use uh rp fixer to get flow information correlate together and expose them using other portals so this has already been uh published uh also introduced in the iep rtf appliance network research conference next okay yeah take away actually so auto is not a new protocol they focus on query interfaces originally designed for the pwp cdn application now actually they tackle"
  },
  {
    "startTime": "02:00:02",
    "text": "some new uh interface like edge awareness networking or service function training actually the they already find some other new use cases especially from telefonica they you know focus on cdn deployment actually integrated auto and the idea is calling it overly and only so they can uh you know use auto to bring back a more operating experience so and uh so that's all thank you for listening uh thank you very much for bringing here and presenting it so that's great to share that group so i think uh if there's any further questions for anyone doesn't look like it otherwise i think graduate thank you thank you is get"
  },
  {
    "startTime": "02:02:03",
    "text": "consistency"
  }
]
