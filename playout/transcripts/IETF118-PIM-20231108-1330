[
  {
    "startTime": "00:00:14",
    "text": "Can you hear me? Does this sound on Thanks, sir. Welcome to to PIM. We got a very full agenda, so we're gonna try to start right on time here. Hope you all seen that note well. Can you try them. Try them Next slide. Yeah. So the note will hopefully, we're all aware of that. It's the same as usual. Okay. Then the agenda any comments on the agenda? It's very full, at least, There's no comments. Let's move on. So I'll quickly go for the working group status So We published 3 new RFCs since last meeting. That's pretty good. Never done that before, I think. And, Then they got the the biz documents. It's the GMP version, the MLD version 2 and, what's it called? The host, whatever Multicast. Anyway, those those 2 document no. No. Sorry. It's some IANA consideration, IIM updates. But those three documents, we did a loss call on them before, and they didn't get any comments that we wanna do a new working group last call after this meeting and you really want some of you to review them like, a moving IDMP versus 2. Sorry. Version 3 and Emily worsened 2 to standard. So it's kinda important work in the we really want it to be correct and So, Please help us respond to the working group last call Yeah. We really want to get those documents published."
  },
  {
    "startTime": "00:02:05",
    "text": "Apart from that, we got this Doctor documents that we need to figure out what to do with some time not discussing them today. The question Yeah. Yeah. So So so think AI was on me. I'll be updating these two drafts Okay. Yep. Okay. Great. Yep. Okay. Next slide. And then we got, point to points point to multi point policy that we're not discussing today. Think the work is pretty much done. So, hopefully, at can go to last call. Silish, got the policy ping that we'll discuss today Kim Lytle discussed today, This is list extensions draft on one of the call first. We need to do more work on that. And then some more documents that discussed this meeting. But, yeah, we have a lot of working group documents as you can see. Next slide. Yeah. Quick comment on the lessons learned. We were gonna present at this time, but there's not enough time. So There has been a fair amount of, new text into that draft on MOSPF and MSDP So please read it. It's gonna be a draft that we'll be working on for some time. We wanna make it as useful as possible. So Please review it. Yeah. I think there's some people that have said they have might have some text or some contributions to it. Alright. And then yeah, I adopted 5 new documents just the last few weeks. Or last month or 2. So this is the host, what there is called, Twellis can help me, but now it's the host, basically explaining the malts Yeah. IP multicast host stack. So"
  },
  {
    "startTime": "00:04:00",
    "text": "as part of revising, the, you know, with 2, IGP and MLD RVCs and so on. We also wanna revise this one to be up to date. And then they got the, different drafts on the, other configuration and stuff that they have been discussing the last couple meetings, we also adopted Okay. Any questions or comments before we move on to Presentations. Alright. That's good. Going, I think, with the first presentation, and lighten and then the Tulsa Okay. So the beam light, I did some modification based on the Last IETF next to slide, please. So, couple of things that I changed. There was a comment that when it comes to the PMSM. There is no concerns with DR and the RP being in the same, team light domain. So I I removed that text. When it came to the PMA cert, obviously, since there is no hello, they cannot negotiate as shirt, and figure out whether there's duplicate traffic coming from the upper stream. So I did put some text in there that kind of explains that from network design point of view, the operator should kind of make sure that, there is not duplicate traffic coming from the upper stream. With the same token. I did also did the example in there, because this draft was really created when we wanted to do PIM over beer. Him tunneling over beer. So I did put a couple of texts in there that when it comes to pin tunneling over beer,"
  },
  {
    "startTime": "00:06:01",
    "text": "when you try to figure out the the the beer edge router that is closer to the source. And if you figure out that there are 2 be your edge router, then you can actually choose only one of them. Based on the, some kind of IP character. Yeah. Highest IP or lowest IP. Anyway, I guess the longest story short, what I put in the draft right now is that this really implementation kind of thing and hear our our recommendation And when it comes to the vendor, they need to implement it accordingly. Nexus. So the next one, which was the RFC 6559, which is the team over reliable transport. That one was a fun one. Use my imagination. So apparently, right now, when it comes to the TCP, you use the the hello message to actually, send the TCP be because I guess the destination after hello message is multicast. So somehow you need to figure out What is the destination TCP port as well? You need to put that TCP destination port in the hello message or something like that. The hellos are just multicast, PIM PIM message is just then to join Froomes there, TCP Unicas. Okay. Alright. Yeah. Yeah. So, basically, there is this thing called the peer connection ID that needs to be set up through the hello message And again, we need to talk about this. What I put down in the draft now is that since there is no hello message, all these, information, they need to be configured manually under the beam light. I I I don't know if the working group agrees on that or not, but, I mean, I couldn't think of any other way of doing this So you just go under interface and you just say that Here's the connection ID on this side. You go on the other side. You configure the connection ID too."
  },
  {
    "startTime": "00:08:01",
    "text": "And off you go, with with the reliable transport. And if TCP doesn't come up, I said, in the draft, go back to UDP. Those are all the changes that I made. Any comments, any thing that you folks an exercise, sir. Yeah. So that's where we are right now. Comments, questions. What do we need to do next? Yeah. I'll stick here. I'm I think I have I need to go carefully through it, but I think I have probably some some input and I'm I'm, I guess, I'm a co offer too. No. I appreciate it. So I should contribute. Thank you for coming up. Yeah. I appreciate that. Thank you. Sunny's already here. We just started our work on the DF election in your working group. So maybe in PIM, you can use this Or so. Yeah. And that's our algorithm to elect as the DF for multiple, source will advertise the we all stand as the same, multicast as the follow. Flowed. So so It's a DF election in the year. Overlay. So maybe team life can use the algorithm also. But it's just a reference. Okay. But there's some kind of signaling for the for the selection. Like, I I haven't read that draft to be honest on on the beer side, there is some kind of signaling, I guess. Took it at her about it in the Friday meeting. Yeah. Yeah. Just, I I guess one thing we need to keep in mind is that when we wanted to do dim light, we wanted to keep it very, very basic, right, Okay. So that's that's the only caution I'm giving out there that, you know,"
  },
  {
    "startTime": "00:10:00",
    "text": "Yes. We can completely start reinventing the villain coming up with all these new packets that go back and forth to figure out a cert and Doctor and all this other stuff. But but but but that takes away, then might as well use pain. Right? I mean, that that why we wanted to do the beam light to get rid of all this stuff. Just a caution. Let's not make it more complicated than it is. You can just, reference in your draft to provide another opinion for the providers to to the algorithm. So it's just, inform our team. Virus. Yeah. Okay. Thank you. Thank you. It's Greg. Me. Solution tends to track the complexity of the deployments. So I'd say, like, I had this explained to me, like, which is great. Well, you got him on the other edge. It's already around the box. Makes sense to you in pit for messaging across the other side. So I'd say the the, generic DF election mechanism is really targeted for those PIM free environments. We talked about data centers where you know, hosts are actually sourcing things like this where there is no debt. So We're kinda stuck having to do both. And I think maybe even explaining in the documents what the deployment model would be, you know, the motivation for doing this so people kind of track their way along. I mean, that that's good point, the depletion that I know for sure is the beer. There were some other ideas that we can use this in other type of, deployments, which I guess, well, I think it was you yourself, right, let's see. Yeah. Maybe. But, yeah, at least I would say I don't think should talk much about beer in this this document at all. There's other use cases too for doing pin without Okay. The hellos and stuff. I forgot what it was. And then in the beer in beer, right, there is this document for for how to do came over And there, I think it's good to have the motivation about that deployment models and way it's like, yeah, what kind of a good use case is? Okay. So, yeah, maybe we should get together and, you know, clean it up Alvin. Alright. Appreciate it. Thank you."
  },
  {
    "startTime": "00:12:03",
    "text": "That's it on this one if there is no other comments. Okay. Okay. Next slide, please. So I'm just gonna give a little bit of update what's happening in the point to multi point policy. So the replication segment draft, we added SRV 6 to it for past couple of releases, versions, and, so now it includes SRV6. Of There will be implementation of the SRV 6 pretty soon. But that the draft which was the the mother draft for this entire work I believe it's going for RFC now. They did the last call on it. There were some security concerns in there on the security section, but I think everything when smoothly, and it's going for the RFC. So when that one comes out as a RFC, the next one would be the point to multipoint policy. So I get to refresh everybody's memory the replication segment was the multicast state. For the tree seat. And then the policy is the head end policy that you can actually use it as a Pim Z against the next generation MVPN or whatever you want to use it against. So that one is in this working group. I think we added some kind of a SRV 6, text against it as well. We need to talk to the authors, but I think it's in a good shape, and we're probably gonna do a I'll see The next one is a yang. I need to kind of revive that, obviously, this technology is the controller type of technology. Of the Yang is really not something important, but it would be nice to have a yank for CLI. So I'll I will revive that."
  },
  {
    "startTime": "00:14:02",
    "text": "And I think there was a conversation and whether this should come into PIM or issue the same spring I'm not sure what we decided, but, I mean, we need to talk about that. The next one is the overlay just how we're gonna signal the overlay for MVPN. That work is in progress too. I think it's in a good shape as there are implementation of this 3 seat with next generation MVPN out there. The lab next one is the PCE. As I kind of mentioned, this technology is, controller driven Meaning that, on the route, you try to out where the leaves are and you feed all that information to the controller. And then the controller tries to nail down all the rep replication points into the into the data path. The beauty of it, I guess, is the fact that it kind of marries Unicast and multicast, your replication points, they don't need to be back to back, they could be connected via a unicast srv6orsegmentrouting kind of domain. Which is attractive to some of the vendors out there. So, yeah, if you're working on the PCE part of it, Again, we are trying to implement that multiple vendors, and and it should go forward. So the IDR, obviously, there's one way of downloading these replication segments from the controller to the to the routers, via PCE, piece up. There's another way of doing it via BGP. The next step after we are done with the PCE would be GPSR point to multipoint policies. To download these, replication points and last but not least, it's some kind of OEM. I think one thing we need to be very careful about is that point to multipoint policy being is only for MPLS. It was not covering a service."
  },
  {
    "startTime": "00:16:00",
    "text": "We did that just to make sure that it's a simple appeal to swallow, because we were following the LDP and the RSVPT OEM stuff. So we just wanted to, you know, make sure this goes through the working group very quickly, and we can have it standard OEM way of pinging all these leaves, that's why we just focus on OEM. Sorry, on MPLS. The rep the point to multi point policy draft that the PIM as our point to multiple and policy draft that has some text for SRV 6 OEM. Alright. Next slide, please. It's Yeah. Jim. Sorry. a question. State, So, Jim Gee Shot, just a, for your information, the, replication segment, I'll just finish that. It's in the ROC editor queue. Oh, so we're all done on that. And I have the scars. So we had 4 discusses on that document. Yeah. But I I appreciate it. Thank you very much. And that draft is one that we're very dependent upon as far as progressing our related draft, the policy draft, We've always been pointing to that replication segment draft. Reason you added SRV 6 to the our draft is because it was added to the spring draft. Is that correct? That's correct. Yes. And is that significant text? I mean, is it Well, it, it does explain how the SRS should be built, and, you know, the, the way that the SRS should should be manipulated on the PhB routers, and, yeah, there are some text in there. So we, as we're, we really need to review that the the pin draft. Because SRV 6 has been added to that. Well, most of that The heart of it is in the replication segment, But, yeah, there are some examples of the SRV 6, which It's fun. K. Pergan. Okay."
  },
  {
    "startTime": "00:18:05",
    "text": "Okay. So when it comes to OEM, MPLS in cap, Again, we kind of followed the the wheel that was already there for, LDP and RSVPTE. We assigned, a Canada path through I, INAA, for a specifically point to multipoint policy. And, from security perspective, I'm just pointing it back to the RFC AD29 because Literally, it's the same implementation and all we did here is we added a brand new sub TLV for the candidate part, MPLS candidate part, and that was it. That was all next to Slack, please. I guess one thing that I missed in the previous slide is that there is a implementation there, and I put that in the RFC too. We actually implemented it. I don't know what her Cisco did or not, but anyway, there is implementation and Last time, I did send a Email to the MPLS working group to see if they have any comments, nothing came out of it. So I think maybe a last call would be in order to get people at comments or whatever that they need to do. That's all. Okay. So you're asking for a last call for this draft. Yeah. I mean, I think, you know, since I tried a couple of times to get some comments, to see what's going on. You know what? I haven't heard anything whatsoever. So I kinda find it hard to believe that nobody has any funds. Yeah. So she'll do that on the list then maybe. That never happens. Yeah. Yeah. So we need to get better at, you know, giving input and more discussion on the mailing list and so on. But Mhmm. That's fine. Unfortunately, I mean Everybody's busy. I know we need to do a last call, I think, to get more input. Yeah."
  },
  {
    "startTime": "00:20:00",
    "text": "Okay. Thank you. So I'll take it to a list there. Alright. Dino is this may just have first one is and Okay. So I'm gonna give 2 presentations. First one on GAAP and give you a demo how we got it to work over ipv6. This presentation is gonna bring two issues that came up on the mailing list. Mostly the stuff that Tourless brought up. And then we're gonna give a presentation ipv6 multicast application over list over Starlink satellite networks. We were gonna do that in the list working group, but we ran out of time. We pointed those people to come here. Okay. Next. Okay. What is GAAP just briefly? It's a centralized multicast group address allocation protocol, That means there's no central entity that allocates group addresses. The group addresses are allocated through a library that gap runs in the application. And creates a unique group address across all the gap speakers. And, no configuration. That's it. K. He he draft status. Is I can't read it. Okay. So we just made it, it became an individual. I can't read in November of 2022. We started it I guess that was last fall, and we just made it a working group document thank you for supporting it. Next next next next So two issues were raised on the list. The first thing was"
  },
  {
    "startTime": "00:22:00",
    "text": "how should gap apps use multiple address families? And should gap allocate addresses out of an ASM range or an SSM range. We'll go through each one of those. So gap apps are basically allocated to, group address when they call the library routine gap allocate they get the 2 group addresses they get is an ipv4 group address that's unique an ipv6 address. And so what receivers could do is they should join 1 should they join 1 or the other AF group Should they j join both? Should they coordinate out of band and decide which one they wanna talk on? Okay? So in my implementation of this, app that I built called gap chat, I'll tell you which one I decided to do. On the sender side, should the sender send to one or the other AF groups, like happy eyeballs does for TCP connections. Or should they send to either 1 or the others, or should they send to both? Probably don't wanna send them both because it doubles the bandwidth. But you have to know what the receivers are doing if parts of the receivers are joining on an ipv4group and partial or sending an ipv6 group. You have a problem here. Okay. So what should we do? We design we still desire that these are decentralized apps, so we don't want all the, coordination to be in band and not out of being Next. I know. I wanna talk So so I I believe that that this is not very much an issue that we have to decide in the gap spec. It's really how the applications wanna run. And I have a resolution through the implementation. So we'll talk about that. So coordination with the network is even more complicated if we try to get v4 receivers and V6 receivers. If you look at"
  },
  {
    "startTime": "00:24:00",
    "text": "RSC 6831 to support overlays that's lisp multicast overlays on either a unicast or or multicast underlay. There's over 500 combinations that can occur. And that means there's a receiver that's on the overlay. It's V Four. Receiver that's on an overlay or not on an overlay that's on V Six. There's senders that are attached to multicast or non multicast you look at every single combination that RC bring puts it out to 500 combinations. So it's totally crazy. Because multicast is hard. Multi recipient. So do we choose an ipv4ipv6underlay And my, that may not be native to all members. We choose ipv6? Do we choose ipv6 underlay? There may not be all made members, all these sort of issues come up. So this is really hard Actually, overlays make it simple because the mapping system can tell you how people are reached. And if they think at the edges, they can't get need a multicast, then you can give them put unicast our looks in the mapping system. More later on that. Next, Okay. So this is probably a contentious group. So gap does is allocating group addresses city application and the application decides on the port number and doesn't do anything with sources we're we want to support the multicast service model, which means we want TTL expanding ring search. We want auto discovery of sources and participants. We want all this stuff to to happen for the application. So, it doesn't do any, source re discovery. So one would argue that this employs an ASM model for any multicast protocol native or overly. So an app can do whatever it wants. As a source, the app doesn't care about the multicast risk model, It can just send and then something happens somewhere else. To make it SSM"
  },
  {
    "startTime": "00:26:00",
    "text": "as a receiver, the app could decide, via IGP if he wants to just join tharcoma g versus an escoma g. These are all the sort of same sort of problems we have today. So I don't think we need to bring this complexity into GAAP because GAAP is trying to provide a any ASM, service model. So my conclusion is is that we I do not wanna put sub ranges into GAAP. I just wanna allocate groups and those groups that are being allocated. Can be coordinated with the network, but it's not gonna be easy to do. Tourless. Yeah. So I I'm 100% persuaded that this simply needs to support ASM and them that we simply split the ad split the address range into both of them. And, It's what what you're writing there is a source. The app doesn't care about a multicast service model. That's not true. When you are a source for an SSM address, then, basically, you need to make sure that the application has a way for the Zebra to know what the source address is. That's an application responsibility. That's fine. Also solve this application responsibility. And for example, the Garmin use cases already. So seriously. It's it's it's very simple. You you are asking first. Right? So we split the address range. There's an ASM address range. There's an SSM address range. In in the API, you're simply asking, give me an ASM address or give me an SSM address. How does the application know what ranges the network is using? So how does it know which one to allocate out of No. That's what what you're doing. Right? So we we have the second draft. Right, which is this, AENA registry. From which we're going to take an address range or to address ranges for for gas. Right? That is the second one from from Carson. Now the gaps the gap spec says it's gonna get a single range. For IPV for Android services. Needs to say it gets a rate for ASM and gets arranged for SSM. Done. And how does the application know which range to allocate it. It's gonna ask gap for group address. Basically, the allocation, as you said, needs to know whether it wants to be ASM or SSM."
  },
  {
    "startTime": "00:28:03",
    "text": "In the case of the Garmin application, for example, it's clear that these are SSM application. So they're basically saying, I wanna have an SSM address. Done. Done. It's not no. It's not that simple. The application doesn't know about any of the sources. And you're requiring it to the the government application. It does. No. They have their own That's that's an application that will not use GAAP. No. That's untrue. I I'm telling you it's not true because this protocol doesn't support it. No. Wait a second. If if if you if you have your way with gas, That's true. But if we if if this is a working group document as a working group member, my opinion is it's it's darn simple to simply have gap support ASM and SSM. But we wanna support, Torres, we wanna support decentralized applications. So how how are the all the applications, all the members of the group and senders of the group gonna decide on either SSM and ASM and also coordinate with what the network is using for the ranges. Application, SS S and SSN application. We want applications to work without knowing sources. No. That's light. Like, this the allocation protocol. Think gaps Because that's the service model we want the to do. But the use case from Garmin was always that sources are well known. We're not building a protocol for one use case. We're trying to make a general. We're building a protocol for some use cases, and you can perfectly well use GAAP for ASM if you think that there should be ASM applications, there are just people like me. And hopefully other than the working group, they're saying there should be support. For SSM applications, and they will perfectly well work if you're just agreeing. To basically allow that gap can allocate out of 2 ranges, an ASM range functionality and the definition of the protocol is that it's an ASM protocol. Period. No. No. It's not it's not trying to add more you wanna add more functionality because simple for it to allow allocation out of 2 address ranges."
  },
  {
    "startTime": "00:30:00",
    "text": "An ASM address range and SSM address range. We can allocate these ranges through the other draft, which is from Carson, which is for, which which ranges. We're doing what this is this is darn simple. What I'm asking for, so I'm not sure what the resistance is. Other than you don't like SSM and you don't wanna see SSM deployed. So an that's just what I'm saying. We should Not for these flavor of applications. No. No. Wait a second. These what what what I say? Think we're running a lot Nate is, like, you should us check what he says, I think. Yeah. Can you do it? Alright. Should I oh, no. I did. Okay. Late, go ahead. Can you hear me okay? Yeah. Okay. Yeah. I was just gonna point out that we we do not wanna use SSM. The the model makes it seem like it's SSM, but we actually wanted to use ASM. Just because our hardware does not support SSM. That yes. There there there is no difference between ASM or SSM for your layer 2 switches. That doesn't that doesn't matter at that point in time. I'm on this draft, so I shouldn't be speaking as a chair. So I'm not. But we'll ask the list to see if you're if the only voice that shares that opinion. Let's keep going I certainly will have to think more about this myself and Yep. Let's have a ticket to the list. Okay. So, at last night, ETF, we showed a an application called gap chat. And what we did was we used GAAP to allocate an IPV 4 group address and we sent messages on it. Gap chat is just a text based program that sends messages to a multicast group and has a ping functionality where it can send a ping message to the multicast group and all the gap chat receivers. Then respond with a pong to the multicast group so everybody else gets it. So the way I implemented it for ipv6 this time,"
  },
  {
    "startTime": "00:32:01",
    "text": "is that I had gap gap chat is actually joining both groups that are allocated by GAAP. Okay. And then GAAP CHAP sending occurs when the user selects the address family on the and the, command line. And if GAP Chip sends a ipv6 ping And the guys that are responding, only support ipv4 sending, they will respond to the ping with ipv4, but since all members are joined to both groups, they receive all the message is. So that's the simplest way to deal with the address family. You sent to 1 address family that's selected, and everybody will receive because they join both groups. And, yes, 2 trees are built in the network. Let's let's Okay. Here will be an example that showing of a real a real live example. Here, we have, 3 notes that are running And if you I don't know if you can see very well. So the this guy is being configured to run IP before. Means he will listen to IP portal. Yes. This time when we send IPV 6, And this guy's defaulting, which means he'll send IP before So the first event, go ahead, hit it. So what this guy's gonna do is he's gonna send something called hello for what IP for senator, that's gonna be multicasted to 2 of these two guys. These two guys, all these three are, docker containers on my lap laptop. So they have native multicast connectivity through the single. In the next presentation, it's gonna be over the Internet. So it won't that made a multicast. So basically, the hello is multicasted. And since these two guys are joining the both groups, they get the ipv4 sender. Next, next Now, we have this guy sent, so he's gonna be sending Hello. From an ipv6 center. Of course, since the joining the law groups, they receive it, Next. Now this is a case where a ping message is being sent on the IV before center and you see that this receiver gets it and this receiver gets it and then they see that"
  },
  {
    "startTime": "00:34:00",
    "text": "they respond back to paong message. You'll see the paong messages come back. Via IP The the IP before you just look here, you could tell. X and now this is a thing that's being said IPD sets, And, this guy's seizure in response to B6, this guy's seizure response with 56, and everybody who spare receives the puns. So that's the demo on how we have, gap chat work for ipv6 multicast. Next steps. More testing, obviously. We wanna test multi AF on an overlay. No data multicast exists in the underlay. The next presentation kinda does that. But we'd also wanna implement a mix of of native multicast and non multi cast islands. Okay? In the list working group, we have this draft called list group mappings where the overlay g and the underlay g originally mapped to the save value. But now we wanna be able to have the overlay key map to a different underage and we have, a scheme where the edges can decide what the group is by using cashing court provider can use it by using the mapping system. And so that draft explains all the the other thing is is when you start up gap chat, the gap protocol runs and encrypts all messages. And it uses the, the name that's the group name to encrypt messages. We wanna be able to, if somebody attacks the group, we wanna be able to have everybody switch over to the key. And if we use Shamir's algorithm, it uses this MPC algorithm where there's a a reverse for your transformer. You can a couple members could supply the part of the key that everybody else can restructure the full key without transmitting it over the network, very powerful algorithm."
  },
  {
    "startTime": "00:36:02",
    "text": "I'm gonna play with that to see if we can rekey the group for a multi participant thing. The lightweight rest of AP if you don't wanna run gap in your application, you want it to run somewhere else, you can do that. I hesitate to do that because I don't want the implementation to be centralized. So I wanna keep it decentralized as much more and then we're gonna write more apps to do different things. And, of course, seek more developers. Okay. So this presentation now is gonna show you CAPTCHA over ipv6 as well. But it's not gonna be on Docker over native multicast. It's gonna be on an overlay. And the overlay is the capital that I Internet And what we decided to do is run it over Starlink, satellites. We we showed that at we showed IP gap chat over IP before over list over over satellite in San Francisco. Now we're gonna show you for V Six. Yep. That was that one. Yep. Why isn't it sharing? Hold on a second. That's good. Maybe put a presentation So, you gotta gotta grab a screening Yeah. Press the play up there. Yeah. Okay. So, basically, just them and is implementing RC 8378, which is lisp over using the mapping system, and the mapping system allows you to tell you what the arelokes that you replicate to? Should they be unit guest, are lokes or multicast are lokes? Okay. Next So you guys already know what gap is. We we said that last presentation, you can go next Okay. So a little maybe a little bit more on"
  },
  {
    "startTime": "00:38:01",
    "text": "gap chat. I should have maybe said this before, but it's a text based multicast app that uses group allocated by the gap protocol. And the way you would start it up on the command line is you type in cat chat. And then this is what you wanna send packets in that address, family, And basically, the group name is actually the rendezvous point. In other words, all the participants that wanna send and receive would use the same group name because that's what the GAAP GAAP will cash on that value to pick a unique group address. And it tests the network. It claims the address. And it tries to resolve collisions. And we try to resolve collisions. So we don't have collisions at the Mac layer either going through L2 switches. That that Nate really wants that problem. Okay. So we're gonna demo it on a a list overlay and it's gonna be an ipv6 multicast overlay top of an ipv4 unit test underlay. Okay? That's all we have in this scenario. Okay. Next. Oh, I guess I should say that, could you go back or anything? Doesn't take too long. Kept kept Now what's important is since we do all this stuff and we're using Starlink Wi Fi routers, we have to go through nets. So all this all this stuff is going through NASA and we're doing that traversal at the same time logic in lists to make this stuff work seamlessly. So this is as soon as it comes up, So the orange, is the overlay. In other words, these systems here, Dino node 1, node 2, node 3, node 4, our Docker containers, and they are, running on the overlay and they are connected to a wifi router that has the white lates that are goes up to the satellite and eventually comes to the terrestrial network on the internet. K. K. We have Dan Mack, which is in Arkansas. He's a physical Mac that he's attached to the Starlink satellite as well. And then we have the map server that server running at AWS. And the RTO is co located within that sort of the same thing."
  },
  {
    "startTime": "00:40:03",
    "text": "AWS. And the reason we need that is because that's the anchor point for the natural vessel. So, what we are showing here is packets. We'll here. We'll go here and get through these 2s. Okay. Next IETF, I'm gonna show you that we're gonna use ipv6 unicast our looks underneath we can go straight because we won't have the math problem. That's what we're gonna try to schedule for Brisbane. That's Okay. So these are for Docker containers, you know, node 1, node 2, node 3, node for And, just to show you on my laptop, I was connected to my Starlink router in my house. And we're going to we're gonna go ahead and send the packets And so let's Okay. So the first thing we do is node 1 says type text message, I am the 1. K? It's That's this guy received it. And, again, That guy received a that that receiver note note that coming in on ipv6 multi addresses, ffonee. Is the a 0 allocation range for the spec. And this is the hash value Next, Now we wanna send something from node 2. Waiting for the delay. So, Oh, here's the delay. Of of of Oh, was that it? That was it. Okay. I wasn't interested. Okay. So, Oh, yeah. Right. So what's interesting here is This is the map cash in the RTR descending package. And you can see that for the ipv6 multicast group, you see the members of the group, no one, 2, 2 look for No. 3. Advanced joined to the group running the application as well. So this is a so where what we're doing here is we're doing head identification to these unicast addresses what we're also gonna try to do for next IETF is You'll see"
  },
  {
    "startTime": "00:42:00",
    "text": "underway multicast address here. So this overlay multicast address will then, replicate to an underlay multicast address that will have, you know, something else underneath know, figure out how to do that. Now what's interesting about I wanted to say about this group is 2400170170 This is the actual group that Gabb uses send his claim messages. And you noticed that all all the notes that are running the application are also joined theater live, the gap library that our journey to be able to get claim messages. Of course, the application doesn't know this is going on. Since the packets have to go through the network, the RTR certifications is going on. So you could is kind of a a dual address family sort of situation that's going on I don't have gap working over ipv6, but that's just a simple matter of of programming and trying to decide Just like the application, should GAAP run over both address families are 1 and that's the sort of thing. Said the whole message is those sort of thing. So we're trying to make it a multi dual stack or or multi address family application and protocol family so we don't have to do this twice. Yet one shipping or just not Oh, Yeah. I don't want so, Mike is asking, we try to get this stuff working on a lot of our max. We had ipv6 problems and Docker problems running on an M 1 Mac. Because of, Okay. That's just operating system crap. You don't wanna know about that. That's dirty laundry. But it it's Apple and Docker not wanting to fix problems because they're pointing fingers at each other. So So so but the reason we should mention it is that we wanted We wanted this stuff to run all on the max natively doing ipv6, and that's what we did in last IETF, we had ipv4 running natively on on, On Max, running M1 and they it worked okay because we had to avoid Docker because of this this problem."
  },
  {
    "startTime": "00:44:03",
    "text": "But then when we did ipv6, we had ipv6 support problems on macOS. So we decided to go to Docker. So we couldn't get Docker, ipv6 and Starlink all the work at the same time, and that's why we ended up doing this. That's what you wanted me to do. Okay. Okay. Next, I think we're done. Any any questions? Reactions. Complicated, simple, boring. No comments. Okay. Thank you. Yeah. Great. We're right exactly on time too. Alright. Nate. Your permit. Here we go. So you're, Can you figure out how to re quest to present I'm not sure how to Okay? It's So it was just Yeah. Yeah. That's perfectly. Sorry. My computer just went nuts. Screen 1. Okay. Okay. Should work. Everybody's in the screen? Okay. There we go. Okay. So talk about the 0 configuration multicast address assignment. Nick Carson's from Garmin And National Marine Electronics Association."
  },
  {
    "startTime": "00:46:03",
    "text": "First kind of an overview of the documents that we have. There's 3 documents the first one is the problem statement. The second one, is looks at some of the, the existing address allocation and kind of points out some of the areas that will cause conflict. So as a result of that, we recommend that IANA creates a registry for dynamic multicast address assignment protocols. And then changes the group ID allocation for the MAC that protocol, which is a centralized protocol that is currently taking up the hex 80 through ff and assigning that to a smaller range in there also acknowledges the the group ID arranged used by the the ipv6 elicited node multicast addresses. And then I posted a new version recently. It just had some editorial changes suggested by a, I think William Atwood. And then the final one here is the, what we'll be discussing mostly today. And that's the 0compindnsbasedsolution This is primarily intended for layer 2 networks, and it Reserves, group IDs, 900 through 9 Fff. From that. In that registry that was created in the second document there. Also wanna thank everybody for their help in getting these approved by the adopted by the working group just a little bit of update, on OneNet. This is the protocol that or the specification or standard that we, are, are, are, that's gonna end up using this technology so in the last meeting that we had in September, I discussed the work that we have been doing with IITF. And kind of laid out, the strategy there and one that currently has reserved this range of addresses 160 through 16f."
  },
  {
    "startTime": "00:48:04",
    "text": "For use on our protocols. And we're we're using 160 right now and the rest are kind of, unassigned. The, the idea here is that in in our standard, we will basically add support for a an altered version of this protocol. That uses, 168 through 16f. And then that dynamically, signs those using the same technique as in the MDNS base 1. But we'll do it in a way that won't conflict with the the the draft that's out there. The idea here is that we'll we'll publish our standard with that. See how it works. And, when the ITS solution is published, we can just, kind of remove that or or treat it as kind of a legacy section encourage everybody to use the, the published, version of the the protocol there. Also talked with somebody from IAB, and so they would like for us to give a presentation on OneNet and they, are used to the IETF Pro within that standard. a proof of concept. The code is posted out there in GitHub. Have And the form that this proof of concept takes is it's a command that will basically engage the MDNS boner to publish the records needed. And and scan for records that, make up the MD and S space 0 cod protocol here. So it's it's focused entirely on publishing the records. It doesn't do any multicast application communication it's just about reserving that that group ID range. So the idea here is that you'll pass in, a couple parameters here. You have the interface is what we need in order to get the ipv6 link local address. You have the the application name, and that's described more in the, the document, but essentially it's it's a unique identifier that's that's makes a part of the the DNSSD record that you're publishing there."
  },
  {
    "startTime": "00:50:02",
    "text": "You have the group ID, which is the group ID that that you're reserving. Now, in actual practice, the way it's described in the document is that this would be This would be randomly generated and then saved in persistent storage. So the user as part of this proof of concept is expected to do that random generation, and and persistent storage aspect or or not. You know, the demo is is more experimental and so there's not it's not using random numbers just because it's easier. Then there's an optional parameter here, the TTL, and that goes into the Indian S record, time to live. And that that's optional defaults to an hour, but the demo will use, I think 5 seconds, primarily. So this simulates advertising and collision detection. And then we can use IP tables to simulate a partition and repair scenario where part of the network is temporarily unavailable and, to to the other part. And then the repair where where we, we make it So they're, again, communicating with each other. And that's not primarily a concern with layer 2 networks. However, there could be some scenarios where if you have like a VPN that temporarily loses contact or something like that. That may come into play more with that type of scenario. Okay. So I'm gonna switch over to my demo here. Okay. This is the demo for the MDNS based 0com solution. So we're gonna run for her. Turn up the volume, Nate, I was using this group I need. I can see it finds the link, local address of the interface bridge that into a links code multicast address and then into the multicast username address here. And we see that it advertises that in Winter Shark."
  },
  {
    "startTime": "00:52:02",
    "text": "And here, if we try to advertise the same address from The same device here immediately, it says that there's a woman named collision. That's fine. We'll go ahead and change that group ID. The registration is successful So both of those took place on the same device, but I only gave it to another device. Here, and we'll try to advertise the sending it through is this. In the upper left. We could see that it encountered a collision and exited. So the change in group might be here. Actually what was interesting here is we'll we'll see that partition. If this is where we'll use IP tables here to block all the indigenous traffic and Toyota devices. And then we'll go ahead and advertising in this group. Address here. And then when we remove the block, simulating the partition repair, and then we see that the first of all, myself here encountered a collision and is now Now let's repeat that, but we're gonna change the TTL It's something much harder. 6 100. So we're down here. 100 And wait a little bit. Before we try to repair it."
  },
  {
    "startTime": "00:54:08",
    "text": "It's much longer this time. But it doesn't eventually repair. Okay. The the time it takes to repair is somewhat dependent on the the TTL, of course, but there's kinda 2 two aspects and play there. One is that the application is querying at a rate where when it's doing a continuous query, it it will back off. You know, let's start with 1 second, go to 2 seconds, 4 seconds aide, and so on. At the same time, it also will look at the TTL for the records and start querying it at or send a query at 80% of that TTL. So You have to understand the interplay between those two, in general, the the shorter the TTL, the faster it will repair. But also the more traffic is on the network there. So I think we we would leave that up to, the the people implementing the solution to figure out what the right balance there is between the the responsiveness to a partition and the amount of network traffic that that they can add as overhead. K. Any questions on that? Okay. With the additional time. I wanted to throw out an idea here and just kinda get some feedback. So what I wanna call this the the null and void pointer port So the idea here is the transport layer is is used to multi the applications that are on the same host. We see this with, like, HTTP and and FTP"
  },
  {
    "startTime": "00:56:04",
    "text": "you would identify identify those applications by the port member on the receiver. But with multicast, especially in this case, the application is really identified by the destination multicast address, which makes the port irrelevant. But despite that, the current practice still requires developers to reserve a port with Iona, which can take a little bit of time and takes up more of the the part registry. Perhaps unnecessarily, the idea behind here is to reserve a port. In this case, 49151, which is the the last user port. And call it the Nolan Boydport. Basically the idea here is that a conformance stack would recognize use of this port, and prevent applications from exclusively reserving that port. And at the same time, they conform to applications would not exclusively reserve the port. An alternative name. If we don't like null and void, it might just be the the multicast application port. The idea behind null and void is basically saying the use of UDP is is essentially irrelevant, within this this particular application. It could just be an IP layer stuff, but the the all the socket APIs and, that are needed on the host are all designed around the use of UDP. So what's cool is we can actually do this right now, and I've got a demo on that here as well. The idea here is that, I'll just use SoCAT here as part of the demo. And this this has all of the, the commands and so you can go back and try this later at home. But I've got 2 devices. I got one of our MSDs and and a PC here. The MFD is gonna be multicasting data to the PC. And the PC, in this case, the receiver, it's binding to the multicast address. On that specific port. And there's no need to do, like, the the stuff that we use at or or we use port socket address. It because it's just binding to the port here. So let me pull up that demo as"
  },
  {
    "startTime": "00:58:01",
    "text": "Yeah. 3 minutes, Nate. Yep. It's it's a pretty quick one. Okay. Okay. This is the null and void port demo. Send a couple messages from each of the transmitters. I'll turn in. So we can see that each message only goes to the intended receiver. And we'll associate this in wireshark as well. Okay. So I just wanted to open up, for comments on that, see if anybody was interested and that pursuing that, being know, participating in a draft or saying it's a good idea. It's a bad idea so on. Introduce yourself. Yeah. Totally's accurate. So thanks, Nate. The way I see it, this is competing with Dinos proposal for for allocating addresses. Is that correct statement? No. I I mean, they I say no. Okay. But the way I see it, we seem to be wanting to, you know, reuse address space from this Madcap's, space. And both of these, approaches would wanna use, part of that address space, right? So are we having 2 competing things for for that address space so that we would have to further subdivided when we adopt when we want to move both of them forward. Oh, so if you're if you're asking about the multicast, address allocation, Yep. What we look at it is more like they're they're 22 possible solutions out there and they each have their own, benefits and and drawbacks"
  },
  {
    "startTime": "01:00:04",
    "text": "so they can coexist. Fine. But I I I call that competition. I don't care about what it's called. Just that, if I wanna run both of them in the same network, they would to have a separate address ranges. Right. Yeah. That's that's what I mean with competing. So we're competing for the same address space. So we'll we'll have to be careful in, that we are all happy with the size of the address base of splitting it up accordingly. Right? Right. Right. But I thought I thought we're taking it all from the Madcap a space that we're, taking back. We're taking back this this mad cap space and then we need to decide how Right. Right. So that address space will be divided into smaller chunks like one for each and then they just just wanna make sure that we all understand that we because, for example, I'm the one trying say that we to split up also between ASM and SSM, and then we have splitting up between this protocol and that protocol just so as far as address management, concerned where under all on the same page. Before Yeah. Okay. I'm asking. Yeah. Stick 56 should always be like. I wanna make sure it's done. Yeah. Yeah. Yeah. I don't remember in IP before if there's any assigned Yeah. I don't know. I have to look at that before. I don't know if it'll be 6 or how it's done, but So then basic comment on the way on how you're trying to kind of claim an address with, MDNS I think you're reinventing unnecessarily something that DNS SD already does. You don't need a new ETH editor.arper, you'll just you know, doing the, you know, pinwg, whatever the name is as a service name and, the ethernet address is just the service instance name. So you can basically by just doing that, simplify it and say this is just how MDNS DNS SD does it. What happens in DNS SD, whoever wins, has the"
  },
  {
    "startTime": "01:02:01",
    "text": "or ethernet name, and the other guy gets ether name in parenthesis as 1, right, because DNS SD tries to figure out. So that's the loser, right? So I'm I'm just saying that people, you know, when this goes to to further review and you you talk with your or other DNS folks they'll basically point to the same thing and ask you why you're unnecessarily creating new you know, things that, DNS SD is already doing. So we can take it offline. Yeah. Sounds good. Charge State. Understand. Understand. Thank you, Nate. Thanks. Okay. Thanks. So returning customer, I was here 2 years ago saying that we were trying to better scale, things that we'd started, in beer then we went to a beer and now we're back because we have some new developments that, in conjunction with how the IETF works, has us, some question marks open next slide. That is way too much history, for your own. Next slide. So right? But, hopefully, it's a nice slide. the So basically, the the, the issue in large networks that we when we started this with global bitstrings is that if a beer bid stream becomes very large. It's potentially expensive. To process and it's kind of nonintuitive to have, you know, 4000 bid and you may only have 10 interfaces to send out to So why have to process them all? When we go to smaller bit strings, then that requires multiple bit strings in larger networks or multiple packets And we also need to do some good SDN controller allocation of them that they worked well. And, you know, the degree of complexity isn't isn't the point, but then we add beer to the mix and that makes that whole problem even larger. Right? So one of the outcomes is even when the multicast trees are small, you only replicate 3 receivers, you may end up having to send 3 packets. Next slide. So this is all wonderful with hopefully nice graphics planned here. There is also an mbondy, a presentation from,"
  },
  {
    "startTime": "01:04:02",
    "text": "my co conspirator, Michael Mend, and and his team in the City looking at performance comparison, mostly for own reading. Right? So you have, 3 bit strings to reach all the receivers, the red a green and a blue one. If you just randomly distribute the bits from them in the network, you're ending up in number 2 with, you know, packets for every color across every link. Then you add the SDN controller to this nice allocation things get better. You get more efficiently than you do BRTE and it gets worse again. So, long story. Just saying that we're here because of a perceived or real problem, in large networks. Next slide. So what is the proposal been proposal has been instead of using a single flat bit string where it's really encoding the whole tree. Right? We're just telling the network exactly where the packet has to be to to hop by hop or indirect hops. And we started doing that all, in, in the beer working with just with bit strings. And here, we're getting to the points that we actually wanna have bit string and sets. So on this slide, we're showing it very simply. You just look at this route Rx. RouterRx needs to replicate to two nodes or 2 R4. So the only stuff that router R2 should have to care about is not hundreds of bits, just, just, just, just, just, just, just, just, send it to r 2 and to r 4. Okay. Fine. But then when it's being sent to R2 and R4, they also need to have their we do the same thing, which is why we're saying we have a recursive unit And so as far as r 2 is concerned, it only sees r 2. Then whatever block there is for, r 2 itself, the recursive unit, that's what it needs to copy over to the package to R2. And once it gets to our tool, it happens to be then, you know, another recursive unit, which just says you need to copy to our 5 and our 6. Right? So can, go arbitrarily recursive, but in the end, the whole point is the only thing you need to parse and deal on is the list of neighbors you have and for each neighbor, some block that you need to copy. In the packet to the neighbor. Next slide. So now that was with a list of neighbors."
  },
  {
    "startTime": "01:06:03",
    "text": "We call that sit list because sit is such a popular term in the IITF that we just had to reuse But, of course, we can do the same thing with a local bit stream. Where we're just pulling, you know, all the neighbors we wanna set to. Together, create a local bit string, router has 60 neighbors, We always have a 16 bit long bit string for the neighbor, and we're just setting number R2 and R4 and, you know, all the recursive units come afterwards. So two very simple alternatives list of sits or a local bit stream. So what which is better. Right? Let's pick 1. No. Sorry. Because It just one is more efficient than the other. The other is more efficient than the first, depending on the size of the tree. Right? So I've given 2 example here. You gotta, you know, was the first one? The the angle here is really hard. Yeah. So we've got an edge route, 128 neighbors. The local bits ring is 128 bits. So if the tree has less than 60 neighbors as if this is better if I need to rep K to more than 60 neighbors, the bit string is better. We go to a core router number slightly, similar. Right? So, basically, it it really depends on the tree what the most, ideal encoding is. And then one string, like, 16 or 24 bits, we can skip over, you know, a lot of hops and also create further. Right? So very, for very our streets will use, a a longer global set of, let's say, 16 or 20 corpits. So that's basically our current state of investigation just from the architecture of how we constructed next slide. So the recommendation. That's in the beer working group on Friday. So we haven't implemented all these together kind of started with the individual blocks, bitstrings, sits and now trying to merge it altogether, the draft here for the, PIM working group has kind of a first attempt of trying to show how that could work in detail. But we we think that this should, work fairly well"
  },
  {
    "startTime": "01:08:00",
    "text": "across all, you know, the high speed platforms. And, you know, the processing as far as what you need to look into, that doesn't scale with the size of the header, right, you know, you need to copy out the RU. So there is a, you know, on that creating the next packet, the copying effort, but that was already when we were just doing bitstream something where most vendors said that isn't the problem, just, you know, long processing of a lot of data. And that's just for local staff now. So that's that that's what makes it more scalable next slide. Okay. Management complexity because we have local identifies every router can allocate them themselves, announce it to the IGP as long as we just use local bit strings and local sets, we don't need an SDN controller. Right? We can build fully distributed system. Every, sender needs to know the topology, the local bits, and can construct a bit string If the header is, a limit, it's also very easy for a center to break up a large tier tree arbitrarily into smaller trees, We don't need to prepare for SIs or so the kind of subdivide the network into, different sets of global bits Right? So we get rid of that management complexity. Global sits, of course. Yeah. So everybody has a loopback address that's global So hopefully that range is also not an issue. Next slide. Okay. So when we already are doing crazy structures in a header, we can do further optimization because there are things that some old people are still using TV, right, So if you have an IPTV application, then you may actually need to go to, let say, 95% of all the 8000 endpoints in, and this is the simulation that was done for a Chinese network. You know, of all these, you know, 100 of million people. I I don't know how many subscribers are there. Right? But so this slide, what that is showing is on the X axis. It's the percentage of multicast receivers from 0 to percent on the y axis. It's the number of packet replication."
  },
  {
    "startTime": "01:10:03",
    "text": "The green line is the number of packet replication used in beer. And the red line is the one with the local bit string variant. With which we started. And why is that number going down? Well, we do the trick that basically on the prior to last talk, we're saying replicate just, you know, one bit encoding that says replicate to all your leaf neighbors. Right? So, that basically means you can compress very large trees on the leaves by saying, you know, broadcast to all your leaves. So that makes very large trees smaller again, and you need fewer copies for them. And I think that basically where we are. Right? We have a lot of small trees that's sparse. And then we've got a really dense tree, and we can also nicely traffic engineer them, steer them across path, and broadcast to the whole edge. Next slide. Okay. So that was pretty much it. Where do we go from here. So we have, our ongoing prototyping work on P4. As I said, the draft here shows the possible encoding idea. So this all based on extending, going back and forth on what we learned over the last 2 years working in the beer working group. The beer working group like the idea with the local bid strings very much, but said they have no interest in the sit list. So, which kind of means we may have an IETF problem, but given how we're not yet for adoption because we really would love to have the you know, full, you know, what what is the best thing we can do on p 4, even if it's not relevant for here as vendors, but we really would love for researchers to be able to work on that. And the only thing that a researcher can get high speed hand on is is the tofino switch. Right? So that's That's as as far as it goes. Right? So and of course, this is not meant to displace or or say bad things about beer and beer te, I I happen to be a big fan of that, but we really wanna have, you know, these larger networks, less management city, better scale, pre engineering, better for building, scale, forwarding implementation. Right? So just, you know, next generation to make it better."
  },
  {
    "startTime": "01:12:01",
    "text": "So, and hopefully, you know, by coming to pin, we also go to a somewhat larger community. Who of you was not going to, to to the beer working group. Everybody? Okay. 1, 2. Okay. Right. So we we got 2 more people. Yay. Right. So, and if you have interest in this, yes, please, talk to us so very happy to, expand the collaboration on this. Thank you. Thank you. I'm at speak up a little bit, can you hear me back A little louder. Okay. Is it okay? Pretty light, but to speak as loud as you can and go ahead Okay. I have I'm from Ericsson. Now let me introduce some updates about this the UJPS model cost, the YAM model, Nice, please. This is version 3. We we we have got some comments and, make some updates Nasfreeze. There are some minor updates. I will I will not list here on this this there's only one major updates. This is, we add the an ATMP policy and the youth and you feature UVPN MLD policy. And the vendors include the enable one feature, I'll post all of them, next please. And this is a Ho jarakioboss"
  },
  {
    "startTime": "01:14:00",
    "text": "about this. And then now let me, make some videos about it. Way I'll manage this if we can you will pay a instance and add 2 leaves UAP and IP policy and the UAP ML proxy. If you if you if you have, if you leave, UAP ICMP process enabled, it will trigger I might root to update with, Monica's flights extended, community and the the IGRMP policy base is is set. Similar as the the UPM MLD proxy. The the second part is we we augment the roots under the European instance and, either I would see 909251 the u v ICMP MLP policy for U VPN defines the 3 and your European rules, tab states, to type 8. And The select table money cost, ethernet tag road. It's a tab 6 tactics root, their performance is of this road is to distribute the host, intent to receive the multicast traffic And the money cast, member shaver reports Sync root is the type 7 root and the multicast. The liu sync router is a multi I I is the tab is the tab 8 root they are used to optimize the multi exercise access the segment with would have, 78 Oh, The next, please."
  },
  {
    "startTime": "01:16:04",
    "text": "We would like to apply for the working group adoption here, and and we'll, and we will welcome more comments sent here. Okay. So, I just started a poll. If you can respond to that please, working group, on whether you think that we should adopt this draft. This is a draft that would be more typically more appropriate in the best working group. We've pinged the best chairs and the and the best working group about this draft. They're a very busy, working group. And Hangji hasn't been able to get a response from them. So that's why he's presenting here, especially since we've progressed several of his other drafts his other young drafts. And so we've been given permission to, see if this is something that we do wanna work on. If this is something that we do, adopt, then, we will once again, ping the, best chairs and get approval and go from there. So Right now, we have eight people that say yes, one person that says no and 29 that have no opinion. So We will that seems to be fairly strong consensus. Davis let's take it to list, ask the chairs, and, and thank you, Anji. Thank you. I think that'll do it. Alright. Yep. You're up. No. Come on. Alright. So she said, This one? That one. Okay. We're doing okay? Yeah. Next Yep."
  },
  {
    "startTime": "01:18:01",
    "text": "Good afternoon. And sorry. I don't have much text. So have more of pictures. Yeah. So in this this draft, we are talking about 2 things or integration of 2 different technologies. 1 is when we are deploying EVP and multi homing and which we we are seeing more and more providers, they want to have multi homing in the exercise. With electromagnetic homing. And multicast, there are still many customers or many deployments where they really don't want to touch. Pam has been working for so many years. So let it work. So what is the problem if we go all active multi homing? So if you see in this picture, right hand side, I have, these, CE devices. Which is that that's where your multiplica source is connected. And receivers could be anywhere. It could be in the layer 3 network or it could be behind your, other some different bridge domains. So left hand side is the actual receivers. Today, how exactly ping works? So when we try to reach any source which is behind these multi homing segment So before even pin join, when we look into our IGP source rich ability information. My spines will see for any prefix that I have to next hop. Which is LEAF 3 and LEAF 4. And the reason is both of them are hosting same bridge domain. And we are using EVPN procedures to support this overall Ethernet segment based multi homing. Now your IGP at spine, our rest of the network says that you have, 2 next hop to reach the same source. When your actual joint comes from the left hand side, join will start looking into prefix, how to reach the if we see here from the LEAF 1 LEAF 1 sees that it has 2 next hop, it can go via s 1rs2. Our team joined reached to s 2. In the s 2, again, when I look at my source prefix, It says that you have 2 next hop, which could be ECMP."
  },
  {
    "startTime": "01:20:02",
    "text": "I I'll take a local decision to go to leave 3. When your actual source starts sending the traffic, in the source when C3 receives the traffic, it is it is a port channel. And when you have port channel with two member ports. You are just going to pick 1 of the member port. And it picks the right hand side So traffic reaches to leave 4. So in this case, we will never have traffic getting converged. So receiver will never get the traffic. And the reason is there are two places in the network where we are making a decision. One is in the CE device. Which is making decision about which upstream I'm planning to send traffic on. And there is a one decision which is happening at Spine which is about how where to where to send my joint to. And these two guys, they're not talking to each other. And that is where we can run into this situation. Next slide. Question. Okay. So how are we handling it today? The way we handle it today and most of this working group, which is defining EVP procedure, is It has defined a layer to tunnel, which is EVPN based on where we send our traffic over bump tunnel to other peer. So in this case, Whichever whatever traffic is coming on l 4 for a given bridge domain, we send everything to L3 as well, which is LEAF3 in this case. Now if you look at from the ping perspective, it is kind of a land case where both of the router have to the 100% of the traffic. It doesn't matter who is getting the join. You will receive the traffic traffic, traffic, traffic, traffic, next. So theoretically, it works very well. It has been working for couple of years now, but the challenge is if you see that we are using those ban link twice, So we are sending a traffic to via spine to other peer. And then again, it goes back on the same link to serve the layer 3 network."
  },
  {
    "startTime": "01:22:01",
    "text": "Now these doubling the traffic sometime depending on the kind of use you have are the kind of flows, bandwidth of the flow. It may not be really necessary that you are using your network optimally. So there are deployments where they want to see that how can we optimally use multicast network. Next, next So here, when when we are talking about team network, So we have an experimental RFC which has been implemented as well. Is EFMSD. So this provides an infrastructure where you can really flood some information in whole team domain. And that is what we are planning to use to make sure these 2, decision makers, they somehow come and sing that both of them are really making the same same decision or similar decision. We can go to next. So what what what exactly is needed? In this case, I want s 2 to know where exactly my traffic is rather than looking into prefix based forwarding. I want to really know where this SD is present. And if I know that that information well in advance or at least when the actual source is active, then I can really drive my joint towards wherever the sources, Next. So what we are going to do, the this is the first step, or I would say brute force method. Where where When system is booting up or your whole network comes up. There is no traffics Traffic has not been started yet. You don't have really control whether source will come first or receiver will first. So let's say that receiver comes first. So if receiver comes first, it is going to send join as it was sending earlier. Right now, there is no information a call anywhere. So joint may really come to lift 3. Even in this case, But eventually, Leaf 4 will receive the traffic. And that is where we would like to"
  },
  {
    "startTime": "01:24:00",
    "text": "when we see and the leaf for really understands that that interface where I'm receiving the traffic is multi home, all active multi home, netnetnet interface. So if I'm receiving any multicast traffic, on all active multi homing port I'm going to start the flooding the information. Now originally, PFMSD are the source flood mechanism was for ASM only. In this case, we will have to do for both. Any traffic which is coming on this multi homing ports will be flooded. And this information reaches to s 2 as well. Now that is where s 2 can do its RPF change. Or if your source came first, the join will really take the appropriate path. So in this case, Use uses the same infrastructure of TFMSD where it is going to flood the s comma g reachability information that where this source is active. And s 2 is going to make the call that I have to send or direct my joint to. Next next So, okay, I think we already spoke this as well. Can you go to previous life? Very, as I said, the brute force method when you start flooding, this information is not going to be limited only to s 2. Is going to be flooded. It is going to be flooded. To the whole domain So in the next revision, what we are trying to come up with that how to control it dynamically where you are these flood information is going only till spines, spines, It really doesn't go to the whole network. And when I say spine in this picture, it it means that the nearest replication point where you come into the situation where you will have easy and So we should be able to stop flooding right there so that we still use flood mechanism but we flood it in the control environment. And that is the next step optimization, we are"
  },
  {
    "startTime": "01:26:00",
    "text": "client to work on Next, And any comment question? Thomas Eckard. I'm I'm not 100% sure. I I I get all of it, but do I see it correctly that this EDPM is doing some prep that does multicast not work, and we have to fix it on top of them. It is not like that. So is So till now, we are most of the time, we were doing multi homing with active and standby. So we were which is getting traction or many people are deploying that, which is all activity home. When you do our active multi homing, both of both side are advertising the same prefixes. That same prefix can reach using both of the PER Vitives. Now that is that is definitely going to impact multicast. For unicast, it doesn't matter because you can come either side, and you can still communicate to your host. But multicast comes in reverse direction. So we have to do something about mean, nothing against the ingenious hex that this this this may actually work, but why shouldn't the EDPN folks first try to fix it on their side when they do something new. So there is nothing which Evipin can do here. The decision which port channel is making, that is like LSCP. So LSCP picking 1 of the neck, 1 of the upstream interface. That that is you cannot do it. You don't have any control over it. But that's part of of of how EVPN is find. Right? They're they're they're they're using that mechanism. So there are There are 2 decisions maker. One is the traffic which is coming from southbound to northbound, how are you going to make how can EV can even make call this happen offline talk. It's just Sure. It's it's kind of, you know, It's it's on screen. Sure. Sunny's on ZTE. I'm wondering that if it cannot only be used by EVP and multi homing because"
  },
  {
    "startTime": "01:28:01",
    "text": "if we use some our 3 multicast source to send us a information through to uplinks, then the situation is the same. So, I think maybe the situation should be extended it to all the information that can included. Yeah. Sure. Yeah. That's all. Rick saw you in the queue. Did you want to say anything or Please go ahead if you have any comments Rurik, Okay. I guess we'll move on. If you have any comments, you can take them to the list. Okay. Alright. So one more evening. Next. Okay. So what what exactly we are going to cover in in in today's session. It is what is happening with EVPN and what kind of requirement it brings for PIM domain when it is getting connected with EVPIN fabric. And this work belongs to best. Why him? So before we go to best. We want to make sure that it really covers all the aspect of PIM, and that's that's the reason we wanted to 1st discuss this in PIM before taking this to this. Most of the procedures change. Belongs to best where we will have to do procedure changes in the EVPN signaling for DGP for EVPM. So it just talks about the use case that what exactly is the use case are where these two tell me, uh-uh, these two technologies talk to each other. So let's have just a quick recap that"
  },
  {
    "startTime": "01:30:01",
    "text": "when we say him, him is us by default, it is soft state protocol. And majority of the packets, we keep sending the refresh, but the most of most of the time which is our most prominent packets which are being used is Hello's join and prune. So this is with respect to pim. What happened in case of EVPN? So in EVPN, all the service services over EVBenn is a services over BGP. So we have a hard state protocol. Where where we don't send same information multiple times. And there is one important aspect to understand which which is the d f election here. The reason why we we really need to be careful about is with it it really defines a mechanism that who is going to send traffic to the south south of the PE devices. So in this case, Your leaf 3 and leaf 4 are multi home. With all activity homing. For any multicast traffic. So not just for multicast. It is for the whole bump. So for bump traffic, there will be only one of the guy who will be forwarding at any given point of time, not both of them. So this is the kind of event requirement. So we have it it it it protocol which is PIM where which is the soft state protocol. Then we have EVPN, which is hard state, and some of the new procedures it brings, which is a. So what we are going to discuss, what will happen if you have a EV pen fabric. When I say EV pen fabric, which means that I am really extending my layer to network or layer 2 circuits or, your MPLS score or any layer 3 core. And within these, individual layer to domains, there is already a routing domain. And if we map this to real use cases, you can have a service provider, which providing services to small enterprises. And these enterprises may have purchased just layer to circuits, with the service providers. Now these these"
  },
  {
    "startTime": "01:32:01",
    "text": "small enterprises, they are running their own pin. Even though they have, they have layer 2 circuits, they have presence across the country or maybe worldwide, but internally, they have their own team domain. So now that is where the intersection comes together where you have a team network then you're between 2 pin domain, you have EVPEN network well, which is connecting these 2 pin domain domain. Next So this is bringing the high level requirement that What what kind of requirement we are trying to solve? First thing is These, reducing the soft messages. So be it hello, be it joined prune, These messages are being sent continuously. If we are going over EVP and fabric, we want to reduce those messages. And then The initial focus is on team Hello and joint prune, but nothing prevents us to really extend this solution for all other use cases. And the next is whatever solution we are doing, it must still provide a optimal way to provide multicast services and then prevent multiplication where you have same traffic going twice. And it should be supporting multi homing and multi homing with heartwarming a stick So you talk about avoiding soft state and periodic messaging. Yeah. I'm wondering if you could use import for the joint prints And do you really need the Hello's or or can we do something like pin lights for some somehow avoid them? Yeah. So I think that's the reason why we first want to just discuss the problem And then we can decide whether we want to convert it state, or we want to really go with something else? To support these cases. Next,"
  },
  {
    "startTime": "01:34:00",
    "text": "So first thing is, when we talk about pim Hello and joined prune. So in this picture, I have 3 p routers, r 1, r 2, and r 3. These these are 3 different pin domains, but are getting connected using EV pen fabric. So today, the way default behavior the way it works by default is Arman is going to send hello. And if we flood these hellos. These hellos will be received by r2andr3. And these hallows will be getting refreshed every 30 seconds or whatever timer has been configured. So these are the packets which will keep going over the core. That is number 1. The second is joint prune. If we build any tree between these two domains, these, joint prune messages will keep going, and they have to cross these core network. Via so right now, it will be kind of a flood where every 30 seconds, we are sending our joints next Then the second problem statement is that is the one of the flood prevention where all the soft state messages we want to prevent The second part is if you have a pin joint, If Kim join is being sent from our 3, the steam joint can go to either of the leaf. And nothing prevents it to go to leave 4. If joint reaches to LEAF 4, LEAF 4 can build all the tree necessary tree and get the traffic. But but but the decision of whether leave 4 being able to follow traffic towards this pim domain depends on the DF state. And if it is a non deal, it is going to drop all the traffic. So we have to have a way where we can support these kind of use cases where irrespective of your DF state, we should be able to serve imdominant next the solution overview is that currently this draft, we are ping this from, I think, IIT of 97 or so. So the initial initial solution, which we had thought was converting,"
  },
  {
    "startTime": "01:36:01",
    "text": "pim hellos to BGP based signaling. Where you get a hello and you kind of act as a gateway in the EVPN land and you just send it using BGP and let individual, even gateway, take care of proxying on behalf of remote guys. That that is the best solution, but definitely we can discuss if we want to go ahead with Kim Light or something else. The second one is join prune proxy procedures, it is again same thing where we are converting similar to hello where, we convert it to BGP based signaling. And then having some assert optimization for the multi homing, we already have RFC which which defines procedure for multicast sync. And those are the routes can be reused even for PIM. And the next point is how exactly your IGP host and source are going to talk if source these 2 are sitting in the same bridge domain or they are sitting in different bridge domain. Fixed So these are the use cases which we would like to discuss And, yes, any input or, feedback is welcome. The list I I can submit. Thank you 10 payments. Yeah. Hello, everyone. I'm Juan Moore from Future. Today, I'm going to talk talk about adaptive stately stately as a t t e multicast. Next page. I would like to thank her, Jeff, and the tolers for their comments we made some appetites So the"
  },
  {
    "startTime": "01:38:00",
    "text": "updates to previous version include adding, simplify the version of a, adaptivity, multicast, and, some comparisons next page. In general, a a medical tree, It's big. And the sporadic in some networks. Example, in this picture, And, and, is a medical tree. So on node p 1, So we have number of links. So on the one end, We have a link to from p 1 to p 2 and a p 3. And then in the other end, we have a number of links the thing is from p 1 to p 8 and then pd line and to PG 19. So if we use a single any single including method, And then the efficiency is not good. So here, In the full version. Of adaptive team podcast. For each portion of a tree, We select and most efficient method. Among the multiple encoderizers, So here in this example, So we use a for the for the link from P1, to p 3 on p 2, we use a lingal amber, which is a psycho by the ping backing in the in in in the in in the pink pink cycle. For the link, from p 1 to PE 8 PE 9 or PE 19. We use another encoding method here, reuser. Flexible, Beat the stream, So this is a cycle in you know, color. So in this way, we can encode any part of a tree use them"
  },
  {
    "startTime": "01:40:00",
    "text": "most different efficient encoderizer. So In general, we can get warpetimum, in codings, to any tree. So that's the full version, of adaptive te mudcast. Some people said comments that this may be, complicated. So in order to address that comments, we propose a simplified version. So you still would have find a version. We just select the 2 method. So we use 2 methods to include any portion of the tree That means that for early person for tree, We just select a more efficientizer from those tools. So important for the future, we can show that We only have a 2 colors of circles. So, so, so, One color. Indicator 1 encoderizer. For the pink cycle, we use Lincoln Lumber, and then for the yellow cycle, we use the flexible speed stream. So this way, we simplified the method but we could also achieve maybe very good results. Next page. Can you define a coding model? For method And what what would mean in in model? That's what We were making a reference to it. Included method does that mean? Those one, we we were talking in the in the drop what's the flexible encoding? What's the, ninklumber encoding? And what's the half lecture encoding, those are details already in draft because we will really present this one. In the brief Yeah. Yeah. We already described those in details. So here, we just Yeah. That's the that's the fence. People also have time or interest to redraft. That's depend on that. So here you see, we give a encoding simply have simpler version because we only use two methods. So we just use a a flag. 1 bit flag"
  },
  {
    "startTime": "01:42:00",
    "text": "So 0 maybe indicate a 1 one method and 1 indicated another measure. So So from encoding point of view, even we have select 2 method, encoding any part of the tree, and then including is also relatively simple. Simple. Next page, So we make some comparisons. So we compare this simplified version with any single encoding, encoding, So here, Just for example, Madica's tree, we we use a simply by the version. We use a 20, 20 three bytes. If we use any other single encoding, for example, half flux pitch train, where users 35 bytes. Flexible bit string where you just 33. And then number, we'll use a sate, And then when I have a message, what will be which will be consume much more price. So from percentage of review, we can see that have flex touchscreen. We'll use a more than set it to a 52% And then for a flexibility train, we're more modern 43 and the nickel number 65%. We can see that simplified version It's much more efficient than any single encoding. But a single encoding maybe a little bit simpler, And then that's a the carbureausians between the simplified file portion, and the single encoding method. And then we also compelled simplified version we use a full version. Simplify, fortunately, is a similar But the full fortune, I said he's more extensible. Because if someone come up with a very efficient single encoding, and then we can adjust the just the plug in to the this, full version Also, in general, the full version will be optimal."
  },
  {
    "startTime": "01:44:01",
    "text": "So that's, and then However, the Take simple by the person is a very close to the to the full version. From the patient is for you. Yep. Next page. Yeah. Any comments are welcome. Oh, this record. Yeah. Would would would be nice to see hardware implementation of Right? So it's, getting, somewhat similar to what we're proposing. For the same purpose. Right? So the simpler and faster we can get it, the better Yeah. I know your message is similar. Yeah. You also combine the different ways, and then in that way, we can achieve, almost a month encodings. I mean, this is this is this is all something which which would really be good to have for implementation for reference. Right? So or else, some other vendor high speed implementation, but then you know, how can researchers use it. Right, sir? Yeah. I think this is also a very good research research topic. With them. This is a different combinations. And then you can get simulations and then get some proposals. Yeah. Thank you, everyone. Thank you. Hello, everyone. This is Luis Contreras from Telefonica, and I will present a work together. With a from NIC team in Japan. So this stuff, described, signal based mechanism for important multi polishing interfaces in A and P among the proxies. Next, please. So this work is is, somehow frame, in in the case. This describe in the, type in the draft that you can see the title"
  },
  {
    "startTime": "01:46:03",
    "text": "the the reference in the title. So you can that that MP MLD proxy. So there we are somehow proposing a an extension of the current specification of the Emp, MLD proxies in order to support more than 1 upstream interface. So the current specification is that, yeah, only one, absolute interface could be supported. So there, we, argue the the the use cases that support the this proposal, and also we, address different aspects One aspect is the the static ops in interface selection that could be basically done in the in channel, the subscriber or the pry or based in a a kind of priority. And then we talk about, 2 specific mechanisms. Installation mechanisms that are, different from the static one. That will be pure configuration. One of them is about automatic upstream interface selection. So involving on signaling. And for that, the proposal is to leverage the the extension of mechanism defined in NFC 9279. So this is the scope of this level that I recommend right now. And then there is a, another, option that could be a controller based stream selection. And this is a work in progress, and we expect to present in next ideas. We would concentrate on the on the signaling for, this automatic stream interface selection. Next, please. So there in, at the time of selecting the interface. 1 is the policies defined in the proxy for selecting the interfaces. This could be based on on a particular, usually identifier. So this hours IP could be the case or either the source or either the group. This, policies will be common to any mechanism So these are not particular. I mean, could be applicable for the controller based or even for the for for the static. But, what we want to concentrate is in similar situations, that will be somehow what we try to to, proposing in this document. And the scenario situations that we do foresee is, one for the"
  },
  {
    "startTime": "01:48:01",
    "text": "retrieval of the multicast channel or or source per person interface. So getting from the from the proxy, what what is the the the the channel or sources stated state, then the multicast channel or source request from 1 or more interfaces to to and to acknowledge what are the the channels of sources coming from each of the multi all the upstream interfaces. And then the 3rd case will be the the maintenance of the multicast membership information in the downstream so that that we can, be sure that that there are subscribers subscribed to the different channels and and who is, let's say, taking it, a channel at the end. And and these are particular, methods that can be defined or we can be defined. Through destinations, following, Arizona to 79. Next, please. So the the changes from person00, we have, refined the terminology. We were using discovery in in in 00 version and we realized that be confusing. So we are substituting that by information retrieval, and we are 1 this is a tutorial worth fixing, in text and figures. And also, we have, we added a number of figures. So in the signaling, wall, wall flows and flows so that the the the usage of the messages here becomes, we expect to be more much more clear these are the figures that have been inserted in the draft. This has been the essentially the changes for this merchant. Next place. So here, we present, basically, the the roadmap that we want to propose to the working group for, for the work in the area of supporting multiple as an interfaces. We have as, mentioned before, the data that this somehow, like, a kind of framework for this proposal of supporting multiple ascending interfaces. We would like to ask for adoption of this of this draft, because it's asset is a kind of framework that opens the door to different solutions. Then for the the data that they presented today, the draft controller has been multifconfig"
  },
  {
    "startTime": "01:50:03",
    "text": "So there are some opinions to dos. Well, one is to extend the content to We are by now focusing on MLD. And then also to include text for the include, exclude modes, in the stations of the report message. This is not yet done, so we need to to cover that in in version 2. And then also we are working, in the draft that I commented also before for the, automation of the configuration be a, a NSEAN controller. We want to propose a model for that, and and that will be the the third route that we will present in in this context. So, summarize this is the the work we are doing. This is the raw material we like to follow. We will lost the chairs in some point in time. The working group at us, you need to consider this, relevant for the working group to work on on this the framework that one. And, yeah, and comments on on or suggestions are more than welcome as as always. So That's all from my side. Thank you. Thank you. So the hitoshi draft then, you are either now or eventually you'll be seeking for a working group adoption. Yes. Do you wanna talk about it later, or do you want that do you want us to what what what what what sorry. We didn't prepare a specific presentation for for today, but this has been presented times in in being working group. Mhmm. So maybe we can take this into the list so that people has time to to read and That's a good idea. And they're coming from decision. Is the draft updated? Is it It has been, updated just simply for referencing the second draft. No. No. Not happy that from the point of view of content, just have simple references. Okay. Updated. Bring it to the list and then we will eventually ask for what group adoption Thanks so much. Yeah. Thank you. Thank you. 80? Yeah. I guess we are dumb. Anything else?"
  },
  {
    "startTime": "01:52:04",
    "text": "Then you Yep. Thanks. Yeah. No. It's not something about late. Yeah. We don't do anything is conventional. Yeah. In reality, I guess, moment presentation. To see how we could get it. But it's kinda amazing with everyone. Right. I think long time to see. But the the IMO, TiRA talked we we also have a update and we think it's stable now. And the we want to ask that for the. Is that perfect? Yeah. Yeah. I was wondering. This is I don't know. They're all in,"
  },
  {
    "startTime": "01:54:03",
    "text": "March in in in in the this year, on the last year. Single knock in the spring. But, yeah, have you made any changes yeah, we got the changes since your last presentation So it's reasonable to present about what you have done, what you changed or some some certain that the the changes, more about the the I did I did you No. I guess someone that was maybe, yeah, maybe read through it again on my cell Thanks, Mike. We'll talk to you later. Yes, informationals. Right, is is it wants to. Yeah. So, yeah, I mean, from what I remember, it's a good shape, but then we want to one more time. But if I only have mine and problems that can be part of the last but that'll be we often have problems getting people to read about hopefully, if you have us call and we'll get that we'll get more people in the"
  }
]
