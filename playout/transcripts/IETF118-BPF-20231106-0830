[
  {
    "startTime": "00:00:30",
    "text": "Close to one. Yeah. Get outside over either one here. Hi, everyone. Welcome to the DPF meeting. At the IT of 118. Thanks for everyone who's here and online as well. We're gonna have a nice, short meeting today. And we made, like, great progress from the last meeting. So thanks to everyone for working on the list. Well as the Linux panelists as well. And my cochair, David, is in, back in the US. Getting married in four race. Look how happy he is. So, yeah, And, Yeah. So he'll be around if you have any questions as well. So, just like, feel free to type on the media code. And,"
  },
  {
    "startTime": "00:02:00",
    "text": "So with no further ado, we'll get started. So this is the note while you kept seeing this is just like what are the rights you give to the idea, and, like, the too much detail to put on the slide. Just follow the links and and look at the details in there. And, Marie, you're excused. Have a good meeting. And please, follow the IDF code of conduct. Please be respectful and provide courtesy to your colleagues all the times. And, just it's it's fine to talk about the technology, but not about the people. Can I please be mindful of that? And don't worry about the blue sheets. Like, just the on-site tool. If you wanna talk or not because it helps us, like, plan the room better. So, yeah, this is the only way we get a count of how many people come into a room. So we don't get into a too small or too big room, and we don't have to guess. So please join the And, looking at the deliverables itself, like, we have, like, one milestone deliverable right now. And that is the instruction set, and that's due in March next year. And we made, like, great progress. So thank you Dave for, like, pushing that along. And, become like a long way. Since the working group has been bombed, and it's like very short time. And our our goal is to kind of, like, talk about all the changes that have happened Since the last meeting, which I've been a lot, talk about, like, you know, any anything that's open, which I think there's at least one thing that's open. And that Dave will talk about. And and hopefully, we'll be able to get to one of the last call sometime in the near future, like, hopefully before the next meeting or at at least at the next meeting And then Alex, he's gonna talk about the BPS memory model, and, like, we saw, I we saw the slides. It looks awesome. So, like, you know, we'll just let Alexi talked about it and the things but it's like, you know, we had to figure out, like, how to dispatch it further. So any questions on the agenda? Anything else you would like to bring up? Seen nothing further. Dave,"
  },
  {
    "startTime": "00:04:00",
    "text": "connect. No. Other analytics. Could just call it next slide. Okay. Yeah. So, Suresh said to thank me, but I'm just the editor, a lot of contributions to other people that will that I will acknowledge later on. I've just been collecting stuff and doing the transport. So instruction set architecture, you can see this one is now draft IETF. Next slide, please. So let's start out by talking about what happened as a result of the discussion last idea. Last IETF, there was a couple of points about needed to move out of the ISA document and into a separate document that's the ABI document. That has been done. The API document exists, but it hasn't yet been submitted as an Internet draft. It's this gets there and ready to be submitted, I think. But, hasn't been submitted yet, but it has been moved there. We had a long discussion last IETF about the honest considerations of what we do for instructions. And we had 3 categories that were talked about permanent provisional and historical, and we'd have a label and very similar to how some of the other registries work. And during the discussion, we agreed that, the permanent IN ever, policies would be standards action or IESG review. Right? So that was the outcome of the discussion, and that has now been reflected in the document. Professional and historical is just what we talked about at the beginning of the meeting. But the permanent was the one we had discussion about, and that's where we settled. As the consensus from last meeting, and there was no changes as a result of the confirmation on the list. So that was done. And then finally, as you mentioned, the ISA document was adopted as a working group documents, and now it's rev to draft 0 0 because it's draft IITF. Next slide, so this was a result of the discussion. Okay. So since I left, IETF meeting. There was subsequent discussion on the list."
  },
  {
    "startTime": "00:06:04",
    "text": "And so a number of things were were done in the in the, document as a result of list discussion. The first one was we had meeting discussion, and then we tried to confirm consensus on the list. And what we meeting discussion, was, different from what the list said, and that's because the list raised new points. And I'm gonna to that. Okay. And so, expressing the instructions, in, in a registry. We had a single table version and a multiple table version. I'll show an example later on. And the in the meeting, we said, well, they're kinda equivalent. You could do it either way. It does really matter. And so there was a general preference to do option number 2 with multiple tables. That was gonna be cleaner. Since then, the list discussion pointed out that they were not in fact equivalent, and I'll explain why. And because they're not in fact equivalent, Alexi and I both argued that this means we need to go for option one, which is the way that it already was. And so we've left that. And so that's why I'm gonna through here to explain why they're not equivalent and why we stuck with option number 1. Next slide, please. Okay. So, this is example, in option number 1, okay, And so in option number 1, there's a table with multiple key fields, right? So for the following opcodeplussourceplusimplusoffsetoffset Right. That 4 tuple has to be unique in the table. And the the description is what the meaning of that 4 tuple is. Right. And so you'll notice here in opcode 17, right, source is 0 and offset is 0. Take take I am in as wildcarded, but it's really offco opco to specified sources specified offset Compare that to option 2 version. Next slide. This was the, option 2 version, which said because there's only one thing using opcode 17, Then opcode 17 means that an opcode 0 hex 18 has multiple things that are distinguished by source and there's a separate table for that. The problem with this one"
  },
  {
    "startTime": "00:08:01",
    "text": "is, you notice, go back a slide, please. This one says only one source equals 0. Go forward 1. This one says, All of source is now defined to be this. And so it consumes a lot more of the address space than the option 1 does. So this one wastes lots of space and consumes potentially a scarce resources, or, no, eventually it may become scarce, right? And so option number 1 is actually more specific therefore, they're not equivalent. So we went with more specific one to not just, you know, waste space here out and there all over the place. Okay. that's why we'd left it there because this point was not part of the discussion last time when we thought it was So place. And so explaining why we did not make the change. We kind of agreed on in in IITF because of the subsequent discussion. Confirmation on the list reversed that consensus because of new information. Okay. Over changes. And so this is where a number of people have authored contributions. That have been merged into the main RST file from which mean in that draft is is generated. And you can see the, contributors of the authors, those contributions over there on brackets. Will, who's the one that gave a presentation, at IITF117, added some, informative text. It planning a tight convention and a glossary definition so that you can understand the they'll turn the documents Jose Define or corrected, there was to errors in the in the document around the definitions of Vpf neg and Vpf call. So Jose and will fix those. Previously, the document used the mix of and ebpf interchangeably, so that was made consistent throughout. Then there was a few typos that I fixed in the op codepenetics where the op codepenetics is informative, it's supposed to match up. What was in the body. And so, like, I had to mirror the corrected definitions and things like that. There was a number of new instructions added since last time by, Yong Hong and"
  },
  {
    "startTime": "00:10:00",
    "text": "through those in later slides. Right? Last time we talked about, we expect it to be to instructions. There needs to be a process for instructions. And so now we're kind of exercising that. I, I, And so they're so we'll talk through that in the next couple slides. Right. So all these are things that are already in the published document right now that's the draft I ETF, VPFisa00. Next slide. Okay. Here's a quick list of the new instructions. Okay. I'm not gonna walk through those. Most of those are kinda explanatory signed division in Modulo Turns out there's actually many definitions of sign Modulo, read the Wikipedia article or other ones for many different definitions. System defines it as being truncated division. Which is, by the way, is the normal one for C, right, but different languages have different variations of of sign modulo, move and load on extension unconditional byte swap as opposed to, like, little lending or big union. This one says regardless of the need of of your, or, of your processor, do a byte swap. And then jump with a 32 bit offset where previously the instruction was to jump with a team that offset So those are different new instructions that have been added into the tables and and new, tuples, consumed. And there's a number of implementations that are already out there. The llvm, often known as Clang, compiler edit these as CPU V Four instructions, the GCC compiler's been adding support. The Linux kernel verifier and Jit compiler have support and other implementations are also in progress across these instructions right now. So it's already out there. There's already interoperability. We're just documenting what's already out there as more and more implementations. Do it. Want them to do it the same Next slide. Okay. Now to the main topic that I asked to be an agenda for, so we start I started a thread on the mailing list, and then I'm gonna walk through the details here. And when we say There is one remaining open issue that we know of, This is it. K. If we get done with this one and everything that falls out of this one,"
  },
  {
    "startTime": "00:12:01",
    "text": "Then in theory, we're done. Right? Okay. Unless somebody finds new, you know, typos or new, you know, errors or whatever it is. But there's only one open issue. And this is Okay. So, background, There's a number of things that are producers of this, right, things that generate instructions. Right? So compilers like Clang and GCC and so on, some applications use, generate, IPF byte code directly without being compiled from a source language like c or Rust or whatever. They just generate and use the byte code directly. Unless there is test suites to exercise things. Right? So those generate instructions. On the conceptual receiving side, the parsing side, a number of things, there are partiers. Right? Verifiers or parsers, jit compilers, interpreters, disassemblers are part service. Right? And so there needs to be a way for generators and parsers to have the same way to refer to a set of things that are mandatory. Right? And so, if a, if a runtime says, well, I have this verifier and this Jit compiler, and I the following instruction set, I gotta be able to tell a compiler to generate instructions that will work with that particular set of things that run time will work. Right? So how do we negotiate which instructions those are. So a compiler doesn't start using optimizations They put in instructions that the percher does not understand. Right? So you just have to have a way to label those, right, Whether that's in a documentation that humans read whether that's in something that can be done like they queried, doesn't matter. You first have to agree on how do you name things? How do you label things? How do you label What's the unit of conformance? Hey, so this once you have a way to label them, then you could do, you know, dynamic version or capability negotiation, or you could just have it be in documentation. Humans read it in use command line options to say the compiler to say generate CPU version 4. But that means you gotta have a way to name what does CPU version 4 mean, right, when the next thing comes along."
  },
  {
    "startTime": "00:14:01",
    "text": "What is the next thing called? And are everything gonna use the compiler is gonna use the same label for it and so on. So this is what I was asking. And so what is the what are those? What's the convention how do you map those 2 instructions? That's the last thing that's not in the document now. So let's walk through this. Next slide. Okay. So second piece of background is that, and I'll get to this one at the end. So I want you to think about this, and I'm gonna have part of the questions for this one at the end so that you don't have to ask questions about it now on clarifying because I'm first gonna walk through the proposal and then come back to this at the there's the last one. There's lots of different things here that may not be mandatory. There's really 2 categories they'll be talking about One is categories that, there might be other existing ways to do, and this is a more efficient way to do k. So now with a new instruction, you can do it in 1, where previously it took 3 instructions to do the same thing So now a compiler can say, if it supports the new optimized way, I'll generate the new optimized instruction. If it doesn't, I'll do it the slow way and generate 3 instructions. Right? So some of these are ones that says, well, The source code is gonna be the source code either way. And it's whether they show up or not. K. That's the 1st category. There's a bunch of stuff in there. Things like, you know, unconditional byte swap. I can do that in one instruction. K? If it's the if the instruction is there previously, I had to do multiple instructions to do that. K. There's a category that's the one I'm gonna talk about at the end, which is support for specific constructs. K. Things that if you're right at a program, there's just no other way to do. It's either there or it's not there. K? So can you call a function that is exported by the runtime? Or can you not call it And we'll talk about that later. Alright. Alright. So one of my goals, which may or may not be the working group school, and I'll ask that as a question later on. Is to keep existing deployments compliant. Right? So since our working group charter says we try to document existing practice, that's one of the"
  },
  {
    "startTime": "00:16:01",
    "text": "that we'll ask at the end because I don't know what the consensus is gonna be on this one. I wanna ask the question. Alright. Next slide. Alright. Some possible units of granularity, right, So I said, this is bust. There's shoes. There's maze. Whatever it is. Whether you call it that, some other way of expressing units of conformance, We've talked about there can be extensions and other documents. There could be, you know, proprietary extensions or at least, you know, platform specific extensions, really. In other documents and places and so on. So how do you what's the unit of granularity of saying support, the set of stuff. Well, you could have all the way go down and say, every individual instruction is a should you can in you can pick and choose among instructions. That's not really practical because you have an explosion thing. You can say, well, I support the following you know, 1000 things and somebody else supports a different 1000 It's just not practical to use in in any real deployment. So That's possible, but I'm certainly not gonna argue for Then there's kind of what's existing practice, what stems originally from Clang and GCC has kind of adopted the same kind of conventions here. And so there you have things like is CPUvonev2v3v4. That concept was created by Clang and has now been copied in GCC but does it apply to other compilers? Like, as couple of rust and the compiler has a drop there. Are they gonna adopt the same conventions? Should they that depends on what we say here. K? There are some things that don't exactly map to CPU versions, and I'll go into this in more detail on the next slide. And so, for example, when, 32 bit arithmetic instructions were added. Right. Normally, they're 64 bit, but you could add to a 32 bit with, 0 extension and so on. Those were added, the CPU version wasn't red and it was called, target feature aou32. Litter on it was rolled in the in the CPU version 3. Initially, there was a set that was the AOU 32 set of stuff. And"
  },
  {
    "startTime": "00:18:00",
    "text": "genality. Right. Right. Between 2 and 3, they had, you know, another arithmetic instruction and a jump instruction and a that there there's just a collection of things that were all put into e3. So this one is kind of existing practice, but it doesn't really correlate any other than historical, you'll Suff. Dave, David has a question online. Yeah, do you wanna interrupt or you wanna wait till the end of the I can wait till the end of the slide. Okay. Alright. Can we finish up and then then go ahead. And then finally, you could do things like, well, let's group, all things that are in the same unit of functionality. Like, all the things that are atomic construct or all the things that are kind of of the same type. The problem is there's nothing in code that means just because you in support one that you have that that's not like they go together necessarily. Right? Logical unit of functionality isn't something you have to support the whole set where it's meaningless. Right? So it's not a strong reason to do that. And the reason against it is, well, it doesn't match historical practice. Right? These are the things that have been discussed on the list here, and I, you know, as you I'm gonna be going for a variation of the middle category here. First, we got David and then Kristoff online before I go through the proposal. I can't wait to see what your proposal is. I'll let Kristoff know that I can chime in after Yeah. I'm actually happy to wait a bit too. I just wanted to place my notice that I'm gonna say something about this I couldn't make out Christophe, anyway else. And the the audio. Don't know what's up with the audio. I'll throw it in a chat then. But said that he's happy to wait for a couple 1 or 2 slides. He just wanted to Thank you. Alright. So we'll wait for a couple more, but, yeah, feel free to jump back online. Alright. Let's go on to the next slide then. Alright. So this one is still background that this is just showing this is taken from the GCC Wiki And you'll see it kind of mirrors the client compiler options. So, the way to read this is CPU equals V2. So first, there was a"
  },
  {
    "startTime": "00:20:00",
    "text": "CPUvone and then jump EXT was added and then equalsb2includes jump EXT and maybe some other stuff. Take and then jump 32, ALU 32, and V3 atomics that were other, you know, categories that were added and the CPU V3 includes those 3 things. So if you specify CPU V3, it means all of V2 plus jump 32 plus ALU do plus V3 atomics. K. CPU V4 was just added, which includes all of CPU V3 plus p swap, s div, and s move as separate options. Right? So you can say, I want CPU V 4, but set for SDV. You can individually toggle these groups on and off and GCC. Right? But the point is these are labels and they reuse some of the labels that, client use. Right. The CPU equals v, whatever convention, you see AOU 32 on there, Right. The point is both of the major compilers are using the same kind of convention here of using strings with CPU equals v to wrap things that are categories of stuff. Okay? So that's the existing, stuff that's out there now. That we can use to help inform were gonna do this in the future, What do you wanna do? And I'm gonna argue best example of being knowing what we wanna do in the future is look at what we've already and say if it's been working and nobody's been complaining on it, let's try to say, let's try to sit. This is a precedent. Say this is the way to do things going forward is to do things we've done in the past. Okay? That's where my proposal's gonna come from. Is it saying, If it ain't broke, go fix it. K. I see Kristoff is still queue. So I think I have a proposal slide. You can just tip ahead of your check it yourself. But otherwise, you can ask ask an hour or wait till after the proposal slide. Yeah. Let's see if Crystal can talk now. K. Stop. Go ahead. Both of them. Okay. Alright. Let's go. He's just waiting in the queue. Alright. This is the proposal, and I think I have an example on the next slide. So The proposal is to create, meaning an example of what the registry Like, I'd like to propose that we create a new Iener registry. Okay. The inner registry would have string labels,"
  },
  {
    "startTime": "00:22:02",
    "text": "string labels to be things like, right, if we were to retroactively things that just just as an example, right, they would have things like AOU32, CPU equals V3, CPU equals V4 would be the string labels, I enter registry. Why? Because they have to be unique, And because you don't have to be in the IOTF, to register instructions, right? That was the, permanent provisional and historical provisional did not require IETF so anybody can register provisional So that means somebody can generate a string. So you gotta have a registry to make sure there's no collisions. Right. We create a string registry. Each label corresponds to some set of instructions Right? Set the label is about points to some spec that says, what the instructions are that are mandatory for this k. Each instruction that's defined has to have 1 or maybe more, and I'll give you a more example later on, but typically one label that is part of. Okay? So here's an instruction, and this is part of the ALU Thirty 2 group. Whatever it is. An implementation K. Whether that implementation is that parser generated, but typically we think of this as the parser side, right, like a the Linux hurdle or, the llvmdashopsdumpdisassembler. Like that. Right? It supports a set of labels. K? Not just one set of labels. It could say at one point in history, it was, you know, CPU equals V2plusalu32. Right? Was a point history right before CPU V3 was snap. Right? And so just think of that as the next version, and this is the this is the analogy. For, you know, same thing 2 years from now and it's just different label Now this shows just like in the nesting slide of GCC that I showed, the groups can be nested, right? CPU equals V3 includes ALU 32. You have a way to express that. And when you do find a specification, whether it's in the IUTF or fro some provisional thing that's outside the IETF. Then you would be responsible for defining if you're doing new instructions."
  },
  {
    "startTime": "00:24:01",
    "text": "1 or more, if necessary, conformance groups, for those instructions. So then when the base spec, we would have more than 1, and I'll explain why. And then any instructions that you would think of kinda like a should or whatever. That means it's in a different conformance group than the ones that are musts. Good. Good. So if somebody does not support them, then it K. then it is missing that label in its list of what it supports. Okay? then Ayanna allocation policies, I'm gonna propose exactly the same And instructions. Right? You're gonna register these at the same time as you're registering instructions. Me, it makes sense to have exact the same registration policies that I showed on the 2nd slide k? This is the proposal. That I have anyway, feel free to, you know, beat it up or suggest alternatives. But let me show you an example Next slide. K. This is the example of what something might look like. And again, I'm retroactively using old stuff here just so we can kind of see what it would look like if this had existed 5 years ago, right, So this is not the entire table. Right? This is just showing a a snippet of it to get the point. This example, there's 3 conformance groups Those 3 conformance groups are labeled, legacy, which I made up ALU 32 and CPU equals V3. And not shown as like a CPU equals V2 label. Also on the table. And you can see all three of these point to the current document. K? K? That that that the the which right now is the internet draft. And you can see there's late there's row there's columns for includes and excludes. Right? I say Once CPU V3 came out, then that said it's all of CPU equals V2 plus the other conformance groups that rolled into plus maybe any instructions that are directly labeled CPU equalsv3. Right. This says it includes all of CPU V2. So if there's some instruction that says CPU equals V2, you don't have to relabel it in the instruction table. K? Just say a CPU V2, but CPU V3 means all the instructions which have the label CPU equals V3 plus all the instructions have the label CPU equals to anything it includes. Right? This is recursive. Right? Plus any instructions that have ALU 32."
  },
  {
    "startTime": "00:26:01",
    "text": "Minus any instructions that have a legal legacy. So why legacy? Well, we have the notion of deprecation. Right? We've kind of already done this nuts. Okay. We have, you can see in the bottom table here, this is just showing the instruction table. And all I've done here in this proposal is I've added another column on the right. Everything other than the conformance group column there is what we talked about last says add another column. And in this example, there's only one, one label in each, in each sell there. There's never any case there's 2. K? That's because we're starting with one that's already legacy. Anything that's deprecated, we stick in the legacy label, and this is just showing what would happen if 3 years from now, we wanted to deprecate an existing instruction. We'd already have, say, CPU equals before or something in that column. How do we deprecate it? Okay. What you would do is you'd and add besides CPUs before, you'd add another label, which is, you know, legacy 2 or something like that that you make up. Now it has 2 labels there. And in the conformance groups, they would say, you know, CPU was V5 means you was before excluding legacy 2. Okay. That's how you express that. Okay. So this right here is the end of the proposal part the rest is kind of fallout from what happens if you do this. Okay. So if you have questions from the mic, please come to the mic now on the opposed part because if we kind of sort of agree with this, it gets down into the details, and that's the subsequent slides. Yeah. I do have a question there. So this means like any new instruction needs to have confirmation in this, like, performance group info. For sure. Right? It's not available. I made up the turn conformance group. It's a label Yeah. So it needs to have it. Right? Like, so is there gonna be a default label that things fall into some request one. Yeah. Every instruction here must have a Confirmence group as my is there gonna be a default one that we fall into? People don't wanna specify one, There is no default. All the rest that falls out from it is on subsequent slides. So"
  },
  {
    "startTime": "00:28:04",
    "text": "and the, I mean, in the AENA registry, the, how you would apply for an addition here, this would be must be present. Right. Meaning it must reference something in the conformance groups registry. Is the way I would write the text if we, if we think this is a good way and the mapping between the instruction and the conformance group is like gonna be verified using expert review or whatever policy we come up with. Right? Not just the performance group, but the mapping as well. The instructions, that needs to go through the review as well. Yeah. Yeah. Yeah. Okay. We got a queue. Kristoff, you can go first, Kristoff. Okay. So when I compare this, how the like, optional instruction support works in, like, actual CPU architectures. I see a lot of similarities and one major difference. And If you look at like X86 or risk 5 which I most familiar with and I think arm works pretty similar, but I'm not quite as, knowledgeable there. Is that instead of doing two things in the group, which is reference actual instructions and reference other groups they usually split it in 2 different concepts. So you have like, a low level group that is basically set instructions. And then you have a more higher level thing, which an arm like is the CPU, the instructions said version and in risk 5, it's short hands, that basically are a just a convenience handle for a bunch of groups that is off more marketing name, but also very similar to say pass it to compilers and and I think that's actually in many ways less confused Right? So in your examples, we'd still have, say, the"
  },
  {
    "startTime": "00:30:04",
    "text": "ALU 32 group, and then the other instructions that that basically anything would need to have shred hand name for the extension. And then you do something like the CPU v2v3v4 as a grouping of the useful baseline that happens at a hopefully very low cadence. Of So the audio of this room is not great. There was some distortion there. I'm gonna tell you what I think that I heard because I'm not sure. If I understood you're right or maybe it's a question, Did you say that, what you're familiar with was a case where everything had a group that was like a AAU 32, and there was a separate layer that was CPU V3. And so in your, preference, like in the bottom table, you'd never see CPU equals V2 or CPU equals V3. You don't wanna see a more specific one that was then wrapped in a CPU v 2 would be 3. Is that what you were saying? Because I'm I'm not Yes. Yes. That was the biggest part of it. And then I probably give the bigger, say, marketing name or high level grouping, a different name than Conformance Group. That's yep. Okay. Let's see who else is in the queue. Thank you. And David Yeah. I I was just gonna say, I mean, I think overall, like, the the Conformis group label approach seems reasonable. Like, it's flexible enough be able to to do what we did. I do I'm not sure how I feel about using and I'm not sure if you were just using this as an phone up, but CPU equals v2, CPU equals v3, We've pointed this out before, but it really is very just like circumstantial and historical how those played out with, the LVM releases. Right? It was like whatever instruction people needed they would add them and then LVM would do a release and then have the CPU version There was no other kind of higher level like reason, right? For it. So I think if we're gonna group"
  },
  {
    "startTime": "00:32:01",
    "text": "instructions by by, like, typing, like, a thing that makes sense to me. I know that Alexa that it can we can also invite Sean but as far as grieving, grouping it by CPU version, I'm not really following exactly what that would buy beyond just for some reason matching LVM, Yeah. Okay. Again, audio is a little bit garbled, so I'm kind of trying to read the, text, transcription of David's comments I've think we're I'm my response to Kristoff, which might be the same thing as you were saying, David, is if you have a, let's say you went to CPU V5 and all you did is you added one jump instruction, 1 ALU instruction, and 1 atomic. Or something like that. Right? It wouldn't make sense to have 3 conformance groups with a single instruction just to have the CPU V5. So that's why I like the proposal here as being probably, less registrations than having a strict 2 level 1 as Christophos are agreeing, but I don't feel strongly either way. So seems to add some of the other stuff. Thanks, Alexis. So, to playing the point about, bike shading that, David sort of referred to. All of this CPU we want, we do the 34, They, legacy affected it. This is how, like, the first in the first place, the name CPU is there only because an OVM that was an existing flag. And we had, like, no bad idea. Just to call me one with 2 or 3, And but all of this, like, audio flag, like, hail usage 2, they actually already did the version between GCC and Clank. GCC choose to, like, at different flags for the for the VM"
  },
  {
    "startTime": "00:34:02",
    "text": "some of those flags we actually edit later, not necessarily as part of the grouping, but is a way to, like, test impeller and a verifier and, like, the whole tool So the grouping that they have like a jumps and lures and everything. They're not necessarily that meaningful. Like, if we do this, kind of grouping for for the purpose of the sensitization for real. We need to go back and really look at all instructions and then, like, group them into new new, some sort of groups. And but most likely, this will be only for the standard. Itself and not for the compiler. Like, in a compiler, we already have flags. We don't want to, like, break them or suddenly change behavior either of GCC of OLVM, and they already, like, different, So doing the exercise of the grouping on one side kind of makes sense. And logically, the way you explained it and especially like the crystal analogy to 5. Makes sense. But to me, it feels little bit, like, ways that effort because the compiler is already different. This is stuff in the wild. And the future MCP UV5. Will actually, talk on my slides, like, 2 possible new instructions that we might add as part of CPU V5. They don't they probably falls into well, not even atomics. They fall into, like, new instructions. I don't even know how to group them. So, Though I like what you're proposing here, I see a hard time. Like, it feels to me that this is, like, very quickly becomes a bikeshade and exercise. K. I think the notion that CCC and the client have different definitions of what ALU 32 means is an important point. And so keep this in mind as to say, this is my analogy to say it that If we would have done this 5 years ago, then they would have had the same definition."
  },
  {
    "startTime": "00:36:01",
    "text": "Right? That's the analysis. Alright. Say, if we were to do this in the future, if we define string here, if inclined and GCC can then use the same string. Or at least they can coordinate at the same time as we're putting into this document, than arbitrarily doing things. So the proposal here is to reduce cases ideally limited to the extent that people confirmed RFCs right, cases where they diverge in the future. Right? We can't do anything about backward stuff, but future stuff, hopefully, we can help with. That's my fan. I wanna go to the questions now because I'm expecting oh, there's one more person. Yeah. Kristoff is in go ahead. Good stuff. Excuse me. Good stuff. Did you wanna say something? Yes, but it helps if I unmute myself first. So I I I wanna get back a little more into what Aleksey said. Right? I mean, our grouping, as of right now should not be based on how instructions were historically developed and supported in compilers I think what we need to make sure is for all the instructions we have in the ISA document right now, we need to figure out which of those are mandatory and which are all optional and water useful groupings for those through optional. And provide a good extensibility mechanism for the future. And And I think, Dave mentioned earlier, there's something about having a assisting implementations conform. And I think that's a nice to have, especially for important in the sense of market year. Implementations, but it's not a rational per se. I mean, if we do the right thing and that means No existing implementation is conforming. I think that's okay. At least if we can easily bring them into conformance, but not mandatory. Alright. Thank you, Kristoff. That's a good segue to the actual questions because this part was to say, Do we agree on the exist, I'm having conformance groups with labels as a way to describe stuff in the future."
  },
  {
    "startTime": "00:38:02",
    "text": "If the answer is yes, then I can ask the questions using that terminology it sounds like I haven't heard anybody arguing against that for future things. Only about problems with deploying it to maybe backwards things. There's, maybe some issues there. So am I okay, asking the questions now? Great. Let's see. Just a quick comment about conformance, they will set, like, a is Linux kernel is come format and with what? A confirmed wisdom CPU before? If Maybe. Then it depends what architecture we're talking about. It's supported fully. On next 86 on ARM 64 and S390 as far as I remember, but not another architectures. But then is kernel overall on all architectures conformance with V3 The answer is similar. No. Is conforming even with Vivan, the answer is also no. So, like, if you look at some, like, specific architecture, like, user modeling. DPF doesn't even exist there. So There's conformance. It's, like, his windows conformance or anything. Yeah. If you have a particular running system, that system will be conformant to some set of labels. Right? If you save the Linux kernel, that can be running on many different systems. Nope. Arm, X Eighty 6, risk, etcetera, that may all have different of labels and stuff across them. For any particular system, the intent is a set of labels that apply which typically would be a operating system version plus CPU Architecture Combination, but it may be more than just that. It's like offload card or whatever. So Alright. I wanna ask my questions now and use this as the as the phrasing of the question. The meaning when I wrote the text of what conformance groups do we use as the base is the spec baseline. Right? So we've got a table of a bunch of in the initial anti registry. Okay?"
  },
  {
    "startTime": "00:40:01",
    "text": "We agree that there's gonna be some labels next to every instruction, we figure out what labels go in the table initially. Paid Do we say every row in a table has one either legacy, which are the deprecated ones, and CPU was before or some other label if you like, some other label better. So there's only 2 right now. It's everything that's not and everything is deprecated. Or is it some other finer granularity? Okay? So if you said, well, I want some in market ones to be compliant, then that means they won't have CPU V Four if they're in market because the newest thing, and they haven't gotten to be widely deployed yet, at least in some cases. And so should you say, well, here's all the ones that are beef 3, and then here's the ones that were added in V Four so that some things can say they were compliant to V free, Or do we just say, no, we're just gonna snap and say V4 and they're just not rfc compliant? This is the number one question. Okay? And there's things that are maybe not it would be nice. Like Christophe said, I think it's the same. It would be nice if could say, well, I'm conforming to CPU equals v 3 label for the, end market devices. And see if you because 4 is what we recommend going forward, and please do that. I would love to say that. Other people might love to say, let's just make everything the VV for, and we don't care if our FC client or not. Right? Right? For me, it's nice. And so this is the question number 1. And so I think, Christophe, you wanted to weigh in on that one too. As you're in the queue, so go ahead. Yeah. I mean, as as Alex said, I mean, whatever we do, we should not use CPU V3 or V4 as names. Even if we end up fully mapping to that, we should give them meaningful names. This is number 1. The other is especially from the NVMe background where we have some use for upcoming things. That there we have program types where at all makes absolutely don't make sense for kinds of programs, So I really love to be able to have a base line that just doesn't have any atomics because I think even in the long run, there's specific program types where atomics just don't make sense, and there's it would be good to disallow them."
  },
  {
    "startTime": "00:42:01",
    "text": "Otherwise, I let people that have more deployed things in there, but I I I can I can definitely go with your recommendation of having an equivalent of CPU w3 as of the legacy baseline as long as it has a better name, I could also see the argument that we wanna do the full thing? And I think someone like Alexey who has more insight how things are deployed and how hard are all the new instructions to bring into him and implementation chime in then try too smart as here. Okay. So I to to to two high level points out of that. And so I've been watching the transcription here to make sure I've been following I think one of your main points is, You like the concept, but you don't like the name CPU V Three. So as long as we change the label to something more meaningful, then you like that idea, including whatever CPU V3 that's some subset of stuff is in there. That's your first main point. And I think your second main point that I saw was actually in response second question, which is you think that the, atomics should be in its own, a conformance group. And that, I think, was it proposal that's gonna be relevant to my second question k. Let me know if I got that wrong, but I think that was your 2 high level points. Everything else kinda fit a lot of those 2 high level So he's saying yes in chat. Thank you. Alright. So I'm gonna ask my second question I mentioned I was gonna come back to this earlier on. I said there's some constructs that are highly visible in source code. It's not like they're part of an optimization. You either can map this to exceed BPS or you can't. A And so one example is can I call some function that's exported by the runtime? Okay? There's some instructions for that. So call helper function by BTF ID, call helper function by address, which is the older one. And so you could say, well, if I have a runtime, let's say it's an offload card, actually exports no helper functions. It just does, you know, a program type and you can"
  },
  {
    "startTime": "00:44:02",
    "text": "turn some values that say, you know, drop or pass or whatever it is, but there's no helper functions exposed. If I don't support the instructions to call functions that don't exist, am I so compliant. Okay. I would argue, yes, you should be because there's no possible use for them on that particular thing. Right? And so you could argue the same thing could happen for things like instructions that are in the a bit of medias like, the address of a runtime platform variable. If you have no platform variables, then there's no such thing as an instruction to reference 1. If you have some architecture that doesn't have a concept of a map some reason. I don't know if there is one, but hypothetically, then getting in the instruction of the first value, the map would have no value. Okay? There are instructions that have these things. So couple ways that you one could go about these. One is to say you could put those in its own conformance group, Okay? And by the way, atomics are in this too because atomics are specific Other things that show up in your source code. I think in Alexis's slides show some examples of of this and his slides. You'll see that later on. Is to say, okay, as long as you don't write program that does those, the compiler can still map it. Right? Should that be in its own conformance group? K? That would be kind of what, Christophe was proposing. Could you put them in the same performance group and say it's conditionally mandatory? Well, you must support these instructions if you actually export any runtime function. Are you much in sport the the run time platform variable, as long as if you actually have any platform variables, then you must support this instruction. It'll be conditionally mandatory because you wouldn't have to have a separate confirm this group, but either apply or not apply. 5-five and so that'd be another way to do it. And I'm not sure between those two, I'm open for input there, but we can't be done until we a decision there. And so I at least heard Kristoff arguing for a separate performance group, but that was before I specific possibilities. So I don't care. I just wanna know what people have opinions on this we gotta come to something to put it into the document before it can be done. Alright. Q. I think Yeah. it's So, yeah, I I just wanna kind of"
  },
  {
    "startTime": "00:46:02",
    "text": "reiterate what I was saying earlier. Like, I I really don't see why having a beat 3 would would like it it it feels like we're just we would just have a v 3 conformance because that's how it is. Right? But, like, having having conformance groups that reflect the actual behavior of the instructions is feels much more it reflects kind of the intention a lot more. Right? Like if you're if you're implementing some porting offload or whatever. You you're you have a reason for it. You probably have a specific set of use that you're trying to enable And I think having just a group of b3 CPU v 3 instructions just because that's what LVM supported at the time. I mean, it's we we could. I I just don't really see like like why that would be useful to anybody? So Yeah. I I I think for me, at least having having separate performance groups makes makes a lot more that's k. I think I mentioned that. Next. Would like to provide some historical the ground of how, CPU history came about. So with starches. So Netronom started working on the floating VBF into the Nick. Into the smart And very quickly, they realized that 64 bit architecture and 64 bit registers for them don't really work well because internally, they have, like, set you to bid So the whole LU suited to and In particular, I see the 3 was pretty much located to ease the of floating or VPN instruction set into hardware. But And, like, they actually did, like, amazing job. Like, we worked together, like, different companies to achieve this, great result but the band out of CPU V3, they decided not to implement few instructions. In particular, this was At that time, in every 3, we only had on-site division and module operations."
  },
  {
    "startTime": "00:48:00",
    "text": "And for the hardware, it just, like, didn't make sense. Like, they couldn't really do them in the hardware efficiently. So they support everything but division. And now in the CPU before, we have signed, module and division operations. So are they, like, divisions and logos should be in their own, like, category and grouping? Maybe, but that's what we can do just because, like, we know asked to learn from our mistakes and understand the history. But most likely what will happen when, let's say, if you have gets adopted by NVMe, Rimi also say that, well, we actually need new instructions on one side to both make our life easier. And at the same time, don't like those that already exist. And that would mean it add new grouping and reshuffling all of the grouping that already exists, just a comment, because you can have more than 1 group per instruction, it doesn't require tough Everything else that you said makes sense, but I'm sure I can answer doesn't require reshuffle. Sure. So, what I guess, I would like to propose is, instead of having this, like, the 2, the 3, 4, And in general, like, come 4 months, What? We can group different instructions into different categories like atomic LU operations, like jumps, conditionals, etcetera. And then whatever vendor they will just say what they actually support. Instead of having, like, label whether you conformant with whatever, the 3 before over the confirmed those atomics, It sees it for hardware or implementation runtime to say what they actually support. So what I'm proposing is to remove this, like, shoot a must distinctions from the standard and have one with the grouping and say, like, This is what the support Okay. We still have one more person in the queue. I mean, I can comment on that, but"
  },
  {
    "startTime": "00:50:00",
    "text": "to be an exotic participant. So it's trying to be Was that from chat? I mean, yeah, I I I'm like, I'm like, I'm So air air air ask, what happens when there's a new atomic? It goes into a new specification. I mean, assuming that this was already in RFC, I a context to your question. Does it already somebody has a new atomic. K. Has to be a new document that specifies to that so that you can register it in the inter registry. Because there's a new document, there's a new conformance It could only have one instruction, and it could have multiple things in it that's in that That's what happens. Yeah. It would not be part of the predefined atomics group. That's correct. It would be part of the Atomic 2 group, which in my proposal might include atomics, and there would be an atomics group that would include atomics, or or or completely separate if you did not want to have included. That's how you write the spec. So Yeah. And I think this this goes back. Sorry. With someone from I think Kristoff was last in queue. Okay. Sorry. And then and then I'll come back to my Yeah. So, I mean, I I I I think we need to clearly distinguish between, again, the 2 things is what amount of grouping do we want to do for the existing instruct and I think it's very clear we need at least an absolute minimum amount of grouping by getting rid of the legacy structions, And I think I've seen some interest including from Alex say to have a little more grouping than that, at least. And I'm not we need to decide on the exact grouping I I definitely prefer it to be a knock to find grain because that's gonna create problems. But the exact amount we need to find and for any future extensions, I would actually expect them to be fearly fine grained and I actually hope there's not gonna be too many of them anyway."
  },
  {
    "startTime": "00:52:04",
    "text": "Kristoff, how do you feel about the proposals instead of not have like should and must. And we group the instructions, but don't don't have any kind of compliance enforcement on enabling all of those in the group. Oh, I was actually gonna say something on that, get that your remind. I for instruction compliance, it should, I think, is a complete non starter. Should should compliance for instructions just doesn't work. We need a grouping and you need to be able to rely everything in that grouping, to be fully supported enemas. But I think Alexis point is that we've seen in practice that that actually isn't true. Right? Like, you don't have to support every instruction to provide the use case for offload or or whatever. No. No. Every instruction in a given group because your programs and your tool chains need to be able to rely on So you need to be able to pick the number of groups you want to support, but you need to be able to rely on them being fully supported, which I guess loops back into how do we find these groups to actually And then that kind of also loops into the the the danger of bike shedding that Alexis was was just and do as well. But, I mean, I think that makes sense. It's just can can we can we like create groups the confidence that are sufficiently granular to let, to let you know, to basically not Force. Off people offloading to like implement instructions they don't need or implement them inefficiently, but also not have like this should concept where you don't really have a lot of guarantees for the compliance. I don't know. Maybe we can I'm not sure Alright. So I'm gonna mention what I hear, what I heard, and then I'll jump in with my own opinion, and a think I agree with, the way that Kristoff was phrasing things just as a a"
  },
  {
    "startTime": "00:54:00",
    "text": "intro, if I understood things right. I think what I've heard is that, forget the labels that I was using the example. We take the existing instructions and we create a multiple conformance groups that make sense like, the legacy ones is one obvious example. But otherwise, things that make sense to either, not implement, like, Lex give the example of maybe division. If we know of cases or offload cards, do not want division, and that would be a fine example of something to put in a separate confirmatory atomics that Christian that that Kristoff mentioned, right, would be in a separate conformance script because we can we know of a technical argument for when you might not want to support that. I get the argument about, you know, platform variables. If you don't have that, then the plat anything around period was gonna separate confirm sweep, and everything else goes in the same k. And I've not called CPU was before they're called something more intelligent that we make k? Suggestions welcome off offline. But, But, and so then you have the set of those. And then Alexi S Eric said they asked a question or or at least implied a question I wanted to respond to, which is If that's all you did, and then over time, we start having a very large number of conformance threats. You say the following offload, compiled supports this subset of the confer of, you know, 15 conformance groups, and it supports this 13 of them. K. And so, one of the reasons that I like having some higher level concept. Right? Kristoff raised it as another level of stuff. I phrase it just another label that includes, and excludes. The reason I like doing that is it, makes implementation a lot easier if you're say, well, this is gonna map to things like, you know, command line options or things in a, in a yaml file or whatever that are labeled to say want to tell my compiler to use the following groups and not use the other groups. How do I do that? If I can do it with 2 or 3 instead of having to type in or have my file 13 of them, that's better. Was something that means like CPU equals V4 that includes the following groups. If there's common sets things than having a label for that. Makes it easier for people to type and use in practice."
  },
  {
    "startTime": "00:56:02",
    "text": "It doesn't there's nothing you can do that you can't do by having 13 of them. It's just easier. So it's pure preference. That was my answer. But otherwise, I think I agree with what, Christophe and David and others were saying, just pick different labels, pick things that are logical units and only create them now where we know of cases where it makes sense to not support them. K. Everything else that we don't know if a case to not support just goes in the base confirms. That that's run taking away as as what I've heard. So and just clarify one thing, David. Right? Way to do that would be to use an exclude as well, right, in addition, like, if Christophe knows something is not supported. Maybe they can do a exclude roof at that. The reason for that I put in excludes originally was to do a deprecation. But what I've heard here is there's another case that would actually motivate using that X Food column that says, if I say, I wanna support all the following, you know, ALU instructions, except for that one, because of a reason we can't think of right now. I could define a new group that says all of those, but then add this other label to just that one, and it finds a more convenient way to in a registry at without without without It's it's the same thing as adding another label to all all but one of them, but it's a little bit easier to say add one label and add, an boots rolling there. So it's a little bit easier on the end of registration. But I believe that this is I said this last meeting and I was wrong because both things are equivalent. Right? So Thanks. Yaron. I think you're on the room. Okay. At Any other comments? Because this is, this is into Mind sale, Iran, chef, I'm a tourist here. So please take my word with this in mind, to two points coming from the CPU world like physical hardware CPUs. One is, CPU ID has worked for the X86 ecosystem for 30 years. The X86 ecosystem is complex. Multiple, vendors and so on. Maybe there's something to be learned from them."
  },
  {
    "startTime": "00:58:00",
    "text": "My second comment is about strictness so if I support this and this and this compliance groups. What is the expectation if I as an interpreter receive in unsupported instruction I would say this is all about security and use you must issue an exception but, sort of hearing the per case and it's it's not quite clear from the discussion here. What is, stance about that? Thank you. That there are a couple straightforward answers, but I don't wanna take up Alexi's time. I'm out of time here, and I wanna make sure time to see Alex's cool slides, And so I wanna seed all the rest of the time to Alexei. So Thanks, everyone. The last question is, another co editor, great for the acceptance. So go ahead. Kristoff, did you have a Yeah. I just wanted to throw in, and we don't have to discuss this to the end. I'm very skeptical of the excludes concept because it's just a way that that that like skyrockets the amount of complexity, and we can think about a bit more of this offline. Okay. Thank you. Alexi. Yep. K. I would rather But what I need network go on your meter call request, permission and you'll get permission. Go on the meter. Your sender here. Yeah."
  },
  {
    "startTime": "01:00:06",
    "text": "Yeah, use the presets we can follow-up Alright. Sure. Hello, everyone. Thank you for joining. First time presenting at the ATF. So and especially I'm presenting not my slides and presenting, but most of the work and the slides were done by Paul McKinney who, just have been doing the memory model work I'm a messenger Agendas, I have plenty of slides so feel free to, ask questions as they go it's more informational with, and hopefully a good discussion starter for many of the things. Or I can 1st I will try to disambiguate the language and abbreviations that people often use on the mailing list. Because I think some of the disconnect happened because it's not"
  },
  {
    "startTime": "01:02:03",
    "text": "people using the same names, but they actually mean different things to different people. So I will start with, PSABI which is processor specific API. And for all so it's, it's defined for all CPUs. Like X CG6 and arm and risk, etcetera. And in particular, it is defined for Bpf. So Bpf is this virtual CPU and that's So all of this, ABI, PSABIs, then include in the first place is, calling mention how, how arguments have been passed from one function to another. The second biggest is, type convention, meaning what is what is the size of, like, point or on this particular CPU and architecture. Then they define L format, but not the l formats that, Dave Taylor, cares about. It's a different outfits. What relocations exist in health. And other things like this. Then People often confuse code model and address space definition and the instruction set with actual memory model. So Here, I want to make it clear that PSABIs and memory model, I two, different things. And sometimes, like, for example, in the 5 PSABI, they confuse people probably even more than they are talking about atomics and how atomics mapped to the architecture which kinda supposed to be covered by the memory model documentation, but It's like 5% of it somehow appeared in the prescribed So what the PSABI is actually even there for for all, architectures except DPF, essentially, it's a manual for the compilers. It's a what comp how when the compiler sees a c code, how they supposed to generate assembly out of it. Like, what decisions they need to make when they see, like,"
  },
  {
    "startTime": "01:04:00",
    "text": "Pointer void star. What is the size of it? When they see, like, a long, like, what's the size of the long on this particular architecture. Long can actually can be different between, like, Windows and Linux, but it's part of this PSABI that's that define, this kind of stuff. So domain you take away from here is without PSABI, compilers cannot do their job. So it's and at the same time, the existence of the compiler for a CPU means that there is a PS API what it means for a Bpf instruction set VPN, it actually means 2 things. And we are in unique position unlike all other architectures. For It's, manual for the compiler to translate from CC plus plus RAS into DPF instruction set. And at the same time, it's a manual for jits that take the ABF instruction and then translate it to 90 So what Jits do, they have to this, do this, complicated exercise of blending multi all PS APIs. So let's say we're looking at XH6JET XH6JET knows how X86 PSABI looks and it needs to understand BPPS API. And map the DPF instruction set into X 66 in a way that both that is still, compliant and still following 2 different TS APIs. So that's actually, like, when people look at what was the challenge us what was the challenge of, like, creating DPF instruction set is not the instruction set self, like picking the bits in a in a registry, but the ad is gonna be 1 or 2, is an easy part. Defining the FPS API in a way that it's mappable to different, native architectures is the biggest challenge that Bpf inspection. So it's solved. So, The PFPSABI exists,"
  },
  {
    "startTime": "01:06:00",
    "text": "Unfortunately, today, it's a big book full of blank pages. And I would say 80% of those pages have text on them, but it's an invisible text. Like, it's not something that we can even change. Like, the text is not yet written. But there is no, like, ambiguity what it's gonna be. And this is because compilers today, like bust all the M and GCC, generate the code. They they already made the decision the calling convention is gonna look like. Types, the size of the pointers, etcetera, etcetera, how stack is being managed, what's stack and winding. It's, but this 20% is undefined yet. The example of undefined this would be floating point. There's no floating point registers or operations in ISA. But in any other CPU, they are part of PSABI as well. Like, how are you even, passwords and points from one function to another. Or another example would be thread local storage. Thread local storage not necessarily makes sense. For something like but compilers have to do something when they see _ go straight. India variables. So they have to map to TLS And this is, like, the exact a category of what PSAD defines. So this is 120% that we would need to define. For, like, PSABH to be complete. Now, to the memory model. So as I said, the completely, it's a different, big document. 6, And, PS API is about single, single CPU is how to translate a high 11 language, like a cc plus plus into assembly. Without thinking about concurrency issues. Memory model addresses the second part of this problem is explaining to the compilers and to the users what to do with the concurrent text concurrent access when multiple CPUs let's say, running different VP of programs. Or when one CPU is running BPS and the kernel and another one in user space, or when it has a program in the kernel and another CPU"
  },
  {
    "startTime": "01:08:03",
    "text": "the actual real kernel code that potentially following a different memory model. So in the past, I will answer to this problem was just use Linux control memory model. And it's, difference in a unique advantage of language memory models see that it's a any language model. It's a strict subset. Hopefully in this kernel. So with AC for the kernel programming and then add extra restrictions that the programmers have to follow to become formal. For the for the code to make sense for the compiler not to mess it up. So that's, I just described, the length of, High language memory models being used by the compiler to run a straight instruction set, And then, jits, take the instructions and map it to X Thirty Six. They do it partially with this, PSABI. That's defined for cost. In this, like, in this invisible book, and due to the memory model. So that's where, What we're defining today is this new instruction level as we call it in a GPU memory model. So this, I would say, the most important slide of this presentation and understanding why defining DPFTS API and DPF memory model so unique and challenging in the industry because we're not solving what CPUs typically do. We're not, we are addressing two parts of this, like, equation that goes from the top, from the higher language into instruction and from the instruction set into into the hardware. When this translation translation happens, let's say on the next 86, Jits just map all of the Bpf instruction. So it's 2x86 1 to 1. But on things like a hardware float, like, smart knicks, it's actually a completely different process. They can do multiple step steps and optimizers that in between the instructions into the, into different architecture."
  },
  {
    "startTime": "01:10:03",
    "text": "Which creates this unique challenges, especially for the memory model. Depbed a site of wine Reno's current memory model exists in the first place. Compilers They don't understand control dependencies, and we'll happily break them. So we'll give an example later of of this why this memory barriers document exist in why coding is called a memory model was developed in the first place. And the second part is this OTA OTA stands for out of scene air. And this is inherent problem of high level languages like seed. What it means that just by If we follow the generality and description of see memory model as as it is defined. Like, for this particular case, if you have, like, 2 variables. Xandy And, they have, like, initial value value of 0 initially. And this code on the left and the right executes, executed on, 2 different CPU saying that So what CMMA model allows that value returned by X And Y can be 42. Like, effectively like any value is okay with the model. And this is That's how it is. So people have been trying to solve it And of course, this is only in theater. Right? So, like, in track like CPU, so any hardware will never, like, give you just a random number. Like, especially when there was 0s 0s in there, but memory language memory model cannot deal with it. Do attempts in the past, and still on going to address it But, It's impossible within the"
  },
  {
    "startTime": "01:12:00",
    "text": "strings of how it is defined. And the compiler, people will look at it, ideates, compiler will become, super restrictive and generate horrible code. Or we have to leave, memory model assist. So That's why this problem is My claim is it is unsolvable. That's why for the for the DF memory model, we're using this more lower level in stack and CPU like memory model. So, For BPS, it also exists similar to PSABI. It's, another completely different big book full of blank pages. In this case, we're working like Paul McKinney and others are working on cover in it. And defining the pieces of it that is, corner case and, black, black magic and defining the things that don't exist yet. But 80% of it is there. We it needs to be it needs to be documented and OVM and Jits. And what the Jits do is now is effectively source or source of throw follow-up as To explain what this work actually is doing And we just, in the previous, they still we just talk about grouping. So here, we'll group instructions in this 3 categories. For the purpose of understanding of a memory model. Is one is whole set of atomics, then, all conditional jump instructions, which like, not not special anyway. And, load, load, load, and store instructions. I will start with the plumbing. So we have change and compare exchange and atomic at or whether it was, fetch modifier or not. The way it is defined today and not necessarily all jits, like compliance was this is compare exchange and compare exchange are fully ordered. This is how it's written in this, blank page memory model book Yep."
  },
  {
    "startTime": "01:14:02",
    "text": "The way of thinking about it is for that it's, memory barrier for, like, using Linux terminology as an memory barrier followed by atomic and prediction. She relaxed, followed another simple memory vectors. And I'm not sure that today, even old jets inside the Linux journal, the map it's, these two instructions correctly because some of because only CPU, architecture maintainers for particular architecture, knowing exactly how it's implemented in a And when we review the code when people send us, let's say, like, s 390 legit support, for for, like, yeah, that makes sense. You're the expert generating the bids. Do the map exactly and does it follow this, like, fully ordered a behavior? Maybe we trust you. We think we know what what what you do Another set of abstraction is atomic Edenor. So those are not those are completely unordered, and we follow the standard of the Linux kernel in that sense, the atomic at operation is unordered. But when it is implemented by X86 exists, it actually for the fully ordered, because unlike 66, LOCXAD is, fully ordered atomic operation. So Jits in this case, 686 Jit choose to implement stronger ordering guarantees. Then DPF memory model requires, and and it is okay. The those with the fetch, fully ordered. So skip this. This is all details. So now, going to the second integrity of the instruction. Those are conditional conditional instructions. And, So the way Bpf memory model defines it is they provide with with with Ordering."
  },
  {
    "startTime": "01:16:01",
    "text": "And what it means, what I mean by that can be explained by the, next slide. So if we have let's say, a lot of instructions that follow it, followed by the conditional, and there is a store instruction what we require Jits to do is to, preserve the ordering because the conditional conditional instructions provide this guarantee that the load has to execute and the value of it known for the conditional operand before before store. So this is this is how, like, related. And in this case, this is c code on the left. Read once is a volatile read of, variable x. And right is a mbpfassembly that Buzz GCCLVM, generate today, and this is just an example. And this is the example of the dependency break that compilers do. So in this case, you notice that both sides of the branches, they write the same value and compilers, all compilers smart enough to optimize it. Into just like read and write. And what what just happened here, like, if you Na Eve, on the sunset of Naive, but they're just that the person, if we didn't read really linens kernel memory model document and write in a kernel code, or DPF cut. And this is a code that you wrote on the on the left side. US, you may be assuming that there is a control dependence because the region because the if can only, like, proceed after checking the value of 0 and the right execute after read, But due to due to compiler optimization, there will be no conditional debt order but only read and write. And On X logistics, it's not a problem. Like, it's stronger. It's, So total store order because of X86. Read will execute before the right but on the weekly order that architectures like armor and others, read and write can actually go to forza, and that might cause all sorts of problems for"
  },
  {
    "startTime": "01:18:04",
    "text": "Bpf programs and see in kernel code that's not written with there's a full understanding of what control dependency are and how compilers can break them. For Bpf, it's even more challenging because we have jets. And currently some of the jits. So there is actually one jits that's super smart, it's taken DPF assembly, converting into the MRR. Optimizing it and generating new codes. So effectively have 2 compiler one compiling from Cedar Assembly. The second one, jits from assembly into X86, and they definitely do the optimization like But in this case, when they do this, what we are saying that they will not be conforming with VPS memory model. So they should not be doing this this this kind of stuff. Yeah. I've talked about this part. I guess we can skip this. So, yeah, another another interesting example of optimization so here, you would think that, code on the left, the way it's written and c both rights will execute after the first after the first load And without compiler Optimization, that would be the case and on X Eighty 6. So the code on the right is X Eighty 6 code. It's it's also the same way because of the conditional move followed, followed by stores. Intel will execute in in sequence, but on arm, conditional move is its own is its own operation. So the store the control flow converge at the, conditional move instruction. So the store intivarablez after it doesn't have a a control dependency constraint here. So and that is also something that you well, unless you really know what is what is happening, follow, Linux card on memory model and VPN memory model faithfully."
  },
  {
    "startTime": "01:20:03",
    "text": "This is this is type of the issues that that can happen. And Jits have to be like careful not to do this this type of stuff. Now by a 3rd and last, category of assembly, maybe if assembly instruction is loading store instructions, And here, I'm explaining the data dependency between loads. So, like, the load instruction, but then it's providing the address of the value for the subsequent lord or for the store to store in some memory. There is a dependency chain, the data dependency chain. And CPUs, track it, track it face for on the 66, it's, obviously, total store order. On ARM, the address and data dependency between load and another load, the load in store without any if conditions attract attacked by the hardware, but this is not the case on, like, potentially some other, like, crazy architectures that should be, like, very fully when they translate DPF instructions in today and Yeah. I can skip this. So, back to back to my initial point. So DPF memory model is defining what the compiler is supposed to do. What compilers must do for the code to make sense. For the youth for don't shoot the the And for the Jets, to, follow it. So what Jits can do if they don't really care about performance. They can just put the fan separation everywhere. Obviously, that will degrade performance greatly, but it will be in conformance with VPN memory model. They can do a halfway. They can convert every load store instruction. That is defined today by the, say, into law, law, acquire store release, but"
  },
  {
    "startTime": "01:22:03",
    "text": "that's, again, on X86 that makes, no difference. Performance will be the same, but on Arm, lot acquirer is more expensive than the regular load. So what we are saying is the 3rd option here rely on source level. This is the C code of the program. To have been that this program followed Linux kernel memory model, standards. Then Jits can map, like, load stores into just a regular load stores on on the com. Particular architectures. As I said, like, BTF Memory model is not written anywhere. It's blank page book, and we can discover it by looking at what compilers do with, built in built in atomics. Let's skip this. For example, on GCC, there is a full memory barrier this atomic threat fence currently, Neither compiler, not just seeing all the M implemented, but thankfully, we have this atomic, store instructions. So with values 0 and on X86. It's actually exactly what the Linux kernel using to implement the SMP SMP memory barrier So for the rest of the docker, these slides, we just call, like, DPF memory barrier. So this is one potentially will be one of our future instructions that will add to because compilers can potentially compile this atomic threat fence into this Lock, lock and add instruction already exist in DPFSA. And it will behave like a proper memory barrier on X86 but That's not, well, nice to, other architectures. Kevin said that,"
  },
  {
    "startTime": "01:24:02",
    "text": "Kristoff's point earlier was while there is no use for any atomics. Maybe there is no use for electronics, but then that would mean there is no use for any barriers either in this particular. So whether we group all future better instructions into automics or atomics and the better will be separated. Grouping is something to that we will back share, I guess, on the list. 2 flavors of atomic loads, Again, neither GCC nor the M support this yet, for relaxed storaging, they affected all normal loads, low load and all DX instructions. And nonrelax. Potentially, it can be implemented by them with the extra memory barrier once it's once it's there. Similar for stores, compare exchange already already working as design. And exchange and competitor exchange. So in case of, regular atomic operations, like atomic or what we don't have, that's, again, another consideration for the future in CPU V5 architecture whether we'll have atomic extension, man. This is something that doesn't exist in NSA, and compiler cannot well, well, cannot really generate anything for it because well, Cannot. Similar here. Those are not supported yet, and the then defenses And my last Topic is the helper ordering. As I said, the programs can be running on a different CPU. So imagine on one CPU, you have a VPN program that is following bpfpsabi following bpfmemorymodel, all the codes is written. With, conforming to them, and it goes through this process of"
  },
  {
    "startTime": "01:26:02",
    "text": "compiling, then assembly instruction, the Jits do everything that they're supposed to do. Everything is nice. So this is one CPU. On another CPU, you have just what they call a DPF helper, which is written as a c code inside the kernel. It's also full of a Linux kernel memory model. It's compiled by GCC, but then it'll clank into native. So what this what are the ordering guarantees when these 2 CPUs, following, like, different memory model. Should they be, like, order it or not. So our proposal so far that no ordering is defined. Unless this particular helper on the cardinal side needs to Unless it's like a requirement for this particular helper. So that's, that's part of VBF Memory model that goes into this 20% of undefined stuff that we're we're defining as we go. And 2 new instructions. So we just talked about grouping 2 new instructions that were thinking to, well, at least to, is load the choir and store release. 1x86, there will be, like, through new stacks, new uploads, and I on X Thirty Six, they will map to normal load store, but on ARM, they actually will be different. It's instead of law, it will be law acquire and the CMOS email entry to the store. What we did in passed with the MCU before. We waited almost 2 years. To collect all of the, ideas and, teacher requests from different, like, companies and we group them together and said, now the system CPU before and added them all at once to compiler, 2 jits and to the identifier. Though they came from very different like categories. Like in CPU before, it includes, signed, signed,"
  },
  {
    "startTime": "01:28:01",
    "text": "sign extending loads, sign extending move operations, it includes, search it to be jump, which is yeah, completely different and includes all kinds of different byte swaps. So if there were group, it will be at least, like, 4 different, groups that would go into single and CPU before, but we did them all at once just well, make it easier for the compilers and the users when they're saying, well, I want to use before you get everything everything with it. Similar, we'll probably do the same thing here for the future MCP V5. We'll wait until, like, load acquire fully, like, implemented with that, it's use in compiler, in the data file, in the courtroom, that it's actually, like, benefits. And similar. And at the same time, we're probably at the barriers. Because, we already, like, have requests by the community to add this kind of instructions. That's pretty much all what I wanted to say. And here's, like, all the additional information, about if you want to follow. Questions? Questions? Thanks, Alexi. Dave, did you have any comments on that? Good. Oh, sorry. I'm I'm alright. Okay. I just wanted to I was wanting to say, I mean, it's it seems pretty clear that a language memory model is equally out question. Right? It's like if you look in industry, there's all these problems with with out of thin air people have been making proposals to to fix it, but then it suffer. The arm doesn't like that. It could potentially hurt performance on arm And so I think, Yeah. In general, using using something like Linux kernel memory models to impose dependency ordering that you don't get from compilers and you don't you don't get from the language memory model itself."
  },
  {
    "startTime": "01:30:00",
    "text": "Feels like the only realistic, realistic approach. This So, oh, I think this is great presentation, Lexi. My question is actually to, the chairs and the AD think Alexis's presentation that makes a good case for why there needs be a BPS memory model document in order to, implement a compiler and have stuff work. My question is, does this fall under one of the existing charter items? Like, for example, does this kind of squint and fall under, you know, compiler requirements or could we say it's in a separate document, but it kinda falls under be, under ABI ones and let's see, explain it's not quite the ABI, but maybe on the Charter speak, it is, and it's just a separate docking or something. And so my question is, I think the working group needs to fill in those, blank pages that, Alexis mentioned. That's my opinion. And if you agree, then how do we go about doing this? I think so too. So, like, the reason we're all here is l exactly work out the details. How are we going to fill in all of the details, though not everyone in the community like agrees, some of the compiler faults believe that things like PSAB and memory model has to stay out the standard that the ETF is not the right forum effectively to document them because it's there was no such precedent, like X Eighty Six, PSABI is maintained the in a GitHub effectively by a group of people. And similar to, like, different different memory model from every model is, like, arguably the same memory model has its own, like, standard for sure, while risk 5, doesn't, like, they just like define it here. So what my personal preference is actually"
  },
  {
    "startTime": "01:32:02",
    "text": "trying to see whether ATF process might be fit for this because of, like, openness and everything. And, see how how it goes. So, I I see that certainly fits into one of our items in here is documents that recommend conventions and guidelines. On the charter? That's the one I would say too. The only problem is that one has an information it. And as Lexi presented, if it's not proposed standard, you don't need an Okay. Okay. I think we can look. If you can change that I to a PS, I agree. Well, that's the problem with that bullet. I I think that there there's two questions. One is whether we should have this being documented in in ICF and the second is whether it should be send them an informational doc. And I I would my personal perspective is that we've already question in misses, we're talking about calling conventions. We're talking about like all this stuff that likes it mentioned, that's think that stuff we always intended to be putting into that document. And the memory model. I mean, it's all sort of part of the same you know, the same group of things, right? It's like what what do compilers and just have to do to create interoperable binaries and I I I don't think we would wanna make that standard, but, standard. But, that that's at least my impression is that that was our original attention. It was not who's not here. So Yeah. Just so just so just across the cheese. I'm not proposing to change the charter. Yes. We have we have, ABIs and, compiler requirements as informational, so I prefer it to stay to stay this way because the thing this is Yeah. It's something that we'll be wallowing in for the long time. So we have, a lot of work ahead of us just writing down what the essay"
  },
  {
    "startTime": "01:34:00",
    "text": "is in the in words instead of source code. The same for the for the memory model. All of it now is the source code. And some people understand it. But but but but It's a challenge. So it's it's it will be a challenge just converting towards k. So what I'm hearing is the answer is it's in the charter right now, but we need to do it as informational. That's what I hear is the answer to my Yes. Thank you, Dave. I'll say additionally that the the, bulleted list of documents in there. Their status is actually represented with some text that says with intended document status. So, We, we might have some wiggle room. Yeah. Good stuff for saying next. Stuffing on the go ahead. Good stuff. Unmute. Kristoff, I cannot hear you. Still kinda Is this better now? Yes. Oh, okay. Yeah. I don't know. I switched headsets, and it looks like the other one didn't work. So slight disagreement, but maybe that's just because we're talking past other. So on the memory model, The important thing to remember is"
  },
  {
    "startTime": "01:36:04",
    "text": "basically for if we look at existing, like, see or whatever language code on on quote, unquote normal processors. There's always 2 memory models involved. One is the memory model that defines the hardware or in this case, like VM behavior. And then there is a language memory model that needs to map to the hardware or VM model one way or another. And defining the low level memory model for EBPF. I think we have new auction except making it an actual normative a speck as part of our sec family. That actual programming model, memory model, is different. And if we do it in IETF at all. Yeah. It's probably informational. I don't know, but different question. But I I I I don't think we can have a non normative work from non standardized. Hardware management model. Now the PSABI I think it would be really useful to have it in the same place. And I consider it normative, but I mean, if if there's opposition and the opposition is actually worse than group which means we need to get the propeller people to actually show up here and express it. I could live with having it non normative, but I think it's actually Well, I think that the compiler people her voiced opposition on hold. Right. Right. Right. Right. Right. Right. Right. Right. Right. Right. Right. Think I think Jose is at least as they has chimed in pretty regularly to to, to suggest that it should be informational The you're talking about the memory model or PSAV. Yeah. Well, they're they're kind of related. Right? That's that's sort of low. No. They're not. Absolutely not. I mean, the PSABI"
  },
  {
    "startTime": "01:38:01",
    "text": "documents I've seen don't actually talk about the memory model l Well, Alexis, do you wanna Yeah. So, like, yep. So PSABIN limiter model is, 2 different documents. Because, like, one is addressing what compiler's supposed to do to generate code, and model talks about concurrency So they can be one dog that, but that will be Leer, because, in industry, this those are different. Then, answering that Krista's question about 2 main memory models. Yes. Like, that's what I started on the slides and now presenting the slide. There is language memory models like ccplusplusandlin model, general memory model applies there as well. And what we initially did for DPF is just that, well, DPF memory model is is the same as Linux Carlman. Clean strong memory model, but we're finding it Now into, for you to be more, CPU like because because CPU CPUs, they also when the CPU, let's say, is 5 for XH6, when they define memory model for them, if it more than they also define America's instances. They they say, how this instructions, like, supposed to behave. With VPS memory model, we cannot do the we cannot say that we're, total store order. Like, if we say this, that immediately, all of the arms, armed autumnjet will will have will have a hit. Right? So we That's why I think the common ground here is to have it if you have my Ronald to be CPU like, like this lower bar, like XH Six zone arm. And at the same time, the high level similar to Linux kernel memory model. That's why it's, like, challenging. So that's why maybe we're like, talking a bit past each other. Since it's I think, like, this is actually, like, new concept that does not exist in"
  },
  {
    "startTime": "01:40:04",
    "text": "industry. And when people just say, like, memory model, they assume either C or CPU, right, So we need something brand new here that's sort of in between. That I somehow satisfied both. So we have this error compiler from top. And jits in the bottom, and memory model has to be the guidance, the instruction manual for both and for the users that will be writing those I mean, I think I actually mostly agree with you, right? I mean, basically, what we need could do is to write something that acts as a hardware quote, unquote, memory model that is closely based on the Linux memory model. And by the way, if you look at the real CPUs It's very, very common that actual CPU implementations or microarchitects textures, have a way stronger memory model than instruction set memory model requires say a lot of risk 5 CPUs actually have a fairly strong memory model that isn't anywhere near as weak as the crazy academically designed everything as possible order in risk 555 through? I think they designed it that way for on purpose. Right? We want to get people possibility to So, and Well, I set in the group. I can tell you some stories, but it's probably not for public. Also, I want to touch by, this conformer versus not informational standard. So even things like PSABI, one might think that it has to be standard. Right? It should, like, if 2 compilers just producing whatever, something else. Like, they're not following the Bpf calling convention. Then it's completely useless. Right? So, like, why you would even have a compiler that's not following VPFBS ABI. Well, turned out that this is actually is useful in practice for, like, on on X HSA. Like, the way protocol compiled first search it a bit,"
  },
  {
    "startTime": "01:42:01",
    "text": "it's not following search it a bit xh6psabi. The kernel is compiled with extra GC flag that says, like, use this 3x set of registers, and it's immediately, like, well, not conformer. Right? So this is the example where practical considerations from the purity of, like, performance and I suspect, like, we should be mindful of, I think we should be mindful of that. With, NBP FPSabi. I think it should be informational, but I can't see compilers, like, having this set of flags to do things that are non conforming. Another example on arm, on autumn, just to see it has a flag. That says, like, w. It's I think it's even called, like, w TSABI and double No dash PSAVI. With allows compiler not to conform to. Our memory model, which also think feels like a natural and pointless, but here we go. I think I think just because there's cases where people might have an option to not be compliant by itself isn't a reason to not be for post standard. I think, Eric and I and probably some other people can think of cases where, in, say, ipv6 some implementations chose to be noncompliant to say source address selection, or to have a mode to put you in an uncompliant thing to have ultimate behavior is a proposed standard, so you can either configure yourself to be compliant to that. Or to something else, right, but it's still a proposed standard. And I think that same argument would apply here just says, think there's a good argument for why things like PSABI should be proposed standard, even if you want to have an option that says, and I'm not compliant to the standard. I'm compliant to some other specification, that's okay. That's my opinion the"
  },
  {
    "startTime": "01:44:02",
    "text": "So, you know, Jose's Jose opinion, I think he's not on the call here, but he strongly believes that ITPS AVA. 1, many models, they should not be is then they should like, information over just I send a message. It can certainly start as informational. Yeah. What's interesting is if we can get him to say Why? Price price. Right? What's the technical argument or whatever? Make all agreement don't know. Just saying that just because somebody does it, I don't think is and not most standard because I think there's cases and and I 6 where we are to have that posting. So So, Alex, you come up with the draft sometimes, though? Sorry about that. A draft Oh, draft. Yeah. So, well, exactly. Yeah. So that's what Paul is working on. Is the time the messenger, Paul doing most of the work, and the plan is exactly to get an agreement, like, here, in, it's through. And we, of course, not gonna be only at the ATF. We are working with different competitive, like, bots that you see in the OEM communities. And Cardinal Community Of course as well. So, Paul will will be presenting his work at Lemons Plumbers, next week. for the first, like, 80% that's malless, like, non negatable. Like, of course, like, we can make changes to some of some of this visible words, the they better be this way. Like, we cannot change really now. That's, like, the things like calling convention, for for the for the VP or to say that compare exchange is not gonna be for the order. That's Not like it's it's part of the Linux journal API."
  },
  {
    "startTime": "01:46:00",
    "text": "At this point. So it's not something we can change without the So some of the stuff I'm not not not for change. They just need to be documented and some other stuff there's a room to define it that it's, more longterm that a better past long term. So that's what we're trying to get from from this room presenting here, then from Linux Plumbers and from the mailing list, And once it's there, there will be a document document produced. In what form there. We'll see. So and the timeline is also, like, not not, here. Yeah. But that's definitely, like, onto the list. Okay. Thanks a lot. Thank you. I don't see anybody in the queue, so thank you very much. And and can have an early launch today. Thanks for making this an awesome meeting. Thank you. See you in Brisbane. And, best wishes, David, or you're all submitting send photos. Thank you. Yeah. I will. Everyone. Suffman. The In the middle of Is this your we are done as this this this this this this your phone siege It's like totally f f to anybody."
  },
  {
    "startTime": "01:48:03",
    "text": "Likes Woah. How do you What?"
  }
]
