[
  {
    "startTime": "00:00:00",
    "text": "sides and to make it good morning this is the net confer group meeting let\u0027s get started we have the note well most of you should already be familiar with it basically anything you say or discuss in this working group has to comply with the rules of the ITF more details can are available at the link at the bottom blue sheets are passing around it please add your name to them this is how the working group gets a wareness or understanding of how many a participants are in the room so the ITF can plan the size of the room for the next times meeting there is a course of audio the Medeco there\u0027s being so we have a couple folks on Medeco and of course there\u0027s a virtual microphone so you can come to the virtual microphone to speak there typically or in past Oh actually forever it\u0027s been the case that we\u0027ve asked for ether pad note-takers but we\u0027re not going to do that this meeting or any well we don\u0027t instead we\u0027ve found that transcribing the YouTube video audio and then repairing it to get a perfect transcription is much more effective than actually having people take ether pad minutes so we\u0027re no longer going to be taking either pad minutes but we do need a jabber scribe so if somebody could please volunteer to be on jabber and subscribe to the drivers cried looking somebody volunteered to be JavaScript anybody we cannot start the "
  },
  {
    "startTime": "00:03:07",
    "text": "meeting until we have a jabber scribe okay you\u0027ll but you\u0027ll keep working on it or you\u0027re completely stuck okay mmm okay so we\u0027ll have to ask for support to see if there\u0027s actually a problem with the Jaguar but we do have me taco working so we can at least work we can go forward with that oh you still have them in a ticket I thought we said we weren\u0027t gonna do them so that\u0027s it for there okay so since last times meeting we have published a number of RFC\u0027s there\u0027s RFC 85 25 which is yang library RC 85 26 which is the Metcalfe extensions to support the nmda and RFC 85 27 which is the rest comp extensions to support the nmda this is a major achievement the local group should be very proud of their accomplishment and I\u0027d like to sort of kick off a round of applause to everyone [Applause] all right so as far the status of the chartered working group items the yang pushed suite of drafts they were sent into IC and currently I believe the last status update was and a last call has been issued on the whole suite of drafts and I guess is C will be picking up and providing reviews so the authors should be prepared to respond to those comments I think I even saw a security Directorate review from this morning on one of the dresses the net con risk on client saw the suite of drugs that Kent will be talking about is still work-in-progress we\u0027ll get a status update from em and decide the next steps the European draft we received some pushback in ITF 103 on the draft so for now we have put it on hold and been with the ultimate intention that we wanted to place it with the multiple streams draft but let\u0027s see what the workgroup thinks about that the yang push notification draft is also work in progress and the yang push notification messages is going to be present is not going to be presented but is work in progress so here\u0027s the agenda for today\u0027s meeting we have of course a whole suite of "
  },
  {
    "startTime": "00:06:07",
    "text": "drafts that our working group items but there are two new drafts that can full be presenting that we probably will take a roll call on to figure out whether we won\u0027t adopt them as the troop items or not in this particular presentation is now 15 minutes not 10 minutes the only other item on the chartered item list is of course the yang push notification capabilities we have two drafts there are non chartered items both the subscription to multiple streams originator that we just referenced and the nmda backward compatibility draft so which the presenters will be talking about right so just as a note you may have already received the second half of this meeting is going to be given to the net mod working group for them to present there and the chairs will talk about what they will be discussing in this session and they come up that\u0027s the second half I think that\u0027s if the chair slides any comments about the agenda before we get started okay hi I\u0027m Kent and this is one of my co-authors Wong sir take this evening yeah my name is hi Wong Wong from a Halloween how long has been helping with the crypto types draft and he\u0027ll be helping me present that part of this presentation so there\u0027s a number of drafts here no it looks like a lot but there\u0027s really just these a couple issues that we\u0027ve been whittling down on and we\u0027re again going to talk about them the same two issues that we talked about ITF 103 so there\u0027s the normal side drafts and my hats just mentioned and there\u0027s a couple two new drafts that we discussed wanting to introduce an ITF 103 and so those will be presented here for the first time okay so just quickly I don\u0027t want this my only status light but the sense ITF 103 all the drafts were updated as a set progress is made on the two issues that were discussed before and this presentation just focuses on those two issues plus a few additional issues have surfaced and we\u0027re first in discussion beginning in discussion 1 about finalizing the crypto types identities acetone horn "
  },
  {
    "startTime": "00:09:16",
    "text": "okay good morning everyone my name is Ivo Roma highway actually yeah color of this a crypto Java types crap this ratios change the limit you know that\u0027s two emergencies the main chains are actually we add in way more categories and change the name of a symmetric key encryption to assume the key at least for the details please refer to the cottage south yeah I wa this is this slide shows the translators of the visual types we actually classify the crypto algorithm into some classes including hash a symmetric key algorithm the Salam yeah so I would like to ask two questions to the floor so firstly is either any suggestion to the classification of the algorithm that means is the current algorithm classification messages yeah good are there there is a better message second is yeah you there new category to be in the classification yeah that\u0027s what I have this great took time to Jack yes thank you that\u0027s right trying to clarify that there\u0027s a number of base identities that are on the screen here in blue and I think the question is whether or not those the the right set of base identities if there should be more or less of them thank you Roger Nootka I have a question related to the recent discussion about the deprecated status so what\u0027s gonna happen if that\u0027s a cryptographic algorithm is compromised so what is the supposed sequence of events after that in terms of updating the modules of - I\u0027m sorry where did we land that it is the status yes statement is currently that algorithm is not recommended to be used after that go in so I believe that the yang module should somehow also take this into account right but I\u0027m asking is syntactically can we put the status statement as a sub statement to the identities what\u0027s probably going to happen in an eye on our edge astray in the corresponding in our history is that this algorithm will be labeled as deprecated in eye on our terms but since apparently deprecated means something else in in in the yang this could be a problem I believe because currently the discussion was the deprecated items basically must be must be implemented anyways okay so first off I think you\u0027re saying that it rule right now the draft would be published with "
  },
  {
    "startTime": "00:12:17",
    "text": "knows it was status current and then as in when INR deprecates an algorithm we would have to republish the module with status deprecated and button and your point but my point is that it really doesn\u0027t work the way that\u0027s probably expected that there\u0027s an abusive even more deprecated means but I think that we would move forward with cognate deprecated because of the yang burgeoning rules that we\u0027re adopting and then we could then do a subsequent update to move it to up sleep to match the full definition of INR and in the interim implementations could do a deviation module to say that they you cannot deviate and identity that\u0027s another problem of course cannot deviate identity okay so I don\u0027t think we have that as a gain next issue doing now we can discuss it during the discussion of that issue we have but I think it\u0027s especially important for these kinds of things that so Martin Buckland about not being able to deviate an identity I mean you don\u0027t have to implement all identities in a module right and there\u0027s we have an issue with that how do you actually tell the client which identities you have implemented so that\u0027s that is a young next issue so I think that part is being covered okay and also we\u0027re talking about going directly to obsolete so maybe in this case it would make sense to go directly to obsolete you speak little bit louder yeah so in this case it might be the quick thing might be to go directly to the status obsolete in the eye model actually the program Arabic again and the program is not only about identities which may be solved in a way that Martin mentioned but some such types can be defined as enumerations and in this case this is clear that manure the same way as foreign entities a high a friendship re I\u0027m also the course of the crypto type documents so I\u0027m trying to answer this gentleman\u0027s question actually when we updated this document we have considered that of course the crypto evidence where we develop and some of them will be depreciated so what we covered or what we read and have region the in these crypto type of documents within current in that idea of the most widely used and most low your poster algorithms we listed there we don\u0027t include some duplicative and such as md5 or 3d year something just our promise "
  },
  {
    "startTime": "00:15:20",
    "text": "but we also notice that with the tons go on yes this some of the algorithm we will be older and we have not be safe so actually we I think with maybe Ken has some solution for this maybe we can updated based on the ocean young ocean a mechanism to to solve this problem yeah and I hope your question we have considered is missing well I find generics on actually I have a question to a previous slide that you want to introduce two new drafts I\u0027m not against these drafts but I would be very I would be unhappy if that would delay the Bayes drafts which are very much needed urgently will it delay or yes the two new drafts that they\u0027ll be in a second discussion were right now on the first discussion so can you hold that comment till then can you go back to the next slide please you know on the first question is there any suggestion for regarding the classification of the number of base identities that are currently being defined are they sufficient should there be more or less so far I\u0027ve not heard any responses to that particular question yet is there anyone having suggestion for okay I think so my own as a contributor I I find them to be sufficiently they are currently being used by a number of the Association to a lesser or as I mean we started this because we were trying to use them for the purpose of the Association TLS drafts we need to ensure that gets complete completely implemented and but so long as that\u0027s done then from our own consumption perspective they would be sufficient we will the chairs will ask for early sector review of this draft since is so heavily enthralled in security consider concerns so so we\u0027ll also get that level of review from security director okay thank you okay so beginning discussion number two which is the adding support for TCP keifa lives if you call this was the same discussion we had at 103 at that time and actually even currently the current adopted solution is as it is on the screen you can sort of see the relationship with all the different groupings in width between the drafts and then at 103 I had this slide on the screen which was a proposal for maybe having a TCP client server draft as well as the HTTP client server draft as well as an HTS client server craft and we "
  },
  {
    "startTime": "00:18:20",
    "text": "talked about that and there was general consensus in the room that this was an approach that people wanted to see taking forward but actually when I got into it I found that there\u0027s an even easier way of doing it which is what\u0027s currently published so there\u0027s just the TCP of HTTP there is no HTTPS because you can see that the rest comp client server is using the groupings from both TLS as well as HTTP if you had an application that just wanted to be HTTP they don\u0027t use the groupings from TCP and HTTP so you can the application that\u0027s being a consumer the groupings can decide the stack of protocols that\u0027s trying to use to sort of go into that a little bit more I\u0027m sort of following the the good bad and ugly triple here I give this as the hazard versus is a object-oriented relationship um I think this is good it enables the application level modules to compose the stack of use of statements so for instance if here an HD client you would use the TCP client and the HTTP client if you\u0027re an HTTP client you would use the TCP clients the TLS client and the HP client if you\u0027re an HTTP call home client you use the TCP server and the HTM TLS client and the HTTP client seeking build your stack based on what kind of client or server you are so that it\u0027s very flexible also this being the hazard versus is a avoids what I\u0027ve learned originally as being called devil\u0027s diamonds this is the old Scott Meyer this effective C++ book but basically it\u0027s a multiple inheritance problem where if you\u0027re using groupings from two different sources but each of those groupings are using a common grouping then you can possibly get the same set of definitions more than once which is not what you really want so by using this has a approach it avoids della diamonds you don\u0027t have that okay so that\u0027s the good the bad top-level grouping nodes are in the same namespace and thus may conflict so in order to demultiplex the node names oh sorry there\u0027s a question like huh stupid comment go back there caller didn\u0027t oh damn Bogdanovich the color schema is unreadable if you\u0027re not really close to here ah okay so I recently upgraded to Mojave I\u0027m in the dark mode for example I can bear like grouping H this something blue then green it\u0027s it\u0027s really hard to read the projectors also kind of dull sorry about that alright well everyone moved closer to the room from the room okay so again to demultiplex the names you can either "
  },
  {
    "startTime": "00:21:20",
    "text": "even do one or two things you can either prefix the top-level node names such as for instance having the grouping tcp client grouping there\u0027s leaf remote address which is not prefix there\u0027s container tcp - keep alive so that one is prefixed by tcp - and then I have an example any data TCP - foo and then for TLS client grouping I have as example TLS - keep alive so you see it\u0027s prefixed by TLS - short and then HTTP - so that\u0027s basically prefixing each top-level node inside the grouping so that\u0027s option one option two is instead to wrap the entire contents of the grouping inside of container which the king of the containers prefix but then it enables all the individual nodes that were previously top-level to not have to be prefix so that\u0027s the I don\u0027t think this is a big issue we just need to decide which approach we want to take currently the drafts are using approach number one because I kind of backed into it and that\u0027s where it was at the time but very willing to switch it to approach from two of and it may prefers that any comments okay I\u0027ll take that one to the list and the ugly okay so should the Netcom prescott urls also follow the has a pattern us do we care about possible protocols built on top of net con from restaurant so currently we have TCP HTTP till uh sorry at TLS and ssh they\u0027re all basically these little groupings that are encapsulating the configuration parameters for a single socket right but then we have the neck off rest comp which are more they\u0027re not just a single socket they\u0027re more like a list of devices or a list of endpoints so presumably we could isolate that which is configured per socket or session from the larger multi socket multi-session model supporting for instance listen and call home so I\u0027m thinking what we could do okay let me be clear currently the grouping if you were to do an instance of grouping of the Netcom client a client protocol yes I start grouping an account grouping what you get is something that can either have a make a connection to a list of endpoints or actors that call home recipient right we could keep that grouping but also have another grouping which really is just representing a single Netcom client in the configuration parameters for it so and be very skinny like Netcom session timeout might be the only configurable parameter there right it\u0027s very small but it\u0027s really just the configuration parameters for a single Netcom session and then that grouping could be used by the larger grouping so if you wanted to little higher level application wanted to compose its own "
  },
  {
    "startTime": "00:24:22",
    "text": "stack and a some where net comp was in that stack but it\u0027s not necessarily the end of there\u0027s not that top of the stack they would have the ability to compose their spec so that\u0027s the bestest the suggestion without here to people would people like to see the net come from rest off models also follow this has a pattern Tim Kari Nokia so I think there\u0027s some value to this particularly when we talk about proxies like if I had a proxy between you know the example would be a proxy between arrests cough and a net cost so I think there\u0027s some there\u0027s some usage here that that probably would make sense that we that we incorporate Thanks thanks Jim so actually with proxy and I\u0027m thinking when you said that I\u0027m thinking HTTP proxy yeah no not H so they\u0027re inside the while you\u0027re stepping back to microphone inside the HTTP client server model in fact there is one of configurable parameters of proxy so if you HP client want to connect to connect directly at the endpoint or via proxy now I was referring to an application layer gateway of between a neck coffin or restaurant okay great thanks okay moving on so that\u0027s the end of discussion number two so before we move there one note as soon as the etherpad link in the agenda is concerned it\u0027s not the correct one I just sent one on the net cunt mailing list use that if you want to provide any comments there are people who are writing notes it needs bad and so before we move to the discussion number three the question for the working group is that I think in 103 there was kind of a poll taken to figure out if there was interest in working or adding two more drafts into the stack of drafts that you have specifically to address the question of TCP and HTTP so keep lights yeah thank so the question for the working group is is there enough interest in the working group to maybe start an adoption call for those two particular drafts that are not workgroup items as yet a show of hands if you are if you feel that there is enough interest in the working group off if you think there\u0027s that you would want to see that work done in the working group all right same question was asked in 103 and there\u0027s large consensus the room that they wanted to go this approach so maybe specifically asking believe wanted "
  },
  {
    "startTime": "00:27:23",
    "text": "a problem of PCP keepalive to be resolved using these two drives okay yeah that would be the next step okay if there is no support for it is any objection all right no objection either I guess then we\u0027ll have to go back to 103 and also of course you have to anyway formally do this on the mailing list so we can try to send the poll out and see if there\u0027s any support did I may read the drafts TCP and HTTP dress actually that\u0027s true that\u0027s the first question that should have been the first question yes no one read it all right so we\u0027re gonna have to take that list but nonetheless 103 there\u0027s the it was effectively the support was given there and this is just basically fulfilling that the promise or whatever agreement before yeah it\u0027s fucking rider one question so we see in the web scale oh we got option going towards quick so do we have anything any thoughts or odd maybe moving also in the direction of quick and we will combine all the benefits of getting quick in terms of security round-trip times whatever or is it so I\u0027m just asking if there are any thoughts around quick using this in this context there\u0027s nothing explicit but I\u0027d be very open to understanding what how it might change so I mean I know there\u0027s a variation of HTTP and so it\u0027d be kind of like how can we Primrose the HTTP model just and for that matter currently the HP model doesn\u0027t make distinctions between 11.11 or two to do so maybe we need to think about that and so please maybe you can send a message to lists and take it up there okay great thank you yeah when you come up to the mic please enunciate your name so Robert here can take some notes okay so in the course of making these updates I kind of unconscious a few issues first is protocol specific parameters are per socket which can lead to some redundancy in the model so for instance the TCP keepalive must be set for each client and server if you\u0027re configuring anakov client or server and areas connecting to a number of endpoints each of those endpoints have to have their TCP keepalive configuration settings set for each one of them because it\u0027s like that\u0027s the way the models working we\u0027ve okay so to be fair this is inherent in any list of like items so anytime you "
  },
  {
    "startTime": "00:30:24",
    "text": "have a list of items it\u0027s not unique to this to these models at all if your list of items and there\u0027s redundant you know information across them you know that this this can happen proposed fixes to do nothing and instead wait for a TBD template team mechanism at some point somebody should the working group or perhaps net mod should define a mechanism to enable some snippet of configuration to be applied to groups or you know more than one instance of a another model and then that would allow for common configurations to be factored out defined once and then applied to the subset of the particular list entries that are inheriting it this in fact is one of the issues in being next number 18 which currently has importance medium which is to effectively reproduce junipers apply groups statement does this any comments about this particular issue okay second issue the keep live config may be present for periodic connections currently I don\u0027t know if people remember but a while back we previously removed that keep lives from periodic configurations we stated that while periodic connections are reddish and you don\u0027t need to keep lives to keep them up you only need keep lives for persistent connections so we removed the keep alive configurations from periodic connections but now the way the model is the keep lives are being configured at the socket level and so it\u0027s being configured the socket level regardless it\u0027s a connection or a periodic connection which is kind of unfortunate however I think as I was creating these slides I was thinking to myself the proposed fix we could use a must statement where we say you know the keepalive configuration must not be configured when you\u0027re configuring a periodic connection something like this yes okay next issue are all the protocol specific keepalive models correct so Tim I don\u0027t know if you\u0027ve looked at them the various configurations but so currently the the TCP keepalive configurations are very much like the POSIX keepalive mechanism there\u0027s a three tuple of values but then there\u0027s the SSH key Politis and the TLS keep lives an HTTP keeper lives and each of them may be a little bit different because each protocol has a different way of supporting keep lives I just so I think TCP is okay actually you know model it directly off of POSIX but the others I\u0027m a little bit uncertain if anybody\u0027s looked at them as "
  },
  {
    "startTime": "00:33:26",
    "text": "concerns good to hear Tim carry Nokia no we hadn\u0027t had a chance to look at them yet but we will because I think they\u0027re looking at instead of augmenting the keeper lives to actually use the draft now so if you remember we had some augmentations in there before in the BBF and now they\u0027re well that was before yeah if we have this approach you would no longer need to do absolutely they know they just haven\u0027t got they haven\u0027t looked at all that keep alive okay give you responses okay okay good number four is there any desire for other protocol specific configurations some for instance HTTP proxy settings a current currently you know the groupings are per socket configurations I\u0027m trying to keep it to be the minimum necessary for what we need which is really a transport-related so I\u0027m not trying to configure every possible knob on HTTP server or or an SSA server I\u0027m just trying to keep to the bare minimum but I do think for instance HTTP proxy settings you know it\u0027s a very common thing for a client to need to for instance to go out through a proxy so I\u0027ve that\u0027s kind of transport related I feel like maybe that\u0027s an example of one that we should add anyway I don\u0027t know if any well since no one\u0027s read the drafts you probably don\u0027t have suggestions about what might be missing but just be aware that we\u0027re gonna have to have a conversation about you know there might be some issues missing HTTP proxies one number I\u0027m thinking about right now I don\u0027t have any others in mind but if other people are looking at it and you think that there\u0027s something missing please let us know five not all HTTP off schemes are currently defined so if you look at the HTTP draft specifically HP supports six I think authentication schemes there may be more sorry there might be more maybe eight but and I\u0027ve only actually defined currently the configurations for three of them I think the remaining of them are just these little fix me comments there\u0027s actually zero content within the container definition they\u0027re just ran out of time so if you\u0027re looking at it and wondering what\u0027s going on that\u0027s why six why do we have special breakout groupings again so I think everyone probably saw the email thread I had on list just recently with balázs the other blush from Ericsson and and so I think the net result of that is that we\u0027re no longer needing to have you "
  },
  {
    "startTime": "00:40:52",
    "text": "adopt them then we just need to finalize the few questions I\u0027ve mentioned in the last couple slides a lot of them might I had the answers for already and some of them were just cross this question so it should all move very quickly I would imagine hopefully before Montreal right so you do ideally like to see if we can give you at least a subset of these drafts ready for looking group classical oh absolutely so same the first three drafts could be in last call maybe a month\u0027s times assuming the cryptic types draft is ready okay blush hello i\u0027m balázs Tanya from Ericsson and I\u0027m presenting this draft which was in workgroup it\u0027s a workgroup draft for more than one year but actually it was sleeping in a way because we had other more important things to do really yank push and now I am trying to restart the work it is needed stuff but yes it is based on the anchor so that has to be first the base problem was that yank push has the unchanged capability notifications they use modify change whenever it happens immediately but that\u0027s a very difficult proposal for some reasons you might have counters that change every microsecond you might have meaningless changes or many times you need to implement schema note by schema knows by schema not one by one that only change notification capability and it will take time for that to happen so practically even if we declare that we generally support on change notifications in practice that doesn\u0027t mean that any single object is really supported in that way which is if it\u0027s a contract then we should say yes or no not that generally yes maybe not so after some debates I did define the yang model to document these notification capabilities basically it documents on whether generally and for each specific schema data node on change capabilities are supported or not to make this we don\u0027t want one indication for each data node so practically we have a default on the top level which means that generally I support unchanged notifications for "
  },
  {
    "startTime": "00:43:52",
    "text": "config and or for state data config and state in many implementations have handle differently and if there is some specific part of the datastore that is doesn\u0027t follow these default values then that might have a known not own specification whether it supports no unchanged notifications I\u0027ll give an example later on but the two principles to reduce the number of markings is that we have a top level default and the support or download support is inherited down the containment tree also we have some other cap not no capacity related capabilities that are not related to the unchanged but generally to yank push and the idea is that yes this should be available online restaurant at home but also for management system we need this data early before the nodes are implemented before the nodes are both so Yang instance data would be the vehicle for that this is the data model top part are the general capacity related problem items how many what dampening periodic we can support how many objects per update so how much notifications can there the server really push out the other one is the to default the lower part is about unchanged notifications one for config one for state and this unchanged notification capability list is for each node you can specify that yes generally it is supported practically for this specific part not there have been some changes since the last IETF added more capabilities we can debate whether these are the exact capabilities that notifications need I\u0027m open to any suggestions these are the ones I could really read from the standard and that\u0027s seem logical oh that\u0027s last late no it\u0027s not oh it\u0027s sorry but what I sent you had your slides this is included in both in one of them I have I think one more slides and other trainers thanks anyway "
  },
  {
    "startTime": "00:47:11",
    "text": "some very good comments yesterday from okay well 906 myself okay I think unless I\u0027m messed up but there should be small slides the main point is that this man is that having default values on and they\u0027re having multiple values that indicate specific part of the models work this way or that way that\u0027s unseen somewhat complicated I promised to some of you that I\u0027ll add examples in this slide outside and in the draft to make it more simple to understand one point is that what categories do we have for the support or non support one was an open issue that do we need separate indications per data store so some ones there is that their implementation with supporting notifications on change notifications on the running data store but not on the candidate yes I I can accept that and then that will be added to the data data model that you can have general capabilities for all data stores or you can have it birth data store separate city the other was that this logic that default may be then one container says that that\u0027s it I say that default is support kept us unchanged but the next container says I don\u0027t support unchanged on statistics because that\u0027s it\u0027s good and then maybe under that I say that the default was support the statistic container said no support but son specifically one or two counters I do support it so these three levels of that say the default container or this that contains it and maybe on the individual leaf will be explained the main purpose of this is that we don\u0027t want the hundred item long list of individual knows that support it doesn\u0027t support support doesn\u0027t support so you need to have this hierarchical and also that the default value whether it is I support them unchanged notifications for everything and yes there might be exceptions that that is the case for some of our implementations let\u0027s say I don\u0027t support unchanged notifications for in objects counters because that\u0027s - that might be the case for some some others my company but others as well said that no unchanged clarifications are important but somewhat difficult at "
  },
  {
    "startTime": "00:50:12",
    "text": "least for state data so for each group of common counters state data each group of individual items will indicate separately when we start supporting unchanged notifications so the default in one case would be support for everything and then some exceptions in other case defaults for nothing but yes support for some exceptions yes questions Robles in Cisco so here if I understand this proposal here correctly the system is running on the box and you can query it and it gives you information about what the subscription properties are effectively get the write-up and you consider doing this off the box using instance data to make that information available at design time rather than runtime is my first question my answer would be yes yes that\u0027s why I want the instance data draft so any two thing where you have a yang model that represents potentially capabilities that you can have the same data and an instance draft that will tell you what they designed okay and then the second question I have is that in here yes you built the parallel structure that represents the properties of what can be whether the subscription rates how things are I wonder whether Harries that\u0027s going to be be used and whether it be easier to have like an RPC mechanism or something that allows you to query a particular path and say what\u0027s the subscription properties for this path so I it\u0027s different mechanism not sure works but it\u0027s just a thought I think you do need this data model because of the offline need yes and I would say that\u0027s a kind of yeah what whatever you like are PC or data generally I prefer doing this with data and that gives you a and then and they there\u0027s anyone if you think we need some art pieces to make it seem more simple we can discuss that but I don\u0027t feel C the needs so I\u0027m not rest as we discussed yesterday by lash but I want to make sure I repeat this for the group there are three different use cases the first one is that an entire data store is unchanged capable so we want to be able to write this the second one is a specific schema note which is unchanging capable like ok want to be able to do this but the the the next one is also alright so I\u0027ve got some counters there unchanged capable but only for some specific interface types which mean that now it\u0027s not only schema specific it just instant specific and we need to have the flexibility of those three use cases we don\u0027t my draft doesn\u0027t support data stores yet I will ask that and we have this node instance identifier that was borrowed from access control which "
  },
  {
    "startTime": "00:53:13",
    "text": "allows you to specify the key values if you want but it allows you to to omit the key values meaning all so I think after datastore update it will be supported what you are very good that\u0027s why I mentioned that it should be stressed out in a text but also it would be helpful with some examples yeah Eric Voigt Cisco I\u0027m definitely a fan of this work this is very good one thing that it would be good to explain a little bit more is the max number trying to figure out if it\u0027s for all updates whether it\u0027s for a certain type of interface sets whether it\u0027s whether it\u0027s for different parts of the data store be good so I don\u0027t have any strong opinions on what it should be but just additional description on max number would be good I think the model when it goes into let\u0027s say for example interfaces that will handle the different parts of the data store different parts of the or I\u0027m not understanding what you would like we can we can chat offline but the description living in point in Auckland so the comment to when were asked question about being able to do this for instances so you said that it can be done with the current data model and I agree but it doesn\u0027t really work for offline stuff right you can\u0027t really have all the instances in the offline document I don\u0027t understand why not you can only know you don\u0027t know you don\u0027t know all the instances because they interface then yes you don\u0027t know what right then probably you don\u0027t really need this for instance but sort of her in this case for interface type right and that could potentially be documented offline not with the current solution but it sounds like it could be done you could build this out to a full-blown filter managed by expert or subtree but I think that would be overkill you could also say that for the key values I love regular expressions for example interfaces are e th / whatever but then not everyone will have that conversion so I I don\u0027t see a solution that would make me happy and we need to cut the line anything so yeah we can continue this discussion but I think it\u0027s important to note that what Benoit asked for is actually not really possible with at least not if you want to do this of mine as well with the Constitution but I\u0027m speaking actually they are to use cursors for the instance draft and Bosch there is like I need the instance at the improv at the design time and I agree with you Martina there is no way to know about instances and there is like a second one a second "
  },
  {
    "startTime": "00:56:13",
    "text": "use case with instance which is I don\u0027t want to provide it like with a yang module on the server but it will be offline this one could potentially be solved but again in that situation I agree it\u0027s way easier to do it with a yang module on the server Rashaad Raman Cisco so Bella is just I just wanted to mention the comment I thank you by email yesterday this my understanding is this would be very useful if it\u0027s unchanged capable itself if that path is not unchanged capable it\u0027s not as useful because then you need to yeah so it\u0027s perfectly fine to have that actual data to be in as a node selector in the data which is being returned yes we really need to move on Thanks Taron can come up hello one in challenge over muhuali and i\u0027m going to talk about the solution alone subscription to multiple stream originators and this is the distributed extension to the existing young push solution and it provided is through the data collection mechanism that allows multiple data streams to be managed by a single subscription and per working group discussion this will support this well be trans for the independent and we identify the true use cases one is the data collection from devices with main border and the line cars we see existing solution push a solution consider only one pushes over residing in the main board so that are crafted from deny called an aggregated in in the maple just so that that the main board could be easily become the the bottleneck so we request distributed data fraction medicine that can directly push data from line cards to the crafter okay here\u0027s another use case about the iot of narrow and i just gonna skip x and here\u0027s the solution overview and i think we we also introduces this last time the subscriber whale sends the Kuroko subscription to the publish to the master and the master decomposed their decomposed the subscription through the component subscription to the n sensual agent so the agent can um push data to "
  },
  {
    "startTime": "00:59:14",
    "text": "activate to the receiver and here we have a function that\u0027s the connection between the master and the agent already exist and the master knows how to decompose the how to decompose the subscription to component subscriptions somebody may have may have interests abouts the interaction between the master and an agent and it would be another protocol for the for example for the agent registration the agent management but it\u0027s right now I was at office scope of this draft here the subscription decomposition the for this the master may need a data structure typically a resource allocation table to keep track of the mapping between the resource and the corresponding location of the subscription server which commits to serve the data and the corrector need to compose the distributed publications need to compose the data so firstly the reserved the receiver can recognize data recalls associated with one subscription according to the subscription ID and then the receiver assembles data generator at one at the same time Puran based on the recording ham and then the receiver also need to know the number of component subscriptions for the insecurity of the data so we propose to add a list of publisher ID to the subscription state started and the subscription modified notifications the publisher need to send the subscription state change notifications to the to the character here we have two options one is that\u0027s each agent send its own notification to the subscriber but we realize the character actually do not have the detail information about the resource and the location so we this information is residing in the master node so we recommended to use master to send notification to acknowledge the global description and so all the subscription state changing notifications must be delivered by the master publication channel which is the session between the master publication and the receiver and when the subscription decomposition results changed the subscription modified notification must be standard to indicates the new list of publishers "
  },
  {
    "startTime": "01:02:17",
    "text": "you know to support the multiple transport we re-examine the subscriber notification Yamoto it\u0027s already supported there and it provides options for the transport for the encoding and the detailed information about the receiver so I think it is enough for four for this for this solution to support multiple transport and there are some other questions firstly this solution is based on is generally based on the configure the subscription we here\u0027s a question do we need to consider the dynamic a subscription I\u0027m I\u0027m not sure if if if the dynamic a subscription concept applied here because in principle the subscription transportable totally different from the publication transport and sessions and some other question like is there any other issues need to be considered for this distributed extension for the yunkish work okay so Kent is a contributor so first off to the first first question and I don\u0027t think so I mean in theory we should but given that we\u0027re talking about line cards and a lot of data for a dynamic subscriber to ask for that much data it doesn\u0027t make terrible - yeah I think you would want to configure it more but if it\u0027s if it can easily be done and great if it\u0027s difficult to know so you want to see that kinda make a subscription if it\u0027s easy to be done okay okay we\u0027re gonna see those and and then otherwise I think everyone just needs to be aware that what we\u0027re trying to support is that this is a notice like from the English perspective this is just another is enabling and the note of drafts to be configured started the note of transports to be configured on a per line card basis sorry quickly from the room has anyone read the current version of the draft just a few okay alright a couple questions then we have to move on to the next uh Tim carry no kiss so I do have a couple questions because it\u0027s I think the draft as you presented it now has gone beyond elements that are in close collaboration with Jeff with each other in other words a line card on - you know the master board it sounds like you talked about some IOT nodes that actually will go across the network and so I guess if we extend the draft beyond that enclosed ecosystem right then the "
  },
  {
    "startTime": "01:05:18",
    "text": "questions come up to say hey how does how does an agent discover a master how does a master be configured with an agent and then I think the dynamic subscription that comes into play so so my question is is that really the intent that that this draft will extend pass that closed ecosystem of of masters and agents to a broader say it\u0027s go goes across the network of some sort yes I agree and I have mentioned they\u0027re seeing in this solution overview and we have assumption right and somebody may think this were this belongs to another protocol for the agent management Rob Wilson Cisco so I think I echo Tim Tims comments there actually there may be two separate problems here and maybe they have necessary quite the same solution and generally I think that the overall problem of getting data offline cards efficiently is a valid about the use case I think that\u0027s that matters people are doing that so I think the problem that\u0027s being roughly described here is is that it\u0027s a good one to solve I done read the solution drafts I don\u0027t know whether I agree with that or not but I do think this is an area it\u0027s worth working on thank you also to echo also to echo others comments this is an important problem I\u0027ve read the solution document it is a reasonable solution as for dynamic subscriptions I agree with Kent if we can find a way to get it and it\u0027s useful but the times I\u0027m seeing it used out in deployments now is mostly for configured subscriptions donnas one overall comment about environment in where this is all operating and this has been triggered by some early reviews from a transport area of the young push documents what you are describing can be potentially large amounts of data exchanged over the short periods of time you really need to look into the congestion aspects in general how that will operate what what is the impact from a transport perspective into this I\u0027m saying this just as as as a friendly suggestion because if this document goes forward it will definitely get negative reviews from a transport area now this this simply needs to be taken into account I think this draft is now transport independent and we just we firstly we describe the the the overall solution and we also we also define some extensions to the message layer or so-called application layer so it\u0027s we this dropped away I\u0027m not going to hatch let me add to that separately there needs to be some new notif for instance binary transport how to transmit and then when "
  },
  {
    "startTime": "01:08:19",
    "text": "we do have a binary notif that particular Tramp notif transport could plug directly into the configuration model that he\u0027s proposing so again when he decides independent of a particular transport any node of transport that gets defined in the future could be used either for yeah for the configured subscriptions whether it be per line card or just control point so that\u0027s fine but I think this needs to be explicitly stated that say transport magician and aspects are not being taken into account for reasons this and that okay okay great thank you thank you again far as your last question and an adoption I don\u0027t think we\u0027ll need to take that one to list our microphone Lauria and today I want to introduce document aful and the particular operation that were compatible with the liquids any advices why we want to propose a document it because as we know the and the architecture heart already be published and the protocols Tenjin also be published and our Bataclan has deployments and with the architecture but we have faced some backward compatible issues so with the rug to shears as issues and the problem to the working group and want to solicit and comments and if the working group agribusiness problems I think maybe we need to amass gate somewhere is no issue to our stresses ok series assumption because the RFC 6241 is why the implement had to not be absolute so it means that in a longer period of time there may be coexistence and and they support hunted now empirical support Kranti and the server and anonymous motor server and if we use that if the am de Conti can it be Carnot can use a convenient operational sir sorry to can use it a conventional we say to communicate with and the server but in other hand if the not MJ server I want to drive the data from the anandhi a spotty server zero have some problems the first issue is how to distinguish the server how to distinguish whether the current spot MVA or not when the server applicator admit and I\u0027m the agree lover and the eight "
  },
  {
    "startTime": "01:11:21",
    "text": "need you support it may need to support both and they can\u0027t and not and not on the account and Syria is that no standard base 22 the server to and to distinguish whether it\u0027s a contour our support MD especially but but things is easy to solve that because if clan it can use a can\u0027t predict operation to distinguish focus ample if kind his sense cat forget config at the config this our pcs to tribes data and the server can assume that it\u0027s a card is a non negative and a non MMVAs support account and if it is a current syndicate data at the data operation to which one data so the server consumes as a can\u0027t hate it support empty a Michael I\u0027m sorry we\u0027re running really low on time I\u0027m just wondering has anybody know how many people are Oh must have read the draft ok fair number number okay and did you see the email I sent this morning yes I said so already I think that it\u0027s just simply driven by the kind of RPC that the client is providing yes then is there anything more just say yes I also have another two problems okay yeah this is not our second tuition it\u0027s another issue is it how to handle to default the data the Simmons artisan system configure the default can fake data is moving to the operational data store and there\u0027s envy the server so is not clear visors and the aware server can return the Simmons out to none and a contest or none in the arrears or does if the working bruising it should return the similars out so it may as amazing impact on the operational especially handles a default behavior because the default a configuration a system configuration that move into the operational data store so if we use a cat config for example in report or model the data driving around that run indeed stall it will be reduced without that included default conflation and if we use a if we user added the data on running digital it we can create her to fabricate configuration because the ranges of the didn\u0027t doesn\u0027t have over a defaulter can see but if we want to delay it is it the filter configure the default configuration it will be false because it moved to the operational is to so "
  },
  {
    "startTime": "01:14:25",
    "text": "Marty murkland I really don\u0027t understand the problem here I think there are different or pcs and and I don\u0027t think that you can really talk about the client being non MDA or an NMDA aware I mean a client that is and then they aware might send an edit config for example or again that\u0027s fine it\u0027s the operation that has a certain behavior and the behavior of those operations haven\u0027t really changed with nm day so i i i agree with Ken\u0027s review and I don\u0027t really see the problem here so Tim Carrey Nokia I will say that we\u0027re doing this same type of analysis in another organization because we do see the problem of of the permutation of different nmda clients non MBA clients against in nmda servers non NDA servers and there some some aspects that are causing some difficulties unnecessarily with the our PCs themselves but with the interactions and in the data stores right and so if the IETF is taking on the work of trying to figure out how to make these different permutations applicable that that will go a long way particularly in some other stos that are also looking at the same problem because it is a it is a problem particularly around the data stores and the associated capabilities ok so I think I mean I didn\u0027t understand those issues from reading this draft so if you have further examples or you know can describe the problem I think that would really help just from the description this draft like I didn\u0027t really understand issues and can\u0027t as a contributor perhaps what you\u0027re thinking about is the defaults are somehow in the operational data store and and therefore an MVA server it\u0027s not in one of the configuration data stores and hence when you do I get config somehow they\u0027re not available for returning or something like this but is not really the way to think about the default values they\u0027re not really in the operational data store they\u0027re just simply people values the the opt state for sure is being tagged as being they\u0027re being tagged as default but I don\u0027t live in an operational data store but as Martin and I have been saying the the of the RFC 6241 behavior doesn\u0027t change the API is identical it\u0027s just an implementation at the nmda aware server must return the response the same way as it would if it had not been an md aware server so so that\u0027s it assumed is a guru easy assumes some shame because if we want if the "
  },
  {
    "startTime": "01:17:27",
    "text": "naam they support our support can\u0027t do read wives want to drive to to feel the data but it it kind of a kind of drive some data which non named days are were supported yes so I think we\u0027ll just take this offline okay because it\u0027s I think we\u0027ve already answer the question no that\u0027s right this is another issue is another issue is a for how to handle that system or config okay here in some one case if the kind want to can take I happy to interface for and there\u0027s an interfacer it Auto is a system config the interface there are some issue because we hope wrong because we were on to configure the IP but as it interfaces a in India is for is in the operational data store so so karna may need to create a interface of full and then configure the IP of this interface so this factory isn\u0027t the same as the Fiat Auto created interface Allah created into physical configuration into run into the stove and make it become configuration and after this interface configurations applied either will be mercury is not there because this is a system configuration operation that is to okay I think we\u0027re gonna stop here just say actually this is the same issues before it\u0027s a non-issue yes sir let\u0027s take this offline we need a segue into the net mod meeting now and and so we can just switch tables thank you Mahesh sorry for the quick turn over but we are running late and I don\u0027t even sure that from it we were gonna do five minutes chair slides but I don\u0027t think it\u0027ll it\u0027s not even do that so we\u0027re just transitioning into the net mod meeting there was a mixup with the agenda scheduling somehow they think that this is currently session two and not so I don\u0027t know how it goes anyway slides if you\u0027re looking online at the slides they\u0027re they\u0027re not lined up just look at the other session slides and and you\u0027ll see it but nonetheless when goes straight into I think Joe Clark is the first presenter right so if Oh you "
  }
]