[
  {
    "startTime": "00:00:14",
    "text": "yes oh sure hello everyone we\u0027re gonna get started now welcome to the first meeting of the privacy enhancements and assessments proposed research group I\u0027m Shivan Sahib my co-chair sorry Dickenson unfortunately couldn\u0027t be here but she\u0027s on Jabbar and me deco and all those things I\u0027m in dari graciously offered to help us so Thank You Melinda so we have four presentations today and try to get a good mix of open-source academic as well as civil society folks who work on privacy and the idea is that by next meeting or so we would also have work items to be looking at this is note well you\u0027ve probably seen this about a dozen times by now and the idea should take Polly take a look at it it has patent information as well as code of conduct and a bunch of really useful links do we have a jabber scribe thank you and Kareem offered to take notes Thank You Corinne it was easy so we had our site meeting in Montreal we heard a lot of opinions and thoughts on where we should be taking the research group and this is the first meeting and we\u0027ve already had a lot of discussion on the Charter on the mailing list we also made some modifications based on that discussion where we order to keep ten minutes at this meeting to talk about if there\u0027s any more opinions and thoughts on the Charter and the research group in general so if there\u0027s any comments was a welcome right now let\u0027s we can also get 10 extra minutes yeah Nick dirty hi Nick you should be able to speak now we can\u0027t hear you Nick [Music] hi Nick we can\u0027t hear you it\u0027s not clear if it\u0027s something in this room or at your end neck if you relay your question to the "
  },
  {
    "startTime": "00:03:14",
    "text": "jabber room we can I mean if you type your question into the jabber room we can relay it to the floor oh yeah the Charter is approved but just in case we just wanted to keep some time to maybe like go over the discussion or if anyone had extra thoughts I\u0027m ok so next question which he did which was not prefaced with Mike is just curious about the status is this already approved and settled what kind of feedback are you looking for now yep so the shadow was approved but again we just wanted to see if there\u0027s any further opinions and thoughts or on the discussion itself as well hi yes Mike thank you um Delaney Elkins I\u0027m confused is this are you asking for comments now or are you gonna ask for comments later or so we already got comments but if you have any comments you can make them right now okay um yeah I\u0027m a little are you looking for I guess is my comment is a more I guess it\u0027s generic is like are you how are you defining privacy is it is it just privacy of protocols or privacy in platforms or you know in a more general sense or what I guess I\u0027m not kind of cuz there\u0027s them there\u0027s different implications depends on how you define privacy right yeah so I\u0027m just that\u0027s a question for you guys or maybe the group great yeah we did go over this a little bit but I think the idea is that protocols primarily but also it\u0027s a research group so we do have you know we want to be able to like get different opinions on like as you said application layer all that stuff as well so then one thing I might suggest is Tim Cook had a wonderful speech that he gave at the EU discussing some of the implications of privacy in particular the amount and quantity and quality of data that\u0027s collected by some of the large platforms and is monetized so I just I don\u0027t know if that has any place in this charter or not Thanks there\u0027s no further comments we can move on to the first presentation is it yeah "
  },
  {
    "startTime": "00:06:16",
    "text": "there\u0027s a comment from Nik sorry comment from Nik I thought it was notable notable that privacy beyond just confidentiality was highlighted but no particular research items or topic seem to be suggested right I mean the first meeting we try to get do some outreach for like groups that we thought were doing interesting research on privacy and work around privacy but I mean like you said you know that\u0027s definitely like in scope and you would be interested in looking at that okay so we can move on to the first presentation by Bennett [Music] hi everyone my name is Bennett ciphers and I\u0027m a new staff technologist at the Electronic Frontier Foundation so I\u0027ll start off with quick you\u0027ve never heard of EF F we are a member funded nonprofit we fight for privacy free expression and innovation and we have over 40,000 views paying members worldwide who support us so I\u0027m gonna start with this presentation this is gonna be a presentation about privacy badger which is our browser extension privacy protection tool and I\u0027m gonna give a little context first so this is about how we came to build the tool that we built and it\u0027s also a story about protocols and how sometimes they\u0027re not enough so some of you may have been involved with this fight and please feel free to kind of interrupt with questions or anything if you want I want to keep this relatively informal because it\u0027s gonna cover a lot of ground and I\u0027d like to see what kind of discussions can come come out of it so anyway back in 2008 and 2009 and some people came up with the idea this is the corporate surveillance on the internet was kind of coming more into the the popular consciousness and people were getting upset about it for the first time well larger group of people was getting upset about it for the first time and so this idea that maybe there could be a way for consumers to actually opt-out of tracking the internet didn\u0027t have to work that way not everyone had to be tracked all the time and some ad companies actually thought this might be a good idea to at the very beginning "
  },
  {
    "startTime": "00:09:16",
    "text": "because they thought they might be able to head off some of the consumer backlash against them by agreeing to not track a small group of people who would opt into this do-not-track idea so in 2009 a group of researchers proposed the first version of the dnt signal this is a header that gets sent with every every request for a resource over HTTP and it was implemented as a Firefox extension and a gained momentum really quickly and 2010 the FTC made a call for a universal dnt system that tech companies and browsers could adopt and it got adopted very quickly a working group was charted at the w3c by the end of 2011 pretty much every major browser had support for this opt-in D and T signal you could go into the settings say I want to send DMT with every request that I send and in 2012 the digital advertising Alliance which is this giant industry group that represents many of the biggest digital advertisers said we are going to respect the DN T signal because this is a way that we can avoid further regulation and everything looked great around this time around the beginning of 2012 and then some some things change some people get a little zealous Internet Explorer 10 and Windows 8 decided to launch ie 10 launched with DMT turned on by default that was the Express settings and ie back back in 2012 was still I don\u0027t know if there is still the biggest browser but they were so massive chrome hadn\u0027t come to dominate the entire market yet and so this was this was huge all of a sudden the number of people who had often into DMT went from like single digits to low double digits percentage to like a very significant chunk of the web many people who never would have thought about tracking at all otherwise and the digital advertising Alliance immediately backed out Google Yahoo a bunch of other companies started putting in their policies we don\u0027t know how to honor dnt we don\u0027t know what it means we\u0027re not gonna respect it at all and that\u0027s when we had the e FF who not me other people at the FF who had been working on this we\u0027re like things breaking down this is not going anywhere we need another way to try and allow people to opt out of tracking and that\u0027s when we start developing the privacy Patrick and then just as sort of an epilogue about a month ago the final charter for the w3c dnt working group expired and there was absolutely nothing to show for it so privacy badger what the idea of it was it was born out of this wish for users who didn\u0027t want to be tracked to have some sort of way to opt out of tracking and so it\u0027s it\u0027s a non-consensual tracker blocker we wanted "
  },
  {
    "startTime": "00:12:18",
    "text": "to obviously provide users with a technical means of blocking trackers we also wanted to spread awareness about tracking and D and T at the time we\u0027re hoping we could still sort of salvage that as as a viable means of opting out we want to promote our idea of dnt compliance and what it should mean for a company to respect the NT and we wanted to also just kind of have have a stick to go along with the dnt caret to punish companies who didn\u0027t respect the d NT signal coming from users browsers but we were a nonprofit organization at the time we didn\u0027t have a get very few coders on staff and we didn\u0027t want to become a software company in order to make this happen so I had to be built by a very small group of people it also had to be easy to use in cross-platform we really wanted this to be a high-impact tool and the final constraint was we didn\u0027t want to use a block list we didn\u0027t want to do the same thing that every other tracker blocker out there does which is just have a curated list of these are all the things that we know do tracking and we\u0027re gonna stop them and that\u0027s for a couple of reasons mainly we didn\u0027t want to have to have that sort of editorial responsibility but also we were thinking like in the wrong hands a block list is a censorship tool if anyone were to ever compromise our motivations or surreptitiously force us to do something that would could effectively be used to block big parts of the internet for all of the people who trusted us and use privacy badger so what did privacy badger become and what is it now basic mechanics privacy badger is it\u0027s a non-consensual tracker blocker so the first thing it does it turns on dnt new browser it sends a DMT signal to every site and every resource that you request and it looks for dnt policy posted at slash well-known slash dnt policy txt on every domain that your browser visits and so anytime you you fetch a resource it\u0027ll first check to see whether the domain that hosts that resource has a DMT policy posted and if it does and if it\u0027s one of the policies that we acknowledge as being a respectful policy we will allow resources from that domain to do whatever they want so they can perform actions that might otherwise look like they\u0027re tracking actions because we trust that this legally binding policy that they will follow this legally binding policy and not use the data that they collect to track if there is not a dnt policy and if it looks like a domain is taking a tracking action we will learn to block that domain and so a privacy badger uses heuristics to identify trackers so at the at the very beginning when you have a fresh instance of privacy battery it doesn\u0027t block anything all it has is a set of actions that identifies as tracking actions and as you browse around the web it will try and learn "
  },
  {
    "startTime": "00:15:19",
    "text": "which domains take these tracking actions and then block them in a third party context from there on out and the the basic mechanic is three strikes from your out so if you are browsing around and you see if privacy badger sees the same resources from the same third-party domain on taking tracking actions on three separate first party domains it will mark that domain as a tracker and block it from there on out in any third party context so what is a heuristic we kind of went for the low-hanging fruit luckily there are a lot of very low hanging fruit in the the tracking world the first one is just third party cookies third party cookies are still used everywhere even though there are a lot of tools to block them and they\u0027re relatively easy to opt out of so we consider any third party cookie with sufficient entropy to be a tracking cookie we also look for local storage reads and writes with sufficient entropy those are basically the same cookies and canvas fingerprinting we have a couple different heuristics to identify more common types of canvas fingerprinting and we detect and lock that as well so we had to make some compromises to keep it the scope relatively contains the first one is we assume that each domain each top-level domain plus one so that\u0027s like google.com and not like mail.google.com or it\u0027s like any anything underneath google.com is either a tracker or not so once once you identify like sub domain that sub domain TLD as tracking it also identifies everything under the TLD plus one as tracking as well unless the company has posted a do not track policy on some sub sub domain in particular and we\u0027re also assuming that outright blocking resources from domains that perform tracking usually won\u0027t break first party sites and that\u0027s just a usability thing we have to go on this assumption otherwise the tool is kind of enviable and that on arrival and so for when these assumptions break down we have a few different workarounds the first one is cookie block domains that\u0027s sort of a middling in-between outright block and resources and outright allowing resources the second is we have a feature called widget replacement which I\u0027ll talk about later and finally we just have user control so every every action that privacy badger learns to take against every domain can be configured and changed by the user if they want and so that gives them the power to the bug issues on sites and to block trackers that privacy badger might not otherwise catch first I\u0027ll talk about cookie block domains these are domains that privacy badger has decided our trackers but we have also determined are unfortunately essential for the operation of a significant number of sites on the web "
  },
  {
    "startTime": "00:18:20",
    "text": "so these sites are not allowed to perform local storage reads or writes they\u0027re not allowed to set or get cookies we stripped the referer header from all requests of these domains and the way these domains are propagated is we just have what\u0027s called a yellow list which is every domain that we have manually identified as being something that\u0027s essential to the function of big parts of the web goes on this yellow list and this is a curated list and it\u0027s it\u0027s all goes to our github and this is this is the main vector that we have to resolve broken site issues so someone says oh everyone who\u0027s using privacy badger is breaking my site and so then we can build allow them to make their case to get on the yellow list and this rests on the assumption that blocking access to these functions almost never breaks a site like if you if you have something that relies on google.com if you if you block these certain functions for scripts that come from google.com most of those sites should still work and that turns out to be pretty reliable in practice next widget replacement this is a really cool feature and it comes from some research that happen at the University of Washington back in 2011-2012 so this is just we have we identify certain widgets and like add-ins from third parties that are common across the web that also happened to perform tracking so like the Facebook like button is the most common one every time you see a facebook like button that has sent Facebook your login cookies they know that you visited that site but it also is a useful feature for a lot of a lot of media sites and so we have this sort of we have we have this feature where we identify that a facebook like button is going to be loaded and we instead insert our own resource that looks like the Facebook Likes button but we don\u0027t allow the facebook like button to actually load so no request goes out our resources there and then the user can click on our resource and opt in to being tracked by the facebook like button but also up to access the functionality that is that goes along with that so we we have that for SoundCloud as well yeah certain sites also certain sites and eat cookies like so putting them on a on the OLS isn\u0027t enough to get them to work other sites need refers that kind of thing this is a bit labor-intensive we have to do a good deal of work to build each one of these widget replacements but it is really effective and it\u0027s a great way to deal with things like like buttons and embedded media finally the ultimate fallback is user controls so if you if you open up privacy badger in your browser the little little tooltip you will see a list of all the third-party domains that have been loaded on the site that you\u0027re on and the ones that privacy batter has identified as tracking the actions that has taken whether it\u0027s being blocked outright or being cookie blocked as well as all the "
  },
  {
    "startTime": "00:21:21",
    "text": "domains that it doesn\u0027t think are tracking and you can manually set what actions you want privacy better to take for those domains in the future so finally I\u0027m going to talk a little bit about the kinds of things that we\u0027re doing to move beyond privacy Badgers original core mission and the things that we\u0027re looking at down the road as where we might have to take it the first one and this is this is an ongoing effort it\u0027s kind of been around from the start is limited first party in software specific features so like the big one is outgoing link tracking so if you if you\u0027ve ever if you\u0027ve ever used social media Twitter or Facebook like on Twitter you\u0027ll notice that every link that you tweet is wrapped in a Tico link and so that has a dual function of shortening the URL Twitter says it adds security features but more importantly it allows Twitter to see every time you leave their site where are you going Facebook we will do the same thing there\u0027s a little less transparent we have some pretty cool blog posts about how those features work and how privacy Badgers counter features actually work to stop them and this is a thing that well it\u0027s not quite third-party tracking in the original sense that privacy badger was designed to block it is third-party tracking in the sense that users understand it it\u0027s like you\u0027re taking an action to leave a site and that site really doesn\u0027t have any shouldn\u0027t have anything to do with where you\u0027re going afterwards and so users feel that this is something that privacy better should block another one is we are trying to build heuristics to identify what we call first to third-party tracking these are trackers like Google Analytics so the way Google Analytics works they don\u0027t use any third-party cookies every site that uses Google Analytics sets up its own first party Google Analytics cookies and then has JavaScript which makes requests to Google Analytics with the values for those first party cookies in the URL parameters so it\u0027s a little it\u0027s not quite as easy for Google to link one user who visits two different sites with Google Analytics enabled to link those two visits together because they don\u0027t have the same like cookie idea that\u0027s persistent but obviously there are a lot of other ways to correlate those two visits for google once once you\u0027ve made two requests from two different sites like they few drapy doesn\u0027t change which it usually doesn\u0027t they can link those visits or like they can use TLS session resumption things or just TLS sessions in general so we\u0027re we\u0027re working on features to identify and block those and web beacon requests are another thing this is a relatively new feature in HTML it\u0027s allows sites to set up asynchronous "
  },
  {
    "startTime": "00:24:23",
    "text": "requests that go out when a user takes a specific action on a web page that might be clicking on a link or navigating away from a page or doing something else and they\u0027re pretty much exclusively designed to do tracking and so we\u0027re gonna start considering those requests track and grow up requests as well when they go out to third parties we are working on features to strip URL trapping parameters like UTM and the new FB CL ID fingerprint randomization instead of just blocking fingerprinting scripts from loading we might try and start randomizing fingerprints when they happen in a first party context and finally detecting and blocking screen recorders there\u0027s a whole new class of companies that do things like you can install their JavaScript on your page and it will record every movement that your users take on that site and then you can like replay them and stuff like that and they\u0027re almost never disclosed on the sites that they\u0027re use and so this is the kind of thing while we\u0027re while it is first party tracking most users would like to opt-out of it if they could and so we\u0027re trying to figure out how to block that next the next kind of direction we\u0027re taking privacy badger is a thing we call badger set and this is just a sort of Observatory which we use privacy badger in which we use privacy better to map out the trackers on the web so we just have a cloud computer instance with running selenium like a headless browser and we have privacy battery installed on it and we browse around the web and measure all the trackers privacy badger sees and identifies on its trip around the web and this is well visit a few thousand to like ten thousand sites and the other thing is last view is ship privacy badger with not a curated block list but a pre trained list so it\u0027s a list it means the first time a new user installs privacy badger nowadays they will block most common trackers because it\u0027s as if they\u0027ve been browsing through all these common sites and it\u0027s it\u0027s all heuristic based but it does ameliorate the problem we used to have which is people would install privacy badger go to a web page and be like oh it\u0027s not blocking anything like it doesn\u0027t work an immediately uninstall it and it also allows us to test out new heuristics and measure their impact on the web so this is just the result of a recent scan we did on the top 10,000 sites on the majestic million and these are the most common trackers we identified facebook.com/ was by far the most common they use third-party cookies everywhere they have the Facebook pixel on as you can see around 1/3 of the popular web Google was the second most common twitter it\u0027s all of the social media companies these days but it\u0027s really a mostly a two horse race sort of a three horse race if you count Twitter double click of course is also owned by Google and this is the result of a test of our new cookie pixels sorry cookie "
  },
  {
    "startTime": "00:27:25",
    "text": "sharing a pixel heuristic which is designed to identify that first a third-party tracking case and to catch specifically Google Analytics and so as you can see we we identified 70-something instances of Google Analytics tracking on the scan we also identified a few other companies that are using similar techniques and finally the last thing that we\u0027re kind of have on the horizon is privacy bedroom mobile and that\u0027s because the web is no longer really the primary way that most people interact with the Internet Mobile mobile browsing and mobile apps are really starting to eclipse the the sort of mind share of people\u0027s activity on the web and it is much much more difficult to block trackers in mobile apps they\u0027re in these little siloed software environments where you can\u0027t really install an extension into most apps they\u0027re protected by the operating system and it\u0027s so it\u0027s very difficult to detect and block trackers within these environments the only way you can really do it is in a with a VPN using the VPN API you can have like a VPN that just sort of grabs every request before it leaves your phone and you can filter things there but thanks to the rise of other great privacy features like HTTP and in the future dns over yes and stuff like that it\u0027s going to be really difficult to filter traffic even in a VPN environment and so obviously we\u0027re not advocating for people to rollback the stuff the progress we\u0027ve made with HTTPS but it does present these unique challenges for like it\u0027s great that the NSA can\u0027t surveil people but it\u0027s going to be a lot harder to stop corporations from surveilling people in environments like this anyway I think I might have used up a little too much time that\u0027s fine but if anyone has any questions [Laughter] hi there this is Daniel con Gilmore from the ACLU thanks for this work it says awesome stuff one things I wanted to mention about the badger set is that you actually have an additional feature that you didn\u0027t mention in your list for a badger set and that is that privacy badger as a learning tool modifies the user\u0027s behavior on the basis of their history and modification of behavior on the basis of history is one of the fundamental patterns that were used to seeing for tracking mechanisms so this is one of the issues with HSTs for example is that HSTs creates a the ability to set like a meta cookie by serving someone a bunch of domains giving some of them some of them HSTs and some of them not and then observing later whether they come back HCBS or not so by using Badgers set what you\u0027re actually doing is you\u0027re you\u0027re giving people a baseline that protects "
  },
  {
    "startTime": "00:30:28",
    "text": "them from from actually having that same pattern used against them at least with the things that you\u0027ve pre browsed so so it\u0027s just it\u0027s it\u0027s nice to know that that\u0027s you\u0027re getting the extra protection there so thanks for that thank you yeah that\u0027s I\u0027m not even sure we considered that but that\u0027s absolutely it\u0027s absolutely true thanks a minute it\u0027s Corinne from the I had a question which I\u0027m sure you have an answer to but it just didn\u0027t come out of your presentation which is so I assume that you can read all of the data of the websites that your users visit yes what do you do with that does that seems like a privacy turn yeah this is a if you read the reviews on our web extensions stores on a Chrome extension store there are a lot of people complaining about that we would not like to have access to all the data on all of the sites but the way that permissions work it\u0027s the same thing with HTTPS Everywhere our other extension HTTPS Everywhere only needs access to read and rewrite URLs but the only way to get that permission is to get access to all data on all sites all the time and so there\u0027s very coarse-grained in a web extensions environment so we have to request that the most permissive ones but yes so the only we we instrument some some of the things like local storage and some of the canvas functions in order to detect tracking mechanisms but important thing to note is that no data ever leaves your browser and goes cff or anywhere else unless you send an error report the only time your browser makes your browser makes two kinds of requests uff one is once a day it makes it get requests you get the new version of the yellow list and the other thing is if you ever decide to send an error report it will include like the information that you tell us an error board but never otherwise does any information lead your pastor thank you there\u0027s an interesting discussion there is a extension permissions in general and what the model is I think yeah yeah for sure we\u0027ve got yeah there there\u0027s some open bugzilla threads about this and the problems with that in general hi Malory you go from article 19 um you may not know this because you run around then but I was just wondering if there was a discussion about potentially developing privacy badger as part of the w3c group that was on dnt and if you did it if you like why you didn\u0027t decide to do that that\u0027s a good question I don\u0027t know I can get back to you though Thanks I am from Germany so I\u0027m using privacy betcha um could you say something on you know feature interaction between different extensions because I\u0027m using privacy patch ghostery at Lucas here and there sure yeah and I mean unfortunately sometimes they have to switch off one or the other I said something that you also consider powder yes so there\u0027s there\u0027s unfortunately not a lot of ways within the web extensions API that we can either detect that you\u0027re using other extensions or interact with them at all "
  },
  {
    "startTime": "00:33:29",
    "text": "so there\u0027s a problem where sometimes like if you\u0027re using I use I personally use you block origin I think it\u0027s great alongside privacy better but sometimes like especially like with surrogate scripts is another feature we have which I didn\u0027t mention and it will like we will try and insert a surrogate script and you block word and tries to do the same thing and there\u0027s a clash and it stirs you know ugly air and doesn\u0027t actually break either extension but it does it\u0027s a bad user experience there\u0027s not much we can do about that but I can tell you that most of the time they work harmoniously like tracker blocker extensions that use lists like you block or gostrey will block a lot of things and then privacy badger will block some things that they don\u0027t know to block because it\u0027s privacy better has learned to block new things using heuristics and that that usually doesn\u0027t cause major issues but if you have experienced specific issues we\u0027d love to hear about it please open an issue hi javonni aside the N until they uh so thanks for for developing this before a fee AFF to doing that ii think it\u0027s great to win yes thanks for that i\u0027m just a common here if he was not explicit but I like the idea Caesar don\u0027t have any kinda me treat data going back from the users to you guys there mmm that project I did for the Rena have this browser somewhere else in a cloud and do all this analysis all those measurements collect all this data it\u0027s a way to also obtain information whose track and so I like this more of like obtaining some information in an indirect way without violating the privacy of user so yeah absolutely thank you mr. Iijima I always have a question when the IIC DS approach is that how much of a cat-and-mouse game is it yeah that\u0027s that\u0027s a good question so fortunately and unfortunately privacy badger is not that big in the scheme of things we have we have a few single-digit million users but there are much bigger ad blockers and the tracking company is most of them operate on scales where they really just don\u0027t care about the revenue they lose from our users so we like it on the one hand it means that we can\u0027t apply as much economic pressure as we would like against these companies but on the other hand it means that it\u0027s usually too much effort for them it\u0027s not worth it for them to go out of their way to avoid privacy badger and furthermore it\u0027s it\u0027s pretty easy to identify new tracking methods in the wild like once like fingerprinting is is basically only used to circumvents anti tracker like when people decide to block cookies fingerprinting is kind of a backup that companies can use but it took a long time to develop a lot of these fingerprinting scripts and once you know what to look for it is extremely easy to look for and block these fingerprinting strips so I think I think in the end if there is an arms race tracker blockers and users have the advantage we be "
  },
  {
    "startTime": "00:36:29",
    "text": "cutting the line now people already terakhir OGF I was wondering do you also provide guidance or for like people want the websites their privacy preserving and that respected dnt end yeah so we have dnt policy that we have written our lawyers have written that\u0027s available at our that well-known slash dnt policy and we encourage everyone to use that and read it and use that as guidance for how to respect users data and then beyond that it\u0027s just generally as a site owner the more you can limit the access you give third parties to users on your site the better but no we don\u0027t have we don\u0027t have a specific guide I don\u0027t think that might be useful to write up though market office as ID unless I love the tool thank you been using it for years but I also have an ad blocker on the same browser and sometimes it\u0027s a little bit unclear for me who is doing what you suppose I would remove the ad blocker would I get ads then again even if I use your privacy badger oh yeah you\u0027ll get some ads so most ads perform tracking as well we don\u0027t block ads our policy is not to block ads but most ads use tracking and so we ended up blocking most ads just kind of coincidentally but if you did remove your ad blocker you would probably start to see some ads in some places and just and also some content again because yeah you\u0027re often I get blocked entirely because I have that yeah and some more content so the other thing is if you if you open up the privacy badger widget at the top right of your browser you can see all the domains of privacy badger has identified and decide to take action on and so like it\u0027s a kind of an easy experiment it\u0027s like if you want to disable your ad blocker see the domains privates better seized and then enable it again you can the difference will be what\u0027s gotten through your ad blocker and to privacy battery thanks thanks that is Sophia and juror there on the media code so if you need to request the mic hey hey me guess we can\u0027t go great yes I got also hear you okay you know I hear each other green oh yeah yeah so you can "
  },
  {
    "startTime": "00:39:29",
    "text": "just let me know and I\u0027ll advance the states okay awesome so we will start okay so hi our name is Sofia celli and you Devon wagon and we work for in Sao Paulo Brazil for our centers the schools centrally autonomy a busy town and today we are going to present you all this doctor stock that is called - no evidence of communication oh dear before which is basically a presentation to introduce you of the record messaging protocol protocol innovation for sound excess light yes all right so what is out here OTR stands for off the record messaging it\u0027s an academic paper that was first published in 2004 by Nikita and Boris off in Goldberg and Eric Brewer version 3 provides encryption with forward secrecy of all your messages authentication so you can be rest assured you\u0027re talking to the right person most importantly deniability anyone can force messages after our conversation but during a conversation it\u0027s assured the messages that are seen are authenticated and unmodified before first entry we had version 2 which was released in 2005 and solution 3 was published in 2012 more implementations followed in different languages has seen clients most popular operating systems a specification was released and has been implemented in a library called lip OTR and clients pitch in OTR by the Oh trt signal created by Moxie Marlinspike and Trevor Perrin others drew inspiration from the OTR protocol for their signal protocol that\u0027s been widely used by lots of people around the world now this next slide okay so basically there was a very brief introduction to what OTA is and the consequence question that we have of that is why we need a version fold we already have different versions of OTA and to answer these questions we mainly will have to look at the main purpose of or Tia the main purpose of OTA was to give deniability so you know Tia version four we wanted to prove this the definitions of the nobility right now the current academic cryptographic literature has already established good definitions and types of what deniability if we have now online offline participation and messaging ability and we wanted to include all of these types of different abilities note here before what does online and offline deniability means deniability can\u0027t be defined in the terms of Oh Tia not as denying a conversation but rather us but rather as "
  },
  {
    "startTime": "00:42:31",
    "text": "saying that anyone could have participated into that conversation so online basically means that during the conversation no one connected that you participated all specific message during the company of Linden everything after the fact that the conversation happened no one cannot say you participated also it I\u0027ll take a message in a conversation I participated in a basically means that you can deny having participated in a conversation or having set and a specific message in the conversation all right so the Koreans say those things Canadian specification that\u0027s on github.com /ot fe4 so govt for at least a film specification and some of the architectural decisions that have been made along the way we also have an implementation called Nepal trng which is written in the C language at this point in time next to a library we have a client implementation that\u0027s underway called pigeon - OTR and G we have plans to package it for Debian and Ubuntu there\u0027s also a pre key server implementation so you can do in synchronous encrypted communications okay so I\u0027m sorry my audio stopped for some reason so yeah as I was cooking we have different deniability properties in note here before and we also have different security properties that we wanted to also to have an OTA before this kind of different properties first most that we wanted to raise the security level of the overall protocol to two to four by using elliptic curve cryptography we also wanted to clear the notion so forward and forward secrecy that means that basically if you had if an attacker can compromise one of the keys used to encrypt and decrypt a message and it passed the future message it would not be able to be decrypted because you only generate a key per message I keep her encrypted and decrypted the message and we also wanted also to include the notion of course compromised security in the way that the protocol Odia before now has a self-healing nature in the sense that if an attacker compromises one of the message keys then the protocol will heal itself and an attacker would not be able to decrypt anything else or to know the contents of anything else besides from the message that it was able to decrypt also wanted to increment a new network "
  },
  {
    "startTime": "00:45:32",
    "text": "model in the cells that OTA v3 had limitations in the sense that it was not possible to do OTA b3 in Laughlin messaging or an out-of-order network and without here before we actually have offline messages an out-of-order network we also have wanted to improve the cryptography to improve the cryptographic primitives well because right now the current academic literature has a lot of great photography primitives that are not used in practice and we wanted to use these new cryptography primitives which are secure enough for us to be used and yeah so basically how audio before looks in the practice you will have always two participants this Alice and Bob and each one of them we hey I want you I mean is very support out here before then we go ahead and this other protocol after that you work to actually witches so figure out your audio cut out so sorry I also just came back so let\u0027s talk about the double ratchet so due to the the way the online community way of communication through the day it\u0027s possible we can do a we can achieve asynchronous messaging like the signal protocol through the double ratchet so even if the other participant is offline and you still want to send them a message when it happens there\u0027s pre keys at the pre key server which allows the user to receive messages that he or she is able to decrypt when even when you\u0027re not online and when you come aligned these three keys will be able to decrypt the messages so even though this also comes back to the deniability part we have two ways of doing a verification so one of them is to S\u0026P which is socialism in a protocol and the other one is to fingerprint verification so through the S\u0026P you can actually have the other ID a question to a shared frequency you have discussed before you are able to actually authenticate that person in question or if you actually have already have Maddie you\u0027re not trying going to change "
  },
  {
    "startTime": "00:48:34",
    "text": "fingerprint anytime soon you can actually do a verification through fingerprints next slide please so I think I already spoke some about the specification so this - specifically this so the the fill specification and some of the code is actually up on our github we actually have an implementation currently OTO and G which is written in the C language we also actually have a plug-in for pidgin called pigeon - OTR and G I think some of it is actually already packaged for the arts Linux distribution our plan is to also packages for Debian and Ubuntu and hopefully we can find some people to packages for us for operating systems like fedora and others there\u0027s a pre key server implementation so you can do asynchronous encrypted communication which is - the double ratchet protocol and there\u0027s two more implementations underway at the moment one in Java called OTR for J by Danny phone Herman and one in golang biola beanie was working at the central autonomia digital hopefully we will see more implementations in the future that span into the mobile ecosystem as well the great thing of course is is that a geography for is not just theory or academic literature it\u0027s quite the opposite is actually an applied pricing and enhancing technology that is free and open source which cuts to the theory and practice next slide please so these are some of our get repositories that you can find online which actually lists so the first one that slash OTO fee for slice of govt four is the fill specification that can be checked out OTR fee for - pre key - server is our pre key implementation that\u0027s based off the free and open source prosody XMPP server the library can be found and as well as the the plugin for the pigeon I am clients and next slide please so he will see the OTR ng pre key server and the other components part of their pre key implementation as well as the toolkits actually and the toolkit is interesting because it allows you to actually force that part of the transcripts after after you\u0027ve actually ended the "
  },
  {
    "startTime": "00:51:37",
    "text": "conversation all right next slide that\u0027s our talk thanks I hope it was actually follow ball even though we had some of the technical issues apologies for that I\u0027m not sure what\u0027s going on if there\u0027s any questions I\u0027m happy to answer great all right Steve so there\u0027s work in ITF called MLS a familiar with that and I\u0027m wondering how out your for relates to that or is different from that I\u0027m not entirely familiar with the mos no I this part is our likely first answers defense question so MLS is a whole messaging protocol where you have lots of entities and different parties in the system that you all have to set up and run your learner\u0027s protocol while OTR is more of a add-on so you encode on any existing message communication you have and then you can send Santos and currents on it is really lightweight it\u0027s between two endpoints and so you don\u0027t have all this problems that they are introduced with group chat where you have like authentication parties and relocation of keys when people join and common that\u0027s and Melissa\u0027s a huge protocol compared to the OTR okay can I also try to answer about MLS okay I didn\u0027t hear the answer of the person who was just so key but MLS from what I have actually been reading does not provide deniability and one of the main purposes the OTR is actually to provide the inability and then and OTR before is actually also beef protocol because it also tries to achieve security privacy and encryption and - an encryption of all the messages as well as forward backwards post compromised security which was also one of the aims of MLS but also it has an ability in all of its different types so I will say the main difference between MLS and OTA before is that it had it here before has the nobility and MLS does not happen so I Steven fro again sorry just a clarify my question I understand the difference do you know T or and kind of group nice group messaging like in large groups with MLS what I don\u0027t understand is whether you know one of the efforts in MLS is to try and improve the cryptographic primitives and get them you know widely kind of studied by the community by kapag refers so it would seem that having you know given that you have a lot of the same security guarantees you\u0027re looking at it would seem like there\u0027s some be some benefit in having the same kind of scrutiny applied to these things yeah okay are you going crazy oh I completely agree with you one of the aims also widowed here before was basically that it becomes also an inspiration protocol so one of the reasons why we have ot is that it was an inspiration protocol to other kinds of criticals like signal took inspiration from me and so other protocol so tear before each "
  },
  {
    "startTime": "00:54:37",
    "text": "aim is also to be an inspiration to other protocols so if ot are updates the cryptography primitives all the protocols would update as well go to the global Center for Internet and Society so he was Sophia your voice is breaking off at the moment but could you just briefly explain again different deniability properties and specifically what what is message and but participation deniability provide okay sure yeah I\u0027m sorry I\u0027m breaking but yeah okay some participation then abilities that you don\u0027t know one on a conversation can actually say that you participated into that conversation no one can actually prove that a messes per message deniability means that no one can prove that you said on a specific message during that conversation every school I have a perhaps different take on this so I think to Paul\u0027s point I mean I think so like MLS and other messaging on systems and OTR obviously have a lot of like things in common about like doing you know that the very security properties that on yours indicating um I think that certainly like if people from OTR wish to be involved in MLS that would be extremely welcomed um I think I think I speak for everybody involved in that one on the internal surprise that but the sort of alternate heavyweight on I mean obviously a group messaging protocol when it\u0027s the stanchion resting settings before heavyweight but the actual on when you skele permit is down to one the one less energy I\u0027ll show that to some more uh disappoint deniability is kind of interesting as you say there two kinds of deniability um mls you like don\u0027t make no attempt to have the liability for these communication at all I\u0027m not sure actually that\u0027s the impossible a multi-party setting on how to think about that one on on LS is just agnostic on the question if the my ability for messages that the protocols aren\u0027t willing to flushed out to specify what is it\u0027s not gonna be the case there\u0027s really been discussions about making that work so again you know we certainly love to have your participation if your existing working MLS as well yeah that is awesome I we have been looking at really at some of the specification of MLS so yeah it will be nice to participate and yes of course great look charging abilities is still an unsolvable problem right now there\u0027s some cryptographers that have been actually looking into this to generate some papers around it and this is something respect to have on previous versions of no previous one consequent question versions of or Tia okay doc responsible area director for the MLS working group basically just seconding "
  },
  {
    "startTime": "00:57:38",
    "text": "what record said you know the deniability properties of MLS are not a health question yet so we definitely welcome further input and involvement in the working group and you know hopefully we can see all their weight thanks your in Sofia all right thank you thanks next up we have David Oliver will transport very good well thanks for the invitation here\u0027s your on so I decided that maybe the best way is to do a summary of everything here at the start because not sure how much time we\u0027ll have to get into some of them some of the detailed things so tries to go from a high level to a little bit lower level here so pluggable transports are a defense against internet censorship and surveillance pluggable transport addresses or abuse gates either the address or the contents of network flows the primary goal being to prevent interception by intermediaries who deploy deep packet inspection the idea of pluggable is that it\u0027s written to a specification that\u0027s being worked out actively by a small group of people interested in this area and we need to be pluggable because the half-life of an obfuscation technology is pretty short and the developers of those technologies and the developers of software that use them need a way to get those technologies into the field I\u0027m going to mention here a couple things that first of all obfuscation requires a partnership between a client and a server or software on the device and software in the network pluggable transports are currently written as VPN services or as local that is on the device proxies or directly into app put McNay built directly into applications and pluggable at this point means pluggable by the developer and not pluggable by the end-user just a quick point about why should we care about surveillance you know over time we\u0027ve started to learn that surveillance runs sort of at cross-purposes to individual privacy privacy is among the core concepts were interested in in human rights and I just wanted to note here that Guardian project for with whom I\u0027m involved work mostly in mobile and mostly on mobile networks so although there\u0027s a wider space out there our expertise area tends to be in the in mobile and the opportunities and problems of the mobile operating systems and mobile networks at the time we started this there was a huge disparity between the privacy technologies that were available on the desktop in in in mobile devices that\u0027s changed over time of course ok deep packet inspection for those of you who have not heard of it "
  },
  {
    "startTime": "01:00:39",
    "text": "when the Internet protocols were designed they were designed to serve to route packets around the internet but this kind of data that\u0027s produced by routers started to get used for purposes other than routing as the technology the hardware technology and software technology in router boxes got more and more and more and more powerful became possible to look at every aspect of every packet not just the IP or headers so this was this has been rolled out over some relatively small number of years in a relatively small number of places but it\u0027s a growing threat because of course you can start looking at every every contents of every packet in your network and even though you we have an encryption there are still ways that there\u0027s still recognizable patterns in the packets produced by that software that allows you to know or suspect the packets are of a certain type and then start taking action on that so you know we\u0027ve heard the the analogy of the postman reading your mail and even even regular citizens get worried about wow what happened if the post-office read all of my mail so now we\u0027re kind of in that space in the on the Internet and some people would like to have more privacy than that so we we are working on this area so can you defend yes throughout few stations there are two ways basically to obfuscate one is to I\u0027ll use look at number B here first which is that you obfuscate the intended a direct service address the other is to obfuscate what\u0027s actually in the packet so but this this idea of obfuscating first of all requires that it gets unappreciated before it reaches the actual service definition that doesn\u0027t make sense to deploy obfuscation technologies that every website or every application service has to understand so there\u0027s a transforming state and a nun transforming state but it\u0027s also important to recognize that the kind of threat the kind of techniques we use tend to be unsuspicious at one point and then suspicious at another point and so we meet pews occasion technologies are moving target and application developers need a way to as I said get this stuff get their work out in the field faster and so in roughly 2012 this idea of pluggable transports was proposed initially by the Tor project these technologies act at the network transport layer so applications don\u0027t see them having their effect applications still just continue to write and read bytes from what they think is their communication endpoint and transforms happen independently of that there are three techniques the "
  },
  {
    "startTime": "01:03:40",
    "text": "first year if fronting is to obscure the address of service and the other is scrambling and shape-shifting actually obfuscate the data that\u0027s in your in your communication the to the latter two are sort of demarcated when one scrambling has just to change the stream of bytes somehow there a variety of ways that have been looked at do this but shape-shifting is sort of a special case of that where you are making your byte stream look like somebody else\u0027s byte stream and in that case maybe music streaming is deemed to be benign in today\u0027s network landscape and so people don\u0027t surveil music streaming whereas they might surveil something else so shape-shifting is a subset of scrambling but it\u0027s severe for a very specific purpose so just to be clear we we do have a two-party system here a client or something software that\u0027s built on the device and then software that exists in the network to do the obfuscation the transform untransformed and that\u0027s important because we the application are the the pluggable transport has to know where it\u0027s a partner endpoints are we\u0027ll discuss them we\u0027ll discuss this a little bit further this idea of a bridge is common to what goes on with tor and what goes on with VPNs and it should be noticed that these endpoints these service endpoints in the network are these service intermediaries in the network pardon me you know are often the targets for sensors and surveillance engines and therefore their addresses tend to be mercurial is a nice way to put it managing the configuration of these servicing intermediaries these bridges is a big problem for VPNs tour and that increases with pluggable transports since each kind of transport has to have its special kind of bridge so there are there\u0027s also work underway to look at crowdsourcing bridges that is making the number of bridges available impossible to black but of course that means impossible to find as well since we\u0027re client-side people and specifically mobile I can really talk mostly about this and there are two ways to implement this technology on the device one is as a VPN or a virtual private network and that means that we can use an operating system interface to to intercept the traffic from every application and and work our magic on it this is a purpose of a very narrowly defined interface in both iOS and Android for very specific purpose so and specifically the the VPN style purpose that allows companies to have their tunnel their private traffic "
  },
  {
    "startTime": "01:06:40",
    "text": "through the internet tor however is accessed application by application and there are a couple of reasons for that in across the different operating systems but you\u0027ll notice that iOS the feature has to be bundled into the app because of the constrained process model on iOS whereas in android there is an application called or bot that is as viewed as a socks proxy by applications so this is just the kind of very rough diagram a very simple diagram the black line inside the blue square there means that there\u0027s a nice standoff between an application and how it\u0027s written and how the how the traffic is intercepted by by the transports and you\u0027ll notice that each transport has a bridge or multiple bridges and then the application services are are beyond essentially beyond the bridges or outside the domain of the monitoring entities so we\u0027re currently we have several types of obfuscation relatively easily available here we have scramble suit and AB few skating and proxy for those are the first two and there those are scrambling traffic meek is is a transport that hides the address to which you\u0027re going and format transforming encryption is the start of something to actually shape-shift traffic these are these are a little bit farther out we\u0027re working on the latter one here and snowflake which you know is going to work with web RTC our work in the future is going to focus on is going to focus on systematizing or make making the technology we have fit better into the operating system so that it\u0027s available for applications in a cleaner way as well as then hopefully promoting a more standardized ability for for the software to get out into the field we\u0027re also going to look at this bridge crowdsourcing idea as well as you know improving bridge configuration this work has kind of evolved from being a tour only thing where plug ability was not part of what they were trying to do for anybody besides themselves to something where plug ability has kind of you know started to happen especially once there were providers other than tor interested in this kind of idea there is a 2.0 specification for this but we have to be aware that there are some pretty heavy incompatibilities within the modal mobile programming models that make this "
  },
  {
    "startTime": "01:09:41",
    "text": "entire thing a challenge so the opportunities for Standardization are to look at you know mechanisms for delivering new obfuscation technologies at a lower level of the stack there\u0027s also a possibility to look at ways that you could negotiate an obfuscation technology this is again trying to reduce the problem of many bridges of many types and then the latter is simply to inform allied standards people working in this area about the work that we\u0027re doing let this slide up just to advise that it\u0027s the intra news organization out of Washington DC that\u0027s been funding a lot of this work the folks here listed here are all interactive on either promulgating or or doing initial early development work in this area pretty simple to go to plug pluggable transports dot info to get virtually everything being done currently in the in this community so I think that\u0027s it you\u0027ve time for just a couple equations alright student so I think sounds like a fun interesting celery\u0027s disk have you talked to the kind of set of tensions between scale and kind of a half-life of mechanisms here because it seems you\u0027re at risk of the more successful you are the quicker you have to turn over the mechanisms yeah I know that from from sort of an organizational standpoint at Guardian project where we started out with you know literally like two or three users using our software we do seem to be on the cutting edge of this stuff and we expose more problems it seems than we solve in some ways now this is good because that allows other parties to get involved and take up the activity but this is definitely not only pluggable transports but several of the pieces of work we\u0027ve done in the past are always exposing something you know there\u0027s a there\u0027s a risk between exposing what you\u0027re trying to hide and you know all this sort of work makes it tough to do in an open-source world right so I guess I\u0027ve kinda wondering is that I mean you know that\u0027s kind of an approach for your kind of as you scale up maybe it gets more challenging in terms of having to get new mechanisms quicker yeah maybe there\u0027s another approach which is if I make all of the normal things the same yeah yeah that\u0027s an interesting we should talk about a little bit about that later sorry no more questions peace after after the ones who are already there so you\u0027re closing the queue at the current queue after Nalini after been connect two points one and I don\u0027t know how relevant this is but there\u0027s actually an ITF working group meeting in the same session right now the transport services working group that you know it deals with Buddle api is for transport I actually have no idea how relevant it is to what you\u0027re doing because I\u0027m not an expert did either of them okay but I "
  },
  {
    "startTime": "01:12:42",
    "text": "would tell me though and you know it\u0027s sort of interesting with deep packet inspection and sometimes that\u0027s just realizing the internet security model that we\u0027ve been trying to use for a long time assuming that you know the network is entrusted and so I think there\u0027s some extent intention to do you know Stephen was proposing of trying to make the legitimate traffic look you know entirely uniform certainly in the quick working group that\u0027s been coming up a lot about you know how can we make you the bulk data transport look basically random yeah Thank You Kathleen Moriarty so this sounds interesting but have you thought of the case where this is being used and both endpoints now become compromised right how do you detect this because what you\u0027re left with is your endpoint that\u0027s been compromised to reveal data so if you bring it back to your sam\u0027l analogy how do you detect anthrax how do you detect bombs yeah we can you\u0027re eliminating all of your so you know I get the concern of protecting data and there\u0027s lots of ways to do that you know on the wire I just want to make sure we\u0027re also considering security concerns and not just privacy right so how does that fit in how how can that factor in so I\u0027m not trying to say don\u0027t do any of this I\u0027m just saying think about security too so I would have a long answer in one way about that so we\u0027d better talk about that later but primarily with the earlier versions of ABS obfuscating proxy for example the net effect was haha we figured it out we\u0027re blocking you anyway so you know it\u0027s it it stops working as opposed to uncovers something do you see what I mean the difference so we\u0027re not we\u0027re not exposing anything that wasn\u0027t previously exposed it\u0027s just that the secret got learned and and it stopped working so now I\u0027m not entirely following because I\u0027m thinking like you\u0027re using this protocol and the server end of it has been compromised and your client gets compromised yeah we can totally take it off I just wanted to make the point I\u0027m not maybe I maybe I misunderstood thanks Nalini elegance I just wanted to kind of wonder about another tension possibly to is that sometimes one wishes to inspect traffic for potentially benign ends like maybe wanting to detect child pornography something like that I just wonder if that\u0027s something that you guys are taking into consideration yeah I don\u0027t I "
  },
  {
    "startTime": "01:15:44",
    "text": "can\u0027t speak for the actual implementers of this but but yeah as I mentioned in one of the early slides there you know there\u0027s there is a tension and a problem between mom you know benign monitoring hardcore surveillance actual censorship and and trying to develop a technique that is sensitive to the ones that we want to block for and ones that we don\u0027t so that\u0027s a tough challenge don\u0027t quite know how to answer that question directly thanks David yep it\u0027s a lot you have the last presentation by yes they say your name yeah can you hear me yes perfect awesome do you need to video okay hello hello everyone so my name is Ganesh I\u0027m a postdoctoral researcher at Princeton University so I\u0027m going to present the paper that I didn\u0027t write which is not something I have done before but so this is a paper that my ex coders wrote and I have also done some previous research for so this the paper were Lucas Stephen and Arvind and it\u0027s a paper about a certain web standards called better status API and assessing the privacy of web standards and standards making process using this API as a as a use case so one kind of correction so Stephen is now at Mozilla although he wrote this paper it is Princeton University capacity let\u0027s say and and the next slide is yeah so I think you can all agree that like me with features and internal Sanders only two privacy concerns next slide for instance take web be our API it\u0027s an API that allows your headset to browse through Internet so next slide please okay so this may be our API allows your YouTube browse the web using your VR headset and one of the things you need to do to optimize the experiences next slide to adjust your entire popular distance this is the distance between the your eye purples next yeah so the this API you like exposes your the distance between your eyes to the "
  },
  {
    "startTime": "01:18:44",
    "text": "website and I think like you can see is like a previous issue so w3c has some like each issue is in place to curb this or addresses privacy epilation privacy issues with the web Sanders and one is a self review questioner next slide so this includes question that standard editors needs to address when during the initialization phase for instance if whether these standard new API that\u0027s to be introduced involves personal identifying information or high-value data and interestingly one of the mitigation strategies outlined in this questionnaire is if you look at 4.3 is drop the feature that is the remove in the feature so next in addition w3c has privacy interest group called ping privacy interest group which among others provide guidance and advice to the during the standards development and next so the let me like a briefly talk about is better status API JavaScript Sanders is a recommendation by w3c and it\u0027s just a way to expose the battery information to the website where JavaScript so it\u0027s a very simple API the surface is you can the website can read the the charge level and whether your battery is charging or not and time the estimate of time to charge or discharge the battery in seconds and next so be CPI first introduced in 2011 and came a long way and after some research and research up the research basically it is the API is removed basically unshipped from browsers including Firefox and and Safari oh this paper is about each other what happened during this time line next so in 2012 the recommendation edit is privacy and security considerations next which said the information exposed to the CPI has minimal consequences consequences for minimal impact on privacy or or fingerprinting this 15 I "
  },
  {
    "startTime": "01:21:53",
    "text": "researchers including myself and Luke rush wrote a paper basically published a paper showing that well actually a website the most website can do a lot using this API so one is that you can just simply use the battery level the charge level to distinguish for example similar computers behind the ads for example in a like a say like a enterprise setting where you have like a very similar computers with waves from the fingerprints and take a same API you can distinguish them for example using their battery level but more importantly we found that actually firefox on linux is exposing the battery level with very high precision it\u0027s a double floating-point number and then using that and somewhat floating-point rates we could detect the capacity of the battery and we probably the proposed that this campus is a long term identifier next and later in 2016 Stephen and Arvind next place publish that privacy measurement measurement of 1 million websites and in their measurement next they found that actually fingerprints is using this API to collect battery charge level as part of the fingerprint so this API was found to be used in the world by fingerprinting spirits to collect a fingerprint so this back the the the recommendation TT recommendation was updated to address this these concerns first they acknowledge that there are some there might be some price problems and vendors should avoid exposing high precision values inform the user may ask for his permission or even like choose to obfuscate or possibly Pelley\u0027s next and late 2016 which is somehow surprisingly actually Mozilla start to discuss are removing this API and next place so the question they ask basically these are like a real website using using better API for the collision its purpose and labor income is that they\u0027re actually although you can do good very actually no they don\u0027t see like a lot of out of users that the original sander that envisioned as the use-cases next "
  },
  {
    "startTime": "01:24:56",
    "text": "and early 2007 actually several vendors removed or restrictive this support certainly privacy concerns and papers and the lack of use next and the Selby this paper actually run a study of like a top fifty thousand websites and found that thirty three websites on like a more than eight hundred eight hundred sites use this API better API and the majority of users are for tracking and fingerprinting so what happened is so this API came out and then several research showed there\u0027s there are some privacy problems or these problems are using the abuse in the world and then some vendors basically on ship the API so what we learned from this all these and so this paper has some recommendations which I\u0027ll be going through in the next next four Slice next please first the specification process should include also review the implementations so a lot of things may go wrong in the during implementation and look as one of the authors of this paper actually moved in the price river of the ambient light sensors API and they found like similar problems with implementations where the the browser\u0027s expose very high precision readings on missus early next and so implementation is one thing but then is another problem another question is like how the API is used the second recommendation is actually looking into the use in the world and this paper says actually so although measurement researchers can look into that that may not always be you know resources or time so and suggesting for instance browser telemetry or measurement by vendors or NGOs can help here and the third recommendation is speakers should take into account different threat models for instance audio context API is like a used can be used by the browser to like synthesized audio and us so this is found to be revealing the users operating system and the browser and in the normal standard browser case this is something you don\u0027t care about this because it\u0027s loading included in the user agent header however like tor browser tries to hide the operating system of the of the user and this is a problem for them so taking "
  },
  {
    "startTime": "01:27:56",
    "text": "the account different threat models and the last recommendation I have here is improved incentives for the academies which I think to contribute research which I think aligns very well with T aligns very well with the principles of this research group so the four key combination is yes all next and next please so yeah basically the people says the things like try to incentivize atoms in santosky resources to look into this Sanders and break into the privacy assumptions and maybe like organize workshops or forums inviting researchers and academics to look into that and and so these are the four recommendations the paper has more other recommendations as well so next slide please just to find a slide so yeah I thank you so you can check the paper for the other combinations as well and yeah thanks for the invitation so happy to take questions your exactly pay seconds for any questions that\u0027s a good burger try to get it was 15 seconds I guess thank you for for this talk I think the recommendations about measurement are pretty interesting I participated in this work when it was very first starting like eight years ago and was a person who went there and said do not standardize this because of these problems there were several of us I know that nick is on Nick probably remember system maybe a little bit better than I do but that was like the best recommendation that we could give because there wasn\u0027t really an obvious way to represent this information in the API without having these privacy leakage problems and and essentially like the drive to do all of these device a P is and the w3c was so strong that those those concerns were were not really listened to and then I stopped participating that of III see mostly for other reasons so anyway I just came up here to say that to give that little bit of history because you know a lot of the things that you\u0027re proposing were have been part of the conversation since the since this API was like very first proposed and many of the other device api\u0027s as well and I think we have a better understanding of a lot of their threat models now and there\u0027s a greater appreciation for these kinds of threats than there was eight years ago but it\u0027s still you know it\u0027s it\u0027s a back and forth Thank You Christine run a NGO w3c privacy interest group co-chair thank "
  },
  {
    "startTime": "01:30:57",
    "text": "you very much to the Princeton team the ping group is very grateful for that research which gave us the opportunity to provide the feedback to the working group one thing to mention to everyone is the Security and Privacy questionnaire is currently being updated so please if you please sing afterwards if you like a pointer to where to find it in github so you can provide input we also need people like the Princeton team to get involved in the work and to do the privacy reviews and the final thing is really great recommendations the other feedback that we\u0027re receiving too is not only should we be thinking about getting in early with the privacy discussions in the w3c but there perhaps we should be reaching out to the browsers as they develop their tools before they bring them for to be standardized so thanks Eric rajala I mean so it seems to be sort of an implicit assumption in this work I mean thank you for this work I\u0027m clear that even works for a company so it\u0027s part of why we hired him but there\u0027s any implicit assumption in this work that API is which enable this kind of fingerprinting are bad and that isn\u0027t really reflect I think the consensus of the browser vendors who basically have given up on for any have to fingerprint largely and I think this is something that it\u0027s important to know where the fingerprinting surfaces are and it\u0027s important to for to be able to suppress them for things like tor but I don\u0027t think that any of the major browser vendors thinks that is practical to prevent doctor fingerprinting in a commodity browser implementation that has an acceptable user behaviour so if you look at what what Firefox is doing for instance we\u0027re much more focusing on detecting misuse by sites and punishing the sites to do that then we are on trying to remove the fingerprint services yeah and second response are you definitely agree so it\u0027s actually if it comes across like this I think I should apologize so it\u0027s not really that these apos are bad but for instance in this case it\u0027s like I think really Tom Hill pedal because the exposure of this like high precision level was totally unnecessary whereas in other cases you have like a legit users of this say fingerprint of a surface sure I think I think that perhaps the Lawson I would take home meniscus back to what I was saying earlier is for a while there was like really a rush to put like every possible API surface that like any like any phone a phone programming environment had and put them the web somewhere and that was going with that really good cost-benefit "
  },
  {
    "startTime": "01:33:57",
    "text": "analysis whether these things were you know were useful I mean like you notice that when we took notice that when we decided that this was bad we didn\u0027t like reduce you know the precision to five levels we just remove this year that this API entirely verdict on battery status API is this useless and this any written any daily could all it was a bad idea home so I think you know I think that perhaps you know that I guess I\u0027ve erosion your thoughts on if any way we could have made that cost benefit analysis better earlier and realized that like there\u0027s no port we should do that like you know not only was it like bad to have a root PI precision leap but this was just like all costs are no benefit I don\u0027t know if he defaults on how he could have made that analysis earlier but that were helpful thanks we can take this to the meeting this the comments thanks to everyone it was a fine presentation and I wanted to keep some time for discussing future work items but I guess we can do that on the mailing list and thanks to all the presenters and thanks everyone for coming out and if you haven\u0027t signed the blue sheets we\u0027ve got some up friends [Music] "
  }
]