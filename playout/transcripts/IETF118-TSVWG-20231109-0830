[
  {
    "startTime": "00:00:31",
    "text": "The ordination of the group. As course. Of the drop. Levels stirring up. To"
  },
  {
    "startTime": "00:02:23",
    "text": "find the funding work. Not not Good morning everyone. Would anybody be willing to take notes for this meeting? Just stay to hand up there. Oh, Thank you. So we have a notetaker. I also see that, Rodney wants to share a slide deck That's unexpected That's I assumed that this was a mistake."
  },
  {
    "startTime": "00:04:03",
    "text": "I'm just uploading some replacement sites for Greg's talk. So if you've looked at the slides on the meetings tracker, have a look again. And This is TSVJ. We've hopefully switched over. So I'm gory on this side and this is bottle. Says Martin on this side. Whether we're working group chairs. If you have things that you feel should be dropped to the group or comments on the drafts in the group that you are not sure about whether to contribute answer is probably send an email to the list, but if you're in any doubt, then please do just contact us. We're very happy to help you to input into this working group. We have an agenda. First of all, we have a note well. Please redo it's important. There's a code of conduct in there, in there's rules about intellectual property. And, yes, we do have an agenda. And we have one thing on the agenda that's not on the slide. Just a presentation about, happy eyeballs, version 3. And we'll do that, right at the beginning. We'll then have some discussion on, each including a presentation with, within recent experiment, on LRS."
  },
  {
    "startTime": "00:06:02",
    "text": "We then will discuss the the SCGP drafts, we'll talk about UDP options. And Then we have some time for individual drafts, hopefully. Any agenda messaging. That is not the case. Are any of the authors of the list of sides in number 10, not to send us some slides and wish to send us one side, then You've probably missed the deadline, but we can still talk about the draft. So no no agenda bash? So we'll move on. Tommy, So while Tommy's making it to the stage, we should give a little bit of background. This is a draft that was presented in V6 ops. If you were also in V Six hops, then you may have seen this talk, that'll be good. I think many of you weren't from looking around the room, So the point is to coordinate this work between v six hops on the transport area. Happy eyeballs is all about selecting transports. And, therefore, it should be interesting. Whether we do this work in this group or be decided when adoption calls made, but it might well land in another group, I think, So we're great. Alright. There we go. Hello, everyone. I'm Tommy Poly. From Apple and speaking on behalf of my co authors, David Nitty and Kanechie. And this is something that"
  },
  {
    "startTime": "00:08:00",
    "text": "As was mentioned, we already presented in v 6ops. It is targeted there. However, in that discussion and other discussions, He was brought up up up that this is something that broader community should be aware of and have input on particularly, DNS and also transport. So I'm gonna go very quickly through these. I don't wanna take time away from the rest of the agenda. But I wanna highlight specifically the things that may be interesting to transport here. So happy eyeballs is a, a way to race Alright. connections. It was originally done to handle, breakages of ipv6 versus ipv4. And, generally you have, actually, I'll just jump to the next slide for context for people. You have many different addresses you get back from DNS resolution, and then you try them one at a time. And these this is a staggered race. The interesting thing for transport is that was always been written in terms of TCP connections, and it's like, okay. You have your TCP handshake. And that determines when a particular address is connectable but you also use the TCP retransmit timer values as when you would stagger the next race. But since, Happy I've also was originally developed, there have been a lot of changes. Some of those are more in the DNS world. We have some new records that have recently RFC for SBCB and HTTPS. That gives us other ways of getting addresses. And gets priorities between records. But it also includes ALPN. And so now we have DNS records. Part of this process that are giving us hints about things likehtv3andhtv2. Which really translates down to quick versus TCP. And so now we have some extra transport information being thrown in And also since happy eyeballs, was devised. We now have quick as an alternative transport that has become very, very common."
  },
  {
    "startTime": "00:10:01",
    "text": "And that is something that general, the draft need to be updated for. So that's what we'd love to have your eyes on. So jumping forward, these are just some of the changes in this recent version. A lot of These bits around SVCB are not necessarily super relevant here. Other than the fact that We do now have information about ALPN And Transports. From the SPCB records, and one of the key insights that we've had as part of the update is trying to update the notion of what the handshake completion is for a given transport connection. Previously, this was just a TCP handshake. And it's quick. It needs to be, the quick handshake. And there's also been, developments around having that include the full TLS handshake have also seen brokenness where TCP is being terminated by proxies but doesn't actually have end to end connectivity see, actual server that we're trying to reach. So here's the roughly updated sorting algorithm there's a little bit in the middle about having your preferred ALPNs, which kind of translates into your preferred transport protocols that you may have for this particular connection. Some of the changes specifically around quick and trying to generalize the notion of transport racing for happy eyeballs, is that, you know, the client now needs to have some preference when it's capable of doing both quick and TCP, which one if it has to choose between different services that only support 1 or the other or both, How does it want to sort those? In general, we would recommend saying that a service that can support quick alongside TCP or just quick maybe a good first option because it does have, improved setup time. It has improved."
  },
  {
    "startTime": "00:12:02",
    "text": "Fidelity of signal for congestion control. It has support for connection migration, etcetera. And then we also need to adjust all the language around connection raising, making sure that it's very clear when the connection completes. These are all bits that as this develops, we would really appreciate a lot of the people in the transport area working group. I guess it's not gonna be the area anymore, but, having the experts in this room have an eye on that and making sure that the language is correct. I'll skip over these because these are very much TLS specific. And so These these are slides that originated for V Six up, so that's why we see should we adopt in V Six ops here, but I think that is kind of one of the broader questions. This is something that is very, very cross area, cross working group. It has many legs in V 6, TLS. Transport DNS. And one of the other things I wanna point out for, the transport folks in this room is that we also have that we've done in the task working group, which is specifically around doing racing between different types of transports, and trying to to have I can switch between quick or SCTP and TCP. That has a much broader architecture of trees of racing and happy eyeballs has always been a part of that. But that is an area where happy eyeballs and some of the broader transport work is in dialogue. Alright. I see Lars's in the queue. That's all I have for this. So let's take questions on whether the IEF should do this kind of thing, opinions on whether this group is inputs or any help on the general topic and move quickly last first up. A lot of secrets. So I think this is, a great, update to have your eyeballs. So we should definitely do this with the IDF. Really wonder why the 6 ops thinks it's the right group for this, or you think the right group for this rather than, like, here or somewhere else, transport So The"
  },
  {
    "startTime": "00:14:03",
    "text": "The reason it kind of naturally falls initially into V Six hubs is that Vs 1 and V2 were there. Having the presentation of V Six Ups, there's also a lot of great input they have other things that need to be updated there around the, elements in V Six only network. So, like, we, we have expertise from so many different parts of that all really should be contributing I don't know when So where the argument that would make against physics of this this while I while it started there. Yeah. And and at that time, the big thing was, like, how do you do V4, V6? Do you handle that? I don't see any growth there. Right, I don't see return coming at any point. So I think the diversity exists now in at other layers in terms DLS and other things you mentioned here. Right? And so I think going into groups where that you you expect that work to happen that will complicate this further in the future, maybe would be what I recommend. But you know, I don't feel very strongly. I just Thinking ethics office, maybe the the correct venue in the past, but might not be the correct venue in the future. Thank you. This is a discussion we need to have. Brian? Hi. Brian Tremmel. I put my hand up before Lars spoke. I agree with everything he said. I would note that this looks now very witty Right. Like, so this is this is the this is the canonical first draft for the new area because you're looking at you're looking at of, like, things that have come out of the website of things, like LPN, etcetera, etcetera. Looking at things that have come out of, of the transport side of things, The V Six thing is now kind of like, historical reason why we did this, but this is you know, not that. I would, at the risk of angering Mars now in order to in order to, you know, not agree with Lars if if if"
  },
  {
    "startTime": "00:16:00",
    "text": "taps were a group that we were not looking to close as soon as it finished current work, which I think is an excellent idea, this would fit in taps very well. Given that we are doing that and having been in that working group years and made a Patrick Gucci slide about how long that had taken last night, I think it's a good idea to close that. That points as a default to this group as the place to do the work. Martin Duke, Am I correct in in, understanding that, like, you guys are already doing this, and so you are not, like, facing incredible urgency to, like, publish this as soon as possible. Certainly no urgency to publish. As far as, like, implementation, The bits around adapting to SVCB and priority in address hints That is something we've been running actually for years at this point. But I think there's a lot of discussion that still needs to be had about How do we correctly incorporate the preferences around ALP. And, like, some of these other more interesting transporter ECH priority questions. I think there's still a lot of room for discussion and debate about the right way, but, like, this is all an algorithm and a heuristic. So there is no time urgency around any of it. I think it's more valuable to get a broad input of the community to come up with, What is the best thing to do? Okay. Lovely. The reason I ask is just to propose a way forward. I think the think the the the normal way we do this is just the ISG discuss it and see if, like, can converge on something, which we can probably do tomorrow. Early, so we try tomorrow. And if we if you fail tomorrow, then, that's what dispatch is for. So, which is why I was wondering how urgently works that kind of sets you back another meeting in terms of in terms of, cycle. Okay. I think that's probably the best way for. I mean, I I think a lot of valid opinions here, but, yeah, you're right. There's a whole there's steaks in lots of different areas. And,"
  },
  {
    "startTime": "00:18:00",
    "text": "I think 4 different areas at least could could claim this in theory if they wanted to. Thanks. And I do agree with Brian about the wit ness of this. I think the reorganization of the areas Does make it fit more in wit than other areas. But then I think it's a question that I would love both the ISG and the working group chairs of this group to talk about of the evolution of TSVWG within WIT is it going to be like the generic wit place, or is it still going to try to be very transporting? So it's it's an existential question for us. No. It is it is not the generic place as currently. Conceived. I seem to be in the wrong place in the queue. I should have been before all that it's an individual comment. I think this is an as an individual, I think this is an interesting draft because it requires inputs from some working groups and decisions by a working group. And we've not been doing so many of these at the IETF. We tend to go off in working groups and do work. So this is an interesting thing for the IETF to do well because getting input from multiple places is something we should be able to do And, yeah, let let's do this work somewhere. Thank you. Thank you for your time. Come back and give us an update if you happen to do it somewhere else. Next slide. We have a bunch of slides about L4S, and Let's start with the field test update. Alright. So you said I have an hour. Right? No. Just kidding. Thanks. Jason Levinegood. And I'm here talking about our L4S trial."
  },
  {
    "startTime": "00:20:04",
    "text": "Which is really the 1st, public, trial trial of, this technology. Next slide. So just a high level, grafted or chart to show you what this looks like in DOCSIS. And SF in this, notation means service flow. Which was sort of a DOCSIS type of concept So what this basically is representing or a couple of things. First, the low latency packet flow and the classic sort of default service flow. I'll share this aggregate flow, which means it's all sharing the same amount of bandwidth. One is not allocated more bandwidth than the other, and they're both at the same priority level. So for us, these are 2 important foundational concepts that we've tried to make sure folks understood that, you know, one of the flows is not a higher bandwidth or higher priority. They're they're all sharing those things. And the classifier function that really sits in front of it basically just looks at the packet header and says, you know, oh, is it an ECN? Know, is it DCT 1 or CE, or is it, DSCP 45? And if it is, then you know, shunts it to the low latency flow. Next slide. In terms of, our requirements, first, about half of our work right now is on a virtual CMTS platform. That's our aggregation point 1 hop after the user essentially. The rest are all sort of older, but, you know, we're transitioning to the virtual platform and So we've only developed this for the virtual platform. You're using 4 different modem types They're all DOCSIS 3.1 modems to our our devices that we provide to customers and we manage the software and then to our retail devices, which we would call customer and managed co m. So we wanted to have a selection of sort of retail and and, customer Sydney Comcast managed."
  },
  {
    "startTime": "00:22:02",
    "text": "Because of the way we've distributed and deployed the VCMTS platform, you can really be anywhere geographically, which was very different. In the past, we would only say, okay. It's in city or that city because, you know, we're updating a particular CMTS. Virtual platform is is just sort of rolling out, now. And we have situations where Like, we had a, a user in, you know, maybe Cupertino who was, like, you know, one side of the street was on a BC MTS. The other wasn't And so, you know, that's that's something that we've navigated through. We also saw, interestingly, an amazing level of customer engagement and interest about this. It really shocked us. Usually, if we get, like, a few dozen people to volunteer for a technical trial. We're like, wow, we've got a few dozen people that know what the hell we're talking about. And in this case, we had thousands of people that, were interested in and applied, which you know, shocked all of us, but was awesome. We've done this in several ways. First, we always start with employees. They're the best guinea pigs because if they complain, you're like, wells. You know? Services free to you. What do you wanna do? So you know, they're the the first audience. And then, we had to have done 2 waves of customers we just started the the 2nd wave a few weeks ago. Next slide. And by the way, as of now, we have a few 100, testers. At the moment, we are primarily testing Upstream. This is the prime, bottleneck in, cable network or in the kind of asymmetric network that a lot of US networks have. So that meant that we are doing this in the cable modem itself. And we're supporting both L4S and not, NQB. And you can see some of the details, at the bottom there. When it's our gateway, it's both sort of the cable modem layer 2 function, as well as layer 3 IP routing, and it has a Wi Fi function as well on the LAN side."
  },
  {
    "startTime": "00:24:01",
    "text": "And what we've done there is when packets say come up or down into the modem and then into the wifi network, The low latency mark packets are going into the ACVIQ. And The super fun thing about that is that we found that we were actually, as we were getting ready to this and we did some peak caps in our first few people, we found number 1, we thought we were not bleaching ECN. Turned out our test was only testing upstream. And when we looked at downstream, my we're bleaching it downstream. And so we had to fix that. The second issue that we found is we were leaking an internal DSCP mark into the wire lands of customers. And that would cause all the pack on the wireless LAN to go into the background. Class, for WMM. And Oops. That's been for a while. We went and fixed that on literally every single, configuration file for cable modems. Which, you know, is easy to do on the CMTS. But secondarily, that w worried us about that is, like, we had to fix that before we really started doing this because we would then have packets at ACVI and then ACVK. What you're, you know, pretty dramatically different instead of sort of BE and, and VI. We've done manual provisioning, and really that means that, like, we created a few boot files, which was kind of configuration files for modems, and we push those out. One by one to the devices that are in trial. Not super scalable, but we're doing it for now. And we're getting ready to test automated provisioning. That's next. Which is really a key enabler for us to be able to scale up to know, millions of customers. Also getting ready for downstream support, and those queues would be in the same TS. Pointing down. We've just tested the beta code in the lab and it works. So we're just waiting for that to go through, QA testing so that we can get that into the field. And we've also tested end to end DSCP 45 marking to appear network"
  },
  {
    "startTime": "00:26:00",
    "text": "I'll show in a second. That also was a big deal since, all that stuff tends to get bleached at, domain boundaries. And the other, you know, fun side, comment is the cable modem config files, you know, we keep finding funny things. Because it's all manual, and it's just like a small team of 5 of us, doing this stuff. One of the upstream's was a 120 megs upstream. And somebody was complaining like, wow. Ever since I got this service, you know, it's really seems stuff's a lot slower. And, you know, we thought about it for a while, and then we're like, oh, we missed a 0, in the config file, and it was like a 12 and a half megabit per second upstream instead of a 125 megabits per second upstream. Like, Okay. Well, you know, we we fixed that. So next slide, that's a question. Do you wanna take it now or at the end? The end Okay. Gonna take it at the end, Jonathan. Okay? Okay. Thanks. So what we've done with users is basically the you know, they have structured activities, you know, 1st week is to tell us if anything seems really rocky. Then start to do web based and other performance tests and the network quality test from Apple. FaceTime testing, low latency DNS testing, some gaming, And then they submit survey forms at the end of each of these test basically to give us the results. Also have probes that we've installed from all these different parties I'm happy to distribute more probes if people have them. Next slide. So high level observations so far We haven't seen any issues of classic q starvation. We actually saw the opposite, which was L4SQ starvation because we had some cable modem, config, issues, limitations, Greg has helped us navigate through. Gonna push, some code late next week to the modems to fix that. So that should improve some things. And that'll explain some of the charts you see in a minute."
  },
  {
    "startTime": "00:28:05",
    "text": "Most of the things are working, pretty well. Cloud native real time apps, you know, seem to see a bigger benefit, than sort of legacy apps, if you will. We've got a lot more, you know, trial plans over the next 90 days. Next slide So, yeah, so at the bottom, you know, just something from our, end to end, DSCP 45 testing, which was with valve, game platform. Next slide. You can skip this one. And that one. So this is from our, what we call IMP, the the cleverly named internet measurement platform, and that's, basically a measurement agent that's in stalled on our cable modem gateways. And, today, you know, putting this trial, we run I think on any given day, like, 800,000 or so tests to modems, and, at all different hours and just sort of see what the health of of the network is and, you know, is service quality good. And, this is a bit of an eye chart. You know, it's sort of showing Number 1, you know, the the bandwidth delivery is still good. We're still delivering upstream bandwidth in this example at the bottom, 103% of advertised. And we've got types that the tests are running on. So again, for us, just showing that it's not just one device, a bunch of different modem, models, if you will. And, you know, in this case, this is, at the moment, just to, you know, so I quick test, you know, and and we're seeing, like, a having of of the, the update. Latency, which is good. We'll really be interested to see what happens once we out the cable modem changes in the next week next slide. This is from, our NVIDIA partner So they have a cloud gaming platform, GeForceNow,"
  },
  {
    "startTime": "00:30:01",
    "text": "I'm really happy with the results that we saw here what's interesting, if you think about gaming the the the usage of upstream is not super banned intensive. You know, you're thinking about, like, you know, controller interactions and things like this. Right? So pretty low bit rate, but pretty important you know, from a timeline standpoint, And, you know, with just classic you know, AQM that we had in the network 4, they were seeing, like, 225 millisecond lag speed you know, spikes with background traffic and I'm gonna mention the background traffic in a second. And then, you know, much much lower, spikes and much better jitter, much more predictable latency afterward which was really great. They were super super stoked about it. And I should mention, by the way, you know, we've tried a variety of background sort of traffic generation. We do and and have tried both you know, ramp up and just sort of run a continuous test where you're you're filling the classic q as well as, running a test that is more representative of very bursty user traffic. And that's the primary one that we use. It's like, okay. Use a 100% of the capacity for a few seconds. And then nothing and then use 50% and then 20% and then 80% sort of skip all around. Try to better represent what what what what you might see in a user's home with traffic hitting a web page or doing some video streaming or something like this. Next slide. And this was just a an example. So you know, like in their game and this was one of the it's always hard to find things that are like to demonstrate to, like, executives and these kind of things, especially if they're not, like, really active gamers, you know, because sometimes it's very visceral. Like, oh, I can really feel the difference I'm playing the game and somebody's not like a regular gamer and and they might not sort of get that. But, you know, there's one sort of sequence where you have this animation and the car is on this turntable sort of spinning, and there's musics that that's coordinated with it."
  },
  {
    "startTime": "00:32:01",
    "text": "And, you know, in the presence of the the background traffic that we generate, you know, they were seeing, you know, pretty high, things that you can see in the upper right hand corner red 259 milliseconds. Know, on the right, once it's in the the, l Forest, q, it's doing a 28. And just the visual difference of, like, On the left, it's, like, jerky, and it stops every few seconds, you know, and the music stops, and then the video starts, you know, definitely a big difference was kinda cool. Next slide. This was, from valve, and, there's Steam, platform counter strike in this example. There's a couple different games we've been thing. And here, you know, the difference is sort of in the bottom to points, which is the the difference, between idle latency with no traffic and, traffic being generated and looking at the the the lag for the game, you know, big difference, small difference there, excuse me, so a big benefit so we were happy with that at that work continues. Next slide. So this comes to one of the areas that we found in terms of bugs. So the apple responsiveness test tries to do, you know, higher amounts of traffic. And, this was one of the things dissen to, oh, we think we have a limitation in our modem config file for sort of the the amount of bandwidth, that the low latency queue has access to and where we found a couple of config file error. So we'll work in to fix that. And these, you know, should, should look different. You know, this was a bit of a head scratcher when we we were in the middle of next slide. And this is an example, of one of a couple of different, probes that are out there. This one's from University of Chicago. Nick Feenster and his team, run this. It's called Net Microscope. Right now, they are only doing classic queue, you know, working latency kind of traffic"
  },
  {
    "startTime": "00:34:00",
    "text": "and what we're hoping to get from them and from Sam's and some others is is you know, they can run that. Sort of classic or normal type of latency under load test, but then they're also running a test, when they're marking packets for the L4S queue and seeing, you know, what the difference is. So this consider this as sort of like a baseline of data collection, And then once these platforms are able to mark the traffic, which depends on sort of the operating system of their particular probe, then we can see the difference. So next slide. Same thing for Sam, though. So they implemented the network quality test, which was kinda cool. So, again, we're waiting for them to get to a point where they can do the marking and then we compare compare that to a baseline. Next slide. Next steps, we expect to continue testing through February or maybe March. And then we're probably out of things to test. As I mentioned, downstream, you know, cube had has been tested. And we're looking to deploy that automated provisioning as super big deal from a scale standpoint. And then, you know, we're continuing to solicit, suggestions for tests that we would like to have users run, anything you're curious about, you know, we We send weekly assignments at the users and happy to add anything that you'd like. And, really, this sort of bottom line is getting ready to scale this to millions of users next year. From our standpoint. Assuming it all works. In terms of our validation over the next couple months. That's the that's the plan at the moment. And, I think that's it. And we can take questions from folks that might be in the queue in the next 4 or 5 minutes. Jonathan. Okay. I've come up with several now. Let's start with the more general one. First, a general comment that these results look very typical to, deploying cake on the upload. Which I've been doing for several years."
  },
  {
    "startTime": "00:36:01",
    "text": "Anyway, The most important question is, how vigorously are you looking for hammed to innocent bystanders. Because I didn't see any of that anywhere in the slides. Yeah. Very vigorously. The users are provided with not just the 1st week to monitor all of their current activities and report any noticeable difference. But every single week, when we give test assignments, we reiterate the same thing. We've had customers open tickets where they reported issues, one of the No. No. No. No. No. No. Not participants. Not interested observers, innocent bystanders. Important distinction. Okay. What what, other innocent bystanders like walking by the houses in the street, or who are we talking about? I mean, I mean people who are on different networks that don't support L4S but might end up receiving spiller for localized traffic. I mean, you do have inter domain traffic. Running, running, Right. No. We haven't seen any, any effect on innocent bystander. How vigorously are you looking for it? That was the question. We're we're looking for any any, downside effects. we've got lots of background network statistics And and analytics that go on. As you might imagine, everything from, you know, interconnection points to other places in the network. And compare that to the baseline of existing traffic. Okay. Now, I'd like to go back to what I was going to see in slide 4. Yep. Yep. Don't those DCP leaks in DCN bleaching that you have to correct. Invalidate on lots of the arguments that were presented for using each one instead of a DSCP. Right."
  },
  {
    "startTime": "00:38:00",
    "text": "So you're saying, There you Yeah. I mean, listen, the most networks, know, have their own proprietary uses of DSCP and we were missing a, you know, bleaching you know, policy on the device. And so, you know, we made sure to go out and fix that. But, you know, I don't know don't all to tell you. I mean, you're using DSCP's anyway. Mhmm. Well, anyway, and just wanted to put that onto the record. But it sounds to say you could have been running these experiments as a kind of normal US configuration years ago. I'll leave it to other people. Okay. Thanks, Chris. Next. Hello. First of all, thank you for sharing sharing all these results. It was really good to see. Towards the beginning of your presentation, you, described said something along the lines of you saw most improvement in cloud native apps. Were you referring to cloud gaming there, or is that more broader? We were referring to cloud gaming, but we sort of have this, you know, bit of the theory, you know, internally about what the difference will be for a lot of sort of cloud based, say, document collaboration, you know, cloud based gaming other kinds of things versus more you know, thick client that happens to have some you know, 10, 10, 10, internet, traffic, you know, So, the the working theory is that the you know, clamping stuff that might see a bigger benefit. But, you know, you know, you know, We'll see. Okay. And also on the we go back couple of slides. The Apple network responsiveness results, on the right hand side, you were showing some RPM changes. Yeah. Bariters, Yeah. So What does that mean? So, it means it"
  },
  {
    "startTime": "00:40:03",
    "text": "couple of things. Great call out because I forgot to mention it. So the the first challenge that we had, number 1, making sure that the customers that we had were on sort of the latest version of macOS. That had the the updated network quality test. The second was making sure that they actually enabled L4S, and and called that out in the sort of configuration of the help have the network quality test itself. Like, there's a bunch of flags that you can run after that. And so, you know, some of that were were confounding issues that we found. And so when we were able to confirm little bit further with people like Did you definitely enable L4S. Did you definitely turn this flag on know, because we can't sort of be screen sharing with customers. We did see some some better differences. On the other hand, I would hope to see higher RPM numbers you know, eventually, you know, once we get the configurations fixed. So is is that examples of 3 different customers there that They were. Changes they scene. Yeah. Okay? Vaxi, Hi, Lars Zegard. So, you're at the slides anywhere in the world on no need the words anywhere in the world of your slides, and I live anywhere in world other than the US. And so I was wondering obviously, you know, you can't I can't join this from Finland. But I'm wondering if you're aware of any other efforts that are going on where operators are testing L4S that those of us not in the US on Comcast could join. Any sort of mailing list where, you know, you guys are talking to other operators. Is there any efforts that you're doing Well, I know How can I play with this? Yeah. I can hear you. Yeah. I mean, first, I'll say, you know, Greg, White, who's in the audience from cable apps and running these interrupts, for a while. I think probably just had, a variety of equipment vendors come Certainly, we've seen in in drops here, you know,"
  },
  {
    "startTime": "00:42:00",
    "text": "upon demonstrations, 5 g demonstrations. I don't know where any of those networks are. Know, I don't know, Greg, if you have any, great idea. I know certainly talking to other cable companies there, there's a lot of information sharing going on Yeah. I think there's a lot of interest and a lot of network operators who are planning their, deployments. So far, deal me, trial that's been announced is the Comcast 1, but, I'd say Stay tuned. Future. And part of my 2024 plan is, you know, go out and talk to some of those operators. And so on. Start in Finland. Yeah. I'm sorry. Finland. So I see the the work item, reporting on l for us is November next year. Yeah. So hopefully by that time, we will have other thoughts from other people as well to go along with this. Yeah. Would lift up. Got one more question in the queue. Hi, Jason. This is Dan Russo with AT and T. Sign me up. I I'll I'm like, Lars, I'm a extended to customers. So Nice. Quick question about, email me your address, and I I can find out, if you're on VCMTS. Yeah. On the in network, in home topology. I'm curious if you I understand that the immediate, need for tests was to connect directly to the cable modem. But I'm wondering if you have any any results on a on connections that are you know, to other from other devices in the net in in the home, particularly Wi by routers, switches and other things that you know, homeowners tend to, to install and they're out of your control. So I I'm I'm curious if, if if if those can be included in, in your future tests. Because I think it will be extremely useful. Let's say, an iPhone connected to, to a, to a Wi Fi router and got connected to the modem or even to a switch"
  },
  {
    "startTime": "00:44:00",
    "text": "and then to the modem. So curious about that. Thank you. Yeah. I think that's a good good, suggestion. We'll make sure we do that we release more data, we are collecting it at when the users tell us, you know, we're asking, are you an ethernet or in your Wi Fi? And then we know what kind of device have. Know, so that can help. Even on the ethernet, if you gotta switch, in front of your Yeah. Cable modem again. Thanks. Thanks for this presentation. Can you go to slide number 4 Yeah. So So you mentioned that you did the test with FaceTime and also gaming, right? So I'm curious that why you are putting everything on SCVI in Wi Fi. I think it's in one of the recommendation documents. I don't know if it's 1 of the first three It's one of the active ones you have, Greg. Got it. It was recommended to use a different, wifi, WMM you know, you know, class than, ACBE you know, to get, you know, because each each of the those 4 WMM. You know, sort of cues, if you will, have different types of configurations and and so on. Yeah. Correct. So I I am wondering whether you're following RFC 8 325. I have to look at 8325. I'm not Yeah. Because yeah. Because if you follow that, then I think gaming and you know, interactive videos will be in the different, classes. So we put everything on the SEVI. Then I think it's it's it's not a fair to invent. Yeah. Maybe. I mean, keep in mind, I think that the primary, you know you know, place a lot of this stuff happens as in the downstream packets coming into the wirefly land, because on the origination of the packet side and the client side, they can kinda mark however they want. Right? The Wi Fi network is gonna do what it wants to do. So"
  },
  {
    "startTime": "00:46:00",
    "text": "on the upstream side where the bottleneck might tend to be typically, you know, 50 gonna market you know, however the the client wants to mark Yeah. That's correct. But I I'm just more interested on downlinks right? Yeah. From AP to the client, right? And if we follow that, I think there should be a separation between Of course, that RFC didn't have 45 you know, DSV marketing that time. Here is some additional additional update is required But I think gaming and conversational video should be in 2 different classes. Right? Okay. Tong from Poway. Thank you for the great results. Actually, I also look forward to other more test results, regarding other access types, like, 5 g r or something. So my question may be some, related to some technical details. Like, how do you set the, say, EA market thresholds? -66, did you tune it? Or do you use some default value for all the traffic? Just just just just mean, just who avoid, like, negatively impacting the user experience. I mean, I think most of that is done on the client side. So the application saw where, you know, can decide to implement different ways, like the FaceTime you know, application could decide to do something different from the gaming client or something like that, unless you have any other comments about, the docs of specifications that Greg wrote. Yeah. On the CE marking threshold, specifically, that's one of the, configuration file changes I think them be rolling out soon. Currently, as I understand that it's a It's a very low threshold. So there might be some excessive, CE marking happening, with the current testing, but the attention is that it'll be around 2 milliseconds of, buffering delay. Would be the the max trash. Cool. Because, one thing I'm wondering is that it may not be"
  },
  {
    "startTime": "00:48:02",
    "text": "the best, option here to just set the, marking threshold to the same value for all scenarios. Like, we have conducted some 5 g task with FRS. Just using, real 5g 5 g RAM devices, and we see that, no matter what's the marking thresholds because of the, for example, the versus scheduling or some other, non congestive behaviors within the 5 g scenario then the tendency will just will not be, decreased to, super low value And in that case, if you set the, threshold to extremely low value, like several milliseconds. You actually they're they're actually negative effects to the throughputs and also the bandwidth just has and efficiency So would like to see some discussion maybe in the future what, mainly for other access types. Thanks. Yeah. I think particularly for, networks where the capacity rapidly varies, like in wireless networks. Think having a little bit more of a buffer gives you the advantage of having bites in queue that you can and flush out of the queue. Soon as there's capacity available, You can have fixed network, maybe not, as we get to. Thanks. Thanks. Great comment Yeah. Okay. So we're we're gonna close the queues soon. So this is notice that the the queue is closing. If you really think you have of being important joining joining the closed queue, but otherwise, is the Q Land after these two talks. Oops. Yeah. Hi, Martin from Samsung. Yeah. I mean, really interesting to see the results presented So I have, like, 2 grays, that One is like, when we saw the gaming latency, yeah, as as someone mentioned, like, once we put,"
  },
  {
    "startTime": "00:50:00",
    "text": "the packets into ACVI. So definitely, the Wi Fi is going to prioritize a few of the packets. So I I'm just I mean, the rfc8325 recommends the interactive gaming to be, part of the But, from the experiments, what are, I've done so far I feel like, the gaming does not actually, follows that So my first query is, like, did we ensure that what we benchmark with the, the default case was it also in the ACVI? I mean, was it suffering even when it was in, the VA priority? So that's number 1. And, number 2 is, like, any plans, for testing with the Android or, like, other databases. Alright. So I'll hit the second question and then the first question. In terms of Android, I we have users, you know, running test whatever they have. And, of course, using their normal applications and devices as they as they have. So, you know, some certainly people are using Android. We haven't done any Android specific tests, if you have any. You know, we'd love to, love to talk about any ideas and and introduce those. So, you know, hit me up, offline if you want. In terms of the first one, you know, the testing that we've done so far is only, in the upstream direction. And so you know, really once once we get the packet off the wireless LAN, we're looking at the the CE or ECT 1 or DSCP 45 marks, and then putting that in the upstream low latency queue out of the cable modem through the access network. And so that means on the Wi Fi of LAN side of things, you know, if the client has chosen to mark as ACVI or AC BE or ACBK, you know, that's just gonna get, you know, handled it, you know, however, know, the the Wi Fi network wants to handle that. So"
  },
  {
    "startTime": "00:52:04",
    "text": "We we haven't been able to sort of set that once we do downstream testing, then we'll see the difference. On the down street inside as the packets come into the wireless LAN from the from the, from the the sort of internet side of the interface, if you will. Thank you. We'll connect offline as you get this email. Thank you so much. Nice We have one more or more? Have no one in the queue. Well, thank you so much for that. For providing that update. That was super good. Come back again. Yeah. Other people, if you also have operational experience, please contact the chairs, we would love to present more experience as we go through this period of testing. Greg Europe. Alright. Alright. Hello, everyone. Greg White Cable Labs. 1st set of slides here to talk about the L4S interoperability events give everyone a brief update on work that's been going on, both here at the IETF and, Another place, just, I guess, I'm in the queue. We can we'll kick you out of the queue. Alright. Next slide. So, I think probably a lot of you are aware that we've been running this series of interop events here at the IETF meetings. There have been 4 of them. There's, are links there to the presentations, that were developed, breach the events. We've work been running these in conjunction with the hackathon. So we start, on the weekend before the IETF meeting. Kind of get the network set up bring the participants together, and then we continue through the rest of the week. So the presentation that's linked, in those links is actually the hackathon, conclusion presentation from Sunday of the event. So"
  },
  {
    "startTime": "00:54:00",
    "text": "it's kind of early on, actually, you know, our testing process and, and So it was more, kind of seeing who's participating and what the, intent is for, test coverage for, for that event. The current one is, still running. I see several of the participants are here in the room, so there are not a lot of testing going on it. Right at the moment, but, Feel free to stop by. We're in the, ballroom foyer that network would be set up. Through at least midday tomorrow. So if you wanna dot by and see, any of that testing or if you have an implementation of L4S that you're working on, please, bring it by and, and, into the network and, and, and give it, a try. In addition to the, IETF series of intro up events. Cable ops has been hosting a series of events at our facility. And, and that's been pretty useful for the cable broadband network equipment vendors because That equipment is large and, sort of complex to set up and, it's already in our lab. And so, it's, it's been pretty convenient for just application developer to come in and do a similar testing, but across, a range of cable network equipment and range of configuration, files, etcetera. And, there are upcoming opportunities. So if you did not participate, so far and you're working on an L4S implementation. Please, consider joining 1 of the coming opportunities. The next one of cable apps will be in beginning of December. Registration is open for that. The link on the bottom there And then, assuming we get critical mass Brisbane in March. We'll to do another event. And if you have any questions about, participation and interrupts Please prompt me a a male, a male,"
  },
  {
    "startTime": "00:56:00",
    "text": "Talk to me. Yeah. Quick question, Greg. Gladys, Edgar. I wonder if you had have had meetings at a nano core ripe or we're planning to because it seems like would be sort of the next step for socializing this stuff. Have not had, It's an interesting idea. No. Thank you. Okay. Next slide then. So the next couple of slides just go through the, participants, who have been involved in the interopts so far. We have It was a 9 different congestion control. Implementations, that have been involved in extra SUVs or Not the latest slides, unfortunately. But 3 on the bottom were new this time, and we're high and I highlighted them in the, updated slides that are on the, data tracker. So screenv2 is, new version of the real time congestion and color that, Erickson has been working on and was tested the first time in conjunction with some of the other congestion controllers this week. The quick go prague, I think it was first time that it's just been, tested, the LRS branch of that has been tested n, n Nell Forest Network and, Hopefully, little bit more testing will be done before theendoftheweek. On that on that? Yeah. Maybe. Okay. And then Netflix, joined this time with their rate controller that, they're designing were their cloud gaming, application. So in addition, 3 implementations of Acura DCN in, network stacks, and then the the Wireshark, packet disector, which can display the accurate DCN information in packets. Been involved as well. Right next slide. On the network side, So, DOCSIS equipment, more than 10 different models. It's really 2 different chipset implementations and, and the OEMs that"
  },
  {
    "startTime": "00:58:00",
    "text": "the old norms. On top of that. And then, 3 different CMTS vendors have participated. And, wipe wifi, the Nokia Wi Fi access point, Google Nest participated in the first interop, with their home router And then the 5 g rant folks who were in the London meeting, Ericsson, both Ericsson and Nokia had 5 GRAN equipment, for testing. And then last couple of interrupts, the GPON implementation from Yeah, So think that's it for that. Piece. So we can move on to the next Any questions? Go ahead. Yeah. So Right. Can you Yeah. Pick me fresh. There's a You need to re Right. Okay. So the slides would If you're going to send slides, it's really better if you send them a day in advance so we get them sync through the system, and we updated them and therefore, we updated them wrongly, and now we little of the right do you have people a new version or not? Why. If we can't, then doing QBN, we'll figure it Sure. Sure. That's the only Right. We'll figure it. Go and do and QB. Alright. The NQB draft, so we'll up to draft number 21. And, The new, one new thing to point out is there is a third co author now. So"
  },
  {
    "startTime": "01:00:00",
    "text": "like, as, Rudigar has made a tremendous number of comments and, and improvements to the document through his suggestions we've added him as a co author, of the draft. As of 21. So next slide, please. The Thank you, Rudiger, for all of your work in, in reviewing the document. Status, is we did a working group last call on draft 14. A year ago. And since then, there were a number of working group last call comments, a number of comments after working group last call, I'm cycled through several versions of, of the document. Now at graph 21, Mile stone is to submit as proposed standard by December, that's coming up fairly soon. I think we're, I think we're close, but, that's, maybe a little bit tight. And next slide. This is the list of changes in draft 20. I sent this to the list, 3 weeks ago, so I'm not going to go through, this in detail, but everyone should have had a chance to take a look at that if they're interested done. The next light, Draft 21. I just posted that earlier this week. Only 3 changes. So adding Rudigar as a co author updating, Thomas's contact info. And then, just a typo, adding the hyphen to Wi Fi. So With that, next line. This draft now, as far as I know, includes all the changes that were requested, through working group blast call comments. All the changes that were requested after working group last call, comments. All of the issues in the GitHub issues tracker are now closed. Link is there. And Next slide. Can we begin a final working group last call on this document?"
  },
  {
    "startTime": "01:02:07",
    "text": "Well, the charter says we should. Are there any people in the work group who have comments on this I'm very pleased with the in-depth discussion that happened on the and that you might reconcile those. Apparently, the people who are talking Working group as a whole, we'll need to have a look at this. Other people here who would review This, if it were put to working group last call, I see 1. Other more? Let's hope we find more. That that will be the question. So let let's look for people to volunteer to review this. Presumably lots of people in the country would like to review the final tech maybe people would know would like to look at it. Please let Greg or me know if you're willing to review. If we gather a few people, we'll a working group last call on the next revision. Alright. This revision, if it's complete, Thank you. Right. We will attempt Let's see that. No? Okay. Well, wait for us off. Yeah. I know which one it is. This. No. The other one just look here. So, it It's in the proceedings. Yeah. Would you like to talk to it without without the slides, the slides are in the proceedings, and it's only one site. Yeah. Sure. So, L4S ops, for those who not be familiar. It's, a draft that the working group started, with, like, signed on as editor, to to to bring together information and, and suggestions and recommendations on how to manage, potential for unfairness in, the network when L4S traffic, and classic graphic,"
  },
  {
    "startTime": "01:04:00",
    "text": "share a single queue RFC 3168 classic ECN bottleneck. And so there's just at least a theoretical, potential for rate disparity between classic and L4s traffic in that situation. And so the draft talks about How do I identify that's occurring? How to, mitigate the issues. And the working group agreed to keep this draft open to collect, further guidance as people get into further experiments or maybe have other ideas of ways to analyze if this is a real issue or just a theoretical one and, and so that's the state. It's it's kind of, in a holding pattern and, Any input is welcome. Please submit your if you have input via the mailing list or Now the draft is on the GSV Working Group GitHub, space. So you can logging issue there or or submit a PR if you have content that you'd like to add to the draft. So and that's it. You have comments, please come to the mic or send them to the list. This is his now on GitHub and Visible more to the working group. We had to issue a track a bit forward, but now the draft's there. People can of course send PRs and people can't send issues. So please do that as people are environment and do their operational experience gathering. Milestones It's, Mafton was milestones, November that year. So so we have plenty of time, but we only have time if we do the work now. Right. Okay. Thanks. Thanks, Greg. Sorry. Sorry. We didn't get the sides. We are. No. On schedule. So this is good. Michael, you are next."
  },
  {
    "startTime": "01:06:15",
    "text": "Michael Hooks, and I'm presenting on behalf of the coffice. Document about, adding to STDP to allow a 0 to be in incorrect checksum. Next slide. So the motivation for this is that SDP uses a CSC 32c for providing data integrity. This is an important feature when you run SCTPO or ipv4 or ipv6 where originally designed for. But if you're in the context of WebRTC, your lower layer is DTLS, and DTLS has a much better, integrity protection then provided by the CSC32 see. So, basically, computing this on the center and on the receiver sideburn CPU cycles, but gives no additional value. So the simple extension here is to negotiate a the beginning that you are accepting 0 as a valid checksum. Even if it's incorrect. And that way you can save these CPU cycles in the backwards compatible way if you're talking to an implementation, which doesn't support this. You don't do it. Next slide. So these are the changes due to the, working group last call comments, which were received Marise editorial changes. So, no, no, not from from a technical point of view. There was a statement in that using this feature must not in here with middle boxes expecting correct check sums. So in case you run this not over details, but over some other mechanism, you are using some other mechanism, which provides the"
  },
  {
    "startTime": "01:08:03",
    "text": "integrity protection and the 0 sec checksum is visible on the path. Middle boxes minded. Drop the packet or do something else. This has been This was a couple of people commented on this and this is now changed to must not result in path failures for more than a couple of RTTs possibly we should change this to RTOs. I don't know. But so for a small amount of time, it's acceptable that you have nonoptimal connectivity, but then you need to figure out that this happens and you need to fall back to using the correct checks on. So there, there is the possibility of using some heuristics. And, another point of discussion was, we have the this document creates an INA registry for the actual method we are using One is defined in the document using detail assess, the lower layer. And the question was how to run this. So the current waving the Registry is run is, specification required, which means you need some specification, which doesn't need to be an RFC. It can be from Samantha. Stand its body or someone, persistent document, and there's an expert review and we define in the IANA section what the experts have to check. Next slide. Implementation status. This implemented in the previous econnel, and therefore also the user lens stack. Use our STTP, there is an implementation DCS CTP, which is Google's implementation of a CTP use of the Chrome browser. There's a patch for the PiON STTP stack. Support in packet on a Wireshark. And we have as part of the GitHub repo on the,"
  },
  {
    "startTime": "01:10:01",
    "text": "TSVWG. Is it? Organization? GitHub organization. You have some packet with a test, so you can run a test really against your implementation. Next slide. There's So the next step is since the working group call. The working blast call is about to be closed. I mean, the, the, the, the, the end date is over, but It wasn't formally closed, but So I will address any upcoming feedback, but there's nothing on the to do list left. So questions on the presentation, anybody, please join the queue not to the working group. The working group last call period will end today. We we will submit that today. So, this is probably your last chance, child and informal working group must call comments. That office, please revise afterwards before you can you we complete the working group last call, or as we complete it, we have to consider one important procedural thing. This document proposes a new registry The registry allows non IETF documents to to specify The underlying transport mechanism of which this runs, and that would the current proposal will be governed by expert review. The Working group may have opinion on this, and we will consult the error director on whether that is the appropriate procedure, but that is what's currently specified in this document. So that is what the working group must call us about, Lars. I I'll have another question. What's the exact Diana registration policy you're saying? Because not is it is it RFC required. Just ex export review."
  },
  {
    "startTime": "01:12:01",
    "text": "Specification required and on expert will review whether the questions. Okay. There are conditions laid out and an we'll check if they are met. Okay. I actually came up here to sort of ask a, question about the, check something and that I should have maybe asked a long time ago if I had, seen the presentation. Do you have a rough indication of how much CPU we're saving here? Yeah. So there are users using data channels. And what they did is they disabled the checks on the receiver side. And you can gain up to 30% of CPU seconds. It's a substantial. Really? That seems an insanely high fraction for CRC32. I mean, 30%. These were low These were low power boxes, which don't have I mean, RMV8 has support for for special instructions for doing this, but they were on on smaller box. All the cycles involved in receive processing. 30% are on this. Well, that but the 2 statements. One is I know about someone who has a product who did this, to substantially reduce the the CPU amount. So he could do with computing to check some. He couldn't do what he wanted to do. And that was, forwarding video frames or something like that. And I, at some point, did some measurements where they where, this adding the checks I'm giving you about 30%. So that's the worst case. So I find that extremely hard to relieve, but I okay. I mean, 30% is Lot. Right. I mean No. That seems That's why you do check some offloading to her. I mean, you can Yeah. But still, I mean, I know crypto takes way less than that. Crypto has support on the CPU of who. Crypto on the CPU takes less than that. Okay."
  },
  {
    "startTime": "01:14:10",
    "text": "I'm stunned. I can do a CRC 32 using lookups in not that many instructions. I mean, Gobsmacked is the response, I think. Now, Niffel underestimates the ability for software engineers to, introduce bloke Apart from that observation, does anyone any other comments? That's It's moved to that slide deck. Okay. And please prepare a new revision when the working group of call closes. I submitted a version addressing all the comments yesterday. If so, all the comments are in the current version. Yes. Excluding last call comments. Yes. Excellent. We can, do a working group chair review and get the AD to look at this. Okay? This is about the document I was talking about earlier. RC 49 95 is the best is, regarding a CV authentication. Something which is pretty old and used for protecting dynamic address reconfiguration and issues in relationship when you run DTS over at CTP. And this is about a biz document. For that RFC next slide. So this is the motivation for this. Erickson has reported to"
  },
  {
    "startTime": "01:16:02",
    "text": "security issues. One is that the the keying, which, I mean, the the HMAC protection, which is done there, uses, symmetric piece in both ways. So what you can basically do is you can reflect messages. That's not what was intended. And that's, that's clearly an issue. The second one was that it's possible that you use 2 different HMAC algorithms with the same keys. This is not something you should do if I understand that correctly. However, there are no known issues in this particular case. So, the first one is the more critical, the second one needs to be addressed. The next point, which was known for a long time, is that it uses specifies age based on Sharwan and Age Make based on Shar. 256, and You want some more algorithms, some modern algorithms, and you might wanna deprecate HMACshot 1. There was some years ago a document proposing some clarifications, basically, we should incorporate that. And during some during the initial work on updating the TLS over as CTP. There was the need for some more providing more information, you know, using the socket API to figure out what kind of keys being used what kind of algorithms being used. So that should be included. Next slide. That's the status of the document. It was the original one was just, the RS see submitted than doing some changes to XML using XML because initially it wasn't used. And then some changes, you can you can go through them via the, data tracker"
  },
  {
    "startTime": "01:18:00",
    "text": "So basically, the socket API has been dated to reflect the requirements of DTLS for STTP. And, the author list has been double checked. So I initially started with a list of authors from the original RC, Ecker don't have cycles to to doesn't have cycles to work on this anymore, so he got removed. And Hannes was added. Next slide. So, what's the main issue here a handshake in STDP where you use, or you, negotiate as the authentication, you have 3 parameters, 1 is the random parameter, you exchange it. 32 byte random number. You you say which chunks must be authenticated by the peers, so you only accept them as a in an authenticated way, and you say, which, HMA algorithms you support Next slide. So the main problem here is you need to differentiate, the roads of both sides. So in detail, as you use client and server for that, we can't do this on in STTP because it supports a symmetric way of of setting up the, the association. So the idea here is to use a key vector, which is already used, concatenating the random parameter, the chunks parameter and the HMIC algorithm parameter. And, base the role on which of this key is smaller. So, that way you can can use, different keys. And, right, and the only problem you have is What if both keys are the same? This can be avoided in a client server situation because the server can always when it chooses the random number and figures out It's exactly the random number it got. It can"
  },
  {
    "startTime": "01:20:00",
    "text": "choose another random number. But if you have, peer to peer set up, you can't do this. So you have to redo the the handshake, and, you can hide this from the upper layer. But we think during the res doing the Hendrake again is acceptable. Because you have a very small probability of the position to happen because you are using 232 byte random numbers. So that should be acceptable. If not, would be good if you can speak up Next slide. Yeah. That's next step. I think it's a good point. It's a good time to ask for back end group adoption since this document needs to be done at some point of time. And it's pretty clear what the what needs to be done. On the to do list is, besides getting the the part to to do what's on the motivation. Magnus has done, revenue of the current draft and has laid out a couple of issues. They need to be addressed. Anything else which might come up during the work on D TLS over at CTP or any other work in this, SDDP security. Design team stuff might come up needs to be addressed in any additional feedback. We'll take questions first on the talk if people have specific questions. And then as people are gathering any questions, we will start that, adoption question on the list. As in now here. So the first thing I guess as people are thinking whether they have questions, the chairs will assert that they rethink this falls within our shorter So we would like to proceed with understanding Who has read? This document."
  },
  {
    "startTime": "01:22:01",
    "text": "If people have read the document, please indicate ice, Yeah. Well, we'll take 1, 2, 3. 4 at least four people. Yeah. Okay. So we have some some people have read it, Okay. Right. We'll start the formal question. And, well, please or indicate remotely. Please don't indicate on in the meeting material if you're humming because you can't catch you twice, but please harm or indicate in the tool if you think this topic of maintaining the spec is one we should address. I can't a small home. Please if you think this topic is one we should not address in the working grip. Silence. Does anyone want to speak about why we shouldn't do this? I hear nothing. Okay. So It was that in mind. We will ask an adoption question here Please use the tool to record if you are able to. So please use the tool. The question will be who supports adoption of this draft as a work item in this working group. We will open the session with the question now. Please record yes. If you think this draft is a switchable basis, No. If you think this draft is not a suitable basis for proceeding or you can call it an opinion if you like."
  },
  {
    "startTime": "01:24:14",
    "text": "So the chairs are recording some support for a yes, and we saw 15 votes. We saw 2 for no, and we're now giving an opportunity anybody who said no to speak about why they think they may have concerns about this draft or the topic in general, please, volunteer opinions if you can or talk to the chairs after this. And we saw 61 with no So 15, say yes. To say no. Do any of the people who said know which to comment at the mic or of, online about why they say no, Okay. We will repeat this, adoption call on the list and confirm the result here. So far, this looks like a suggestion that we should adopt this as a work item. Thank you for the contribution and work done so far. We will start a adoption call formally on the list to confirm that. Okay. Thank you. Thank you. Whoops. Michael. Is there anything on the SCTP details group that you wish to report upon. Okay. So repeating that by the mic, There is a design team meeting after this meeting."
  },
  {
    "startTime": "01:26:01",
    "text": "Will be an informal design team meeting because we want a video call for remote participants, I think. But it will be a point of coordination we will be having additional design team meetings scheduled with a remote participation And from that, we hope to see a pathway forward on the FCTP details work. That design team should, and at the end of December. I report back to the working group. Okay. Oh, and I I see what's happening. Need to summarize what's happening with UDP options, and I shall do that via the mic. So, Gary Firth is speaking on behalf of the Working group shares about the TSB WGA UDP options draft, and the editors of that draft have been talking to me, that's your touch. And so her Mike, who's been on list right, these are my summary slides of what's in tracker. So this is a summary exactly of what's in the GitHub tracker. Left side, So we have a bunch of issues. Joe has filed, rev 24 during the IETF meeting, which he hopes has resolved this set of issues, These set of issues are, ones that are in the tracker, they're visible, I'll go through each intern and the intention would be that we close these issues once the people who've raised them or discussed them con have confirmed that there are no additional work is needed on draft 24 clauses. So, 18 was from the presentation at last IETF meeting, about the design calls of UDP Options,"
  },
  {
    "startTime": "01:28:00",
    "text": "15 was about the res option 12 is about Whether the OCS is mandatory under civil circumstances, this month has attracted a lot of comments backwards and forwards from a few individuals If you are one of those people or anyone else interested, please check draft 24 to check that you see this issue closed. Number 10 was a pseudo code error, which we expect is resolved, number 9, a formatting error, which we expect to resolve, number 22, was to discuss privacy exposure when you use UDP options. For which new tests have been added to the security considerations. If you think that resolves or does not resolve this, then please comment, I propose that we allow a couple of weeks. And if we don't hear additional feedback, we declare these items as closed. I'll post that to the list. Next slide, please. These are the issues to be resolved. Most of which have discussion points, but require some sort of action. And after this bunch, we are hoping that the working group can have a working group plus call So now is the time to check that you have the issues addressed that you feel should be addressed next slide is where I think we are at. This is my own personal summary as a chair. A shoe 21 is discussed. PR is needed. We don't have a PR mechanism at the moment. So send text to in the issue or send text to the authors. It would be nice to have the sync at home, I think, so we could actually raise a PR. Talk about whether we can get a text there or not. Issue 20 We think is wordsmithing,"
  },
  {
    "startTime": "01:30:02",
    "text": "somebody has to read through the text and check it's done. Again, the same 2 week cutoff will be done on trying to close that issue. Okay, issue 16 is something I'd love feedback from, which maybe people in this room might have a possible input too. So I'd like to explain that and see if anybody does have any input. UDP Options provides a fragmentation capability to That means that a single big UDP datagram can be sent in multiple UDP Pockets. This raises the issue that what happens when you only get a few of the fragments you need to reassemble a full UDP datagram What happens when there's a drop fragment? There are 2 potential things that have been suggested here One is do nothing. And let the application figure out what to do. It's a UDP application it almost certainly has some idea of what should happen, and it probably has its own application way a way of feeding back what to do when it doesn't get fragments. Maybe the fragment size was wrong, or maybe it's drop fragments. It can signal that at the application layer. Using a datagram sent over UDP. The second option is we send an ICMPV 4 or ICMPV 6 are a code in an ICMP message, for one of the pipe kits that were dropped which contains the UDP segment rather like we send an ICMP port unreachable. That provides you with a Feedback mechanism using ICMP that the sender could observe. The UDP sender could configure the ability to receive ICMP messages could validate that these apply to the UDP floor could process them. Could do something useful. My question to the group is, does anybody here have opinions about whether generator"
  },
  {
    "startTime": "01:32:01",
    "text": "an ICMP message from the UDP stack Back to the sender to indicate fragmentation is a good thing something we should try and write a spec for or a bad thing. Does anybody have a feeling for this? Come to the mic, please, and help us work this out. Voice mail. Wolfgang. What's going back? .Com? I think it would be a bad idea to have ICMP feedback because if you have things like oversized UDP media packets, you're not interested in the feedback from ICMP. You have other feedback mechanisms like RTCP. If you think, UDP based protocols like DNS or SIP or something like that. They have their own time out mechanisms and and retransmission mechanism. So I would proof solution that simply drop the UDP if you don't have the fragments within the time frame. I understand. So proposal just to let the application layer deal with it. I'm I guess also that means that if the application deals with it, We don't want ICMP messages because we end up with 2 messages for each packet, which in is a bad side effect. As in 2 notifications of fragmentation problems, around 1 ICMP, 1 in the locations, I hear that. Anything else to add? Oh, that's good. Who who's next? Oh, go ahead, Mike. I concur with everything that was just said. You can care with that. Okay. Anybody else want to come in on this? It would be helpful closed this draft and get it published, and this is currently need feedback on Christian, Christian, The the main, way that application deal is augmentation loss. Is by setting up the don't fragment bit. So I sure hope that we're not messing with that."
  },
  {
    "startTime": "01:34:03",
    "text": "Well, obviously, these are not IP fragments. Interesting. Okay. How do I talk between the bursts of drilling? I'll try to. You told Secretariat. Okay. They will hopefully do something. Okay, Christian. Hopefully, you can hear me. These are individual UDP pockets, which can set DF. This is fine, but they are fragmenting a larger UDP data I'm at the sender into 2 individual UDP packets each with an IP header. The setting of DF is It's possible. I mean, you know, I mean, application do what quick does, in particular, is set the DF bid system, particularly, why we're seeing. And that's its own packetization on top of that. Yeah. Uh-uh. And and this I think this is an part to this because this is about, fragmenting the payload. On top of it. But again, and so so do you understand what I'm saying, Christian. No. I mean, if the application is fragmenting the payload sending multiple data clubs and the application deals with, we are simply and, we repetition of whatever. And so I think, I do concur with what was said before. Please don't do anything special. That I hear very clearly and I think that's currently been the consensus. I haven't heard anyone else say that they want to ICMP packets. So thank you, Christian. Very clear. Sorry for the drilling. Okay. So on"
  },
  {
    "startTime": "01:36:00",
    "text": "Number 16, we will provide a feedback to the editor that I'm about what was said at this mic here. Right. We have a comment. Sorry. I my my thing crashed. I'm Martin Duke. No hats. Yeah. I mean, like, I think This is confusing because there's IP layer fragmentation and this is, like, you deploy your fragmentation if I understand correctly, and then there's application fragmentation, which is perfectly out of scope. Tip. If I think about it that way, then, like, an ICMP message is a layering violation. Because that's for IP fragmentation. Yeah. Port both our UDP level. So, I mean, it's possible to have a UDP. ICMP message, although whether it's whether it's the right thing to do is kind of what I'm asking I think we'd have to have a strong reason for doing it. Yeah. Okay. Thanks. Thank you for that clarification. So we have a number of comments on issue 16, which we will edit into the tracker and then hopefully be able to close this Then we have issue 6. Which is the UDP encryption, This comes from the last working group last call where it was asserted that we don't have a full for UDP based encryption in this document, and we said it will be a downrev to reference the individual draft, which is also incomplete on this. And the suggestion was to remove it from the spec, respond to another spec, at the moment, we still have a assigned UDP option number for this. So we will have to decide as a group, or the chairs will have Nias with their AD about what we do with an unspecified option. With an option number, that seems like a a thing that we have to talk about, we will do that if you have fee"
  },
  {
    "startTime": "01:38:01",
    "text": "feedback or comments on whether we should use an option number to describe something which is currently unspecified, please talk. That is option 6. We will clarify this and continue with the working group last call on this item because this I think is just a procedural thing number 5, authentication, the question was, is this sufficiently mature? It was raised in working group last call, I think, by Magnus, and, please look at the spec and comment on issue number 5. Finally issue number 4 was Whether we should include a more complex and probably better RTT estimation algorithm apart from a simple echo clearly, we could. Much of my question really to this working group, which is one I'll paste again. Into the mailing list is is the current simple methods sufficient? And I haven't heard anyone say that it is not sufficient apart from people who says we're said that they might like it more finesse and more capable, but then as I note in the issue tracker, this is something we can add a new option for in future. So, limitation of going through this list is not to bore you. It's to try and close these items out so we can publish a final document then proceed to working group must call. So it's hedged up that this document is actually going to be finished. Can we go to the next site? Pulication milestone was September 2020 3. You know, when we talk about RTT, accuracy, I mean, was pretty good. It would I think we're still near September 2023. So I'd like to try and leave the milestone and actually try and get this done before the end of the year. There's been significant progress since the last working group must call. I believe that as a working group chair, the document is now stable. And the issues are very few remaining."
  },
  {
    "startTime": "01:40:03",
    "text": "Will need to find a working group last call. So at some point, would like to make and not working group bus call. Anybody any questions? Oh, good. I hope you would come back. Go ahead, Mike. I, admittedly at the last minute, went through slides and all the issues. The current dash 24 didn't quite get any of the ones that are expected closed fully addressed in in my opinion. And I comments to that effect, in the in the tracker if you could back up one slide, I'd like to make a couple specific comments there. Please do thank you. Number 21 is is, I think, our biggest bug bear And it's basically that, modulo the issue of auth not really being ready, which I happen to Reon, after a lot of thought. Those two are specified correctly within the architecture that was set forth and actually published in this in this, version. But they defy expectations. And I think the working group really needs to decide, do we want these things there at all in present for. The easy thing to do there is drop them all together. If that is not if they Defy expectations and don't do what you want. I am I just assumed to see them gone. But they, APC in particular, the issues not raised until recently, so I would understand some dismay on the part of our of our editor."
  },
  {
    "startTime": "01:42:01",
    "text": "For a late surprise, and all these things happen. And, I think on on the, the rest, we we we seem to have agreement in principle if we can get a get a a new draft turned around. So that, and by the way, editorially speaking, making a decision on whether you keep a placeholder not for Eui and C is it's it's it's kinda important to the editor because there are a lot of it's it's used as an example in a lot of places. And if it goes away entirely, there's There's a some collateral work there. That isn't a reason for making a decision, but, just be aware of the of of what it that it it'll have some impact Thank you. Okay. I mean, just to be clear on the editorial I might because you might be the mom doing it. I wonder if we can actually keep the concept of its, you, Hank, would have coded this and just just keep some of that text so that we don't lose the discussion there. But we just don't specify a code point for it because I'm really I'm hesitant to the specified test to see if I a cold point for something that's not specified why don't we just write another RFC to do that? Kinda hard to argue with that. Okay. Thank you. That's good. Oh, thanks, particularly to you for your diligent checking of that. That was so good just to have another person go through. Right. I don't see comments from the working group here, and I suspect we shouldn't take more working group time. Just to say, I think the most likely thing now as a chair that we should do is clearly serve as quickly as possible so that we can do a December working group last call and really ask if there are remaining important questions in that working group last call for resolution as the working group"
  },
  {
    "startTime": "01:44:00",
    "text": "rather than just the editorial team. So we will push as far as we can. Try and ensure that the working group gets the document they can count on in entirety. Please, then contribute and review Anything to add my margin? Nope. That's what we talked about, so that's what we shall try and do. The You with and a heads up Unproposed work. Oh, well, what? Oh, okay. I might sit down. Yeah. Working group, and comment. We we have had a full agenda time for many IETFs in succession, and a set of drafts which have existed for many I. E. Tests in succession. We now appear to be entering the wet area with some new set of work. Most of which currently, has not reached the working group because we have a charter. We have lots of individual drafts. Lots of people thinking that that something should be done here. We have turned away a lot of presentations in the past because we had no time. So we might be entering a new area of looking to see whether there is important work to be done here. I think that's as much as we want to say, really. I'm just trying that we are now open to listening to people for new items of work if there is something that's pressing and the community wants to do And with that in mind, we will take some individual draft which are being discussed on the list. Is John"
  },
  {
    "startTime": "01:46:12",
    "text": "So this is the media header extensions draft. And revision 3 of the draft. The next slide is So, we've got a lot of feedback on, revision 2 and, then following our revision 3, we've gotten extra feedback too for which we've made a lot of changes. I just wanted to run by what exactly we're talking about before we get to what the comments were so that everybody's on the same page. So essentially, this is the problem is that the wireless network capacity changes very quickly? And, on the other hand, media that sent from a server. Cannot adapt at that speed it it settles to a longer term average, but it cannot adapt at the very, millisecond or submillisecond rate of change. So what this draft is proposing is to send additional metadata that can help the wireless network make the decisions for those very short time frame. So with with that overall context in mind and we've, we've proposed, mechanism to send metadata on packet by packet, basis that will help the wireless that would make these decisions. That will the data are essentially about relative priority within that flow? And, delay And, the bird's size. So that's that's the that's the aim of it, which I'll get into the next page, but for this page, I just wanted to go over"
  },
  {
    "startTime": "01:48:01",
    "text": "the main set of comments and where we are on the method. I mean, it's grouped into two sections, basically. The draft There's one aspect about the metadata itself. And the second about how it's transported. On the metadata itself, we've been fairly stable from revision 2 onwards. There have been a few changes that was suggested, and we've made those changes. In terms of the procedure that's used this method is is there are a number of signaling metadata, patterns that have come up in the IETF. This one is talking specifically about sending per packet data. That will enhance QOS and it's provided between 2 domains. So there's a provider B in this figure that writes this metadata and it is sent to provider a, which is the wireless provider. And it's done on a packet by packet basis. Some other patterns that we've seen include an event or a condition of a network that triggers sending of signaling data. But that's not on a per packet basis. And yet other patterns are for services to be initiated in that provider's can to be granted in that network. So There are 2 or 3 patterns, and this is specifically about the pattern that I just talked about where the server sends a packet And, the wireless note reads it and uses that on a pocket. To group So this has been, this is pretty stable on the draft. On the transport, there has been that's the second point I'm going to right now. There's been a lot of discussions we had 2 different options in the draft. One was"
  },
  {
    "startTime": "01:50:01",
    "text": "the what's shown in the figure, read right by the server and read by the wireless note. And another one was, this is what we call a transport option. The other one was to use a network option where the the the option was sent end to end. And based on a whole lot of discussion on on the list, we have decided to keep it simple and only use this option where there's a producer a server that writes the information. And a consumer, the wireless know that reads that information. And that is sent in an outer packet. In this one, we have a viable solution that can work using UDP options, options, but, we're flexible to have other ways. So solving that transport if something comes up. But essentially, we wanted to to support this use case. So that's where we are on this one. If we go to the next page, I can Go. Okay. So, here's the the set of things that we want to accomplish. I mean, I mean, I mean, I mean, on on the left side of the page, we have the information elements. And the talk tree, the importance or the relative priority, the best size that indicates the the the a frame in the application. And, the tolerance to delay that has. So all of these parameters are the same for a set of packets or group of packets that come together, for example, and iframe in a video or a peak frame or and so on. They do not change per packet. They change only per application unit or what we call a media data unit here. The other 3 parameters the, at the bottom, the the sequence number, the packet counter and time stamp. They are changing on a packet by packet basis. So these together make up the metadata that we are sending"
  },
  {
    "startTime": "01:52:00",
    "text": "between the server and the wireless note. On the right side is a processing. I think I covered a lot of it. This is one way only. The metadata does not change or look at or affect the the payload itself, which may may not be encrypted the network entities do not read these data. And, Yeah. The the model is very simple. The server produces metadata and the wireless now consumes it. Other, there are a few other things that, you know, it does this this method doesn't affect things like queuing or other aspects in the network. Nothing has changed. Only the this is only for the wireless network, so it's a limited domain and can be incrementally blight, plight, handling off this in the wireless network and related aspects of fairness and so on. Handling in the wireless network. Self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self, self The signals are advisory. If it's not received, it goes down to basic handling And, there's one aspect about feedback to the server via RTCP and so on. If we need to look at pacing or something that would be another profit. It's not the scope of this Did you want to And just a clarification question, when you say the values of these fields change per packet. Are the fields mutable or immutable within the network? They are not changed in the network, then they're in need. So they're in need. Yeah. Thanks. So, And I think Dan will have a question, or I can wait until you finish. I just put myself in the you. So I just wanted to point out that this point, we have a very clear separation between the metadata itself. The transport. So we have the ability to I mean, the metadata has been pretty stable for quite sit down, so, so,"
  },
  {
    "startTime": "01:54:00",
    "text": "And and that is the major part of this draft. So as, I mean, the transport, we have a viable transport. But we are flexible to look at other options if there is a need to do that. And, I think if we go to the next page, I think, Yeah. So in terms of how this would get changed in in a revision of the draft. The top part on the metadata as I just mentioned is all stable and no changes. Everything is as it should be maybe a fewer editorial changes. On the transport There's like chapter 5 and 6 And now it's simplified to just what's in 0.3, which is that simple model between the server producing data and the wireless no consuming data using this UDP option. I think that's it on this page and I think at the end of it, Yeah. We we think that the major part of this document, which is a metadata is table and, the transport only has to be cut down to the simple operation, So this has been presented. A few times in this, working group There's been a lot of discussions which is which has helped us reduce it. So thanks for all the input and suggestions. That's been very helpful, and we now have a simple transport mechanism as well. I think the feedback we've gotten the last time was in general that people would like to look at this problem. And, that's all I have to say about We are not considering an adoption call at this meeting. But let let's take questions first, but we will like to ask questions to the group if we can't Thanks, John. Dan Ruth's AT and T. As you would not be surprised. I'm interested in this subject. I just don't know so first of all, I have a question about,"
  },
  {
    "startTime": "01:56:00",
    "text": "you know, what is the overhead? Have you kind of considered, you know, the overhead of adding per packet information. And specifically, information that needs to be updated quite frequently was the overhead on the media server? Was the overhead on the wireless node. Also, What is realistically? Is it feasible? Are the media server. Providers willing to play along. To me, this is the more fundamental question. Not not that is a technical or not technically feasible or not. It's just is it feasible in the wild? And how do you plan to encode those 3, elements on a per packet. I'm curious because I've seen patterns in which you know, the expectation is that there is one piece of information being sent. You're actually expecting to send 3 you gotta have some sort of a data structure to come along. So I'm just curious. Thank you. Can I respond? So Yeah. I think, in terms of the size So if I remember the first question, how big is it? I mean, it's, 18 bytes. The data self. If they add an authentication option, then that would be the additional size to it. So it's not too big in I mean, it's it's pretty compact data, I would argue. In terms of updating things, I I think we we've got it to defined it to be So I think one of the parameters is the importance of the relative priority, which is pretty easy to provide. The other options are, the the burst size and the delay, which may not be so easy to provide. So the the data is flexible in terms of providing just 1 or 2 or all 3. They're they're incrementally."
  },
  {
    "startTime": "01:58:00",
    "text": "We may need to give short answer. We're gonna get to some questions at the end, but Okay. Okay. And can I just answer the last question? You used time to see So very quickly on Dan's last question, I think that was a very important question. I completely agree. The idea of having something the IETF is to allow many service providers, I mean, the application providers, and wireless service providers to have a common framework on which on which which they can use as a basis to do this. But, yes, there are trade offs in terms of how easily this can be provided or how fast this can be processed. And that's something we need to look at as we go Thank you. We only have 2 minutes left, so please keep your questions short. One of my concerns around the metadata here is is related to how the information They know that I could process this in the in the wireless network. Might actually have to keep state because some of these information and the set of packages is over. It's longer, maybe, than your buffer death. Which means that you need to keep surface mounted state tracking things in. I'm I'm quite worried about this and that the fact that for doing this. And in this case, there are work ongoing in fifty people around this subject matter. And and some of these questions seems to have a lot of impact there, and it might actually be them that has a very relevant insight into can be they will not do a certain thing and it's and if the metadata is useful. So I'm a bit worth rushing ahead of ADPP here. And we're not going ahead if it's an individual draft, and we're discussing whether these are important parameters. We're only going ahead if we actually do a spec. Yeah. Thank you. Martin. Martin Duke, no hats, First of all, to answer the question about media providers, I mean, I think I told you this privately already done, but, like, the sad CDN folks, our largest content providers are trying to solve very similar problems"
  },
  {
    "startTime": "02:00:01",
    "text": "I would strongly encourage you to align with that effort. Rather than do like a bespoke thing in TSCWG. I do like I what what I really do appreciate how this is sort of migrated to UDP encapsulation which I think we know how to do, and there's like an explicit channel between endpoint and network and also allows us to easily plug in things like DTS. To provide security and and and privacy and authentication instead of like, having to roll our own mechanism. So, like, this direction towards you keeping encapsulation is much, much better. Than using UDP options and other things. Thanks. So Hampshire from Huawei. I think this use case is valid and it can be separated into 2 parts. So firstly, it's about what kind of metadata useful for this kind of media where our QS And the other part is where to pull this metadata. It kind of we should separate the students first agree on the metadata part for the second part of the encapsulation, I think we may need to, to defer it to the implementation or which protocol are you using? You just, you can set that protocol to generate another 6. Thank you. TINCI China Mobile here. Well, I know the background about the things. Actually, they are, real requirement from, through GPP regarding the work John is doing here. We do support the idea. It's one of the, but one of the very, possible options for a 3 b p to look at this one. So I I think this is a a good life. Just, you know, there are some something else to take Thank you. Marcus? Alright. Yeah, I just wanna come and say, agree with Magnus that we should really listen to what 3gpp decides on this because there's a lot of work on the applicability of"
  },
  {
    "startTime": "02:02:00",
    "text": "this one comment, I think you have to think a lot about the trust model and security here because these these signals can, in principle, configure the behavior in your 3gpp radio, and can allocate resources. You need to maintain state, and there's a lot of work, you can make the radio do. So you have to think hard about how you can trust these signals. Thank you. We'll be doing that. Yes. I'd appreciate, if you were discussing 5th a little more intensively in your draft and not just reject all the principles and and methods are available there, which will simply do without discussion, which nothing is appropriate. And, I also wonder, if so, she could signal up to 64 scheduling behaviors, what does his wife know do. What do you expect us to do? Have to answer right now. Please add material to the draft and so that I can have a discussion because for the time being, there's no material and no starting point. Thank you. Can't Okay. So our case trend, let's try a couple of students and then the working group will have to close. The first question is, can you please if you think the topic of per market. Sickling. In other words, within the floor, signaling to element on the path be the wifi or 3 GPP or something else. Is a topic where you would like to see work done. Please if you think per packet, option is something where you would like to see work done here. Please, if you do not think we should do work on per packet. Flow marking. No. Thank you. Some homes both ways. Probably slightly more for the first one. Narrow question. Who would contribute to this work, please, go, enter the"
  },
  {
    "startTime": "02:04:04",
    "text": "tool, and please answer a question. If you would like to to to work on per packet marking for this application. That's it. In for network elements on the path to see per packet updates of the flow details. Please say if you are willing to do this or if you are willing to Hewitt, This is not whether you support it. It's whether you're willing to work on it or review it. Yeah. Sorry. We need to bring up a port. We are doing that, and the poll tool is there. Yes. Would you work on or review work on this this is okay. I'm not sure what no means, but, that's okay. Volidanza. Okay. Okay. Well, Okay. So this is really for me to judge whether there is a community here who could comment on this and I see that twelve people twelve people. our people responded. That's a useful input. We saw 28 people interested at the last To IETF in this topic. It's something we will talk to you more about and something which we think the working group should use working group mailing list to develop more thoughts on this subject. So please continue to discuss this on list, John. Thank you. And we will close unless our AD says he wants to say something, and he doesn't. So we close. Thank you ever so much for attending. We will see you at the next IT Thank you."
  },
  {
    "startTime": "02:06:09",
    "text": "Did I just hear somebody go, sign relief?"
  }
]
