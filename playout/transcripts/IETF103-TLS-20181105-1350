[
  {
    "startTime": "00:00:26",
    "text": "all right here we are in TLS meeting we\u0027re still looking for our note taker like somebody to take notes you don\u0027t have to capture every discussion just the action items rich sauce we\u0027ll take notes for us thank you alright if you do them in the etherpad rich if he doesn\u0027t mean that you to path and other people can follow along alrighty here\u0027s the note well it\u0027s Monday you may not have seen this yet basically you\u0027re gonna get recorded bade professionally you got IPR you need to discuss it disclose it I\u0027ll give them well request we got a minute taker thank you got a jabber scribe the blue sheets are being distributed now make sure to sign those put your name and your affiliation on there when you get to the microphone please sleep state your name at the mic for the note takers let\u0027s keep it professional at the mic and I\u0027m adding a new a new one to keep it succinct at Mike I know some people do monologues we don\u0027t always need those alright so the next thing is the agenda I think there won\u0027t be any agenda bashing asthama hope basically we\u0027re doing the administrivia now then we\u0027ll look at the details 4.3 draft then I\u0027ll spend a couple of minutes talking about that deprecating TLS 1.2 and 1.1 then a bunch of time of a encrypted SMI and TLS and then we\u0027re going to kick over to proposed charter checks that we suggested then we have some non working group drafts that\u0027s what that line is trying to figure out if they want to be adopted or not what PS k plus certificates additional certificate types the support be able to do communications and then we have these two ideas about PSK and quarters and universals and trying to figure out what if anything we want to do there and then we have another one called to get requests the agenda for Wednesday our next session is all about DNS like chain extension and what if we can do anything to move it too long there are some preliminary slides already uploaded for those as well document status since the last time we met we\u0027ve actually published five RFC\u0027s ECC cipher suites or TLS 1.2 and earlier two standard track we did our RFC a four to two elliptic curve cipher suites for TLS 1.2 and earlier we did some elliptic curve diffie-hellman PSK stuff with GCM at CCM for d TLS version 1.2 the drafter when we\u0027ve been waiting for TLS 1.3 and some slant some i annan registry update drafts a record size "
  },
  {
    "startTime": "00:03:27",
    "text": "limit extension for TLS which was probably has the record for being the quickest one ever through the working group we have in the RCA turkey now we have currently have an example handshake traces for TLS 1.3 i guess that\u0027s gonna get spun as soon as it gets to the off 48 stage it\u0027s kind of a pain apparently to pull the crank so we only want to do it once more since the last working group meeting cycled the the a dane record and indiana sec authentication chain extension for TLS back to the working group um we also adopted two new drafts which are this deprecating TLS 1.2 and 1.1 and encrypted sni for TLS we did a working group last call for the issues and requirements for SMI encryption and TLS that were thinking they keep probably pretty was pretty easily resolved without those issues on list and then get it out of the working group soon to be in working group last call we have three exported authenticators draft for TLS the details connection ID and greece basically i need to get together with the office for greece to get them to include a couple but then I think it\u0027s pretty much ready to go and in progress we have DTLS 1.3 a certificate compression draft which seems to be going pretty well they\u0027re experimenting with it now with the early code points level we had I\u0027m the delegated credentials which we suspect that we will hear a lot more about next time in Prague or wherever we\u0027re gonna go okay what\u0027s next so the Dilys designated experts stuff got set up as a result of our c4 for seven so we wanted to let you know who they were in case you missed it in the email that got fired off their rich salts Nick Sullivan and yo gear you have a request you can fire it off to that mail list the archives are now publicly so you can see the requests we don\u0027t want this to become an alternative place to discuss Els things this is if you have a request it goes over there they round-robin figure out how they\u0027re gonna do it and they get back to you if they don\u0027t get back to you in time there\u0027s ways to fix that um so far we\u0027ve had these values registered only one was recommended as a yes because it came out of the token blind working group the other ones were all kind of individuals stuff so the first floor I think were one was for peer Guttman\u0027s long-term stable TLS drafting they would have been three for Dan Harkins dragonfly draft three brain pool curves for supported groups and then a bunch of exported label values for one them to them one three so and that\u0027s it we\u0027re gonna put this on every time just to make sure that people are kind of aware what\u0027s what happens and gets done so no one\u0027s really caught off guard so they maybe you don\u0027t have to go and check the pool list but that\u0027s it now we\u0027re gonna move "
  },
  {
    "startTime": "00:06:31",
    "text": "on to DTLS 1.3 okay hunt this you get yeah I thought probably why spit yeah okay no all right so um this actually appreciate forward um I\u0027m going to start with summary the changes we made then have a few not really open but quasi open issues and then say I\u0027m done so we screwed around with the header format repeatedly and in the last version of this we had a header format with like a bunch of empty blank space that we have marches reserved and Warren Thompson played out that we could shift things around and wouldn\u0027t have and make the sequence number longer but also have less blank space so we have the following structure now um so the first as it\u0027s been for quite some time the first three bits have to be zero zero one that\u0027s like math saw for a specific region of the of the other code points based the there\u0027s a C bit which means the CID is present or absent one means present there\u0027s a L bit which says the length is present or absent and then there\u0027s a and then there\u0027s a sequence number length bit which says Helen sequence number is and then two bits of the epoch and I\u0027ve forgotten to mention this when I looked at this um I think these are probably in a Roman order so I\u0027m actually probably shuffle them around but other than those are your order but it\u0027s done um so probably I move around a bit but other than that um no one cares these bits go so um the basic idea is there was like I don\u0027t know there\u0027s eight separate forms depending on which bits are set but they\u0027re all fairly straightforward basically things are present or absent this gives us a unified header with a nice range of with a width length or not and a nice sequence numbers that should be big enough for anybody no I don\u0027t think anybody thinks more than 16 business sequence numbers needed so this was an initial draft nobody complained this is what we discussed last time so um this is just a briefing um some of you have just you know who speak up but I\u0027m just gonna keep going otherwise all right oh and here are some examples that show like the smallest possible thing on the right and the biggest possible thing on the left okay um the second big change is we did we added record number encryption or record secret or encryption this is basically the same technique uses that we just "
  },
  {
    "startTime": "00:09:32",
    "text": "stole on so the basic idea is that you establish your sure key is part of the key schedule it\u0027s not the it\u0027s not the record layer key it\u0027s a sequence number key and that key is used to generate a mask we have the it\u0027s effectively a PRF using the using some of the ciphertext as the input the PRF the specific function actually is depends on the Associated but for AES basically you compute a es e CB of T um you give it a sec V of the ciphertext and then you take that mask you XOR the sequence number quick has a somewhat different description at this this is a national algorithm that Martin and I disagree about what the most of what specific way to describe it is oh who was it okay other haters so I tried several several ways of describing this and no one was happy and so I went with the last one right that I ended up on and landed that anyway it\u0027s different to what you have here I started with what you have yeah so one thing worth noting is DTLS is not quite as aggressive as quick-quick about encrypting all the control bits so right so we quickly gonna be encrypting the epoch because in quick we\u0027re going to make the sequence number protection key fixed yeah over the lifetime of the connection worse yeah so I mean if people think we should encrypt more originally can on one thing that was extremely annoying quick is I\u0027m not knowing how long that there was so I\u0027m like not super excited about encrypting the bit the control bits here right and you certainly count and cook things like the connection ID bit because those are you typically used by something that\u0027s right not privy to the keys right so I think I\u0027m tempted to leave it the way it is but if somebody thinks more in detail is generally not as aggressive quick isn\u0027t working everything anyway okay um third major announcement um I D here so tails for three is its compatibility mode that would let you get through screwed out middle boxes there\u0027s like no point having that for DTLS 0.3 as far as anyone can tell so the spec kind of said you should use it and this Becker line where it says it really says don\u0027t use it so that\u0027s just like concretizing that okay so now to the actual technical matters such as they are on so TLS one three has this message called Hinch investors called a OED end of early data have you cut over between the early data fields and the and the clients second handshake flight said so in tell us what this tells you is now is the time when i\u0027m not sending any more early data and then the next thing you\u0027re gonna see is gonna be handshake and um so in TLS you need this to avoid a trial decryption because the state machine is like it was like a "
  },
  {
    "startTime": "00:12:32",
    "text": "block step state machine it also has the effect that it prints truncation attacks because because we\u0027re changing keys and your genes you can sequence numbers if you don\u0027t know when early date ends then the attacker can just pull a bunch of early data and have that go away and then you just think the early data did you get you basically got a slice cut out of the data between the early data and the one and then wonder who did it so none of these things applies to detail us DT loss is like a perfectly good like field that says like which keys things are encrypted ins you know what you\u0027re doing and because details has lost anyway the truncation attacks don\u0027t apply and it would just say well they apply in the sense that you can always mount them in the end that the Yui did not prevent them so however if you do heavy OED in the protocol this is a potential cause of blocking because you\u0027re gonna lose the OED and then like you could be processing data but you can\u0027t now and um so like this is irritating and when quick did the tail Centauri binding we just removed you IDI from for the whole thing and this leg gave everybody like a little bit of angst but like nobody could figure out a real problem with it we thought about it pretty hard um so um months Rosalyn here is the same thing here which is basically just strikeout eud this is done in PR number 62 which has a part this is effort even though there\u0027s not one here and one thing note is this affects the Trangia transcript so because Ely DS presidentially transcript this affects the transcript but that really shouldn\u0027t be a problem anyway my famous last words I know we\u0027re gonna attempt to convince you know Karthik or someone to analyze this for us but it\u0027s this pretty straightforward this was on this was not controversial quick it might be controversial here I\u0027m gonna wait a second or two okay I\u0027m gonna merge this BR yes the second change I made is the connection ID mechanisms in in detail us at the present version of the specification have essentially one CID at a time so when the set and the receiver issues you see IDs you can send you one and when the sender asked for a CID he asked for one and this is this is tend to be workable but as a few annoying properties in particular because one because when you uh when you send a connection ID one of the things you say is should you wash out every other connection ID you already had and so if I want to if I want to basically send you if I want to say if so say the way I got things structured is I\u0027ve got a bunch of about just a bunch of receiver state whose job it is to remember election IDs and I want to issue a new I want to blow away that state machine you see IDs right so what I do right now is I have to say here is one new connection ID forget everything else also here new ones one at a time right and so those get reordered then it\u0027s like I\u0027ll pay in the after process so uh if you basically just maybe just take each of those fields that\u0027s like one and make it n then this problem goes away because then you can basically say here eight new ones for Galilee or once so "
  },
  {
    "startTime": "00:15:33",
    "text": "there\u0027s a conversation Erik Kinnear and I had and this is quite a substantial simplification on the so the changes I made are the new connection ID has an arbitrary number cid I was not to manage the same um the request connection ideas account that says how many more you want and the other thing I did was you can only have one of these each of one you only have one of each type in the flight from you at a time so that then you don\u0027t to worry about reordering each other so that makes things a lot easier there\u0027s um you know there probably is are some edge cases like where you can be like connection ID starved um you know even in quick we didn\u0027t really like we\u0027re sore like someone has to go write a camera prove to ourselves you can\u0027t starve yourself but they seem pretty edgy and um most of the migration which was pathetic so um this is my plan here I have a PR for it so not seeing anybody standing up I plan to merge this as well so these are the only remaining issues my plan is to merge it not seeing anybody complaining other things my plan is to merge these issues issue a new draft and afterward new boss call so will that include a pause to get Karthik or cast or somebody to give a thumbs up on the removal bit I think we should ask them for that but I think we shouldn\u0027t wait for what\u0027s called okay um other thing is I\u0027d like to see I\u0027d like to see a deal with implementation which we plan to do very soon so so I think I like I mean if you if you prefer your your the chairs but I no longer plan to work on this document I plan to start a charter plane yet so if you want if you want to do working across call and then pause or close in your nose call I don\u0027t care I would prefer to do the work you last call now and Oh show it off is it more time yep so basically when you spin it the next version when we see it we\u0027ll take it and start the process yeah some not until so this gonna take us a little while to implement the latest set of changes and get them deployed and and all that business but we\u0027re committed to doing that so in that time we hope to be able to convince someone to give us a bit a bit of analysis time yeah thank you next we\u0027re doing deprecating deprecating okay so about three slides yeah this is draft I guess we talked about last time about that ethylenes I\u0027m here till tomorrow but she will be here then come talk the Corvette Hey so there\u0027s only a few issues with this really in terms of the texts so basically I think a tricky issue is going to be which does this updater obsolete for the hell that\u0027s probably making a long list there\u0027s will "
  },
  {
    "startTime": "00:18:33",
    "text": "issue is the it\u0027s it\u0027s changing something in a BCP so it does look it compared to that PCP I\u0027m guessing this is all kind of boring so we can just kind of work there with two tears and the ABS and the ISP will mind about it later so yes absolutely most people will not care about any of this right and there\u0027s some text in there about perhaps current measurements and the question is a freshman we leave that a nerd just to leave before co-star see alright if anybody has an opinion just stated I don\u0027t really care too much yes I\u0027m told so no there\u0027s a lot of documentation in the draft motivating its existence and some of that is is quite so within the sense of you know outdated algorithms and all sorts of other things but the the measurement related stuff I don\u0027t think really has much much place in the sort of permanent record that we\u0027re looking to create here so yeah I\u0027d be happier with it coming out it\u0027s pretty convincing but I think it\u0027s good without it and also fewer words yeah Erica scroll up the less the better sure okay I\u0027m just gonna stand here because I have an opinion about this next thing okay nobody come to accept that\u0027s what they do and then it\u0027s then there\u0027s the third issue is this sex nice and just don\u0027t you shall one of the signature hatch so again this was a this could be something that should be yeah you could argue this should be done separately so argue yeah I think it should be separate I mean I don\u0027t reject it but the thing but like things should do things she\u0027d do it says in the ten it says hinders deprecating one over one yeah if Hubert suggested that the EP came as a PR so he said to do it in and then ask the working group from stopping so unless there\u0027s some other reason to do this here we take it out I don\u0027t know if this somewhere in some other place to do you guys can think about that so those are the only kind of stuff text II kind of issues really but then I guess the bigger issue is render progress it\u0027s and again there are steams chairs will tell us the answer or whether they think the answer is so basically I guess the quaint the real kind of question seems to be is the mail infrastructure sufficiently different to the web to want to do this at different times or not and I think myself and Kathleen think going ahead is probably fine but the numbers are have a difference so if people have opinions on that I guess now is the time I do want to wait until you do working with basketball or something John\u0027s vaguely taking is everything it\u0027s a lot until tonight I\u0027d be happier seeing this published relatively soon now you might have noticed that work from at least some of us have taken steps in this direction already in terms of deployment so it would be good for us to have something more concrete if they would have published sometime before the start of next year that would be also good maybe the year after even I mean I\u0027m not I\u0027m only huge rush but I don\u0027t "
  },
  {
    "startTime": "00:21:35",
    "text": "see any reason to hold this it\u0027s talkative on yeah benkei duck no hats just it seems like the question of whether or not something is bad is completely orthogonal from whether or not people are currently using it yes yeah air patroller um yeah I mean I think that like that\u0027s I think that part of motivation for moving the measurement is that like the ideas position is this stuff is no longer like current standards and you should stop using it and you stopped eating it at whatever pace is practically to stop using it and maybe you have a situation where it\u0027s impractical and I never take a longer but like as brightly you weights or a pin you should stop okay the input that\u0027s there was pretty clear we\u0027ll make those changes and you guys like to ask oh yeah okay no time like the present scream no okay so we\u0027re gonna be chatting a little bit here but encrypted s and I this was dropped that was proposed and and we\u0027ve had version zero version one version two published these early versions have been deployed for testing situations with the CloudFlare so all buckler\u0027s customers have yes and I support as well as Firefox nightly has implemented a compatible version about this that this was not without its pitfalls as I guess we\u0027ll discuss later and there was also a lot of discussion on the list I had an you slide but I was too late to get it to the to the chairs but um the general overview of encrypted S\u0026I for for those nothing following is that there is a key published in dns called es and i it was in the original graph in the card draft a text record with prefix and this content contains a structure with the public key and when a client is meant to connect to that server that has ES and I enabled rather than sending an SN I extension it sends a encrypted SN I extension and the content of that extension contains a reference to the key that was used and the the key in DNS "
  },
  {
    "startTime": "00:24:37",
    "text": "is a diffie-hellman key this is combined with a client-side diffie-hellman key to create an encryption key for the SN i volume and the public key for this encryption is sent along with the club with the the client alone so this has some features in it to prevent it from being replayed and the goal is for SII to no longer be clear text on the wire and so forth I was following along there were some some changes from the original proposal and the original proposal the diffie-hellman key share that was used to encrypt yeah the s and I value was also the one used in the TLS handshake this has been separated there\u0027s now a separate key for yes and I and this this was meant to protect from essentially DNS being able to dictate with which diffie-hellman share was being is going to be used for the connection there was also a few additional features added for replay protection this is a nonce as well as the AE ad for the the key share an ad aid the additional data in the aad for the encrypted S\u0026I value covers the key share in the client hello and this this is prevents prevents rate but there\u0027s a version at it as well for future compatibility not many changes so there are some pending changes being discussed that the main one was the use of a specific RR type for es and I rather than a text record this does simplify some situations you no longer have to have a underscore ES and I\u0027ll able to obtain the sni key this simplifies cname setups it also makes it easier to deploy new types if managed without users and there\u0027s a couple opinions about our being more correct use of dns yeah question Edward Dean semantics so I have a statement a question in a follow-up so several middle boxes that do TLS inspection depend on the s and I in order to make a policy decision about whether or not to do a decrypt on that session and with this proposal that\u0027s gonna break the metal boxes ability to do that at Montreal we had talked about okay if the middle box wants to participate it can potentially if it has access to the DNS it can censor out the es ni txt rector basically disabling yes and I totally for the session I\u0027d like to make a different proposal for that one where we can still have yes and I working but haven\u0027t worked with both the middle box and the ability to communicate with the fronting server and the proposal is to basically allow if a "
  },
  {
    "startTime": "00:27:37",
    "text": "middle box can inject something into the DNS record have it inject a vector of ES and I keys where you can have an en si en si key for the fronting server as well as similar keys for the middle box or possibly middle boxes that may be in the path and have a requirement beyond the client that if it detects that there\u0027s multiple like a vector of es nike\u0027s it actually encrypts the s and I in multiple headers multiple extensions such that if a middle box gets the client hello with an encrypted value inside of it it can actually decrypt its portion of that to determine what the s and is make a policy decision and if chooses not to do the SSL inspections or the TLS inspection it can just pass through the remainder of the stream untouched and there\u0027s nothing that would break and if it does and it can proceed to do the the termination of the TLS and do its inspection at that point this has a couple of benefits it makes it a bit more transparent that there\u0027s a middle box there so the client now knows that there\u0027s a potential middle box that wants to participate in the TL cells in the TLS session the fronting server may also get some visibility to this as well because the client hello would actually indicate that ivan ivan cryptid my SNI for you but I\u0027ve also encrypted it for another party in this session so we don\u0027t have to disable the encryption of S\u0026I when there\u0027s a sanctioned middle box in the way that wants to potentially do TLS inspection so that\u0027s my proposal it\u0027s a very clarifying question I didn\u0027t hear anything and what you just said that had anything to do with switching from a txt to RR type what did I miss it\u0027s not related to that at all this is a brand-new proposal you\u0027re just throwing it in at this point because it was a handy as a response Li the ability to use multiple sni keys is something that potentially has other applications it hasn\u0027t been discussed on the list them Lorenz clearly what are the implications for anyone who wanted to sign that DNS record though right so you\u0027re basically moving the problem where you want to do intercepted at the s and I layer two now you have to like you\u0027re basically like running away from the security train that\u0027s gonna hit you and it\u0027s like well okay the first line of defense is encrypted s and I okay well we\u0027ll monkey around with DNS because DNS SEC isn\u0027t all out yet but so basically we\u0027re just moving the problem down to see DNS so that proposal would have essentially it would mandate inability to do DNS SEC which kind of means you basically because the NSX is a decision of the of the sort of person owning the domain you "
  },
  {
    "startTime": "00:30:37",
    "text": "basically disable it for the clients for every hostname so that\u0027s kind of a very different impact and I guess you just just blocking this right I mean I\u0027m not enthusiastic the result but given that the premises proposal is it the that these guys are just playing a trust anchor on your client the fact that they\u0027re gonna be a DNS SEC does not seem like the simply serious part of the problem on the I I guess I don\u0027t think this is the right place to do this it might be the case that one would want to have some mechanism for clients might never not be the case they find seconds of clients to exfiltrate to the little box what the yes and I was but I think trying to take a mechanism which is endemic hasn\u0027t been blaring and the middle mechanism at the same time it\u0027s like not like the right place to manage that and again I\u0027m not not taking a position that is a good idea to in the first place yeah my only response to that would be TLS is designed to be a point-to-point protocol but in practicing use and enterprise it\u0027s not there are multiple parties in the system and we have to work around the way TLS was designed and effectively hide the fact that we\u0027re doing inspection whereas here we have the opportunity to do it quote-unquote the right way and in a more transparent way so that we\u0027re actually recognizing the fact that some enterprises want to have the ability to participate in this and if we design the protocol to allow that it\u0027s a step in I think it\u0027s a step in the right direction rather than trying to hack around the protocols to accomplish something that there\u0027s a real-world need for authority I tend to support a KERS point that this is probably not the right place to do this partly for the the reasons that Lorenzo already put forward but also because it now creates a dependency that you\u0027re kind of getting your DNS from the right server because the chances that the public server that that\u0027s able to look at this are r-type from from beyond your enterprise has this available is very small which means that if you have a doe server or some configured server that\u0027s not using the local enterprise server now the enterprise is both going to have to block access to that in order to force you onto some locally configured server that has this additional RR type record in order to do that as well as block any DNS SEC validation you might have done as a client in order to trust the DNS SEC validation that\u0027s being done servers so I think that the the analogy Lorenzo said was you\u0027ve moved the stop you\u0027ve moved one stop down the set of train stations but the train is still coming for you the the side effects of this seem bad enough that starting with this design in order to accomplish the exfiltration is probably not the right way to do it "
  },
  {
    "startTime": "00:33:37",
    "text": "rich Saul\u0027s Akamai i1 advantages gets you is if you have things that are out of sync such that you know origin or gateway servers that are tightly synced to DNS and TTL or they\u0027ve lagged behind then you can put new and old keys in the AES and I record and then things won\u0027t break yeah I think it\u0027s worth differentiating between the motivation and the definition of what this proposal is I\u0027m Jonathan Holland I might have missed something where is there some obvious mechanism that you know that the es and I the multiple encrypted all points at the same place so you just send one thing that you know won\u0027t be expected to the middle box and connects wherever you wanted anyway I regarding I having a separate key for is in a photo a middle box to show well my point would be that server name server selection is a our it\u0027s a client and service role so the sailors so clients first signals what the service wants to send to the collector and then the server is in response tells you to which service actually being collected by using the search get message so either I give just looking for it and I see technically well it\u0027s not ideal so if you want to look to determine to which some of you actually quite thing to so I think what you should shoot for is to get access to the such get message that after it gives you to which server the kind have connected to learns are clearly again surfer maybe sort of red holing discussion but I I wanted to ask forget the name the gentleman from Symantec what was was there any thought to basically like allowing at filtration only this essentially on device as opposed to on network because a device that\u0027s an enterprise zone device may have different security zones where if you do this the enterprise that man has you know all the keys to the kingdom if you do that you\u0027re running this other at this other work profile whatever then it doesn\u0027t and so I think if the if the filtration was done on the device and then maybe assuming that there\u0027s a root cert on the device or something then that would sort of allow for differential privacy implications in these contexts and I wonder if there\u0027s something which makes it hard because the proposal was basically doing this in the network in the middle box but I think all of these devices these days they have enterprise management algorithms that you know and and and modes that we could use so I wonder if there\u0027s something that\u0027s inherently hard about doing it that way as opposed to this way it not this way the way that was proposed and I don\u0027t see anyone coming are they are no I think the assumption was in writing this drafts that the end the enterprise mode of the "
  },
  {
    "startTime": "00:36:41",
    "text": "of the client could potentially kick in and yes and I would be disabled but you don\u0027t even want that right because you you want to spy on your users but you don\u0027t want the internet to spy on your users right so see suit as an enterprise admin you want to basically see everything that they\u0027re doing presumably assuming the law allows you to do that but you don\u0027t want the internet to see what they\u0027re doing right so yeah it\u0027s so I wonder if like a wonderful way out of this conundrum is to say look this is how it\u0027s gonna work and if you have the ability to push a root client a root cert on the device or if you have the ability to run code on the device then this is how you do it and then all that of all the implementations could do this or not if they didn\u0027t want to sell to enterprise markets and then we have a solution right so it is the proposal potentially installing an additional es and Ikey locally and then encrypting your sni to both the one discovered through the network as well as the one that was installed locally I I don\u0027t pretend to understand the complications I\u0027m afraid it\u0027s just trying to understand the user visible behavior which is why I just asked could it be done in another way you could I apologize for hijacking most your time just to respond to the one question why can\u0027t you just always do it in the end point for most enterprises they want to run the situation where you don\u0027t trust the endpoint you don\u0027t trust the network so you want to have a layered security model where you can do exploration in multiple places so that you\u0027ve got yourself covered so that\u0027s why the desire to doing the network exists student power could we talk about encrypted SMI instead yep let\u0027s move forward so with encrypted s and I there are two major operational issues that were raised in both the deployment and in questions about clients deciding not to deploy the draft as currently built the first is the potential for a heart failure if the dns and the server get out of sync and then the other one that was raised on the list was the multi CDM case so I\u0027m not going to propose solutions for these a for the first one I\u0027ll sort of hint at some potential ideas for getting around it but I want to raise I guess the problem statements around these are potential operational issues first the heart failure so your risk is your DNS caches your yes and I longer than your server keeps it around and this is this is a bigger risk if you\u0027re doing fast rotations of keys and you want to have forward secrecy around this so you want to delete the keys pretty quickly also if you if the organization has if there\u0027s two different organizations that manage DNS and they choose yes and somehow they get out of sync these things happen it\u0027s not common but it\u0027s it is a it is a risk because yes and is currently defined the way that clients "
  },
  {
    "startTime": "00:39:41",
    "text": "would deploy it is to not have a fallback so if the key has a mismatch this would be a vector for the for an attacker to force the client to reveal the SNI that it\u0027s going to so the impact of this is is unavailability you as a client you\u0027d not be able to see the site so there\u0027s a possible idea for solution which is to distribute the ESN Aiki through TLS through the connection one idea around this is typically if you connect to a site there are servers that are able to handle requests that do not have sni and therefore having a default certificate installed you could potentially imagine a scenario where the server has a default certificate for no sni and then another default certificate for an es and i that can\u0027t be decrypted you could indicate in the SMI record that if you see the default certificate this is a trusted channel for updating ESI so you would make a request the server does not know how to decrypt B ES and I the encrypted s and I extension instead it replies back with an es ni ki and this handshake is signed by a certificate that covers the say distinguished hostname for that es ni key and then you would terminate the connection and you\u0027d resume with another TLS connection using the new es and Ikey so this this is this is a case that should be rare because miss configure and this miss configuration in this manner should be rare but there are definitely issues with caching in DNS vs. and you know transitioning from one key to another and we ran into situations that I mirror this and our in our initial deployment clarification question let\u0027s say that you wanted to implement this where they resolve our library with an HTTP library or with that sort of HTTP quick whatever transport layer library you would need a sort of richer communication mechanism between those two than just here\u0027s an acai record and and here\u0027s the key right you\u0027d have to also return the host name as well but is that all it takes or is it sort of visit like complicate the interaction between these components more I think the proposal is that in the ES and I record you put in DNS you whoever is configuring that knows what the default hostname would be and just just looks it as an entry puts it into that structure so I mean all these the existing stacks that I\u0027ve seen that the NS s1 and Pico TLS one you just you just give the stack a giant whatever the heck "
  },
  {
    "startTime": "00:42:41",
    "text": "appeared in DNS is one giant monolithic blob I think that um the difficulty here is gonna be that this is gonna manifest manifest itself as a as a connection depends afghans implemented it\u0027s gonna manifest adele is a very funny connection state where it\u0027s like i\u0027ve connected but like this all along hum and so you\u0027re gonna need some way to basically say basically that the bypass whole sort validation logic and say like listen you connected on but like this is not really a connection and like if you make this api call the other api call huh well you do serve validation but it gets a different search because you because the connection is not live right and so it\u0027s like listen this connection don\u0027t try to write in here international for God\u0027s sake but like you know but on but but like if you call this other API key API call you\u0027ll get the yes and I blob which you\u0027re good back to me then like a begin new connection and that\u0027ll work good so I think you lenses right it would be it would complicate the API substantially I mean while saying it\u0027s unfixable but it wouldn\u0027t be like totally straight for and the condemned the fear I would have would be making sure at this does not ever put you in a position where you\u0027re the this first this suicide connection that doesn\u0027t it doesn\u0027t it doesn\u0027t work properly is writable and you\u0027re sending data down the essentially the wrong pipe the because it\u0027s not like um that that\u0027s not a because that really I mean that is not a secure relationship right I mean that is like like you\u0027ve got me you have a secure connection to someone just mean you can\u0027t actually trust and so you and so it\u0027s absolutely unsafe to ever write any data down that Oh an or any conditions yeah this is this is just an initial proposal and it\u0027s definitely not perfect you could potentially imagine restructuring this in terms of not two handshakes but an extension of the first handshake but again that would really complicate what TLS looks like civil diner um so this also assumes that the fallback hostname does not change as well and so that\u0027s right and so or changes slower than the yes and IKEA it\u0027s a point and also like you could get into other situations by this fallback connection is used as a look sorry this suicide connection is ekor called it is used for the other requests for example if the fallback hostname certificate actually does contain a valid host name of the yeah or a star dot or something then you what is the policy that the clients should you should still terminate the connection or should it use the that for coalescing the domains yeah good point steamboat so I think I\u0027m kind of confused as to what this fallback hostname actually is but that\u0027s probably okay because it\u0027s like not written down yet and so it\u0027s not a just declare it\u0027s "
  },
  {
    "startTime": "00:45:43",
    "text": "not a kind of name for the fronting server or for the back end it\u0027s just a third name entirely it would be a third name entirely you could imagine someone creates sort of a random string sub domain and okay what\u0027s an int yes so I think more generally I mean I think the the point of previous slides I think there isn\u0027t that I think it\u0027s probably fair to say that the the current proposal and maybe this is friendly towards TLS developers I don\u0027t know if it\u0027s friendly towards TNS operators and because I think like you know having it been up before not after in the es Mikey\u0027s seems to me to be a bit odd it seems to create new corner cases when you compare with other kind of TTI\u0027s and our RC kind of eligibility periods and so on and so I guess I\u0027m just I would ask that at some point we try and make sure that what we\u0027re proposing to put in dns is something that people would like to put in DNS more generally than just the initial two people deploying yeah but okay thanks turban parents committee so my first instinct is is this is a configuration error right in theory or is it not a configure it is a configuration error it\u0027s one in which because of privacy considerations there is no fallback yeah it\u0027s very damaging configuration error how like how much do we think it would hurt adoption of this proposal if we basically declared it to be a configuration error I mean you can create other configuration errors like hand out the wrong ap v4 address in your DNS and yeah the site\u0027s also unavailable in that way so if you like you know have we you know have we tried to say look yeah we could say this is a configuration error don\u0027t do this cuz it\u0027s really dangerous and my sense is that some points would not deploy at this risk does that matter is it like critical to the adoption or is it like yeah some people won\u0027t do it and they\u0027ll do it later I I can\u0027t speak for the organization\u0027s I don\u0027t think they have representative here yeah rich Sol\u0027s Akamai yeah we would have a real hard time the we want to deploy some kind of encrypted S\u0026I we would have a real hard time deploying something that had this kind of failure case because people who want yes and I really want that privacy guaranteeing and if all of a sudden we all and we\u0027re running the DNS server and we it\u0027s not it\u0027s not just a configure our you know networks break apart they there\u0027s all sorts of things that can go wrong but even if your configuration is correct you can still get inconsistent results of these kinds of things you really need an atomic fetch which is why you know the proposal the new record type it seems the NS folks are waking up to the fact that parsing text records with "
  },
  {
    "startTime": "00:48:44",
    "text": "the reg apps doesn\u0027t work and so new record types are amenable and yeah any work on this would have to involve the you know DNS folks and I know that\u0027s the intent to Ted Hardy pretending to be a DNS vote for just a moment that they actually been recommending using newer types for quite a while now so really not their fault there there been deployment issues that have made other people recommend that you do not do it but from the from though what what is the one true way you are are types if in the one true way for a good long time but I actually wanted to kind of go back to a question that I think both Stephen and in chat maybe Martin we\u0027re getting act which is can you end up in this situation in in essence because of a clock skew problem where the you you have something where you think this is fresh data it\u0027s not fresh data and they\u0027re out of sync because the the DNS client doesn\u0027t know that it ought to be getting it\u0027s time for a new fresh fetch right and there\u0027s a question in my mind about this and the way that the document is currently and I assume in the new one describing how long the records would be valid for because if you\u0027re actually trying to define that using the the DNS primitives for how long the record itself is is valid for then allowing somebody to order the records by a validity isn\u0027t possible right now you basically say any of these records can be used that they\u0027re all valid if there\u0027s multiple ones of these records they\u0027re all valid you could actually cause the structure of what you include in the record to include validity dates or or other timing information that would allow you to tell that the two different ones you got are actually meant to be use sequentially oh sorry does have that and I just missed I\u0027m sorry okay was the sawing window then I just missed it in the draft my lord John colonics so I was I misunderstood the suicide connection thing in a way that I think might work better which is why can\u0027t you just restart the TLS handshake from scratch over the same connection after you\u0027ve gone through this dance which could then hide all this complexity within the TLS that could hide all this complexity from the from the application or the transport layer I mean obviously it\u0027s going to cost you two round-trips but in the in this weird configuration error state I think costing a few round trips rather than a heart failure is definitely a bin Oh ekor said he didn\u0027t think any stack you thought we were going to do that I mean just start from scratch as treated as a new handshake would be probably my understanding is that you all you might already have something in the pipeline for this connection and doing the "
  },
  {
    "startTime": "00:51:45",
    "text": "connection management and is tricky also quick but wait good we are with the TLS doc did a goofy position respected the okay we got about two minutes and thirty seconds left for this okay well my good thing I have no proposal for the next problem yeah so the next problem is the the multi CDN case this is how a lot of sites are configured such that well I guess there\u0027s two main to main configurations there\u0027s either on the apex or on a sub-domain on an apex you can have it configured so that depending on who\u0027s requesting or the location or the time you could have your the authoritative DNS provider return estate of a records corresponding to one provider or another provider and these providers are likely not going to be sharing es ni keys and you have the option it\u0027s ten there\u0027s potentially a situation where one provides the pro one provider does not know about the other provider or one provider supports the sni and one does not so the question is if you do obtain these two queries would be you query a a a sorry a or quad a well and then you also could query for yes and I record and they could end up pointing you to different providers there\u0027s no nothing atomic connecting these two requests together so getting out of sync would result in encrypting sni to the wrong providers key or to a provider that\u0027s not have yes and I enabled and as another case for this this is I guess more common is if you have a sub-domain such as dub dub dub you can do load balancing BSC names so you would send a seat C name to one provider C name to another provider and these would also be sort of alternating and based on various load balanced load balancing policies and so in either of these cases the current draft does not have a solution it does result in connections failing and unlike the previous slide in this situation there\u0027s no way to do a default hostname and recover because you\u0027re you\u0027re explicitly getting a different es and I record from a completely different provider so this is this is an open question and one that seems like a very difficult design space to work in Lorenza T is this is this is because the SMI key is actually a property of the destination IP and none of the hostname right that\u0027s right and we have not thought of like putting it in a door or something okay yuku doesn\u0027t like it nobody okay sounds good okay so I wanted to raise this as as an open area for for I guess design considerations for this and and from the folks who are interested in "
  },
  {
    "startTime": "00:54:45",
    "text": "implementing this this is a very big blocker and it\u0027s it\u0027s one in that would stop the deployment of yes and I in a lot of situations okay so requirements for a solution you want to prefer soft failures too hard failures these are also open up for debate no serialization of DNS queries is another potential requirement for this if you have to do two DNS queries in sequence it\u0027s not desirable compared to right now or you can query them both simultaneously this needs to work in a majority of deployment scenarios and we prefer fewer changes to authoritative servers in finding a solution here this is dkg from they show you I just want to play out your top two bullets seem to be a little bit in conflict and I think you\u0027d be better if you rephrase the second one is in the in the so the as that point the slides are changing yeah this one yes this one Thanks yeah in the normal case no serialization of DNS queries but the SoftLayer could well be a serialization of DNS queries in order to to resolve it right you don\u0027t want to rule out serialize DNS queries as a way to deal with the soft failure yes I guess I\u0027m okay I guess yeah you don\u0027t want the cereal super serialization in the general case actually you don\u0027t have any time for questions I\u0027m sorry we\u0027re already way over unless you can make it very very brief I\u0027m sure yes just a question about the dependency on the backend server so notice there\u0027s a remark in the current draft which says that the backend server can be unmodified but with the introduction of the nonce has to be sent back yeah so that\u0027s a so I I guess I just want to clarify that the draft needs to be clear on the dependencies on the back-end server imports yes that\u0027s about yeah yeah to be fixed all right thank you they stick all right so the next item on the agenda is the proposed charter text a couple of weeks ago we sent around an initial proposal we thought now that we have 1.3 finalized be good to sort of address what remains with respect to you know holes in the TLS ecosystem and to finish up existing work that\u0027s are even started so there are three main items listed here the first of which is to finish up DTLS 1.3 and everything that entails the second of which is to sort of it add mechanisms to sort of improve the usability deployability extensibility etc of TLS and related protocols and the "
  },
  {
    "startTime": "00:57:45",
    "text": "third of which is to sort of recommend deprecating removing getting rid of old bad things as time progresses so hopefully we can use this time to sort of talk about the texas proposed to change things identify issues with what\u0027s written and so on so martin you know so I realized the rule of threes is quite nice and you\u0027ve done that very well here three bullet points three actual points but the first one given the discussion that we had earlier in this session might have already happened and so I I suspect that we\u0027re gonna find that this Charter is no good by the time it gets approved and published if that first item is in there so maybe we can take the detail s1 out and just concentrate on the other things most likely yeah so I was gonna pour something different which was just to sit on this for a couple months and then I mean feel free to write any juror details in it but then we can and then sit on it until until we call the call us and then we can return her value my pros I mean that there\u0027s an ad right here so we can ask him what he thinks but it\u0027s kind of a I find return you kind of pain and I\u0027m constantly screwing it up so uh-huh you know I would hold off of that but yeah so I guess the point there would be that the current Charter covers tell us 1/3 and we can just say well tell us 1/3 obviously means DTLS 1/3 and carry on and then we\u0027ll deal with deal with the other stuff when when that gets done there\u0027s only months it\u0027s not like it\u0027s gonna be forever I think yeah but that\u0027s perfectly fine as well I guess we\u0027re interested to know if the remaining issues you know putting details aside are of interest to the working group should be in scope should not be we don\u0027t have to necessarily do the recharging right now we can of course wait for details 1 3 be finalized but sort of identifying what are the next big things we should be working on I think is a useful exercise I\u0027m Stephen well yeah I mean I think maybe leaving this for few months might make some sense just to get simplify that the change I don\u0027t have a proposal for how to do it but if you guys are clever enough to figure out some text to say what we don\u0027t want to do that would be very useful because as we\u0027ve seen against there every time you try and do something there\u0027s somebody who wants to do kind of the opposite I would encourage you to try and think if there\u0027s any way you can kind of say that you know here\u0027s what we want to do and here\u0027s a characterization of the things we don\u0027t want to ya know didn\u0027t find your children just uh one word that I\u0027m not seeing in this second working group goal is security it\u0027s I mean it\u0027s part of the security area but if you\u0027re talking about proposals regarding say new threat models P Q etc could be worth explicitly saying that yeah that seems fair sort of "
  },
  {
    "startTime": "01:00:46",
    "text": "a follow-up questions that do you think items such as PQ should be considered when we do actually conduct the reach are during exercise I think the next presentation well is is gonna be in that vein right yes does anyone have any other comments criticisms etc on the existing text if not we can move on and you know we\u0027ll discuss when we want to actually do the retiring like I said we\u0027re perfectly fine to sort of table is for a while while details one three four one three is finalized there\u0027s no rush but just sort of getting a feel for what the next big things are to work on what\u0027s the what\u0027s the point here so yeah perfect all right so Russ flew so I\u0027ve talked about this a couple times and then we had a call for adoption then it did not succeed so I want to go through a little bit of history in Montreal no one objected to the base case that was in the document but two cases were discussed that people wanted to include in addition to that base case one of them was to provide some proof that the server still had access to the private key that was in the certificate and the second one was on resumption to provide a different certificate yet to avoid the conflict that if there\u0027s early data and you\u0027re doing resumption if you were to change certificates at that point you wouldn\u0027t know if the early data belong with the old certificate or the new certificate so don\u0027t allow that so I added those two cases in into the document and then there was a complaint that well now we\u0027ve gone too far it\u0027s got too much complexity so the question is that I\u0027m hoping this presentation will answer is where does the group want to go from here so just as a bit of providing you enough context to answer the questions that are coming this is the handshake where there it\u0027s for the initial handshake where you\u0027re including a nish a pointer to an external PSK to be mixed into the key schedule this slide has not changed as the last presentation than the case where resumption and "
  },
  {
    "startTime": "01:03:46",
    "text": "you\u0027re proving that you still have the key that is in the certificate or the private key that corresponds to the scheme the certificate what is this one and when you are changing it you can\u0027t have early data and that\u0027s what leads to this case so I have three questions I would like to have the chairs ask the group and there are these three homes so I don\u0027t know which of the chairs I\u0027m handing it over to at this point right so we talked about this he said in Montreal if there was a couple objections that have since been clarified so been or ecker I didn\u0027t know if you were like any other sucker yeah I mean I get I guess um I want to take the tip before we do any other stuff on it the amateur on like how much enthusiasm there\u0027s for this document as opposed to how much not objection those for this document so um particular I like to see other to ask if people actually intend to employ this so you want a hum zero and the front of this more or less yeah okay I mean our people come to the microphone this is I\u0027m not sure I don\u0027t like this but it\u0027s not on my limitations real map and I wonder presenting on anybody else\u0027s because I think I guess like this isn\u0027t about this particular just be clearly so at this particular document but I feel like it\u0027s working around a lot of trouble over the years by like by like taking just things that people didn\u0027t have got to and so I want to take things well any people enthusiastic about if you\u0027ve got a positive home for all three of these are we still may need it does that mean that people still can later on decide they don\u0027t like the document overall and don\u0027t want to adopt it so is it is it a are you asking that for an answer of the form if if the working group were to do this I would like one two and three but I you actually don\u0027t want the work me to do it I\u0027m not saying that\u0027s my position I\u0027m just this is the clarifying question I don\u0027t know I don\u0027t understand you I think these homes asking for it say implicitly asking for working group adoption if you had a document that had the outcome of the hums and put forward for adoption I would hope that you would get a consistent answer but obviously the group changes over time but such as over time because if somebody has an answer for home one mm-hmm they that doesn\u0027t mean they want to adopt the document this with its you know position X 4 1 \u0026 y 4 2 and Z 2 3 right that\u0027s correct thank you you\u0027re just touching on the you who\u0027s gonna implement question that doesn\u0027t have to be a hum they could be like show hands so let\u0027s just do that "
  },
  {
    "startTime": "01:06:48",
    "text": "can we have a show of hands of people who would who have read the document okay it\u0027s pretty good number say 20 or so people that are planning to comment on the document I fix going forward all right less but some who\u0027s planning to implement the document one minute when I saw a few more three more so yeah so there\u0027s a couple that\u0027s the stretch in the back there so it\u0027s a couple couple no it\u0027s not no it\u0027s certainly not overwhelming but it\u0027s a rich sauce yeah but you know it\u0027s open source and we take full requests and if this is meet somebody\u0027s real need then it could show up they don\u0027t have to mean that I\u0027m gonna write the code or they\u0027ve been you know would write the code so it\u0027s not quite a fair question I mean I understand yes it\u0027s good but I don\u0027t think the lack of answers you got are definitive again what I\u0027m trying to get at is do people in this working group think this is like a positively good idea or is it just like the Russ is like in the front of the room we like Russ and like this is like a doesn\u0027t seem like terrible I\u0027m like you know me you know like appealing is a positive good idea then you then of you\u0027re willing to implement their solicit someone\u0027s importation or hope somebody else it\u0027ll result them right and that\u0027s I mean I can imagine a bunch of questions but I guess what I\u0027m asking is for other people if the microphone who like this and say we think we should adopt this and we\u0027re in favor of it well for now I just trust Russ I mean so I I think there\u0027s a real need here it\u0027s just not a need that I have and you the people who have this need may not be the root nikka\u0027s disentangle himself I think so I mean I guess there is a real need here but it does I have a slight concern that maybe we\u0027re being a bit premature and trying to figure assume we know that this will solve the need so you know it may be that do after having this type of competition with new algorithms and so on maybe there\u0027s gonna be something that people would want to implement much more than this so I don\u0027t know I\u0027m not against this but I don\u0027t I don\u0027t feel confident that this might be the thing that saves the day well I certainly don\u0027t see this as an alternative to what\u0027s going on with Vista competition it\u0027s it\u0027s more of a gap filler until those get sorted out and implemented and then we find out whether TLS 1 3 supports them more we need the VTL s14 etc yeah I like to sell implemented before I have a specific use case it\u0027s not the same as is the typical use case "
  },
  {
    "startTime": "01:09:48",
    "text": "but I think this is this is good to have signatures on external vs case especially so is there any way it\u0027s a violent objection if we adopted this in your yeah News case would be specific non-public PKI service to service not violent but I\u0027d like to propose that if we drop that we don\u0027t lose experimental a lot as the visitor they\u0027d be fine with me if we were voting ID pipe it against it but I\u0027m not gonna like wine from the road Tolson I was wondering whether I even got out for this one um but I\u0027m gonna say it anyway there I was originally sort of enthusiastic about the second point I\u0027m learning to sort of downscale my expectations with what it is that I can ship and so that one is no longer something that I think we we can we can do in the short term not opposed to it and still still think that any solution here has that has this property and that would be good this document came up in discussions related to the pipedraft that was going on at the moment as well there was a desire there to to use some combination of certificates and and the pake stuff so just wanted to blow your mind just a little bit and expand the scope even more but that\u0027s exactly what I was thinking right so yet definitely I think the experimental sounds like a reasonable way this done stop thinking about this way this is also not a concrete use case but what we were talking previously about yes and I there\u0027s a potential to use something like the second note to to distribute the SNI the specific situation not not sure yes so I think I think where I am on this is that I don\u0027t think right now people have the energy to properly analyze 2n3 and so so I think that I would not be in favor of taking two and three I would like to two and three at some point but I just I\u0027m like that sec how does it like how wiped out everybody is from like doing eighty four forty six and presumably would have a korean call one details Mosley um and so I think I would I was like I would hum like definitely against taking two and three if he want to take one is experimental I got to put it like a finer point in this writer like Russ wrote number one and I think Martin was like hey number two to be great and then Nick said hey I\u0027d like to number three to if Martin and and uh and Nick are willing to say yeah we can wait to do it later and let\u0027s that won\u0027t go through "
  },
  {
    "startTime": "01:12:48",
    "text": "his experimental and was a lawless hums that hum so so take one home so we really want to do one first and the other two like that there\u0027s not a pressing need for two and three so to say the same as I believe with Martin\u0027s but that was it was just be ashamed to build this machinery and not use it for these use cases all right so we\u0027re gonna we\u0027re gonna hum for a weather this document should exclude include external PS case with certificates for initial handshake so hum now if you think this document should be limited to just external PS case with certificates for initial handshake please some now if you do not so that\u0027s rough and we\u0027re gonna have it um go as experimental I can do that now please some now if you would like to adopt this draft please some now if you would not want to adopt just wrapped but there anyone that hum know would you like to get to the microphone to say why great next car hopefully these are the updated slides hello I represent you today the transport layer security extension to support I Triple E and it\u0027s a certificate with it on vehicular network so the agenda would be I will give some motivation and the objective our of our extension then an overview and also some use cases how and why we are using we need this extension finally I will give some details of how we made it under the raft so competitive intelligent transport system is high mobile environment we with with a limited bandwidth that\u0027s why x.509 certificate is not optimized for delay sensitive and limited bandwidth its application that\u0027s why your on C 80s and vehicular "
  },
  {
    "startTime": "01:15:51",
    "text": "environment we are not using x5 online and we switch it for I Triple E and HC certificate I Triple E is 1609 point to Eckstein 1609 point two and the 81 is one oh three oh nine seven and I have to mention here that the 81 is just the profile of the I Triple E that\u0027s why we intend to create to add work just one profile on on Terrace protocol so the objective is to make authentication to have this authentication method the more optimized and modern appropriated to the vehicular environment and to enable plant and server authentication in using CTS certificate some use cases we can use this extension for self or for uploading logs from vehicle to to server of log R to make updates of vehicular software r2 to make a date of configuration just the configuration of of software on embedded on the vehicle and it can be used also for connected cloud services connected and fun payment and it can be used for authentication between client and server server for example of the parent company for car manufacturers servers and wireless electric vehicle charging though so there is very an urgent need and say it is let\u0027s have board for this extension so we we proposed to add a new number for 1609 dot to certificate as a new certificate type and we define it is entry like what like we present here on the slide and here I give an example of handshake where the client is in its declaring that he can support 1609 to certificate and the server can send 1609 one x.509 online or a raw public key so the answer of the server is x.509 the default one and the client certificate type would be 1609 dot this which is compared to the last FC of TLS 1.3 so just just to add one "
  },
  {
    "startTime": "01:18:52",
    "text": "information about privacy privacy a consideration made by this kind of safety key in fact it\u0027s provide privacy relying to temporal and the locality and geographical and temporal validity criteria and minimizing the exchange of private data the F so if this this draft would be accepted we will ask enough for a new value for to register this certificate a still a certificate that new TLS certificates I\u0027d thank you can I show I see a show of hands of anyone who\u0027s read the draft all right that\u0027s cool I just honest um I was I was wondering why you conscious registered a value is there really to be established to register in such a way that requires an RFC for in this group specific lines so why why can\u0027t you just do that like it sounds like it\u0027s great you use TLS 1.3 in or DTLS monetary in a vehicular environment you use another certificate we defined one other things earlier like the raw public key looks like looks like very straightforward to me you mean introduced the I Triple Aim one on narrow public yes no no you apparently there\u0027s some work going on in the I Triple E on this con future star in your specification at the end like send a request to Ayane there will be an expert review and then with this new value being added to the registry I don\u0027t think there\u0027s any other there\u0027s a barrier on defining a new certificate that like you don\u0027t need a ITF document to do that my understand I have to make it as a draft and then I ask if it\u0027s accepted I will ask a value from a jana as you know because i I was working with raw public key some other guys here and I remember that at that time I didn\u0027t have to do anything it was just to be added some other extensions that why we had to add write an a draft for it why didn\u0027t later which later became an RFC but I think in your case since you only need this well he registered I don\u0027t think you need to do anything in the IDF besides writing sending a mail - Ayanna to add that today already sound I made - I think and he told me that I have to get you don\u0027t you just okay you just "
  },
  {
    "startTime": "01:21:55",
    "text": "have the if there\u0027s already a public specification available yeah that\u0027s it you just then we can request okay this is the part I tried to explain - it kind of changed under your feet since it started now you can send in the draft a pointer to an internet draft to say here\u0027s the thing and I would like this value assigned okay so you don\u0027t even need to go through the rest of the process or get us to adopt it you don\u0027t even need a draft um the thing that is interesting in this draft though is if we\u0027re good we\u0027re gonna progress I think that I probably takes some of the things out like there\u0027s uh the security considerations there\u0027s like a recommendation for a minimal profile that doesn\u0027t really kind of seem to fit in this draft I think that would be better in an IP wave document or somewhere else to specify that over there because this is like this is the steals extension thing you know if you use TLS uses this other stuff this other stuff just it doesn\u0027t kind of really seem to fit in that particular in this in this draft because you\u0027re just defining these this new particular certificate type yes I get again push it on IP wave group but still Paris extension so must be I think it should be discussed a year or no exam I my great disgust but the point I\u0027m saying is the ones that are already defined and you\u0027re saying when you when you do a connection you should only be using these extensions that I don\u0027t know that that even applies here and that in the document just doesn\u0027t make any sense to me it\u0027s a pro it\u0027s a profile essentially of how you would do it and I think that goes someplace else it doesn\u0027t belong in this particular extension document um the other thing is I think you would put a big ole warning in the security considerations to say hey look we define new certificate formats which also have new processing rules they are different than what is done in regular x.509 and Dragons be there they finally got fudged or fuzz enough to kind of work right and we kind of know the pitfalls at this point these are new I\u0027ve never looked at them I sure hope they work properly sometimes that was that was a new a new security consideration I think but I mean I think at the end of the day if you could clip out some of this stuff here if you send the request to the TLS reg email lists that I put up there earlier I think get a KO point probably by the end of the month yeah because we started I think it\u0027s a new process this what yeah okay thanks thank you yeah it\u0027s like two months old so this roughly my understanding is as long as you want it can live with a number that is being assigned that is 64 or greater you don\u0027t need to do anything more other than ask I am its if you want a small number yeah then you gotta go through and get a standards track RFC but but in the past it was not the case that\u0027s fine "
  },
  {
    "startTime": "01:24:55",
    "text": "you know that\u0027s the way I read the Rangers thank you thank you [Music] right so this is something we talked about right near the end of finalizing TLS 1.3 particular there\u0027s some oddities around external PSK and how you use them properly for this new version of the protocol so they were to basically design basic designs that were discussed in on the list one is from David been describing Universal vs case another one was his key import or idea the ekor and I had talked about so this is just kind of getting that down in writing and hopefully we can kind of make a decision as to which two we are fond of I guess you may want to address this particular issue going forward so just some pointer to the facts they\u0027re not four four six that says you know if you\u0027re going to use a PSK make sure you\u0027re gonna use it it must only be used with the single hash function in gos 1.3 and be wary if you\u0027re using the same PSK across 1.2 and 1.3 because we haven\u0027t really looked at that very closely and there be dragons but possibly so like I said we want to only use a single hash function our PSK with a single hash function entails 1.3 whereas ds-12 has no particular restriction and we want to make sure that if we are to use PS case that were provisioned for 1.2 or other versions the protocol it\u0027s safe to use and 1.3 and ideally do it in such a way that you don\u0027t have to tie details of TLS to the provisioning processes vs case you can kind of just reuse the machinery that\u0027s there and then sort of stuck them in Steel\u0027s 1.3 and use them as such so the analogy that I\u0027m kind of drawing out for the importer is exporters which as you may know you have some you know secret export or master secret inside the box you input some label and context and now you get as a key that\u0027s for the specific context with the drive using the specific label and this sort of diversify the PS whatever the your secret is using that particular information importers in contrasts are sort of a way to take an external PSK and diversify it by the supported hash functions that a particular tail 1.3 implementation happens to have so assume you have a PS k this provision out-of-band that has some external identity and you have some label you want to associate with during the import step and the label here is bound to you know a particular like a protocol in which you would import the the PS case so if you\u0027re using TLS 1.3 over tcp the "
  },
  {
    "startTime": "01:27:55",
    "text": "label might be TLS 1 3 using TLS 1.3 in the context of quakin might be quick so on and you have a particular like I said a particular hash algorithm that you want to use this particular PSK with you might the basic idea the importer is you form the identity of that PSK as the topo the top will affect the value of all these fields and you use that to derive a per hash function hash algorithm PSK but you would then use to compute binder values and send to the server and the client hello so finding out how many hash relatives you support in your particular stack you may have one or more actual PSK finder values that are sent in the client hello to the server seems pretty straightforward it was traded as such so you have some extra room external PSK associated hash algorithm you HDD f it with the identity with the label and the hash algorithm that you are using to split it up so if you support all if you support all versions of sha-2 you would have three binder values that are sent out the door for this particular PSK and if the it\u0027s important to note that the hash algorithm use for the HGVs operation here is that which is provision with the PSK not the one that you\u0027re using to diversify the PSK during the derivation steps that\u0027s not shot six 384 by twelve it most likely will just be shot 56 and if it\u0027s not specified in your provisioning process just you shot 256 and be done with it some constraints for this particular importer design or that if you\u0027re going to use it for early data SPECT clearly can indicates that you need to know information about the context in which you\u0027re going to use it so values for a LPN another quick transport parameters the draft right now is sort of just kind of hand wavy in that particular spec so you know we could certainly do some thing to improve it there is the issue that was raised on the list with respect to privacy in a privacy respected the labels that are being used but perhaps that was my own fault and not being clear and what the actual labels are so they were really intended to diversify importing PS case for different protocols be it quick or TS 1 3 or whatever you\u0027re going to use TLS 1 3 4 not as identities associate with external PS case the privacy issue with external PS case is still very much an issue that potential users are thuggin all through this whole problem and there\u0027s not really much specific details around how you would how these are sort of compatible with TLS 1.2 the TLDR is that you don\u0027t really do anything specific retail 1.2 there have been proposals have been discussed to potentially do some other do essentially import for TLS 1.2 using the label kill us 1.2 and use that as your PS k value probably fine but wasn\u0027t once something I was trying to do for the initial version in the draft yeah on this Chris if you go back to the previous slide so "
  },
  {
    "startTime": "01:30:55",
    "text": "you have this key derivation function for the PS k what about the PS k identity are you you keep that unchanged no it is the this particular structure so it\u0027s this entire value that said okay yeah so the server upon receiving you know an external identity and a hash algorithm they\u0027ll know which which PS gate to derive and they can verify finder with yeah because otherwise you would suddenly have you have a client that doesn\u0027t have that extension that you\u0027re proposing and then a server that has it and then but it\u0027s the same key identity issues that gets confusing yes would that go into the TLS stack or detail s stack or would that stay at the application layer when you say that what you mean that the implementation of your document of this inside the geo stack okay yes I mean clarify but that my understanding was that Maya implement the invitation that we put together was inside stack you would in importing PSK you be just be given an external identity a PSK associated with it and then the stack internally we do the transformation and dryable he escapes afterward oh I mean you could do that that was not mine but this design is specifically intended not to require that so you can do it I guess you can do it either way but like it\u0027s nice to just sort of have it imported the interface be simply have an identity so at the end of PSK value and the transformation happens the term that seems most intuitive to me that\u0027s a reasonable set of position but it is not mine well yeah the important point is that that is not required because they this is this is consistent with existing API if all you have is a standard PSK api you can use it this way by just yes by general I\u0027m just worried about sort of exactly this compatibility between a client implementing something a server implementing some party not implementing that extension and the other one does and so you get this weird error cases up if PS case like we already had previously both appears case when people use different encoding at the user interface and then it just they\u0027re just failures and you have to go through the lock of the TLS handshake to figure out what what the failure case is because the error messages in TLS for PSK are not very enlightening yeah something that you consider I mean you might be possibly consider some other signals to indicate that this client is using this particular extension and maybe the server can operate on that and maybe that will help your debugging issue what yeah so there\u0027s a lot of things missing from the container so remember saying extension but this isn\u0027t like a protocol level extension this is just you know it does not change the protocol in any particular way right right so miss just a fact you\u0027ve got you so if it\u0027s like a mismatch between one side implements the other side doesn\u0027t implement it\u0027s just "
  },
  {
    "startTime": "01:33:55",
    "text": "you know you\u0027re getting a PSK identity offered that you don\u0027t recognize yeah and you know yes the durable behavior in this case is not super great but it\u0027s not catastrophic either yep yep sometimes I assume that in in the case where you plug one of these in you\u0027re plugging this entire struct in as the identified entity not just the first piece of it so it\u0027s it\u0027s it\u0027s possible for someone who\u0027s when there\u0027s a confusion between the two endpoints the identifiers that are used for the keys are different because this is this is an extra in it so my implementation in my understanding was I would just plug in the first thing and then construct the rest of it internally but oh okay it\u0027s all set yeah I guess so let\u0027s take a step back a conventional kills 1 3 um you know stack right there when you have today if you had PS case what it would do is it would take a external PSK and it would be attached to it would be the the key to using the hash function to use the TLS handshake and a label those are the triplets árbol things you get right in a and so the there there are two implementations options for doing this and with this option one is to externally generate a new set of PS k\u0027s from that initial triple that have um that that each have that each of which itself is a triple of with the new pit attached hash function and to show them the interface exactly as exactly as they currently work option and they have names are synthesized in the way Chris indicated option two is to have a new interface on the outside that says here is a PSK that you should never use directly for TLS but is 8 is a root PS kqs drive use drive other PS KS according to this function and that\u0027s what Chris has done yes but those two implementations ought to be interoperate just one yes so the interface that have mine is specifically an import this PSK it imports this external PSK not set external PSK given this blob yeah but again purely imitation detail and hopefully they do interoperate the end of the day yeah right so the other design that I mentioned earlier is that from David Benjamin just sort of similar in some respects the basic idea is that it sort of abstracts the general idea that you only want to use a single PSK with one particular hash function in TLS 1.3 the design basically takes the external PSK uses it to derive a new PSK to compute the binder values in the client hello and if the server does indeed you know verified the binder and negotiate cyber sweetie you then afterwards derive a purr cipher suite or a new PSK or using the key "
  },
  {
    "startTime": "01:36:56",
    "text": "schedule based on the negotiated cipher suite for the hash algorithm associated with the cipher suite so in effect you\u0027re sort of changing what PSK value is injected to the key schedule but the benefit is that you\u0027re only sending exactly one vsk over the wire which is the sort of fundamental comparison difference between the two so with the embroiderer proposal you have an inflation in the number of PS KS that you\u0027re actually the binders that you\u0027re actually sent over the wire you\u0027re not changing the protocol in any particular way with universal feeis case you are changing some of the key schedule details but again you\u0027re not inflating the climb hello unnecessarily so which one we prefer is sort I don\u0027t really care I think we should do something here because many people use external PS case I would like to use them for to us 1.3 in a safe way and just need a way to do it so then all right thank you no because so I mean we should be clear about what we\u0027re actually doing if you\u0027re sending multiple PS case over the wire you\u0027re sending the PS K which is you know or what so you\u0027re saying that the label and then you\u0027re also sitting in the binder yeah and the binder is the full width of the hash output and so you know if you\u0027re talking you know that\u0027s minimum 33 bytes you know because you got the length field for each binder you\u0027re sending and you more for the larger hashes and so you know if we\u0027re only gonna be sending sha-256 and sha-512 hashes currently with TLS one two three sacred suites associated to them you know maybe that\u0027s not so bad but if we start getting into know we\u0027re sending six things on the wire that\u0027s kind of large and you might start to impact our decisions yeah absolutely something is there yeah it\u0027s true I\u0027m not overly worried about that to be on the stick we\u0027ve gotten pretty far we\u0027re not very many hash functions and I think that for me like basically I felt like University s cases like wheat in which if I wants to tell us um for something which I didn\u0027t think was like actually as valuable as perhaps other people did so um the design of the importer specifically designed not to do that by all steal us so uh I guess you know I\u0027m sort of like a lukewarm on the whole thing but like I\u0027m negative on I\u0027m negative on your 40s today so that we use to be as case for some of the low-end IOT devices that don\u0027t have enough sort of RAM flash etc for the public key crypto so I understand that it\u0027s not particularly useful in the web context for variety of reasons but they are specifically for those PSK cases sort of often the over the wire transmission size also matters so maybe that\u0027s something to take it into account and I can actually point you to some of "
  },
  {
    "startTime": "01:39:57",
    "text": "the products we have in that case because it\u0027s it\u0027s not only used by us but also by Paris yeah absolutely I\u0027m not saying that that\u0027s not an important thing to consider I just it we should do one of them and there are trade offs yes yeah I mean and there\u0027s also the question of you know if you do have this sort of tightly constrained environment or you\u0027re actually going to be sending multiple things or would you just be picking one yeah sure one I mean Jonathan Holmes and in when you say in a seemingly safe way do we have any sort of reason to believe that other than yeah it feels ok it feels ok so as a former analyst I\u0027d say that sounds terrible yes so of course it does require some analysis I think David in his drought who specifically says like yep this is not undertone significant analysis and certainly there\u0027s some we doing that sorry he\u0027s someone timing to do that doing it I believe you just volunteered yourself no not that I\u0027m aware are you interested to doing that that you said that is the one nice thing about the importance you don\u0027t really do any of this analysis over again so probably someone years hiring oh yeah so is that it Chris no sorry Erickson one more little plug sort of orthogonal especially with respect to the issue of privacy it was various on the list kind of wanted to discuss this very briefly there is this sort of issue with tickets and resumption PSK is in that you may use them servers may use them sort of traffic clients across resumption attempts depending on your perspective that may or may not be a good thing say for example if you were using you know are implementing and using DNS over TLS with resumption to speed things up the resolver to which you\u0027re connecting could link the queries that you\u0027re sending over time arguably worse in privacy depending on what day the week it is so there I guess a number of different things we could do to address this particular issue the first of which is if you\u0027re you know implementing Till\u0027s 1.18 you\u0027re not actually sending any early data don\u0027t ever resume don\u0027t give the server any state that is not really useful for anything because most implementations I\u0027m aware of I should don\u0027t know what NSS those but boring a stuff for example will never do just kiss key on the resumption it will do PSK with a full handshake is that the same for NSS as well yeah yes yeah I\u0027m not aware of anyone who\u0027s doing just pure PSK when it comes to the sort of context work we\u0027re operating right so in our implementation in our system Apple\u0027s implementation in system this is not a big performance it at all so that\u0027s what we\u0027re doing other option is if you want to resume and send some early data potentially use the semi static approach was it has not yet seen significant Syrian Alice\u0027s John to encrypt the early data "
  },
  {
    "startTime": "01:42:57",
    "text": "with a public key that has shared amongst many people instead of a PS ksoc with the ticket that share beat specifically between one client and one server that has some nice properties we also had this crazy idea to at one point use the view of the fort whatever you want to call it I think that\u0027s how I pronounce it barb - instead of simply recover the encryption of a PS gate but to use them to derive PS case in an anonymous way and you potentially use that to resume and send really data as well yeah yeah so um right um so I guess I think that this is not a crisis I think if we do anything we should well we do to at some point I am having trouble wrapping around how number three works perhaps perhaps yeah there is a draft written transmitted as it is I forgot the word crazy I\u0027m in there it\u0027s you know right well I\u0027m not saying is good or bad I\u0027m just trying to think about how it works so just real quick are you saying that number one you would not do or oh I I think I mean one is fine I don\u0027t know I don\u0027t think we\u0027re gonna do it hey I guess like i guess i i i i i think that like justjust in the setting of like it\u0027s just because of the way like the system is kind of constructed like there\u0027s like 87,000 state vectors and so like trying to like remove this particular one while i not fixing all the other ones so I got pretty helpful and so I\u0027m like basically like no I know you\u0027re gonna say no indicates used I know I\u0027m gonna say is like that the right thing to do is like when you when you decide to when you decide to create a cut point like you flush all your state that includes this and you know II just don\u0027t resume at all and like saying like oh I\u0027m gonna like send my like my CP cookies but I\u0027m not gonna like semi TLS like session ideas like doing all so like like French are it\u0027s like much more sensitive a clean cut point then kind of where it is that each individual thing like one of the time yeah but identifying that cut point is extremely difficult and tricky I would say I mean you can for example bound the tos session state to the lifetime cookies that\u0027s that the relevant example that I mean it\u0027s effective we should be done yeah yeah but there are other identifiers other places in the stack that may not rotate may not change yeah yeah right I you you wrote the draft saying that you have to do them all at the same time muttons also how do we know that the semi static th secret is only said it is not only symptom I to me it\u0027s not like some key you\u0027ve got a key identifier in there for it obviously and that key identifier is state that the client is now mirroring back to the server so I think I think proposition number one is really the only feasible one that\u0027s the sort of thing that way of welcome to implement and I I don\u0027t know I don\u0027t know that this is used as a "
  },
  {
    "startTime": "01:45:58",
    "text": "motivate motivation to do the second one although we might want the second one for other reasons yeah so I second one in particular still very much a work in progress we\u0027re still trying to actually show that the you know using semi static for the regular tails handshake is safe and we\u0027re actually making some progress there with tiwa and mozilla but yeah doing it for early data is still something that we have not really looked at and we just have really good feeling hearts that it will be safe that\u0027s what matters Christian Chris Christian Rita man Chrissa I never be disappointed because you present here a lot of mitigations for the resumption issues my Dussel risk that sees that if you have a PSK you need a big identifier that PA identifier uniquely identifies the key that you\u0027re gonna use and as such is a tracking device so if you reuse vsk identifiers multiple times you get talked yeah so this is like I was saying when I transition to the slide this is sort of authorial I just have this like here in particular to talk about privacy issues with presumption not privacy issues you to dump them with extra PS case and the identifiers and labels associated with them so this is for the normal like forget that this is actually a slide in the external PSK presentation this is just sort of are you going to advance they have this are you going to address that caneta address what that privacy issue so I don\u0027t really do as a PS k2d file I don\u0027t really know of any a good approach to addressing that like PSK is external PS case in particular just have and identify with them at the at the minimum you need to have a big red warning sometime in the Security section yeah okay yes sorry so I should many more clear this is sort of a thorn off to the external PSK issue I just it\u0027s something that came up during discussion in the list I want stuff I think hi to Martin just to address your comment about the th secret not knowing whether this is rotated I believe you\u0027re pointing here the whole the whole point of this is is at a network adversary in which both the client and the server are trusted so you would trust the client and server to you know not the server not to try to trick the client into losing its anonymity but here you\u0027re looking for its if you if you cross out servers and you say network providers I think then this makes a lot more sense this slide resumption of yes case then because of a presumption PS case you\u0027re supposed to get a new one bridge connection resumption fee this is about the resumption case okay it\u0027s an everything right but then but then the issue is that then the issue is not never service providers its endpoints the service just like civil anger I\u0027m wondering why this occurred me why we "
  },
  {
    "startTime": "01:49:00",
    "text": "need to have a can we so keep the API as set PSK if for example you say that the implementation if you set PS k whatever what it could do for the whole strong entity it could generate a hash of that element with the intended hash function that\u0027s supposed to be used for and then what I could just stick that in between the PFD in front of the PFD identity or at the end of the PST identity I mean it\u0027s effectively what this is yeah but but this report it\u0027s not exactly that because you\u0027re like oh we can discuss this outwards okay yeah sorry right um so that\u0027s the end of it sorry for the quick detour with the presumption PS case but can we get a sense of the room if we had to go down the two approaches whether there\u0027s two options right basically one if I can is-is-is is bigger client handshakes the other one is mucking with the key schedule two people have a preference if we were to support this whether they prefer accepting the bigger handshakes or mucking and we could have both but we probably do not gonna try for that it\u0027s big a handshakes in the case that you have someone certainty about the hash function that\u0027s used if you\u0027ve only got one hash function this there\u0027s no difference in Tosa sauce yeah and the external PSK in our particular use case we know which hash algorithm is supported by both pens so we would only send one but I don\u0027t know hummus if that\u0027s the same in your use case that you had described okay are you gonna take it home or do you want to keep that small that\u0027s where I was going I was gonna be like you know bullet number one that there is it\u0027s you know hum now if you think that this is the way to go and for the second how are we home now for the second one you know what you tell me like in bite it bite sort of bits what bit size difference up then I know what to how much impact that is because for web people it probably doesn\u0027t matter because they are sending lots of other stuff anyway I mean it depends on the label that you\u0027re actually providing associating with external PSK in the size of binder value actually sorry so we will have to look at the details essentially yes it\u0027s like 50 or 60 bytes it\u0027s probably near the most likely case that is gonna actually happen I\u0027m going into the next working group meeting later this week and there I will be told that TLS and DTLS 103 is awful we can\u0027t use that because it\u0027s so heavy and we shave off one byte and that\u0027s why we need to crank out and completely new sterilization effort and then it would be promoted in all sorts of other organizations just because of that argument makes me implement the two different protocols that essentially do the same thing you know what I\u0027m getting to yeah I mean "
  },
  {
    "startTime": "01:52:00",
    "text": "if you care about the size just pick one hash and only use that one hatch them there\u0027s no expansion yeah so sometimes the the point that people are making here is that in a lot of these cases you\u0027ve got a constrained implementations they only implement one cipher suite you\u0027re only ever gonna have one hash so you\u0027re never going to have to run into this problem with the the binders now it might be that you want to define something a new cipher suite that has a shorter binder so that you can have save even more bytes but that will require some more analysis all that business but the key right right you have to make some changes in whatnot good point but the point here is that the from that perspective in that under those conditions these are not different yes correct and and the the first option is far less violent to other parts of the protocol yes so since you looked at this crits um for one hash algorithm what is the by difference between the two options before I don\u0027t I don\u0027t know the exact street bikes oh so I\u0027ve been convinced this is not hummable we will try to take this on the list to see if we can figure out a way forward next don\u0027t go anywhere [Music] [Music] ah yes there you are the best right okay so this is something we also talked about in Montreal the basic idea is that currently most server implementations will just send you a fixed number of tickets regardless of how many you actually need so if you\u0027re a client who\u0027s not only using one ticket some of these go to waste if your client needs more tickets and you don\u0027t want to reuse tickets this is potentially not enough and say the the multiple you might want to use multiple tickets if you\u0027re racing GLS connections and they happy eyeballs be to kind of style all the way up to tell us over different interfaces over different address families so I in general there\u0027s some sort of mismatch between how many clients or how many tickets clients need and how many tickets are vended by servers so the initial design we came up with was basically wait for clients to requests "
  },
  {
    "startTime": "01:55:00",
    "text": "tickets on demand post handshake there are several issues with this in particular we don\u0027t I think as a whole we\u0027re not really fond of post handshake things for censoring messages in particular this would have been the first one or the first draft which introduced a client originated or client initiated post handshake message which is sort of okay yeah right sorry it is sort of a non-trivial protocol change is adding this request response so that\u0027s potentially undesirable and then there\u0027s a story it\u0027s not clear how you actually buffer these reads and writes of Depot centric messages on the client side potentially especially if you have them arrive out of order from the server so the feedback we got from the room is that potentially this is useful it might be simpler if you just have the client tell the server upfront how many tickets it actually needs and then the server can choose a use that as a hint to determine how many to vent back so if you are server who only spends two tickets and the client says he only needs one then the server could potentially just some one ticket instead or is it the client says I need 250 five tickets because I\u0027m going to be doing a lot of resumption and server only supports to the server can still send back call me too it\u0027s simply just a hint that\u0027s sent in the client below in a new extension that says please give me this number of tickets I expect to use these in the future connections in the case and for the Apple case in which you\u0027re using or racing TLS connections across different address families across different network interfaces we would request for example for and hopefully we would get those so we could not use the same ticket across each of these particular interfaces and address families if we\u0027re resuming connection later on orthogonal to this whole issue is that of post and check buffering so Thank You Martin for sort of bringing this quick issue to the list are we sharing a pointer to it so a client can by design request up to 255 tickets and if a willing server is going to happily provide 255 new session tickets after the handshake is complete and we\u0027re not really doing flow control for post handshake messages in quick that sort of complicates things there\u0027s also the issue of you know these messages potentially arriving out of order so this client would have to buffer all these massive new session ticket messages which may not be great also that there\u0027s no way currently could restrict the handshake message size that is sent from client or server in the protocol maybe that\u0027s something we just do in a separate draft that are now an extension to negotiate that it seems sort of orthogonal to this particular proposal here but certainly an issue to consider yeah Martin not so much real fun little if you put a day in front of a tape in TLS so in dates you lace you might you might receive the 255 handshake messages and start getting only part of the tail of them okay you have to deal with I mean you can still in this case at least process them out of order and so as soon as you get a whole session ticket you can take that "
  },
  {
    "startTime": "01:58:02",
    "text": "one out and you return the space back but you still have that problem yeah good point thank you oh sorry I should point out not a lot of implementations would do that now naturally yes most of them will go oh this one\u0027s out of order I\u0027m gonna wait for all the elements to arrive yeah so super Langer I would like to point out that there\u0027s a slight distinction between the number of session tickets they\u0027re sending and the size of each individual session ticket so that the handshake message size limit would that we discussed would apply to the size of an individual session ticket yes versus the number yes I mean so easy I mean these general issues came up both and quick and tell us um it\u0027s effectively possible given like any kind of you know fragmentation reassembly protocol to force the other side - like attempt it buffer like an arbitrary my crap in that like I mean the only way I\u0027m aware of this really of dealing with this is like I\u0027m checking the maximum amount of outstanding data ievo control I mean like not as I can\u0027t shake message size at the issue so much it\u0027s probably handshake message size but like martin says you can have that what are messages so ultimately it\u0027s like if you actually want to seduce me about this you have like you know basically say like you know i won\u0027t let you have some more than so many bytes outstanding i guess i\u0027m perhaps less enthusiastic about this than other people seem to be by this you mean but by this problem hung like I\u0027m certainly aware of like why you want flow control for like like you have a bunch of concurrent HTTP connections but it\u0027s a practical matter like I strongly suspect you can set like really quite narrow limits I like what you lot of people to do and if they violate them just like half the phone I don\u0027t think I mean hey the but that is a practical matter the amount of outstanding data should be relatively modest and so like if you said like any reasonable limit you should be able to just deal with it yeah so I I guess I think I was opposed like h2 or like really wasn\u0027t for another foot control I think if you were to be like I don\u0027t want more than 32 kilobytes of a standing it like you\u0027ve actually been a pretty fine situation more than that I\u0027m gonna hang you up that also seems strange for clients the requester fuck tickets the first place so and kind of book on yourself there yeah suppose I I don\u0027t know whether we should be discussing that particular issue at the moment there\u0027s a long diarrhea die have about this and the quick mailing list about flow post tantric flow control and that\u0027s a whole discussion which will be painful to have so probably we should keep those to this if we want to make progress in this just keep those two separate I\u0027m good to me yeah Ben yeah I\u0027m just sort of with a car you don\u0027t necessarily need a protocol limit you can just have an implementation limit that\u0027s fine okay so the response team you\u0027re generally positive at the last meeting so I would like to see potentially this "
  },
  {
    "startTime": "02:01:02",
    "text": "is something they worked group is considering or would like to adopt and work on and that\u0027s very good can we see a show of hands who have read the document yeah that\u0027s actually not bad um can we get a hum for those of you who would support adopting it as a working group item okay those who would be opposed to it as a working group item anybody voted no feel free to get to the microphone all right good hey so one other thing there\u0027s some TLS stuff that\u0027s happening at the IRT F open meeting there\u0027s some stuff about mission accomplished HTTPS secure after DigiNotar and somebody\u0027s gonna be updating with some recent TLS 1.3 measurements in case you\u0027re interested thank you Oh [Music] quickly there will also be a talk in that bar G tomorrow about OCS the most stapling responses from Nick Sullivan so if you\u0027re interested attend "
  }
]