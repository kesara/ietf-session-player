[
  {
    "startTime": "00:00:02",
    "text": "thing, so that we have an accurate sense of who's here and whether we can get the sessions started But in any case, we're going to get going in a couple of minutes because I think I see on the camera that we've got a good number of people coming in Okay, we're a minute past the hour and I think we have a lot to cover today. So let's get, let's get into it. Um, to welcome everybody to the first of two more instant messaging interoperability sessions we'll be having this week during the site IETF plenary session First off, as usual, we'd like to remind everybody to note well the note well, in particular IETF's policies on intellectual property and the code of conduct that you've already agreed to by attending this meeting Before we look at the agenda of"
  },
  {
    "startTime": "00:02:02",
    "text": "would anybody like to volunteer to take notes for today's session? Yes Somebody got volunteered somebody without a laptop got volatile daynotes Okay. Can you sit up here? You can sit there, yeah, it's okay It's not like a big duty you don't have to sit up here. Everybody's staring at you for an hour and a half. What's your name? Sorry can we get it? Connor. Connor is our no taker. Thank you very much Connor. Thanks, Connor. Sincerely appreciated Okay, now let's look at the agenda for, our two sessions. So today in session one, uh, have Administrativeia, which we're covering right now. Then we're the agenda for our two sessions. So today in session one, we have Administrativeia, which we're covering right now. Then richard barnes is going to give us an update on the protocol That document and the architecture document have been adopted by the working group since the last time we met in a plenary, so lots of new stuff there Then Rowan's going to, Ron Mayhe is going to do an update on the content format draft and then we're going to have a couple of presentations on the question of metadata privacy from Conrad Cobroch and then brendan mcmillion mcmillion The second session, which is later this week on Thursday, will be focused on user discovery requirements and then we'll talk about room policy on. So do we have any changes or additions to today's agenda? Sounds like we're okay um oh conrad go ahead sorry yeah i just want to note might make more sense for brandon to speak first about his approach and then uh me talking about the feature stuff Okay, Brendan's not in the"
  },
  {
    "startTime": "00:04:00",
    "text": "participant list. Perhaps we're still on their way or Okay. Brendan are you in the I mean, I can go first if he's not here, but yeah Okay, thanks. Okay. Well, I guess we'll see when we get there, right? Actually, speaking of people being here Richard's first up on the agenda, but I don't see Richard in the participant list. Yeah, he's in the room richard barnes you ready? You can sign in to me to go after maybe Hello. Oh, actually, wait, do we want to? deal with this let's do that at the end of day too yeah. Okay. All right Richard, I'm going to throw up your slides slides oops there we go take it away richard vallee right, cool. So this is going to cover the architecture document just real quick, because there's not really any new there in the protocol document The only real news with the architecture document is now draft IETF because we adopted it last time One of applause for working group projects, yeah progress Yeah, um, is there, should I just shut it soon? That works. But, you know, since a lot of folks weren't on the interim meetings, we haven't seen this in three months four months, figured it would be good to like refresh people's memory on the architecture we have here and what we're talking about Is this working? I don't know that it'll work because it's all being under me to go anyway. Not working. Yeah. All right, so Tim, can you hit the next slide? please so just to remind people this is my favorite bit of terminology in Mimi. We have a client to server to server, to client architecture So if you're a client, you have a local server you talk to, the meeting is hosted on a server which we call the hub, which may be a different server and the other people on the other side of the meeting have their own local server through which you reach them. So everything kind of gets routed through"
  },
  {
    "startTime": "00:06:00",
    "text": "those three servers. And the organizing concept is this room thing. Next slide, please So that's just more of what I just said on the last one. Next slide Yeah, so the organizing unit of functionality here is a room, and this is exactly the concept you think it is Like it's a space that has a bunch of users where we're exchanging messages posting files sharing emojis things like that In this, we're going to talk less about the actual messaging and more about the metadata and the functionality because Rowan's got a nice content document that just finds how you actually do the funds stuff that you want to do with the room. But we as the working group, we do it define all the boring stuff, like how we decide, you know, who gets into the room, who how everyone knows who is in the room and things like that so we have a set of state attributes associated to a room and authorization policy, a participant list, and a list of clients who remember So we have two, kind of two levels of membership. Users are participants, right? So users are like, people like Connor or Britta And then clients are devices like Connors laptop or Britta's phone right so you those are members. We have two different notions of membership, and that becomes salience because of the participant list is managed to kind of the Mimi layer the client list, the specific devices that are involved. That gets managed at the MLS there that's the We're how the insens of insecurity attaches. So yeah, and that those two relate to each other is a lot of where the subtlety comes in and I'll talk about in a second I'll skip over the last one because it's not super salient. Next slide, please So this is just kind of putting that that kind of layered notion in a figure because it's useful to think of how these figure are light. So on the left-hand side, we have the policy that govern who can be in a room and what they can do And then we have that participant list"
  },
  {
    "startTime": "00:08:00",
    "text": "which is at the user level. And on the right-hand side, we have the very specific list of clients, those individuals devices. Next slide, please Capabilities Thank you So there's a couple of principles in the design here. One is this policy of preemption that the authorization policy governs the participant list The participant list governs who can, who in which devices are in the room, right? So you can only be you can only have a device in the room if you're a member on the participant list, you can be only be a member on the participant list if you are allowed by the authorization policy, right? Makes sense Next, next slide please There's also this idea that we want of confirmation So MLS, our end-to-end security layer, provides this property that it can confirm that all of the devices in a conversation have the same view of it And so we would really like to confirm that all of the devices in the conversation have the same view of the participant list and the authorization policy so that we all have a coherence view of what's going on in the room So there's kind of this back-and-forth dance where the policy governs the participant list which governs the MLS group, but then the MLS group kind of reaches back and confirms that we all agree on all that other stuff Next slide, please You have Mary in the key question. Oh, sorry, yeah, I can't actually see the Q so. Yeah. Mary, do you have a question? Oh, okay Maybe I can see the queue, Mary just wasn't there All right, next slide, please. Oh, thank you. Yeah, so this is going to, the kind of interrelationship between those two directions causes a little bit of delicacy and how exactly run the protocol because you need to kind of propose changes at the to the policy or to the participant list and then these those need to get committed quickly so that we do that confirmation property applies And you get confirmation that everyone agrees on the changes All right, that's your three minute"
  },
  {
    "startTime": "00:10:02",
    "text": "four-minute architectural overview of me That's kind of as far, you know, gives you the big picture of how this results as far, you know, gives you the big picture of how this is all supposed to fit together. Let's dive into a little bit of the protocol bits and how this mechanically fits together a little bit more This is also a draft IETF Nine of applause for working through progress All right, and this one we actually have a little bit more we've done a little bit more work at some of the interims between the last meeting here. So we'll cover those as well. So next slide So you may remember a few slides ago I talked about the client to server to server to server to client architecture. I always, I have to count in my mind when I do that And this gives a little bit more detail. So basically the arrangement we have here is that the room is attached to a hub server. So each room lives on one server logical server, you know, represents a provider The other servers that may represents users or clients who are not with that, you know, the hub provider are we call them follower servers, I guess we should Maybe you have a terminology on the problem, folks or leaders, but this is the terminology we have right now. So we then have interactions using HTTP requests. So it's just showing something like a messaging interaction where a user on this side of the follower has sent in a message for that follower provider to the deliver. The follower provider sends the submit request out to the hub and the hub fans it out to everybody else The other little subtlety here is that the hub maintains a cue of MLS proposals, which is related to that interaction between preemption and confirmation we're talking about where sometimes you know, some things need to get queued up and proposed in MLS before they can get committed and so the hub kind of tracks those and causes them causes clients to then commit them at the right times next slide please server-to-server communication, it's all HGTPS. We assume that"
  },
  {
    "startTime": "00:12:02",
    "text": "servers, providers are identified by domain names So you have provider a.com, provider B v.com, and then we just use regular WebPKI Mutually Authenticated TLS, server to server It's presumption nowadays. We could iterate on this if we want, but nothing really surprising here I think the main ambiguity is where that will construction worker side is, like how do you identify? when you call out to a certain, when you make it, HTTP request to a server you specify the identity of the server and the host header among the potentially many in the certificate there's not really a way to do that for the client side, so you can send a client certificate but HTTP doesn't really have a way for a client to say, this is the real identity I'm representing in this interaction So we may need another HGTP header for that We've used from right now, it's not really right. It's not a difficult thing to fix. Next slide, please So this is where it starts to get cool So MLS, like I said, has the group agreement property, but you need to kind of feed stuff into MLS if you want to confirm that you all agree on it. And so we've grown and I define this Absin protocol, which is an extension to MLS that lets an application use MLS to synchronize some state so the state the out you know, some blob of state that the application is provided gets included into the MLS state that everyone can confirms they agree on. And then we can use the MLS proposal machinery to make updates to that that state so as a result of that, we end up using MLS for a few things. So we do the first two are kind of, the stuff you agree, you would expect MLS views for. We use it for intending messages. We use it for controlling which devices can send and receive messages who has the end-to-en encryption keys. But then that third thing is we use this App Sync extension to synchronize state. And so the state we end up synchronizing here"
  },
  {
    "startTime": "00:14:00",
    "text": "is those two, if you think of that three-column dice diagram, we synchronize information about the participant list and information about the room policy and what that means but by virtue of the fact that we're feeding all this into MLS, is that if my client, and Connor's client and Britta's client are all in a conversation together we all agree on who's allowed to be here and who is here right now now That'll make sense. I'm glad JDR is nodding along here Next slide, please So Paul policy and participant list, this is like real hard hat area. I think Rowan has some more concrete thoughts on how to express this later. There's been a lot of iteration on this that's we need to kind of start working into PRs but yeah idea is oh yeah bro go ahead yeah there's agenda time on Thursday for room policy yeah excellent so what's in here right now is sort of a capability framework. The idea is you have identifiers for things like rooms and users and then you assign roles to the participants in those rooms As Rowan said, we have time on Thursday. This is very likely to change but this is what's in there now. Next slide, please Finally, these are the interactions we've got to find right now that have happen among the servers in the current documents So you start, if you've seen it Acme with the Acme directory, this might be familiar to you you start with a directory that tells you where all the endpoints are that you talk to, to do things on a given provider To add someone to a room, you first fetch key material for them, and then unless this is a key package that you use to bootstrap someone into the end-end security. And then to make changes to a room, you submit these updates to add someone to the participants list or to add a device for them To do actual messaging, you have a submit message which you send to the hub. Oh, I'm sorry, this notation on the left"
  },
  {
    "startTime": "00:16:00",
    "text": "is follower and hub for F&H Right. So these interactions with key material with updates are all either transiting the hub in the case of key material or going to the hub to make updates to the room likewise submitting messages the the follower server representing the user sending the message uses the submit endpoint to send that to the hub, and then the hub uses the notification endpoint to fan that out to the other follower servers the group info endpoint is a thing another kind of information about the room endpoint that tells you how you can add a new device to this to the MLS group, asynchronously of all the other participants can add a new device to this to the MLS group asynchronously of all the other the other participants. So again, this is probably highly likely to change, but this is where we are right now. Hopefully you can kind of see how this basically participants. So again, this is probably highly likely to change, but this is where we are right now. Hopefully you can kind of see how this basic set of interactions gets you toward something like the messaging interaction you would expect to be able to Next slide, please All right so that that is getting you up to today. So we have fast-forwarded through the last four months, and now we are at Ihead, well, we're here So actually, not quite there. We're going to go through the PRs we've done here in the last few months. So we have some interim meetings next slide please tim Had some interim meetings to try and you know, agree on some changes to this after we adopted it. First PR, we merged was to change it from draft whatever it was to draft IET. So once again, a round of applause for working group progress. Thank you I didn't expect that to actually have happen again another kind of housekeeping one we just merged is to take the apps and stuff we'd originally written it up as a section of the Mimi spec. We moved it out to a document in the MLS working group just housekeeping. More interesting tech merged is to take the appsing stuff. We'd originally written it up as a section of the Mimi spec. We moved it out to a document in the MLS working group, just housekeeping. More interesting technical stuff. We added a kind of internal identifiable resolution function Actually, Rowan, would you mind explaining this real quick? I'm forgetting the details sure yeah so the"
  },
  {
    "startTime": "00:18:03",
    "text": "idea is that, I mean, basically when you would use this you have a handle, but there is an identifier that's actually used, maybe it's like a UUID, that is actually used internally, and so you need to take the handle and say, okay I've got a handle at this provider, give me the internal identifier. And then that's the thing that you use in everything else So this is like your wire handle might be the public thing you want to resolve that to some internal like that you use right? action. Yeah. So think about whether this is you know, if you're with a messaging provider, think about whether this is salience here is, you know, or if you have more public stuff the other thing we added was a very basic consent mechanisms, right, in messaging systems right, not everyone wants to be contacted, not everyone wants to be added to rooms you have limitations on those sort of things And so we added a mechanism by which someone wanting to add someone to a room can make that request to get the other person's consent to add them to a conversation and then receive either a specific grant of consent for that one thing or a broader grant that says it's fine just you can add me to whatever I'm happy to be generally connected with you So it's very baseline thing. We've got in there now. I think that's something we'll probably iterate on but I'd be interested, especially folks have trust and safety experience you know, how that looks. Finally, we had a bunch of discussion and only recently I don't think we have PRC here, but we've got a couple of drafts we'll talk about later in the agenda about how we handle kind of metadata private and invalid commits and things like that A bunch of good discussion in the interims, but don't have any PRs, so nothing merged right now so these are the PRs we've merged I think the next chunk I have is on things that are still open Next, yeah, so next slide, please So we've got, I think, four PRs that are open at the moment, one about downloading five"
  },
  {
    "startTime": "00:20:00",
    "text": "abuse reporting and then a couple of approaches to this metadata privacy question that I mentioned on the previous slide So I think I've got a couple of notes on each of these in the next couple of slides Next slide, please, Tim So on the downloading files thing like I think everyone on the room probably knows the general pattern that every messaging app in the world follow is upload a file to some, you know, encrypt the file upload it to some server, and then in the messaging system, you send a link to the file and the key to decryptitress That is obviously the pattern we're going to apply here It gets a little complicated in the federated case here. We have this practical concern about who's actually going to store the files, visit the hub server, followers, and how you you access control in those situations. There's also a privacy concern around this in that wherever the file is hosted, that person can see who downloads it and that leaks information about, say, who's in a group to someone who might not otherwise have that information. It leaks things like IP address apps, and things like both these HTTP. So I think there's, the PR that's up there right now, provides a process download functionality where someone can ask a server to download a file on their behalf It's kind of like a, you know, the same sort of thing, same sort of indirection you would do with oblivious HTTP, but done at the application layer I think it's a starting point It's a PR, so feedback, welcome But the idea is to kind of try and address that privacy question by indirecting it, just like you would Next slide, please And happy to have discussion if anyone have thoughts JDR, I see you making concern faces. I'll wait for the opportunity ahead Yeah, this is the more discussion oriented because this is still, you know, still stuff that's open. Jonathan Rosenberg 5-9. First, like, I apologize, I might have, I've been out for a little, so I may have missed some discussion on this, so"
  },
  {
    "startTime": "00:22:00",
    "text": "feel free to say sit down we already discussed this I understand the general file of upload, download pattern, but why does the file system have to be outside of the hub? at all like i mean this this problem's about leaking of information happens when it exists as a separate entity, but practically speaking, it won't I mean, the hub is not like a server. It's a giant service, right? So, doesn't all these problems go away if we just make this some more? interfaces on the hub? It could be, I think Rowan has gone on yet. All right, rohan mahy So a pattern with you know, there are not that many federated systems, but the federated systems that exist they have one of two patterns. The sort of plurality of them, upload to the sender to the patterns, the sort of plurality of them, upload to the senders server, and a handful of them upload to the sort of owners that you know the hub what would be the equivalent of the hub But in either case, the idea is that, like, maybe you trust maybe you trust, you know, some large provider to be the host of this system where all they see are a bunch of pseudonyms but you don't trust them to know when a particular IP address downloads something because that leaks private information about that user who has no other direct IP connection to the hub hub Right, so I say that differently. In the Mimi interactions, all the interactions are indirected through the follower server And well, so that's actually what this PR does It does exactly that. It does exactly that. Through the follower server So I actually think it's compatible with what you're talking about you here benjamin schwartz meta"
  },
  {
    "startTime": "00:24:00",
    "text": "although I don't work on chat systems I claim no expertise I assume whatever you talk about is binding on WhatsApp Too bad I, um on what's on. Too bad. I, um, so I have real difficulty imagining that any of these servers are going to want to like act as reverse proxies out to arbitrary origins on the internet to download random files. So I think that that seems like not a, not a deployable architect Presumably, these files need to be effective hosted on one of the participating server presumably the follower affiliates with the user who did the upload Because as a hub server, I'm not going to let you like, random user with whom I have no business relationship posts like a gigabyte of data that I have to store for it and I like the idea of proxy download. I do think it would be helpful if we could be careful to do that in a way that permits streaming so that I can potentially still be uploading the file while you're downloading it Because otherwise we're creating a tan delay effect where I upload the file to my server and then it has to be, and only when that is complete can you potentially download it and then for you to download it has to be in some designs transferred in the whole to your server or maybe to the hub and then to you server and so we're we're creating a performance issue there Well, so I good. I appreciate that Ben and jonathan hammell both articulated support for the very two models that Rowan mentioned so I mean actually if we could scope this down to those two models, like, we can maybe have a thing where we could negotiate it at runtime, like it's a file either lives on the senders follower server or on the hub. Like you have to design a way to fetch from another follower server or from the hub"
  },
  {
    "startTime": "00:26:00",
    "text": "but that's not a difficult thing to negotiate I'm not 100% sure that there's a distinction if these are caching proxies Although, I mean, it's a difficult thing to negotiate. I'm not 100% sure that there's a distinction if these are caching proxies. Although, I mean, if the hub is caching, then I thought you just made the distinction about someone else not wanting to down from an arbitrary user server So isn't that the distinction? So the, the, my, my expectation is that if there's a long-term, essentially permanent home for the item, that that kind of has to be the file follower's servant. That's my, my expectation But that doesn't mean that every down has to go all the way, be proxied all the way back to the followers server. These are caching proxies a lot the way, then it could also be for a substantial amount of time sitting at the hub server and effectively served from there so you're making a distinction between permanent storage and temporary cache storage. There Raphael is next Hi, Robert from Phoenix, R&D I just wanted to note that we do have a draft for that called Mimi Attachments. We've had it for a while and we never really proposed it for this discussion so far, because at the time, it showed like it was too far out to talk about that So it doesn't really go into the whole question of proxying or not. I think the underlying assumption was that FISA would be on the hub indeed for well, I think mostly for privacy reasons and also because since the hub is the one manager, resources anyway, it's in the natural choice to do that And it also covers the question of access control in that instance and how the file should actually be encrypted. So long story short"
  },
  {
    "startTime": "00:28:00",
    "text": "of course, the idea was never afraid to be a standard on document It should probably be merged into a protocol at some point So yeah, just want to throw that in the ring Thank you you Hey, I'm Ben Thank you. Hey, I'm Ben. So, let's see, my first question is about something Jonathan said about like, hubs will only ever be big Is that like a goal or requirement of the architecture? Okay. And then, yeah, second off, I guess I just want to voice support for the idea of letting data be not a the hub because it seems like it could lower the cost of operating a Mimi provider by letting provide cooperate and coordinate and share the data hub so plus one for that cool thanks thanks Yeah, my yeah, I'm just thinking about this architecturally, normally in the architecture, the first S and the third S in the CSSC, never talked to it each other is the intention, you know, directly. They only talk to each other through the hub. Does that apply in this case also? Because that would require more proxying, but might be easier both from a, I don't know how to what extent server you know you know remote followers are considered private from other followers servers. Yeah, I think, I think one of this slides I skip past kind of quickly in the architecture discussion was there was a principle in there that all of the communication is via the hub there You don't presume that service calls and talk to each other directly of the originating server, that instead of be a double proxy. Yeah. Okay Which if you stream it right, you know, might not add much latency Jonathan Rosenberg, to be clear, like you say everything goes to the hub but actually the consent requit are follow-for-faller. It's inconsistent in the architecture"
  },
  {
    "startTime": "00:30:00",
    "text": "So I was going to comment like, yeah, you've been standing up here, like, lying for like an hour It's like completely wrong. Even the acronym is wrong. All right So, I think there's actually three orthogonal design decisions. And I think there are actually orthogonal design decisions other. The first question is, is the transference of the file through the Mimi Protocol? itself? The second question is is it sorry, I thought, I had it three and then I came up here and now went down to two in my brain Is it through the Mimi Protocol? Is the file stored at the follower? or the hub? I thought there was a third, but maybe those two. So I think we've been, we can sort of make separate decisions on those different things Yeah I'm of the opinion that the, I think the harder one is whether it's on the hub or the follower. I'm actually of the opinion that it's on the hub, not the follower And the reason is, is there really a difference between a big message? and a big file? We're already storing big messages in the hub. We already say that the authorization decisions, policies are on the hub So if there's a decision for, like, how long this content lives, you know, that would be an interesting piece of authorization policy It often is, right? Like in Slack, it says, you know, your messages will be persisted for two years or whatever. If those policies change that affects the storage and all of them I think, points to the file having to be on the hub So we're already putting a lot of work on the hub Sorry, had files All right, rohan mahy. So first, I want to just say, you know, we kind of risk it by shedding here because this was the sort of least interesting of the PRs that we've got Yeah. Yeah So what, one of the things that this group has been lacking except during the interims, has been interaction on the line"
  },
  {
    "startTime": "00:32:00",
    "text": "and so I would encourage you if you have an opinion about this, to either post a response to this PR to the GitHub repo for the draft it this PR to the GitHub repo for the draft that Raphael mentioned. Please stick a link to that in the chat of this, in the working group chat or on the mailing list But I want to say as well, a lot of these choices, we don't need to decide because there are going to be operational decisions of the providers So if a HUD provider wants to say, sure, you can upload stuff Great. If they don't, they shouldn't have to And it still works. So if you think that that is not true, then please go and either find me in the hallway or post on the PR Thanks. I need someone to store the data I'm going to close the queue on this topic in a minute, so if you have any, if you're not in the queue and you want to be in the queue, then go ahead and get in. Try Travis. Yeah, Travis from metrics.org Just the obligatory or obligatory Matrix already does all of this we already have all the the upload stuff, all the download stuff that we're kind of talking about here something to consider to the considerations list for either the mailing list or the people whichever would be basically just making sure that media is, or down the I guess, are linked to the messages themselves so that way third parties from the conversations can't grab them and then also just get that authentication component that comes with that As for whether or not it should be stored on Follower of the Hub, I'm born inclined to put it on to the follower myself just because the hub is already doing quite a bit of work and so it sounds like a pretty big commitment too them for a service provider to do that that Can I just ask a clarifying question because both of the last two"
  },
  {
    "startTime": "00:34:00",
    "text": "speakers referenced this like the any server in the, constellation could be a hub and any given time. It's not like there's services that are signing up for this but they're like boom I'm never going to be the hub. So I don't really understand this argument that much about like we should put it on the follower because the hub's doing so much because everyone who's participating in this has to be prepared to be a hub at certain times based on who starts the room. Or am I misunderstanding? Travis I think it's based off of yeah who starts the room but um we put too much onto the hub then or into the hub's role, I guess then the requirement on those service providers is that, well, if you want to start a conversation you're signing up for potentially terabytes worth of data which is a little that's a little harder to, I guess, reason about as a provider whereas if that sort of stuff is pushed out to the followers and then cache along the way potentially then that's a little bit easier in that sort of respect There's still certain things that the hub will have to do, and I don't think that's there's really a way around that, but it's just like where do you put the 30 terabytes of media that? a relatively large conversation might generate? But so that implies a service provider who, the service that they offer is you can join other people's groups in the interoperations case, but you cannot create them because I don't ever want to be a hub Potentially, yeah, like if there's too much for that one server to do, then those providers might just go like, well, the easiest way for me to be interoperable is to just never create rooms, which might be a legitimate strategy. It is just like, I guess, like, whether or not that's a real concern might be an open question"
  },
  {
    "startTime": "00:36:00",
    "text": "here, but I am a little worried about yeah, just the hub doing too much okay I think we need to figure out that's like a real requirement or not can you get in the queue Will you ask a clarifying question to the last two speakers? So that would be Travis and I. So there are clients that already do this where they store it on their local provider So I don't think there's anything wrong with that. I don't think it breaks anything So why would we say, why would we be prescriptive about this? That's my jonathan hoyland, Claflare Um, this, this like a song that doesn't need to be standard at all, because the reading the Mimi attack draft, it's committed to by hash, the hash of the plaintext is what's sent in the group so even if it's the sender has to upload it every time somebody's trying to download it, it's still works and makes sense and like is can just be like, whatever you want to do is fun even if that's stream from the sender Like, it works just fine. Like the security wise yeah it's security wise sure like throw it on ipp IPFS, adjust by hash. But this is already addressed by hash, right? It's like... No, I know, but I think we will the goal of this working group is also to enable functionality in addition to being security I think making that functionality work requires a mechanism that people do in which case just make it very very general and say you can do whatever you like Then shorts So saying that the only ethnic authoritative source of the upload is the client device that uploaded it has a certain elegance, but as a practical matter means that if that device is not online"
  },
  {
    "startTime": "00:38:00",
    "text": "then you've lost your guarantee of being able to download the file. You've got files in the group, you click download, and it just doesn't work for some kind of mysterious reason. So uh i don't know i mean maybe that's maybe we can paper over that with enough caching and it works I'm not opposed to that but it's not straightforward Hey I'm sorry we went out of order I'm Ben Go, I've been working on IPFS I am curious, it seems like it might be a good idea for the there to be a data commitment on the ciphertext of the encrypted file Is that already there or do, and if not, do you agree that it? could be useful for like security? By data commit, you mean like a hash of the file? Yeah, like, yeah like like a should that maybe you use rc 9620 to do generate that link or something. Yeah, I mean, yeah think probably open the format. I think Hohelo was just saying that that's already in the draft filement mentioned. I'm not sure if it's in the PR or not, but that seems like a sensible thing Thank you. It's kind of an aside on the thing about the user, you know, I've service that never creates rooms. I was imagining, I could imagine say a bot service where you invite some bot, you know, that invites some bots to existing rooms. And so that that's only ever, you know, running rooms on other service. I don't think we need to do anything special for the architecture for that If somebody chooses to write an implementation that can't be a hub, well, then they never not create rooms, but it's their problem, not ours ours Well, looking forward to some vigorous mailing list discussion on getting this driven down. All right, ready to move on to them more controversial topic next slide, please. Metadata privacy it's one we love. So the core tension here is that on the one hand, like we would like to tell the servers as little as possible"
  },
  {
    "startTime": "00:40:00",
    "text": "If the server doesn't need to know something, we shouldn't expose the information to it On the other hand, we want to have server do stuff for us. I want to be able to ban someone and have the server forbid them from ever interacting with me ever again. Right? The server needs to know something about who's in a room or who's trying to interact with me in order to enforce that policy for me So we have this tension We want to create some features that require servers to see some things but we also want to manage the privacy of who's in the thing like who's in the room, and expose that as few people as possible. And at a conceptual, though, there's kind of three designs here Really, we're talking about the proposals and the commits that are effective putting into effect operations in this group So proposals to add and remove devices, proposals to change the participant list of add and remove users, things like that And so there's kind of three protection levels we can afford to that information Right now, I think we're in state number one, where these things are unencrypted. Anyone who's in the system can see them Like it's all TLS, so the network can't see them but like any server that's involved, any clients involved in a room, they see all the MOL stuff. That's like max who's in the system can see them, like it's all TLS, so the network can't see them, but like any server that's involved, any clients involved in a room, they see all the MLS stuff. That's like maximal functionality, minimal privacy On the other end, number three here, you could have schemes where only the clients see these things and they're encrypted so that none of the servers see any of the MLS That's what we have some drafts later on the agenda to address. The PRs we have open are trying to address kind of a middle case where the clients are allowed to see stuff, the hub is allowed to see stuff because it's in charge of enforcing policy But the follower servers who are just there to route message control messages, they don't get to see things So basically you end up with, I think Rowan's called it semi-private messages, where it's a message, it's private to the clients in the group, but it's also exposed to just the hub server. So you just let the hub see these messages"
  },
  {
    "startTime": "00:42:00",
    "text": "You provide the hub the encryption key so I can read the messages so that it can do its job in force these policies. So it's kind of an intermediate between the maximal function minimal privacy case we're in now and the max key so it can read the messages so that it can do its job enforcing these policies. So it's kind of an intermediate between the maximal functionality, minimal privacy case we're in now, and the maximum privacy of challenging and functionality So it's kind of an intermediate between the maximal functionality, minimal privacy case we're in now, and the maximum privacy challenging functional as though. I look forward to draft case in number three So that this is kind of the design space we're considering for a bunch of the rest of the time today. I think I'll probably defer to discussion on this one to once we've seen those drafts because I think it'll be a little more productive. But this is kind of just teeing up that giving folks the conceptual framework to understand the Ophiope space. Next slide, please yeah and finally the last thing we have a open is an abuse reporting spec. So like obviously, lots of abuse happens in messaging including IETF spaces And so we want to be able to have providers be able to respond to find out about that from users to get reports of abusive messaging interactions and take action on those. Now, as usual, the trick with end-to-end encrypted messaging services, the person you're reporting this to once to verify that you didn't just make this message up to screw over the person that you report so they want to verify this as a message that that person actually sent and sent it through this messaging service So Rowan wrote up this PR leveraging a bunch of existing art around franking where you do some extra cryptography around these messages to add some proofs that the message came from the sender who's claimed, and it transitioned the server This, what's outlined on the slide here is reflects not actually what's in the PR, but what Rowan and I discussed the other day, but the general idea is to take this franking design and import it into Mimi. So you get some little extra cryptographic proof to prove those properties so that you can have the foundation for reporting and then you just have like an HGTPN endpoint where you can report to the hub that things have gone I see her on moving, but no one in the queue"
  },
  {
    "startTime": "00:44:02",
    "text": "Travis you Travis. I think Travis got in first? Yeah thanks. Yeah, I guess it's just a question of why are we sending the reports to the hub and not the followers? servers? That's a great question. I would invite Rowan as the author of the PR to apply on that. First question seems like the hub is the one enforcing policies, so they're in the best position to take action So if the hub is responsible for the policy of the room, if the policy of the hub for this particular room is that you can't drop F-bombs then it's the one that knows that policy and there's no way that the follower server necessarily knows what that policy even is So that was my motivation for doing, for sending the report to the hub I mean, if you wanted to have a if you wanted to sort of more generic way of reporting, something to, you know, abuse of the provider aid by Alice at Provider A of Provider A's generals terms of service, that's a totally different thing. And I think there was a comment by Travis actually on one of the PRs about maybe we need two different mechanisms but i think the mechanism that people are, that I've heard from, talks with providers, with existing providers that they most care about is is somebody violating the policies of the room, which would also include the general policies of the hub I would also know that franking design would get a lot more complicated if you had multiple potential reporting points Hi, there's been a series of future work building on asynchronous message frankings since that was"
  },
  {
    "startTime": "00:46:00",
    "text": "designed and delivered in, I think it was Facebook Messenger is the only major deployment I think so, yeah. There's some work one of the titles is Hekate, which is backwards and forwards privacy different ways of reporting even in anonymous encrypted systems have we looked at that a little bit, or is it just sort of no? Okay. Yeah, I think the goal here is just to improve whatever the best art in literature is not to and then i'm i'm not even sure if they've looked at group management or tree like tree ratchet or, you know, any of that stuff, but there's other work beyond franking that might be informative Yeah, that would be super helpful if you want to send a notes list. Thanks All right, I think we've got a couple minutes left, and I think that's the end of my content. Next slide Tim, is there, is there a next slide? No more slides. All right. You're free free content. Next slide, Jim, is there a next slide? No more slides. All right. Did you have something? No, I was just going to turn to our next agenda item unless anybody has anything left they want to say about anything that rich just walked us through. Well, I have one question, which is we have a parking lot in day two. Do we want to come back? around to the the um file down thing do we think we have more to talk about or people want to kind of think about it and write? some stuff to the list and we can talk about it on Thursday? There's a lot of traffic in the Zulip the Zulip, I guess, about this. So it does seem like people have strong feelings Yes. It also seems like something that's reasonably constrained we might actually come to conclusion on. Right I'm going to say that we had uh we had lots of lots of constrained we might actually come to conclusion on. Right. I'm going to say that we had lots of discussion on the mailing list and in PRs about the meme metadata stuff and haven't had a chance"
  },
  {
    "startTime": "00:48:00",
    "text": "to discuss this, you know, in a sort of a larger meeting yet whereas the download stuff has had zero feedback on the mailing list. And so I think it would be maybe appropriate to allow that to have hallway discussions and mailing list traffic or comment on PRs first if we see if we can make progress on this kind of pretty, pretty pivotal architecture decision about metadata privacy which can affects everything else in the protocol and then if there's still room then we can you know if there's still time later that we can continue to talk about download here afterwards Okay, yeah. I mean, we have an hour for metadata privacy today, so maybe we'll come to conclusion But if not, we have more time on Thursday Okay, I think Rowan, you're next. Yep, for metadata privacy we have content formats Hello, hello. Okay so next slide, please We're at draft four of the media content document So I did a draft three and then draft four in fairly rapid succession We had a we had a consensus that we were going to move forward with Seabor as a concrete encode binary encoding for the data structures that were in the mini content document So here we go. So the document now has seaboard structure and it has a CDDL schema and example documents and they valid with CDDL and there's in the GitHub repo there are all of the examples"
  },
  {
    "startTime": "00:50:00",
    "text": "and all of the in all of the various formats and feel free to go and take a little at them and see what you think the only other sort of main content change that I made was something that I planned to do in 2002 and then just merely forgot basically wrote it down on the list of things to do and then crossed it off before I did it, which was to add a hash of the content to the external content array. And so that was actually something that people were discussing in the Zulup about whether the hash should be something of on the ciphertext or the plain text. So feel free to chime in on an issue and the GitHub repo. That would be a very effective way to focus those conversations. Next slide, please okay so there are a handful of issues So we have three things which are related to different C-Bore encoding choices we could make And I was largely looking for input from that community to give input They're fairly you know fairly specific to knowledge of seabor idioms they don't really affect the function or the semantics of the of the community content format the mimi content format. So that's those first three things there and then we have two other issues one is uh somebody proposed that we add a subject field. Um, There was some discussion. I'm going to propose that we close this if somebody wants to use a subject header or have something like that And they want to do that via the existing extensions mechanism there is like an extensions map it doesn't require going to Ianna it doesn't require doing anything fancy. You can just go and use it"
  },
  {
    "startTime": "00:52:03",
    "text": "And the second the last thing there is there is an issue related to matrix extensible events, which I think is no longer really relevant because of choices that were made in the protocol document So those are the open issues. Would anyone like to comment on any of these? Hearing nothing let's go to the next slide. Oh, sorry? Hey, Travis go ahead yeah just mentioned all the nature's extensible events um go ahead. Yeah, just mentioning all the major extensible events. I think there's probably still a little bit more work to be explored there but for now we can close the issue until particularly us on the Matrix side get around to it. Thanks Yeah, and opening in a more focused issue a more specific issue is obviously welcome so Okay, next slide, please Okay, I had brought up this sort of nagging doubt about using an implicit message ID And so I'm just going to kind of keep bringing this up until we have actual implementation confirmation that this works that this works well for multiple implementers So the content format uses a message ID, which is calculated from the hash of the ciphertext and a timestamp, which is, and it's timestamp is, uh, chosen by the No, that's not right There is a, there is a timestamp when the message is received by the hub, which is conveyed"
  },
  {
    "startTime": "00:54:00",
    "text": "in the response and is forwarded on to everybody else. However, because Mimi is defined as a protocol for provider to provide, as a effectively a provider-provider interface with some requirements from the MLS and content perspective we can sort of force the client to server or the client to provider protocol to convey a to convey this time stand all right so sorry, I'm just going to try to mute this here Excuse me it's really hard for me to read both of the copies of the slides So for the purposes of abuse prevention and, uh, history sharing in a, you know, that is consensual history sharing the party looking at a decrypted best that is consensual history sharing, the party looking at a decrypted message doesn't have the cipher text, and so they can't independently verify the message ID there there are a number of things that, there are like some subtle things that seem like they could go wrong there, but I don't have like a concrete like this will definitely be bad if we do this Deirdre How, what are the restrictions? on the types of ciphertext formats that we're allowed to use in MLS? Because if we have deterrent, which we may, or if we have caching which we may, we may have collision for very popular memes that get thrown around because a news event just happened and just by happenstance we have colliding timestamps on the center the hub, and depending on the type of cyber that is being allowed to use, depending on how flexible that we're being about that sort of thing we might have collisions there too"
  },
  {
    "startTime": "00:56:00",
    "text": "Yeah, so this is always going to be an MLS private message and then it's going to be the hash of that MLS private message So I think we're pretty covered there and that you know you could send the same meme, you know, so several thousand times and it's not going to give you the same the same ciphertext. The timestamp is, the time that it is accepted by the hub, and so you can choose whatever granularity you would like at the hub to make sure that that is a unique, a unique timestamp and actually in fact nothing does go does go wrong if the timestamp is is the same for messages that arrive you know basically at two different instances of the same cluster on the hub, for example. Okay, so this is including a ton of other metadata, not just like, ha ha Yeah, yeah, this isn't just ha-ha this isn't the Mimi content format containing a ha ha this is the mLS private message, which has a generational ratchet and keys and nonses and reuse cards and all sorts of nice things there So it's it's MLS private message, which has a generational ratchet and keys and nonses and reuse guards and all sorts of nice things there. So it's pretty safe, I think Okay, thank you This is daniel king Gilmore. So it seems to me like you would not be able to send the message that refers to another message that you would already sent until you had heard back that it was accepted by the hub in this architecture. That's true So if I'm composing messages in like an offline form and then I connect and I want my client to flood those messages to the network, it can't actually have one of those messages refer to another message I mean, I can't reply. Yeah, I wouldn't be able to reply to myself. That's right No, actually. Or send the message that like, revises the previous message or"
  },
  {
    "startTime": "00:58:00",
    "text": "anything until I've heard back from the hug, not just from my server but until i've so So I can even hands up to the server. And the server has it and is ready to deliver it and I can't even send a follow up. There's like, whoops, no, I didn't mean that with a reference until I've heard back from the hub that the hub. And it's a little bit more subtle of that because you can't actually encrypt to the group until you are connected again because you don't know what the epic will be and therefore you don't know what the epic secret is okay so while you are offline in a not in the encrypted form that they'll go on the wire yes so if you if you went if you went offline at Epic 12, and you were, you know you were gone for an hour when you went offline at epic 12 and you were you know you were gone for an hour uh when you come back you could still be on epic 12 or you could be on epic 36 and there's no way of knowing that until you've downloaded the the list of messages that are in that group in the that are in that group okay and what happens when my server and the Hub lose connectivity briefly? Um, I mean, nothing unless you want it. I mean, what, I mean, exactly what you mean. So you mean if you... Sorry, I apologize I don't know. This is, this is actually very used for people to understand so so I am now on I'm now able to connect to my server You're able to connect to your server. And I'm going to send a message that will go through to the hub via the CSS arrangement And then, but my server and the hub server are, you know, they've disagreed about something in the network and they can't talk at the moment. Yeah, there was a BGP flat essay right and I've sent my message to my server. Yeah. You will love get a response until the hub says, Here it is, and so I can't even stay just message to my server. Yeah. You will not get a response until the hub says. Here it is. And so I can't even stage a second message to the server. That's correct yeah so I mean I so I can't even stage a second message to the server that's correct yeah so I mean I'm someone who does a lot of offline work so and and"
  },
  {
    "startTime": "01:00:00",
    "text": "server. That's correct. Yeah, so I mean, I'm someone who does a lot of offline work, so, and I'm fully aware that the network fails, so I'm just like trying to figure out what the consequences are operation for that. Yeah, you can you can hide this on the UI side. You can have a UI where you, you know, have the ability to go and do that and you can, you could even have a setting that says allow offline composition and automatic system You could have an offline composition and then confirmation are you still sure you want to send that given the after reconnect or you could have a strict you know wait until but if my high bandwidth time that i would to send is during a time when the my server is flapping it's communication with the hub I can't make you of my connection to the server at this point because I have to wait for response from the hub even if I'm even if I got it fat channel to my server at the moment, by the time I can connect to the network again, I might not have the fat channel Yeah, if you want it, I mean, it's all about whether you want to encrypt to the current members of the group, right? Because while you're offline well you're not connected to the hub, while you're not connected to the network at all or while your provider is not connected to the hub if the membership changes then you're, you know, you would be encrypting to the wrong set of participants. And that's the agreement is King agreement is king in or queen or is regal in MSF, and in the ones to close the queue here in a minute so if you want to be in the queue, please get in the queue or over time a little bit Rafael Yeah, I just want to speak to that really quickly because what DickoG said, that's a really important point for folks to understand It's indeed true that you need to have a good connection between your client and the hub via your service So there's a strong requirement on that working well We can be much more relaxed on the next section between the hub and the photo server"
  },
  {
    "startTime": "01:02:03",
    "text": "So that can be pretty much asynchronous, like it could be buffered. It's not entirely clear whether we'll have a push or pull mechanism, I think But fundamentally, we don't have a strong requirement for, you know, anything to be online in real time. But sending out messages you somehow need to be able to reach the hub as a client Thank you So I think the point raises like very important but like being able to respond your messages, edit your message So maybe if we need a connection to the hub to send a message, we should actually like enforce that. And if you're server can't connect to the hub after, say, a time or something like that, it will actually respond with an error and use your client's ability to resend. That way you don't get in the situation where you send a message when the hub is offline and then you go camping and this message that you actually type with something, it's very offensive, gets sent and you have no ability to respond and correct yourself yeah so unfortunately that's out of scope because that's what you're talking about is behavior between the client and its provider, which is explicitly not covered by our charter or is explicitly covered excluded from our charter. But it's a good idea generally for implementers yeah maybe it is something that can be like recommended or something yeah i mean if we finish all of our all of our milestones and, you know, nail it like, knock it out of the park then maybe we can extend and we can start doing some other stuff That's it for me. Thank you. Thanks Brendan Europe up. No, we switched Is that okay?"
  },
  {
    "startTime": "01:04:05",
    "text": "Okay, so I am going to talk to you today about a draft that I shared recently called the robust and privacy preserving DS proposal It used to be just the privacy preserving DS proposal, but now it's also robust because privacy is actually not the most important part, spoiler. Next slide So if you think about kind of in the abstract, what problems does Mimi need its DS? to solve? One of the first ones is actually control. So you want to make sure that only members of a group should be able to see and send messages. And you also want to be able to do spam and abuse filtering, so you want to prevent users from receiving or, you know, forcing the provider to store a bunch of abusive messages if someone, you know, sends a bunch of junk messages, you want to be able to just kind of like delete that and recognize them and um messages. If someone sends a bunch of junk messages, you want to be able to just kind of delete that and recognize them and not have them stick around and take up, you know, disk space Those are the two main ones. I mean, there's a lot of other ones but focusing on those for now The current approach that Mimi uses is the provider inspects commit messages, and it does that too learn and enforce and also sometimes try to modify the group membership And of course, the problem there is, the main obvious one is there's no membership privacy because you are requiring all of the handshake messages to be public. And also you can have this problem with invalid commits where because the D.F or the server has relatively limited visibility into whether or not a commitment have this problem with invalid commits where, because the DS or the server has relatively limited visibility into whether or not a commit is actually valid, so like the delivery service or the server can't verify the member tag. It can't verify all the little encryptions are done correctly in an MLS commit. The provider can end up trying to enforce the acceptance of a broken commit where someone sends a commit with EPOX 7. And so now the DS thing, EPOX 7 is over and it's not going to accept any more messages to that. But really, this is not a good commit and nobody's able to process it so the group is kind of stuck"
  },
  {
    "startTime": "01:06:00",
    "text": "and then there's also the pseudonyms proposal, which I think Conrad is going to present next which does address the membership privacy issue, but it does it by adding some implementation baggage in terms of who can be added to a group and when, and also does the same issue with invalid commits So, Robin implementation baggage in terms of who can be added to a group and win, and also does the same issue with invalid commits. So, right. Okay, so going into what would be better than this? Next slide, please So if we think about kind of the abjured what does an ideal MLS group look like? We have a series of epochs. So in this kind of diagram, each arrow is in epoch. And then the little dashes in the arrow, we use that to represent application messages And then each epoch kind of perfectly ends with a little circle which represents a commit. So each epoch has a single commit that commit ends the epoch, and then you start a new epoch and it's very fun and clean In practice, though, that doesn't really work Or that's not kind of how it is in practice. So next slide In reality, forks are kind of inevitable so if you have an invalid commit that gets provided to by really work, or that's not kind of how it is in practice. So next slide. In reality, works are kind of inevitable. So if you have an invalid commit that gets provided to you by the DS, the question is, what do you do? So one of the first kind of basic approaches is that you kind of just give up like you see an invalid commit, and you're like, well, this group is kind of ruined now so I'm going to go home. That is a solution, but it does unfortunately allow any malicious user to send such a commit and then DOS the group Hey, so because the sort of title of this chunk of block at time is related to metadata privacy, I'd kind of like to have these discussions between invalid commits and metadata privacy a little bit separately and discuss the metadata privacy one first I think that one of the, so one of the things that you didn't mention on your first slide and didn't mention here"
  },
  {
    "startTime": "01:08:00",
    "text": "is that it's possible if the DS is completely uninvolved, it's still possible to construct invalid commits where the DS has, you know, doesn't get to see them at all And this, you know, the, the draft that you wrote and the Google Doc that's associated the mailing this traffic, there have been no proposal for how to solve that problem. And so from my perspective, there's an invalid commit problem You know, there are ways that you can construct invalid commits both in the case where the hub inspects messages and where it doesn't. And so I think we should first focus on the salient differences where we have metadata privacy differences between several approaches that have been proposed, what's in the draft right now with student what's in the draft right now it's in the draft right now with pseudonyms, what's in the PRs that I proposed, what's in me, me, me and what's in your proposal so we've got sort of a menu of possible things and talk about what those will give us and kind of have a talk about that first. Thanks Well, I would push back on the claim that there's not a solution to the invalid commit problem because that's what I'm currently presented But also, I mean, if you want me to like say, down and come back for a later block of time, I can do that but this presentation is about invalid comments Okay okay. I was going to say, you know, that for invalid commits, if you, if the DS is paying no attention whatsoever I can send a, I could send a remove request or I could send an update and I could manipulate the update path in a way that's some users are in the new group and other users report And we had this conversation on the list. You agreed"
  },
  {
    "startTime": "01:10:00",
    "text": "agreed Your proposal doesn't solve that. So why is it? better? So there is kind of a hierarchy of different types of invalid commits. We have commits which are completely invalid even to the DS. So the DS looks at it, it verifies it as much as it can, and purifies the signature and it looks invalid to the DS. That's one type Then the other type, or there's kind of a middle type, which is types of commits, which look valid to the DS, but which nobody in the group can process. And then there's a third type of invalid commit which look valid to the DS, but can also be processed by a subset of members, right? So what this draft doesn't address is how to process is how to handle invalid commits, which can only be processed by a subset of members So only that one type. What this does address is how to handle invalid commits which look valid to the DS that can be processed by nobody And then in terms of invalid commits, which also look invalid to the DS, we can kind of ignore those because we can say like, it doesn't matter the DS can filter it or users can filter it, we can ignore it. Does that make sense? Yeah, but, I mean, I guess the question is, is that meaningful? for Mimi? Is that is that do we have any evidence that that this is a meaning, that like, the number of, the number of, ways in which you can do the you know the the the category versus the second to last in the last category is meaningful I think it's definitely meaningful because the last category where it can only be processed by a subset of members That's one very specific way that a commit can become unprocessable versus the second one, which is a commit which looks valid to the DS, but which no member in the group can process There's a thousand different ways you can do that. You can make the cybertext incorrect"
  },
  {
    "startTime": "01:12:00",
    "text": "you can make membership tag incorrect Yeah, I completely disagree that there is a meaningfully different sort of numerical difference of how many different ways you can do that basically you can work the tags. That's it Okay, but also the solution to address that, so if you have the subset issue, that's one specific way you can go wrong You can invent a way to handle that one specific case um that's a lot easier than trying to do that same kind of thing for the second type of invalid commit where nobody can process it I don't see why that's that's different. You've got two different ways of causing, of breaking the group It's here from Conrad Go ahead, Conran Could you clarify a bit, what is the threat model here? Are you worried? about, and I think you talked about both at different times? are you worried about buggy clients? Then I agree that might be, you know, there being more ways to break, you know the second to last kind of break with the second to last Invella commit. I would agree that sure there's more ways to have bugs that that cause these invalid commits but if you talk about like a malicious user surely whatever works the malicious user will do so kind of excluding the second to last category is not super meaningful because the malicious user will always then, you know, just use the last one that's so possible Could you speak on that a bit? So the threat metal here that we're concerned about is how to handle both a malicious DS and how to handle malicious users because the DS can be malicious but also so can the users and you want to prevent against both of this Okay, fair enough. Then I have to say I second"
  },
  {
    "startTime": "01:14:02",
    "text": "Roan and that I don't really understand the, like I don't think there's a meaningful difference between the second to last and the last category Yeah, sorry, just my two cents Okay, so to go back, in the case, where we're in a group and we're reading messages from the group and we said that the DS has provided us with an invalid commit. The question is, what do we do? in this case? One solution is you can give up and you can just kind of go home and say if the group is broken that is a solution, but it's unfortunate and it allows any malicious user to TOS group. So next slide A second approach is to externally rejoin the group. So basically you accept that this is the commit, which is the epoch. I just can't process it and I have to do something about that. So in that case, I would leave the group and then externally rejoin at the most recent epoch And we kind of unpack this for a very long time in the MLS working group yesterday. But this introduces a lot of really difficult security concerns that we don't have any concrete way to actually address our handle. And actually it also has the same issue as the last one, which is it still allows malicious users to to DOS the group. Next slide So then the third option, when you receive an invalidation commit from the DS, is you could ignore it And this is actually the same thing that you would do with any other invalid packet and basically any other protocol. So if you receive an invalid application message from the means server, you would kind of just throw it away. You wouldn't like do anything special because of it. Also like if you are a TLS client and you receive an invalid packet from the server, you would also just throw that away. You wouldn't do anything special with it so that's nice because it lands a lot more closely with the actual provable security guarantees of MLS So it doesn't have any kind of security concerns from just ignoring messages you can't process. And it also doesn't"
  },
  {
    "startTime": "01:16:02",
    "text": "introduce the DOS concerns that the other two approaches have. Next slide Of course the problem with potentially ignoring some commits and accepting others is that that creates the possibility for forks where multiple users send commits at the same time and they have different ideas about which commit they should accept so in this diagram, we have, you know, an epoch or we have several commits which have been sent to it and only one of them is actually valid and, you know, only one of them is actually valid in the eyes of the user but to the DS it just sees several commits and it sees several different e-box branching out from each of those commits so that's what we have to figure out how to handle in the proposal that I write The way that we can handle this is we can put each of these kind of forked epochs of the group into a box essentially, which is a way to pass it around on the server. So in each of these boxes we have a single epoch, and then within each of these epochs within each of these boxes, all of the message, are kept in a linear order So within each box, all the messages are in a consistent linear order But what's important is that there is no order between each of the boxes, so they all kind of exist in space and the DS doesn't really infer a relationship between them it just keeps all of them and it keeps all of them messages in each box in that order So next slide How do you actually make this usable for processing a group? What you have to do is you have to give each box a unique ID so that you can address it. And then that ID is what's used to read and write the messages to each box So if you're just starting a group, you might start with like box A and you read all the messages in that epoch, and then you get to box B which is the next one and then you can see each commit in box"
  },
  {
    "startTime": "01:18:02",
    "text": "B has an implicit relationship to all of the sub subsequent boxes that follow it And you can kind of traverse that relationship to follow basically different paths through the branches and across the reason that you you can't just address them by epoch number anymore like if b is epoch seven you can't just say, I want to send a message to, you know, epoch 8 because there are multiple epoch 8s which are all like DC and E so next slide To kind of work through an example of actually reading messages in this model so if like I said, if we just join a group and we're in epoch, or we're in box A, we read all of the messages in that. We find the first commit that we like that we think is valid We take that commit and we process it and we move on to EPOCP B or to box B, which is the next epoch. We process all of those messages we come across the first two commits in box p which are invalid for some reason. Maybe they have proposals that we don't like Maybe they've got the group policy. Maybe they're just cryptographically invalid So we just ignore them, which is what I said to do And then we get to the next first, the next we get to the first valid commit, and we process that and that takes us to Block C, and then we continue that So that's how we would read messages through a series of epochs in the group. Next slide So to kind of understand how access control works in this context, like we said before the idea of each box is what we use to read and write the messages to each specific box And the way that we compute that ID is actually that we derive it from the MLS key schedule. And the consequence of that is that you can only derive the box ID if you're actually in the group at that epoch And as a consequence, only members that are actually in the group are able to compute the box ID They're the only ones that are able to send in receive messages to that group, because if you, you know,"
  },
  {
    "startTime": "01:20:02",
    "text": "And as a consequence, only members that are actually in the group are able to compute the box ID. They're the only ones that are able to send in receive messages to that group. Because if you are removed from the group and some commit, then you're not going to be able to process it. You're not going to have the key sketch for the next epoch with the group and your next going to be able to commit the box ID and you're not going to be able to sit or receive messages to the subsequent epoch, and you're going to be locked out. So that's how that works. Next slide So to really talk about why this helps with invalid commits, commits, because we allow these different branches of the group to exist, users can change to follow these branches if they actually want to process that commit But in practice, you know, users are going to choose one commit free Cheapog and they are going to process that and they're going to follow basically a linear series of epochs through all of the branches, which means that all of the branches that correspond to invalid commit users are never going to actually access Next slide So, and then why does this help with spam filtering or spam deletion? Because when users send invalid commits, they create a fork. Like we said, any user that isn't actually interested in that fork isn't going to you know, follow that path. They're not going to download that box of message and they're never going to access those boxes And of course, the hub can actually see that through traffic analysis The hub can see that, you know, some users simply to commit, they created Box D and they never sent any messages to it and no one else ever requested Box T that, you know, some users sent to commit, they created Box D and they never sent any messages to it, and no one else ever requested Box D. So that seems sort of reasonable to conclude that that was a spam message and that nobody's actually interested in that. So we can go back and delete that later Next slide So to actually get to the privacy part, like I said, this is not really related to privacy It's more so related to how can the delivery? service not have a prescriptive view of the commit messages that get sent to an NLS group"
  },
  {
    "startTime": "01:22:02",
    "text": "and of course when the delivery service doesn't actually need to inspect commit messages you can encrypt them. And if handshake messages are encrypted in MLS, that restricts the visibility that each participant has into what's in the group. So if you look at this diagram, if we start with the hub, the hub holds all of the messages for the group The only thing that the hub is the about the group is the blue arrows that are going to directly into the hub. So the hub can see that its own user users A and B, are interested in participating this group So then the hub knows that those users are probably in this group, and the hub also knows that, you know, service provider 1 and 2 are interested in this group But it doesn't actually see anything about user one or two, about the users of each remote service provider it just see sort of aggregate data from each remote service provider in the case that handshake messages are encrypted Next slide So also it was brought up on the list that because you have to process each box one at a time and you kind of have to follow a you know, a series of jumps through each box You have to fully process one box and process the commit to compute the box ID to download the next box that could potentially create a lot of round trips where, you know, if a user has been offline for a long time, then they come on online it could be a lot of round trips to actually go through and get to the most recent stage of the group rowan slide 10, you show a fork and so it's unclear to me how you pick which so here you've got the hash of a is b and then the hash of B refers to C or does it refer to D or E? How does that work? Why does the, why does the hash of B? refer to C and not D or E?"
  },
  {
    "startTime": "01:24:02",
    "text": "in your in the slide you were just on? So each box has a unique ID and that ID is computed as a secret which is exported from the MLS key schedule in the epoch that the box represents. So in this case, B represents the secret which is exported from the key schedule in the epoch for whatever message Yep. Yeah. So in the picture that you just showed, I think slide 15. Right So you said, so in answer to a concern that I had about excessive roundtrap Right. So you said, so in answer to a concern that I had about excessive round trips. So slide 15, I think it was, the slide we were just on on So, thank you. So how does this, so either the request is asking for the hash of the box ID or requester is asking for the hash of the, the hash of a box ID or it's not? right? Okay, so let me talk through this So, like I said, because you have to kind of jump through different, you know, a series of boxes to get to the most recent state of the group. If a service provider is confident because it's interacted with other users that, you know, some series of epochs are going to be requested one after the other. You can provide them proactively. So if a user requests, you know, box A, and you're pretty sure that the next thing they're going to request after they finish processing A is B, you can provide box B. And how does it know that? Because it can't calculate the actual box ID? No, it can't calculate it, but it does, you know, interact with users requests within the group. So whenever someone sends a commit, to box A, they also tell the search the next box that I want to create is called box B And so if there's only one commit sent to box A, the logical conclusion is that the next box that the person is going to want is box B. So in other words what you're saying is if there are no forks that this proceed normally, but if there is a fork, you can still access that correct, the"
  },
  {
    "startTime": "01:26:02",
    "text": "you're saying is if there are no forks that this proceeds normally, but if there is a fork, you can still access the correct, from the client's perspective, the correct fork Yes. Right So the way to think about this is kind of like an HGTP2 push So when a user request one thing, and you're pretty sure that they're going to want other things, you can kind of provide the other things that they may want proactively. And it's not like a requirement that the user actually go through and process all of these things. Like you don't have to actually 100% know that this is the next thing the user is going to want and they're absolutely going to request it and you're going to force them the process it. You can just provide it. And if they actually end up wanting it it's already there the only sort of caveat is that you have to hash the box ID for boxes that haven't actually been requested yet And that is to avoid leaking box IDs at the fee might not actually know because if the user was removed in one of these boxes and one of the commits in one of these boxes, they're not going to be able to keep processing in the group But if the handshake messages are encrypted, you won't know that So that's why you have to do that. Bingo Just a clarifying question about that Can we look at slide 10 again? I want to make sure I understand the answer. And I think what you're saying is that basically like in B, there's there's base like B prime and B double prime. Like did the different perspectives on B from the from different clients depending on whether they treated the commits as invalid or not. Like, and so there's different, uh, different clients that treat some of those commits as invalid will have like different perspectives of what B is and therefore follow this exported key schedule link to different boxes exactly. Yeah, this kind of accepts the possibility that some users will have a different view of what the valid commit for each epoch is, like which they'll have a different idea of which commit they want to process, and then which box they want to go to after they finish process B"
  },
  {
    "startTime": "01:28:02",
    "text": "Of course, the catch is that, all of the honest correctly implemented clients will always choose the same commit to process. So all of the honest correctly implemented clients will always stay together and always follow the same commit The only people that branch often actually follow other branches are people that are either malicious or buggy I understand. Thank you And I think that that last slide was actually my last one Yep We have about two minutes before we're supposed to move on, so please keep it brief. Yeah, so I just wanted to confirm, like in this functionality privacy trade-off here it seems like in this scheme, the only thing that the server does is apply access control based on these box IDs So you can't do something like have the server enforce a ban or have the server facilitate a joint of a new device, because if you're going to do that, you'd have to distribute your group info which would leak the like a bunch of stuff Is that a correct assessment of what the server can do here? here? um so the first part where you said the server can't help assist a ban, that is correct. So in this model, all of the policy enforcement is on clients Clients have to enforce all the policy. So if you, you know, see a commit which adds someone that you think is banned, what that means is that you would ignore the commit and you wouldn't process it and you wouldn't go down the fork where that user has been added to the group. The second part, you see commit, which adds someone that you think is banned, what that means is that you would ignore that commit and you wouldn't process it, and you wouldn't go down the fork where that user has been added to the group. The second part you said, which is that the user can't, or that the server can't facilitate an external join, that's actually not true Because in this model, this is indifferent to whether or not handshake messages are encrypted or not. You can encrypt them or you cannot. And if you don't encrypt them, then you can support external join still and you can do that Okay, sure. Anyway, question for the group just folks for folks considers, like, given that summary of"
  },
  {
    "startTime": "01:30:03",
    "text": "the functionality, is that a good tradeoff for the group to adopt? Yeah, I'll try to be brief and I guess Cameron is also going to touch on that and what Richard just asked, but maybe to, maybe you can give us one example Say I have exactly one client, one phone And I want things to be private So I want to have encrypted hand check messages And now I have a bit flip on my device So the consequence of that with the MLS, of course, is that I can't really decrypt messages, but on top of that, I can also not even go fetch them from the server because I cannot calculate box IDs anymore What are my options? as a user? You ask, what is your option? for doing external rejoins if you don't know the box ID? Well I mean let's just say how a bIETFlip on my device, right? I'm in a group chat and now I don't receive messages anymore because I cannot even go fetch them Like it goes silent, but somehow I know that that cannot be right, but what are my very like in practical terms, what are my options? to get out of that mess? Sorry, Raphael, can you just repeat the last thing, the last sentence? What are your... So, yeah, sorry So my question was about the user experience here I have a phone, like it's a single client I'm in a group and I have a bit flip in the state that is on my device So the immediate effect of that is that I cannot, no longer decryd messages and that's always true for MLS But on top of that, I can also not fetch new messages because I can no longer calculate the box IDs And my question was, from a user's perspective, in terms of user experience"
  },
  {
    "startTime": "01:32:02",
    "text": "what are my options to you know into that group again? Got it okay, sorry. So your options there if your state are complex or if your state is corrupted, you would just do an external rejoin to the group and you would join the most recent version of the group, which you can still do, you can send an external commit with the group info, and not know the box ID and just have the delivery service add your external commit to the most recent box. So you don't have to know the box ID. The DS can do that for you without knowing that But so, but we want to use encrypted and uncheck messages right, for privacy reasons. I mean, that's the whole purpose here of doing that. So where does the um how does the external join work like in very practical terms? How does the server know the ratchet, etc.? Well, if you have encrypted handshap? messages, then you can't support external joins So essentially, it comes down to having a choice in that particular situation between having metadata privacy or having the functionality, right? I think so, yeah. I mean, it's possible to like make a new extension that like maybe helps that case. But right now, yes that would be the trade-off so this is what the entire next presentation is about so do we need to go, could we move on to it? Well, I'm just going to add one, a variation on what Raphael said, which is even if it was public message and there are multiple there are multiple forks. How does the how does the DS know which for to give when it's asked for the group info? well it's dealer's choice essentially so in other words you have indeterminate indetermine behavior Non-deterministic behavior I'm sure implementers will love that. Thank you Thank you very much Conrad, you're up"
  },
  {
    "startTime": "01:34:05",
    "text": "Okay, thanks Yeah, so last and the last meeting I promise to you know, since we had these two, competing metadata concerns approaches, on the one hand-check message encrypted handcheck messages, on the other hand-hand-hand-shake messages, on the other hand-hand-based approach to go over the Mimi features or the features that we talked about in the past and see which of the features works or doesn't work with which of the approaches to caveats right of the bed I just realized that when exporting slides from Google slides, you also get as a PDF you also get the kind of slide that you chose not chose not to show. So there's, we might have to skip a few slides And also, I think it's worth and I didn't do that it's worth differentiating as Brandon also pointed out that we have uh we can do in crypto hand check messages and we can do pseudonyms and then in addition we can use this kind of this approach to handling invalid commit messages that Brandon just proposed with this you know, I don't know, how do we call this approach? Would be good to have a name for it. Brandon, do you have a do you have a idea what to call it? the boxy approach kind of thing, which? the box approach, okay, for now um so we have chris box approach um that we could use both with you know, both with the baseline Mimi Pro maybe protocol that we have right now where we use user identities and there no metadata direction. We could use it with a pseudonym approach. And we could also use it with the encrypted handcheck approach approach"
  },
  {
    "startTime": "01:36:02",
    "text": "And yeah, in these slides, I haven't really differentiate between the hand check approach and encrypted hand check messages approach with the box epoch thing and I haven't looked at them independently So I'll try to break that down when I get at the slides Okay, let's get started finally. Next slide, please okay so just to kind of start by looking at the approaches and I want to roughly kind of say how they protect metadata or which parts of the metadata they protect. So starting on the left, we have the base I want to roughly kind of say how they protect metadata, which parts of the metadata they protect. So starting on the left, we have the baseline, which is Mimi Protocol right now. It leaks wherever say how they protect metadata, which parts of the metadata they protect. So starting on the left, we have the baseline, which is Mimi Protocol right now. It leaks where every message leaks the group ID, it leaks the epoch If you have the baseline, which is Mimi Protocol right now. It leaks where every message leaks the group ID, it leaks the epoch. Um, if you, um, if the, the hub keeps track of the the hub can keep track of the group state, so it leaks the identity of group members to the hub, it leaks the identity of centers of messages and leaks, uh, group operations if a center doesn't add or remove, you know, the hub sees all of that. So that's kind of the baseline that we have right now in terms of metadata protection is not great. So then kind of as a next step, there's this Mimi approach, which is the pseudonym-based approach. Still leaks the group ID with every message, still leaks the epoch But now it only leaks the per group pseudonyms of members it only leaks the per group pseudonyms of message senders, and it only leaks pseudonyms group operations, so the hub can still see what kind of, if there's an ad operation or remove operation, but it cannot really see which real identity is targeted. You can only see this pseudonyms and then finally there's the encrypt the hand check messages approach which with every message really leaks, only leaks the group ID, and it leaks the epochs And I, Ron, just giving you one second. I didn't differentiate here between, I'm saying it leads to the hub and depending on you if you use the semi-private message that you proposed, it might also"
  },
  {
    "startTime": "01:38:02",
    "text": "lead to the followers or not, but we might get to that later a bit. So it's you, if you use the semi-private message that you proposed, it might also lead to the followers or not, but we might get to that later a bit. So there's a bit of nuance depending on how you use it exactly Yeah, yeah. All I was going to say is that under baseline here that actually you could sort of split it out into a into of two or three different variants where you can still use, you can use pseudonyms with baseline, which is, you know baseline is basically what's in the draft now Baseline with pseudonyms is mentioned as an option in the draft and then semi-private messages is listed is a PR off of the, off of the Navy protocol, which leaks the identity of the pseudonyms to the hub right? So it, it is, there's like a nice space there. Thanks. Yeah, if you go to the next slide we can we can actually see the spectrum i think yeah so this is the taxonomy Run, thanks for the feedback on the slides at this point So this is, I think Richard kind of proposed this way of splitting up the metadata privacy tier just to go over it again because I think it's important. We know what we're talking about So based on this hub and followers can see everything, then the second one is the essentially baseline with pseudonym as Ron just said where everyone just see pseudonyms instead of real user identities. Then the third one is the same as two, but now messages are additionally encrypted to the hub so that everything is hidden from the followers and the followers cannot essentially see anything except for the epoch and the group ID And then the fourth is that we kind of extend this encrypt to not just the followers, but also the hub So it's a kind of graded approach here. Okay, next slide please Thanks. And so this is kind of what I wanted to go into detail a little bit about and then maybe we can have a discussion about kind of functionality and what we want in terms of compromises between metadata privacy"
  },
  {
    "startTime": "01:40:02",
    "text": "on the one hand and kind of the functionality on the other hand, what kind of features we want that stuff. So go through it again So in the baseline, we have both push and pull architectures and by that i mean the hub could push to the followers, but the followers could all pull messages from the hub and pull architectures and by that I mean the hub could push to the followers but the followers could also pull messages from the from the hub essentially both might work. I don't think we've decided also pull messages from the, uh, from the hub. Uh, essentially both might work. I don't think we've, uh, we've decided on any one of those and also in the baseline approach it allows to server-assisted joint, external join. It's because the server sorry, the hub can actually track the group state and if someone comes and wants to rejoin the group for whatever reason or join the group for some reason, the hub can provide a group info, can provide a ratchet tree and help that client actually join the group without any intervention from an existing group member And then thirdly, we can inform any sort of policy on the hub because the hub can see all of the messages Then kind of going one gradient up to the pseudonym-based approach, it's essentially the same as with the baseline you can do push and pull architectures You can still do services to the external join. There's a slight caveat because the hub doesn't know the real identities and so if a new client comes in and wants to join the group the new joiner has to somehow learn the mapping between the pseudonyms and the real user identities so they can actually know who's in the group and since we encrypt that so the hub doesn't know it the new joiner needs some sort of key material. And so the new needs to be some sort of involvement of off actual member of the group It's not like again, it allows the assisted join, but again you need some sort of key material in addition And then finally, uh, in the pseudonym-based approach, there is a way to enforce policy at least partially, given that the hub"
  },
  {
    "startTime": "01:42:02",
    "text": "cannot see the real identity of the members So as we will learn in a couple of slides, for example, a ban cannot really be enforced on the hub because the hub doesn't really see who's trying to join the group. And then finally getting to the very right, the encrypted hand check messages approach and here I wrote, it requires a pull architecture or a subscription-based architecture. That's because I assume that with the encrypted handshake messages approach, we're also using the kind of boxy epoch thing, which doesn't really allow you to push out because the server doesn't, has no idea who's actually in the group, and it needs the followers to go and fetch the messages for the users of the followers that the followers know are in interested in the messages from the group. And then finally, as we just discussed that raffelle noted and wrong noted that there's no services that external join possible if you encropentgic messages because this hub cannot keep track of the group's data and not help new clients actually join the group because it doesn't have the necessary information and finally there's no policy informant on the hub because the hub doesn't really see what's in the messages and who's adding whom or who's removing whom and that kind of stuff Okay, next slide, please, and I think we have to skip the next one Yeah, skip that one please That was not great of visualizing stuff. Right, so I looked at a couple of features. Those are taken from the from the spreadsheet I can't remember who compile it but it went around the Mimi list Yeah, the matrix team, yeah Okay, thanks. So yeah, this is thanks to the Matrix team who compiled this list of you the matrix team yeah okay thanks so yeah this is thanks to the matrix team who compiled this list of they went to the kind of DMA gatekeepers and looked what kind of features they would support. And so I went through these features and tried to see if we can still support those if we have this one of these two metadata uh, reducing approaches. And so just to list them real quick, there's direct invites"
  },
  {
    "startTime": "01:44:02",
    "text": "so a user invites another user to a group then there's invite codes uh where a user creates some sort of code that allows another user to join the group. But in this case, in contrast to the direct invite, the user who creates the code doesn't necessarily know in advance who is going to use that code to join the group Then there's third party invites, which is kind of a variant of invite codes where the invited user could also be some from another platform. This, I think, appears most as kind of guest rooms and current keykeeper platforms, but yeah, but not super sure about that Then there's a ban so that users can users can ban other users and then somehow it's enforced that that user cannot rejoin the group kick, users can kick other users of the group Next slide, please Rowan, yeah. Yeah I just wanted to mention that I think it is a pretty strong requirement for the larger providers to be able to not just have a user ban someone from a member ban a user from their group but also to be able to have the hub provider say, I've seen enough reported abuse that I want to ban this user in all groups, and I want to remove them from all groups I think that's a really critical requirement and we need this solution to, you know, we need the Mimi solution to be able to do that or we need to come up with a reason why we can get how we can get similar abuse, strong abuse, prevention without that. Thanks thanks yeah thanks um we'll let conrad get through to the end but if any if people disagree with that, it would be really useful like today's the data to state your disagreement"
  },
  {
    "startTime": "01:46:02",
    "text": "Right. I mean, this kind of the, there was kind of the purpose of this uh of these slides to kind of elicit that you know make people come up front and say what kind of features they want that they think it's important So thanks. Yeah, so just go through the rest limit who can post and send So this is essentially allowing users to mute one another then edit delete other users post is kind of self-explanatory Access control, there were a bunch of features that I just decided to group under access control You can look at the sheet the sheet to to go into details but I think for the purpose of metadata, of looking at the approaches and what you can do with them, I think access control is a good catch-all term. Yeah, Benjamin I'm sure you all have had this conversation a million times, but the idea that for abuse prevention, you need the ability, the hub needs the ability to identify individual users of third-party platforms and selectively ban them is fascinating, at least, and a little scale more than a little It changes the nature of the relationships here significantly, where instead of the providers having relationships with other providers and their own users, now the providers have relationships with the other provider's users as well. Potentially as a provider, I need to have opinions about the individual users of other providers, which is a very strange concept because I have no idea how their account mechanism works. I don't know if this collection of handles associated with some other provider actually represents one user or a credit"
  },
  {
    "startTime": "01:48:02",
    "text": "card or a postal address or like what the account creation restrictions are what their rate limits are, are these ephemeral accounts that on and on. Also, it raises a bunch of really interesting policy questions Like, if I have this about, to create this kind of, uh, of, uh, control, then do I incur a response? to exercise? this access control? I think as a provider I would actually feel more comfortable if I had no technical capacity for that and could very cleanly say to anybody who came along, that's not my user. Go talk to their provider Just a quick response to that If you're a hub provider, and you have a policy that if you have a group for a group for you know, discussion on some topic and the policy of the group is that you're not going to you're not going to share pornographic material That's perfectly legal and might be accepted on the hub on a different room. But if you have a, if you have policy of the group is that you're not going to share pornographic material. That's perfectly legal and might be accepted on the hub on a different room. But if you have a user who keeps you know, who does that maybe repeatedly, to say that the hub has no ability to remove the user from other, from other room in their on their system I think that that's, you know, I think that I think that's a perfectly reasonable thing to do. We're not talking about saying you have to go delete delete this user in other rooms on other hubs So I think there is a version of this that maintain the CSSC architecture, right?"
  },
  {
    "startTime": "01:50:02",
    "text": "where essentially I file an abuse report back to that provider. So this user appears to be misbehaving. I really don't want to do business with this user anymore That, I think, maintains the separation and potentially allows that provider to think about things like whether there's a cluster of abusive accounts here that it can identify because it has much more metadata than I do I would invite you to go and comment on the PR or to write a draft or to come see any of us that have been involved as authors in the hallway Okay Ben, do you want to respond? to your still in the queue or do we defer this? discussion to the mailing list and the PORs? Ben is out of the queue. Okay So yeah, there's only 10 minutes left. I really like this discussion so I'm not sure how we should proceed We can defer the discussion, but I'm happy to have it here since like I have a couple more slides, but questions yeah. I mean, anyway we really do want to get to the end point where we kind of make a decision or have at least like a sense of the room about you know, how people feel about the different options So we have, again, we have more time that we could use for that on Thursday. So if you'd rather do that, we can do that But the point, the point week is to start taking some options off the table here. Okay then I'll try to get through the slides and maybe we can either have this discussion then in the last few minutes or in the next meeting. Okay, so just to close on that, there's access control, kind of general terms here. There's auditorium rooms where users"
  },
  {
    "startTime": "01:52:02",
    "text": "can only see or identify a subset of other group members And then there's kind of means of limiting who can send what types of messages It's essentially both the same as access control So next slide, please Great So yeah, I try to color code here in terms of on the left, we have the different features and on the right we have the two approaches MMME and encrypted handcheck messages and I encoded green where i think it's really not an issue and red where it's an issue or at least it's an issue to do it on the hub So, for example, invite code would require the external join feature, which is essentially, which is as far as I'm aware, not really possible with encrypted handcheck messages So that's a no And then we have, in this case, the invite code with Mimi-me-me-me, I think should be possible even though you need the key material to identify we have, in this case, the invite code with me, me, me, I think should be possible, even though you need the key material for the new client to identify the group members You've just embedded in the link and then invite codes should work with a certain number-based approach approach So KIC should work in both cases BAM, as I said, is tricky to enforce and we can have this discussion later, but maybe if you, I don't know, if you have abuse reporting involved, and the reporter of the abuse, could actually, you know, reveal the actual identity and des pseudonymize the offending party or something along those lines. So I'm confident we can make something work there with encrypted hand-check messages I'm less confident. But yeah, don't want to go too much into specifics. Next step, please please Again, with the features on the left, side, this is mostly about access control or, you know,"
  },
  {
    "startTime": "01:54:02",
    "text": "visibility in the group with the auditorium and the main issue here with the encryption hand check message is again that the hub cannot release enforce any of this or be a part of any of this because it doesn't really see the messages And whereas in the pseudonym-based approach it's possible because you can, for example, assign roles to pseudonyms and then you can use it, you know, you can do access control just like you would do normal role-based access control Next slide, please And I think now you can essentially skip more or less until the end. I think these slides are just draft stuff yeah So can you go back one slide? Maybe there was, yeah. Okay, there's a brief summary. So both approaches limit mid-hide leakage clearly a kind of ingredients. Mimi to a lesser degree using the pseudonyms, encrypted hand-check messages are really good they almost completely get rid of the metadata then, but in both approaches, limit the hub capability to enforce policy and curtailed hand-check messages make it pretty much impossible MimiMi still allows it to a certain degree because the up conceded is pseudonyms. And then both of approaches also kind of limit the capability to perform services external joints. Again, encrypted-hentic messages kind of don't really allow that And Mimi-MeMe does require this additional key material to desudonymize the group members for a new joint And then the last point about restricting to a poll slash subscribe model that applies to encrypted hand-jerk messages, but it generally applies to this kind of box epoch kind of approach if we if wen lin the end want to use that to mitigate invalid commits of course you could use that from the me me or the baseline approach as well"
  },
  {
    "startTime": "01:56:02",
    "text": "And yep, that's pretty much all I wanted to say give a brief overview, kind of get a give everyone a feel for how the individual approaches kind of limit what we can do And yeah, want to encourage folks to come out with features that they think we should really have such as banning or uh Rohan mentioned, for example, being able to, if an account that gets deleted, being able to evict that deleted user from all of the groups there is and yeah maybe we can discuss those and see how important those are for this limited metadata leakage approach Thanks. Also, maybe no. Sorry, one last thing as part of the discussion. I think last time we also agreed that we might want to have two modes. So we could have a like a baseline mode for Mimi, which can do essentially everything. Then we have an additional kind of limited method mode, which can only do a subset of the function but it's better at hiding metadata just to kind of keep that in mind that there might be two modes that providers can opt into into Yes, so that's actually I think where I was going, which was I think, the sense that I've gotten from past discussions is that people want to have the two modes. So we would have a baseline mode, which would look approximately like it does now, and then we'd have a limited metadata mode And we've been talking a lot about what that, which approach would modes. So we would have a baseline mode, which would look approximately like it does now, and then we'd have a limited metadata mode. And we've been talking a lot about which approach we should take for the limited metadata mode. But maybe we can talk a little bit about that today. And then on Thursday, we'll can come back and allocate time to talk about the choice within the limited metadata mode So having the two modes is probably going to make a lot of sense I agree with that, but it does seem to have been the trend over time What a baseline mode looks like"
  },
  {
    "startTime": "01:58:02",
    "text": "though, should probably be open for discussion because one thing I noticed here is we're talking about obviously, Mimi is about using MLS and not to extrapolate this further, but it's noted in the MLS working group the baseline for MLS was signal And if we're talking about leaking more metadata than Signal, then we're actually overall reducing the security that we're providing So what that baseline should look like and how we can minimize it while providing the net functionality that everyone wants as the possible version and then having more secure version probably makes a lot of sense but we do want a decent minimum bound there versus the mass data leakage overall and can you if you haven't we do want probably a decent minimum bound there versus the mass data leakage overall and can you if you have an opinion right now say do the purpose group pseudonyms as the baseline meet kind of what you're thinking or is there some other option? you prefer? Great question So not to make you hate me, but uh so there is actually a somewhat third off option among these that have been discussed or fourth option So we had the pseudonym approach, obviously We have this encrypted handshake which is meant to keep everything out of the hub's hands We also have a version here where we use the semi-private messages that I think Rowan has a draft for and use that to encrypt to the hub, the handshake. So it's available to the hub but also not available as a mass metadata leakage And then there's like a two sub versions of that if we really want to have fun, where we can use that with a pseudonym approach and then have pseudonyms available to the hub, but not again mass on the wire. Now that just expand their space of options here, and as I said, it's going to make you hate me But there's a lot of variability here. I would say as a personal view, having a pseudonym approach or sort of encrypted hand going to make you hate me. But there's a lot of variability here. I would say as a personal view, having a pseudonym approach or sort of encrypted handshake approach would be the minimum bound so that there is would say as a personal view, having a pseudonym approach or sort of encrypted handshake approach would be the minimum bound so that there isn't stuff outside of what the hub can see"
  },
  {
    "startTime": "02:00:02",
    "text": "Thanks. Rome Yeah, so, I mean, just to be clear my proposal has been that using the choice is kind of available to the clients if they want to use semi-private or public And if they want to use a pseudonym in that in a particular room. But if you wanted to make it simple you can make the recommendation just use it per group pseudonym unless unless the user takes explicit action to say, no, I want to be correlated with, you know some specific permanent identifier So don't walk away, come back So in the case where you leave it up to the client, then there are quote unquote baseline doesn't have any of these metadata limiting features. The baseline is the hub has to support the semi-private message in it and and you know it like basically as written as written in the protocol, it works fine with pseudonyms. So it needs to continue to work fine with pseudonyms right but what i'm saying is that uh protocol it works fine with pseudonyms so it needs to continue to work fine with pseudonyms right but what I'm saying is that what it sounds like to me is that the the the is, can a client or can a can a service choose on behalf of its clients that it's used? this baseline that doesn't have that doesn't take advantage of semi-private messages or or pseudonyms? uh i mean i think i think what we're talking about is like basically a mandatory to implement kind of level thing. Is that kind of what you're talking about? Well, this is what I was trying to elicit. It's like, are these things, are these things mandatory to implement or is one of them man? mandatory to use at a minimum I'm not, I actually don't have a strong opinion on that. Okay. I think we definitely need mandatory to implement okay um Conrad and then Raphael and we're over time so Yeah, I, in principle, I like the idea of having this hybrid mode where clients can decide or providers can decide what they allow in terms of"
  },
  {
    "startTime": "02:02:02",
    "text": "you know, a student-based approach or real reality-based approach. I'm just going to say, like, even if you may that optional, the student-based approach you still need kind of the machinery that the student-based approach needs in terms of desidonomizing folks and having these kind of functional, functional audit around there so i'm not sure that's really what we want in the end, but yep, just wanted to know that Oh, yeah, very quick final notes going back to what runs it, I think the semi-private messages, it's still a great concept It's somewhat orthogonal to the pseudonyms and unless we run into some very specific problems I think we should make that the baseline for sure Personally, I'd also be inclined to say, we should use pseudonyms as the baseline and then see how we can solve some of the problems we still have. Like if ban really is something we need to address then we need to find a solution for that But going back to what British said, I'm out for raising the bar for the baseline Great, thank you. Okay, we'll kind of figure out how to structure the rest of this discussion on Thursday So thank you, Conrad. And thanks everyone. See you back on Thursday. Thanks, Tim Here grab a bottle, and you're on the toilet Thank you"
  },
  {
    "startTime": "02:04:01",
    "text": "Thank you Thank you very much"
  }
]
