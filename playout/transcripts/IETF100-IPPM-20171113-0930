[
  {
    "startTime": "00:00:04",
    "text": "this is Prague as you can see the you know it\u0027s really it\u0027s a meeting room and the same windowless thing in the basement anyway yeah so this is clearly IETF 100 and Singapore and today is Monday the 13th November 2017 um Phil couldn\u0027t make it here so I\u0027ll be running the meeting this is a ATF working group meeting IETF IP our rules apply this is the note well if this is your first IETF meeting and this is your first session of your first I usually do these on like on Friday so it\u0027s like it\u0027s all yours I know well if you haven\u0027t seen it by now than it yeah so it\u0027s actually entirely possible that you haven\u0027t seen the note well by now so if you haven\u0027t I\u0027m actually just gonna keep talking louder until um everybody gets quiet enough that people can hear so I mean I am amplified I nice thing about having the mic up front is I can actually get louder and louder if you do want to have side conversations there are hallways can take it outside please thank you so um this is a important group meeting this is the note well these VIP rolls if you have not seen this these are kind of important please go have a look at RFC 53 78 RFC 81 79 um so working group status um since Prague hey we\u0027ve reach our turd um welcome to all the I am IO am folks in the room we are happy that you have a home with us here we published 8250 and we\u0027ve got uh three um drafts that are basically ready to go model-based metrics is in the RFC editor queue I saw there is one more update to that is that editor comments unsurprising um and we have one in I used a evaluation the alt mark graph that\u0027s I think that\u0027s on the telus at after this meeting there was a one comment and then an officer review that came in bit delayed that after the idea of 100 and we have 2905 which is in need right upstate and then it goes the um al Morton we\u0027ve got a write-up I mean Nalini prepared it she\u0027s our document volunteer document shepherd okay and we\u0027ll see the status of that in a minute okay beso is I didn\u0027t see in the data cracker so it\u0027s in there okay since the since I did these slides probably then okay cool that\u0027s not working okay right "
  },
  {
    "startTime": "00:03:04",
    "text": "it\u0027s a Mac it\u0027s not focused follows mouse here\u0027s today\u0027s agenda we\u0027ve got three working group documents twenty to thirty ipv6 the the update modernization event we\u0027ve got the two registry drafts which we\u0027ll be talking about together and then we\u0027ve got IOM data Frank you said you needed five minutes but I\u0027m giving you 15 because it seems like we might actually want to discuss a couple of things there yeah then we have individual contributions um so the IP PM advanced routing Gregg\u0027s two drafts on stamp and then this is the port key lamp test update where we\u0027re also going to be talking about to amp yang correct that\u0027s right so so if you want to do that at the after the individual contributions we could but it\u0027s really all about Greg\u0027s comment to the yang model shepherding form great which clarified the text of the portrait so you want to move that up too so yeah let\u0027s move to working group documents let\u0027s bash it up to right after IOM data then yeah okay that\u0027s done that\u0027s but that\u0027s probably still five minutes yep cool then we have a relatively long lightning talk queue but it looks like yes since we\u0027re starting on time here we\u0027ll probably get to all of these Onis he tells name there so thank you very much Tala for taking minutes if we have one remote so if we get somebody who\u0027s already on Jabbar - Jabbar scribe in case of the me deco doesn\u0027t work there anybody our neon driver probably not you\u0027d otherwise you\u0027d show up in the thing there re both will assume that me deco works then so with that Vinnie ak okay so I\u0027m going to be presenting the ipv6 update two two three three zero so this was this next since this was necessary rate by it comments by Fred and what it defines and rank of intent what it defines his standard form packets what should be like a valid measurement packet and the results are depending on what kind of packet a measurement type packet do you have so we call it abstract um packet of type P so this I\u0027m going through the initial sites quickly because this hasn\u0027t presented in the working group for quite some time quite some time before so ipv6 "
  },
  {
    "startTime": "00:06:04",
    "text": "ipv6 is currently out of out of scope for RFC two-30 IP VM framework so the idea was to write a draft that gets it into the tooth 83 0 format and and defined the same as as I mentioned trigger was input by brand carpenters in know ipv6 coverage so ipv6 support by PBM was also sorted heat it up and this is that draft so it has been adopted to the working group item in delayed to zero one six x fred by Markus Marius so so the night I ate if 99 meeting there were bunch of open topics handling of large packets in ipv6 which leads to fragmentation the extent of coverage for six low and ipv6 header compression I think this was suggested by a Spencer and then there was a discussion about the theoretical concept of a minimum standard form packet and the way ipv6 header treatment is done in Indian intermediate and so those of you who are subscribed to the IETF discussion mailing list and I think v6 ops if I\u0027m right and there was a lot of heated discussion about how to how to handle extension headers whether they should be touched by middle boxes or not and that has a direct impact on how the measurement has major measurements are done and you know it affects a measurement so okay so the so we have decided that fragments are not standard form and use the same kind of handling that we have for IP ipv6 that we have ipv4 as well and for measurements we will have non fragmented packets yeah and that also means that if we if we do not adopt this we\u0027ll have to review and update existing IP PM our metric RFC which is what we don\u0027t want to do at this point in time so since the last working group as in the major change was the suggestion of 600 and 6 lope and so we were locum and me and the other co-authors actually went up and looked at 6 low 6lowpan related routes and we realized especially the header part whether it is header compression using slack or I think if I remember I\u0027d shake it actually debates it has some it deviates from the ipv6 header format quite a bit also there is some amount of local knowledge that is stored in the "
  },
  {
    "startTime": "00:09:05",
    "text": "end node to reconstruct the header information and we that if you want to address excellent 6lowpan rather than do it in this rough we would probably want to have a separate draft that looks at six learnt 6lowpan so move it out just as we have done five maybe six so that seems like a better approach of handling things rather than cramming everything into this draft which looks at ipv6 okay um so this is like the minimally standard form packet so we have removed a definition of minimal standard from packet 5p v6 and ipv4 and because mainly because there has been no usage of it of the concept in practice yeah yeah so this was the other big topic which was the treatment of treatment of extension headers so there are two camps in in six one is to allow extension headers and letter middleboxes touch it and other ones other camp says you know you should not touch it at all because it violates so there are I think as far as I know there are implementations of both in the field so there is no consensus honestly on this so the best after a lot of debate and discussion about this video we thought that it was best to point out the challenges and the drawbacks and then leave it to the implementers to actually figure it out what what works for them because as I said like we have both implementations in the field and there are there are challenges in the way which extension headers are done especially the middle boxes projection errors that can lead to excessive processing time which means the measurements are affected so we thought that we pointed out in the draft and move on from that topic so this is a version 2 of the rename draft this stuff has been around for a long time it results all the open items all of the comments that were there on the list and the WG Elsie has started and ended as well the tract is considered to be stable and all of the open requests have a handle there is no additional feedback WLC so I think I think we are good to go so if you have any questions I me and some of the co-authors are either we\u0027ll be happy to answer any questions if you have yeah any questions on this draft how many of you have read the draft "
  },
  {
    "startTime": "00:12:05",
    "text": "[Music] [Music] Noemi Elkins I didn\u0027t want to make the point that we need we do need to write the an add-on 6 low draft I know Vinayak said that but that\u0027s something that\u0027s additional work [Music] probably have another draft soon on that but the intention is that we\u0027d like to extend this do handle six all as well yeah so the other question is whether six low and 6lowpan does fall under the purview of IB i ppm that that is that is the question I would have to you as well if it does then it would make sense to extend this and you know handle all of the like the header compression is that one of the biggest things that raised 70 parts the real question to me is did is their demands to actually do measurements with IP PM protocols for 6lo and as there are demands to use this framework to describe measurements in 6lo environments and if there is then we should write the draft and if there isn\u0027t yet then we should probably not worry about the draft until there is because it doesn\u0027t seem like it seems to me just the amount of work that you\u0027d have to do you have to go and understand 6lo and you probably want the people who want to do the measurements with the stuff to to come in help so that\u0027s about it very valid question so it did come al Morton it did come to Al Morton\u0027s attention that there were some folks who were making measurements more of the IO and M milk on a six low kind of wireless networks and I think the work that\u0027s being talked about here is just defining what is a standard form packet for these reduced rate etter sized compressed things right and so it\u0027s it\u0027s just I think it\u0027s just that additional work that has been the asset okay so I mean yeah if there\u0027s if there\u0027s interest in doing the work and there\u0027s interesting using the work then yeah go ahead and do it send up a draft and we\u0027ll adopt that clearly yeah but okay thanks so this is hold on let me come over here and have a look at this draft and so working group last call is done it needs so it needs a shepherd then right I mean we\u0027re done we have no Shepherd dot dot sorry let me be more explicit about this question would anyone like to Shepherd this document through the process who\u0027s not an author preferably I sorry I saw one hand in the back who\u0027d read it start there yeah so we\u0027re basically looking for someone just to do a quick a quick write-up of sort of the process in the working group and um so that we can send that up so "
  },
  {
    "startTime": "00:15:08",
    "text": "that\u0027s bencher can read it and say okay yes this looks like everything has happened um anyone going once going twice okay anybody who\u0027s looking at me is gonna get the Neville is going to be the document shepherd for no sorry actually it\u0027s been a while since I\u0027ve done one of these so I\u0027ll just go ahead and I\u0027ll just go ahead and I\u0027ll do this all right so this document now has a shepherd and I\u0027ll get it right up done probably not this week and then we\u0027ll go ahead and send it up to Spencer cool so next [Music] good morning everybody I\u0027m al Morten and we\u0027ve been working on a registry in the AI ppm working group for a long time and this is actually the this title slide for the initial rent registry contents which I\u0027m working on with those stately gentlemen next slide but the the registry format is in this draft and and this time around almost all the changes were in the initial content so when I put up first there\u0027s always some implications for the registry format so we\u0027re just going to take that ahead please go alright very quick summary the problem was how do we summarize our metrics in a very precise way we defined them very flexibly in AI ppm that was the intent but when we want to use these things for very precise comparable measurements sometimes with great implications like comparing service providers for example then we really want to nail down what\u0027s exactly being done so we\u0027ve we\u0027ve got a registry that helps to do that we also provide unique IDs and detailed exposition of the methods and the metrics and so forth lots of references next slide please so here\u0027s a quick summary again this is how the registry concept was constructed we\u0027re up to version 13 now and so each entries a row and each row is indexed by an ID we\u0027ve got control and reporting protocols using a URI or the ID to identify the metric they\u0027re measuring and the next slide shows the categories and column headings thank you so here\u0027s how its organized summary metric definition methods of measurement output an administrative info those are all the categories and you can see the important stuff that sneaks in here now that the IDS the names the URIs which include which include a name and a URL and then we have the metric definition with an explicit set of references and then we "
  },
  {
    "startTime": "00:18:09",
    "text": "start to talk about fixed parameters the parameters that are absolutely going to be they were completely flexible in the standards but now we\u0027re going to nail those down to numeric values typically for the measurements that take place the same thing happened with the methods of measurement we\u0027ve got parameters there and so forth that those are now nailed down and then eventually we allow some parameters to be flexible what we call runtime parameters okay so there\u0027s then the outputs every kind of result of the metric is going to be nailed down and that\u0027s an explicit list of things typically in the output there may be a reference method for calculations there as well and the unit\u0027s a method of calibrating the metrics if we have that administrative in info and comments next slide okay so here\u0027s the updates basically we\u0027ve replaced the Poisson I said I said what\u0027s on there it is why Sarah hates when I do that so it\u0027s place\u0027ll we\u0027ve replaced passant with periodic metrics and that happened in several of them there UDP round-trip delay and loss so new metrics for ICMP this was a request from the last meeting that\u0027s all in section 9 it\u0027s all going to be round-trip delay and round-trip loss obviously we\u0027ve got these statistics the min and the max and the mean but I had to come up with a new sending discipline this is like this is this is the sort of the third thing beyond what\u0027s along and periodic and a lot of ping tools use something like a send on receive I built this out of the periodic stream and and with a max waiting time built into that as well and and so that should match what most ping tools do next slide ok so you can quickly see how we\u0027re mocking up the most important parts of the registry there and they are the names and the URIs and description you want to be able to read this from the back but you can see how the name changed when we change the sampling discipline it\u0027s now periodic instead of a song next slide so here\u0027s what happened with the registry format we we had to update the registry that\u0027s got the elements for naming so fortunately we already had ICMP and TCP but we\u0027ve added the units of packets and packets per second and in the output category we\u0027ve added count and I already mentioned send on receive that\u0027s also going to be a name element for the sending discipline next slide so we\u0027re up to slide 9 now for those playing at home so this is a look up look at the mock-up of the metric naming sub registry which we\u0027ll use to help us name things unambiguously and they will all have good definitions and descriptions "
  },
  {
    "startTime": "00:21:09",
    "text": "and so forth and you\u0027ll see today how we\u0027ve reused a lot of these round-trip delay and loss metrics next slide so the previous to-do list was a question about the name element sets do they cover passive elements are well enough and that that question asked at the last meeting got converted it into a request to prepare a new passive metric for TCP round-trip time and so we did that we actually did a set of those and that\u0027s in section 10 of the document now so Brian provided extensive references for that on the list and I really have to say thank you because I learned a lot about passive measurement from from reading those references i\u0027ve always been an active guy but but you know we\u0027ve we\u0027ve but you can see where the interest is because this is where we\u0027ve actually gotten some comments now so it\u0027s it\u0027s kind of cool next slide so the passive metrics and this is where I want to spend the most time that\u0027s why we\u0027re rushing ahead here we now so we\u0027re fairly sure that the registry accommodates passive pretty well just because of the way that the naming work we had we ended up some with some new name elements of course but that\u0027s fairly routine every time we look at a new class of metrics we found you know a couple of things that had to be added to the naming element so that\u0027s why we made that a separate sub register it\u0027s working very well so here\u0027s the new metrics round-trip delay passive IP TCP the RFC that specifies the metric it\u0027s going to be in seconds as the units and then there will be separate ones for each of these statistics Mean Max and the minimum and then will us as just a packet and account of losses I think that\u0027s the best way to go with this so our next slide Brian so here\u0027s the game board when you\u0027re measuring TCP round-trip time we\u0027ve taken the position in this method that you are a sort of a mid path observer and according to Brian\u0027s reference they\u0027re in line data integrity signals for passive measurement that means that you have to split the round-trip time measurement in half so you measure the reverse direction and the forward direction you\u0027ll end up adding those together so fortunately we\u0027ve got composition functions in an IP PM we can we referenced things there to be able to put these two measurements together and to do that and you also notice a little delay there between the between the sender receiving the first acknowledgment and then subsequently pushing out the the next packet to the to the receiver and that is sort of a source of error which we\u0027ve identified it\u0027s kind of the application not sending immediately so that\u0027s going to be an additional time that\u0027s viewed in the RT t of reverse direction next slide so I sort of concluded that there\u0027s no standard metric and method in any RFC so far for passive TCP measurement so I "
  },
  {
    "startTime": "00:24:11",
    "text": "looked at all the references that Brian sent and wrote one and now that huge not huge but several page long metric definition and method of measurement with heuristics is in the registry entry so there\u0027s a lot to look at there let\u0027s see anything else yeah the the heuristics are really important because it\u0027s you know and passive you\u0027re looking at things and you\u0027re trying to make their measurement as correct as possible things can go wrong like the little delay thing I just described and let\u0027s see oh yeah yeah one of the choices I made was that all these statistics would apply to a single TCP connection so we looked for the sin the sin AK and the AK that actually helps us to describe the nomenclature so in the metric definition you\u0027ve got a host a which is the sender in the previous picture and the host B which is the the one that\u0027s generally the receiver and and that\u0027s defined by who sends the syn okay and in a fin fin ACK pairs would terminate the connection they\u0027d also terminate the measurement interval assuming we see those so next slide okay so there are some open issues here and this is worthwhile quickly discussing today so if you search the draft for the quad at you will find them so really still no standard metrics nobody looked this up while we were going through that slide okay well then we\u0027ll just go with what we got so one question is in IP PM we\u0027ve always defined delay as from the first bit of the packet observed on the wire to the last bit of the packet observed someplace else on the wire and do we want to keep that convention here I think I mean I think we could but I\u0027m not sure that passive really gives us enough information to provide that kind of timestamp so that\u0027s an open question no no okay well it would so I\u0027m at least up at the the layer you know when you\u0027re dealing with TCP at that layer you pretty much will get packet level timestamps not get level timestamps kind of what I thought all right so that but that\u0027s you could you could you could fake it yeah but you probably shouldn\u0027t yeah so let\u0027s not fake it let\u0027s just say I can\u0027t do that yet all right good enough and that\u0027s worthwhile mentioning great so so that\u0027s a so that\u0027s a feedback for the draft i I kind of think that the round-trip delay that\u0027s measured on the syn syn ack ack three-way handshake that that\u0027s a good metric to separate out on its own I am suggesting in the method that we measure it or they didn\u0027t pull it out as an output parameter or result so I think that we should do that I think that that\u0027s a reasonable thing to do any any feedback on that all right "
  },
  {
    "startTime": "00:27:12",
    "text": "well so then I\u0027m gonna have to flip the slides I guess now hi Brian Trammell speaking as an individual um so I think it\u0027s a very very very good idea to take the syn syn ack ack out as a separate metric for a number of reasons an unbounded number of reasons I don\u0027t want to count them yet because I\u0027m not thanked okay um so unbounded reason number one is that in a lot of cases the handshake is going to be treated differently than other packets in a flow right like you may have additional delays based on the fact that a load balancer needs to figure out how to take a five tuple and assign it to something or State that\u0027s getting ripped along the path as you as you send that sin because anther special yeah the second reason is that this is doing this metric definition for TCP lays the groundwork for doing different metric definitions for other transport protocols and for example it is an open issue in quick there\u0027ll be a report I think tomorrow from the RTT design team which you may have heard of since you\u0027re on it so am i I have that basically says well we need to have a discussion about whether or not we want to make this running a passive RTP measurement of quick possible or impossible and if that is made impossible we still have the handshake RTT that\u0027ll that will almost certainly stay in there so having a this split out into two metrics so that we can go and update it and say okay for quick you just basically the same thing except for the heuristic for determining whether it\u0027s a handshake isn\u0027t syn syn ack ack it\u0027s client initial server clear-text client clear text without 0t i mean that the heuristics end up being a little bit hairier but it\u0027s you can still define them it would be really useful to have this as a reference for that work yeah yeah oh and that reminds me let\u0027s add quick to the naming element yep yeah cool okay and then also as an individual I will review this section please do yeah yeah because it\u0027s it\u0027s my first attempt at this so and then Rachel from Huawei I read the draft thank you for your comments Rachel and she suggested that we also pull out round-trip delay forward and round-trip delay reverse as being useful metrics as well so I think that\u0027s that should be fairly easy to do no any you know one thing it\u0027s sort of a Christmas you know especially in in hearing Brian in the handshake a lot of times the first end number of packets of us you know as we\u0027ve talked about are different and some of them is of course the TCP since intact but then especially now that with "
  },
  {
    "startTime": "00:30:13",
    "text": "TLS you\u0027ve got you know the first ants number also so I just is I just wanted to throw that out not to confuse the issue but yeah you know no you\u0027re right you\u0027re right watch out behind you and and so actually I think I said that in the draft that these are special and it\u0027s one way to do it right yeah sense for this useful metrics and really interesting that because now when were implementing vo or something we found that the in the standard word we really like this kind of passing metrics for TCP so and I\u0027m very happy to see this coming and for the questions and I really think that the the delay for the I know sing and act should be a separate new metric and also as I are suggesting the men wastes that you know are RTD forward and RTD received should could be separate because we are using it for troubleshooting or than diagnose what what statistics would you be interested in seeing they\u0027re like we got min Max and mean for the overall round-trip delay average okay all right that makes it it makes it simple if we just do one yeah so let\u0027s just do one all right good thanks thank you so yeah next slide it needs review folks thank you Rachel and for anyone else who problem yeah hands hands for reviewers for this okay see like four or five that are okay cool excellent right thanks thank you so basically all the sections have been updated nominally and then nine and 10 are the ICMP and passive TCP respectively looking for feedback on all of this you know I mean people are gonna have to implement these and be happy with it and and and be comfortable that there\u0027s no ambiguity now when you\u0027re making these measurements so review thank you next slide please we still got to sort out something with DNS the the loss DNS loss metric do we do we require that the method generates an ID and puts it in the message the query actually or or do we choose a different source port for every query so that we can disambiguate two successive query attempts looking for feedback on that oh somebody yes please thank you so I have a I have a question about the I actually haven\u0027t read the most recent version of this with respect to the DNS "
  },
  {
    "startTime": "00:33:14",
    "text": "response time do you get you\u0027re basically looking for DNS response time for a specific or are are you looking for a DNS response time where you get to encode information in the ours I think it\u0027s a specific are are okay because one of the ways that people tend to do dns based measurement so Geoff Huston has this has this really beautiful incredibly elaborate DNS measurement thing where he you know is using advertising he has ads do DNS lookups and he\u0027s doing a bunch of measurement based on that and he\u0027s actually using the thing that he\u0027s querying for to encode the information right so um and because you get to query sort of like sub are very sub games names there might be um so the question so the question is what\u0027s the requirement here\u0027s the requirement here is that you need to look at response time for a specific or R right like I care about www.google.com for example or is there are you looking to measure the response time of the DNS infrastructure where for example you\u0027d want to make sure that the RR that you\u0027re querying isn\u0027t cached somewhere in which case you would be encoding information in the query itself that\u0027s an interesting distinction to the cache so I think I think here for this open issue we need to like step back whole bit and figure out what it is exactly we\u0027re trying to measure we trying to measure user experience for the DNS component of some of you know of some larger transaction or are we looking to measure the performance of the DNS infrastructure itself because that machine or is the answer I think I think it\u0027s the first one more like what\u0027s the user experience kind of thing so I would think ok yeah so yeah yeah all right yeah so what\u0027s this metric about is in metric is about the first one then yeah we need and I think I mean the the problem we\u0027re trying to solve here is from a registry point of view there there hasn\u0027t been a nailed down method to do this right for these measurements so given that there\u0027s value in both of those let\u0027s let\u0027s nail that down for both so that\u0027s another action item for the registry you\u0027re welcome all right I\u0027ll just quickly mentioned that the traceroute we\u0027ve got a route metric proposed you\u0027ll see more about that and many methods of measurement actually but fortunately the draft is going to really nail that down fairly exactly so we\u0027re in much better shape when we finally get around to registering that next slide yeah oh and just to mention that we were asked about a year ago I think or maybe a little more than a year ago to investigate how the model-based metrics would fit in the registry and so Matt and I did a draft on that which we haven\u0027t updated in a while and and Matt thinks that we still need to do quite a bit of work on but the but the bottom line is we should add this to the rest of the first crop of metrics when we when we when when Matt and I are comfortable with it and so are you so that\u0027s just mentioning the the status I think that\u0027s it for me I don\u0027t think I "
  },
  {
    "startTime": "00:36:14",
    "text": "have to trouble the working group with any other questions okay I would ask at this point is the working group on a trouble owl with any questions I were up here assigning him additional metric work to do so he\u0027s here so you can make him do more stuff and and actually I\u0027m getting pretty good at this I find now that I can really bang out a registry entry which is really detailed but I can do it pretty quick okay no more homework around oh yeah I do CPX ah oh yeah yeah that one yeah so like I said on the list I prepared that a long time ago to prove that it could be done it\u0027s not in the right form and I think the question I asked on the list was what do we really want to measure that rtcp XR provides I mean I just chose the burst and gap as something to do because of something I was familiar with but but if we want to do something else there then make that suggestion on the list I would say that\u0027s hope that\u0027s homework for you Rachel go back and they define some you know the report block protocols Randy it\u0027s Center rtcp X dot you proposed this metric but of the metrics registration I\u0027m not sure if it should be consistent with this format or not but people are you think it is useful I think I can provide some input to that okay all right thank you all right thank you very much thank you everybody next is Frank and maybe Mickey and Chong can you just join me yeah because I\u0027m just gonna go do the all right so this is a all right so quick update on on IO am and next slide so from a from an overall editorial perspective there were relatively few Commons most of the consolidation really happens across github so people raise issues there as opposed to on the list I\u0027m always trying to provoke that take it to the list as well and well in many cases that happen there were a couple of smaller things that came up that we "
  },
  {
    "startTime": "00:39:16",
    "text": "cleaned up well whereas MSP is it this one or that one so we harmonize that with a reminder but there weren\u0027t any real other things that needed to go get cleaned up from an editorial perspective which brings me to two discussion topics John and Mickey here come along next slide I don\u0027t know which one is first up oh yeah well there was one thing that that Mickey raised on on github as an issue we don\u0027t really include data lines as far as opaque stage not a snapshot that needs to get cleaned up there was even a pull request in there we just need to go and hit OK right after the meeting so we could have filmed that but that usually confuses people if you publish you know to write Monday morning so we decided not to do that and then we go into the media discussion around what John ones next slide he basically wants another timestamp format and I met John make the case for that hi John lemon we have people that want to be able to run NTP either because they can\u0027t or won\u0027t run PTP and we we would find it very useful if we could carry timestamps in either format so this is proposing adding NTP in addition to PTP and letting the user choose one or the other and indicating by the bits which type of timestamp is included this has been discussed on well sort of discuss a little not much on the on the list and previous github poll but needs to be updated also yes Greg mercy City why you need to have indication of separate seconds and nanoseconds or fraction seconds rather than just have one indication whether you have PTP format or NTP format why not to do it one place well my original proposal actually was to just include one or the other and assuming that you would that the entire domain would all be running the same type of timestamps but I\u0027ve been told that that is a false assumption and that there are some servers that need to be able to communicate with users that are using NTP and some or clients using PTP and so it would actually be handy to be able to have both transpiring at the same time and this would allow the server to figure out which of their which is being used yes but again could somebody give a case where you have "
  },
  {
    "startTime": "00:42:16",
    "text": "PTP time PTP style seconds and NTP style fractional seconds I go oh I see what you\u0027re saying why not combine the two of them right because they\u0027re already separate elements seconds and again I can give example on tym test enhancement that we use just one bit to indicate the format whether it\u0027s PTP or end ntp and you don\u0027t need to separate portions you might have different lengths of their time staff that\u0027s true well it was it\u0027s possible to include just the seconds portion or just the sub seconds portion that\u0027s with IO a you know but doesn\u0027t matter you still say this is this format and this is that format you know not set two formats in the same time step so I I see just one binary flag yeah and that\u0027s certainly possible it require using some extra bits somewhere else to indicate which not but if you propose to use four bits here yeah to 312 you can all get in one bit I save you three bits I know but again the pro K if you will say that we don\u0027t support it that\u0027s capability you can do it advertisement in control plane capability you don\u0027t need to do it in attack if you dare say okay I don\u0027t put timestamps period don\u0027t look at me okay and that will be control plane but it\u0027s timestamp format I don\u0027t see the combination that it\u0027s really needed because to me it looks over complication just my opinion I think you\u0027re asking for a fundamental change to how the data is encoded in IO am yes okay that is it the fallacy okay [Music] indication of PTP I mean we need a bit type to indicate that we need to include the timestamp in the in the per packet control but whether it is PDP or NTP given that IOM is going to be defined for the main I don\u0027t think they\u0027ll have a mix of PTP notes that would differently insert the timestamp so it\u0027s more like a control global flag which doesn\u0027t have to go in for packet so while we leave the bits to say that seconds and nanoseconds need to be collected but the form the synchronization protocol itself is a more of a control global flag that doesn\u0027t have to go in per packet the "
  },
  {
    "startTime": "00:45:18",
    "text": "reason I tried to explain before is that you might have a node that is running both ntp and PTP so that it can communicate on two different timing domains at the same time and it needs to be able to accept a timestamp in either ntp format or PTP format depending upon who it\u0027s communicating with but but would it be responding to two different iom domains at the same time yeah but still right given that node ID and other stuff that needs to go in as a control mechanism to the node this could also be conveyed on a per iom domain when it when the control plane is setting it up rather than in a per packet basis yeah all right and I\u0027m hi Frank Ramos speaking as an individual so the general um the general requirement here I strongly and wholeheartedly support especially because we\u0027ve also done this and you have but in all other places where we\u0027ve made assumptions about we\u0027re only going to use a single kind of time stamp and that bites us and now we do NTP MPTP right so this is consistent with the rest of the work in the working group and I applaud it I have spent a lot of time trying to do analysis on data on timestamps from providers such as a system like this that did it wrong so I have very strong opinions about this seems dangerous to me in ways that you may not be looking at right so there\u0027s a there\u0027s a well-known problem with trying to interpret time stamps in in nut flow version nine because it basically has a two fields internally that it uses for counting for the time base it uses the seconds and the fractional seconds and they just don\u0027t export the fractional seconds right so you can end up in a situation where you\u0027re using sort of like times the reference other times and you just truncate the time and now you have you know one second of error that you have to like do heuristics to guess so I can kind of I can kind of see where you might want to be in a situation where you would turn off bit you have fit to on and bit three off or bit twelve on and bit thirteen off the other combination bit twelve off and bit thirteen on right like so NTP fractional seconds and only NTP fractional seconds without a second base seems really weird to me seems a little bit less weird to me for PTP because you know in that case you really are like actually sort of like down at the metal carrying about nanoseconds um I think so Franks probably gonna say something that\u0027s you know similar but different I think you should probably take all of this feedback and come back with a different um either a different design suggestion "
  },
  {
    "startTime": "00:48:20",
    "text": "or a different or a set of design rationales as to why this is here because there are trade-offs in this space right we can\u0027t do it perfectly um and I\u0027m not convinced that this is the optimal point in that trade-off space Thanks [Music] so Frank runners so I think I second some of what what Brian was saying so when we started off with IO am we on purpose picked a dedicated namespace for virtually all the fields for IO am why because we didn\u0027t really want to go and be bound to some parent protocol and the associated format because whenever you do that somebody else will show up and say I want this as well and then you suddenly have probably 128 bits of it field to indicate and it\u0027s still not sufficient right so yeah which is why I have a little bit of kind allergy when I see that at the same time I second that there is use cases where you could have different nodes filling in things with different formats and you want to go and indicate that but you\u0027re not alone because there is other metadata typically inserted along with time staff I\u0027ve not really seen a case where people just insert timestamp but no node ID so if you indicate the node ID you know what the node is capable of doing typically whether it\u0027s using 1588 or MTP but it\u0027s rarely seen or maybe there is a use case tell me where the node would either insert 1588 or NTP depending on a particular use case are you making things up here if that\u0027s not the case then we may not need that indication but we can go with two fields and maybe what you\u0027re telling me is we\u0027re overly specific even than saying well it\u0027s seconds and nanoseconds maybe we just say okay there is two fields and you are free to go and populate them depending on what you need so I second basically Brian\u0027s comment I think you\u0027re raising a really good topic and a really good discussion but it needs more thought on how we gonna go and resolve that because we don\u0027t want to be imperative from what we\u0027re doing from a formatting perspective so that we are not going down the slippery slope of having eventually to accommodate the world of different formats not only here but you can take this over also to interface IDs or whatever right so then people say I want this format and not that format and I think that basically the suggestion to look at this information being part of configuration and control plane is in a very good direction and I think that to me what it "
  },
  {
    "startTime": "00:51:23",
    "text": "suggests is that should we look at the control plane of our IOM or and data model so again it they\u0027re granular this is not probably only the question of times temperament yes I agree that a note can support both formats and that can be something that is either negotiated or just advertised or the node is told that for this data stream you use this format and because node ID will be present it would not necessarily require information in each data packet okay quick comment on that you\u0027re there\u0027s an assumption that node ID would be present and we don\u0027t see that as necessary to see that actually as a burden actually to have to include the node ID because it adds a lot to the header to process in hardware and we\u0027re actually looking at and you also suggest relying on the control plane but again if we\u0027re trying to do this within the chip trying to inject control plane information down into chip to figure out how to interpret the timestamps adds additional complexity to the hardware okay I think that probably at this point is better to take it offline and continue discussion on the list but then I definitely would like to understand their scenario when their day that meta data are not accompanying by some sort of ID okay next slide in addition to wanting the oh right so there\u0027s a there meta there\u0027s metadata that\u0027s available on the hop-by-hop basis that we would like to be able to access on just edge-to-edge while it\u0027s possible i mean while it\u0027s possible to take all the information from hop I hop added up together and come up with a total delay we would prefer in many cases not to have to rely on every hop by hop and instead just have an end-to-end measurement and so we\u0027re asking that there be timestamps at the same timestamp information that\u0027s available on hop-by-hop to be available edge to edge and the second request with regards to edge to edge is a 32 bit sequence number either in addition to or instead of 64-bit again this has to do with ease of processing in the chip and depth of I am header into the packet "
  },
  {
    "startTime": "00:54:28",
    "text": "so for the edge-to-edge time stamps the current time stamp and my hobbies I would we would want to eat grass on transmission and in grass on reception yeah is that what it says in the drop I don\u0027t recall if it specifies that let\u0027s fix this forever so Frank runners so what might make sense if if you come up with proposed text and sent that to the list for the two ones so that we well are a little bit more specific on how things would would work out I do believe that having additional attach options is not a problem it\u0027s relatively easy to do so let\u0027s do it all right so I think of having short and long formats for sequence number well we do this for many other fields as well why not right and from a timing perspective again more detail would be okay thank you take it to the list first rather than I know it\u0027s easy if you put a push request so a pull request but many people don\u0027t see it our way and so kind of this this thing that we need to go and mimic things on the list so that everybody has visibility or what happens on github because not everybody watches the issues on github okay yeah and I have I have a chair comment on the github thing but I\u0027ll do it at the end of this hole I see there\u0027s other slides up here okay I don\u0027t read github thank you very much Sarah banks I had a question you keep referencing chip and easing things on the chip and my skin crawls a little because that sounds very vendor specific so I\u0027m just curious what chip are you referring to I\u0027m not referring to any specific chip in general but rather to general implementation within silicon yeah not that tall so one thing I noticed while coding things up for the hackathon was that the current definition of the we have undefined bits in the IOM trace type but we do not say "
  },
  {
    "startTime": "00:57:28",
    "text": "anything about what you\u0027re supposed to do either on transmission or reception of an undefined bit in the in the IOM trace type and it\u0027s the reception one that is the issue of concern if you want to be able to use those bits in the future if you look at the way the encoding works anytime you have a bit you expect a data field after that corresponding to that bit so ignoring the bit will not work if you\u0027re not adding the the info but the bit is set then it will not be possible when you get at the other end so we have to do something two obvious approaches one is if an undefined bit is set don\u0027t add anything at this hop another possibility is to try to nail down the lengths right now even a friend to find bits obviously that has some some pitfalls but it would allow you to at least insert everything with a proper length so that it can be parsed at the at the monitor and if anyone has and anyone else has any bright ideas of better ways to approach this happy to hear them why can\u0027t we sit it is reserved or experimental no so but but the the problem right now is if if your implementation today implementing this version the bid is undefined and you ignore the bit then you\u0027re not going to add that information into the packet but when you actually pull the information out of the packet every time you see a bit you expect that the information from any one hop will include that length of data for that bit so if you just ignore it and you don\u0027t add the information to the packet then when it comes time to read it you will actually be thinking that info for this hop it\u0027ll bleed over into the next hop what the next hop did and everything gets shifted and you won\u0027t be able to parse it okay Greg Mirsky Z T so I really wonder because if there is something undefined which is like must be zero right so usually in a document we say must be set to zero on transmission and ignore it on the reception yeah I\u0027m saying you can\u0027t ignore y know if it\u0027s if it\u0027s M busy you should ignore on reception okay so let me give a simple example so if you have to you\u0027re implementing this version of the spec this makes it the RFC you go out you implement and off you go then in in the trace bits you may say I want note ID and interface IDs so every hop would add node ID interface ID note ID interface ID when you pull all that apart at the end you\u0027re going to assume "
  },
  {
    "startTime": "01:00:28",
    "text": "that after every two bits it\u0027s another hot so the first two headers is the last hop no but who\u0027s not before that so on now if later on we define some undefined bit and now the source sets three bits to rhythm that were previously defined and one that\u0027s new a new version of this back then now the the expectation when you get to the end is that every node is adding three fields and it will go through the first three fields and assume that\u0027s the last hop and three after that is hot before that and so on if I hop back she only adds two fields then you start mixing and matching well when Wu is the actual source at any one hop and and how you\u0027re interpreting it okay so I understand so you you asking the question of proactively basically you\u0027re asking about how you ensure backward compatibility between versions yes yes and okay so I think that there one way to do it is that you have the record type embedded in your metadata that you put in so thus they can understand basically you have some TLD effectively so you can parse it without really relying that you have a fixed size records on your bits another approach is that okay well you know it might be not backward-compatible and third approach would be that this information about capability will be advertised in the control plane or data model and then somehow will correlate to the packets that you receive so choose what you like there\u0027s a lot of complexity in several of those answers just rather note what I said before my suggestion is if they are you know set to reserved in someone set one in basis of its I think the whole header should be ignored not only one yeah so it so that that was the first suggestion was at any one hop if you can support all the bits that are set go add your data if you cannot don\u0027t add your data no but it has to be the node that\u0027s adding right once once you get to the end you don\u0027t know what happened no but once you see a bit that has to be zero and is not one you should know not using anything there because you don\u0027t know what happened in the real I friend Ramon speaking as individual this is um trying to con him I\u0027ve had this discussion "
  },
  {
    "startTime": "01:03:29",
    "text": "before um in a whole lot of different protocols uh and everyone does it a little different and some of the reasons I think that they do it a little different is because they have different requirements and some of the reasons because it\u0027s like oh hopefully we haven\u0027t looked at what was done before I don\u0027t uh I\u0027m not deep enough into how IOM works to make a coherent suggestion here but I\u0027m gonna make one anyway I think that so if you want an extensibility system to be used and useful you basically need to set it up before you start I mean like at at you know before you start allocating code points in this code space you need to set it up so the UN exactly what the what the the failure state is and like so you know for example with the ipv6 extension header types there\u0027s the attempt to say you know whether you know you know there must ignore a bit and must for a bit and so on and so forth um it seems here that the main problem is a problem of length rate of you must understand every bit in order to be able to figure out what your offset is when you\u0027re sending do I understand that correctly it\u0027s an offset calculation problem um well not exactly because the the way that it\u0027s set up right now is it\u0027s more like a stack and you\u0027re always pushing your information in the front of the stack so the nodes that are adding info don\u0027t have any problem right oh it\u0027s when you\u0027re riffing a stack apart at the end right so it\u0027s still an offset calculation problem but it\u0027s not a cinder offset calculation problem is a receiver also calculation yes exactly all right yeah then you either need to define a fixed length record per hop and you know each hop just basically adds stuff until it runs out of things to add or out of space or and then like maybe that\u0027s you know it\u0027s variable link but it\u0027s fixed length for a given trace or you need to basically have each code point in the space even the reserved ones define what their length is right now and you have like you can have like a short night variant and a long variant and you just so this is when we when we hacked up sort of the thing that became plus we ended up going with that like you know there\u0027s a bit here this is which bits how what fraction of the bits here are integrity protected for example and the same approach that second approach seems to me to be the most what that was trying to describe and yeah he said ok ok so I did I did understand that correctly yeah then I\u0027m just in having looked at this problem in other protocols in other spaces the second one seems to be the most promising to me are you so from poly a tray we wrote it dropped maybe that might help to solve this problem so in case one node can note process or add some data to the IOM header it can use a extended bit map to "
  },
  {
    "startTime": "01:06:29",
    "text": "indicate validation of the data it can just reset that bit to zero to indicate this node not had validated to two to the IOM header then obviously this will require our we know the size of the data so maybe bad for be just the you know assume every re datatype it\u0027s just as 32-bits so in that case we just add some maybe all app data to the to the to note but sets that bitmap beat to zero to indicate this no cannot had any data valid data so this can help to address this issue I think Kyle eros and vine just a comment about the 0xff at the fan option one problem with that is it does limit the range of valid options for all existing types and all future types by one not really a big deal but if there is some type we wanted to find in the future and all possible values inside that type makes sense then you might run into issues if is your xff yeah at the moment that we\u0027re doing that for some of the fields but not all the fields so anyway I mean we obviously we need to take this issue to the list I was just hoping for some feedback to see if we could narrow down one proposal I think back it\u0027s not one proposal yet good so thank you very much I have a chair comment about um this is just something I noticed on the the github repository um there is an emerging de facto sort of method for doing the use of github within a working group like we\u0027re basically the you know the repository gets moved over from whatever individual organization into a working group organization and also a standard for the arrangement of those which is you need a contributing file the points in the note well that\u0027s the big thing so if anybody comes in and looks at a github repository from outside the IETF they understand that contributions for this document have are subject to a ETF IPR rules like that\u0027s the big thing that that we figured out and I just looked at this repo and it doesn\u0027t do that so we should yeah so we should get that fixed and I you know with my chair hat on I have since this work had a long independent life before it came into the working group I don\u0027t necessarily need to have this as getup comma slash IETF I ppm def WG / IOM drafts but if there is "
  },
  {
    "startTime": "01:09:34",
    "text": "interest in the future and moving some of the I PBM work and to get help I can go ahead and do that and we can make that happen I don\u0027t care but how about we do that right now do it right now and then say okay there\u0027s gonna be more along the same lines because well you you notice that we\u0027re starting the journey with all the various yep protocol working groups to go and find a home for where to put the data fields so there will be more of the same yep and rather than just continuing down the wrong path kind of thing it\u0027s still early enough to go and switch parts I will go ahead and set that up so thank you alright so thank you very much um we\u0027re going to I\u0027m gonna alright actually now we\u0027re gonna switch over you and forth discussion now which is really a model for reasons [Music] yeah yeah that\u0027s easier slides yes that\u0027s the right place to start thank you okay I\u0027m mal Morton I\u0027m working with Ruth\u0027s civil and Rashad ramen and Mahesh chef from Donnie and Custis Penn acoustics is our editor working on the yang model 40 WAMP next slide so here\u0027s a summary of our interim of progress and we had a working group last call and there were no comments but there wasn\u0027t a call of the consensus of the last call that\u0027s something action point for you or someone else and the Chairman seats I didn\u0027t I didn\u0027t see any I I think there\u0027s consensus oh yeah I think so too but Arthur but there should be like a message that yeah I\u0027ll send that out yeah so while we were working on on last call we also had a rear view from our yang dr. Yan Lindblad and we cleared up a few issues with him and then we had a review by our volunteered document Shepard Nalini elkins so thank you for taking that job Malini and for volunteering to do a big is if this was a big a big step for somebody who hadn\u0027t really read tea went before so much appreciation for jumping into the breach on this no many did this incredibly considerately in that she took everybody else\u0027s comments that had been raised like yawns and and others along the way greg\u0027s and and and said did you guys really "
  },
  {
    "startTime": "01:12:35",
    "text": "resolve this you know show me that show me the way you did this and so almost everything that was done against this draft for several years has been checked and Nalini was finally satisfied with it so she published the link to the Shepherd\u0027s write up and we immediately published a version o 5 to fix a few things including the doctor and Shepard points but then a Greg mirskiy here made a comment on the shepherd right up draft which we continue to the next slide to take a look at yes and and it really has a lot of relevance to this draft which Greg and I put together during the last meeting on the reassignment of UDP port for the T web test protocol so this really covers both these these drafts although this one\u0027s individual as you will notice next slide please so Greg was seeking to align the - ports draft which you just saw the title supreme for with the yang model and Greg proposed that we do all this add the range including the UDP port 862 plus the full dynamic range and then to add a note that that 862 would be the default but but then I said on the list we\u0027ve already got thousands of existing implementations that aren\u0027t going to recognize this as a default so that\u0027s kind of an issue where we can\u0027t do this by sort of retro actively and I\u0027m and I wasn\u0027t getting a mandatory default from reading this sentence which is at the bottom of the slide but I realized that we could probably clarify it and Greg agreed that we should clarify and so then the proposal to clarify it went on the list which is on the the next slide so you\u0027ve got the old sentence therefore for reference but what I did was to separate it into three items which should be very understandable the first sentence basically just requests the reassignment to I Anna and it stops there but now we qualify what that new reassigned port means to t when it\u0027s optional in standards track Oh wham and T win and then the last sentence provides the future looking clarifications that we were hoping for it may simplify some operations to have a well known port available for test protocols and for future specifications involving T web tests to use this port as a default port any comments on that wording I\u0027ve already heard from Greg on the list that this is this is okay I think I mean to be honest I think I could connect it better here but but I unless I\u0027m really moved I think I\u0027m just gonna put this in the draft our draft and and that will clarify the situation so I think that\u0027s it Brian or wait there\u0027s next steps here oh yeah "
  },
  {
    "startTime": "01:15:35",
    "text": "so next steps for the port draft assuming we can agree on the wording in slide five then which we just did then then the only point raised for clarification was was it that\u0027s everybody seemed else seems happy with that draft unless there\u0027s some other ones coming up now to the microphone and the microphone is empty so the authors suggest a call for working group adoption of the T WAMP report draft that seems reasonable to me so so this is because this is a little this is slightly esoteric right so I I\u0027ll ask who\u0027s read the draft and understands the the issue here port reassignment oh great yeah the port reassignment thing yeah okay yeah so that\u0027s like the number of hands we usually get 14 um stuff right yeah so any objections to adopting this as a working group item none so I say we just go ahead and put the call for adoption out on the list this seems like pretty much like a no-brainer to me so and and I\u0027ll push a revised version with this text that you can refer to in the adoption are there other updates that comes out of come out of this that have to go back on to the TMP engraft no so there\u0027s so the I just changed the status to W consensus waiting for right up right which I should have done a while ago right because we already have a write-up so we\u0027re not technically waiting for a write-up so I can click the button now and send that up to the iesg Ben um one thing to fix here which is the last the last three lines so what\u0027s next job for this so we\u0027ve got the call consensus working request call publication request but we want to make port 862 optional in the model and I think the way to do this is to add a leaf okay so everybody\u0027s cool with that all right so we need so we need to know seven yeah six actually six yeah yeah so my understanding that if their range will be enhanced by you listing 862 or range actually it will make it optional okay that\u0027s I guess that\u0027s a different way to do it the or okay if we can go back to the my proposal so yeah too far yeah there it is okay so if range statement acceptable that makes it optional just drop default use range and that makes it optional the last the default 862 goes away yeah and that\u0027s an "
  },
  {
    "startTime": "01:18:35",
    "text": "yeah yeah okay I don\u0027t know enough about yang but if you say so that no no don\u0027t take my word but no I think that\u0027s my understanding yeah okay but when I talked to the co-authors they suggested two separate leaves so yeah all right we\u0027ll work this out work it out yeah um work it out send a send an ex probe and then we\u0027ll request public because I mean this is this is so down in the weeds yeah I don\u0027t think there\u0027s it\u0027s important to get right if anybody if anybody decides that um that you know the particular yang implementation here means that they are no longer comfortable with having working group consensus on this then please raise that concern on the list otherwise this is the plan we\u0027ll go with yeah good okay cool thanks next up is al right oh yeah that\u0027s I was on YT talks that\u0027s look like my stuff ah okay so this is an individual draft on the advanced unidirectional route assessment whoa whoa Ignacio and Al and yokum Fubini have all been working on this this is our second reversion so we\u0027re trying to get this to where the working group likes it enough to adopt it and and carlos pinero suggested this acronym by just recognize again it was already in the title hora sounds pretty good I think we\u0027ll insert that in a future draft name if we\u0027re successful with adoption next slide good all right so here\u0027s the background we developed a route metric and we introduced it before IETF 99 we got rid of your guides comments which became our initial to-do list seven items we\u0027ve addressed pretty much all of those now and have some replies on the list so that\u0027s all that sort of thing is is in zero one but then in the interim after the meeting we got extensive comments from Carlos pignataro so thank you for those when you when we get to the to do\u0027s you\u0027ll see a lot of things that are labeled CMP those are all addressing Carlos comments as well but many of them have have been addressed so several remain though some we\u0027re going to discuss today so there\u0027s actually going to be some real interaction here get ready for it that\u0027s what we\u0027re gonna do we\u0027re going to talk about expanding the scope that\u0027s a big deal off less comments from Frank Bruckner\u0027s do you remember reading this Frank yes it was so anyway thanks for that and thanks to all the reviewers really and I\u0027m gonna I\u0027m gonna do a brief presentation here so if you want to see all the diff "
  },
  {
    "startTime": "01:21:36",
    "text": "thanks to all the next slide so major update the hops we originally described each route as an ordered graph so that meant that our source host was in this nomenclature 0 1 and then you encounter of of hosts along the path and you you identify them all according to this numbering system and then at the end of the path you eventually get to the destination so that basically the path was defined as existing between a given source identity and a different destination identity and of course multipath means that you can have different sub paths along the way so that meant that we had to have something called a root ensemble which I will get to but but the most important thing was that we originally referred to this these H IJ\u0027s as hosts and what we quickly found in looking at the methods of i/o a and M and some other things that are around is that there\u0027s there\u0027s additional information available at every hop and I\u0027ve got it listed there it has to include a host identity but it may also include an arrival interface identification same for departure arrival timestamp we were just talking about formats for that round-trip delay measurements which are measured elsewhere but still can be put into this Tuffle there\u0027s other things to MTU cue state lots of things could be really measured here that that and different interrogation protocols tend to make these things possible so what we\u0027ve done is really to expand our our representation of what\u0027s being measured to include all this information as a possibility and that\u0027s a big step I think that we\u0027ve we\u0027ve now covered a lot of a lot of new information that\u0027s available beyond the old traceroute methods and will be available in the future so next slide so the also we\u0027ve have we have an update which is a foundation for all these three components so we\u0027ve identified a host identity as the addresses the host reveals when communicating it\u0027s under normal and error circumstances a discoverable host is one that corresponds to the requirements and these are FCS listed 1122 and 1812 and it sends a basically sends an ICMP time exceeded message when discarding a packet due to TTL expiration so that\u0027s discoverable now a cooperating host is one that\u0027s participating in an interrogation protocol like I OEM for example and it must respond with identity into the interrogation should provide the other info and so and one of the things we\u0027ve done with all of these identify identified components is that we\u0027ve used the RFC 2119 terms to say what they must and should do and we feel that we can i we can generalize all "
  },
  {
    "startTime": "01:24:37",
    "text": "these components beyond IP if necessary and that\u0027s really one of the suggestions that come in from Carlos which we\u0027ve begun to discuss on the list so next slide here\u0027s the interactive portion we put your pcs away let\u0027s get ready to talk about this the the proposal is should we expand our scope beyond IP it\u0027s the IP PM working group it means that our framework was really strongly based on IP layer measurements but there\u0027s so much good synergy with the tools and the additional information that can come from LSP ping and LSB traceroute and and some of the other nicely constructed features that are available now in MPLS wide area networking that we could easily expand our definitions here sort of generalize them and include MPLS routes and in this work so uh open mic now Greg okay great idea but why not generalize even further not just MPLS being straight out being a trace route because we\u0027re discussing engine trace route functionality for all different overlays like NV o 3s FC beer I so I think and many and many of them is which what\u0027s important in this work is they\u0027re natively unidirectional yeah yeah and that\u0027s what we\u0027ve got here is right and actually unidirectional so generalize go just being trace route functionality on different networks and overlays so I so I think a good point and it\u0027s actually what I mentioned here and what Carlos also also mentioned nvo 3 there\u0027s a facebook UDP thing that that\u0027s yeah it\u0027s a gooey generic UDP encapsulation and segment routing allows some delay measurements yes segment routing again segment routing has two data planes for MPLS and ipv6 but at the same time so we have beer actually and then beer it\u0027s interesting because it\u0027s multi casting technology so so here\u0027s here\u0027s here I appreciate that there\u0027s lots of ways we could attack this I think that and lots of protocols and underlying technologies that could be included what I\u0027d like to do and propose to the working group now is okay what I\u0027d like to propose is that we we take on MPLS we simultaneously write the definitions for standard formed packets at the MPI layer okay because in order to measure round-trip "
  },
  {
    "startTime": "01:27:38",
    "text": "delay and loss and the other things that that Ignacio was proposing we do here we kind of have to include them in our framework and that\u0027s the way to do it I don\u0027t think that\u0027s that hard though and and and in that just let me finish and so in the and in and by generalizing to MPLS I think will actually create a fame framework where we can add methods easily from any any of these other technologies which would be which would be available for MPLS definitely we need to look at 63 74 which is a packet loss and delay measurement in MPLS networks 374 yes just note is that in MPLS control message already has for the ping timestamps right right and and that\u0027s that\u0027s babe sorry that\u0027s yeah that\u0027s exactly why I was trying to do this but yeah and actually what what would be very helpful and valuable is recommendation because for some other networks there is a consideration whether include the time stamp and what how many times them how much of a space for the time stamp to include because I I agree with you that if we\u0027re doing a unidirectional time stamp we don\u0027t need to have more than one time step filled it looks like we need have a charter discussion though it might be what the chair is telling you by your slides off and putting the Charter up yes and highlighting a specific set and highlighting a specific sentence I\u0027d want to be ready for this right so actually meaning you want to go ahead from the Charter but it\u0027s back to your draft I mean if you are talking about I suppose expanding everything in your draft was really talking about TCP UDP as the transport and not taking into consideration you know other transport protocols is that is that your intention well well that that would be that was that was what Carlos proposed in his extensive comments and and he saw that we had basically the features to be able to cover these in terms of a metric but we hadn\u0027t quite gone there yet although a lot of the new work that I did like defining these components and so forth that\u0027s that\u0027s I think now generalizable so that we could easily make the jump if we had to you know basically although all the the work on a1 in the metric definition was looking looking ahead toward possibly doing this yeah sure because I can definitely see you know if you do SCTP and then or heaven forbid quick you know what I mean is if that is the transport protocol well actually I think I think where we\u0027re headed is down down and not across well I\u0027m I can I can "
  },
  {
    "startTime": "01:30:39",
    "text": "I can I can I can talk I can talk to that point a little bit later in fact yeah so let\u0027s let\u0027s cover this though yeah um so this is our Charter which we just read it and so individually I really like this idea because I think that you know basically it one of the things that we\u0027ve so the the IETF is is basically structured in a way that there\u0027s like you know layer three and below and layer three and above and never shall we meet but the way that networks are run right now like everything\u0027s an overlay over and overlay in a tunnel over and overlay and you actually in order to be able to understand it you need to not quite have this strict layering idea in how you measure it so but we have a charter and the Charter says this and the standard formed MPLS packet seems to be such a blatant violation of the Charter that we\u0027d have to reach order to do it yeah however if I may before the before the the area director cuts me off oh please continue if I may um the end goal of all of this measurement is to determine the quality performance and reliability of Internet data delivery services and applications running over transport layer protocols over IP it\u0027s the end goal right we care about what\u0027s going on in the tunnel or over the tunnel or through the substrate because we care about what happens to the packets over it yeah so it\u0027s it\u0027s the work to generalize the route metric seems to be defensible the work to on say here\u0027s how you apply it to MPLS and here\u0027s what an MPLS standard form packet looks like seems like it might need a reach order do you have a an opinion or an alternate opinion on that responsible area the lowered a bit first which is there\u0027s different styles of managing working groups one is the one where you come up with the work the Charter and then never change it until it is so obviously out-of-date that no one will come to your working group anymore and the other one is to keep it up to date as as things develop I\u0027m actually okay with keeping something up today there\u0027s new work arises and you know that is at the edge of the scope you know that that\u0027s actually that seems like to me responsible working group management practices thank you and Bill for that we\u0027re moving to the high order bit I\u0027m going to be an area director for right at about 500 more days so I\u0027m "
  },
  {
    "startTime": "01:33:40",
    "text": "starting to think about what I\u0027m leaving behind it seems like to me that what matters is what work needs to be done and whether we can assemble a community to do it that might be here that might yeah you know I actually had this question about Instituto a.m. is this going to be so big that it swamps everything else the working group is trying to do I\u0027m not saying that it does the chartered it the way we did but there was my first thought so my thing is this might be the right place this might not right be the right place I\u0027m fine with figuring out whether the work needs to be done and then we can figure out where it needs to happen because if it needs to happen that\u0027s you know that\u0027s an IHG responsibility so make sure that we do the work that we need to do for the internet so let me let me make a suggestion as the chair let me say that let\u0027s um so the fact that we\u0027re the fact that we\u0027ve we\u0027ve traditionally solved these problems in different ways in different spaces and now we\u0027re doing less of that with the bringing of I mean that was sort of an explicit goal of bringing IOM into this working group it worked and it seems to have worked is that this work on sort of the topology metrics is generalizable and it should be built in a generalizable way but I would say that for right now we develop it with an eye toward the present framework okay with the understanding that we don\u0027t want to do anything that you know we\u0027re understanding now that we\u0027re not just you know it\u0027s just like down to the first IP header and then we don\u0027t care anymore we might want to care below the first IP header we know that now we didn\u0027t know that 123 30 was written right because the internet wasn\u0027t made of tunnels yet right um where you see mp4 that so I would say like basically go go ahead with route as you\u0027re doing it yeah we now know that we might need to to UM extend 23 30 further um after we have the route work done but let\u0027s do the route work first okay and then generalizable but still focused above IEP way that would be my suggestion so generalizable but still focused on yeah I would support that as area director so thank you all right [Music] thank you all for bringing this discussion to the working group you know my main goal of this discussion is like you were saying before Bram that this is "
  },
  {
    "startTime": "01:36:40",
    "text": "generalizable that we don\u0027t need to reinvent the wheel that whatever we do you know serves as a framework foundation whatever you want to call it so you know with that in mind I like the suggestion I would add however you know if there is a focus on energy to also figure out how to do this with MPLS even if it fits in a non normative appendix on how you would actually extend the technology that would be useful let me let me make an another suggestion the way in which we run this working group which I intend to continue running the working group which has worked very well for us is anything that is related to current work an IP p.m. which has a draft - name - IPP - whatever title that gets discussed on our list gets time on our agenda after we finished all of the working group stuff so even if some of this the specific work to actually bring this down to MPLS isn\u0027t quite yet on charter yet it can be co-developed with route and adopted later okay okay I think I think that that that could actually work out yeah yeah quite well because it might be that it might be that we do want to like if this I don\u0027t want the working group to get so big that it\u0027s like you know four sessions and there\u0027s the 12 people and he went people and they\u0027re over here and they don\u0027t talk to each other point of having this all together is so that we can actually cross pollinate some of these ideas and if it gets so big that everybody\u0027s only focusing on their little thing then it doesn\u0027t work so we do actually need to figure this scope out and I not sure I want to move this over the routing area quite yet why that\u0027s yes that\u0027s why I raised it that way but I think that this would allow us to do what we want to do with a route thing and and do it in a manageable way yeah yeah good so so we\u0027ll generalize the metric definition currently the methods are modular and sort of distinguished between the active trace Rowdy kind of things and the interrogation IO and M kind of things and there\u0027s space that we could eventually insert other methods there which are unique to their their lair let\u0027s say and that\u0027s what I just said so let\u0027s see so the week we\u0027ve actually clarified the checksum calculations thanks to Tallis RFC that was an easy reference to make much appreciated and new sections define it combine combining different methods that\u0027s really important that was one of Ruettiger comments you know if we if we do an interrogation eying them on a single domain how do we combine that with an active traceroute sort of thing and what we\u0027ve identified there is the key is that you have to have overlapping "
  },
  {
    "startTime": "01:39:40",
    "text": "host identities then we can put these different collection results together and then we\u0027ve got these discussion development areas the interaction between host identity and the be ability to discern subpaths that\u0027s discussed there in some detail the the co-authors discussed a temporal composition for route metrics we\u0027ve we\u0027ve got some thoughts about that assessment at IP layer this is the important point to your question Nalini assessment at IP lair reveals the route ensemble for IP and higher actually because we\u0027re talking about ports and other things that are higher so that\u0027s the conclusion there and also this idea of Class C which was an important notion in the original framework packets treated equally it\u0027s it would be very useful to know that to incorporate it as parameter in the route metric it\u0027s a concept that we\u0027ve developed in the framework and the metric definitions next slide and I would point out it is a an area of active research yeah from an act of measurement standpoint like how do you how do you do this is hard yes yes and but this is a clear place where where it would be useful to know yeah yeah okay so here\u0027s the to-do list I won\u0027t go through this in detail but you can see that there was lots of things here that Carlos suggested and we thank him again for that and also the the one from Frank on using the IO am loop back bit and then if we do MPLS I guess we\u0027re not going to do that but we might be able to still talk about TTL propagate or something like that Nalini IP and higher you have IP and lower to I mean I know this is shocking but I mean interface idea is actually you know layer to well well but that\u0027s information you collect it\u0027s not it\u0027s wonderful it\u0027s not route determining I think that\u0027s the point yeah a source and a test and yeah there\u0027s something inside wanna we can discuss offline because there\u0027s something in there about like you can\u0027t determine certain things that the IP layer if it\u0027s the same O\u0027s but indeed you can write each case if you have a different interview if you\u0027ve got information below yeah that which is what we\u0027ve talked about and whatever the whatever the hosts are willing to reveal that\u0027s what we\u0027ve got back up so next steps please read and review how many people already read it decent showing plus the people who aren\u0027t here and we did get a lots of comments so we\u0027re we\u0027re kind of interested in working group adoption of the draft now that we have a clearer view of the scope really this is the metric side of the work we took up earlier this year the telemetry data I oh I am "
  },
  {
    "startTime": "01:42:40",
    "text": "I mean this is a this is a tool that\u0027s going to enable measurement of the route that we\u0027d like to put a metric on and this is our traditional work we started out defining metrics here and the methods of measurement well now we\u0027ve got to catch up really that\u0027s my appeal let\u0027s let\u0027s have a route metric available when this IOM data becomes available and we could create a milestone for this as a first step that would be great too so so um actually could I see the hands for who\u0027s read it again um can I see the hands for who hasn\u0027t read it yet but after this presentation is interested in reading it okay that looks alright that\u0027s enough for me I\u0027m gonna go ahead and ask for a really loud hum because they\u0027ve turned on the turbines to change the air out in here so um if you would like to see us adopt a milestone for um unidirectional route metrics and this as the initial document for that with the title craft IETF I ppm I ppm our uh I like the title so I\u0027m going to go ahead and put that in the hum please hum now if you would not like to see this milestone on our Charter or have serious problems with this being the draft for it please hum very loudly now that seems pretty clear to me so we\u0027re gonna go ahead and do in a call for an adoption on the list awesome thank you thank you working group I think that\u0027s it that is it all right and then I think we are now come on do stamp there we go okay so we started new work that concentrated on test protocol and so we\u0027re bringing two documents individuals drafts one is a base specification and the data model today the model would see it\u0027s important because since there is no plan to create a control plane protocol to control you know instances of sender and reflector in SDM manner using the data model next slide please so what\u0027s the scope one of the first requirements that we said to ourselves is that to make it on water compatible with the T ramp in unauthenticated mode and that basically directed us to use "
  },
  {
    "startTime": "01:45:43",
    "text": "sender format and reflector format that used in the t1 test but at the same time there is an experience so we looked at certain feedback from deployments especially t1 plight and document developed and broadband forum TR 390 performance measurement between C and IP edge which suggests that default symmetrical packets is very much appreciated and useful so that\u0027s we can go to the next slide and so this is their center format as you see so we already set 27 bytes of padding to make it symmetrical and then accommodate of copied packets optional parameters that will follow this 27 bytes padding for functional extensions we propose to you steal these so that if there is a deployment scenario where we have stamp sender and T womp white reflector for the T womp reflector that they will look like bedding and they will just reflect and that can be figured out through a data model and the test still can be performed on the basic matrix so that\u0027s the idea so the reflector format will be somewhat different but again the idea is that it will be symmetrical of course for the control from the data model that can be changed but otherwise it\u0027s symmetrical yeah that\u0027s the sender and that\u0027s reflector now so we can figure it out within offers our idea of where we want to take unauthenticated mode but then the security comes and taking advantage of our proposal that we discussed in Prague and now I\u0027ll present it on reassigning a UDP port a 62 for the test protocol we propose that this port will be used as a default port for the stamp protocol and other options will have use of all dynamic range so that gives us compatibility again with the t1 in unauthenticated mode at the same time there visioning of the reflector becomes much more simpler because we can have a "
  },
  {
    "startTime": "01:48:44",
    "text": "default and don\u0027t touch it unless we need it the next question is so because introduction and definition of well known port creates a potential attack vector or somebody will be trying to skew the measurement by intercepting packets and holding them hostage for a while so that measurements will go and accurate how we can do that the initial idea of QM test protocol to use and negotiate dynamic pores was very nice because it prevented this so the detecting of test flow which was much harder now with the well-known port it becomes more exposed so what we do there is a trade-off and that for us something is the open question that we want to have the discussion with the working group is so how we can protect the test data plane the test packets at the same time providing accurate and meaning for measurement because the problem with authentication and encryption as already being pointed out in 5357 is such that we want to do timestamp very close to their hardware at the same time we need to do certain operation on securing the packet there was interesting very useful comment from Henrik who after zero version now joined us and now is the cover of this proposal is to have characteristic of how the timestamp being acquired in the packet so basically introduced sub registry where we can define the code points that characterize whether it\u0027s a software-based timestamp whether it\u0027s a hardware close to transmit or when it\u0027s Hardware being put on fly in the transmitter so exactly meaning interpretation of the components is open for discussion but this is something that can be discussed at the same time we realize that that can be information that only communicated in the data model so there is a trade off whether we put it in the packet or we just expose it in the data model again something to discuss yes another thing is back to the discussion of the timestamp format like in tea womp we already provision possibility of "
  },
  {
    "startTime": "01:51:46",
    "text": "using NTP and PTP timestamp formats and it\u0027s in the manner that actually the sender and reflector they can use different times than formats but that is communicated in a packet so that the sender because only the sender does a calculation of delay and jitter so he needs just to interpret both formats and this is a control playing function nothing to do with the data plane and that\u0027s why this heterogeneous deployment in our opinion is possible so we can go to the next yeah so it\u0027s already mentioned the tio V there was a proposal not to use the OB but use a bit field option the correlation again that\u0027s something that we opened the discussion and we appreciate comments on the mailing list from the working group an excellent so yes the idea is that in unless the gating mode stamp Center can be compatible with the tea womp white reflector and especially we got discussion with the offer of TR 390 that it will be good that it is well known port will be default port so that\u0027s t1 quite equipment that compliant with the TR 390 doesn\u0027t need to have to be provisioned and works seamlessly next please so the data model the idea is that use of data model is supporting enabling Sdn environment where we control everything from their controller Orchestrator and because we have a single point of control we can control both configuration and operational state of sender and reflector and so data model reflects what already being said is that symmetrical size use of UDP port 862 as a default port and then we propose performance metrics including percentile the feedback from operators the percentile is very useful in their operation and they suggested to have it something that the level of percentile "
  },
  {
    "startTime": "01:54:47",
    "text": "can be set whether it will be set throughout the old metrics or for each metric like percentile scale for one-way delay will be different for percentile scale for packet loss that\u0027s something to discuss i we believe that one scale percentile for all metrics is sufficient because we provide option to configure define three different levels of person so if there is interest to support usually it\u0027s like 95 99 in 99.9 the percentile being used but at the same time we provide option to change that and I think that\u0027s it so again this is just work started we appreciate your comments especially your thoughts on securing the test protocol there was one interesting discussion I had offline where realized that we might not need to do very much security for ipv4 because of communication that IG had that actually development of new functionality for ipv4 to seize and we do development of new protocols for ipv6 so if that\u0027s something that would be acceptable then for ipv4 will leave only unauthenticated option and then secure option would be for ipv6 just as an observer of the ways in mysteries of the iesg I\u0027m not certain that that arguments going to make it through a sector review but and my understanding is that so they the the ceasing new development on ipv4 doesn\u0027t mean don\u0027t secure stuff on ipv4 but I mean so then there\u0027s that there\u0027s the real question in the case so they\u0027re real you have to look at what the what the encryption is buying you rate so that\u0027s I think that\u0027s where that that\u0027s where this question needs to happen what are the requirements great like so what are the requirements one of the trade-offs and the trade-offs are somebody knows that this is stamp traffic can mess with the stamp traffic and screw up your measurements and then the question is what\u0027s the threat model why would they do that some of those threat models are more theoretical in some of those direct models you actually have to worry about rate so again since okay since we are going with their networks that care about SLA skewing the measurement any "
  },
  {
    "startTime": "01:57:48",
    "text": "problem yes that\u0027s a problem okay because basically they make your measurement worse that the your network is forcing you unnecessary actions and so so I basically creating instability of the network in this indirect manner so it\u0027s a real it\u0027s a problem right it\u0027s a real problem this this is something that would need to be addressed in the security consideration section there have to be an analysis done in an eventual draft so you just made a a request I\u0027m trying to have speed up so we can get through through the Lightning talks I\u0027d like to try and give everybody some time you made a request for adoption I brought up the list of current drafts just to see how much room we have because what we\u0027ve done in a lot of cases is you know brought stuff on until we have like a certain amount of stuff and then develop things in a holding pattern as individual and then went ahead and adopted them and brought them through I\u0027m looking at where we are with our current drafts though so we\u0027ve got this one which is V 602 that is gonna go into last call know a tiny - Sheppard right up that ones 20 to 30 ipv6 need to need to write up and I just assigned me right so we\u0027re gonna start Elsie on that and I\u0027ll do the write up we have alt mark which is an ISDN evaluation we have model-based metrics which is in the @q we have to UM yang which is going to have a 0 6 and is going to be out so we\u0027ve got three that are off our list we\u0027ve we\u0027re bringing on t om port which will be really quick yeah um we\u0027re bringing on our o which will probably not take as long as model-based metrics but might and I think we have another slot here so I\u0027m gonna go ahead and do the humming thing again who is so this has a this draft has kind of a very long history right so it started off as he went up late yes this is sort of an effort to essentially standardize that in a way that is safe to use and what\u0027s happened in the in the intervening time is um the the juggernaut and behemoth that his yang has now given us a way to put a control plane on top of this thing and that that\u0027s sort of what\u0027s changed here so who here has read this draft or is familiar with tea lamplight I see a show of hands okay it\u0027s the same usual futile act of measurement protocol suspects so I\u0027ll go ahead and and do the hum for a I\u0027ll have to we\u0027ll have to figure out how to do okay so to adopt a milestone "
  },
  {
    "startTime": "02:00:48",
    "text": "for the definition of a tea wimp light compatible protocol controlled by yang called stamp and this document as the UM as the milestone for that please hum now okay a hum slightly higher acoustic energy than the air conditioner for if you would not like to adopt this document please hum now that\u0027s below the noise floor on the conditioner but given that it\u0027s a tea one thing um I think that\u0027s sufficient to take it to the list so we\u0027ll do a call for adoption on the last busy on the list after uh after this so with that we are now into the lightning round of our meeting and we are about we had five minutes a buffer and we\u0027re ten minutes late so I\u0027m gonna ask the lightning talk people to be quick if you can so that we get a chance for everybody who is on this list to go I\u0027d really like to of dollar chance he\u0027s been over there um furiously typing the discussions up and I\u0027d really like them to get a chance to say it stop so how are you song you\u0027ve got three in a row yeah so let\u0027s just yeah cool thanks I\u0027m going to talk about three individual drops with each try to addressing try to address specific issues we found in the current IOM specification of course the proposed solution here is not the only way to solve this issues but we just hope this can help the community to be aware of these issues and eventually come come up with a newer or even better solutions here\u0027s it\u0027s just a or the best solution we can think of to address this issues okay the first one is about the data type extension currently the specification defined using a 16-bit it\u0027s bitmapped indicates different data types so ah it can and most support up to 16 standard data types but we can see with the new applications emerged new use case emerged we will eventually use up all these bits so if we want to continue to scale to support more data types we and it still uses this a bitmap encoding stay out and we need to find a way to extend it so here\u0027s a the proposal is we just reserved the last debate in this current a bitmap to indicate there\u0027s another extended bitmap follow the the "
  },
  {
    "startTime": "02:03:52",
    "text": "first header words so with this a simple extension we can immediately support another up to 31 you did it haves so again we reserved the the next bitmap last bit to indicate if it\u0027s one maybe indicates and another bit follow that so with this using this approach we can continue to extend the bitmap to support more and more standard did it hatched and if we the last bit is set to zero which means okay there\u0027s no more bitmaps follows and after that we are see the actual note data so this is the first next next slide so there are several use cases we already find in some example there are some meter box in the network which will change the flow packed header you want you if we want to keep tracking the the flow identification we need to have a way to actually save some of the header fields into the IOM data so we may need to define new data types in the bitmap also there are different different application scenarios like in the wireless mobile and optical networks which may require a different type of data such as power temperature signal chance GPS location and so on they may all need their own data types defined in the bitmap okay there are also other possible data types like the metered flow band waist time gap between two consecutive a flow packets and the buffer occupancy of the node and so on so we can see there are plenty of use case which may require more data types so this first improvement might be necessary ok next one ok so the second and proposal is about how we can limit the IOM data overhead so we know the IOM header can propose a significant overhead to the packet itself if we want collect more data and per node and also the the past collecting past is long then the accumulated data made it have a big chunk of use useful network bandwidth so how to limit that so one way to do that is we simply know what\u0027s a maximum overhead we can a support then also if we know how much data we want to collect at each node "
  },
  {
    "startTime": "02:06:53",
    "text": "then we can calculate how many hops we can accumulate the data and then at that point we have to strip off the IOM data and shipped it out then start from there we will refresh the IOM header and the start to collects the data from scratch and of course as a collector and the connector it can combine you know this the IOM data data for each segment and combine them together to form the to gather data for the entire in high-pass so the the proposal is also very simple we just reuse some one pi it helps up header a header field and we use one bit in the flag field to to indicate this is a segment IOM right then then we use for for P to indicate the segment size which actually just indicates a number of hops we can collect the IOM data and this is the remaining half so the indicates okay which part be already in this segment and each hop is simply I D Crimmins this number by one so if if the our hop reached there oh you know we already reach the segment boundary then we need strip of the IOM data and then we reset this to the to be equal to the second size and start working so by doing this we can we can know what\u0027s a maximum size of i m iom header so next slice released several use cases so you want extreme case we can just set the segment size to one which basically asked require that each node to stand the IOM data out immediately it never puts a data extra data in the IOM header so we can minimize the overhead also it has a side benefit if the packet is happily dropped in the network we know exactly where it\u0027s dropped by just a check okay and at which point we stopped receiving any more IOM data for flow also there there might be some practical limitations on MTU so this give us the upper upper boundary for the practice size so we can based on the what what amount of data we need to collect and each node then we can calculate exactly what\u0027s the segment size is also there there might be a very "
  },
  {
    "startTime": "02:09:58",
    "text": "long past so if you want to keep accumulate data you want each node you know it\u0027s very ventually exceeds the capability of the each node because each node they deplane device may use that use a mean and most that amount of a header header data if it\u0027s a true deep it can not no longer to process it so in that case we have to limit the size of the IOM header so we have to use as a sum idea like segment io am okay next one so here comes a last one about the OM iom data a well at it validation option so basically we propose to type our bitmaps to indicate the data validation well validator indicator the first one is a bitmap is for to indicate the note Verity to validate the notes so some some IOM capable knows they can precise the IOM header but for some reason maybe is too busy or for some other reason it\u0027s just refused to add the IOM data so it can simply set a bit in in this note valid bitmap to indicate okay I will not participate this session and I won\u0027t Adam and it ate her to the to this following data list so so the receiver can just even know that part or or Assessor don\u0027t indeed inserted in this list and the Capac data together to to save the space so another useful bitmap is applied for each node in this data list right so so there might be the source may require us for different type of datas data but some nodes may find it can note support this type of data may be due to the you know the version difference or just the sauce ask for some data this notice is incapable for providing that type data or it might be also too busy to handle that request so in that case it can also set just add a bit in this in the bitmap for example here is the result as for this this this data one two three four five six seven seven different type of data but here are we have this "
  },
  {
    "startTime": "02:12:58",
    "text": "validate a bitmap for each each data node to indicate okay this data and this data or we cannot provide it then we can only provide five of them so then the following data array we only provide five valid data but these two atoms are just invalid we can can be ignored so by doing this we can also support different use cases okay so yeah I already mentioned maybe I will not repeat it just uh this is used to handle the case that some nodes just want to refuse to serve some data requirement or it can even have a ball fighting that kind of data so for this use cases this improvement is useful so that\u0027s one that\u0027s it thank you comments or questions on this please take him to the list so next morning I\u0027m Sami from TP this job is extended om to convey in situ om configuration state intention of this job this job provides a method for the IOM encapsulating know to determine the IOM header and the discharge dynamic lactation is proposed a traditional om mechanism such as SN keeping or NPS to ping can be used to convey Aaron conversion state this diagram illustrates the principle of this job eylem encapsulating node can send echo request to every iom transit note I am decapsulation note in this island domain and every receiving node can respond with echo reply and there\u0027s a quadruped I include it\u0027s a ion configuration state next a new tier VI ramp configuration data theories introduced in a kuru cast when is the always present in echo request it means that IO am encapsulating note request to receive in order to reply with his IOM configuration data next at the same time a new tier VIII IOM confusion that govt "
  },
  {
    "startTime": "02:15:59",
    "text": "is also introduced in echo reply and the next four slides show the sub Q is that can can be included so we asked for more review in the comments and the razzes chapters love comments and then maybe ask for adoption so please have a look and um if you um if you see something you like take the list if you see something you don\u0027t like take it the list and then next okay here are currently you had has already a kind of aesthetic loss measurement but maybe it\u0027s not accurate enough so we want to extend it to up to about direct loss management control trap control extension a new direct loss management flag is introduced in this job and it\u0027s backward compatible with that already find the flexed next this is an extension to Q AB test first the standard test packet and you send a text counter is added to this packet and this set said to the number of IP packets of the particular monitored flow transmitted towards the factor thanks for the reflector test packet three new counters in it I did so okay next this is the calculation formulas for the traffic elastic calculation and you can use this formulas to calculate the fire in the rows here and the last fan the loss ratio and the end row special okay thanks also the same as for comments well resided instruct cool thank you very much and same comment from the chair she\u0027s annoyed people assuming you don\u0027t like take it the list thank you very much so next we have Josette Bay morning this is an update about multi-point marking draft next document changed from zero zero ashen to zero one version make to true important modification the addition of a new section about correlation with our FSC 56:44 thanks to all Martin for comment in particular we need to extend some definition of this RFC because this is limited to active measurement so we need to extend multi-party metrics from one to group also to group to group and same for segment matrix and also we added "
  },
  {
    "startTime": "02:19:01",
    "text": "some definition and some new methodology for delay particular summer FC of about the hashing selection methodology 5474 at 54 75 so why we need multi-point marking so alternate marking works very well by definition in case of a multi-point path but this draft is very useful because we need to formalize how the marquee meter can work in case of multi point paths and we need a draft to formalize and to highlight the property of this methodology so in this way you can choose the identification fields and the create the filter criteria without any constraint next so in general for example you can imagine to have an SDN controller if you if you have an SDN controller than can manage all your network with a marking method you can calculate and the network packet rows that is the difference between the number of input packets Minho\u0027s number of output packets so in case of in case we have no pocket rows okay no problem but in case we are part it was we have to individual the flow that is experimental departed rows so we can identify the sub networks that are the smallest sub networks where the packet rows property is still valid so the number of incoming packets is equal to the number of going pockets so net so we can individual the classic why is a useful identification of this cluster and of these sub networks because if you have your wall network and if you are experiment some packet rows you can make a per cluster basis analysis so in the few I want you have individual to the cluster that is experimented pocket rows you can make a detailed analysis on only on that cluster without so without use a lot of resources and so on so this give more flexibility and resource savings this part of presentation is about the delay so the min delay works in case of multi point the double marking delay doesn\u0027t work in how to make multi point but we have found some result in narrow feci 5474 and 5475 about using a hashing selection for simple pockets and these make this a methodology that caplet with the marking methodology very powerful next in fact they are FSC 5475 of the same weakness that can be solved by the coupling with marking method methodology first weakness is that we have a difficult implementation of the ashing selection in a continuous packet flow but the marking method can anchor the "
  },
  {
    "startTime": "02:22:04",
    "text": "same pulse width in a marking period and this is very useful in particular for the correlation aspect the second problem that is solved by marking method is the possibility to have a dynamic cache so to change within a marking batches the number of ash bits in order to make sure and to guarantee that number of samples are almost constant within a marking field next so we got some input during that the ietf last call that makes alters also this work were interesting and we got some reviews before the desire atf meeting from more Morton and we would to address these this comment in the next version so next slide okay this is a summary hope you can read this draft because a particular is a good next step for a marking method and I suggest also to read the compact alternate marking draft that is related oh thank you very much and Wow exactly five minutes um yeah thanks my name is tal Mizrahi and this draft is called compact alternate marking its joint work with karma Giuseppe Mauro Mac zero and Greg just to satisfy my curiosity how many people have read the draft okay thanks so what we\u0027re trying to do here is to measure the performance between two measurement points MP 1 and MP 2 next please and alternate marking in general is a method which uses a marking field in the header this field is used for coloring the packets between the two MP measurement points and it splits the traffic into consecutive blocks of data X please so the scope of this draft is to define a set of compact alternate marking methods which means we use just one bit or data packet or 0 bits per data packet next please so one existing alternate marking method which is used which is worth mentioning in this context next please is the double marking method the idea is that in every data packet we use two bits one bit is used as a color indication the other is used as a timestamp indication next next please okay so in this draft one of the methods we define which uses just a single bit per packet is it called multiplexed marking the idea is that instead of using the two bits from the double marking method we multiplex these two bits we use the rusev or between them and that allows the same level of accuracy as the double "
  },
  {
    "startTime": "02:25:05",
    "text": "marking method we with just one bit per data packet next please another possible compact alternate marking method is called pulse marking the idea is that in each time period we have just one packet which uses a different marking value and that one packet per period is used as a reference for the measurement both lost and delay measurement in that period next please the draft also defines methods with zero marking and the idea is to use hash based selection so instead of using a field in the header we compute a hash over the sum of the fields in the header and then if the hash is equal to a predefined value then the packet is used as a reference for measurement and of course we can use mixed approaches where we use one bit in the header and also we use the hash next place next okay so the draft also includes a summary of all the existing alternate marking methods and the new methods which are presented in this draft it also presents kind of a comparison and a trade-off between them next please so one thing that may come to mind is okay another internet draft which presents things that will never get implemented so this is not the case here we actually presented a live demo and the ITF 99 bits and bytes Josep and Malraux from Telecom Italia are actually experimenting with some of these methods on their network so this is actually being implemented in practice X please so please do not read this draft if you\u0027re not interested in performance measurement however if you are interested in performance measurement you should definitely read this draft you should definitely have an opinion about it and we want to hear that opinion on the mailing list thank you thank you very much um Wow we have two minutes left it\u0027s not enough for any other business uh so um thank you very much everyone this was I think this is a really good meeting um I\u0027ve got a bunch of to-do items which roll at some point later in the week once uh once my queue drains a bit will lead to a flurry of emails to the mailing list so there\u0027s some Shepherd write-ups to do we\u0027ve got uh one two three working group calls for adoption coming out and yeah so with that I will see you all in where are we next frog yeah okay London yes okay so I\u0027ll see you all in London um have a great rest of your year and a great rest "
  },
  {
    "startTime": "02:28:05",
    "text": "of your week thanks a lot [Music] [Music] you "
  }
]