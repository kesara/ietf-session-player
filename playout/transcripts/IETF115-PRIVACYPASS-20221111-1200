[
  {
    "startTime": "00:00:06",
    "text": "I don't care all right folks uh welcome to uh privacy pass at ietf 115. um here in uh London and uh Ben is online and thank you thank you all for coming um let's see just a few things I know this is this is The Bitter End of the meeting and so the note well you've all seen this before about what you should consider before you're contributing to the ietf and and code of conduct um so I'm just gonna leave that up there for a brief second but if you're not familiar with it obviously you should be by this time in this week um code of conduct uh this group is in general really good um but we want to make sure we treat everybody with respect and and uh keep focused on engineering Solutions all right here comes the hardest part of the meeting we are requesting a note taker don't all jump up at once folks online can do it too all right thank you Florence um next let's see so when you're in the meeting room please sign into the on-site meeting tool so that you can join the queue it makes it a little easier to manage the cues between remote participants and local participants you know this already you've been here a while all right for our agenda um we have a couple of uh discussions of working group drafts um right now we have our core documents"
  },
  {
    "startTime": "00:02:00",
    "text": "either through working class call or in working group last call and we really for the ones that are in for the issuance document and the HTTP off scheme really want to make sure we get good review of that I haven't seen much activity in GitHub lately or on the list we want to make sure these documents are ready to move forward so please put your reviews in Tommy uh yeah just to comment on that for the core docs um we did get some good review on the auth scheme and we sent that over to http and we made some adjustments based on that so okay yeah yeah but I think uh definitely emphasizing the call for review on the issuance protocol um since that one has not received and it would also be good I mean these these documents have been around for uh for a little while so um you know even if you if you've read them and you feel like they're ready to move forward and letting us know on the list uh would be helpful um because there may not be much to comment on at this point but we'd like to make sure that these are being reviewed um we did have a plan for some time to talk about uh key consistency because that's a newly adopted draft but we did not have anybody take us up on that so we're going to strike that from the agenda today but if anybody wants to make any comments on that uh that would be fine um other than that we have a few other presentations is there any other business anybody thinks we need to conduct at this time or modifications to the agenda"
  },
  {
    "startTime": "00:04:00",
    "text": "all right given that um I think Tommy you're up and I'll assume that you'll take control of the uh let me just get rid of this and you should be able to share the slides right yeah um if you just grant because yeah perfect thank you all right um hello everyone um I'll be giving the update on the rate limited issuance document which was adopted since last time um and one of our co-authors Stephen is in the room he'll be presenting some stuff later but he can also help chime in so uh the two things we wanted to go through today was one is just a recap of the differences in rate Limited uh token issuance as compared to the basic token issuance just to remind people um since this is the first time we're presenting this as a working group document and so you know take a look make sure you understand and are happy with the the current shape that's in and then we'll go through some of the open issues there's essentially one major open issue and then we'll just mention some of the other smaller ones all right so starting with recap what are we doing here uh so this is an extension essentially to the basic issuance protocol it is based on the publicly verifiable variant uh which in the basic one is Type 2 and the difference here"
  },
  {
    "startTime": "00:06:00",
    "text": "is that um this is essentially always done in the split a test or an issuer model whereas uh with the basic type you can either have them split or combined and in this model the a tester is maintaining some state on behalf of the client essentially counting the number of tokens that a client has received for An anonymized Origin bucket and this is a bucket that is defined by the client it provides An anonymized Origin ID and the a tester can use information it gets from the issuer to validate that this anonymized origin ID is indeed a one-to-one correspondence with some origin but it doesn't know which uh upon requesting a token through the tester that goes to the issuer and then the issuer in this responses to the tester adds an extra bit of information which is a rate limit to enforce and so it gives out a token and then says um this is the number of tokens that I'm going to allow for this origin and um it doesn't the issue does not learn if that uh rate limit was reached or not but the attester uses that to drop the request if the limit is reached um so looking at this visually again there are two halves of all of the different privacy paths protocols there is the side that actually talks to the origin that's uh the challenge and Redemption flow and then there's the side that is the issuance flow so there's a very"
  },
  {
    "startTime": "00:08:00",
    "text": "minor change to the um Challenge and Redemption flow well there's actually no change to the Redemption and the challenge um only has to include one new key and this is a hpke key um that corresponds to the issuer so that the client knows how to um encapsulate the actual origin info and the origin name when requesting a token to the issuer and then on the issuance protocol side um the main differences are what we alluded to before but um more concretely here there is an hpk encrypted inner request to the issuer that the tester passes along but it cannot read that contains the origin name uh there is an anonymous origin ID that the client communicates the tester to be this bucket for keeping counts there is the uh token rate limit per time window that the issuer communicates the attester and then there's also a set of signatures that the client provides and that the test the issuer also provides input on to prevent the client from cheating and saying that what uh is in reality one origin trying to make that look like it's two uh looking on the chat um the origin here chooses the singular issuer and gives the um yeah so any particular challenge is related to one issuer the origin can provide multiple challenges"
  },
  {
    "startTime": "00:10:01",
    "text": "but any particular request for a token is bound to an issuer and that's the same as the basic types that's no different from that um so looking at the actual uh on The Wire bits so this is how the basic token request looks like um for the publicly verifiable type it has the token type key ID and the blinded message and the difference for the rate limited it has a different token type and then it has the stuff in green which is a HP key protected inner request that gets passed along and then it also includes um information for the signature and then the inner request is what includes the key ID the blinded message and the origin name info all right so that is the recap of the protocol and its Delta from the basic type and so going into the issues the main issue that we've been discussing recently is number six on the GitHub um which is about a linkability attack that was not detected earlier on that has to do with a malicious issuer um so in this case the Melissa the malicious issuer is uh reusing something called the issuer origin secret across different Origins this is the secret that is used uh in the responses from the issuer to the attester that help the tester verify that the"
  },
  {
    "startTime": "00:12:01",
    "text": "client is not uh cheating in terms of what it's claiming as its Anonymous origin ID um so the point is that the issuer can essentially confirm it when it's working well that to that what the client claims are two different Origins really are two different Origins um however um the issuer could maliciously say that oh yeah all of my Origins are the same origin um to essentially make it look like the clients are cheating or malicious and based on the current text in the document when the tester detects this Collision since it was assuming that that is a malicious client it currently just says you drop that request on the floor um and that is kind of the root of this particular problem because if you were dropping that on the floor then that is potentially a signal kind of going out to whoever requested the token that uh may be the reason that this request didn't get a successful token back was because uh you had hit this Collision which implies that you had uh previously requested a token for a different origin right so if you had uh various Origins colluding with their issuer um to say you know hey you know make me collide with this other origin and then I'll try to guess that when a token fails to be generated it was because that client had previously talked to a different origin it's not a particularly direct signal"
  },
  {
    "startTime": "00:14:00",
    "text": "there are many reasons that the um the token issuance could fail you could have hit your rate limit the tester could have not liked you for some other reason but it is kind of a bit of information that you could leak if the tester naively just drops requests foreign so the proposed fix that we think is the kind of the the smallest Delta and kind of the correct thing to do for the protocol is uh to not just naively silently drop a request if you see this type of collision not only does that allow a malicious issuer to leak a signal but it also isn't uh particularly useful um you know let's say we do have a malicious client that is intentionally trying to make different uh or make one origin look like multiple different Origins silently dropping the requests on which they're trying to cheat and not doing anything else is probably not the right thing to do um you know the whole point of this a tester vouching for the client is that it is a testing that you know it meets some bar that it is a legitimate client um foreign ER has detected cheating it should probably instead you know penalize the clients or you know say you know you're no longer someone I'm willing to serve tokens for so overall you know we need to work on the text here but The Proposal is that instead of just dropping a request silently the tester would flag the Collision events"
  },
  {
    "startTime": "00:16:00",
    "text": "and use the Collision patterns to reevaluate trust in the issuers OR clients and you know in general with non-malicious implementations these cases should uh you know you should never have these collisions so if you have them they do indicate that someone is messing with you if you have a case of a malicious issuer that is using the same secret across multiple Origins the pattern that should be become visible is that you're going to start hitting collisions across many different clients um if the tester detects this situation it should you know rather than just dropping a request it should essentially you know remove the issuer as a trusted partner or kind of you know put put them in a penalty box at the very least and similarly if the if it's a singular client uh that is doing this and it's not across many different clients for a particular issuer then the heuristic can say you know we're not going to issue any more tokens in the future to that client so overall uh rather than dropping a particular request in the moment the approach should be uh rejecting future requests for that client or if you detect eventually that this is more likely the issuer problem than is the client then you stop using that issuer which effectively stops using letting any client talk to that issuer through that a tester as a bit of sidebar we filed another issue that you know we should have more text in this entire area as we were talking about it you know we've for the basic types we already have some experience with uh a test or an"
  },
  {
    "startTime": "00:18:00",
    "text": "issue or deployment we're getting a lot of more issuers being deployed for the basic types and we're working with our tester and they're there is already a fair amount of validation that needs to go on between an attester and an issuer um there are things Beyond just its pattern of uh you know are you uh being malicious or not but are the lengths of the windows that you have for uh enforcing a rate limit uh an acceptable thing you shouldn't have windows that are one minute long you shouldn't have a window that's a year long so there are things that the tester needs to validate before it's willing to trust an issuer for that um the different rate limits um there may be bounds on that you may not want to accept a rate limit of one you may not want to accept a rate limit of a million and so there are values that you need to be able to validate there and of course you also need to make sure that um if this is uh kind of a generic case that the issuer you're working with has enough different Origins being served to create an anonymity set um so I think overall there should be more text in a section on the trust relationship between the tester and the issuer and part of that then would be um the Collision detection uh then the other direction I do want to bring up um for that uh malicious issuer attack um there was an alternative approach that Nikita brought up and we discussed and I know he's on the call here which would involve a completely different approach uh to the uh"
  },
  {
    "startTime": "00:20:03",
    "text": "signature uh that currently prevents the clients from cheating that instead of using uh that crg work uh you would instead use zero knowledge proof that the client would present to both the tester and the issuer and be kind of like a one-way thing um so this is cool um it does however rely on new crypto that's not specified yet in any document and would have uh more impact on the protocol and who knows what and how you would uh have to deal with other normalization issues so you know this is something that were we to go in this direction would need uh a lot more you know kind of starting from scratch in cfrg other discussion um and you know we're not sure all the details of how it works so um I think my recommendation and our recommendation uh as the authors is to uh for the basic rate limited type that we're defining now uh do the fixes that we previously mentioned but I have the zero knowledge proof uh Direction B candidate for future token types and future work in this area um once it's gone through cfrg other um groups and other analysis I think there's other features that people have discussed Beyond just like a basic count of rate limit that could involve state or these more complex relationships um and bundling the news or knowledge proof so if that would make sense to me so"
  },
  {
    "startTime": "00:22:00",
    "text": "um yeah I I see some comments in the chat that's yeah it does seem like a big change um but yeah I think it's very cool and I I think we should keep pursuing it um I think one of the benefits of the architecture that we are using is that we have flexibility on token types we can Define new token types that people can move to that can bring us new cryptographic algorithms that can bring us new capabilities and properties um so I'd like to see this used there and we do have uh somebody in the queue if you'd like to oh do we yeah oh sorry I didn't see it John um not a question just the note that um the uh Jose work group is in the process of being recharted by the iesg to formalize jwp which is pretty much exactly what you were just talking about so um there is a the Jose working group is intended to look and formalize how to do Json tokens with um zero knowledge proofs approved algorithms from the cfrg so that is in process um if people are interested then pay attention to the newly reformed Jose working group should they see it RG approve it next meeting okay got it yeah um we will definitely want to track that and yeah I'll also see what common bits are present in cfrg then thank you um great and so then the other uh open issues uh there's some discussion about the uh token key ID uh length and if that should change"
  },
  {
    "startTime": "00:24:01",
    "text": "um there's a discussion around uh ways to potentially hide the issuer rate limit from the tester that is something that we think may work better in a future token type kind of like the zero knowledge proof um there is an issue just remember this um ah yes uh I think we need more discussion and text around how um you deal with rate limited tokens when you have an origin info that lists multiple Origins so this is like when you have a third party um you know let's say you have a recapture embedded on some other website and it wants to do a rate limit and how you handle which one is kind of the one you're limiting on and then this last one I mentioned uh where we want to expand the text on the trust relationship between the testers and issuer and what they need to um validate against each other uh so that's the end of the slides I have here um I think our main next step is to update the document for these issues based on what we discussed here if people have opinions we'd love to hear that we are still tracking the cfrg dependency for the signature key blinding that helps us do the proof that the clients are not cheating and other than that we're gonna keep working on this um any questions there were a couple questions in the chat I don't know if folks are wanting to bring those to the mic yeah I tried to address some of them as I saw them coming by but"
  },
  {
    "startTime": "00:26:00",
    "text": "Nick yeah thanks for the um overview I I was asking about the um uh I think it's an encapsulation key right that the origin provides uh I I want you to go get a token from this issuer and gives you a particular key to use to uh encap your request um and that just seems like a potential tracking Vector I know there are other tracking direct vectors if they um collude but um that seemed like a potentially significant one um and it seems like there's some mitigations in the document about the a tester can help mitigate by trying to make sure that the key isn't um unique or something uh is is the is the assumption that okay there should be a single key for each origin like there should be a universal a consistent E3 Georgian right right and so part of this overlaps with the key consistency um document an approach but yes there there is for the hpk key there would be one or you know one wrote slowly rotating key um for that issuer um and so you need to make sure that you have the same key as everyone else and the working with the tester is one way to do that that like if you're doing a key consistency approach um you you have one source which is the origin uh telling you here's the key to use and the tester can also potentially be a Vector to validate that that is the same as we see what it sees across all other clients"
  },
  {
    "startTime": "00:28:00",
    "text": "and does that I mean if if it is going to be that sort of consistent does it even need to come from the origin or just should there for an issuer and the Orange is not involved at all yeah it definitely doesn't need to be um and I don't recall offhand but I think I think it is optional like because even in the basic um token requests the origins include for example like the RSA flight signature uh public key that they're going to verify against that is something that doesn't strictly need to be in the challenge if the client has another way to get it um so um Origins could leave it off um and then you know essentially Force the clients to fetch it some other way but it uh it is defined as a parameter that can be included in the challenge if that makes sense yeah that um that that's helpful I mean it does it does seem like we should have as little information in coming from the origin that could be used to directly communicate with the issuer yep yep that's a good point thanks uh yeah I I think sometime when we have more key consistencies key consistency discussion we should talk about how those related um Ben you had had a question on the chat about the blinding being symmetric encryption was that answers I'm very uh I'm very naive about all this all this stuff that I've been trying to figure out if the key blinding is just equivalent to taking the taking"
  },
  {
    "startTime": "00:30:03",
    "text": "the public key and encrypting it under symmetric encryption and passing the passing the password around that you know passing the the symmetric key around as needed is that is that all that the key binding is actually doing here um I don't know if Stephen or others would want to comment on that um Stephen Google um so the scheme there is slightly more complicated than just the symmetric thing like it's using the public key of the issuer but then we have the extra binding so that the tester can verify some Anonymous ID that the or the issuer provides without like learning the actual origin or key information so it's like slightly more complicated if we didn't care about the attester and not learning like the Intermediate result you could use something more symmetric but I think that's why we need the like heat Landing like the RSA cleat blinding dependency here uh so I'm not talking about RSA blind signatures I'm talking about the couponing yeah okay uh yeah I'm happy to I'm happy to take this offline I don't need to waste time on this yeah yeah we um I would rather that uh you know Chris Wood and some of the other authors on that comment authoritatively I don't wanna uh perjure myself all right okay any other uh questions all right so it sounds like uh there's a we have kind of a way forward for some of the issues uh raised some of the other ones still maybe need a little bit"
  },
  {
    "startTime": "00:32:00",
    "text": "work but seem relatively straightforward so uh I guess we'll expect some revisions and work on the on this document over the next couple months that's right thank you awesome thank you all right I believe next is it I think we have a Steven up to talk about what's going on in w3c let me get your slides up or pulling slides I don't know um I think I've never tried it um can you share a slide through that maybe you need to do the sharing then or do I share do you share uh okay you should have it cool so I'm Stephen Google I'm gonna give a quick overview of the current state of privacy pass s work in the w3c and where some of the next steps might be there um so there's a few relevant Works some of them in the w3c and some of them not quite there yet there's private access tokens by Apple cloudflare and fastly there's private State tokens which was for well known as trust tokens there's a device at a station use case that has been coming up in the w3c and there's a few other uses that have come up so I'll go over them and we'll see how much of this is purely w3c work or how much of this might be work that we want to pursue in the future in the Privacy success group so first private access tokens is one of the more mature things it's based on currently the blind RSA and the rate limited token draft that is currently undergoing adoption that Tommy just talked about it's pretty close to the existing privacy pass protocol there's very minimal deltas um the thing is that you need to do in the w3c to support this are the there's a fetch API this is different from like the JavaScript Factory people a but this describes how web requests and web"
  },
  {
    "startTime": "00:34:00",
    "text": "responses attach various information such as the WWE authorization headers that we see in private in privacy paths in the authorization draft um there's also some question if there's a way to delegate usage of this API and that's also going to require w3c work to allow this API to be used outside of just the top level um so for this particular API I think the it currently doesn't exist in any community group in the w3c but I think it would likely end up in either the wiki which is the web incubation group or the anti-fraud CG which is a group working on a bunch of anti-fraud technology which private access tokens sort of falls under as a quick aside the w3c has a bunch of different groups there's interest groups which are exchange of ideas Community groups business groups working groups the important distinction here is that computer groups tend to do like early work on various ideas but don't actually produce deliverables or standardized documentation eventually once something is in a good enough State there it'll move into some working group I think for privacy pass related technology this would likely be web appsec though if there's a lot of interest and a lot of like things derived from privacy pass it might be worth having a new working group so I think the yeah the general structure is we'll have Community groups working on this sort of things for early design and getting input from other folks and then move it to a working group to actually create a deliverable of effectively an RC finalized document um so to talk a little bit about how private access tokens usage format Works um right now token issuance is a trusted tester in the Apple case it's the Apple platform um and I think that's the general idea for Access tokens um and then any uh website is allowed to redeem these tokens to have some proof that like you can access this resource because you have a real device or a legitimate platform um and then to do rate limiting with the rate limiting draft dude both rate limit of each origin is only allowed a fixed number of tokens so you don't like go"
  },
  {
    "startTime": "00:36:00",
    "text": "take a hundred thousand tokens from one device and go spread them to a bunch of malicious devices and there's also rate limiting based on the attest or can rate limit like you don't want to be spitting out a ton of tokens for one specific device uh just since these sorts of token farming attacks are quite common at least in the web space around cookies and we'd expect similar things with uh private access tokens and other privacy pass related technology um so another API undergoing work in the w3c is private State tokens it was formerly known as trust tokens uh but both the name trust there didn't quite reflect what it actually did and it was better to try getting it to a closer more coherent story with all the other tokens that are undering work it is based on a very old version of privacy paths the vopf draft and I think from like three years ago and a not standardized PMB tokens graph which is a version of privacy pass that has a private metadata um I think there is a plan to update this to the more recent version once the drafts are finalized and we have an RFC cut of it um and hopefully a PMB tokens drafted that's still of interest in the ITF could get standardized though it's unclear how much interest they'll be here and how useful that is um it is currently in the wick tree um we're hoping to move it to the anti-fraud community group just because while the web platform incubation group like there's lots of documents in that you don't get as much feedback and response there and anti-fraud I think is the core use case of that API so we're up to move there um let's see uh the model there unlike private access tokens is that any website either first party or third party would be issuing tokens if they have some concept of the users like legitimacy I think the recaptcha edge capture case is the primary one here also if you have a strong first party identity and then you're willing to share that information that might be another case where you want to be"
  },
  {
    "startTime": "00:38:00",
    "text": "issuing tokens and then other Origins can redeem tokens from those particular users there's likely going to need to be some sort of partnership between the issuers and the folks redeeming uh just because they need to know what a token means like if you get a token from some random issuer and you don't know like what it actually is attesting to what it's actually promising that's less useful at least for these sorts of ecosystems um one other thing in private State tokens that's slightly different from privacy pass is to avoid having to spend a token for all like 50 requests you might make on one top level page there's a concept of a Redemption record which is basically like a stored local cached version of the Redemption um though this is charted by the top level to like avoid that Redemption record acting as a cross-site tracking vector um so some other Deltas from the privacy of house protocol uh that hopefully will go away as far as things get standardized or we update to the new rfcs is for private State tokens in order to get key commitments and to avoid the like different users getting presented different keys we're using the data database Discovery Model which is described in Chris's draft uh which is basically there's a central service that fetches all the key commitments and those are provided to clients having some sort of standard around like how this actually functions beyond the random thing that's written for private State tokens would be good and hopefully some of that work can come out of the key consistency draft currently private State tokens instead of using the application private token request method where like use an entire post it instead runs the Privacy pass protocol via headers on existing fetch request or existing xhr request I think this was partially an optimization because having a completely separate Quest was an extra overhead um that's possible we can just move to this post method and with a lot of the H2 things allowing for pooling of connections and requests the value here might not be all that useful"
  },
  {
    "startTime": "00:40:01",
    "text": "um another thing though this is unlikely to be specified in the its is that there's a way of triggering all this using the fetch JavaScript API instead of just HTTP authentication the idea here is that there are various websites that won't want to do a full like run a separate request or have to embed a separate like iframe on the page in order to get tokens or if you want to do it in the middle of other activity happening on the page I think we hope to also add HTTP authentication to the private State token so it would be a strictly like super set of what's currently provided in privacy pass and what private access token does um and as I mentioned before there's the Redemption records which help solve some of the latency issues where you have a bunch of requests from the same top level origin um so moving on to slightly less thought uh fleshed out Solutions a common thing that's come up in the w3c anti-fraud group has been the idea of having some sort of device out of station similar to private access tokens but like some way to attest to facts about the device or test two facts about the client but this needs some sort of mechanism some sort of anonymous credential style mechanism to do this without leaking information about like this particular device ID some variants of privacy pass might be useful here either building up on the private access tokens private State tokens or some other variant if there are other types or other parts of that attestation work that either need slightly different features or need don't need a lot of the extra complexity here um let's see there also have been a few other uses also similarly less well thought out in Pat CG which is the private advertising technology community group there's a thing called the aggregate reporting API um this is basically clients send reports but there needs to be some way to authenticate this avoid uh attacks from uh fake devices or devices that aren't authenticated in some way you don't need a like real user"
  },
  {
    "startTime": "00:42:00",
    "text": "identifier attached to the support so you just need someone somewhere like was fine with this and attaching something like privacy pass might be useful there there are a few complications here where you want to bind tokens to like particular origins or include some amount of public metadata inside Beyond just the like your choice of keys so we need some of the more complicated uh public metadata forms of privacy pass for that case um but yeah privacy degree has been visiting other sorts of privacy preserving technology so there might be some work there and then at tpec the web often and web Havens folks had a joint session with the anti-fraud group and there's was some vague interest in various blind signature methods and honest credential methods there to test to something about like you are you've worked with some instrument providers some credit card providers in bank and you want to attest to some facts about that in privacy paths or other variants of this might be useful in that space um I think that's all okay Nick Martin's in the queue if you're ready for a question yeah Martin Thompson I just want to avoid creating a mistaken impression about some of these things I think this might be misrepresenting a little bit what Pat Sage is actively working on the there are proposals in our community group uh to adopt think the aggregate reporting API is just one of the candidates that's being discussed there's there are some designs that don't require at least don't require to the same extent those sorts of capabilities as a result of their design so there are some designs that rely very heavily on something like privacy pass and others that that rely on it somewhat less so to be clear with the device attestation and the ones here this is places where privacy like technology has come up it's not necessarily A Hard requirement or even likely to happen for these but it's"
  },
  {
    "startTime": "00:44:01",
    "text": "places where we might want to look at for future use cases or other extensions that might be useful in the space okay cool all right so it sounds like there are some dependencies between the the two groups but right now there are is there any any problems that we need to address like with respect to expectations of the w3c on work that we're doing or vice versa um so yeah I think for a lot of these it's still in the early stages so there's no strong expectations um I think depending on how the standardization process and the input we get in like the various CGS like some of these things particularly the key consistency might be useful to have some baseline sorts of things in the ITF um I think for most of these the we already either have that through the rate limiting draft or some of the other items undergoing adoption but maybe good future points to future work that once that like gets to that state okay uh Ben hey so it sounds like the work in the w3c is really pretty nascent uh there's no none of these proposals have uh have actually moved into a working group so uh what are the odds that by the time uh By the time any of this work actually is moved into a working group um it'll turn out that the specifications that we've written now actually are not what's needed and that it turns out that for example what the working group wants is PMB tokens or uh some other arrangement with properties a little bit different from what we're specifying um I think that's one of the benefits at least of the like the way the core protocol models are structured like if we need slightly different properties we can come up with new token types and work on standardizing those at least I think the general issuance Redemption format of the core protocols is like"
  },
  {
    "startTime": "00:46:02",
    "text": "pretty like in line with what we've seen and I think it's mostly just going to be a question of additional token types to expose whatever features we need in the space okay thank you Tommy yeah um just to answer a little bit also to Ben's question there I think um the the benefit of how we ended up designing the HTTP off scheme in privacy pass means that you know it is usable kind of by various websites without a w3c particular adoption or change to JavaScript apis um so you know people are able to deploy it and use it independently so um like our w3c is not our only customer directly right like people can benefit from it independently um I think there's also you know some very minimal work that can be done to like we're talking about you know can uh you mark on like an iframe specifically which iframes or third parties are allowed to issue issue token challenges or not and what the browsers will accept and that's something that you could do very uh surgically and minimally within w3c work that would integrate well with what we're defining here in privacy pass and then there are these other use cases which may be able to use privacy passes for defining it or may didn't may need a new token type but I don't think it's um invalidating the basic types I think the basic types are still a good foundation that will be used uh regardless of how complex the adoption in w3c is on top of them"
  },
  {
    "startTime": "00:48:06",
    "text": "okay um any other comments or questions Nick yeah is there um is there documentation or a specific proposal on the private access tokens um I I personally wasn't aware that was using uh rate limiting um version of this and um I'm sure that's my fault that just if there's somewhere I could be reading that or if that is likely to go through standardization at w3c then um that would be helpful thanks Tommy maybe yeah I can respond to that so the the the private access token name is just um it's not a formal thing really um it's what when like apple talked about our tester that's what we talked about at our conference because that's what marketing wanted to call it um really all that is is just the basic uh publicly verifiable privacy pass token and saying that we support it and we also intend to support the type 3 and other testers and platforms can support those as well um so I I think the parts on top that this is referring to is um you know do we have changes to fetch or permissions policy that really probably would they wouldn't talk about private access sections they would just talk about like uh privacy pass um or like the private token off the scheme type essentially saying what uh resources are allowed to uh include the private token off scheme"
  },
  {
    "startTime": "00:50:02",
    "text": "challenge and that's all they would amount to it's just kind of giving boundaries on who you accept these from and is there a is there a dependency or an implementation of the newly adopted rate limited tokens draft or is that a not necessary for um it's it's a bit separate so the like the type 2 is supported you know in production for us um with different issuers we support kind of like uh beta testing with the rate limited types but I don't think the type actually directly impacts what would be here in the like the permissions policy for example in w3c that would just say like are you allowed to issue token requests in general and then the actual challenge would include within it the type and so if there's Type 4 or type five you know who whatever else comes out um I I view this more as just a way to enable some uh communication about privacy pass in general at the um like permissions policy layer okay thanks all right unless there's somebody else who wants to join the queue um uh thank you Stephen that was a very useful all right next I think we want to uh have kind of a chat on where privacy pass is and where uh we can you know what what sort of"
  },
  {
    "startTime": "00:52:01",
    "text": "next steps might be were you able to share the deck yeah there we go so I think Ben will take us through some of this hi everybody so uh we've got plenty of time left in the session and uh that sometimes means that we're running out of things to do I don't know that that's true in this case but I want to ask the working group where they think this group should be going so first uh just to recap where we are right now we have the architecture document that has completed last call we're holding that just so that the architecture and issuance and auth documents can be considered together in the post-working group reviews uh so we have the issuance and off scheme documents and working for blast call uh please do please do review and and comment yeah if you're very familiar with them then you can just tell us that you think they're in good shape um but please comment on the mailing list uh we have the recently adopted adopted key consistency informational draft uh it seems like we don't have any major changes in Flight there we have the rate limits document which uh has a lot of attention on it and Tommy walked us through some of the interesting things that are happening there but it's making good progress uh and I think the question is what else do we want to work on um you know is this are we essentially wrapping up here or are there are there other things that we want to do here uh we had a draft in the past on consolidation considerations uh we've had a lot of discussion about different token types and"
  },
  {
    "startTime": "00:54:02",
    "text": "uh and the the chairs recently were got a request for a new batch token issuance flow so that's uh something that people might want to work on there's uh I have a draft on a specific consistency protocol um and there's a there's a an endless number of of possible topics but I want to know what the working group thinks is interesting and also just to remind people we have a charter and so if you want to talk about the progress we've made we can compare it against the charter Martin yeah I think on the consistency side of things it it seems to me like there's a very strong need to have something uh in this space concretely in addition to having sort of just a general guide of what what consistency is and and what it's good for and and why it's important I think there's a concrete need in some of these deployments to have a strong consistency protocol or system in place in order to provide the sort of privacy guarantees that we're hoping to achieve uh some of the proposals that I've seen really just don't don't work without something like that there has been some more discussion this week about the exact shape of consistency protocols I think Richard Barnes had some interesting ideas about applying something that's basically uh how did he phrase that something like CT but without all of the warts um so having that work happen here would be I think a good thing this is For Better or Worse the the group that has taken on that sort of work it's I think it's integral to what we're doing here but um at the same time I also think that that discussion is fairly nascent"
  },
  {
    "startTime": "00:56:01",
    "text": "and I don't know that we're really in a position to make some strong decisions yet about the exact nature of those protocols despite the fact that people might want to deploy things that depend on them thanks uh I see Stephen in the queue I'd like uh in addition to whatever you're planning on saying I'd appreciate if you could share with us your um your sense of consistency in the w3c context you mentioned that there is already in a sense a sort of proposed or draft consistency solution there yeah so I think the way we're doing consistency like in w3c is very like flying by the seat of our pants and it would be nice if we have something more standardized that like isn't just each UA is going to do their own like form of doing key consistency um I think Chris's draft is a good start but I think we want something more structured coming out of that either as part of that draft or as additional drafts and then to my point I was just going to mention that like as an additional token type I think it's potentially like there might be some potential interesting stuff coming out of the zkp solution to uh issue six from Tommy's proposal and it might be worth having folks talk a little bit more about that and see if that's something of interest to pick up and whether that introduces new interesting work thanks you know another thing I heard mentioned in this meeting or alluded to is a formal verification to my knowledge there's no formal verification of the rather complicated cryptographic Arrangements that we have been specifying I wonder if anybody would be interested in uh and working on that Tommy um I'm not the best person to talk about Chris Wood was driving more of it I know Nikita's here but"
  },
  {
    "startTime": "00:58:01",
    "text": "I I think for the basic types as well as very limited types they've had formal verification oh that's great which is how the issue six came up okay Nikita yeah I just wanted to uh maybe I could say with more is that there is a formal verification of the current protocol in uh using proverif uh and other than this unlinkability issue it shows uh about how we discussed um it shows the security properties and um I think there will be a write-up of it in the next month or two that could be made public uh thanks Phillip on the topic of like future work and potential concerns right now when an attestation mechanism is compromised any abuse that arises from that compromise will be felt by the relying parties but the attester has no way of narrowing in on which devices are compromised and should be ignored or debugged and obviously that's intention with the blinding property it's also unclear how the issuers can choose the testers and how relying parties assess the relative strength of these testers and issuers and some of that might come to Bear an application over time I'm also new to this group but I'm kind of I'm very curious to see how that will unfold over over the passage of time thanks uh you know one thing that that this reminds me of is uh thanks Steven for the overview of the w3c side I think it would be potentially helpful if we"
  },
  {
    "startTime": "01:00:02",
    "text": "had a draft here that laid out in a sense one level above architecture not just how the Privacy pass system works but how uh how it's actually used or how some different ways that we expect it to be used uh that allow us to think through some of the details like you know Canna can one origin uh drain your entire collection of of privacy pass tokens or you know are we expecting that there's some upper layer defense against that and also walking through some of the difficulties that in those models uh I would love to see an informational on something like that if if anybody's interested Richard yeah so it says uh Martin mentioned my name what we had I thought I might recap some of the discussion that we had in oi for folks who weren't there so I obviously has a similar key consistency challenge to privacy passes so there's some discussion about um whether to do uh consistency work there as well and presented his subject proposal um in that discussion it came up that there's actually a slightly more General consistency property that one might like for HTTP resources um you know things like some applications might be interested in binary transparency like guarantees that you're getting the same you know web resources that other folks are getting um so it's possible this consistency property might be a little bit more General um the the conclusion that discussion in Ohio was that you know if uh consistency work is going to be done you know privacy pass is you know a an instance where there's clearly a need for this it's probably the most acute need for these consistency guarantees and so this would be a a good place to work on it um"
  },
  {
    "startTime": "01:02:01",
    "text": "but it may be their Solutions out there a little bit are a little more General so um I don't know if we dive directly into the work here or maybe we run some stuff through sick dispatch but yeah I think it's a doing doing a little bit more uh consistency stuff here is a sensible idea okay uh I I hope that you've been inspired to uh to contribute more interesting work to the working group if you're working on formal analysis it would be great to uh to maybe see a seize the results of that at the next session and uh I'll turn it over to to Joe for uh for closing yeah I think that uh comes to the end of our regularly scheduled agenda if there's anybody who has any additional topics uh we can bring those up now and if not we can adjourn till next meeting um so thank you all for coming and I hope you have safe travels back to where we are going foreign"
  },
  {
    "startTime": "01:04:13",
    "text": "take it easy Sam thank you"
  }
]
