[
  {
    "startTime": "00:01:16",
    "text": "just go. And are people on the call with us? long time listener first time caller. I'm Chris. to my left is Russ and to my right is k or are in the Cider ops meeting in San Francisco at ITF117. If you are not at IETF 117, then No. Welcome here anyway. If you think you're not supposed to be inside our options, you'll probably leave the room. or stay. It could be fun. Here's the note well. I'm sure everyone's read it. You can't read it on the screen because intentionally very small. Thank you. We have a relatively tight agenda, so the people owe. Oops. Sorry. I misspelled Jeff's name. barely. Yeah. Awesome."
  },
  {
    "startTime": "00:02:02",
    "text": "Okay. Perfect. I'm very I'm very sorry. to the front, Clemons. Okay. there is a question for the in the agenda bash that came up. I think Job wanted to have us talk quickly about requiring implementations before we take a draft off that has some, you know, software implications off to the ISG. think we've talked about this in the past maybe 2 years ago. I think we sort of said, this sounds like an idea that would be good. we didn't really do anything about that. It would be good if maybe We thought about this again. talk about it on the mailing list. I'll start a mail while we're having the rest of our conversation here. But I think we've we've certainly found cases where we deployed software for this for the purpose of CiderOps and gotten ourselves in trouble, with not having interoperable software stacks. So I'll put all this in an email, and maybe at the end of that, we'll have some reasonable, I don't know which one's on. We've also had trouble where people have deployed code on early Internet DraftS. and then the RFCs come along and they don't interoperate. So some way of of dealing with these issues or at least identifying them. would be help Let's say And I'd say, you know, this has worked very well, and in IDR. based on what we have done done in IDR. So it's generally a good practice to enforce it with a single implementation minimally. Jeff doesn't like it. Jeff's -- Yep. really quick comment about that. I actually find this troublesome and difficult because of where Russ said the the issue of investing time, effort, and resources"
  },
  {
    "startTime": "00:04:01",
    "text": "into this area without knowing where the target is going to be and whether your work is treat for nothing or not. I also find that once you get a draft and you've got implementations, there's an fordinary back pressure, against change. And -- That's the install mix. -- my first idea is always my worst. Right? And if someone's gone, oh, I've written it all up, and it's kinda well, for you, that was really a bad idea. So I'm a little bit more You know, It shouldn't be a strict prerequisite. Now at some point down the line where you're willing to say this draft, this idea, this framework is now mature enough change is not gonna be substantive. You've got a much better chance of actually writing some code and seeing it through. but at the early time, oh, jeez. It's a lot of effort and it's a big pun, and I'm not sure people are that rich these days in people and resources and money to chase every last thing. So just really quickly before you get too deep in the line. We have 6 presentations. We have 60 minutes So I would I'm gonna write something during the presentations, and it doesn't mean I'm not paying it the Jeff but but but And we can discuss this, I think, on what I think would be the best place. I just wanted to make sure to bring the topic up. Jeff's slides are about carpi a I have no idea. Oh, prefix list. It's something about prefix list. Yeah. Yeah. They're hopefully, you sell them. their entrance. It's actually a really simple draft. So I'll talk about it and and hopefully some slides will come up. Aroa is a one way authority without any handshake. So I happen to have control on the current holder of prefix. and I can Allow a s 1 a s 2 a s 3 blah blah blah. anyone I want, That doesn't mean they've agreed. But if that appears for some reason, god knows why, That AS hasn't necessarily been part of the"
  },
  {
    "startTime": "00:06:02",
    "text": "appearance of that particular route because there's no handshake back. The IS holder hasn't agreed. Now, if you look back at where the IRR was, and the areas about what we put in that route registry was one thing that supposedly was authored by the originating AS. You're really doing well on that slide pack, aren't you? You did. Okay. I sent them an email to you So this is a signed object signed by the holder of the AS. and it enumerates All of the prefixes that you intend to announce. It's kind of saying, if you see this, it's not a leak. It's not an accident. this could this could happen. There are reasons why I'm doing this. If there's both a rowa and the prefix is on that list, actually got the handshake you're after Because at that point, there is an implicit authority and an intent to route. So this is nothing different to the original IRR model of Was it a route set? Does anyone remember? north. Someone remember. It was the route it it was the route object. and we are out object actually had Counter signed, from the address space and the AS. Well, signing and the IRR was always an interest concept. But let's just leave it there. Yes. Yes. Waiting has -- -- off the the who the set objects never had any any valid kind of So so the route object is then signed by the AS holder if if you're seeing something that I'm originating that's not in that set, You shouldn't believe it and you shouldn't accept it. I didn't say I was never gonna do that."
  },
  {
    "startTime": "00:08:00",
    "text": "If you see something that is on that set, but there's no rower You shouldn't accept it. There's no rower. if there was a row for other ASs, but not mine. And I've said I'm going to announce it, It's an invalid case of announcement. Throw it out. If they both exist, you need the handshake to make it valid. Slides explain this in detail. You're looking quizzical, Warren. I'm still extemporizing here. We'll just have to take it on the fly. Yeah. Without the slides. I'm gonna answer. It's all explained in the slides, by the way. So Warren, Kamari, with no hats. So a little confused If I say that AS42 can announce a prefix. If it's not -- -- prefix. Yep. My prefix. Isn't the other part of the handshake when a s 42 act actually decides to announce the prefix. And if they don't announce the prefix, what does it matter if I've said that they can do it. Right? Like, what's the actual problem that this is solving other than, like, I can say AS42 can announce it. and they can just ignore that. I feel like we're back at the same time. Probably, I something nice. Yeah. You did. Rudiger, you can answer him. I can answer him, but I'll leave it to you. Warren, kind of what we ours what the proposal actually delivers is that In absence of BGP sec, The signed AS signed root information, protects against a different AS announcing the stuff. And well, okay. if Kind of it does it's not really worth working on it. I mean, if I don't want ASR 42 to be able to announce it, I don't list a s 42."
  },
  {
    "startTime": "00:10:02",
    "text": "in the ROA. And if I do, then they -- They're back to couple while they're having Okay. Hopefully, Jeff's thing ex oh, look. My name is still up on the list because the pressing the queue. back. one minute. Yeah. It's equivalent of a route set. it's what you may announce. it was an old idea to say, Write down everything you intend to do If you're doing something else, you may well have had a whoopsy you've got some kind of leak going on. you didn't intend to do it. There is no reason why it should be there in the routing system. anyone can take it away because you didn't give permission as the AS holder. So that's the basic proposal. I think you've gone through in that discussion of the microphone, most of the other points. If there are any other clarifying questions, I'll happily try answer we'll give it back to the kabbalah microphone again. they can reconvene. I can spend working, man. I I tend to agree with Warren that this is not a help ful way of solving that problem, like, finding I think we can find a better way of solving the AS impersonation problem, which is kinda what Rudy Gu was talking about. But I do still think that this is helpful. a nice think and the reason that I think this this this is helpful is not because because I don't think that that handshake is necessary what what we do need, undoubtedly, is a way of verifying that someone purporting to be the the a BGP speaker with a particular AS is in fact the holder of that but I think this is not quite the right way of solving that problem. It the RPKI says you're the holder of the AS. Otherwise, you could sign it. So it's not the AS itself. That's the issue. The issue is really one of I see a route out there -- Mhmm. -- he was the originator. Mhmm. Is this a lake? Is this synthetic?"
  },
  {
    "startTime": "00:12:00",
    "text": "Is this real? Right? Yeah. Now in in the golden world where everything has rowers, it's not a problem. You will be dead before that happens, and so will I. Mhmm. So until then, the way of the AS holder can kind of say, look. If you wanna order what I'm doing, Please do. Here's the list of everything that you might see from me if what you see is not in that list, Feel free to discard it because didn't intend to do this. Yep. That's all it's saying. belts and braces. There may be optimal solutions down there further down the track then. fine. this seemed a simple port of a route object Thank you, Rudy again. into this world that is an exact one to one replica. That's all it is. So I don't I don't disagree with any of that. And I think that this is and I think that this is useful partly because of the way that operationally today, what we have is we've got this. We've we've got kind of a bunch of static filters to deal with boggons and stuff like that. We've got a bunch of IRR based filters. that are kind of a worst case scenario with a lot of garbage in them, which act as a backstop. And then we have we have origin validation, which is much more fine grained but can go away in the face of operational and we need all of those things. if we're gonna get to a place where we no no longer need the IRR base, component of that, then we need to we need to replace it with something, and this is a good candidate for that. So this replaces the route object. Yes. It's a signature. validity types, and a clear author hoop. Hoop. Hoop. is the AS holder I can't just make random ASCII nonsense and drop it in a registry. Yep. All of those things are improvement to a venerable model has been used by many communities in the past. So it's not doing damage."
  },
  {
    "startTime": "00:14:00",
    "text": "keep it up to date. There have got dates anyway. If you don't, it's going to lapse. and that's a good thing. Old information is bad. and it just seems This is just a small brick. in that area that is not harmful, it's actually a positive movement. So I think the thing that we need in order to kind of complete that the the replacement of those properties that we get from the IRR today. is and we were kind of talking about this offline is we we need the that the thing that the IRR has going for it. which is the other side of the problems that result in all of the stale data. is that the data in there is really stable. Much more still much more so than the RPKIs today. The RPKI information goes away in a transient fashion all the time because of operational problems. what we need is a is a stable backstop indicate the worst case, not the the the kind of the the widest possible set of things that could be validly announced by an AS number, and that's what that's what resolving rootsets and ASets gives us today. I think that we need In order for this to fill that gap, we need to think about what the what the the the relying part model should be in the face of these objects expiring and not going away in a surprising fashion. think we need some way of of making them kind of fail closed in a safe way. in a way that doesn't switch off the Internet. if there's breakage in the RPQI system. I feel we've kind of taken stuff. Hold on, Jeff. We one I need to cut the line because we have a whole bunch more Meaning, you guys stay, no one else joins. But let's keep the questions short and the response is short too. Thank you. think you've got the answer. Go. Joe Snyder's Fastley. It is my personal desire to help move this community away from plain text, unsigned,"
  },
  {
    "startTime": "00:16:01",
    "text": "esky Garbage into RPKI based solutions, and I think that this draft represents a positive step in that direction. to Answer Ben First, the relying party will, of course, just follow the science object template validation procedures. what the operator does with consolidated outputs So for instance, cash hits, over a number of cycles. That's up to the operator. and to ask answer Rudiger, that he says it's not worth it. This spec is so simple to implement for signers relying parties and BGP implementations. that it seems like a a worthwhile exercise to to run this through and and see how it benefits us. especially because we can now comfort prefixes, are not covered by ROS. So there's there's multiple angles, I think, positive benefits to this approach. you, Koko. Uh-huh. Thank Sure. This this is the call consistency. guess the IRR can do that, and it's just a feature get there. But where I have trouble understanding it is what threats we're we're mitigating with this approach and how this all fits together. because we are adding a cost to the ecosystem because the data is it's a features only valuable when it's, like, data is actually there, correct, no expires and people and it's kind of complete. So at any addition, I want to know what what tracks we're mitigating by adding it, it's and if it's the right solution. it takes the place of unsigned unverified, Anonymous data that sits inside the route registries we run today in that particular area. And, surely, that is better than what we're currently doing. That's all."
  },
  {
    "startTime": "00:18:00",
    "text": "I there are myriad of other problems out there, feel free to solve them all. This one has a very small target. that's exactly what it's intended to do just that. Okay. Thanks for that. explanation of this mitigate if the credit mitigates, I guess. riram missed. So, Jeff, you should take a look at just Google Yes. hijacked side drops. So we wrote a draft maybe 4, 5 years ago, which is exactly the same thing. So I'm glad that that -- It's it's the the this is not an invention. This is the old rat registry rat object. Yeah. Nothing has been invented. other than it's got a signature at the bottom. Right. No no problem. I'm happy that you are collaborating what what we thought about and wrote it down or wrote it down. Really good. wrote it in a draft several years ago. we we called it Deep, r e h e. and overs exist for all my prefixes. So they we propose that object. It's signed by the AS. and, basically, this this is what it says. So please take a look that, then we can certainly -- Well, if you find that there's more text that to go in this. Can we go to the last slide, please? because we're gonna throw this cut this to an end, no, further further further. Yes. There we go. if you choose to adopt it, you feel free to have a hack at this and find out what's missing from your perspective. there's not much in it. You could probably read it in less time than it took to get through this presentation. Very simple. Thank you. Thank you. Next up, Hashiran, please. And we are 5 minutes behind the schedule. So Please go as fast as possible."
  },
  {
    "startTime": "00:20:02",
    "text": "There's a point there here. Good evening. As as I'm Sridhar from NIST. So this talk is about the ASP draft update. both the ASP, a verification draft and the profile draft were up updated this month. the f f e limit has been removed so that that causes some ripple effects in the verification draft. So the verification. Next slide, please. verification draft. has been updated to to conform to the removal of the athlete limit. So that's good. Section 788 have been better organized. We've added a new section verification and mitigation at egressebgprouters. But the thinking about it again, and I had a discussion with the job yesterday. it doesn't seem like a good idea. So we are going to remove that slide. sorry, that section. then DDoS mitigation service provider. It's a simple operational recommendation that helps DDoS mitigation service. Next slide, please. So one question that has came up is regarding, like, so far, the verification drop only includes ebgp ingressaspart verification using ASPPA. Do we want to have something corresponding to RFC 88 93 Rudiger and Randy Bushes. To do egress ebegpegrisaspartverification,"
  },
  {
    "startTime": "00:22:00",
    "text": "It's not as simple as it is for ROV. It's it's it's complicated. We also I have a question about whether ASPA verification should be done in ibgp as well. So IPGP seems doable and without without requiring any algorithm changes. One simple thing that would be done is to look up the AS2's own ROA atr2r2beingtheegrisrouter when it receives routes in ibgp, it looks up AS tools own ASPA and uses the same up stream, downstream algorithms for AS path verification. and that works fine. But with ebgp, it's not possible to do correctly without much more complexity. It does not sign seem like a good idea. Instead, if we simply focus on using the OTC attribute RFC 9234, that would do that would go at do a great deal for preventing local route leaks. That is what egrissebgp verification accomplishes. Next slide, please. So we are I mean, I put together some slides. authors will hopefully get together and discuss it. this week. ku, job, then whoever is available, we can have a little conversation about that. I'll just go through the next three three slides in 30 seconds, and I'll be done next slide. These are backup slides, so I'm not going that's why I'm not going to go into detail. Just want to mention that I'm I'm I'm made the slides. The material is there that will help this discussion. So details of verification in ibgp. That's doable, and it it it can be possibly included in the draft with very little effort. Next slide, please. verification atebgpegris So, Yap and I discussed, we didn't think it was a good idea. Gets into some complex things."
  },
  {
    "startTime": "00:24:03",
    "text": "again, the details of how that you might approach that, but what are the drawbacks how it fails, how it into I mean, how it evaluates unknown as an in sorry. An invalid is an unknown. That's not a good thing. And then if you complicate it further, then only maybe you can get it right and it's not worth it. But instead, if you simply do RFC 90 34, which is the only to the customer attribute to detect whether you are purse I mean, your AS is causing a leak lower and you can prevent that. And that that combined with ingress, with IPGP verification does it all for us on the ingress router. So next slide, I think yeah. I have a few possible recommendations. So we'll see how the discussion goes within in the author group, and then we will take it out to the email list as well and we can resolve it easily and quickly. Thank you. Any Any questions? Oliver is to the raw failure based incision. Oliver. Oliver. this place. doesn't matter which one you start with. Okay. So This is a it's basically 2 drafts in the both pretty much the same. 1 deals with ASPA, validated ASPR objects, the other one with validated raw objects. And the intent from that came in IETF 112."
  },
  {
    "startTime": "00:26:00",
    "text": "we created or we had a hackathon where we were creating ASPA data sets and so forth, and the idea was to have a certain dataset and certain result set, and then when you wanna test your application, your implementation, you can basically get your results set and compared to what we gave Now, yes, there are JSON models of of all the stuff, but they are not really human readable. They're very complex, cluttered, if you only are interested in the validated output And that's why we why we came up and said, okay. Let's create BNF rotation, where you can display the validated objects And that can that can make it very easy to compare result out outcomes. We have some tools where we basically lock things or maybe also script certain things, that can be used for that. And maybe one thing what I forgot to say, that is only informational. So it's not a standard draft. It's an informational draft. can be used, does not have to be used. It's also very good for documentation. Next slide. So that that would be, for example, the the ZASPA notation, there you see basically the examples how it could how it could look like. And then the second graph is pretty much the same just for raw objects, They can go directly to slide number 3. So that would be for the raw object or the validated raw information, information, That's it? Questions? So yeah. And would like to make working group adoption call for that."
  },
  {
    "startTime": "00:28:01",
    "text": "But I also will send an email to make it. Yes. Yes. Yes. Jeff I was at the risk of putting people to sleep. So important stuff is your intent that this shows up in this format as a string in yangmodule that will be for ASPA, or is it your intent that you actually unpack this stuff into a structure of leaves for this in yang. or have you not thought about Yang yet? I did not think about Gong yet. No. But we can we can talk about that. Okay. That's I mean, Yeah. Yeah. You don't know. I'll offer comments all fine. The thing is we wanna make it simple, that's why we also say informational. And it it's it's not something what People have to implement. People have to use. It's just for the small group of people who basically have implementations that we have something where we can create something where we easily can compare outcomes and so forth. Right? One of the things that you're gonna probably also wanna talk about is sorting for the list just simply because one of the things you're gonna end up doing is you got people that are despite the fact that this is structured data, gonna wanna run a grip on it. step, Rudiger. Okay. Rudiger. the queue is locked. Unfortunately, we are running out of time. will you call it? Well, okay. The syntax does not look very thorough. But looking at how simple it is, I think well, okay. The sorting thing from sorting sequence, I think, is actually very important And for the syntax, actually, a CSV would do Yes. But you still have to basically give rules for the sentence. Yes. Define define the standard. Yeah. Yeah. Yeah."
  },
  {
    "startTime": "00:30:00",
    "text": "That's basically it. And I think, actually, please correct me if I'm wrong. But I think we have sorting in the Is it draft? And if not, then we can easily add it to I agree with you. Yeah. Yeah. Yeah. makes sense. Thank you, Oliver. Okay. What else? Okay. Microphone is working, and it's I'm breaking his online. This should be short and sweet. Next slide, please. Yeah. main code or autos are working on the document with best practices for running a publication server and our sync and other pure repositories. because this is both simple but also complicated. Next slide, please. So Yeah. The the the base is simple, but the the the d sales where it goes wrong are complicated. There's a lot of lessons learned, to write those down before are people did? Yeah. learn these lessons through debugging. That's the goal. The scope is how you run a publication server, asking RTP repositories, and how these repositories interacted, chosen the deployment platform, firm stuff about low balancers, CDNs, negative caching, Some things to debug, and how these choices relate to relying party behavior. Next slide, please. We've written down the first version of of the draft and potentially there's a very large scope. So we're trying to keep it limited And we are discussing some quite they seem arcane operational and deployment choices that are part here because these are painful lessons learned. And these are small small issues in the long tail, but potentially with the big impact if that happened to you. Next slide, please. So all of you Please read these documents. Really welcome to work with you on the content. and expand it where needed."
  },
  {
    "startTime": "00:32:01",
    "text": "I think writing this and people applying this will make for more LIBOR repositories. and Yeah. I'd we need really like working with production for these documents. That's it? You send email. Will do. Will do. Will do. Will do. Thanks. And you get full 15 minutes now. There's some deals after. Yeah. Yeah. Alright. CMS signing time. Next slide, please. Oh, I'm Joe Snyder's. I work for Fastly. Thanks for having me here. Today, I wanna talk about a mechanism to improve the efficiency of failing over from RDP to rsync. In the last few years, we've seen a number of Let's call them RRDP outages. that are, for instance, the results of somehow malformed XML, slipping into the notification file or snapshots duplication of of published elements or TLS errors where the publication point operator somehow forgot to renew their, let's encrypt certificates. There there is some areas of reasons why RDP might fill. and that's okay. because the working group arrived to some informal consensus that if RDP doesn't work, Only then, we'll try rsync. and optimizing the switch from fetching FireRDP to fetching FireR sync. I believe there's some some implementation tricks that that would help reduce the computational and bandwidth cost on both clients and publication points. Next slide, please."
  },
  {
    "startTime": "00:34:02",
    "text": "How our sync works? when the rsync client connects to the rsync server, by default, the mechanism to figure out if a file should be transferred is to compare the last modification time stamp of the file on on the client side with the last modification timestamp on the server side. and additionally compare the file size. And those 2 primitives are super easy to to check. You don't need to read the whole file. You only need to read the metadata after file. So this makes for in incredible speed. Next slide, please. Now let's let's talk about a a a naive RDP implementation. Most realign party implementations use a a a post Excel file system, Esther beckons, either for the the so called staging directories in which they unpack data that has not yet been validated. or for their so called validated local cash which is a set of data that the relying party considers fillets and usable for further dissemination in the pipeline. Now speaking for just RPKI clients, what we originally did was we'd we'd slurp in the XML over the TLS connection, decodes the the base 64. Frights that dure encoder bytes to disc. run a cryptographic validation process And if that was successful, then move the files into from its temporary location into its its final location. But in doing so, the creation of that file on the file system had the time stamp Now, basically the moments the RP start of writing to the file system. Next slide, please."
  },
  {
    "startTime": "00:36:08",
    "text": "And and the the consequence of this is that the moment RDP fills for one reason or another. You cannot recycle those files when you initiate our sync transfer, because the last modified time stamps for the objects retrieved via RDP. is Now, whereas what's visible on the rsync server is some points in the past. So here's an example of the 4th validator running against the right trust anchor, It stores the files in slash temp/fort/repository. You can see that the creation dates of the the MFT CRO and robots. is very close to the dates at which I launched this process Fort takes, like, 1 or 2 minutes to to do this job. But if you then inspect the rsync server itself that hosts a copy of these files, you see that the last modification dates are are very different. Next slide, please. So recently in RPKI clients, we implemented the following trick. When objects are retrieved through RRDP, after validating and and parsing the file, So we before we can extract timestamps that are internal in the RPI file. We must, of course, conform that it's possible file. So the moment we move the files from the staging directory into its final senation, the local validated's cash, The last modification time stamp is updated in the case of CRLs to be This update, in the case of certificates, the not before time stamp"
  },
  {
    "startTime": "00:38:02",
    "text": "And in the case of signed objects, the CNS signing time is used. Now Shoot for some reason. My TLS certificates on the RDP server expire forcing me to try rsync. RPI client calls the rsync utility with a command line option called. compare best and and This is a really cute feature because it allows you to point at a set of object that you locally use that to figure out with the parsing server, what the list of files is gonna be to transfer, dump the new or different files into a temporary directory, you can run the validation process. Now Because the RDP originated files have so called deterministic time stamps, The rsync transfer that relies on the last modification time and the file size is incredibly efficient. as efficient as it can be. And below is a link to the commit that accomplishes this, and you'll see that it's not a lot of clients. Next slide, please. So how efficient is this in reality. many, but not all. certificate authorities immediately write to disc after signing an object. So you'll see this predominantly with rpk.netbasedcaimplementations. And because of this property, coincidentally, A lot of the not before or CNS signing time or this update, timestamp values internal to the RPK object, align with the last modified time stamp exposed at the file system level. if publication point operators would start doing this purposefully."
  },
  {
    "startTime": "00:40:01",
    "text": "we'll see more and more benefits for our piece that are failing over from RDP to R Sync. Next slide, please. also interesting to note is that at least in a lip crypto What's open SSL, LibraSSL implementation of of CMS. By default, the CMS signing time is included in the signed attributes when the CMS product is is creative. Next slide, please. So this being the default in a number of cryptographic implementations apparently has led to all science objects that were discovered in the last 12 months I clouds through through tens of millions of them from the RPI fuel support Argoiv. carry the CMS signing time object attributes. So based on this data, it seems feasible to me to change the CMS signing time the the requirements for it to be present from a optional to amendatory. because everybody today all CAS under all trans anchors are already today adding the CMS signing time attributes. So in increasing the requirements for this attributes would not put any CA in a state of noncompliance. Next slide, please. My recommendation is for relying parties rust or Java equivalent of netis, to align the file system's time stamp on the file system, with the relevant internal RPK time stamp."
  },
  {
    "startTime": "00:42:02",
    "text": "And then in addition to that, if you use RSync's compare best feature. you can repurpose your locally stored validated cash in order to have a head start when you sync against the rsync server. And for publication point operators, my recommendation is to ensure that the last modified time stamp of the files on your parsing server align with the file's internal RPK time stamps. Next slide, please. implementation status. RPI clients has support for this feature That's on the relying parity sites. And on the publication side, I've wrote a tiny utility called RPKITouch, If you pass the file names of the files where you would like to change last modified time stamp. the file system metadata, to the internal RPKite time stamps, You just pass the the foul names as argument to this utility. and it will change the time stamps. a very small utility, and you can included in your existing deployments, or, of course, do this in the signer layer But that's up to publication point operators. There's there's many ways to to solve this term. RPKI Touch serves as an example implementation of what the expectation exactly is. And then as I understand it, right then to see has a utility called r sync its that converts RDP. to an rsync hierarchy that you can serve up and they they also deterministically set the timestamps following the procedure outlines in in this draft. if I'm not mistaken, I did not test this offer. Now Your feedback is most welcome,"
  },
  {
    "startTime": "00:44:02",
    "text": "The draft is now a working group document, so I would love to hear from the working group like, hey. Can you clarify in a certain way how exactly to do this part of the trick, or why is that thing written down that particular way. Whole requests are welcome, but you can also just email me, and and I'll integrate your feed back. I think it's time for questions. And for the obvious one, I think. I think we both fully agree that our sync repositories need to have deterministic timestamps for objects. And only question is about where to get the time stamp that you use. I think that right now we have a situation where for signing time, there are no it cannot affect the validity of RPI signed signed objects. and it appears to be present in all objects. other time stamp you you could you could use is the note before in the and i certificates, I didn't write calls for this to check if it's present in all easy certificates because if it's if it's certificates, it will take a lot before time. However, of course, EBITDA is we're using the same certificates for multiple signed objects not following the new interpretation of manifests, The the not before could be equal. So my question is, yeah, why not not before? I think both values can be used because we agree indeed that having a deterministic time stamp is what makes this kind of trick work. But I personally like to see him assigning time a little bit better, because if you the the signed objects as an onion with multiple layers. to extract the CMS signing time It is literally less steps to extract the time stamp than to get to the e certificates not before. So on the publication points, It's a tiny, tiny optimization. So you'll see an assigning time instead of"
  },
  {
    "startTime": "00:46:00",
    "text": "the embedded xhypheninetimestamp. I also think there is a subtle benefits to assigning a purpose to the CMS signing time attributes. because up until this day, it is it is optional. but but the IETF 116 presentation by Randy Bush about timers in the RPK ecosystem, that paper showed that there was a lot of value in being able to see a difference between the not before which may be backdated as because it does affect the validity window. and the CMS signing time, which is not back to Avis. the just does back backdating matter for the for the time stamp being thisministic? So, ultimately, you need. You need. You need. a deterministic time stamp that we all a great tune. A great tune. Which of the timestamps to pick? is indeed a matter of almost intellectual debate. And this is why I'm advocating to give the CMS signing time a purpose because It has in the past and probably in the future, benefit to researchers to understand timing, the RPKI ecosystem. But but Technically, Eater valued would work. Not after might also work, like, Yeah. The there's a bunch of failures we can choose from. and it is of critical importance that this working group comes to consensus on this is what we pick Because if we all pick something different, we are not gonna have any benefits doing this type of optimization. And they they might even might even be equal yeah, my inclination is to is to Maricando Maric Campbell, the CMS signing time. And completely give no meaning to it and still keep ARTRADE. No constraints there because it feels simpler to me."
  },
  {
    "startTime": "00:48:00",
    "text": "I guess, in in the line question is how many objects how many CAs are out there that are not using single use certificates. That's recalls there. That's where there's a benefit to using CMS signing time. I'm pretty agree with that. tease, I think that's exactly the right question. Right. Because if they're using multiple certificate, the same certificate design multiple op. corn, what Russ said might have just made my comment stupid. But to me, CMS signing time seems to sort of align with the sort of you would sign a thing and you'd write it to a file, and the m time would largely be similar about So it seems like that lines up better with the sort of Flow of data, how it normally would happen. So CMS signing time seems like a much more sane use. or much the same timestamp. Some implementations immediately fight to this. Yep. But -- Some of those. Other very large implementations store the file in a a relational database and then produce RDP. And then -- Yeah. from the RADP outputs produce the rsync. So it It before, which is kind of like a it just seems close to them some date that I made up at some point, Wow. Lots of people stand up. can I clarify first? I'm there. from my perspective, I see an implementer both signing time and not before, not after, I just values of so far picks. So they don't not necessarily have any connection to a point in time you make the objects. So I'm gonna try and echo back to the point that you I think you were trying to make. you can tell me if I'm right or not. think what think what you were saying is that fundamentally for the you were I of making the asking transfer more efficient. It doesn't You just need a time stamp of the publication side and the RP agree on. Yep."
  },
  {
    "startTime": "00:50:04",
    "text": "but the argument for using the CMS signing time rather than the the not before is that if we're going to keep the signing time around, it's nice that it has a purpose so that it's clear what it's being held around for. and this is an opportunity to do that. So rather than having this slightly hand wavy situation where it can be there or it doesn't have to be there. But if it is there, then it's helpful for debugging, but you can't actually rely on it ever. this is an opportunity to say, it must be there. it must be there for this specific operational reason. Yeah. In that case, I agree. that's the right choice. Yeah. I knew it. You were right. Yeah. Tees offered some feedback few weeks ago arguing that publication point operators should should not have a must set the time stem So we'll leave it up to the operators if these are the benefits to do it doing it this way. That's up to them. So in the current version of the draft, the it's a publication point operators should do this. And I I think That that's okay. It's it's an optimization. It is not a necessity. Alright. Next. 4 minutes, please. Alright. Next slide. The Aspire objects, profile, specification has been updated. 2022. easily see the differences. I recommend using this beautiful short URL that is easy to know, punch into your phone. Next slide, please. In summary, the working group came to consensus that API agnostic Aspire objects are beneficial not only to sign our but also to realign parties. And"
  },
  {
    "startTime": "00:52:00",
    "text": "HP implementations and network operators. And given that ASPPA is not really yet deployed in the fields, The only as per verification deployment that I'm aware of this my project in the Calgary Internet Exchange. So creating a situation where where all currently deployed objects, say for 2 of them, are noncompliance. possible. Next slide, please. With yellow and strike through I highlighted the changes, Martin Hoffman was kind enough to point out that for the last few years, we were We got it wrong, and we're implicitly encoding the ASR 1 text. So this So that shame on the working group and and myself for not noticing this issue this very fundamental issue earlier on but that's now been fixed. Another change is that the value of the So Putting some pressure on me. another change is that the value of the version fields previously, was 0, which means that from a Doctor encoding perspective, it would not be encoded. on the wire because it's the default value. But going forward, the version field carries a value of 1 that means it must be explicitly encoded. So keep that in mind. It's in the ASM 1. It's in the natural language, and it's in the example aspart object that is in the traff. So there's three places where you can now see that the version is 1, And then last but not least, the provider AS set is now a composition a sequence of ASID, which is an integer and no longer is a sequence of provider AS. which was another sequence. Next slide, please."
  },
  {
    "startTime": "00:54:04",
    "text": "From an implementation in the last few weeks, we have made very, very good progress On the realign party site, there is RPKI Clients and Ruximator that are able to decode the version 16 objects. Both of those are not released or the feature being gated behind a pow option. So this is not for general consumption, but for demonstration purposes, On the signer side, if I'm not mistaken, THE PEOPLE FROM RIPENS SEI, APEONIC, have produced code that can encodes the new version of the object. And then I have a private implementation myself to also produce new versions of the checked, checked, So there's a good interoperability matrix for this current version of the draft, which would tackle a barrier going working group last call Next slide, please. Last slide, yeah. Yeah. Yeah. Yeah. the tricky one. So we we have this notion of some networks being transfer 3 or tier 1 or Transit 3 in the sense of it being an IX route server. and there's a few ways we could express this in the objects. So there's not really right or wrong so we can, you know, really bike shed this one until cows come home. time to wait, sir. But we should think about whether this transit freeness should be expressed by using an integer of value 0 in in the s ASID. or use an empty sequence where providers simply are absence. and that indicates the transit freeness of the AS holder. I would love some feedback on this on this preferably."
  },
  {
    "startTime": "00:56:02",
    "text": "And I think once we answer this question, the profile should be ready to go to the next phase of review. Last slide, please. Yep. Questions? What's this t suite that does? You gotta wear a high heel span. will look good on you and be very practical. I can talk and balance at the same time. then We have got one more presentation to go in 5 minutes, which is a bit short. So just to add briefly to the the question of how we express transit preness. in addition to kind of the the familiarity with how we do this for rowers. using the the the AS 0 hack. The the reason that we need the it's it's totally a hack. the the reason that we needed to do it with with Aspir in the previous version profile is because we had the the disjointness between the address families. And so we needed a thing to be able to attach anafi limit to. We no longer have that now that we've dropped the Aphi limit. And so I quite strongly feel that the cleaner way of doing this is to express transit freeness using an empty sequence. but we can bike shed that more outside. Alright. I see where to go in the grievance. Then worries, maybe, Alright. Yep. We'll take it to the list. Just a quick comment. You mentioned that you have the only SPA implementation. I just want to inform you that the NIS B GPS or X Implementation includes the SPA at least since IETF 112. So we have 2 implementation even though we have to update ours with the AFE and be happy to do that. apologies. Thank you. I just spoke. Yep. My you. 2 sentences. I I didn't mean software implementation. I meant deployment I'm real"
  },
  {
    "startTime": "00:58:01",
    "text": "Internet infrastructure. So, yes, there's multiple software implementations. and there's one production implement deployment of ESPA verification. So your Thank Yep. Goodbye. Thank you. you. Yep. Hello. That thing is young people coming from Tongan should have already. I will introduce briefly to your the receive. I can't cannot set this day. I twest approach for total address with addition. Next page, please. Thanks. Status stat headset is awesome. It defaced. I'm just moving improves security and privacy. and it is well understood and technically in metro. it can be extremely fast. and the cash flow networks. Can you see it? Next page, please. Oh, the typical setup protocol or ad set is using Internet k is change to create out to know, and our traffic could send to and receive from PRAs, let's do now. But if we can combine RTK, on the ID stack, This mechanism could play a more powerful load in the Internet Next page, please. Here shows the core idea where we're safe. First, if our cafe format equivalent Harish and Bobo's emails as the laughter slash shows 2nd, Each participant published their config in the archive database, including the content IT s number and edge runs. 3rd, all participants think the RBC database and the overall. And the last"
  },
  {
    "startTime": "01:00:03",
    "text": "if participants connect to the all the other participants with the their content IPs. And There are so many details technical details to be handled. But now let's demo learn, and that's a focus on receiving the stuff. Next, Pedro, please. Okay. That is the our way we'll I will save. It is both RBCA and ID Stack. And it add a Mac, add her sources up on the router, and that leads under red verify and the deleted and the destination as for the router. if the packet carries the correct Mac, Mac, ideasource progress is real as correct. Next, Pedro, please. Okay. They that is the 10 days to the Idissect. no need to stay in the crosstalk, I think. next page or piece. Okay. your sales creates This is the summary. We still face the Internet and the true network networks. it provides listing. It provides clear benefits for participants. And we think it is a macro 1 and this we are thinking working group full adoption. which one is the best working group. I just like me are Cedar Ross, Cedar Ross, So, again, since I welcome this, thanks to you all. Any comments for him about the this whether it belongs in IP SECME or this group."
  },
  {
    "startTime": "01:02:05",
    "text": "Joke Snyder's fastly. My gut feeling is that this belongs in an working group. but it would be useful if if the documents progresses further. to ask CIDROps for a review of the ASM 1 application and and any other comments. But given the the nature of of this type of work. I think it's closer alliance with with a source address, validation, commelting group or or ipsecgroup, not necessarily Cider operations. But we can, of course, refill the documents at some later stage. If there's anyone who has the opposite view, please come to the mic. SaaS. Okay. Then I guess we would like to see this progress or if this is progress as an IP second E or elsewhere, then we'd love to review it. when it's beginning to get mature. cents. Okay. Thank you very much. that's the end of the agenda, and past time. Thank you. Bank Bank Bank Bank Bank Bank"
  }
]
