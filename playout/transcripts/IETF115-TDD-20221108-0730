[
  {
    "startTime": "00:00:04",
    "text": "ready we should start getting this show on the road yeah uh oh I will I will put Refresh on the slides of the SE slide slide slides they're uploaded now right if you don't upload them they're not gonna be anywhere I am not well responses fairly not super responsive oh and right uh you have a go to your court chat I sent you a link or if it's faster just email them to I don't know which is faster itf.org I'll pick them off of there so I think you've you've actually like I'm oh I can I can revoke slides okay your slide deck has been shared error are you doing that yeah yeah can you refresh yes as soon as they're uploaded good morning everyone"
  },
  {
    "startTime": "00:02:02",
    "text": "[Laughter] it may be morning but for those who are still jet lagged each rewarded everyone we're just making sure that the slides are perfectly fresh they're hot off the front so it is now Tuesday morning so many of you have probably seen the note well if this is a surprise to you please do go have a look at this wall of text by downloading it from the data tracker make sure you understand it um any uh so we didn't really have any participation with the mic yesterday uh today the reason that we are all here at 7 30 in the morning thank you all for coming so early is we're going to have a panel discussion after this anything said in the panel discussion is a contribution to the IDF and therefore covered by the Noel so um it's a rerun of yesterday morning slides for those of you who are here it's still great to see you all in person thank you especially much for waking up so early uh to be with us today 7 30. and you know if you're watching us on YouTube later we love you too so today's agenda yesterday uh recap of basically a um extremely informative and very enlightening I learned stuff which I was honestly not expecting to do um uh presentation sort of introducing quick uh and you know why it is and what it is and how it is uh and today we're gonna dig a little bit more uh into into specific aspects um of this so uh Ian uh with some help from Martin I guess um"
  },
  {
    "startTime": "00:04:01",
    "text": "moral support for Martin um and slides from Martin we'll be talking about uh some experience with deploying quick at scale uh and then Lucas who I don't see here but he had to commute in um so he'll be here in a bit uh we'll be talking about applying observing and debugging quick and then after that we're going to have all of our speakers come up uh for a panel discussion slash q a that is the audience participation part so you know those of you who are still waking up you have either an hour to find your notes from Monday's session to figure out what you'd like to ask uh or um you know start thinking of your questions now and think of them as things go on um so with that we will reload the slides hmm reload the slides with that en is going to start telling you some jokes while we oh slide hmm uh it's 7 30 in the morning you're at an ITF meeting and we're at College improv have fun everyone trying to think of my best quick stand-up jokes I don't know oh no that's nothing nothing too soon I don't see them are they still not there they're still not there okay you can do in you want to do you want to do Lucas's slides what you can do Lucas's slides and and I mean I can I can start talking through some of it yeah um that's fine okay so we're going to start with load balancing or the quick LB draft uh a number of you who are involved in the quick working group or have been to the quick working group are probably fairly familiar with the quick uh load balancing draft"
  },
  {
    "startTime": "00:06:01",
    "text": "um but we just wanted to go over it real quickly because we're actively in the process of uh deploying it at Google um and so specifically there are a number of things that it potentially could really help us with include printing linkability but one major issue is when you have any cast uh where you're using bgp to try to like do load balancing for a single IP potentially globally in our case um it's there are a number of complications so one complication is if you ever want to change the weights on bgb or anything about the bgp announcements of course a number of connections like start getting sent to the the wrong server at least without like a good bit of extra work um and that's particularly true for quick um and you might combine with like a nap rebind or something and this makes this all like much much worse um another problem is also connection migration so typically when you migrate a connection when you think of like connection migration you're migrating say from like cell to Wi-Fi or vice versa um so it's fairly common you're actually going to land on a different as an entirely different network and as a result it's fairly likely that you actually land on basically like an entirely different peering Point uh next slide I'll go back one moment just to go through so the identity load balancing and then we're going to talk a little bit about black hole or flow black cohing uh a fun little story on an outage that we had uh just about a year ago and then like one slide on zero RT in quick and why it's hard as well as some information that you can go look at more if you want to care uh so let's let's go next slide actually two more there so this is essentially the situation I was talking about where we have an anycast address or using an L4 load balancer or in this case like a slightly more intelligent L4 load balancer is quick aware and we're sending it to an L7 server of some sort whether it's application front end or another layer of load balancers or another layer of load balances um and so again if you have flapping or anything else next slide"
  },
  {
    "startTime": "00:08:02",
    "text": "or connection migration it's fairly likely you will end up on another load balancer so but yes this is particularly true if you're migrating from cell to Wi-Fi you're potentially changing carriers and you're potentially hitting different viewing points um and so this means that even though connection migration is great it does not work nearly as well at least in our infrastructure for any cast as it does for unicast whereas you know basically an IP is tied to the very least a physical location in a fairly strong sense like a Metro um peering point or something smaller like that um so when you arrive at the second load balancer it's like is this a new flow I don't know what to do with this I'll load balance it like a new flow so it's like all the old information is lost we have a lot of servers the odds you hit the same server is basically zero and you know the whole thing fails um and yeah and migration will fail uh so we'd really like this to work because we'd really like to move more traffic to anycast actually for a number of reasons um additionally it's like a very popular option for another number of customers so uh next slide that's one great reason to do quick lb and connection IDs but there's also kind of a discussion here oh next slide about linkability and there we go so yeah we got we got a fair amount of latency okay perfect linkability is basically like anytime you have a single device connecting to a single machine and you can like track it the whole time you know if it if you have a single IB for example in a single device like that's perfectly trackable right like it doesn't even matter if quick is involved or any other thing is involved like you're going to be able to track that connection um because there's you know there's only one connection to that IP in the entire world um so that's kind of the worst case scenario and you know so for but more typically what you have is kind of a good number of clients next slide connecting to quite a large number"
  },
  {
    "startTime": "00:10:00",
    "text": "uh of servers and you know asymptotically this looks like perfect unlinkability um so anycast is actually helpful here in the sense that there's only one Global IP and so you have a lot of servers that kind of look like one server um and potentially you have something like you know a million clients or possibly even more connecting to that IP at any given point in time and you combine that with encrypted connection IDs from Quick lb and you start like approaching you know some real vision of unlinkability that's that's quite strong um you know it the what the word perfect is you know it is asymptotic but it becomes extraordinarily difficult as an adversary uh short of compromising the keys um so it becomes quite a compelling proposition from our privacy perspective as well as from a network infrastructure perspective and that's why we're we're deploying it um so hopefully uh you know probably q2ish q1ish next year if all things go well um and sorry uh wait hold on you got it I got it got it I got it I have like does anyone is it was the quick lb section clear does anyone have any quick questions before we move on now that we have like two seconds oh yeah I have there's more of that to come but thank you I'm trying to do the X for sure oh sorry quick lb there's a draft called quick lb that kind of describes this proposed solution I um yeah as you can have any connection problems I will do the share instead there we go so apologies we had entertainment because Martin Duke in the front row is the expert and as well as author of quick lb um and so you know any any super detailed questions I will defer to him um and he will be on the panel with us so okay"
  },
  {
    "startTime": "00:12:01",
    "text": "um there we go ah yay okay this is the thing I was alluding to the entire time uh so quick lb has a single connection ID format that begins with two bits for config ID so that allows like rotation of keys and some other things um it has what is called a server ID portion and a nonce portion um and the you know the typical approach is that uh I think at least in the encrypted version which is what we're looking to deploy that this is basically like all encrypted and this is all you know except for the few bits and the the length this is all essentially opaque bytes to any passive Observer um yeah but the technically the draft allows for unencrypted but I personally would not recommend then um and the marginal cost of doing encrypted honestly is it's not particularly High the worst part is just key distribution that's by far the most annoying part the actual encryption code is not that hard so uh even an L4 load bouncer um so come on then having to do a unicast different infrastructures are different but the key fact here is when a packet that it does not know how to route arrives I don't any load balancer on Earth as long as that load balancer has the keys that we have distributed to it in order to decrypt uh these connection IDs it can decrypt the connection ID look at the routing information inside of it and do whatever the network infrastructure like needs it to do so like at Google we have a bunch of stuff that doesn't really make any sense outside of Google and so like describing it would not be particularly helpful but like you know every different network infrastructure has information uh that they want to wrote by that's like that they can pack into this encrypted payload it basically is what I'm saying yep"
  },
  {
    "startTime": "00:14:01",
    "text": "could be a tunnel it could be something else could be GUI is actually another common option as an example uh great next slide okay let's talk about black bowling um so this has been a problem uh for a while at least for quick um this is partially historically due to some issues with middle boxes I think most of those issues have been solved at least to my knowledge but nonetheless um the internet is a terrible place and black hauling happens um and it's extremely user visible this does also happen for TCP as well um and I know that there are some mitigations in the kernel but I wanted to go through kind of what we did in quick uh to mitigate this problem um and next slide and I also want to say that a five Tuple can be black holed in either direction or both but it's quite often actually just One Direction but it doesn't really matter because you can't really tell like you can't really tell if you're not getting any acts because the packets aren't getting through from you to the server or if you're not getting acts because the ax get dropped it looks the same to you uh as the client so another challenge is it's fairly common that for a given five Tuple that multiple paths on that five two pole or similar five pupils will sorry uh will work like the the connectivity between like IBA and ipb is largely functional but one percent of the flow hashes may be dropped so it could be because you go through a bad wine card um you could be going through like a bad Rudder you could end up you know there's some load balancing going on and suddenly you end up getting sent through like some bizarre peering Point that's like extremely far away and there's extraordinarily High packet loss like just things happen and so it's not that uncommon for like you know two endpoints to be largely reachable but like either intermittently not reachable or otherwise unreliable um so the worst part about this is when you have black hole Wing typically you experience a timeout at least by default and you have to wait for the idle time out of the connection"
  },
  {
    "startTime": "00:16:00",
    "text": "um so this can be as short as 30 seconds but commonly you know could be a few minutes this is extremely user visible and extremely painful um and so like having someone sit there and like wait for a page to load for a minute or two because uh you know a flow happened to get a lot cold though it's rare is quite frustrating um and so in order to bring down tail latency next slide uh right now at least in our implementation we close the connection after there are five consecutive probe timeouts under the theory that at that point the odds that it's still alive uh are quite low um this certainly kills a small number of flows that actually are viable um but you know the vast majority of flows it kills are are dead at that point um I think that turns out to be when you do the math at least in our code at least like 10 or 12 seconds of time so at that point the user is probably quite frustrated anyway assuming it's an actual user and if it's a non like if it's an internet client like trpc or um non-user facing then I mean that's still an extraordinary amount of tail latency and at that point you're better off closing the connection starting all over um so it does reduce tail and Z has some downsides um it's kind of unclear why this is so useful on the server as well as the client we tried to just do it only on the client side and it turned out doing it on both sides the size does help I mean I can come up with theories but it's a little bit hand-waving um so I don't really love this mechanism in the sense that it's a little bit hacky um but it does work and it does fix some fraction of the cases the mechanism that we came up with more recently that I like quite a bit better uh next slide um see a quick solution um got a joke in there again uh is Port migration oh that's you dude never got resolved that's nice uh so the observation is that changing only Port can drastically change the"
  },
  {
    "startTime": "00:18:00",
    "text": "internet path that you eroded to uh if you do a trace route from two different ephemeral reports uh on your machine we've seen cases where you actually ended up going through different peering points for example which seems like amazing um in some cases like you'll have like nine hops on one side and 13 on the other or something it's like drastically different routes to just it's almost inexplicable it's kind of like shocking how different they are um and so as a result I mean sometimes like if the connection gets black hole like just try a different port on the client side um and it turns out this fixes the connection in a remarkably High fraction at the time like I don't have exact numbers and it does depend on platform um but and I'll get exact numbers at some point in the near future once you know maybe for a future ITF talk but it's it's quite high and it's um you know that avoids us relying on this five RTO or PTO approach of closing the connection and assuming it's dead because instead of dying those connections get saved and we have to use that mechanism less frequently so this introduces entropy in both directions so and like some of the changes um such as changing like an ecmp uh flow hash sorry a flow hash in IPv6 in order to get like ecmp uh to change and giving entropy which only works in One Direction this actually works bi-directionally and so it doesn't matter which side of the path is actually being black hole in for order for it to fix um and it's Now default enabled in chromium which is chronet Chrome and anyone else who pulls in the chromium source code which is a good number of folks um but yeah quite simple mechanism uh Works quite well highly recommend it um yeah and a nice benefit of quick over TCP actually because we've had similar problems at Google for TCP um and the solutions are much more challenging than just changing import as I said IPv6 uh you know flow hashes like one of them so next slide excellent"
  },
  {
    "startTime": "00:20:01",
    "text": "oh so we had an outage uh last November I'm fairly sure it was um it was quite terrifying actually uh it was definitely like one of the scary outages it turns out the impact will not end up being as bad as you might fear but it was quite terrifying um so there's a query of depth it was triggered by resumption information sent by gfes which are Google front ends uh two clients and then the clients within the resumption information back to servers so we talked about this yesterday with you know how you get zero rtt and such it's a lot of like let's ever give something to the client that the client then replays the next time and makes a connection so like it's fairly standard stuff real quick um unfortunately this new information was sent by these new servers caused our server the other servers to crash immediately um so much so that the handshake never even completed I got the client low and immediately died um so at Peak it was around 10 of all GFS or public-facing internet servers at Google it's quite a number um but it was very uneven it was mostly in Europe um and it took an hour and 44 minutes to fully resolve the issue which is quite a while um the reason for that is actually mostly due to um the SRE tooling and the impact on that um the reliability Engineers actually did not have access to number the tools that they normally would have access to uh there's actually like a lot more detail about that part of it in a recording I link to you later um but for now I'm actually going to focus on the technical bits because I think they're kind of interesting as well next slide so we we coined after this we coined this new idea called contagion which is like an interaction of distributed systems um so a key Point here is typically at Google what happens is We Roll something out we can area it say we tend to in this case it'll be sent to only two machines but typically you know sign into a rack or something we test it and if it starts crashing or doing something terrible then we roll it back right like standard stuff"
  },
  {
    "startTime": "00:22:01",
    "text": "um however contagion bugs at least in this case have the property that rollbacks don't work um because there's now a state distributed in things that are not your server and not the thing you are rolling back so in this case it was all clients on the public internet uh particularly Chrome and it turns out to be the worst one for reasons I'll get into later um but it's quite a number of clients that were potentially uh having to roll back and you know this basically we're waiting for these machines people to like restart their browser or something like that before we can fully roll back in some sense um so that's quite scary from an SRE perspective and a reliability perspective because uh you know rollbacks are like your friend you're like you assume that if you roll back the right thing you will definitely fix it and like rolling back the issue did not fix it um and that also means a single task can actually cause a global outage which is the other thing that terrified everyone um so next slide so an example and one of the ones that happened in this case is TLS or quick resumption so again uh you know this is widely used the server gives the client something that the client then repeats back to the server and then the server parses it and then you know if server a produces something that when server B parses it it crashes or otherwise you know has undefined Behavior memory access and so on and so forth then you're in a bad place this is sort of a unique outage in the sense that it can't be fuzzed in traditional Senses at least not particularly well um and it's not a zero day in the sense that an attacker could take advantage of it so as an attacker you cannot craft a token or a resumption ticket that our servers will parse it'll just not decrypt it just won't work so only we uniquely have the power to cause a global zero day contagion outage of ourself it's amazing with great power comes create responsibility um okay so next slide"
  },
  {
    "startTime": "00:24:01",
    "text": "so let's go through what actually happened to Google um I'll go a little faster through these because uh they're more visual but they're quite fun so uh a browser does a handshake to where we call a canary GFE which is a machine that's um you know using the latest software and or Flags so completes the handshake get you know next slide uh as I said before a token is given to the client that you can use to approve your IP address for future use so that's the source address token um you know the the client saves it everything is wonderful uh in this case uh the canary jobs populated a new field um that was mostly used for informational purposes but you know and uh so there's this new field that was that was shoved into this particular blob of data but of course it's all encrypted to the client ganto next slide uh again tokens and on the by the client demand next GFE uh this one does not have the new code um and Additionally the token should be cleared no matter what after doing this handshape because you already used it once however um due to a bug in our iitf quick implementation in Chrome at the time that did not happen so it's sort of stuck around in the browser until a handshake completed but unfortunately next slide every single time that token was given out the server crashed and so a handshape would never ever ever complete yeah it just yeah so you basically have a poison token that will never clear itself um and the sir the client will just keep like contacting servers and be like I don't understand like why are you not there why are you not responding to me this other person responded to me why don't you like me anymore next slide uh and it keeps trying and they keep"
  },
  {
    "startTime": "00:26:00",
    "text": "crashing next slide uh yeah exactly so the one of the good things that did happen here at like one of the few good things is chromium has this exponential back off thing where like the handshake fails it won't try um quick to that domain for another five minutes however we were giving out tokens across like a whole host of domains for like the period of time that we were giving out tokens and so uh you know a single client could still be crashing like 10 or 20 different you know services for like five or ten minutes um so you know it's it's still quite a bit of impact for like a single client that happened to be given these tokens uh next slide so let's talk about kind of the timeline next slide oh that did not get exported properly PDF fail okay back I'm gonna have to do this from memory um okay uh two seven PSD so the middle of the night um server started crashing the automated Canary checks uh started noticing that servers were crashing they instantaneously rolled them back after only two servers got the new code this rollback took approximately four minutes so two servers performance had the uh mysterious code enabled on them so but zero three one everything was rolled back sres were looking at it and they were confused because the rollback had completed successfully and servers were still crashing and additionally they started realizing that none of their tooling worked so all of their monitoring and everything at least in the London office was completely unaccessible um they couldn't access uh logging they couldn't access crash dumps uh they couldn't access they could barely even figure out like how many servers were actually crashing um or where it was quite Dreadful and it took them a while to even realize that this was not an in fact a global Google outage in fact the vast majority of Europe where this was centered had no"
  },
  {
    "startTime": "00:28:01",
    "text": "outage whatsoever for google.com youtube.com and most major Google domains um due to our Quirk of how this particular like rollout happened but for a while they were absolutely paranoid and completely apparent what they ended up doing is contacting some colleagues in Australia and New Zealand who are awake at the time um and had no problems whatsoever accessing these corporate systems because it basically was only crashing servers in Europe and they like basically hook them up with uh access I think it also turned out that meat worked perfectly during this time so like they like once they realized that they're like oh I'll just get like people in like another time zone to like get on a video call and like help me fix this up um so once they actually had access to everything all right which is around 138 um it took them about five minutes to figure out what the problem was and what to do and like seven minutes to roll it back um so you know it was like a 15 minute outage and a of the actual system and about like an hour and you know 15 minute outage uh of all the SRE reliability and monitoring systems that they need to actually fix the system um and this was another reason why it was so you know lengthy and painful I will re-export these slides so they're actually what I just said is done there okay so let's go to the last topic um so zero rtt is is quite hard even on a good day it's particularly challenging in ITF quick uh versus Google quick so you have things like multiple packet number spaces which from a design perspective are great um and have a number of number of nice properties but they are quite challenging to get correct and make sure that you are retransmitting the right thing at the right time and bundling the right thing with the other right thing and particularly if any single packet starts getting lost what you should do in response to losing that packet is sometimes subtle and if you get it wrong you either end up with a handshake deadlock or something that takes so darn long to complete that your usual will be very unhappy so like a single packet loss at the wrong moment if you your"
  },
  {
    "startTime": "00:30:01",
    "text": "can easily uh you know increase tail latency a few seconds uh not a few hundred milliseconds um so Additionally the key management is less synchronous in uh compared to like TLS over TCB so in particular the problem that Chrome had was Chrome had this thing where like it made the keys available when it were for handshake Keys available when it got the servers initial and like and then it could parse the server's handshake packet and then acknowledge that and like continue through the quick key schedule um unfortunately there was a bug in Chrome where if certificate verification took longer than it took for the server's initial to come back the event like the event never got triggered to actually release handshake keys you would never get handshake keys and chrome would just be like I can't process this packet because I don't have Henry keys because like pouring SSL didn't give it to me uh and like it would just sit there and like not acknowledge anything and not and of course the server was purple X because the server had gotten the you know its initial acknowledged and it's like well you process my initial why don't you have henchiki's um but yeah it was just due due to timing sequencing error um and again like this is one of those bugs that like quick due to kind of like the potential reordering events and stuff I think is quite a bit more likely to to have um so there's a whole talk on this uh recording and slides um that you can watch and that's why I didn't go into it further but uh it's it's there's some complex sticky details in there but uh needless to say it's it's something that requires a lot of patience and a lot of debugging an excellent tooling um without excellent tooling I would say uh it's it's extremely difficult if not impossible to really get this right um also I'd like to say the first time we tried to enable zero to T it was a substantial regression compared to not having zero to D so do not assume it will be faster just because it's zero to T even if your zero to T success rate is"
  },
  {
    "startTime": "00:32:01",
    "text": "like 70 percent the 30 that don't work if you know a bunch of them are like have terrible tail ends here or something it's going to drag everything down it's going to make the performance worse so like please do not assume just because you enabled Xerox that it will be a performance when um you know really test it and actually like do the measurement and gather the data to like ensure that it's actually um a win for your particular implementation um that being said once there's a win for you for a given implementation I would expect it to be a win for all applications using that implementation so I'm not saying you have to like retest it per application but um for developers I would just definitely be very cautious about that an amount of time thank you very much Ian uh and now direct from the London Underground to talk about excellent tooling we have Lucas Perdue do you want to share should I share here it's uh yeah that one that one okay you're gonna have a clock oh I'll get your clock okay I'll fill in the meantime I was trying to think of a transport related joke on the way in while I stood on the tube all I'll say is my round trip time from here to home is about eight hours I think so anyway uh I'm Lucas Padu I'm a co-chair of the quick working group um I'm here today to talk you through all these slides about applying observing and debugging quick um I'm a little tired so just bear with me in case I ramble a bit but I've got a clock so I won't run over time uh so this is good I wanted to spend more time talking about the applicability in this talk but there's just way too many slides so in the slide deck are a load of overflow got a backup slides maybe if you have some questions towards the end or in the panel session we could go back to those or you go away and you're so inspired by this talk you want to find out a bit more um so just keep that in mind uh in this talk we're just going to kind of probably touch on other topics that Martin Jana Ian and Martin may be touched on but just from a lens of Uh"
  },
  {
    "startTime": "00:34:02",
    "text": "something's going wrong with my quick connections I don't really understand it that well um I'm maybe like an SRE or an Ops person and I just need to figure this out I'm familiar with TCP I understand networking but what what can I transfer from my previous knowledge into quick and what things shouldn't I do um where do I need to retrain my brain these kinds of things so this is just going to walk through a couple of real world examples literally something I was looking into the other week There's a silly book but you know something that's been there latent and so we looked at it and so let's go next slide please but first the important things just to reiterate if you haven't learned anything yet in these technical deep Dives the quick is not TCP there's lots of similarities but it's different and those differences are the the kind of the the places where you might stumble or fall next slide noise quick just TLS as as we we saw yesterday's presentation the architecture and the interactions the models between quick and TLS you probably need to know some TLS so some of the stuff we're going to look at shortly is it's going to get into things like TLS client hello understanding around aspects of the TLs handshake but not the timing and interaction specifically of those messages it's going to be important because quite often when things don't work they don't work from the first step where the handshake fails so let's go next slide and it's not it's not HTTP this is one of my bug beds quick yes okay G quick was uh built to carry HTTP but that's not what we have today we have our ETF quick and it's capable of carrying anything you can imagine um literally you need to go if you have an application and create an application mapping I'll allude to that later on maybe more about what it means um but yes it's not just HTTP there are aspects of Quick's design that lend"
  },
  {
    "startTime": "00:36:00",
    "text": "itself well to bi-directional exchanges but we have other capabilities to carry things unidirectionally or we have a datagram extension that will allow unreliable message delivery don't make assumptions about your understanding of how HTTP works and if you don't understand how HTTP works that's even better because you can come in and take all these learnings away next slide please um and it's not it's definitely not the web over EBP it's it's here for for many applications in our working group uh we can help advise you if you want to use Quick uh but we we won't be The Gatekeepers for application mapping documents that describe how to use Quick generally the transport services it provides work now um module some implementation concerns but it's it's here for everyone to use it's not the only thing you should use it's not you know our Panacea of everything but it's definitely a tool to sit in your toolkit for internet next slide please um and it's quick quick is quick next slide it's a secure transport protocol which means we might have some issues trying to analyze it if we're doing things like packet captures just keep this in mind that some of the things you might be able to do with TCP where you're analyzing it with tools like Wireshark they're not impossible but they're different and they might require different approaches next slide and it's what you make it which I've already touched on next slide um so if you haven't got the time for any of this quick starts with a handshake we have application data sent as soon as that handshake is done for some definition of then Ian just talked about zero rtt there's different effectively stages within the connection the application data can be exchanged but it all relies on this handshake happening first post that at some phase within that checkpoint the package is going to be protected if you don't have the keys for that session you're not going to be able to see the contents you'll have a very slim sliver of information available in a header"
  },
  {
    "startTime": "00:38:00",
    "text": "um it's tiny and you can't just rely on that um and the other important thing maybe it's been touched on already but we we have a reliable and unreliable application data the reliable data is re-transmitted in new packets it's not re-transmitted in in the packet being resent this can cause differences in the way that packets and framing work if you're familiar with TCP and you're trying to look for maybe particular byte offsets within a packet capture this isn't not the way to do it you're going to have to drill down into streams and probably any application layer use of that stream or reframing or subframing on top of for extremes next slide please um and we talked about applicability management too um whatever we mean by management of a network maybe if you're just an operator a network then you're the manager I don't want to get into that but we have two excellent drafts that have been published uh in September so fairly recently but they've been developed alongside their core Roc specs uh you know 899 through 9003 um and they cover two different aspects of things you might not be aware of these documents they're a really good read if if you want to get away from the nitty-gritty protocol details which are good but you know that's more of a reference manual these documents are written for a different target audience the first one is the applicability draft RFC 9308 uh talks about the features of a transport protocol how you might adapt your application whatever that is to work on top of quick but not just an instruction guide but the caveats are considerations that you might need to make where you have stream concurrency that's a different feature compared to TCP which had one single reliable byte stream quick off easy a lot more things and a lot more ways you could hurt yourself and a lot more potential for interrupt consider problems so where you have a client in the server that have a different kind of understanding about what concurrency means for example so it's an excellent documentation document for that kind of thing"
  },
  {
    "startTime": "00:40:01",
    "text": "um and then a completely different target audience in the manageability draft which is more for people who uh aren't operating a quick stack entirely but seeing quick traffic flowing back and forth across their Network so this touches on the quicker variants and the quick transport protocol um and gives you effectively um some explanation about what quick is or what quick will be maybe how to analyze it maybe how you won't be able to analyze it compared to other protocols that are traversing your network so next slide please um again let's go back everything starts with a handshake there's all the the places where handshakes mentioned it's everywhere it's great uh this is already covered I hope um but the key items here I want to focus on today are these two packet types that we have initial and handshake these are the things you'll probably see in the first five lines of any lecture that you take um the initial's not tight is a type so it's not an adjective sometimes when I talk to people who aren't familiar with quick and talk I'd say you know we need to see the initial packet and they think they mean the first one but you get things like re-transmissions or retries reattempts to send the initial and you'll see multiple initials um and they they also hinge on the the actor in The Exchange so you'd have a client initial the server initial using the terminology like I'm that person who insists on trying to use it correctly and to to everyone's annoyance but it's really critical here and and my my understanding is we need to up level a lot of people within the wider ecosystem people like sres or operations to really they don't need to understand all of the details but one we're just communicating can you help me and see if the initial made it through through the network and arrived at my server stack these kind of conversations people can be familiar with the TLs terminology like did we receive the client hello it's similar to this kind of thing um so but if that's one thing I would ask you to focus on and take away um use the right terms next slide please"
  },
  {
    "startTime": "00:42:00",
    "text": "so there's this excellent tool called The Illustrated guide to stuff uh I can't remember the right name uh there's a link here uh it covers not just quick but TLS 1.2 1.3 I think um this is a visualization of of actual kind of simulated data if you go to that website in the repo behind it you'll see that they use kind of real client server interactions and take the pcap and then take those bytes so um you can see here I've just tried to point the text as well I apologize but there's a lot of stuff going on I do encourage you to go visit it but you can see there's there's two different initials within this vertical trace the client initial and the server initial the arrows there kind of pointing in the opposite directions um so if you go to the next slide each of these boxes you can expand and it's really meant as a learning tool this isn't a debug tool um the bytes here you can say you can go into the GitHub and they're canned and you can go and understand exactly maybe you want to go and Fiddle or do other things maybe you've got some comments on the additional kind of annotations you might like to see but you can you can open up the client initial you can view the TLs client hello within that client initial and then drill down into different bytes there so it's good if you just want to say maybe take an existing trace and compare it to kind of a reference example say next slide please um just to drill even further in there are these transport parameters these are the the properties of a it's a connection that each endpoint will advertise to its peer we don't have time to go into that um but if if you're like looking at a packet capture and you see and you're drilling down and you see these transport parameters and you think what what are these going looking Ayana they should be registered there maybe not but you know this will give you a brief overview most of these are in RFC 9000 but we have things like extensions which would use transport parameters these kinds of things might be new to you you might say I'm seeing some kind of issue and it could be related to you know a"
  },
  {
    "startTime": "00:44:01",
    "text": "mismatch or an impedance there you can see on the right hand side is this full expansion of what all these things mean next slide please um so let's look at an illustration from Live Connections we just looked at you know the some pre-canned examples you can use your old friends pcapp and Wireshark to look at this uh to just sex successfully dissect quick packet to get any division of Wireshark 3.4 and upwards um the examples here for the remainder of this session I just created using cloudflare quiche I work for cloudflare it's the client and the server I'm most familiar with we have some example apps in the repo pretty much any other client is going to be very similar to this so if you have a favorite you could probably recreate these things but just in this example I have a server running on localhost these flags effectively minimize the handshake they just reduce a few steps for clarity if I didn't have that no retry flag for instance it would send an additional message during the handshake it's all cool but it's complicated we don't have the time um so you can kind of ignore those things but yeah this is just a request on my Local Host to get an index file and that pick app underneath what you see is very small text and you probably can't see it but um that's kind of the point because I want you to go and look at this yourself but the first the first packet or the first line there is the client initial going towards the server and then we have some stuff coming back in the other way it says handshake there but we're going to drill into that next um well one more um so I have some ready-made examples speaking with Brian we thought it would be cool to like take some live real things um that I captured and put up on GitHub this these P caps and Q logs that I've got for local who's good just a simple good exchange of a request that succeeded at the quick layer at least um so next slide please um again too tiny to see but if you opened up Wireshark and you clicked on your first line and you expanded out all the details you're going to see a few"
  },
  {
    "startTime": "00:46:00",
    "text": "indicators here about what is the client initial um it's easier it's a lot easier here because we've only got you know a very small pcap of of one interaction and we already know that but if you're kind of trying to find a needle in a haystack trying to look for some of these things it can be a bit difficult but yeah we've got indicators like the source port or the destination Port this is a bad indicator using Source Port don't rely on that being anything it could be the same for everything because quick is clever but alongside that within the the packet type information here we've got you know dissection to tell you the type based on stuff and underneath within within the contents of the client initial we have the the client hello so this is the TLs client Hello message again zooming in we see the transport parameters this is exactly the same as the other slide I showed you but these are the actual transport parameters that the the quiche client sends in this case next slide please um important thing here is application layer protocol negotiation I don't really have the time to get into this at all but the in this case what happens is the client's going to send a whole set of different variants or versions of HTTP that it talks um so it's like an offer um answer application protocol and this is it you might see different lists different sets of protocols in there if you're writing your protocol you should definitely make an alpn for it um because it helps you allow multiplexing of different applications maybe if you just want to set up one quick listening port and support a slew of applications on there um this touches on the applicability drafters things you should consider around transport parameters in relation to the application virtual you're trying to negotiate and where things might not completely converge but that's another talk for another day go read the applicability draft next slide please um in a reverse direction we have a server initial and a handshake and you can see in the top the indicators are"
  },
  {
    "startTime": "00:48:00",
    "text": "kind of similar The Source Port is the server's listening address that we showed um in the line a couple of slides back uh we have the the initial type again indicated um and then just below that we have a server hello coming back um but we can't see as much information as we could in the client initial um we have this server handshake packet just underneath um but you can see it's been quite clear there we can't decrypt anymore because the secrets aren't available what does that mean next slide please um we need the keys we need the keys to see the full picture um from even in that early stage of you know one and two interactions going in in opposite directions um we might not be able to see everything that's happening that would help us diagnose some kind of issue that might be happening early in the connection you're probably familiar with something called SSL key log file but if you're not um it's used by many but not all implementations endpoints can be instructed but like an environment variable or maybe you know just built or configured to drop sorry Place their keys explicitly in a location that can be used to contain the session keys in a format um this is kind of common it's a de facto standard Martin's been working on a new ID to kind of formalize this format which is good work um uh but the session keys are symmetrical so if you can drop them from the server or the client and you should be able to decrypt the the packets for anything so depending on who you are what you're in control of sometimes you can you can use this as a kind of I need to see both directions of traffic in this example like I said we're just using an environment variable um to to dump some keys into files locally we can configure Wireshark to pick that file up next slide please um so we I can't go into it but yeah the Wireshark documentation will explain this and go into your preferences or there's all kinds of cool tricks you can use but once you're configured once it finds the correct session keys for an"
  },
  {
    "startTime": "00:50:00",
    "text": "interaction um this is again there's the same kind of dissection I showed earlier but this time that handshake packet is revealing a lot more information it's showing the alpn it's showing that in this case the server picked H3 so from that whole list of things it picked one next slide please um but if we revisit the kind of complete picture not just the one packet we can see the dissection without the keys there's some you know the top four lines too small again sorry but um we've got some packet types and then it trans uh kind of converts into those protected payload where we can see a field called the DZ I'll explain that in a couple of slides but um that's it if you click those things you're just going to see opaque bytes and you're not going to know what they are with the dissection well with keys you can see that we're actually can drill in now we can see different packet types packet numbers frames within those packet types um stuff around streams acknowledgments crypto etc etc next slide please and then I touched on the SIDS these are connection IDs if you look in this example we're going to see different connection IDs going in opposite directions this can be useful if you're just trying to trace um you know connections of a particular type again if you're trying to find a needle in a haystack next slide um so that's why shark and that does one thing well especially if you can dump the keys but we have something called q log which is like my colleague Robin down the front has been working on for a number of years he'll tell me my description is rubbish here so go and speak to us at the end and we can inform you everything but you know the implementations often have debugging or you know logging of their own to augment stuff like packet captures you can see kind of the reason why something happened not just the fact that it did happen um and the common logging format can encourage you know an ecosystem of analysis and tooling um that isn't just specific to an"
  },
  {
    "startTime": "00:52:00",
    "text": "implementation um so so what we have in the quick working group is adopted working items for a kind of core base schema and cddl this is very extensible we can use accessibility to Define concrete definitions at the moment we're just focused on quick and HTTP 3 related events because that's what we've worked on but other kinds of things can be added so if you're adding application mapping you can well maybe you wanted to find some q log events that's something we're trying to figure out this week what's the right level of guidance to give to people um but it's extensible it's just logs it's just kind of text you can stick stuff in if you know how to read it if you know what to look um but what's nice is the the current Fleet of quick implementations many of them do support q log so if you're trying to find a bug between client and server implementations and you understand what stack that is so it's curl built with hb3 you can enable q log and get this q log format out and stick it somewhere that will help you analyze maybe fault diagnose more quickly or understand what's happening with the congestion window next slide um and we have cuviz Robin's lovely Q visitor um which I would just describe as trying to make sense out of Oodles of data um if if you went on the GitHub and grabbed some of the the reference material I had you can go to this tool now um you want to do for option two upload a file it's not an upload it's kind of all client hosted for what we would analyze today at least um so all happened in JavaScript in your browser and come up with this kind of excellent sequence diagram again way too small to see the details here but this is effectively rendering the same information we just looked at in the Wireshark in a different way so this is going to give you maybe a bit more of a context aware view of packets exchanging between the client on the left and the server on the right um each Line's a packet that's my interpretation again Robin correct me at the end but um within those you have the"
  },
  {
    "startTime": "00:54:01",
    "text": "frames we have kind of a very quick summary view of what those frames are and then if you click any of those boxes it's going to give you an expanded View and it's this is a real example but it's a good learning tool if you're just trying to get familiar if you're not somebody who can read a spec um you know in one go and walk away and understand everything if you're a bit more um like me a bit more practical and you just want to run some stuff try some things out and do this next slide please um so I just want to look at a real world failure that we had again this is using SSL key log file they're great and no the box is in the wrong place oops so um yeah it's using SSL key log fault amazing but there's a property in hb3 you need to be able to open some new directional streams again don't have the time to go into that but you can configure this quiche client this example application to advertise um from the client to the server a value of zero that it can open zero initial uh unidirectional streams when the handshake is complete our server code doesn't like that it wants to be able to open these streams and if it can't it will detect the error in the code and send a connection close message so an explicit immediate close from the server to the client to say I want to open up the Control stream I can't sorry like go away this is the kind of thing you should probably be looking for if there's ever a report of an issue stream research Connection close messages are kind of good strong indicators of what happened but maybe not why next slide um same failure same same Trace effectively the q log captured at the same time a different rendering you can see here the connection closes in the bottom in red that's as much as you can see because of the rendering but yeah um it might be a better way to view these things next slide another one another failure this time pretty much an identical command but um"
  },
  {
    "startTime": "00:56:02",
    "text": "for a different host name so the last one was the localhost and this time to to my website um and in the packet well the peacock looks a little different it's just just from a mile kind of view it's different which is always a good sign of if the behavior is different if someone's saying this behaves weird for this thing and not that one and you see a P CAP that's identical that's annoying but if there's something like this that's immediately there's a change in Behavior that's a good signal so here it's like where is that connection closed I told you what the behavior was what we're expecting we're not seeing that why slope is qviz it's even worse it's even smaller you can't see it the indicator here is it's really long there's a lot of things going on here in terms of timing there's no collection closed received by the there's a bug here it's received by the client not the server but anyway backside please so what's the difference um you know we've got effectively the same client Behavior it's just pointing at two different endpoints are they a different implementation are they different Stacks no like they use the same underlying stack in this case I know that but that's because I've got Insider knowledge what's the root cause what could this possibly be and that's what I had to spend some time on the other day looking into outside there's different types of connection close we haven't got the time to go into this but you have a transport layer and an application layer and um code and they send different types and stuff next slide so the root cause here is a trouble with timing the hb3 light library that we use for the server side like I say it sees the zero doesn't like it cause close on the transport layer passes it an application layer code and a reason but neither the application or the hb3 library track the transport State the handshake had completed correctly at that time so that this doesn't happen"
  },
  {
    "startTime": "00:58:00",
    "text": "unilaterally but there's some timing differences that I found and because there's a potential leak of information of application layer information before the handshake had completed um the the RFC says to don't send it you know send something you can strip some information so that the the peer is going to receive That explicit close and know that something went wrong but not the specific details um but that was just a bug and so the the server didn't send that the the client kept retrying not retiring that's what I want to do um but eventually the idle timeout kicked in and gave up after several rounds of retry X slide and so that that debugging given I had some tooling and some knowledge of where to look God quite quickly I was able to um kind of turn that into a unit test and come up with a fix which was a one-liner and now the client will always receive the timely close next slide so yes in summary it works if you know what to do and that's what I want to make sure that we can scale out our understanding of quick our ability to use it it's one thing having us back on the Shelf great wow but we want people to use this quick as in TCP it's not TLS it's not HP or the web over UDP it could be anything that you would like it to be and there might be use cases that you need to use that might need kind of slightly different approaches to debugging but generally in my opinion stuff to do with the initialization the the handshake is it's kind of the first step in everything um there's minimal information available on the wire crc9312 for the for information about how to observe quick if you you're not as kind of involved in the interaction between client and servers you would like um and and just be aware that implementations and deployments can behave differently sometimes there's bugs sometimes there's a lot of things defer to an implementation choice you know I should kind of level of normative"
  },
  {
    "startTime": "01:00:00",
    "text": "requirement and just opinions of The Operators so I don't assume too much I don't assume that the implementation is perfect or that a behavior that you see that seems weird isn't done by intention and there's ways you can kind of get some logs to do this that's it I'm done thank you thank you very much Lucas so uh I will ask uh all of our speakers um to come up um good morning Jonah uh Lucas you too [Laughter] oh that's gonna be cold and actually if one of you could grab the mic and we'll do the past the mic thing yeah and if you have any questions for any or all of our speakers please put yourself in queue and come up to the mic now I'll give people a couple of seconds to figure out what they want to do before I start asking my own questions I know it's early yeah actually for the for remote people can you like actually put yourself in queue I mean you go ahead and say your name but um like we do want to make sure we're refer to people who are not here my name is David and I guess question for Martin Thompson I probably could have looked us at myself but um I think you mentioned that you initially tried to use dtls but then is a bad idea so not using TLS um but quick is UDP so is TLS TCP or UDP um I got confused in that point oh that's that that's that's a fun question so um we we initially thought that maybe the handshake uh could use"
  },
  {
    "startTime": "01:02:00",
    "text": "the DLS dtls mechanisms for reliability and we would just do dtls to start with and then we would get to do quick things once tcls is done unfortunately dtls doesn't have the sort of really sophisticated uh recovery mechanisms and all the other things that quick has and so you get a lot more Advantage from from building all of the the reliability and and in order delivery mechanisms on top of quick and so that's what we've we've done by doing that we were able to use TLS which is a much simpler protocol and so um we avoided all the detail list Machinery necessary to do reliability and fragmentation reordering and all those sorts of other wonderful things and just use the stuff that we use for reconstructing streams in quick and and that turned out to be much much easier in the end as it turns out once we made that decision it was it was very straightforward to to use all of the quick machinery for for managing packet loss recovery order delivery and whatnot the TLs uses so yeah you get the you get the um the advantage of you can use like a sort of a single software architecture and the disadvantage is you get a really wonky layering diagram right I think it's like and we we spoke about that early on it's like oh this layering diagram looks weird there must be something wrong here and it turns out that it was right because otherwise you have to have or whatever so yeah I mean I I think we've always held that the layering diagram should follow reality reality shouldn't follow the diagram um and in this particular case it was very obvious that actually having a separate um loss detection recovery Machinery was going to be fundamentally sub-optimal it's not something you want if you have"
  },
  {
    "startTime": "01:04:00",
    "text": "a big data stream and you have all the mechanisms built in you want to use the same one for all the data that you send not just for the handshake data is not special in this particular way yeah cool thanks David I tell I apologize that I suspect that this was some already addressed and I missed it but what's the current status of the original Google Quick implementation with regard to the ITF implementation I we are attempting to turn it down and remove the code as soon as humanly possible um it is a very very high priority of my team um the expectation is q1 it may be off sooner for sure than other properties so like YouTube might go down like turn it off earlier and stuff but um it's either going to be very end of Q4 or q1 that you're going to start seeing it being turned off um hopefully the code will be delayed by the mq1 if I'm really lucky but it it's a lot of code and maybe you do so yeah hello and I'm escort AG just a quick question about uh quick and using it over Nats and firewalls Etc is there any special consideration or things you have to do uh let's say to keep a connection alive it's just wondering about that um I mean yeah just just don't block all the connection after the handshake it's a bummer to debug um it's very bad for user experience like if you're gonna drop like a quick handshake just don't let any package through because remember one packet in each direction is enough to complete a handshake in some circumstances and so like some we've had issues with packet inspection where like some of them are like I'm going to take a few packets to figure out what flow type this is and it's like after three packets it's like yeah I don't think I know what this is"
  },
  {
    "startTime": "01:06:00",
    "text": "so I'm going to just drop it it goes terribly these are experiences Dreadful so don't do that uh besides that like I think a lot of things are quite acceptable oh there's also information in the um manageability draft that's actually quite good yeah so um the the manageability draft talks about uh from from the client or server side when you when you potentially have a middle box on the path that's doing that or something or firewalling and um as long as they follow the advice that Ian uh talked about there then then things will work what we do find though is that some Nats will time out faster than the connections will time out that's okay uh the use of connection IDs will ensure that connections will still manage to to work um it looks like migration at the server but everything just sort of sort of works out reasonably well we don't recommend that people do keep lives keeper lives are useful in very narrow circumstances um but in most cases you won't need them it is better to just walk away from a connection um and never send any other packets if you don't need it and we found that in particular when you're dealing with mobile devices that's that's uh excellent advice because you don't want to wake the radio up just to say that I'm going away just walk away so that's some context because I I think it may not have been clear um browsers currently rely on TCP as a backup if quick fails so if the quick connection were to fail the user would not see a problem would be able to fall back to http 2 and TCP and that would work just fine that's currently something that we do across the board and the problem is if quick doesn't fail quick succeeds HTTP succeeds and then fails eventually that's a harder one to debug is the is the the basis for that now the the"
  },
  {
    "startTime": "01:08:00",
    "text": "one thing in terms of keep lives and other things is that and that cannot do much in terms of adding to the connection right and that cannot send keeper lives and that cannot do any of those things and that cannot send a reset um these are things by definition just part of the protocol it's all end-to-end encrypted and that's that's that's one thing but yeah the things that the NAT can do are things like dropping in odd places or or things of that sort but those are the things to be mindful of one thing I'll add is um as the stated in the manageability draft if if possible if Nats could actually conform to the RFC and I use the I think two minute minimum idle timeout for not rebounding that that would be that's sufficient for like I think the vast majority of use cases but if if that's that would be my like ask is like ideally if they could do that that would be wonderful hey uh just to add um John touched on TCP fallbacks um this works well for HTTP but quick is not just HTTP so uh if you are if you're designing another application to go on top of quick um you you might have different world or different considerations maybe you're taking something like that already works over TCP and a new mapping on to Quick the applicability draft gives a good section of considerations about the need for a TCP fallback but not the Mandate um and gives the color commentary about these kinds of trade-offs which are Illuminating okay thank you George Michaelson can I shift Target a little bit which riffs on what you just said I realize 99.999 of the world is HTTP and I would approve of targeting the thing that will make everyone happy and money but I live in SSH and mosh and I sit here wondering why isn't there a shimlair library that simply allows me to do single packet transactional work reliably across address Mobility taking"
  },
  {
    "startTime": "01:10:01",
    "text": "care of this stuff why hasn't there been an interface spec that gives me a command and control interface for a machine that runs over quick and S Tunnel exists so it's not like people don't understand how to do SSH over TLS through Packy abstractions but couldn't you code a shim layer that just gave me transparently access to this framework to do zero rtt low latency protected access walk away from it come back on a different IP and carry on the session this is what mosh does but I don't want to run a pearl user space demon to do my terminal binding where's the shim where's the equivalent of trumpet windsock that gives me ubiquitous access to this software that's off topic right that's the quick answer is sorry that's off topic Focus has got it and John is up and I'm gonna put my hand in here go ahead no Lucas I'll give you the the short answer which is the the person who wrote mosh uh is now I believe a Stanford professor and probably has like much less free time than they used to um but but uh yeah I think I think it's a very viable concept I mean it's it's mosh solved a problem for all of us right and this is I mean it did solve a problem for all of us and and the fact is that it's that Mobility is something we want session Mobility something across the board is something you want I mean but but as Martin's pointing out I think that the protocol offers the facility for doing it there's absolutely no reason to not move no but the essential quality in the very badly worded question is there is a significant barrier to entry unless you sit in HTTP mode and think oh well quick is just HTTP I'll use Quick well it's not just HTTP and your comment when to if you are running in different contexts you may have to do TLS failover and I'm sitting here going I have to code the TLs failover no you should be coding the"
  },
  {
    "startTime": "01:12:00",
    "text": "TLs failover for me it should be a transparent shim function I should not have to perform that function I expect respectfully this is not a service organization yeah but you know what I mean with that software you know what I mean this is not really a question for us this is a question for the audience please please someone provide George with the uh yes with these capabilities we would all love that very much um some of us are doing other things at the moment so maybe this gentleman here will do it for us hold on I want to do I I do want to to I thought one of you was going to say the following but uh I think mask is tomorrow morning right and mask is um about 80 of what you want built put together in a different way for a different use case right so like I'm not saying you know use mask for mosh but if you basically reorganize the bits of mask you could build a mosh and you know you all of you just let this be inspiration as Martin said like the tools are there the bits are there we're still learning how to assemble them and I think that we could very easily assemble something that looks very much like what John uh what George wants from parts we mostly already have yeah but I do want to reiterate this this fact that you know we we've done the work so far um and we explained the protocol so go build the dam tools and this is so to all of you right I mean it's it's all of us as a community to build this yeah I was going to say yes I am working on something like that but it's going to be a long time before it works over quick in the first I've got to work out how to do exactly you know transport layer fixed then work out what the API needs to be in order to abstract an agile cryptographic transport or whatever and then finally I'm not using quick at the"
  },
  {
    "startTime": "01:14:01",
    "text": "moment I'm using the M stuff I'm going to have to work out how to map that onto quick so it's going to be about 12 months before I have something that will do what he wants and then it's probably going to be another 24 months after that before we work out how to to do it on quick I mean I think it would be very valuable to abstract down and work out how we apply quick like transport directly to web services and get rid of http because HTTP is a really rotten way to do an RPC interface there's a huge amount of overhead and I'm speaking as one of the original authors of HTTP 1.0 and the person who originally made it possible to do that it's what I want to do is to take those parts of HTTP and put them into the transport ship so but it's going to take time so yeah there is um the quick working group is not going to produce a quick API I think there's enough Divergence in the many importations that work that's just not going to converge um there is however the Taps working group which is working on abstract transport layer interfaces that that support all sorts of advanced functionality that um that transports like quick provide and so I really encourage people interested in a more generic API for this kind of stuff to to take their energy there so the documents are mostly done so take your energy there means please comment on ITF West call uh true there is this totally quick nothing to do um yeah so it's not just HTTP we have DNS over quick which is defined and it's a thing and and you might say well it's natural just fall back to TLS there but that might not be what you want right you might want to fall back the DNS over HTTP there's I think it's very easy just to assume that we can build a batteries"
  },
  {
    "startTime": "01:16:01",
    "text": "included API and Library those things could exist they could be powerful but um sometimes they behave in ways that you don't want and there's no hooks or configurability to change things because the needs of your application are different presuming there's always going to be a TCP equivalent to your application protocol is like that's just a guess we don't know what those are and trying to anticipate is a bit a bit rubbish um so we we have some of this going on in web transport where you know we we have different ways to carry this thing some are UDP based over quick and they want to use the service of unreliable message delivery and so if that isn't available falling back to a TCP based fallback isn't going to give you that same transport feature is that really what applications want or would they prefer to give up and fall back to something like webrtc that might not be ideal but they would prefer that possibly we don't know it's it's kind of impossible to anticipate all of the application needs and being too opinionated is maybe giving people a disservice there and actually trying to trying to allow applications to model that is where a lot of the complexity in the tax interface comes from right like that's the hard problem so there are two things here right one of them is that there's um there's the network and then there's your your application that you want to run on top of quick so in terms of what do you want to build here you this is what I said yesterday in my talk we built using HTTP because it was an excellent vehicle for us to get this out there but the work that's happening now DNS and and others and and also uh mock which is also happening uh later this week all of this are you know work that's going on and trying to map other applications and and protocols on top of uh quick finally in terms of the network itself we know for a fact that there's a small percentage of the network that"
  },
  {
    "startTime": "01:18:00",
    "text": "doesn't allow UDP or you know when with experiments we found that quick doesn't work on 100 of the paths that's also an application Choice your application can absolutely choose to say that it's okay if it doesn't work it doesn't work the application doesn't work if quick doesn't work you don't need a TCP fallback and that's all uh up to the application and I think we have a question from Tony Lee who is remote I think um some of us are thinking about migrating in a strange application to Quick this application is called bgp and we'd kind of like to not mess it up uh do you have any idea where the potholes are you going to be okay where are the potholes for putting bgp on quick yeah I'm aware of multiple bgp over quick drafts um and I've skimmed they seem to be fine to be honest I don't know enough about bgp to comment but you know the the quick working group is here to provide some feedback so we can do this formally um absolutely if you want to come and ask for like an early review that this is the kind of thing that personally I'm I'm always happy to do but I think people in the working group because we don't want people to try quick and then it fails trying to preempt what those problems might be is is difficult but kind of the typical ones for me would be flow control um connection level and stream level flow control how big are the messages that you're exchanging you're going to find some way to get not deadlocked but not for perform as well as you might do multi-streaming in general is is a big issue here you're using quote probably to make use of the multiple streams and the one draft I read um how do those things actually interact at the application can the the API from the quick layer and your application work in such a way for example there's no Global audience of streams in quick this is the done by Design as a"
  },
  {
    "startTime": "01:20:02",
    "text": "performance Improvement so we've already had a line blocking but can the application manage out of order delivery you can send them in the correct order but the network is the network and they might arrive in a different order if you're depending on specific ordering between things at the application lay you'll need to accommodate that in terms of synchronization or checkpointing or however you might need a design if you have more Atomic messages like DNS over quick where these things are very independent it's a good mapping um just uh stream credits so we talk about flow control but the number of streams that you can have open concurrently how is that done you have the initial unidirectional stream limit I talked about earlier um those are the initial limits but as soon as you've kind of blown those limits you need to keep sending stream Max stream frames to keep granting credit so I think something we found in the early interop days is you could do some like quick tests like I just did one or two two requests and response interactions all good then you run a server then you have a bug where you forget to Grant you credits and you eventually get to a point of kind of connection saturation and nothing can happen nobody can do anything any ideal timeouts which is okay but it's probably not what you want if you're running a Services trying to run and run and run foreign what's interesting I think about bgp to Lucas's point is that it tends to have extraordinarily long-lived sessions and um quick sessions will eventually run out um this is something we did in HTTP 2 and and and also have done in quick it's probably not likely in an apple in a in a protocol like bgp that you will run into these things but who knows some of these boxes stay up for a long long time uh the thing that I think is um probably more of a challenge in this in this context is is managing keys and and Authentication"
  },
  {
    "startTime": "01:22:00",
    "text": "because I understand that the bgp is uh often run essentially in the clear between different asses and that's going to be um a shift in the attitudes in in terms of how you configure this the the the peering points um that that happen there because you need encryption with quick uh I don't know how many stacks currently use something like appreciate key mode uh that is not something that is widely used in on the web so it may be that you end up in a situation where you want to use for instance self-science certificates with um with with maybe even no uh validation of them to to ensure that it works as the the existing system has done with of course the option to upgrade to something that that is fully authenticated yeah I was going to add that I'm happy to review a draft on bgp I think it's like a desolate use case uh key distribution seems like a problem but um yet there are a number of solutions I think I think it's just a matter of looking through the options and getting a review from the quick folks and the transport bits and then maybe getting a crypto review as well on the on whatever key distribution or lack there have you choose to appreciate um but it seems very doable Chris so when the about how the handshake Works um I saw that there was obviously some information in those initial packets um uh for example I saw advertisements about um uh what alpns we might be about to talk on and obviously when I saw alpns in the clear uh alarm Bells went off um I was wondering what information all do we actually leak onto the wire in the clear if that question makes sense yeah so um"
  },
  {
    "startTime": "01:24:01",
    "text": "as I talked about yesterday we're not strictly leaking it in the clear uh anyone who is able to see the initial packets from the client um and the connection ID that's in them and they know the quick version that's in use we'll be able to recover the keys and decrypt that information so technically speaking when we when we talk about what's in the clearing quick um that's that's often a shorthand that we'll use to sort of mean that well there's no genuine cryptographic protection for these things we're just applying what is effectively AES as a check summing mechanism and an obfuscation mechanism so um what's in the clear is everything that will be in the clear and TLS 1.3 and not a lot more honestly so if you look at TLS 1.3 and it's uh client uh hello and server hello those are the things that will be in the clear and so for the most part that sort of falls into two categories there's the there's the things that you need in order to configure the key exchange in TLS those things will always be in the clear to some extent but then there's also a bunch of configuration information from the client side LPN uh some certificate related extensions uh and also the Sni sorry and yes and at quick level there's transport parameters which is configuration information usually related to the operation of quick and so um the encrypted client hello spec will ultimately be able to take all of those things and provide some level of protection for them there's all the debates about the availability of Sni it's potentially the case that you could still put Sni in the clear and still protect all of those those values at the same time that's that's something that I think a lot of people sort of don't really understand about the value of ech"
  },
  {
    "startTime": "01:26:01",
    "text": "is that it provides the ability to protect all of that sort of thing that's coming not yet um instead of extracting Sni from packets if we can all move to anycast I know that's like asking for ponies then you can just use the IP and like please don't look in my packets yeah but yeah if I want you to look at the SN I would like staple it on to the front and like so you could find it yeah I mean just just to follow up on opening the packets I mean we have rc8999 which is the invariance draft and that is sort of the working group's contract for the world on what will not change and what you should rely on and to even say that like few versions of Google use tls13 is is not something we're I mean I think you know someday they'll be Tails one four I would think and you know when that happens we'll use it um so all this stuff is going to change uh as as the protocol evolves it's one of the key points of quick thank you thank you anyone else in queue oh I have I have one I have one gotcha question that I had you know lined up um in case nobody came up so one of the things that I saw as a theme across all of the presentations was um we tried this and then we realized we had to do this and then we realized we had to do this like the the idea of building a pro a transport protocol on top of a security layer on top of the transport protocol that like this turned out to be super hard to do and was one of the reasons this was a really long effort um in what came out in quick version one uh in your opinion um whoever grabs the mic first what is the sort of the hackiest part of the protocol and sort of like the undone work Martin take it unless Martin wants to take it"
  },
  {
    "startTime": "01:28:04",
    "text": "I mean if you misheard happiest you can also do happiest right what's the happiest part of quick for me there's some there's some pretty happy parts we managed to get more of the protocol encrypted than I thought was possible at the outset um so that that was a happy thing uh probably the hackiest and and the part that I'm least confident in is connection migration the security model for that is a little unclear and the mechanisms that we have in place are not as thoroughly tested as as I would have would have been uh confident with at the time um the way that we defend against various tax uh is constrained to a very large degree by the nature of the network that we're dealing with and so um I'm not confident 100 that it will stand up to rigorous attempts to attack it I agree with Martin and cinnamon um I can attest that connection migration works because we've default enabled it and then quite a number of circumstances um and and so like it does actually function uh as intended uh but the attack surface uh it seems very difficult to reason about and I I am I'm sure our implementation has something that you could do that would at least be annoying to a user if not like problematic but like at the very least it's certainly not perfect um I can't think of anything else I mean there's a few decisions that got made that are annoying to me but like I wouldn't call them hacky they're just like implementation annoyances so I I'd say that uh I thought you said the happiest part of the program you can answer that question too if you want to that's what I thought he said but the hackiest part of the protocol I think that I don't know if I don't know how to think about hacking because the whole protocol is is hacky in a certain way if you depending on how you look at it I think of haki as clever so I think we"
  },
  {
    "startTime": "01:30:01",
    "text": "did a lot of things that were clever uh in the protocol but I'd say that the things that are that feel a bit fragile are both connection migration for sure but also the handshake it's it's it's robust it I think it's robust but having you know that the fact that I have to say I think is probably the argument there right so um outside of that I think the the uh happiest part of the protocol is that we actually managed to encrypt everything it's okay we got the uh packet numbers encrypted too which was which was a joy yes I've been rearing the thing on the handshake I think we decided we were done with a handshake like four years ago and then kept finding problems in corner cases and having to add a little more Machinery um so like for me the happiest thing about it is extensibility um like many of my colleagues here um spent a lot of time in TCP where it's like so hard to change anything for for various reasons and oh no but it also leads to what I'm kind of most deeply concerned about which is that and they'll probably laugh because this is my um hobby horse but like version ossification um with the things that our visit I mean the question alluded to things we could read in the client hello between that and just this very readable version field um you know people could just say well version one is fine and everything else I don't know what that is I'm gonna drop it and um you know that's something that we have to think a little harder on and come up with some solutions for to preserve that accessibility because I think eventually you can get to a place where we get really big performance Improvement we already have big performance proofs on TCP but as the internet changes quick can change in a way that the old tools can't and I think that's actually sort of like I mean we talk about this is it's a it's a work it's done but it's a work in progress unfortunately we built a thing that can be a work in progress where we don't have to come back to it 30 years later and I think that's the giant win so on that I've given myself the last"
  },
  {
    "startTime": "01:32:00",
    "text": "word because we are at time uh I would like to thank all of the presenters uh for their presentations and for the discussion and all of our audience for joining us here at 7 30 in the morning um your dedication to the internet is much appreciated uh please enjoy the rest of your week um and see you around thanks a lot of you keep you on our phone oh since it's an 18 minute walk wow it's up to you like yeah"
  }
]
