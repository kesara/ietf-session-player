[
  {
    "startTime": "00:00:05",
    "text": "and by way of proof and this is us so me I was routing ad for for while a while and I\u0027ve co-chaired a number of working groups and I\u0027m really a circuits which traffic engineering person deep down inside I\u0027ve just become the independent stream editor for my sins how many out and this is brilliant this you\u0027ve got to guess the age of hammy on illness in this photo and compare and contrast with him now this this was this was his graduation some twenty years ago Hamlin\u0027s pretty active in in some of the key working groups T\u0027s and PC in C camp and has been a specialist in in Jim PRS and management for optical network C so what we\u0027re going to do is do some tag-team going through this do some different slides each but probably interrupt each other as well so by way of a warning we can do nothing more in an hour than really skate over the surface of what traffic engineering is and what work the IETF has done will be moving pretty fast there there are individual slides in this set that we could talk about for half an hour but we won\u0027t so the intention is it gives you some pointers some IETF work to go away and look at and obviously if we leave out your favorite protocol it\u0027s either because we forgot it or we don\u0027t like it right so we\u0027ll break it down as what is traffic engineering and and why we do it have an overview of some ITF technologies some of which are quite old and then try to spend as much time Oh No traffic engineering working group chair has just come in at the back so now we\u0027re really in trouble yeah we\u0027re trying to introduce and spend quite a lot of time on some of the new techniques and architectures for for traffic engineering as far as references go there are just way too many to list what we\u0027ve tried to do is pick out on many of the slides a key RFC or draft that you should start with if an technology interests you and then at the end we have a list of relevant working groups so what it what is the point why traffic engineer it\u0027s all about getting "
  },
  {
    "startTime": "00:03:07",
    "text": "good performance out of a network and delivering additional services so that the first two bullets here are a quote from an RFC from last century 2702 is actually a requirements RFC for traffic engineering in an MPLS network but what it does is set the scene by saying this is the application of technology to measurement modeling characterization and control of traffic in the Internet to achieve specific performance objectives and it does it then goes on to not say what specific performance objectives they might be but in summary the purpose then is to allow you to provide more reliable traffic delivery offer advanced services if you\u0027re a network operator you want to offer advanced services to your customers you want to make better use of your network resources so deployed resources cost money you don\u0027t want them wasted or tied up you want to be able to get as good a use out of your network as possible you want to survive network outages but also planned maintenance and a part of all of that is making the network predictable so you can guess what\u0027s going to happen to to your customers traffic when there\u0027s a change in the network what this really means is you have to know your network you have to know the nodes and the links and how they\u0027re connected you\u0027ve got to know the capabilities of those nodes and links largely in terms of bandwidth and delay and an arbitrary metrics which are assigned to them Oh first typo you need to know traffic patterns demands and matrices you\u0027ve got to know what traffic your network is going to carry if you\u0027re going to engineer that traffic and you have to know what sort of errors what likelihood of errors and what plans you have for maintenance once you know all that then you have to control how the traffic is placed on the network and to do that you configure the network the traffic and you actually configure the management tools themselves what sort of networks are we talking about well this is the IETF so essentially we\u0027re talking about the delivery of IP packets turns out that the principles of traffic engineering apply to any network that delivers "
  },
  {
    "startTime": "00:06:07",
    "text": "commodity so I\u0027ve seen similar or identical algorithms applied to electricity networks to the management of cars on road networks to the delivery of water and the inverse delivery of sewage and so on and a sewage it\u0027s fun because I used to have a company that made a sort of traffic engineering tool using machine learning we built it for IGF protocols our first customer was a sewage company what that tells you about the ITF I don\u0027t know here we\u0027re going to focus on layer 3 and below so that\u0027s IP MPLS Ethernet and then all the transport technologies that sit underneath so it\u0027s all well it\u0027s nearly all some kind of circuit switching whether it\u0027s connection oriented or connectionless but IP is a little bit different on top all right computer science networking 101 shortest path first it\u0027s what our iGPS do it\u0027s how we generally deliver IP traffic in the network and it\u0027s great except that traffic tends to converge towards certain links and it\u0027s just a little bit hard from outside the network to know where your traffic is going for any particular flow along comes constraint based shortest path first and all this is doing is saying not only am i interested in the cost of links but I\u0027m interested in additional qualities of those links and it may be things like bandwidth availability that\u0027s the most common one and from a computational point of view it\u0027s very easy you can prune the graph before you even start so you take out all the links that don\u0027t match your criteria and then you run SPF it\u0027s easy those computes can be end-to-end and that\u0027s also easy you\u0027re you\u0027re just running a limiting factor on SPF so it all turns out to be really simple in in this picture you might want to compute a path that uses only red links to get in to end and that would be fine but you would still find that if you ran your network saying everybody\u0027s interested in only redlynx then the traffic would tend to converge "
  },
  {
    "startTime": "00:09:08",
    "text": "so this is a standard picture from traffic engineering tutorials it\u0027s it\u0027s a fish we overlay on the fish the reason why it\u0027s a fish if it\u0027s if it\u0027s sort of fish shaped graph we overlay on it some nodes and links and the links have bandwidth limitations so the green ones are 10 megabyte maybe bit the the blue ones are 7 and the yellow ones are 5 and then we place 2 demands on the network one of them is a 7 made demand and one\u0027s a 5 mega demand and they\u0027re both coming in and they\u0027re trying to get to the fishy as knows your fish have noses anyone know nobody knows your fish have noses yeah ok virtualized no nose yes so suppose the 5 make demand comes first and we and it\u0027s rooted on shortest path first well it\u0027s gonna go on the and the blue link accom help and it\u0027s going to pick the green links to go through and when that happens the 7 make demand turns up and it can\u0027t be placed clearly the network can support both demands but not if they\u0027re they arrive in the wrong order and they just handled a shortest path first so what traffic engineering is all about is understanding the set of demands you\u0027re going to have understanding your network and causing those demands to be placed in the right way through the network so if this if the 7 Meg demand can be sent the 5 mega right demand rather can be sent around the yellow links then there will be space for the 7 when it comes later so to solve that problem then you need to know the topology you need to know the status of the links are they up down paused ready to come down for maintenance what\u0027s the bandwidth of the link but more importantly what bandwidth is available and it\u0027s not been taken up by other services already other constraints that you might be interested in and and those are increasingly delay type constraints as we start to deliver 5g services but for optical networks they may be the ability to convert or not convert wavelengths and things like shared risk link groups which are the preponderance or the the likelihood of one link failing at the same time as another link fails so if you know all of those things and then you know the demands that are going to be placed on the network and any relationship between the demands for example one may be providing a backup service to another you don\u0027t want to send them down the "
  },
  {
    "startTime": "00:12:09",
    "text": "same link if you know all those things then you can do a computation that will cause you to place your traffic in the network and do clever things to make sure that you deliver services so we need tools to do this we need network management the network management can see the network and it\u0027s it can see the demands and it\u0027s responsible for working out how to place the traffic and issuing instructions to the network to configure the network so that the traffic will go the right way we need some mechanism to learn about the network learn its status and learn its topology and that\u0027s really a discovery process but for various reasons we use routing protocols to do that we need the ability to configure the network devices and that can be direct configuration or C protocols and then as the packets go through the network we may need to mark them so that we can tell which packet is meant to go which way through our network and essentially the rest of this presentation is talking about different techniques for doing those different things you don\u0027t always end up using all of those tools at the same time so these are the existing IETF tools that we will run through and then we have another section talking about the future ones so we\u0027ve got a slide or so on each of these and this is this is where references to our RCS and draft start coming in there\u0027ll be little yellow boxes down the left-hand side to give you your pointers source routing then source routing is encoding information in a packet to say which path through a network a packet should take it\u0027s essentially a series of hop identifiers either link or node addresses saying right now you\u0027ve done that hop this is the next hop to do and that can be a strict path a strict path is a full list there\u0027s never any ambiguity whenever you have a packet in your hand you can see this is the next thing I must do it requires no information to be stored in the network all of that information is placed in the packet itself and the example best example of this is ipv4 strict source routing option which enables you to put in a list of I believe 9 IP addresses "
  },
  {
    "startTime": "00:15:12",
    "text": "and this is instructive just as a side issue when ipv4 was designed it was clearly expected that the diameter of the Internet would never be more than nine hops so that was a good prediction wasn\u0027t ipv4 strict source routing option is generally not used okay it exists it\u0027s not used loose paths a loose path breaks that strict path down and says sometimes I just want to get all the way over there I don\u0027t need to fill in the gaps I\u0027ll just say next hop maybe get to them the edge of the next network so that information is still in the packet header but it relies on the network itself to fill in the gaps using normal shortest path first routing so it\u0027s it\u0027s a combination of tools then and there are two examples of that ipv4 has got the loose source routing option and ipv6 has got a routing header extension and apart from segment routing which we\u0027ll come to later neither of these options is actually used in the wild so it\u0027s a great tool it\u0027s just not used another tool is called metric tweaking and we have two graphs here they are the same topology and the same demands a green demand and a red demand trying to cross the network and in the top picture if we use shortest path first routing what we find is that both of the demands get routed across the same two links in the network these two guys and that potentially means that they\u0027re overloaded so the metric tweaking approach says well if we just go in there and change a couple of metrics in the whole network we can cause the demands to go differently through the network so this is just touched these two metrics and now the shortest path first I can see you all busily checking my mats and I think it\u0027s right they get routed differently none of the links is overloaded so in principle this is a really nice technique but you have to notice that I\u0027ve done just two demands on a simple network if you put 10,000 demands on a big network this becomes an extremely interesting computational problem you can get some very exciting unexpected consequences you go in and tweak one demand and all the traffic\u0027s suddenly goes a different way you can flap the "
  },
  {
    "startTime": "00:18:15",
    "text": "network as you install these new metrics and if you\u0027re doing that in a live network yeah I needed to change both of these but I changed one first and all the traffic went the other way and I\u0027ve just made it even worse and then I change the other one and the traffic comes back again so you would be really really careful it needs a central offline tool to do all the computation to understand the whole traffic matrix and how that\u0027s going to end up on the new network but that really is possible and it really is deployed and there some Tier one carriers who do this in their IP backbone and they still make money they haven\u0027t screwed up so it\u0027s entirely possible all right you can look at one topology one network topology and make multiple copies of logical copies of it and effectively mentally partition the network resources into multiple slices instances of that and build what we call colored graphs so what the figure does is it says look there\u0027s a a topology there and for every link we will give it a red metric and the blue metric art from my notice that one which is a colorblind blue metric second type oh I thought you reviewed these so what it means is when you\u0027ve got some traffic to inject you can make a decision I\u0027m going to call this blue traffic and it will get routed through the network on the blue graph or I\u0027m going to call this red traffic and it will go through the network on the red graph how you actually make that decision well that\u0027s a local policy choice you might make it per customer or you might just hash the the source and destination address into a bucket and say all of that traffic goes on one graph once you\u0027ve done that you color the packet you use a field in the IP header or in the MPLS header color the packet and then it will follow that graph through there through the network and the iGPS allow you to advertise the different metrics with their colors and off you go I\u0027ve seen two principal use cases for this one is providing resilience so you\u0027re able to partition your network and say if there\u0027s a failure on any link I know that the other color network the "
  },
  {
    "startTime": "00:21:17",
    "text": "other color graph will be up anyway so I\u0027ve got a backup and I\u0027ve also seen one color reserved for high priority traffic so emergency service traffic goes on the red graph normal traffic goes on the blue graph and in that case the red graph is probably highly underused inter RSVP RSVP is a signaling protocol it functions by having control packets that fly around between protocol instances and are used to describe the traffic and to Grahame their network to expect that traffic those control packets follow the the flows or they follow the same path that the flow will will follow so they ideally come before the traffic but they could actually happen once the traffic is already flowing they have the same IP addressing so they follow this exactly the same SPF path and what they do is they go out words describing the flow saying this there is traffic coming here and it needs this amount of bandwidth and then the packets are the control packets are fired back down the network saying yeah okay we have a destination we understand what\u0027s going on now reserve some bandwidths and buffers or whatever in the devices so that the the packets can be processed so what\u0027s going on here is there\u0027s an overhead of control message exchange their state needed in the network to actually reserve resources and to understand the relationship between the control messages but it\u0027s a highly adaptive to changes in the SPF so if a link goes down and all the traffic is routed a different way the control packets are also routed the different way so they everything the network quickly learns about the changes it also handles merging of flows which is not uncommon there are lots of traffic\u0027s coming from many places going to the same destination you can start aggregating RSVP is it\u0027s quite old but it\u0027s not widely deployed there are some deployments typically in enterprise or aggregation networks but we\u0027ll come on to MPLS traffic engineering in a minute and that builds on this protocol so the mpls data plane has its origins "
  },
  {
    "startTime": "00:24:24",
    "text": "in a belief that we couldn\u0027t do sufficient IP address lookup at line speed which has turned out to be a false assumption we\u0027re perfectly happy to forward IP traffic ridiculous line speeds because the silicon got much better but along the way some other uses for MPLS came along that were were pretty handy it\u0027s based on a little header that\u0027s inserted on top of the IP packet and constructs a forwarding state based on a label lookup so at every hop you look up the label and that tells you one interface to send the packet out of and put a different label on and then along it goes through the network it\u0027s creating a connection-oriented packet switching technology and that turns out to work really well for traffic engineering what MPLS traffic engineering does is use a constraint based shortest path first where the constraint is basically bandwidth find me the shortest path with sufficient bandwidth for this flow and it allows you to place traffic in quite a sophisticated way in your network to reduce the cost to make more efficient use of the bandwidth so this is a capex saving to ensure that you get the the right policies the right behavior for certain types of of traffic so again it\u0027s really nice for emergency service traffic you can find a really short path and make sure it\u0027s got higher bandwidth reserved ready for it and it\u0027s really useful for recovery or protection against failure so you can set up a backup path if there\u0027s a failure on the fault on primary path you can just shift all the traffic to the backup path the ultimate goal it turns out for impe LST is its cost saving and you can look at cost saving two ways it but principally it\u0027s it\u0027s squeezing more out of a network right the service provider has spent money deploying equipment they want to get as much traffic running through that network as predictably as possible there some protocols involved here what was done was to take the existing iGPS which are advertising and reporting on the quality of the links in "
  },
  {
    "startTime": "00:27:26",
    "text": "the network and to enhance them with a little bit of extra information to report on the information and status of the to you qualities of the link and again bandwidth is the top of that list so the IGP on its own would say link status and metric the two year extensions gives you the bandwidth and a te metric on top of that there\u0027s a signaling protocol required to go and program the nodes in the network and what we did was we took a RSVP and made some additions to it so it was traffic engineering aware and that means that those RSVP packets instead of following shortest path first they actually have an explicit path that nailed into the control messages so that that we can set up the flow for the LSP and it\u0027s interesting let\u0027s just do that okay Jim Paris is exactly the technique of where I started my ITF and I we have already been demonstrated to saying that the are so apt and OSPF T is a works and they save the class to sell ITF C is really good at doing something like generalization and makes the same philosophy applied everywhere so for every potential circuit switching technology this concept is generalized and to construct a label hierarchy on the lambdas on the label packet and also on the fibers so this one is extended only for 4 from the NP RS and the into ours is very typical we keep the OSPF p and r rsvp-te extensions and all the same time we also develop the new protocols called RMP for the coordination between the physical links and this is all distributed all the nodes how the gim PRS is working and then pass computation so will you have everything on the distributed manner then there would be a problem on the vision because considering each often node you can only have restricted vision of the whole network rather than we have a global topology information so it is request that the routing and path computation "
  },
  {
    "startTime": "00:30:27",
    "text": "function to be moved to a component or entity that can have the global issue to provide further optimization so PC is evolved in this way and now very popular and can be applied as a component or can be applied the application or a network note everywhere as long as there is a need for the past computation function so the earliest RFC 46:55 specify the functionality but it can be embedded in any routers in every router and to say the cost where you need it and the second RFC in this page effective wanted to provide a more advanced the use case that is a word to P o P use case which announced the PCE domains can be interacted with each other so in this shape there can be the interaction between the asbr and there can be remote call to stitch the result has past computation to form and end to end in cross domain pass so there are the different kind of realizations of the PDE in the architecture and historically okay for noted when we call the historically means is something like twenty years ago and here when because this is a previous technique so so this slide shows something that just three or five years ago maybe so BCE actually locates at so wherever there is a need for past computation the first the scenario would be the RS are the second scenario would be a in ms they already have this kind of functionality as but as they do not just to use the PC terminology to do that but after that when we have a PCE separated out as a dedicated server there are also special configuration like the T database like our SP database how many connections are in the whole network these are all understood on the PC server and there are also different ways to interact with other kind of PCs and the opposite to a PC is some kind of PC see the client who requests for a house computation and there is that is where the PC protocol is designed for past computation interaction and then we comes the topology aggregation because of different component have different "
  },
  {
    "startTime": "00:33:27",
    "text": "the topology informations there from the perspective of PCC is a network is URI rather simple and for the PCE rather it\u0027s a big and more complicated topology information so here the RFC 79 26 provider very typical examples for how the abstraction is done between the client layer network and the service layer network so you relieve that when you look into the operators or even look into the windows there it\u0027s very large networks but the representation of the clients idea is do really simple so here for example we have five nodes in the summer Network but all the other client connections is so only useful to say three to see three of them and you can just hide them to simplify the work of the client so the abstraction abstraction layer resource can be either node abstraction can be also link abstraction and also just show that all three to the client and given this kind of abstraction there can be a few technical about virtualization which means something you pretend you have but you really have in another shape so previous page shows an example on how to simplify while the abstraction but this one also show another kind of variation you can also multiplied your your that works it\u0027s a abstraction layer and [Music] allocate them to different work networks to satisfy the requirement for different users and this is nothing but a map between the physical ones and or what you want but what you need is just a memory how many you really have and don\u0027t just overload your network so there are different kinds of policies different kinds of algorithms working on how to efficiently virtual eyes and how to make best to use our distractions if you do it with a very abstracted manner it will actually sacrifice your efficiency because you have too little information but if you have maybe one-to-one mapping and show the whole picture then the complexity or the client is really really high so there is always a balance between the degree of virtualization and that introduced different kind of policies so one of the challenges is that the network "
  },
  {
    "startTime": "00:36:30",
    "text": "understands its topology its shared information and we now need to export that information to some controlling computation entity and we may as hamyeon has just said need to abstract that information before we export it for policy reasons for privacy reasons to give customers or customer networks of specific view so we we identified that need and we were looking for what protocol shall we do use to do that and and pick bgp and i think there were a number of reasons for that and only one of those reasons was that the vendors driving that work happened to be really interested in BGP BGP implementations are really good at klein policy so abstraction is all about policies so that\u0027s a good reason bgp is actually quite good at moving bulk data around and the export of topology is an example of moving bulk data and it also turns out that the places in the network that you want to do the export from are typically nodes that are already running BGP and lastly a feature of BGP the the root reflector allows you to send the information to multiple places without overloading the network nodes themselves so we invented link state BGP GG pls and it\u0027s a set of encoding to take information that describes links and nodes in their traffic engineering form from the network and send them out in BGP to important notes on that BGP is just a protocol that could do it there\u0027s also work now to write yang models to describe topology we have a slide on that much later and you could be using net clamp to export topology and there\u0027s also a pro proposal for using the PCE protocol so we\u0027ve seen how the PC protocol goes between nodes and a controller well maybe you could also use that to export topology so there there ends the the first lesson all of the stuff that\u0027s pretty much out there already and now we\u0027re going to come on to new tools or work-in-progress a lot of that is minor tweaks to existing protocols for example there there\u0027s work out there to add a description of link "
  },
  {
    "startTime": "00:39:30",
    "text": "latency into the iGPS so that when you collect the whole topology you can see how much latency each link is adding and I\u0027ve seen all sorts of other things like some quality of reliability of the link will be reported so lots of small tweaks and then a number of somewhat larger pieces of work that are going on that we will introduce here so the first one is improving IGP flooding and this has been talked about in the ITF for the longest time the intention is to reduce the processing load in the network as the iGPS continue to announce and maintain the network state particularly important is when there\u0027s a link failure that information has to get propagated to everybody if you can reduce the background processing of the IGP maybe you can get the network to converge faster this is interesting for traffic engineering because not all nodes in the network need to know about all te link changes so if you can reduce the flooding of that information to only the people that need to know you can make some savings it might however actually not be necessary and this is kind of work that\u0027s being discussed still because when you do a T link advertisement you\u0027re supposed to damp that advertisement anyway you don\u0027t need to announce a change in bandwidth of three bits per second you you can bump that up and say well maybe I\u0027ll only announce the change if it amounts to more than 10% of the bandwidth additionally traffic engineering state has a tendency to be fairly static so maybe there\u0027s no need on the other hand it could be interesting work it\u0027s it\u0027s one of those things that we we will play with debt net deterministic networking is a relatively new working group in the IETF it\u0027s about Billy building deterministic paths predictable paths for data it\u0027s aimed at layer to bridged and layer three routed Network segments quite often looking at a concatenation of those so you might start it in layer two do some hops there and then move into a layer 3 network and then pop back out into a layer 2 network the intention is "
  },
  {
    "startTime": "00:42:31",
    "text": "that the paths provide some predictability in terms of latency and loss and jitter so not necessarily controlling those things but knowing what the worst case might be and that is really useful in delay sensitive networking for things like video transfer especially popular for for video editing Suites probably quite useful for augmented reality unless you like falling down holes the work is being split between the IETF det networking group and I Tripoli 802 dot one their time-sensitive networking working group which is looking at the layer two parts of this it\u0027s still a little early to know where this is ending up but it looks like it\u0027s doing data plane encapsulation for NP RS and IP it\u0027s relatively simple although not not completely trivial and ends up based on tunnels with the MPLS tunnels placed with some knowledge of network behavior and well that could well be rsvp-te as you see this is the this is the first box that doesn\u0027t show in RFC but shows an internet draft segment routing segment routing is essentially a tunneling technology so the the payload data is encapsulated in a packet and it\u0027s forwarded based on information in that encapsulation header in a way that is very similar to I P source routing that is to say there\u0027s a list of hops placed in the packet header and those hops describe the route that the path that the packet must take through the network and each packet is then a free agent it goes off with its information in it it doesn\u0027t follow any programmed path in a control plane each packet contains all the information it needs to get to the end that makes it traffic engineering technology where some entity can compute a path that wants the packet to go on program that information into the packet header and off the packet goes and follows that path so if the control entity is capable of seeing the whole topology and accounting for bandwidth you can do a fairly sophisticated traffic engineering resource reservation protocol the "
  },
  {
    "startTime": "00:45:34",
    "text": "control plane all the signalling is now not needed in a network so there\u0027s great save there the routing protocol continues discovering the topology and just has a little bit of augmentation to support segment routing and segment routing works for MPLS and ipv6 and because it\u0027s the modern protocol it does not support ipv4 anyone shocked by not supporting ipv4 good okay and given this kind of technologies and then it\u0027s time to talk about how the controller is designed and what kind of techniques can be used while the controllers so PC yes previously discussed it includes functionalities on the past commutation and this is exactly one of the functionality need to be achieved by the controller interesting architecture software-defined networking so PC protocol actually provide a very mature there mature solution to the Sdn southbound interface the solution and this kind of control and computation may also be applied on a single node so the applications can be it\u0027s proposed from both NP RS non packet and IP environments so this is widely used as a controller and can be constructed as the controller hierarchies if necessary and based on this idea we have from promoted a new architecture namely as ICT and obstruction control of T networks by constructing the controller of the high Rockies so this this is actually some kind of state of art into the industry and we are implementing this kind of as the in controller hierarchy to make use of the abstraction techniques and this is very well accepted by the carriers for multi domain in Europe and from a T domain but not when they\u0027re interrupts and multi domain coordination so we separate to the different than list of the controllers and from the customer from the carrier and this from the winter so the customer early do not have much knowledge on the network and they only take care of a few boxes located in their working area so what they need is just to represent their request to the carriers by Chris parking interface we named this as a CMI and the Perea is actually is a critical component in the whole architecture because to the above we "
  },
  {
    "startTime": "00:48:34",
    "text": "need to be connected with a customer to understand their demand and to the bottom they need to interact with a winner so on the detail the network configuration so to interface all them for the customer understanding virtual service coordinating for the different customers and the coordination between multi domains for among the winners and this is all the support it applies the abstraction and the virtualization techniques so the window specific ones is actually the most complicated ones it\u0027s very challenging because the scalability of the network and there is a lot of parameters need to be configured on both the network level and the device level so currently I think about most of the winners have their all at one tutors for their own implementation but people ask you meet requesting for a standard interface to be to enable the internal friction among multiple vendors this is done on the MPI interface and carioca handle that are not you in their case so typical scenarios for a city and how the topology is discovered how the topology is abstracted the Union and this page shows an example on how this is done so if we look into the network number one domain there are actually seven point seven no scenes in the domain but to be abstract so we only use a border node to form a four point apology and report it to a higher hierarchy of the controller\u0027s so the higher on the perspective of the MDL CV it will receive the topology information free from three different domains and thus teaching them together to four a very brief topology that can be used and understand easily by the controller by the customer controllers which is a DC here and everything can be representing the ass of connectivity matrix to have local information and all the capability on the switching and the bandwidth information of the network everything is understandable from the abstraction topology and given this kind of topology people are when people are capable to to deploy their connections onto the networks so we still assume there is a request from cross domain connection and this this request comes to the carrier\u0027s first day and then it\u0027s decomposed into different winders and prospective domains it is worth noting that this can\u0027t be a kind of technology "
  },
  {
    "startTime": "00:51:34",
    "text": "specific domains saying that we have different techniques like IP like article like something together but everything is nothing but kind of decomposition as there is already a kind of standardized interface and models we can easily instruct the same which domain to complete which part of the work and this will be very helpful on the setting up the end-to-end tunnels and deploys or connections so on the different level of the interface we are having different kind of protocols so further above interface the mode is you early represented by the protocol and for the negotiation between the operator and the winders there are multiple ways including the piece AB and the rest confit on which is fully automated there are also QF Kaba and the SNMP used to for many many years and that but some kind of manual works request it and the first bone interface there can be PC protocol this is between the controller and note and a Molineux there can be GMP are so a city has good progress eitf it was first proposed to maybe use four years ago 2014 and directed to teas working group in 2015 and in 2016 we did develop two hackathon events and then promote the draft sought out in the working group and though our hackathon also evolved from transport only to IP plus transport so that is a kind of demonstration of how the entire operation can be achieved while standard models and now it\u0027s becoming an RFC so the architecture is now and what we are investigating only is a kind of young models to fit into this architecture so before for the listing of the young models we since been maybe one minute own introduced what is the young model so it\u0027s just a kind of data model that represents the information of the networking and the most special one is the young model is both human readable and the Machine possible so the the readable for human make it easy for the development developers to implement and interrupt the machine possible actually guarantee the efficiency and that that is why ITF finally choose the young language to be the language for modeling and the current is can be encoded as both XML error and JSON format and we "
  },
  {
    "startTime": "00:54:38",
    "text": "are having more and more young drafts in recent ITF meetings and it is becoming a very key component for the whole system so here we try to summarize how many young models need to be involved in the whole architectures there are many and we may still miss something don\u0027t be angry and for besides the two as a top is just as generalized the drafter for the a city and the bottom ones are absolutely drafted that describes how how the in from network information is more daughter or how\u0027s it model it\u0027s used in the whole architecture so each of the box in the car is actually a module again module and they located in separated crafts and the arrows here shows the relationship on the modules so who the the arrow points the pointed one will augmented to the the base model and this allows people to generalize a model and augment it for the technology specifically use so from the basic categories and categorization it is classified into topology Tunnel service and types and we also have the layer 0 technology to layer three technology for every type of this kind of models we\u0027re coming to and as a summer session so T traffic engineering is really a valuable tool you do not need to spend more money on your infrastructure but you get more from your network so it helps people to guarantee their quality of the delivery and it also provides some kind of bonus on their networks by carefully and efficiently use their network resource and to achieve this goal actually this is still an ongoing work and there are really a lot work in the past and in the at this moment so most of them widely deployed and we are developing more tools and techniques so there are a lot of opportunity to get to be involved here if you understand if your expert so if any layer of the technologies and want to bring such kind of models highly welcomed and this page just to show some pointers but yeah ITF for started 30 years ago when I was born so so one page should "
  },
  {
    "startTime": "00:57:39",
    "text": "not be sufficient to list all the reference but the PRC\u0027s has been listed previous slides and you can look into that one and figure out that will help you to to point to more RFC\u0027s and some interesting working groups for the existing technology promotion including the t\u0027s for the architecture of all the te technologies and NPR ste is something specially designed for NP RS secondly is something specially designed for optical switching and the PCE is everything about the pc protocol so sprint working group c is now working on the segment routing and IDR works for the BGP and the BGP Ras extension that model is a right working group to the young modeling and the corresponding protocols and error error s are provides extension to the i gps their networks all the time sensitive networking and I think that\u0027s all right time for the questions and you\u0027re welcome to provide us the feedback by doing this away perfect I did I did warn you that it was going to be a squeeze to get it in in an hour I\u0027m I have a four day course I can teach exactly the same material we\u0027re I think the next session in this room doesn\u0027t begin for 30 minutes so we\u0027ll hang around and answer any questions if you want otherwise you can go and find somewhere where the ocean dish naturally works just a native question you have introduced the PC and before you have distributed tea protocols my question is they are the totally two but two different side of the protocol why is the totally different way out the distributed way and the PC is totally centralized away is that true I yes and I think if you when you reach some advanced age like me you\u0027ve seen this swing backwards and forwards in the industry multiple times IP is very focused on being distributed Sdn is very focused on being centralized traffic engineering needs a centralized view and we are moving backwards and forwards between centralized controller with a distributed control plane or totally centralized controller with a southbound interface and there are pros and cons of "
  },
  {
    "startTime": "01:00:41",
    "text": "those for those so discovery maybe works better with a distributed control plane rapid provisioning maybe works better with a central controller single point of failure really is bad for a single central controller so that there are there are pluses and minuses and some of it is just fashion some of it is is always liking to invent something new but different operators have different use cases and different requirements further if there any possibility that we can combine these two solution you know in some specific use case or if they\u0027re already some this kind of work like the edger computing right we have the centralized control and we also have some distributed away and it can benefit each other yeah and I think one of her Mayans pictures for a CTN shows centralized controller talking down to a domain controller now whether that domain controller then uses individual southbound programming or uses a control plane in that domain nobody further up the stack knows about that or needs to know about it so different domains can do different things but still be underneath the central control architecture good runaway "
  }
]