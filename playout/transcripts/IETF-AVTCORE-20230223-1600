[
  {
    "startTime": "00:00:04",
    "text": "foreign and or whatever time of day everybody did we get any volunteers to take notes I think Bernard asked them uh we haven't we didn't get anyone to answer oh by the way Jonathan I just uploaded new slides because new slides came in so I think you want to refresh okay make sure do I have to reload to do that or is there a way to do that without uh I think you have to reload it because I just uh all right I'll be right back then the way you'll tell if you've got the new slides is this should be 32 of them now hmm what what should I see that shows this is the new ones uh you'll you'll see the um new slides starting at slide uh 20."
  },
  {
    "startTime": "00:02:01",
    "text": "uh viewport no it's just I still have title goes here there there are no slides after 20 then you have the old deck all right that's I just so ever it's in the data track do we have to do something to get it in the data all right it's been uploaded to the uh data tracker data tracker that might be in your oh it's in your browser cache probably you might have to clear the browser account okay all right let's see unless you unless you wanted to share them let's see if it's right yeah well maybe maybe uh maybe we'll try that hold on okay so let me see if I get a different oh yeah let's see [Music] oh well uh okay so we can well I'll just do the uh the share at premieres from locally okay that works yeah yeah uh I don't want the whole thing okay uh and let's see uh what do I got here I think you can just Mouse over on the bottom I don't know yeah so that's still okay so I'm I'm still showing the old one"
  },
  {
    "startTime": "00:04:01",
    "text": "and I think we're gonna have to do uh screen share okay all right that's good all right uh should be able to destroy just a single window yeah it's not uh ah there we go got the tab you found okay great all right so now we're uh yeah we're good to go okay anybody want to switch that to presentation mode or whatever yeah okay but we still need a note ticker so I see some people who are here anybody who care to volunteer it's hard to have a meeting if we don't have enough digger ideally should not be one of the people actually presenting so that's right are you willing to volunteer I mean I think he's presenting isn't it Spencer I see you unmuted I think I hear background noise but I don't hear you just be aware Spencer if you don't unmute silence will be ascent foreign"
  },
  {
    "startTime": "00:06:15",
    "text": "button on the upper right which will give you an online note taking which then other people can also look at and maybe even help you with yeah yeah I've got that open now thanks wonderful thank you so much Sam all right okay so welcome everybody to this interim uh hopefully you're all familiar with medical by now but here's the basic instructions um you'll need to unable you'll need to enable your audio manually um pressing the button at the and the thing at the top left you can see if you have audio by looking at the little it should be a little uh audio meter thingy there um you can also enable video if you want if you want us to see you um it's helpful if you want but audio edits separate from audio so you need to enable audio also uh please keep the audio video off unless you're carrying or presenting or you know commenting um and use of a headset is recommended so you don't get open uh Michael uh there's an iitf meeting that well applies um so which is basically a you uh you know the various IPR rules we you're being recorded and see follow our code of conduct that's a very brief summary of something that's it's in itself a brief summary please see the BCPS for in the privacy policy for details um not really well um you know a professional environment please behave professionally um if you feel anyone has not behaved"
  },
  {
    "startTime": "00:08:02",
    "text": "professionally um please contact uh the chairs or the ombuds team um and so this is the about the meeting we have Sam Hurst as the note taker thank you Sam um and here's our agenda we're starting with every payload format for skip which is in iesg review and green metadata RGB over quick and viewport region of interest and then wrap up next steps in any other business if it has anything else anybody has any comments on the agenda do that now otherwise we will move forward okay let's move forward I guess oh no draft status right yes um yes um a number of things published VC and cryptex both exciting vpdyne is still a misraph waiting in directly on frameworking um uh 7983 best is in is approved announcement to be sent which is there what is that instead of 80 follow-up Bernard is the author do you remember what the was there like some it was approved but they still had comments which is sort of an odd state but well I think there was an i i Anna action and maybe one or two editorial things okay yeah I don't there's nothing really the working group but worth talking about today so okay um there were some discussion positions on skip so I will be talking about that here and we're still waiting for trademarking but uh I'm always homo is here so I can AG email no please it shouldn't be very much work Mo just just please get it done so mostly so we can publish BB9"
  },
  {
    "startTime": "00:10:00",
    "text": "wow and then uh adopted um number of things which we'll be talking about today so that's cool so skip and down are you presenting yes here all right uh thanks John uh let's Dive Right In Here we had a couple of comments regarding the from the telechat group and the RS tsv art group um mainly the section that was missed we failed to put in there before the congestion control considerations so we will be adding that into a upcoming revision um uh a lot of it's again the boilerplate text from from the standard rfcs and as well as a particular sentence basically saying that skip in itself is limited as far as basically what codec is is underlying um for example you know the Melbourne 729d don't really have much you can do with that other than um you know increasing the packetization rate or something like that you know more packets more video more codec frames per packet or something like that but um so the kind of congestion control mechanisms will be kind of limited um but again it's really based on what the underlying codec can support at this point so it's kind of our position with that um we going to be renaming the section we had put in before change controller address we realized that was kind of poor choice awarding on that um so we're going to change it to skip contact information regarding specifically the um the skip 210 specification which is under the control of the NATO skip"
  },
  {
    "startTime": "00:12:00",
    "text": "working group um one of the comments one of the commenters was concerned that um that was applying to this uh to this document the the internet draft and it wasn't it was meant to emphasize that the skiff 210 specification is under control of the skip working group um there are some other minor editorial Corrections that we will be making based on some of the comments mine rewarding things here and there but also what we're looking to do is kind of also trying to shift our Focus there's a lot of there's been a lot of conversations about exactly what our RTP payload format is um and we've tried to describe it as best we can without going into too much dto only because it's it's hard it's it's unlike other RTP formats um that there's a fixed format and there's only one format and that's all there ever is Skip is a lot different in that aspect it's that there are many depending on the state of what skip is in the the stream can be different you know so it's kind of it's really hard to pin it down into one particular format which is why we've been trying to avoid doing that um I guess it's caused some confusion and some of the reviewers outside the group that um have some issues with that um again but we we want to emphasize that we want to be treated um basically like a unformatted Clear Channel kind of like what RFC 4040s defined unfortunately RSC 4040 beat our needs so we can't just use that for transporting skip that's why we're looking for our own because it doesn't do video and it doesn't um things like that so we kind of want to be able to to shift the focus on that to be"
  },
  {
    "startTime": "00:14:01",
    "text": "um you know again we'll put some revised wording in the abstract introduction saying that we want to treat this as a Clear Channel um with the intent of that network devices cannot or should not be able to try to profile what our what our traffic stream is looking looking like because it's it's so highly variable that it it would seem it's an impossible task that you'd be able to build a network filter or packet filter based on what the contents of the the skip RTP stream would be so that's kind of where we're where we're trying to focus on that um I'm not sure what the group thinks about that but we can certainly talk about that as a way forward with this um again because we've received so many comments for folks wanting to really dive into the RTP payload format which in a way again I understand that that that's the focus of but you know most typical RTP payload format rfcs do that but again I think ours is a special case because the format of our stream is not a fixed format like like the other so it's kind of where to be over that um I guess next slide there was also some talk about of this one of the reviewers about the security consideration sections specifically again the boilerplate text that refers to the RFC 7202 the reviewer felt that that was irrelevant because payload is encrypted um we disagree only because um part of what 7202 talks about is secure RTP which goes beyond just encrypting payloads um as you all know it has payload encryption plus authentication header authentication mechanisms of that as"
  },
  {
    "startTime": "00:16:01",
    "text": "well as doing secure rtcp as well so um again there's really no reason why we can't think you could also run skip over secure RTP if you really wanted to I don't think there's any technical reason why you wouldn't but so we feel that that particular security consideration sections is fine as it is um at least I mean so again for the reasons why we're stating with that so um to where that sound I guess final slide if we have one more slide on which um and again just what we're doing at this point to resolve short of you know we again we have a version five basically ready to go we were just waiting to make sure that where we were going with the changes we want to make would be satisfactory so we don't have to keep doing revision after revision at this point so um yeah so that's where we are thanks again um I think it might be helpful to show the working group the actual ballot positions because um I think uh you know a lot of things you're talking about here do make sense to do them but I don't think it's going to resolve the fundamental uh I don't think it'll resolve all the discusses because as you said they are looking you know the isg just considered the VVC document a couple of weeks ago and I think they're in the mindset that they're looking for a standard type RTP payload format document with you know sections on the RGB payload rtcp and they didn't get that so that's where I think the disconnect is but it might help to talk through the actual ballot positions and at least for us to discuss what the answer is to the because I think you obviously we know what the answer is to the ballot positions and"
  },
  {
    "startTime": "00:18:01",
    "text": "the questions and it might be simpler for you to just write some of that in the document and then you know it's all in the skip payload info right once you read that you understand all these questions are asking they didn't read it because you made it non-normative and so you're kind of in this weird position where they're missing some info and they they have they're not they don't want to read the document to get it because they want to convince themselves that it's really non-norative so anyway um I think it might help to look at the actual ballot positions and then discuss that does that make sense Jonathan um let me just try to see if we can shift yeah yeah I guess that's the advantage of the fact that you're sharing from here stop stop the existing share and share a new tab which is the ballot positions and uh uh see ah okay so here are the ballot positions can people see them yeah uh I can okay um so let's go through them so we have Francesca uh so that's the change controller one and I think so I think you've got a reasonable uh path forward on that one and then okay so Roman right so Roman says he didn't read skip 210 so uh then yeah he's looking for the format right um so he's asking are the details entirely opaque so Dan I mean once you're once you're exchanged the keys right it is entirely opaque is that is that correct yes you know once you're in in the"
  },
  {
    "startTime": "00:20:00",
    "text": "encrypted mode where you're encrypting right you know any codec you are I mean again there's the section establishment which is not necessarily in the clear it's basically clear text if you will but it's not right again referring back to 210 it's a series of messages that are defined in 210 that just that go through the whole process of establishing the keys and things like that so yeah I don't think you have to go into detail on on the key establishment process but as an example if you were to say here that once once you've reached the key establishment state uh which is where you would be once you start uh one once you reach that state then it is entirely opaque I think that would address Romans first question and then I think that can help you the other thing I think you need to say as far as the RGB format is concerned is that because it is essentially dealing with the underlying codec uh and I think you do say a little bit this but maybe not all together in one section which is that essentially the underlying codec is doing the packetization right so whatever it happens to be h.264 so the h.264 is you know figuring out where the where the now unit boundaries are and so forth handing that to the encrypter so essentially the packetization is being done by the underlying codec different right he's trying to figure out what ends up in the payload the answer is the underlying codec basically passes up the does it according to the the existing RTP format payload format document passes that up to the floor by something proprietary to to skip and that doesn't matter yes well the only part that skip plays in that Jonathan I I think I mean we don't"
  },
  {
    "startTime": "00:22:02",
    "text": "I mean they might be doing something different than what RTP payload format does and that's fine because it's not our business but but Dan I think you say that it is doing the RTP format elsewhere in the document right is that always true yeah we talk about that that it's you know it's basically using the existing you know 729 or whatever 7-Elevens things like that whatever it is that packetizer which is passing this stuff up skip just then encrypts it with the keys that it's derived so anyway that's that's the process by which the RTP payload field gets filled in the session establishment process which again which is yeah you don't have to go into that which is our sticky Wiki yeah you don't have to go into Z but the point is that once they reach key establishment State that's how it all works so anyway if you were to describe that I think that would that would address Roman's question first question and then uh uh well let me look at the second one um again that's a security consideration section again that's he's commenting on the again the boiler the boiler plug text that you know is is the standard security consideration I think that one just trying to understand what you could do there um well it appears there's tight coupling yeah there is I guess uh but the point again the point here is you reach the key establishment State and that's um really all you need to know uh with respect to RTP because there won't be any RTP exchanged well you're I guess you're exchanging the as the skip messages within RTP and once you reach key establishment state right then then after that that's the Codex only appear at that point otherwise you're"
  },
  {
    "startTime": "00:24:00",
    "text": "just taking the skip messages I mean I guess you may need to say a little bit about how you uh uh the skip message is prior to key establishment state are just essentially uh they're they're essentially fragmented into the RTP payload right with the markup bit telling you at the end of what end of a particular message is that correct um we have no we are well we aren't using the marker bid for that so um so does each message fit within a packet is that right or is it just a bit stream with its own marking just trying to have it it has it yeah it has it has its own message length and Fields in it which will tell you how big it is I mean some of them may span multiple packets because they may be bigger than the MTU side so so that's all you need to say about the the skip exchange prior to reaching key establishment state right that's the that's the part of the RTP payload that just describes how the skip messages get sent you know there's a link field that's it so that anyway I think I think those two things would address Romans comment so then we absolutely I mean do you think that I mean keeping that section in is is fine well again that's I think that's what standard that's required is an added most RTP RFC so we have that security consideration section yes keep the security consideration section I'm just saying if you were to put that stuff we just described into a just create a little RTP payload format section and just put what we just talked about in there I think that would that would give Roman what he needs to understand the payload format it's not you know what we just talked about is just a couple of paragraphs and that's it um right okay so then uh because then they would have but they would have the section they're expecting and then they would go I have it okay right right so then let's talk about uh uh okay so then we have a comment from okay"
  },
  {
    "startTime": "00:26:00",
    "text": "another comment from Roman uh okay then he's talking about secure session establishment protocol Behavior uh which I don't again you don't have to go into any more detail I don't think except what we've just talked about I think that would that would give him what he wants uh and then uh okay yeah these are just editorial right okay all right so then we have uh sarker uh uh that's RGB profile well that's uh right I mean within with most codecs right you can uh the answer would be it depends on the codec right I mean um and the architecture you're dealing with yeah the right right so but that's again skip is just encrypting whatever whatever codec you're using so I guess I guess maybe that's not clear enough that that there's this underlying codec that's going to determine that um yeah so maybe maybe a few words early on uh than just making it clear that skip is just encrypting underlying codex and so the underlying codex determine the answer to these questions that make any sense yeah and then uh Kevin is highly variable right because it's the underlying codex again what is highly variable traffic uh well again it's it's this concept that the underlying codec is it's the underlying codec right which could be audio could be could be video that's what it that's what you mean right and it's you know depending on what its state is and how it how you can adjust it or not adjust it based on yeah so maybe right right so maybe that's I think I think the thing that they're missing is just this the overall concept that we just talked about which is that this underlying code I can skip just encrypts"
  },
  {
    "startTime": "00:28:00",
    "text": "it um and yeah excuse me this is Mike Fowler speaking can you guys hear me now yes yeah okay I haven't been able to be part of this from the beginning due to technical problems within our company here um I would like to we use we use the term codec flowing it out there a lot um right the uh that underlying codec can be something as simple as a chat session too so right we need to understand it appears more like data than it does necessarily codec going across there it is just right whatever skip happens to be using it for yeah because technically skip is the codec uh from this sap point of view so yeah that that might be confusing them a little too but I I think the uh the point we're trying to get across is that there's an underlying encoder or decoder and that that's maybe a diagram would help feeding it up to skip that's encrypting it I'm not sure but that's why I think that's what I think people are stumbling on here um thank you yeah I mean you're not uh a bit the bit rate again um well you say Jitter buffer may be implemented well yeah I think I I think that might just be a matter of wording I think what you mean is it can only be implemented in a endpoint device whereas he's interpreting that as the endpoint you know the endpoint has the option of not implementing consider buffer which I think is not true right right right so yeah yeah so that's probably just an editorial thing it needs to be you know only a oh yeah I think everybody just say only an endpoint device can use fully implemented or buffer would be you know good point more or less what you want to say okay okay so I think I think between those yeah I"
  },
  {
    "startTime": "00:30:02",
    "text": "think I think we I think sarker's comments can be resolved with uh that way and let's see uh so he also asked for a link to skip spec which I think is easy to provide uh and yeah well seriously saying he's looking for the design principles and I think that's some of what we've just been talking about I don't think you need to go into skip in a in infinite detail here um I mean the way I think about it is like the in in ipsec right we have the division between Ike and the and the ipsec format this is equivalent of the iPhone 6 format so you wouldn't do a whole bunch of stuff about icon and ipsec document um but you just need to know a few things about Skip for this all to make sense um well just uh just what would you think you need to know about the skip to to implement that well it the only things are the only relevant things are the things we just talked about which is that you have this exchange of skip messages you're going to describe how they're packetized and then you reach key establishment state and that's when the the data that you I guess that you call it will start to flow exactly I think right that's really all you need to know if you want the state machine you go read the skip document but you don't really need to know that here I don't think right that was kind of the point of the the email I sent that's the truth you you don't need really to not skip 210 to open uh a payload type for Skip and let the traffic flow it has yeah I think it's you know it's it's it's more it's not so much a matter of what an implementer needs to know is what the document reviewers need to know here so basically what they need to know to understand whether we know does this make sense and because we've told them that it's that skip is informative they want to"
  },
  {
    "startTime": "00:32:01",
    "text": "know this without reading this gift document yeah I mean like when I read the skip document I understood all this within the first couple of pages and then I didn't have the question but um because we want to keep it non-nordive I just think you just have to have a little bit to just give them the framework um and you can say something like the skip document creates a state machine that basically the only things you need to know is there's this exchange of of key establishment you know messages and negotiation and then you hit the key establishment State and everything is a fake blob after that yeah throughout the session it can change you know yeah it will be yeah that's kind of yeah that kind of doesn't matter of you know just give a you know the 30 000 foot view of how skip works so people know what's going on yeah I mean you can have you know key and renegotiation or something that's that's fine again that goes back yeah application change um yeah all that can go on um yeah again I mean it's not gonna uh I don't I don't think that really a I don't think they need to you didn't you can say that that'll happen but it doesn't really affect as unless it effects my opinion the less said the better because it can it doesn't necessarily even have to go through the type of things that were originally discussed it can just start up into traffic mode in a particular mode um you don't have the messaging so it the variability on this you know one of the fears that uh that I've had in speaking with vendors of network equipment is when they first hear it is the the comment the first question out"
  },
  {
    "startTime": "00:34:01",
    "text": "of each of them phrased differently was but was how can I filter on this and and the truth is you can't it's just that variable and changing yeah well I mean I think you know I think you know 30 000 view that makes it clear that is variable and changing would thus be useful here to make make people clear to people you know that you know trying to filter on it is a Fool's errand don't try so basically just give enough description to say you know this could be at any number of different things not try to filter on it whether that could be helpful both for both for uh you know explaining to the uh I guess see what's going on and also for implementers to know don't try to be too clever well implemented will know what to do because they'll be no I mean implemented implementers of network equipment that are have to pass skip yeah I mean yeah the idea has had huge numbers of problems with people doing deep Tech and inspection and inspecting you know expecting certain things and then when the version changes you know the equipment's touch breaking stuff so it you're in good company here I mean that happens a lot we're trying to avoid um and give us an RTP Channel and we'll work through it we don't care what you do in your network devices between your RTP there and we Implement RTP and our endpoint devices to best practices but they are vendor specific each vendor is implementing their own uh product to their specifications that will work on a network and we have to be careful not to put things in here to make people believe or expect certain things out of devices when we don't control that yeah yes I think you need to make it clear you know that that make it clear that you know any number of things can happen so don't try to be too clever I think that would be useful documentation there so I I mean you know if you look through Dan for example in the quick specs there's a lot of concern about what they call"
  },
  {
    "startTime": "00:36:00",
    "text": "ossification which is a similar thing people expecting quick to look like that and then the version changes and you know they're afraid it'll be broken so you can you could include a little section uh within security considerations for example on on DPAC and inspection or or this kind of profiling just to make it clear that that fools errands well that's a good place to put it that's a very good place to put it yeah just don't do that um so anyway I think we've I think if it you know we keep to what we've just been talking about that could be a path forward to get past these discusses just basically put in the minimal amount of info that you know I need what they would get if they read skip to 10 but they don't want to so well we we try and point them to RFC 4040 I don't know if you guys discussed that or not no I'm not I mean it's a yeah I mean it's all it's it's often the case that you know it'll be different people at different times and you know the you know obviously that was an entirely different iesg at that time and sometimes they're like well just because they did it you know that's a pretty common phenomenon unfortunately but yeah it's uh it was the model of what we were looking for yeah I mean I think it's a good model but you might need more explanation than they insisted on them right just fine I think our our task was to basically create a similar like model to that that we would get through and if we start adding we have to be careful when the impact to the skip Community yeah which is diverse at all NATO Nations basically plus their partners yeah yeah I mean I understand that you don't want to create conflicting normative text or anything in the two documents but uh you know they in BBC RGB payload and many other things you basically have this little summary in the beginning that kind of tells you the features of the thing you're of the Kodak or whatever and and"
  },
  {
    "startTime": "00:38:00",
    "text": "that little section is often what orients the reader so I think that's what they're looking for all right all right okay all right so we're now on to the green metadata I think Young here okay thank you uh can you hear me yeah okay good so yes uh yeah this is the rtcp message for green metadata is proceeded to the uh WG draft so next slice please just quick rewind so the Jeff the proposed uh two rtcp message where is the temporal spatial resolution request another is the temporal spatial resolution notification next slide space so the main update in the WG draft is uh based on the command we received that the spatial temporal adaptation should in collaborate with the STP update so a new section section 6 sdp definition is added to the draft to define the rtcp FB attribute and parameters for the proposed message so this is along with the IFC 5104 so a new TSR value is added to the CCM parameters and some example is given to show how the capability exchange is used is used TSR in this case so that's the main update for the WG draft yeah that's all so any comments questions I'm trying to remember I think there are"
  },
  {
    "startTime": "00:40:02",
    "text": "comments on the list and foreign I think do you remember that Bernard I think yeah just comments received from Nokia [Music] um that it should note how the STP may be uh used in this case yeah let's see okay yeah let's see [Music] maybe I can copy the message to the chat window yeah let me I'm just reading various um [Music] I think we had a question about Nokia is I think a matter of if there was [Music] um any discussion of the if there was any um negotiation of the resolution in STP how that you know how that interacts with with these messages and I think the answer is probably it's uh you know you have to you know you know you should never go about what you guys should get in the sdp but you know this is not this is not required Dynamic to get renegotiation with the sdp as long as it's within the window sdp allows blueberry suspicion but probably you should say that there's also a question of I think for Magnus westerland during the call for adoption um"
  },
  {
    "startTime": "00:42:00",
    "text": "um I'm thinking about the format which maybe you should take a look at um this is on November 23rd yes yes other command to receive the most were addressing last meeting the only comment yeah to rename the title yeah I said yeah the question on the reflector I did not receive the preference so I just keep the okay yeah yeah I mean as an individual I would certainly be you know I think it would be clearer what it's about if we just said it was temporal spatial resolution you know because especially because the um the green metadata document from the um that the um that was that did that MPEG did it does more than just TSR it does a number of other formats also so making clear this is just TSR and the people are not familiar with MPEG that that it's uh that it's TSR I think would be helpful that's an individual opinion so if anybody else feels differently okay I think this would be yeah okay uh is that all you want any other sliders at all right any other comments on green metadata otherwise I'll move on to RTP over quick Dale did you want to say something or you just submitted foreign oh I'm sorry um no I don't want to say something it's I just need to do it to get my speakers to work oh oh you have that bug where it's only it's not working in the yeah there's a so some sometimes there's a well sometimes made it goes weird and so because they'll use"
  },
  {
    "startTime": "00:44:01",
    "text": "it two different modes and sometimes if one of the modes doesn't work that's fine all right it was presenting for RTP over quick because it's Spencer um you guys hear me okay I can hear you Spencer yeah that's unmuted which of you is presenting I will start and then I will hand over to you Spencer okay yeah uh and uh Madness is is is starting I was making sure that I could unmute when it mattered sorry okay great great yes no thank you for doing the soundtrack before you know we all stood around and said hey yes all right I think you can hear me too um yes so great um we have a short update on a new submission we post this week and then we will go over what's what we're currently discussing with Spencer and York and in the end to see what um other open issues are upcoming um for our new submission which we posted this week we rewrote the abstract and restructured introduction um the introduction has now a subsection on background and we have two new sub sections on what is in scope and what is out of scope um then we added new terminology points for congestion control and rate adaptation we will go into a bit more detail of congestion control later so this terminology parts may change but we added them for now and to have a start um then in the last interim meeting in December I think we discussed multiplexing a lot and then also on the mailing list we now added a new subsection on that topic in the draft and that subsection continues to use the flow identifiers we had before and adds more explanation on how that works then we made a couple of clarifications on the rtcp feedback packet fields that"
  },
  {
    "startTime": "00:46:02",
    "text": "we map to Quick State information in the rtcp section and we had a couple of editorial changes throughout the whole document and we added Banner Sergio and VD to the acknowledgments sections thanks to you again for providing feedback and issues um next slide so for condition control and rate adaptation are briefly mentioned we have a new terminology on that we got the feedback that the whole section on congestion control as we have it in the draft needs some more work and need some clarifications on a couple of questions for example um we obviously have the question of what kind of congestion control should be used because RTP obviously prefers low latency rate adaptation while some quick implementations may only provide by transfer optimized congestion control and then that also leads to the question which layer should actually do congestion control and how do they interact if we have congestion control at the quick layer and that's the application layer and then since we added or since we already had it before but now we made it explicit in the multiplexing section that we can have concurrent non-rtp streams we of course also have to care about congestion control between and or sharing bandwidth between non-rtp and RTP streams um then from here I think I'll let Spencer talk about what's the current state and the whole discussion if you want to join in Spencer yeah thank you Meredith so um where we are so far is that uh we've had some good discussion in GitHub and on the mailing list uh we especially appreciate uh the review that vidi did and uh her engagement with us in GitHub um"
  },
  {
    "startTime": "00:48:01",
    "text": "I've managed to convince myself that there are multiple issues in GitHub now but that those issues are not complete and may not be all that well structured which I get to say because I wrote them um there is um there are also um suggestions that we're talking about uh that are kind of contentious um and I can go into more detail about that and maybe it would be good for me to do that but just you know like number one if there are things that we are going to have to do or have to not do uh then that can constrain the rest of our conversation uh if that makes sense um so um medicine is it okay if I talk for a minute about uh the congested control controversies yeah sure uh they're not there are far too few people in line with the mics already uh so one of the things that we talk about we've talked about periodically for a while uh is disabling quick congestion control the issues I've seen with this uh over the past number of years that we've talked about it um any implementation can do anything at once at its end but there's not a defined way to tell the other end to do that uh so how do we make sure that we're talking to an a other end that will do the right thing that could be port numbers which some people don't like that could be alpn which some people don't like uh there we could just think assume the RTP sender"
  },
  {
    "startTime": "00:50:00",
    "text": "will never cause uh quick congestion control to kick in because it's interactive media and just think happy thoughts uh and there could be other ideas as well I feel like I should be looking at zulup while I'm talking um the question of what we would need to do to conform to RC 8085 because we're running over a UDP and if we're turning off quick congestion control however that happened um that it would be um did we need to figure out what our congestion our own congestion control story is because we're not running over a uh congestion control transport ation yes tell me tell me when tell me when I should stop and let people talk yeah no I'm just oh yeah yeah I guess my comment was two things one of which is that I don't think you need to negotiate congestion control right the the quick protocol as long as you conform to that let's let's send their choose congestion control mechanisms so it's not something that really needs to be negotiated and both sides don't you they don't need to use the same thing in each Direction uh and it won't cause an interrupt problem it might cause other issues but so I don't think you have to really get into negotiating it um with respect to a disabling quick congestion control I mean we've talked a lot uh in various venues about figuring out what algorithms would work um and you know if the document has recommendations that would be great but uh is there really serious discussion"
  },
  {
    "startTime": "00:52:02",
    "text": "about people just disabling it and doing away with it that that's certainly not going to work in environments like a browser right you you pretty much have to have something there um and I I don't know is it is that a serious thing that people really want to do so I was so okay so I would say three things and one of them is that Menace is also in the queue um so so he might want to uh correct me on this um I think there's two you know there's two levels of this one is we're using the language about disabling quick uh congestion control but the other question is how how do we tell how do we tell how how do all the people how do all the entities in an implementation know who is doing congestion control who is doing really adaptation and how do they know that it's that they're doing radio adaptation that is not for H3 you know not appropriate for H3 uh so if if you you know if if we could not run in you know if we could not run this over bbr that is going to uh do bandwidth probing and then uh and then lose lose uh lose packets uh as it's figuring that out that would be great you know so uh I guess the question is how do we know that we're talking to an other end that will do the right thing if I'm asking it to send something how does it know you know how does it know and whether that is get the quick level or at the RTP level or at the application Level uh that's that's a that's an interesting story is that is uh Bernard did that help"
  },
  {
    "startTime": "00:54:05",
    "text": "in the case uh in the case you just mentioned Spencer it's possible for one site to do bbr the other side to do new Reno right they can still talk to each other uh you know the draft can certainly as you mentioned you know the probiot phase will mess things up uh so that probably wouldn't be a great thing to to do but um you know they they don't have to signal each other about what they're going to do each side can can decide its own congestion control later it's not negotiated um and I I think the job of the draft is to kind of describe what is likely to lead to good results uh okay and and that's fair uh what I'm saying is I'd like for us to adopt what you just said as a thing going forward and if that's not the right answer we can argue about it on the list or in the right place um the the third thing was uh whether there was a whether we should have an uh mandatory to implement rate adaptation algorithm and I don't think we should um for some processing sort of reasons and some technical sorts of reasons but I I you know I don't know that we agree we I don't know that we agree on that um I don't know who is looking at uh work the Christian guidelma is talking about in uh mock uh like in the past week or so um for a media aware congestion controller um so it may be early to pick an algorithm now but um the other thing I thought I knew was"
  },
  {
    "startTime": "00:56:02",
    "text": "that a lot of the work for NADA and scream was making sure that they were safe against other NATA or other scream um I don't know how much work was done on them running against other congestion controllers and um that would be the kind of thing that bringing them into the ietf and having the ietf review them for publication as proposed standards or what whatever whatever it would be but just basically how do we get the ietf review of those that would justify putting them in this specification as basically a must implement again I'm not saying we should do this I'm saying this is the kind of conversations we've been having um I should be I should be not starving the queue now so um oh where did Peter go or is Peter talking Peter's unmuted but I don't see him I don't hear any audio from that Peter are you sure you have the correct microphone or whatever on your end Peter made some comments in the okay uh yeah can you hear me yes we hear you now Peter here perfect so I don't think this is a question of whether or not we're turning off uh"
  },
  {
    "startTime": "00:58:02",
    "text": "congestion control in quick um how an RTP over a quick endpoint implements the combination of quick and RTP on top of that I think is an implementation detail and really what we're asking is what is the feedback it's going to use to implement that and so the question is whether the feedback is in quick or the feedback is on top of quick and just like in the webrtc world we don't standardize which congestion control algorithm use but we do try and standardize feedback mechanisms um we should be talking about what is the feedback mechanism are we going to extend quick so that it has the time stamps necessary on uh the feedback already there so that you can do proper congestion control or are we saying uh we don't want to try and extend quick instead we're going to do it on top of quick with feedback that's embedded in streams or datagrams so I think that's the real question what how a particular implementation uses that feedback is I think up to the implementation uh Peter uh thank you thank you for that I agree with that largely with the with the thing that I'm curious about which is uh if an application so there's really you know a lot of the like I say I want to improve back on my slide I want to improve the quality of the discussions that we've been able to have by having better issues with better descriptions uh so one of the things I'd like to do is we've had a lot of conversations as if there were two levels but if an application on top of RTP is trying to do this also there's really three and we haven't had a lot of conversation that focused on all three we've had conversations that focused on two of them"
  },
  {
    "startTime": "01:00:00",
    "text": "so um that that that's that's uh yeah and especially uh taken with your your or your comments in uh zulup um that's super helpful I should also mention that uh Harold had a uh useful comment in Philip as well that um let me let me like I said let me go back to the queue and uh Jonathan um yeah so I think you know on the topic of the death control I mean I agree that you know the question of whether you have you know congestion limitation you know condition control at the RTP level I mean I think let me put it this way I think the uh decision of what to send you know basically the decision of how much you know how much is available to send has to happen at some one of the transport Stacks um which is a separate question what this end obviously has needs to be at the application Level whether that's adjusting a codex encoding rate or you know a SFU doing something um like scalability considerations or whatever I think but I think yeah that probably does need to be clear clarified the other question on the CC so my expectation though this obviously needs some experimentation is that if you're looking at a you know a standard you know boss based or cubic Cube building based congestion algorithm like neureno or cubic if you then run a low delay um professional algorithm like you know Google Cc or NADA or whatever on top of that my expectation would be that except in extreme circumstances the um the the quick the lower level algorithm would never cut in because you're keeping your cues low except in like extreme like you have a sudden drop in available bandwidth case which"
  },
  {
    "startTime": "01:02:01",
    "text": "you know um so my expectation would be that those would actually work together well um things like bbr2 as it might be more problematic um and that's not really query to be what things are how things like L for us would interact figure that in a good intuition for that yet but it might be that they would again just not interfere with each other very much um so um so but I think but there I think the issue is not so much centered again I think all these are things that can be done at one end point so the issues are then communication between the layers which you know if you're talking about things like web transport it doesn't matter for standardization though not necessarily iatf standardization otherwise it's just advice to implement or especially what kind of apis need to have available and what kind of features of your quick stack you'd have available both of those things are useful in the document but uh with different levels of normativity right um so like I said the the high order bit uh on this from my perspective was basically asking people don't go look at the issues that are out there now let us clean them up between now and ietf 116 so we can have a coherent and well-structured conversation and then like I say give us give us a hard time at 116 if what we have done is not that okay Bernard yeah I just have a general comment I've been playing around with this uh for a while and one thing I found this is where this really the rubber hits the Road Spencer is when you're sending a keyframe because your your keyframe will be you know 10 times or more the size of the P frames that you're sending um and so that's that's where you can"
  },
  {
    "startTime": "01:04:01",
    "text": "start to get yourself into trouble because you can talk about average bit rate but it really doesn't mean all that much when you have this Spike around the keyframe um right and so that's where you kind of have to make the decision you know based on your feedback what am I going to do am I going to lower my resolution or change my QP or or you know something because I've been having some loss um so that's where that's what really um becomes a problem and there's two things that you need to know it's you know there's there's the bit rate available the bottleneck estimate that's useful uh but but it is sometimes not enough information when you're talking about a keyframe because it can be so big right it's not just right it's you need to know um uh so so uh some one one thing which actually I've seen is useful is to know the size of the congestion window um and in particular what that tells you is how many round trips it's going to take to send the keyframe uh and so that actually can turn out to be a big delay parameter because it depending on how big your C window is it could take like three or four rtts just to send the keyframe because it's so big right so anyway uh you know we've been trying to work through in the w3c for example what information that that uh the application would need to know to start adjusting the encoding parameters um right and I don't we don't really have implementations so we don't know whether they're good enough but I mean Peter's been uh doing a PR on trying to try to Bubble some of that information up um so that when it comes time to do something you you'd have the information you need to decide what your best option is yeah and and and that's very so uh when I when I when I showed up and started talking to uh Madison and York"
  },
  {
    "startTime": "01:06:00",
    "text": "uh the uh this you know this is exactly the kind of thing we're talking about which is um yo basically the other thing I I Bernard tell me if you agree with this or not but it seems like we're going to have an arms race between people wanting to send more and people having better compression and you know and so the thing with the thing with what you're what you're saying about um the very biggest frames that we send uh I would not be surprised if they were getting bigger over time if you know at least at least until somebody comes up with a way to advance to that yeah because you know there's two things you can do when you get better compression right you can keep the resolution and frame rate the same or you can decide hey this is cool I can do you know irres and and do more sophisticated stuff and maybe make a better uh arbr system or whatever you're building right and so it just having better uh encoders doesn't necessarily mean you end up sending less because you could just take on more try to try to make it more sophisticated well oh yeah I I mean is it is this even a question right yeah it depends on the publication right and and as you said sometimes uh like for example for ab1 which we've been playing with um you'll see the P frames can very be very small but then if you're doing even even if you're doing high resolution you know with a talking head but then you you send the keyframe and the keyframe is going to be 10 times that size so it's going to still be pretty big you know could be 60 kilobytes or something like that yeah and and uh the Madison and New York we're doing the uh due"
  },
  {
    "startTime": "01:08:00",
    "text": "diligence and basically trying you know trying to see if uh quick congestion control was was kicking in at all on some sample traffic that they were looking at it and it wasn't um but I mean you know the question is how long can we get away with just thinking happy thoughts about that they did the right thing I'm just saying you know we need to keep an eye open the the other thing Spencer that turns out to matter in all of this is the amount of concurrency you want so for example are you sending P frames at the same time you're sending the keyframe yes and that and that's important because it some people are saying hey you're dragging out the keyframe transmission time but uh the glass to glass latency could actually be decreased by having that concurrency and the second thing that the concern concurrency does is it actually influences the the sea wind and the growth of the sea wind yeah so anyway that's just something something for people that's that's another parameter that you have to play with is the amount of concurrency and it is something for people to think about while I well we are cleaning up the issues in the in GitHub um if I could just mention a couple of uh a thing for our uh Note Taker I uh uh first uh I I will uh I will cut and paste my notes of what I meant to say uh about the congestion control controversies uh in the notes so you'll have that to work with and just in general uh it's really helpful to have the um discussion in now zulup uh as part of the notes because often that's where the real meeting is happening so uh back to you Matt uh"
  },
  {
    "startTime": "01:10:00",
    "text": "yep sure next slide please uh so after congestion control we have a couple of more issues which we group into three here um it may be a bit optimistic to say we will discuss all of them in itf116 but that's what's the plan for now to work on these after we clean up the congestion control issues um then we have two issues on quick multicast and quick multi-path which we think may be rather to be solved in a follow-up document because those are themselves the work and progress and we're not sure if we will be able to solve or say anything about these and the current version of RTP over quick yeah and then in I think in London we had a discussion about s frame and S packet um depending on what the solution there will be if there will be some more general resolution which also applies to other things outside RTP over quick we might only reference that from RTP over quick or if there won't be anything like that we may say more about this so at least for now I'd like to defer the discussion about SRAM at s packet and see if we have anything after we solved all the other issues that are listed for next steps and yeah I think that's it for an update for today any questions Spencer yeah I was just going to observe that Mattis has a great point which is uh if people want to help with this between now and 116 uh the the issues on uh slide 19 uh here are great places for people to look at and provide comments"
  },
  {
    "startTime": "01:12:02",
    "text": "and feedback and maybe even text um and uh definitely definitely uh thank you for that also um the the text and the the text in this uh scope sections you know what's in it without a scope uh especially but um section one is pretty heavily Rewritten uh and uh if people look at that and see things that they don't agree with please let us know because that's that's kind of what we're work that's kind of the scope that we think we're working with but thank you uh Spencer do you want solicit volunteers for working on some of these issues um technically technically Madness is leading the charge on these so uh on the 19 I will be back for a list of volunteers on the previous slide um in 116. okay so if there are volunteers who want to work on these that would of course be great um I think 45 was already discussed in London we don't have a final solution for that yet we will we should add some text for that but there were some details why I didn't do that yet um and then the others of course if there are volunteers I'm always happy to have feedback on this or even help people to write text and of course also on the congestion control issues which we discussed earlier"
  },
  {
    "startTime": "01:14:09",
    "text": "uh really says I can work on congestion control issues in the chat foreign volunteering but maybe people are just being shy so let's move on and it's rid of us should have unless I see you on YouTube can you talk make sure hello uh thank you can you hear me okay thank you yeah so uh thanks for accommodating your request we recently submitted the important region of Interest dependent delivery of volumetric media proposal document and thanks for accommodating for this interview meeting so uh in this uh basically I provide a brief background with a brief background on the immersive media and the motivation behind the proposal for the partial delivery of famous media and then add a few details about uh what our proposal document is actually providing can you go to the next slide all right yeah thank you so uh so there has been a substantial increase in the interest towards emerging media Technologies such as virtual reality augmented reality and other immersive experiences uh it's"
  },
  {
    "startTime": "01:16:00",
    "text": "majorly because the visual volumetric media increases the end user immersion compared to the traditional 2D videos and majorly an example for such kind of immersive media is a point clouds which basically stores a set of data points in the space are belonging to a 3D object and the number of basically the data the data required to store these Point Cloud objects is uh enormously High because we have millions of points in a dynamic Point clouds and the uh the number of bits required is pretty high so uh MPEG 3dg working group has developed a coding media codings a visual video based coding standard v3c uh video based uh visual volumetric according and we also have an uh RTP payload format for transmitting the v3c coded that uh and that was submitted into the AUD course of working working group and it's currently in the working group stage uh it's been uh provided the details in the slide and there are also plenty of extra use cases that are basically discussed in various uh standard bodies such as air conferencing shared ER conferencing experiences streaming volumetric media to Glass type Mr devices and other stuff so uh so basically the motivation behind the contribution is because the bandwidth requirement for the real-time transport of this immersive media is so high so the need for support of partial access and delivery of the MSU media content based on the user's viewport or region of interest is very important so to enable the partial access basically a volumetric video frame can be divided into a number of independently decodable tiles as we call"
  },
  {
    "startTime": "01:18:00",
    "text": "that as a 3D trial Strand and this basically all these decodable tiles are mapped into a three-dimensional subdivision of the space so as shown in the figure basically uh the the 3D regions are access align cuboids which were basically defined in the Cartesian coordinates with an anchor point and the size of the cuboid so uh a volumetric video that a volumetric image that was same that was shown in the left side has been partitioned into three spatial regions three 3D special regions uh so can you go to the next slide so obviously uh the during the real-time transmission of the MSC media the 3D special regions that we can define basically need to be transmitted to the receiving side and the receiver can request for a portion of the uh the MSU media content based on the uh region of Interest or viewport-based requests so if you take the re uh based on the region of Interest it can be a static 3D region or the receiver can request for an arbitrary 3D region and in case of uh viewport it's like based on the current user's viewport it can it connect first for a viewport based delivery of the content and uh obviously when the so when the receive when the sender receives the request or that it basically constructs based on the 3D tiles that are present in the spatial region and it constructs the actual 3D regions that needs to be transmitted transported so uh it's it's essential"
  },
  {
    "startTime": "01:20:00",
    "text": "for the sender to inform the client what are the information are to report the client that okay the region of Interest information that has been uh provided to the client so the client uses that information and basically uh when uh when the users reports are changing it can uh based on that information it can respond back and sometimes uh the 3D the MSU media content uh Point routes uh the special regions are so Dynamic so yeah that they will be changing over time and in this case also reporting this Dynamic special region information is very important from the sender to the client uh can you go can you go to the next slide so uh considering all these things so the problems that we have is like how to signal the special subdivisions that are defined and that can be used for partial access so how do we Define those uh subdivisions and how do we share it with the client is what is the problem and also when uh when a receiver knows about the special subdivisions how can it actually retrieve the content based on its viewport or region of Interest under the stuff so how how can it be achievable and also uh how the sender can inform the receiver about the changes in the spatial region learning that uh over the time so oh and basically all these cases so the required signaling between the end points to negotiate the uh the the mentioned capabilities is also uh need to be solved so to resolve all these problems we have actually proposed the document uh can you go to the next slide please so uh we have uh various proposals so uh we we proposed like rtcp feedback"
  },
  {
    "startTime": "01:22:01",
    "text": "messages so the rtcp feedback message just kind of contain a request for a static 3D region of Interest or an arbitrary special region of Interest or it can be a 3D viewport so when when a sender receives this information this feedback information from the receiver then it basically prepares the content for that particular special region or viewport and reports back that okay what this is uh the special region we are transmitting or if there is an update in the special region so I the sender basically updates the client saying that these are the dynamic 3D special regions uh present in our in the content so this information can be transmitted or using the RDP header extension for real-time transmission cases and of course all these capabilities needs to be negotiated between the sender and the receiver using the STP so the sdp signaling for static 3D regions are needs to be done and the rtcp feedback messages that were discussed earlier and the RDP header extension formats for the uh the above cases needs to be resolved so we defined all those things in our proposal document can you go to the next slide please so uh for signaling the uh the the above mentioned the information in the STP we have we defined a new media attribute uh called acre to 3D regions so it's basically informs the a number of 3D regions present in the content and what are their positions and the size of the 3D cuboid region the cuboid and other stuff and we also have some information about like okay this 3D region belongs to what portion of the immersive media content something like that and also Define the rtcp feedback messages for requesting static or"
  },
  {
    "startTime": "01:24:01",
    "text": "arbitrary or a 3D viewport all those things and also reporting the reporting a transmitted 3D region information or the RTP header extension has been defined here uh can you go to the next slide so uh I'm just providing a a an example view of the rtcp feedback messages so we are basically uh using the uh RFC that was rtcp feedback messages that were defined using the RFC 5104 so because these are like fellow uh these are like payload specific for the imsu media content so we wanted to use the payload specific feedback message payload type for this uh rtcp feedback messages and the FCA for this rtcp feedback messages for requesting a static 3D region is like on the top figure and for the arbitrary region can be in the below figure uh can you uh can you go to the next slide please [Music] and uh prtcp feedback message for requesting a viewport is provided here so basically the viewport can contain the position orientation details on the horizontal vertical fov field of views of the user and clipping sorry the near and far planes for the things okay and you go to the next slide uh for so when the center receives the request so it has to basically prepare the content and also inform the client that what what does the regions 3D regions that it has been sending so in case of like a static 3D region request it can basically accommodate like what are the number of regions how many regions it has been sending and other region IDs and in case of like a"
  },
  {
    "startTime": "01:26:01",
    "text": "arbitrary special region requests so it's basically constr the center is constructing the uh data for that specific special region so it basically uh it accumulates the number of tiles present in those special regions and finally send those Styles tile content so in that case basically it is Recon it is constructing a special edition for that particular request so we we can send uh the the sender can send the position and the size of that constructed 3D special region and uh can you can we go to the next slide foreign it is just reconstructed at that point uh so in case of dynamic 3D regions basically the center is updating all its 3D regions uh the 3D special regions so it has to be informed for the client so the client went basically uh request based on the region or are based on the viewport it will know what are the spatial regions that needs to be that so that information can be transported using the RDP header extension yeah can you go to the next slide please so these are the basic messages RTP and rtcp header extent sorry rtcp feedback messages and the hardp header extension matchages as well as the STP parameters that we defined for requesting these so we're looking for any suggestions and feedbacks and I'm not sure so I I think we can use the IDF mailing list for providing any suggestions and feedbacks and we will update the draft based on the feedbacks we get there"
  },
  {
    "startTime": "01:28:01",
    "text": "thank you are you asking for adoption at this time are you just letting us know about uh we are just letting us know about this yeah and we are actually looking for suggestions and feedback on this okay yeah I mean I think from the RDP level point of view speaking of individual here the architecture looks good I know nothing about the content of the data that's not my area expertise but sort of from the architecturally it seems you know from the you know use of header extensions feedback messages seems reasonable um but like I said I don't know whether the data that's being carried is the right thing for this Spencer um Spencer is often confused about a great many things but uh is is this ABT core RTP v3c00 [Music] no this is a uh sorry go ahead you know this is um that's the doc that's the draft that's you know we've adopted for sending the uh sending the encoded okay thank you thank you this I was yeah so uh yeah this is a different draft for requesting which value better data you want okay and thank you yeah so yeah the the RTP pellet format is a different wrap and this basically we wanted to add on top of that I mean it's like utilizing utilizing those media format format"
  },
  {
    "startTime": "01:30:01",
    "text": "so yeah I guess um yeah I think this is you know obviously useful necessary work as part of a whole uh the infrastructure you know it's a if people have any comments on it let them know but um hopefully and so is there are there multiple is this something that people are actually already looking at doing interop with and multiple people working on implementing this and want to usefully talk to each other the Yes actually uh this is a pretty much interested for uh many aspects our use cases uh uh yeah I mean uh so we that that is a work already uh going on in the MPEG and we introduced it is also basically uh interested in supporting this uh viewport-based request yeah and uh storing this basically they're storing the content to support like a partial access of the data yeah style based and region-based things yeah so yeah I mean I want questions to be whether MPEG would be a better to just Define what a viewport is and what a region is that those definitions as you know you would just send that but I mean I mean that I want to make sure that the right experts they have the right expertise to do that of those definitions to make sure that you have the coordinates and like for AR how do you answer it to the real world and things like that so uh yeah Yes Yes actually uh the viewport and other stuff is like defined in the MPEG and so we we were using those uh okay yeah so instead of fighting that and that's just kind of yeah so yeah the FBI is basically constructed based on those messages great those definitions sorry yeah yeah Mo you raised your hand yeah just wondering about the quick scan of the draft you were talking about coordinate systems that are in in meters"
  },
  {
    "startTime": "01:32:00",
    "text": "and floating Point uh is that really the model in Heath RAC the the video is described in meters and floating point in a global World coordinate system where it's not it's not traditional pixel based uh or voxel-based uh references that are independent of any real world coordinates so uh it is basically uh so when we when we make the 3D regions yes it is based on the uh points if you can see it in the first slide itself it is based on the dimensions uh but yeah when you say that viewport is basically you can also send it like uh on the real-time coordinates uh sorry in the real time um scenario where basically the uh the distance for the U current user positions and other stuff foreign so the reports can be uh requested in that fashion it just seems a little odd to me that it didn't seem very interoperable to have something some concepts of oral geometry and end users physical geometry being in these messages when the video itself is not in terms of that geometry it seems like a more inoperable who would be relative to the actual videos Dimensions natural Dimensions not not some observers physical real world dimensions which would be a difficult to interoperate with yeah so it's basically it is this it is the the transmitter Ascender basically converts those uh viewport information uh related to the uh 3D objects so it's uh so it's it's basically the sender uh translate translates that information into the coordinates from the special I mean uh and the uh the MSC media content special regions foreign"
  },
  {
    "startTime": "01:34:04",
    "text": "understand this this Nuance it doesn't seem like the right way to specify things to me because if you just look at a 2d analogy with video you know clearly this would have relevance to image or video as well if you just specify an Roi of a pixel based coordinates of images or videos that would also be useful but I would never imagine doing that from some real user observed metric I wouldn't try to understand the the viewers physical environment and and have him specify RTC feedback messages based on that physical environment I would make it relative to the actual video itself which has you know internal Dimensions it has internal dimensions of pixels or something like that that's what I thought would be a more interoperable format um okay for these black messages yeah so if you see the region of Interest so basically it is it is based on the pixels it's not based on the meters or something so the regions were well defined in the sdp uh based on the pixels and they were they were actually transmitted to the receiver and the receiver basically understands and what what kind of pixels I mean what kind of uh data it requires uh how many pixels it requires so it basically requests based on the dimensions uh so that's the thing so when when in case of viewport it is basically it is translated into those and then it will just send back like okay this is what is required this kind of this many pixels from uh so and so XYZ position to this one's XYZ position I need it and that is translated uh at the server side and then it's it basically understands reconstructs uh sorry constructs the tiles and then sends that a corresponding content as a special region so that's how the uh the understanding so if it is a region of introspect it is just a direct message"
  },
  {
    "startTime": "01:36:02",
    "text": "ah okay so maybe a little bit of words to the thing on the draft the difference between the message formats for the positions versus the viewports it wasn't clear to me it looked like they were all four uh four by uh 32-bit floats in meters in a global reference system in the global you know coordinate reference system that's what's confusing uh okay okay sorry yeah it said actually yeah thanks for the uh yeah I think it is basically for the viewport for the viewport we provided but in in case of 3D special agents it's normal it's basically the pixels yeah maybe uh I can for I can recheck and if there is anything I can upgrade it yeah yeah please check that and just you know clarify that it's injures and it's and and as your pixels relative to the video itself yeah sure yeah it's it's our regions are based on the pixels actually yeah sure thank you thanks all right um any other comments on this okay all right in that case oops after the slightest but dead filler what do we do this slide do we have any action items or or uh things to follow up on believe he's just soliciting comments for you know future development of the zeros as an individual Saban draft yeah so if you have comments follow up on the"
  },
  {
    "startTime": "01:38:01",
    "text": "list I guess in which case is that everything I think that's do any more slides uh no I think that's the end of the slides just um if there are action items on other action items on other drafts um I guess for skip we'll we'll await um your submission on of the new uh draft Daniel and Michael um and see how the isg reacts um what will probably happen is that isg members may drop their discusses or change their votes um and then we'll see what discusses are left up next week the update yeah okay great okay I think that's it for today uh we'll see you all at iqf 116. foreign have a good rest of your day everybody"
  },
  {
    "startTime": "01:40:24",
    "text": "foreign all right foreign"
  },
  {
    "startTime": "01:42:37",
    "text": "foreign foreign all right"
  }
]
