[
  {
    "startTime": "00:00:04",
    "text": "thank you that's quite helpful okay so testing audio Bernard can you hear us yes I can hear you awesome and we can hear you foreign conditions"
  },
  {
    "startTime": "00:02:18",
    "text": "all right let's get started good afternoon good morning good evening good middle of the night everyone and welcome to web transport um we are meeting today at itf151 there we go um most of you probably have seen these especially if you're here virtually it means you've figured out how to join virtually um but yeah especially if you're virtual please use the directional microphone or headphones otherwise we get bad Echo um this is the buttons with the hand allow you to join the queue it's different from the race hand button and this is how you unmute um if you're looking at the slides from the data tracker here are some useful links but the note well so for those of you who have been here all week you already know it but I want to take a second to highlight the note well in particular we the ITF has an IPR policy Sony contribution you make be it on chat at the microphone on the mailing list um triggers your responsibility with regard to patents that you need to disclose if you have any so if you're not aware of this please read it before making any contribution similarly this contains our code of conduct which ensures that we all work together nicely and professionally luckily we haven't had a problem here so let's keep it that way um if you see anything that might amount to"
  },
  {
    "startTime": "00:04:01",
    "text": "harassment or other problems please contact the chairs or the ombuds team or anyone in leadership we're all happy to help resolve these these situations uh as a reminder the this ITF has the roughly same mask policy as last time so please keep your mask on most of the time uh you can remove it briefly to eat or drink but that is not an excuse to keep it off for the entire time uh if you're in the room um if you're alone at home you do you um would we have a volunteer for note taker please I really need to cue the Jeopardy music for this one so I'm looking at some newcomers that's a great way to help out if you'd like not twisting anyone's arm but that is always much appreciated by the community the notes really don't need to be perfect if you look at those from any other meeting it's just a rough idea especially now that we have the YouTube video so is anyone willing to take notes please foreign 's like staring at their laptop instead of making eye contact wow it's okay we just won't oh thank you very much appreciate it uh if you can take them in the uh notes.itf.org there's a link from the agenda or from the slides um and anyone else if you want to jump in and help um that's much appreciated thank you and please put your name at the top so I can probably thank you in the email uh right this is our agenda uh as per is often"
  },
  {
    "startTime": "00:06:00",
    "text": "the case here at web transport we're going to do an update on what's going on at the w3c uh then discuss the um capsule design team and its impact on H2 and H3 and other H2 and H3 open issues then we have a specific topic on reliably resetting streams from Martin uh and then we'll see if we need any hums and wrap up would anyone like to bash this agenda foreign with this uh will yes let me just confirm the mic's working all right yes it is okay thank you uh happy middle of the night from California my name is Will law from Akamai I coach you at the w3c group along with yanivar Brewery from Mozilla so we have three quick slides on updates and then a slide with uh four questions for this group which I think would hopefully be the bulk of our time so just an update since we last presented July 26th we've updated our working draft to the latest revision happened on October 11th the charter is in the midst of being extended through to December 31st 23 we're actually uh just passed our Charter limit currently but we're in process so we're fine from a w3c perspective our timetable for the year we're really trying to move to candidate recommendation it requires stability in the API and also a proposed recommendation The Next Step requires two independent implementations uh Google have implemented in Chrome Mozilla are close on Firefox uh so we should reach there and hopefully within Cube one our goal is published in the uh to publication in the first half of next year Milestone status we have a candidate recommendation that's the one we track closest it has 10 issues actually"
  },
  {
    "startTime": "00:08:00",
    "text": "should have updated the slide here um eight open and five ready for PR next slide please so uh just some updates for you I won't go through them I won't read through all those texts in detail I think the one not most meaningful for this group is we added a new congestion control Constructor argument so it's an enorm it has three values default throughput and low latency so you give them an indication of what type of congestion control you would like the user agent to invoke on your behalf in the web transport connection that you're instantiating if you ask for low latency and it feels it's able to comply with that request in some way then when you query back the getter the property it will Echo back low latency but if you ask for low latency and it feels it can do nothing special for you it's going to Echo back default so you have a little bit of feedback as to if there's any ability of the user agent to accommodate your request it has been pointed out that low latency and throughput might not be antagonistic goals especially as we look at l4s and other congestion controls in that case the the very broad default would probably suffice couple of editorial changes editorial changes uh we also want to thank Granada Boba for contributing uh sample code both for a simple Echo server and then an echo server with Pub sub on video it's really been instrumental in moving forward uh some of the early work around web transport on the web well it looks like we have a question from the room okay let's pause for questions go ahead uh Jonathan Linux is that decision about whether low latency can be done"
  },
  {
    "startTime": "00:10:00",
    "text": "done before the connection is established because I'm concerned about the case where you have a congestion control algorithm that wants I'm thinking in particular of say the time stamp extension and I can use it you know and I can Implement Google congestion control if I have time stamps on the other side but I can't if I don't so which means you wouldn't know until after the connection is established whether you got the low latency congestion or not is that something you thought I believe it's yeah it's it's correct value is only after the the connections established and it's ready but there are other group members here Bernard or David even do you want to comment on that yeah I can answer on that one this is part of the Constructor in JavaScript so at least for now in Chrome we don't uh pool multiple web transport sessions and different connections so you would always have this information when creating the connection else even if we do Implement pooling you could totally say oh this connection isn't valid for this Constructor we'll create a new one so I think we we're covered because this is on the Constructor it's not something you can change later sorry no what I mean is it might depend on whether the peer supports certain quick features I see so so I think and well you can correct me if I'm wrong uh the in the Constructor you say hey I want to do this and then when you query it later it'll the value will depend on what happened during the connection setup okay yeah you can't query it immediately right you need to wait for the connection to be ready before you can then query whether it was able to comply with your congestion look uh control request so the code wouldn't literally be what you see on the screen right there Bernard is next for Q yeah yeah I think Jonathan's question may also have been about whether web transport requires some of these time stamp options and the answer is no uh I I don't know if Jonathan wants to come back and clarify that but um anyway this is just about the"
  },
  {
    "startTime": "00:12:01",
    "text": "congestion control algorithm that would be implemented uh um on the web transfer client it doesn't influence what's on the server or anything like that okay thank you next slide please so we have two main issues uh of debate the first remains around prioritization we have three issues uh up there uh and we've proposed over the last few months various ever more complicated uh apis constructs around flows of short-lip streams for example and waiting schemes uh the latest uh issue there's a comes from myself which is as a baseline maybe we should consider simply doing the minimum necessary to support mock media over quick which has a a simple relatively simple requirement for ever escalating priorities so we have not resolved this issue it's an issue of debate uh but that's on the books the second remaining large issue is the stat surface we've had prior discussion around packet arrival departure times latest rtt and ecn information uh Peter Thatcher's put forward a PR that resolves that to a single property basically expressing available throughput and there's also debate over what's the time base over over that uh value so we have other issues obviously before we can go to release but these are the two main ones next slide please and it looks like we have another question sorry I'm not watching the queue Alan yeah no no worries uh Alan from Dell meta and priority Enthusiast um I I guess I just want to and also my co-chair um Mark is in its very early days and if you were in our mock session this"
  },
  {
    "startTime": "00:14:00",
    "text": "morning you know there's still a lot of debate about what's going on with priority so if you want to wait for mock to Define what its priority scheme is going to be before you finalize your API it may take a very long time and so I think the recommendation I would make is make it whatever you do don't get over complicated and make it flexible and extensible as much as you can and from an API perspective so that you can catch whatever we land on there because we could be talking about it for a long time noted well thank you David back to you um a related question challenge Point uh uh is it would it be possible to ship like a first version of web transport without priorities and then add that later or do you think it it's important for the first version we have some difference of opinion I personally think it's important for the first version because it seems necessary to implement one of our strongest use cases which is the web conferencing use case in other words a client sending real-time audience video to a server it's working well today and uh and uh good Network conditions but it doesn't work well under poor Network conditions so we feel that we need a prior some type of prioritization scheme uh to be able to make that happen that makes sense thank you Bernard uh yeah I just wanted to clarify here you know priority isn't free um in that when you if you when you do that uh and have this strict sending then you lose concurrency um and you know for the at least for the conference in case it's I I don't agree that it's it's required to to do that um and in fact when I've done the samples um it can actually be harmful um so I guess you know I agree with Alan that it's it's something that should probably be extensible but"
  },
  {
    "startTime": "00:16:01",
    "text": "um you know I'm not really sure that it's actually absolutely required for for the first version Bernard would you be comfortable leaving it out of the first version completely uh as opposed generic and extensible that might accommodate future requirements I I would say that the goal should be what Alan said which is figuring out a way making sure that it's not precluded let me put it that way um rather than because because uh yeah um and also you know they can be there can be some experiments because I think you just have to be very careful because priority goes hand in hand you can't get but both have priority and and claim to get rid of head of line blocking right I want I want I want strict priority of my frames well if one of them retransmits then you're holding up everything in a queue so anyway it's not it's not a free lunch okay oh slides disappeared yep sorry my media code is saying unstable connection to the server I think it's reconnecting one second foreign next slide okay so here are our four questions and I'd like to take them one at a time if I read all four of them we tend to lose some of them so the first one is will web transport as defined by this group in the ietf include a send Priority mechanism which w3c user agents can then leverage directly so we can define something on the same side of user agents but is there an underlying protocol based um send Priority that it could be tied into consistently"
  },
  {
    "startTime": "00:18:03",
    "text": "Ellen Alan Ferndale yeah I I think Martin made this point a second ago in the chat which is that we the web transport protocol as it's being defined in ITF does not have a way to Signal priority over the wire and I don't think we plan to create one the API consideration is very much about the JavaScript code being able to communicate to its local implementation how it would like things to be prioritized before they leave that endpoint okay that's good thank you and that pretty much answers the second question then how will priorities be signaled consistently through intermediate relays uh I think we can take that answer to satisfy number two number three can web transport require an alpha Randle l4s friendly low latency congestion control such as Prague and this I think is probably what I was alluding to in the prior question and Bernard may want to add more color here that we feel this is necessary for a client to send uh video in a congested environment up to a server in real time uh David schenazi speaking as individual contributor so l4s is not just a congestion controller it's a concession controller and a marking system using ech and an aqm algorithm so for it to work properly you need your bottle-like bottleneck link to implement some specific kind of smart queuing and the idea is l4s uh like the the short of it is you have a shorter cue that l4s gets into but it promises not to grow the queue uh there are a lot of folks working on those and we saw like there are a lot of progress with the hackathon but they're not deployed yet and most"
  },
  {
    "startTime": "00:20:00",
    "text": "importantly um web transport being can't do requirements on anything that's not the endpoints um so additionally uh yeah on the server so I don't think requiring it from what transport is feasible it's saying that you know being able to have this is great but if you're on a network that doesn't do it you're kind of stuck Eric okay so Eric can your Apple um I think even if you take that in a slightly more narrow definition of on the endpoint and only on the endpoint can we require essentially you know non-q building flows regardless of what queuing mechanism is is happening elsewhere in the network it's still a little bit unclear as to what uh why we would actually want to be able to require that I think this kind of comes back to number two and I don't want to reopen that if we've got a nice no answer but like I think the the sentiment that I'm feeling which I think might be shared is like we're not currently planning to Signal priorities we're not currently planning to try to require that kind of congestion control um but that doesn't mean that that could never happen that means that like right now there is no clear use case for why you would need to Signal those priorities as opposed to having it be an endpoint only thing similarly for question three like I'm not seeing a huge reason that you would want to require that everybody anywhere ever doing web transport can only do Prague or something similar as opposed to Simply making it available for an implementation that needs one Kathy it wasn't mend the request is not that it's the only one that it's an available choice that could be selected by a client but I think Bernard's next in queue and this was a request directly from him so he may want to well it wasn't yeah I uh my question I guess was probably to you Eric uh have you seen implementations of quick that have"
  },
  {
    "startTime": "00:22:01",
    "text": "Prague and support l4s have I seen yes uh I'm aware of at least one um but the yeah even if it's available we're saying that you can't call it web transport if it doesn't offer Prague because I think yeah because when we were talking about hey for congestion control I want to request low latency that is very much a request and even if you have Prague on your local endpoint that does not necessarily mean that we would consider what you're getting to be low latency so I'm a little bit hesitant to say that we're gonna like say this is a thing and everybody should go off being happy and then be surprised down the line when that's not what they got yeah uh anyway uh yeah having this available I think to play with to see if it addresses the um some of the low latency use cases will would make sense but that's probably something outside of this meeting but I think the the feedback here is the answer for three is no it might be fun to experiment but we cannot require it and it cannot be relied upon uh to be present Martin's next security so I am hello um I think we've answered the priority questions adequately I think there's there's a lot of space in here for signaling but that will be very much application specific and really all that we can do with this at this layer is uh provide an API that's thankfully not a problem that the ITF has to concern themselves with there's a bunch of people who have some experience in that area who can take that to the w3c I think that's probably the cleanest way to manage that um I think on point three what we have with with the the application expressing a preference for the way in which congestion control is managed but leaving implementations and by implementations I mean browsers and"
  },
  {
    "startTime": "00:24:01",
    "text": "and servers to um to just sort of compete on the quality of the congestion control algorithms is probably the most sensible approach having a mandate for a very specific uh set of congestion controls is not sensible in my mind the last one on the little Morse sort of on the fence on but I think probably in the short term the answer is no um the time stand up timestamp option does help in some very narrow cases but at the same time it seems like you can get a long way without it so I'm going to sort of say maybe no there's a whole lot of information that a congestion controller might need in order to run something in JS but that presumes that you're willing to trust the JavaScript to run a congestion controller for you and I don't Thanks Martin uh before we go to Christian I'm going to cut the cue soon uh so if you want to comment on this topic please uh join the queue uh Christian you're next yeah I mean I'm pretty much with Smart in on this I mean certainly for position control I have a financial issue there is that the construction control is the property of the connection as a whole and a web transport is only using part of the connection so you might even have two web Transportation on the seven quick connection and what if those two web transports make different demands that'll be really weird the the other point I have on all of those is that we have here request that surface capabilities of the underlying stack"
  },
  {
    "startTime": "00:26:01",
    "text": "I am a bit concerned about the Privacy implication of those things I mean are we just increasing the fingerprinting surface I mean can we say that oh I I see that they they do support l4s and that Mercy one of those client implementation I mean we we have to analyze when we do things like that what's the Privacy impact and based on that I would say no to everything there and as for the timestamp option um I'll be more than willing to get feedback and updated thank you hey Luke from twitch um so fortunately Christian opened Pandora's Box for me but pooling um there's there's some on the previous slide you exposed some Network stats like the estimated bit rate rtt a congestion controller it doesn't really make sense when you're pulling um so it it seems like at least the JavaScript API is assuming no pooling um or is that is that true well there's no there's a there's a property to know if it's fooled or not firstly so we know that and the current implementations are only not pulled they're a dedicated connection it and it may stay that way on the website uh we'll see what the competing uh applications come up yeah a new connection right uh Jonathan X I said this in the chat but I thought I'd repeat it in response to what Martin said I think the point of the JavaScript based congestion control is not to replace the congestion controller but to provide additional congestion control specifically to avoid Q building behaviors either in the network or in your um or under our local output buffers to keep your latency low even if you have a default congestion controller I think"
  },
  {
    "startTime": "00:28:01",
    "text": "that's the point of that and I think there have been some experiments early experiments with like RTP over quick that have gotten reasonable results with that basically avoid the queue keep the cues low keep your latency low over a default congest controller yeah it wasn't that people wanted to implement congestion control and JavaScript it was to to try to improve the delivery and to do it on top of the existing digestive control that's happening under the base layer is very difficult and I think you're referencing the ADT core work that was done over bbr if I remember correctly there um so there was random in the queue between Jonathan and Peter but I'm assuming that was that you're not intending to be there or all right Peter gotcha I was gonna say roughly the same thing as uh Jonathan that we wouldn't be if we added an API which we don't currently have but if we added one for number four um it would not be trusting the JavaScript with congestion control it would just be allowing it to go lower than whatever uh built-in congestion control there is if it wants to it wouldn't be allowed to go higher necessarily so uh that's in response to Martin's comment um I I think there might be potential for doing something like that but it's something that needs to be explored and uh I don't think that the quick timestamp option is even mature enough yet to be something we can rely on so I I think while number four has potential it's not something that is mature enough uh either with the extension or to see if this uh whole idea can work to be something we can rely mandate right now thank you my computer well I was in the queue as an individual as well but everyone already said it so plus one um as chair my read of the situation is"
  },
  {
    "startTime": "00:30:03",
    "text": "I'm getting agreement in the room for no on all four points um I'm gonna reopen the cube briefly in case someone wants to disagree just so we can have that but we're not we're not going to run a formal Contessa's call because I don't think you're asking for a full liaison here but does anyone if anyone wants to disagree here's your chance we're going to spend like a couple minutes but I think otherwise it's no on all points I'd just like to say I think it's no on all points but not like a no and you should be sad for doing it more of like a no and if there's a cool use case that really needs this or like if there is a place where you do need to Signal priorities like that is an open thing so I don't think this is a no we're uninterested in what you're trying to solve it's more of a from what we're aware of for what you're trying to solve we don't think any of these things are needed but that's not a like know and stop talking yeah and I'm seeing a lot of nodding heads in the room yep I totally agree with that myself all right uh thanks will well that concludes our size thank you very much I'll relate that back to the w3c uh web transport thank you cheers and uh Eric uh let's chat about web transfer over http 2. oh is that a thing well I don't know if you do that that's probably yeah I don't know I pressed the button cool hey look at that sweet let's talk about capsules um we've been doing this for a while we got some capsules there's some more capsules we should do capsule stuff um concretely"
  },
  {
    "startTime": "00:32:02",
    "text": "we've now removed basically all of the stuff we were talking about about flow control from the capsule design team uh pull requests at this point so we've we've ripped a bunch of stuff back out we have left a very little bit of it in so we've we've left all of the stuff for H2 because none of our reordering issues occur in H2 because H2 is conveniently on top of this Knight's reliable ordered protocol um and there's a little bit of Base text for session based flow control that is still in H3 there's some settings changes that we'll talk about later and otherwise this just converts everything over to take our existing tovs and call them capsules and list them this nice new list of capsules that we have so this is now fairly minimal please actually go read and review you've seen this diagram at three ietfs by now it has not changed so let's land it and move on so we can stop looking at this diagram we're going to talk a little bit later in Victor's section about how we negotiate web transport uh just very briefly jumping in as chair uh we we did a consensus call on the list from the output of the design team that Eric just uh uh presented and didn't get any response because like you know everyone who had been involved was part of the mostly part of the team so we're gonna we're assuming consensus is we're going to merge that the the call actually ended uh three days ago and I forgot to say that so unless you want to jump up and scream now but otherwise like that's getting merged like pretty much today or whenever we get time beautiful thank you and thank you the folks who did review I know uh Martin gave multiple great rounds of reviews so thank you for that um sweet thank you chairs all right um yes negotiating web transport so we talked a little bit about this at the previous ITF"
  },
  {
    "startTime": "00:34:00",
    "text": "we have decided that we would like to independently signal support across all the different layers whereas up until the previous ITF we had said that pick the highest layer and saying settings enable web transport implies settings enable connect protocol and everything else uh some implementation experience said that's actually really really painful when you're implementing because it means that you have to teach your uh quick datagram implementation about web transport and about the extended connect protocol and everything in between and so that ends up being mildly painful especially because some of the settings don't show up until after you need to have looked at the transport parameters anyway so when you suddenly start getting in datagrams you're like hey I'm annoyed now so these are likely to become totally separate things there's a slide and an issue for it later so we can talk about it globally for H3 and H2 but we have made the same adjustments to the H2 doc as we are likely to agree to making in the H3 dock one piece of uh update from the last time we talked about this we had said that we wanted to switch completely from settings enable web transport over to settings web transport Max sessions and just if you set it to a non-zero value that implies that you enable web transport when actually writing that in with a keyboard into a document that got a little bit more thorny because settings web transport Max sessions set to a non-zero value implies that you're willing to accept an incoming session from the other side and that's a little bit weird for a client that is not allowed to open web transport sessions so this is a place where it would be nice to have input from the folks in this room um should we have both sides just continue to send enable because settings are cheap and it's not that hard and then the server sends back sessions or should we try to put in some fancy text that says that like the client just always sets it to one or something like that or try to do some weird definition of"
  },
  {
    "startTime": "00:36:00",
    "text": "having zero not mean zero anymore oh I smell a bike shed it's my favorite kind zero one's fine I'd also be okay with zero and non-zero if the client wants to tell us over how many it intends to create if it knows but that I I don't think we need two settings but zero and one's probably best for the client so the client would set it to one to indicate support for web transport and just yeah and that doesn't actually mean that anybody can create anything to you yeah okay one just you know zero and one I think is most sensible I don't think there's any need or value in the client saying a hundred I just can't imagine what client would know how many sessions it would create at the time it makes the connection right so yes true or false which is a bit weird but better than having ooh two seconds is that actually better than having two settings where you send you know one one person just sends both so so settings like cost the same either way so this is just double the cost and we're going to be sending them on every connection yeah every connection we make to any web server will have this setting in it if you make a send to we're going to be spending all of those extra bytes and we do kind of care about those bytes so once One's best thank you Victor uh I'm moderate for two settings because I currently use settings enable web transport for versionings addressed protocols so if we don't use it for that we would have to come up with some alternative way of doing that can you describe a little bit more what you mean when you say versioning you so you're not setting it to zero one you're setting it to some version number well no we have nothing to enable web transport and the current code point is for draft O2 and the way we determine"
  },
  {
    "startTime": "00:38:01",
    "text": "which version of web transport you speak is we find the highest enabled web transport route point but Victor you can do that with web Max sessions right oh sorry to jump in if both sides censored sure yeah so that's what that was The Proposal both sides send it and the client sends zero one okay and then we rotate that as an indicator for version okay I'm fine with that correct you just change the type of the setting not the value yeah Alan Alan trendel um since web transport sessions are client initiated aside from the use case Victor just mentioned uh which is a strange way to version the protocol anyway but okay um what if the client didn't have to announce support via setting and the server says I could handle one or more web transport sessions and then the client sends it one and it's like oh the client supports web transport otherwise what will you do other than just the client says I don't support it and then sends you a web transport session it's like aha I got you you get an error hey Lucas party Cloud Player I like Alan's suggestion just there um I think the the comment I was going to make was about defaults I didn't hear anything about defaults yeah and then maybe it's in this back I didn't read but like what the default would be off I suppose and unless you get the setting that says it's on and then it everything's a lot simpler so yes do that default would be zero and depending on is there anybody with a particular peer-to-peer use case that would want to be able to Signal this from both sides or would that just be its own extension that says now the client sends it and then the server can do stuff and we can move on sweet Jonathan uh yeah Jonathan I mean I'm not sure why you need to have I wouldn't having just the client send enable and the server meaning I I can"
  },
  {
    "startTime": "00:40:02",
    "text": "create my website uh transport but don't create them to me basically have a different don't have you know basically the same semantic as Max session zero but it means Max session zero but I do web transport and so basically have this can be asymmetric basically you can have enable meaning not actually enable but I'm willing to create I'm able to create them that's essentially the current meaning of settings enable way yeah but then you would say but rather than both sides send enable just to have clients undenable so we could have them both send a setting and have them send different settings but at that point what valley challenge Point like what value are you getting out of having the client send anything I mean I think um yeah I mean I guess the question is if your implementation is such that like what the web transport stuff and the HTTP 3 stuff are different parts of your stack and you need to transfer the socket over to a different part of the handle but be determined what different part of your code or even a different process or something that would be the reason I would think but right well and if that's a use case that somebody has or a need that they have like let's talk about it now before we take away your setting that was what I was up here to ask uh David was ahead of me but now I'm yeah and never mind go for it does anyone need to know and I think I can probably answer that question so does any server need to know that if a client does work transplant I think there may be cases where servers need to know but in those scenarios you can put the server on a different hostname and the client will be able to connect to them and do the magic stuff um that way rather than looking at other things I like our own suggestion if if we can make ourselves happy with the fact that the servers won't know until the connect arrives right and the server is going to get an opportunity to see that a connect came in that it did say it supported and that everybody said was totally on board now you get in this list of protocols"
  },
  {
    "startTime": "00:42:00",
    "text": "and one of them is web transport and the server says oh I guess the client supports it I now have to ask how many people running so how many people building clients would pay attention to a redirect in response to that connect we might um David schenazi I I was initially going to say that the client should send it because like this modifies HTTP semantics and it tells the server that yes you can send sort of initiated bi-directional streams and that's how we generally do that in HTTP but then I remembered that I really don't care either way works um and Victor's visioning thing from the client can be done as a header as well all of these work so now with my chair head on I'm going to cut the cue after Mike and Luke so we don't spend the whole time on this bike shed but go ahead oh Luca sneaky I will be very brief and just say it does not seem like there's any actual information here that the server needs to receive from the client the client needs to receive the number of sessions and anything other than zero implies everything the client needs to know so let's just have one setting set in One Direction and be done all right Luke uh Fringe use case but worth saying my server is only web transport I don't want to serve HTTP 3 so if quick connects to me and it doesn't support web transport I want to close the connections that it's not just wasting resources but it's kind of Fringe thank you yeah I think that's the kind of like hey I have a legitimate reason I need this to be sent so if those exist Now's the Time hey Lucas Pottery just a quick one um the what was I forgot what was it gonna say damn oh uh quite often we think of settings as the only way to negotiate a semantic change in HP 203"
  },
  {
    "startTime": "00:44:01",
    "text": "the spec doesn't require that it can be whatever else we would come up with so that would fit potentially this as well thanks um as chair the sense from the room that I'm getting is there are some opinions but no one feels overly strongly and there seems to be a sense of the room for one setting only sent from the server uh can someone not live with that crickets uh Victor in the chat objects to can you come to the mic Victor then as I said the versioning sync cannot be done via the only server thing because you have to understand which version you speak so for instance between regular 2 and chapter four we decided that we're uh Banning uh on bi-directional streams where require web transport uh session frame to be in the very front and that would be a breaking wire change and we have to know on client and server have an agreement on which version is actively being used uh clarifying question Victor can't you do that with a header on the request no because by that time because that is because one the header per request not per connection so you have to like cache it once and two you can receive that bi-directional stream before you say it receives the open connect because there is asynchronous so by the time you just receive web transport data you might not see the header in the first place so so I think we have two concrete options here option"
  },
  {
    "startTime": "00:46:00",
    "text": "one is the server sends settings web transport Max sessions it can you can encode a version in the type of the thing that it sends there if you like and when the client sends extended connect you can always mint a draft specific protocol token just like we did with alpn for H3 and things like that right and that arrives with the extended connect there's no asynchrony happening there there's no reordering possible the other concrete option is we say both sides send Max sessions and we just Define one from a client to be a sentinel value that means I support it but I'm not willing to accept any incoming web transport sessions foreign it sounds like we were leaning towards the first option there not the second option there does that work for you Victor can you live with that I'm I'm sorry could you repeat that again yes so option one the server sends settings web transport Max sessions to some non-zero value and the type of that transport of that setting encodes your version and when the client sends extended connect you can always mint a new protocol uh entry so right now we just call it web transport but you could always call it web transport-02 or however you want to Signal support for different draft versions of things just like we did with alpn for H3 um your second option is settings web transport Max sessions is sent by both sides you've encoded the version in the type of that setting and we Define one for the client to be a sentinel that means that I'm not accepting any web transport sessions at all but I do support web transport and you can then infer the version from the type of the setting that was sent oh yeah and so if we would like to go with the first"
  },
  {
    "startTime": "00:48:00",
    "text": "option can you live with that over the second the first option uh I'm thinking about the ways of in what currently we have works and I have serious doubts okay we can always take that to the list too I think it would be fine for us to to ask for feedback that's uh Martin you know I just I just realized that with with the first design the server can advertise support for multiple versions now clients can exercise whichever one they choose simply by indicating with the version in the in the header field the challenge with the other design is that if the client can't support multiple versions you don't have any version negotiation available because the client if the client says oh I support draft 15 and draft 16. then when it exercises that option later there's no way of knowing which one it concretely is using so I'm uh I'm like even stronger on option one now to answer that just we we made that work for HTTP datagrams were we said in the draft if multiple versions are supported the latest one is what is agreed on so you can make that work you can sort of make it work okay yeah yeah but even still I'm still send nothing ever from the client said the bits Victor I I was about to make the thing no more too this is the the way when HTTP datagrams work is you pick some X version yeah so given all the conversation Victor uh can you live with this and or should we take this to the list"
  },
  {
    "startTime": "00:50:00",
    "text": "uh I think we should take it to the list I can imagine us living with this long term as in when we ship the final version with the laser client-side setting all right let's take it to the list thanks all right moving right along flow control in H2 um this is way easier than flow control in H3 we have a setting it limits the number of sessions we just spent a good long time talking about it Follow That Thing respect to the Limit don't screw it up that is all right so we are now in a place where we have uh read and reviewed some of these PRS so thank you folks who did that sounds like we're going to send a thing closing our consensus call on that at which point we will just merge things yep well um and please if you know I I see Victor Martin keep keep the constant the conversation going in the chat if you can resolve it there otherwise we can do it on the list let's not please face plant on the settings like this is the silliest part of the protocol uh oh for next time no close the slide they've added a button so where I can reclaim control now yeah no worries anyway um cool then oh right no Victor's not going to continue the conversation he's going to be up here presenting um let me share pre-loaded slides share yes you can send multiple settings in H3 uh uh and Victor can you request a slight transfer or whatever that's called nope too far all right you're muted but you should have control of the slides foreign still muted"
  },
  {
    "startTime": "00:52:02",
    "text": "say something in Morse code mute it now all right now we can hear you uh okay so uh I'm doing the presentation for web transfer to overage free open issues there are plenty of those but most of those are actually either addressed by the previous presentation uh IE is a design team output or they're addressed by the presentation that Martin will make later so first of all the update on what actually got merged which is one issue uh is uh that we have a clarification text on that when exactly you can open new streams and datagrams and the client can basically open them as soon as it opens extended connect uh now let's discuss open issues there are three of them and one of them I think is easy and two musem or hard so the first issue that I think is relatively easy is that we have a proposal is that currently we have settings enable web transport or settings Max web transport sessions uh that tells you that currently tells you that everything all depending features are enabled and the proposal is that it should no longer do that and that we explicitly acquire you to obtain into supporting a capsules be quick datagrams C HTTP datagrams and de extended connect and you need all of those in order explicitly negotiated in order for web transfer to work uh and uh I believe this is a correct proposal and we should adapt it the only"
  },
  {
    "startTime": "00:54:01",
    "text": "reason this used to not work this way is that the settings extended connect was not even defined for HTTP free when the original license draft was written and now that it's written uh I believe we should uh adopt this proposal do people have any opinions or comments on this on Alan frindell um so I actually got web transport uh uh implementation working uh this week with chrome and uh it was a huge pain to figure out why Chrome did not like my server for a long time and I think the thing I don't like about this proposal is that there's four different ways you can screw up and fail your handshake and it might be easier if there was just like yes I want to do web transport damn it uh Alan uh my answer to this is the uh please file a bug for better developer tooling uh for Chrome because this is definitely something I have uh have that has frustrated me in the past and I don't think we can get rid of all of this issues so we definitely need more informative uh tooling to tell you why your server got rejected uh uh and it's just a matter of writing with the code Eric so is is that a case where it is just a developer tooling thing or is that actually going to be a huge pain for everybody because I would be strongly in favor of not having to teach all my different layers about each other quite as explicitly here so the the annoyance in debugging is is annoying but doesn't imply a ton of code writing"
  },
  {
    "startTime": "00:56:02",
    "text": "uh just to reply I I think maybe the it makes quick datagrams are a totally different layer and I didn't like having it for HP dreams I think extended connect was kind of the one that felt like why do I have to opt into this but anyway sorry uh Jonathan Lennox I think um listing them all explicitly is uh probably a good idea because otherwise in five years we're going to be in a situation where you know okay you send you know if you want these 15 features and this one implies these four but not these other three and it'll be a complete mess rather than just let's list them all from the start that said I feel like there should be clear Direction on what to do if somebody gives you a nonsensical response like you know I support web transport but not extended connect or something like that so um or you know HTTP datagrams are not quick datagrams um there should be a clear indication of just you know if so somebody has something nonsensical just tear it down and consider it a complete failure don't try to continue and Jonathan either medeco glitch or you cut in front of Mike and Lucas so no no big deal just for next time go ahead Mike um well someone to repeat what uh what he just said that if you try to do web transport without having turned on one of these features it depends on it should throw an error that says I don't have my required dependencies and that will help with debugging um I will point out that technically quick datagrams is not a hard dependency for HTTP datagrams because we have a datagram capsule I wouldn't but we added the requirement that it'd be in there um so it's not quite nonsensical it's just prohibited but yes you should always explicitly negotiate the features that you need and then fail if the ones you need are not present don't try to imply things because that way life's Madness"
  },
  {
    "startTime": "00:58:03",
    "text": "thank you Lucas hello Lucas Pardo um yeah the comment sorry I just got invoked to say devtooling's really awful all of this layer are very pessimistic it's going to get better I want to put energy into it and try and work with the community to do it but I wouldn't hold my breath on that happening um it's going to make web transport interrupt difficult for us the best bet we can get is probably seeing like uh 400 or 500 response to a connect UDP coming back um but anything else is like going to be super tricky but we should do a lot better uh David schenazi speaking as individual um yeah I'm very strongly in favor of using the setting for every feature that we use because like we have points in our stack that uh let's say validate the pseudo headers and like I'd rather like not teach web transport to Parts that'll need to personally so now speaking as chair uh Alan you sound in the rough do you can you live with this all right cool uh I'll repeat in this in the mic for anyone remote uh Alan says he's fine with it so I think we we have rough consensus here thanks for thanks for thanks for that Alan appreciate it all right let's move on to the next issue which is a bit more complicated uh what do we do with HTTP redirects so during the last meeting we all agree that we definitely should have either a must support redirect or must not support redirect because anything else is just highly unpleasant developer experience and everyone was uh leaning and it's a general consensuses or MC was"
  },
  {
    "startTime": "01:00:01",
    "text": "leaning towards supporting them and requiring their support uh and I went and I asked Adam rice who was the reason I originally uh uh we did not support toys RX is what are the uh pitfalls with that and he made a reply which is you can read on the issue tracker with one of the potential attack on redirects but so the more I think about it the more I said I come to conclusions that redirects have a lot of really unpleasant semantic edge cases and a lot of them revolve around the fact that in order to send the redirect to a web transport resource you need to uh user connections that supports web transferred but redirect is something that a server that either supports or does not support where transport can reply with so what happens if you get a redirect for a web transport resource and it redirects you to somewhere where this not support web transport or can you consist what should we handle redirects and attempt to fetch for those redirects in cases when uh we are on the connections that does not support web transport in the first place and then the second issue is okay we allow technically currently allow client to start sending streams uh when the before getting reply from the server and this has the obvious problem of okay we sent some data on the streams to the server and now we got redirected what happens to those streams and that is the second problem we have to deal with this so my personal current inclination is that we should not support redirects because we will have to deal with all of"
  },
  {
    "startTime": "01:02:00",
    "text": "those and I would like to know what people in the room think about this Market yeah I think we should um support them I don't I think that the first two are very very easy if you ever hit a a server that doesn't support web transport don't send it a request requesting web transport that's that's just a final condition that's just another one of the things on the checklist that um Alan was talking about before that's difficult to get right but you only really have to get it right once item potency is interesting um which sort of led me to ask the question so you're connecting and you're sending I I don't know what are you sending on this on this thing you're sending stream data what's the stream limit on the other end do we have a default can we can we guarantee that you'll have a bi-directional stream to create and send on uh you don't know especially not in the H2 case anyway maybe in the H3 case because you're just taking from a global pool that you already know the size of but I'm tending towards the conclusion here that um that is difficult and um I'm not sure what to do with it if it's just stuff that's sent in the payload of the request then it's relatively straightforward and I think that's all you're allowed to really do before you get confirmation that something is done so maybe just replay it is that right Eric's nodding I think if we if we make the semantics of a 3xx in a response that none of the payload of this request was was processed if you if you're doing a connect and you've got to redirect then then you can just take that those bytes and send them on the next one it'll be fine um if you have anything other than that I think this is really really difficult um I'm not actually sure how we're going to do this for H2 the more I think I think about it you can do some bookkeeping but"
  },
  {
    "startTime": "01:04:01",
    "text": "you won't be able to do any stream data because our default stream limits are zero aren't they yeah hey Alex tranovski Google um I'm reminded of some of the zero cost extensibility questions that we had in the mass working group and I feel like this is sort of similar here where I seem to recall we had a similar discussion about you know what happens if you want to send a capsule that may not be supported on a server opportunistically and that sort of feels like the same thing here with the API issues question so if we want to support redirects I feel like the answer here if you're definitely going with sending data over datagrams is that you just have to assume that anything that you sent prior to getting a confirmation that the extended connect succeeded just like as we did with the underlying mask stuff that you might have to retransmit it so in this case I feel that what Martin was saying here around item potency is very clearly solved that you know you get the redirect you assume it all that data was not processed so unless I'm mistaken I think we can fairly easily support redirects by simply saying that any data must not be processed if you send the redirect I'm seeing nods in the room so regarding flow control so what happens if your flow control window decreases between redirects yes sir Victor that's a fair question uh this is the case where you you attempt on on one connection and you've got a nice fat flow control window and you send you know a megabyte of stuff um not that you should be doing that but let's say you manage that and you get a"
  },
  {
    "startTime": "01:06:00",
    "text": "redirect and then the next connection only has like 10K what do you do with the the extra stuff that you can't send I think there's kind of an unavoidable uh sort of gotcha in terms of redirect processing in that the client has to remember everything that sent and then spend whatever time necessary to uh ensure that it gets sent again which means well it's funny it's not only about bytes but also about opening streams yeah so what streams are you opening again so you start imagine you start by opening free by direction oh but you need directional streams and then you get redirected and you get redirected to a server you connect to the server and the server says you can only send to streams at the time I see yeah so it turns out that I don't think the client can open up any streams because the stream limit is zero we don't specify the default well the the employee default is a quick one right which is zero it's well that's for web transport over HTTP 2 right no it has to be so so Alan just said off off Mike well it has to be at least three streams I'm like no that's just a requirement if you want to use http 3. we're talking about this right here which we're just talking about um all right within the context of this one that's hard yeah I would agree at the same time I do think the what happens after I'm redirected is not massively different from what I would have done if I went there originally so like if I if the"
  },
  {
    "startTime": "01:08:01",
    "text": "thing that I'm running requires me to have three streams open and I would have gone to a server that says no you can only have two like this is the same problem right so the fact that I was able to have to pack my connect with additional data that tries to open three is not that's not really the fault like that's not a problem related to redirects that's just a generic problem in general and I think right now it's pretty underspecified so I think we need to do a little bit of writing too so it's list for dedicated web transport or for HTTP free you can open as many streams as the quick transport settings allow you and the reason I say opening streams specifically is that buffering data is something you can do transparently but with opening streams or API explicitly gives you a promise that is not resolved until the stream is actually opened doesn't that apply in the same case though if if I try to connect to a web transport server that in H3 says hey you can't have that many streams and I needed that many streams aren't I similarly stuck like it doesn't matter whether I got redirected there or not I'm still stuck uh no because as far as I remember you can but you learn the server Max open streams initial before you get the server reply that's a window in which you can open those trends yeah it just still doesn't mean that the thing I was trying to do with that many streams is going to work why not"
  },
  {
    "startTime": "01:10:04",
    "text": "so rather than try to come up with a solution to this problem here I think we need to take this offline and have a bit of a discussion about what it is that we're doing here I think Victor's right this is this is much more difficult I don't like the dedicated connection thing um but that's maybe something we have to Grapple with uh maybe we need a new setting for that because in in the in the pooled scenario maybe you don't want clients just opening up new web transport streams for sessions that haven't been approved yet and in the in the dedicated connection case well maybe it's okay to do that so that's something that I think we're going to have to think about a little bit more carefully because that changes the disposition toward this particular um question quite a bit Martin isn't that just like the flow control discussion that the design team had that's what I was going to say yeah so this is a this is essentially the box of things that you open up when you start trying to do that kind of flow control and things like that so I think I mean I'm totally game to go try to figure that out offline but I don't think we're going to answer it in the next half an hour yeah but just speaking as chair here the uh I think the output of the design team that we declared because sessas on was like the flow control for that part is oh right now we we we punted it out that's true so that we didn't reach counter consensus on it so that's still like a nice landmine that we haven't decided how we want to step on ah thank you um so should we put a pin in redirects until we've solved flow control uh I'm not sure flow control specifically we definitely I think it's"
  },
  {
    "startTime": "01:12:01",
    "text": "better to take it offline because there it's very clear that there are a lot it sounds like there are unsolved design issues here and we should either solve them or design decide that they're not worth solving or should not be solved uh but it doesn't sound like we're arriving to a new conclusion that's submitting so I suggest we move to the next sounds good okay so the third issue which is actually three issues which talk about truffle is the same topic but different aspects of it or maybe the same aspect of it is that uh the we have for unidirectional streams in web transport we just have a unidirectional strain type and we use that and we put the session ID and then we it just works for bi-directional streams or no stream types in HTTP free so we made a special frame that just says everything else is on this stream is web transport and we can make that frame it's legal because we use a setting to negotiate web transport support meaning that we can alter the protocol and then the question was well can you put anything before that and during the last ATF meeting we roughly agreed that the answer to that question is no because we want to have consistency between what we do with bi-directional streams and unidirectional streams so that is as far this is I think we have agreement on that uh and Lucas and Lucas please correct me because I am trying to"
  },
  {
    "startTime": "01:14:01",
    "text": "vaguely restate what you said in the issue slash pull request uh suggests that instead of doing that we should just Define bi-directional uh stream types uh and uh as an extension to http free uh and uh there is a pull request to do this and I will let Lucas advocate for it because my current opinion on it roughly this has the same effects on the wire so I don't think this is particularly worth it but Lucas please so I I had a clarification question but I think that's a great segue maybe Lucas can answer it my understanding and correct me if my arm wrong is this doesn't change the wire format in the sense that the bi-directional stream will always start with a variant that is an identifier and that identifier will either be in the streams in a registry stream type sign a registry or any frame types I never actually that's that's what we're debating is which registry but it doesn't change the what we're actually sending is that correct I'm asking you Lucas okay uh Lucas party Cloud Player so I I want to apologize for dropping the ball on this PR like I created after the discussion at the last ITF or the one before that one I can't remember um but the concern I had here isn't so much like what registry it lives in I think if I'm over a call recall correctly it was more that I didn't like the idea that we have like hp3 frames that always look like this except in this case it's a special thing and it's very different and this changes how you would approach frame parsing if you wrote a generic H3 Framing and sleep machine layer um if instead you kind of say when we're"
  },
  {
    "startTime": "01:16:04",
    "text": "using web transport or an extension of this type there is a way to convert the semantics of hb3 such that biddy streams no longer become request streams and this is a way to do that the PR's in web transport I think it's into a section of the document that's like maybe we don't want to do this in web transport um and that maybe this is something we take to the HB working group and say we designed hb3 for for this use case and we're trying to do other things with it and this is an approach so there were some good comments that you made on that PR and some stuff has shifted on I haven't had the time to go back and comment them um it's not something I want to give up on yet because I haven't had the time to revisit it if everyone hates it that's okay but I haven't I don't know um I just don't like the current design is my issue and if I'm in the rough then so be it but I don't think we've had enough discussion around this yet oh just to double check is there any actual wire difference between what's proposed in your PR and but I don't believe it's a wide difference is a very nuanced kind of bike shed it's a tiny it's a Kitty bike chat um yeah like I've not I'm just not in the right state to for phrase that Nuance correctly sorry um I I asked chair I'll jump in and try to phrase the nuance and please jump in and correct me Lucas if you think I'm doing it wrong so in HTTP 3 uh well quick has server initiated bi-directional streams in HTTP it says You must not send them and if you receive them explode so we know no one's sending them but now we have magical super duper setting so we know"
  },
  {
    "startTime": "01:18:01",
    "text": "that we're in a different mode and that setting tells you what you're allowed to send on this stream and how you're supposed to parse it so we get to decide and we have two options here uh one is you send so you send frames on HTTP streams uh sorry on survey issue bi-directional streams in HTTP three that I have the white transport setting that's a mouthful um and the other is you send a stream type and I mean as I'm saying this out loud I'm realizing that this might be outside the purview of this working group um but I think that's the color of the bike shed is do we want it to be frame types and have the the award that Luca described where we have a frame type that doesn't have a length or do we want stream types I hope I didn't say them completely backwards every time um all right that's an economy let's discuss I'm going to time box it so we don't face plant on it too much but let's have a let's have a discussion yeah so thanks uh summary um it's reminding me some stuff which is good uh the the other problem I had with this is like if you're building a a stream parser like this and yes say it's a client request stream this is the one we're concerned about not the server but these stream known case um so the client request stream uh you have frames and if you don't understand frames extension frames you ignore them what we're saying is we want to change some of that Machinery too such that when you receive this Frame um it seems the property that we want is that web transport starts and converts the stream immediately into the mode that it needs but by using a frame what you end up with is effectively an infinite amount of stuff that could appear before that web transport stream frame um and that just seems completely pointless and so you're making like"
  },
  {
    "startTime": "01:20:00",
    "text": "another exception for behavior for web transport streams but I don't think we need I think we should just say if you're using web transport and you get the stream open and it has to start with this byte otherwise there's something Focus going on it's not it's no longer a framed stream it's something else which is the property that we want if I understand yeah so I'm not all that enthusiastic about the the way in which this is working out because we have bi-directional and unidirectional streams and the client initiative initiated bi-directional streams have to have frames and in order to for us to to do this we have to choose a thing that sits the front of that stream that looks like a frame or at least uses a number from um the the space that isn't like we have to register a frame type in order to avoid colliding there right so I don't want to have I don't want to have us fix the asymmetry between unidirectional streams and bi-directional streams only to create this problem with the others so I think we're probably in a situation where unidirectional and bi-directional is the is the cleave that we're looking for and then I think we have uh frames now if we want to avoid putting a zero length thing or like this weird thing without a length we can just put a zero there or we can just say look it is what it is um that's that's all fine um we can also Define a rule that says this has to be the first frame that's on that stream if we want to go that way we've done that for for other things I think that's true of settings in H3 already um what I don't want to have happen is we we lose the um the ability to distinguish our streams from their streams uh when they when they share the connection so I'm like"
  },
  {
    "startTime": "01:22:02",
    "text": "need a handle there I would prefer to use the frame parser to do frame parsing um on like the bi-directional streams which potentially means it's wasting a bite for a zero length I think zero length is easier than a than a whatever other options we have for that field um because most frame parsers will be type length something and um knowing that we have type length of zero and nothing following it makes those stream passes very much more easy well we've got a session ID um as well of course um so I'm actually kind of okay with the current design with with maybe a few tweaks I'm gonna cut the cue soon so if you wanna talk about this get in line now okay meet Echo made this too tall it's okay yeah I just couldn't have said anything any other complaints the magic words that summoned people okay I shouldn't have done that uh Alan friendel okay so um I've implemented uh this as a frame and I've put it in my frame parser and it's gross because it has to be the first frame it doesn't have a length it completely changes all stream all frame parsing after that so I don't think you if you're implementing this I don't think you actually want to implement it inside your frame parser I think you want to do is treat it like a stream tech so before you pick before you even instantiate your parser you're peaking at the first bite and you're saying is this one of those special things that's not really frames at all uh and then once you look at like oh look it's one of the web transport ones I will not instantiate my frame parser I will just go do the web transport thing just like"
  },
  {
    "startTime": "01:24:02",
    "text": "that's not frames it's something completely different um that said Martin is 100 right that you've got to register them in the frame space of H3 because otherwise somebody could create an H3 extension frame that could be on a client initiated by directional stream and that's not going to work so um but I think I don't know how many people are going to actually implement this who haven't already started uh so maybe it's guidance for people that don't exist in the future but I think having them you know having it described in the document as a stream type uh and registered in the frame registry might be the thing that gets the most people to write the correct code here rather than trying like oh it's a frame I'll put in my frame parser and then like a week later they're like that was such a bad idea what did I do so okay that's all kazoo Castle I think my preference would be to actually have stream types for both uh foreign correctly when we develop HTTP 3 we believe that bi-directional streams would only be used by H3 therefore we don't need any extension points but now we think that we have to use them for our own purposes and then the question is would there potentially be another protocol that would co-exist on the same connection that would also want to use by directional streams for other purposes and if we think about that possibility I think we need a clear separation a clear way of separating the string types uh the type of the streams that's being used thank you Victor uh"
  },
  {
    "startTime": "01:26:00",
    "text": "I kind of agree with the fact that you probably don't want to put this into your regular stream parser if that's the only thing okay our current implementation puts it into the stream parser but that's because we implement the version of the draft where it's allowed to appear not in the beginning of the Stream uh I don't think that uh streams without the frames without length are conceptually bad because we had at least one other proposal for a frame without lens that made sense and I found in past like actually useful uh but in this particular case uh I don't particularly care because I believe those are linked to the same thing as a wire thanks Victor uh so I'm David schenazi speaking as an individual contributor here um so my first point is I don't feel too strongly here I'd much rather we but whatever it is even if it's a coin toss and progress rather than anything but it I think this it's early enough that it's worth us discussing more on the list I'm not saying but anyway my personal opinion is since we need to register it in the frame type Ayana registry no matter what um it makes sense to just keep it be a frame one interesting property is so the thing that kind of flips people up or trips people up a little bit is that it doesn't have a length one interesting thing we could do is if you set the length to 2 to the 62 minus 1 which sure it's gross where we're wasting eight bytes that's actually an interesting thing because"
  },
  {
    "startTime": "01:28:00",
    "text": "the quick stream can only carry to the 62-1 and you've already burned uh eight byte for the lengths they however many for the thing so you know that you're not going to go off the end of it anyway so that effectively means taking all over the whole stream so you could use that as they must send the length to all of this and I'm seeing P Martin make Mia that's gross go away face so anyway it was just a thought um but I'm just throwing the idea out there I'm not pushing it serious so strongly all right uh Lucas hey yeah so I mean hearing some people here doesn't seem like I'm that much in the rough wanting more of a stream type model um it doesn't seem like it needs to be web transport specific either and I'm wondering if there's interest in trying to take this into just a small Standalone ID to go back to the HP working group and say look there's at least one use case here that wants to repurpose client bi-directional streams and here's a way you could do it and what you need to do is go and Define a code point for your specific use case and then web transport can Define that code point we don't in the Iona registry yes we need to avoid a frame type Clash but we don't we can just Reserve that code point we don't need to call it anything and therefore um a frame parser would see that and say I there's nothing I can do with this like I I probably need to to if I'm going to try and parse that as a frame I need to crash because if I try and read the length which is a humongous number or Garbage bytes after like I could have like serious problems here like I'm concerned that security problems related to that kind of thing well if the if the peer is sending you something bare something bad and that makes you crash you have a bug in your code but anyway so let's not designed something that is like so easily no no I I agree that's a fair statement that this is that what I was saying with is"
  },
  {
    "startTime": "01:30:00",
    "text": "silly I'm not disagreeing with that just saying good uh but I'm willing to go and do some some more work on this if people are interested I might just do it anyway and see there's a store store person kind of thing um okay that makes sense uh speaking as chair now to wrap this bit up um what I'm seeing is no clear consensus on one way or the other um and actually a good conversation of trying to figure this out I'm not seeing people with disagreeing priorities or goals here so this should be pretty straightforward to resolve um this sounds I mean let's take it to the list and discuss it there if we can't resolve it on the list I might suggest a like mini design team um for or even just you know uh or an interim whatever just an excuse for people to get in a room and like spend a bit of time I would normally say oh you should all grab lunch but it's already Thursday afternoon uh I see Lucas saying if anyone wants to go grab beer with them uh that or he needs a glass of water um maybe yeah go talk to Lucas after the session is a good idea as well uh what I'm thinking is action items um I'm gonna take an action item with Bernard to talk to the HTP chairs see how they feel about this because um neither of them are in the room right now and this sounds like it could either be the and just in terms of ossification my gut feeling is that if whatever we design in web transfer will probably cover every extension that wants to use bi-directional streams in HTTP forever because in practice like once you've set that setting that's how it is and we've so I'm sure they're going to want to have a say so I'll discuss with them my only concern is I don't want to delay this document too much so I'll try to negotiate with them if it makes sense to have something fast tracked with them to like very tightly scope to solving this problem all right and with that Victor I think"
  },
  {
    "startTime": "01:32:03",
    "text": "you can keep going oh uh uh I think we're actually out of actual issues there are some open pull requests that I would like people to look and but I would like people to look I mean I believe all of those already had consensus in some form another so uh special is the first one we've agreed that we want to do this but we've never agreed on the specifics uh everyone is welcome to take a look at this and unless there are any objections I will merge all of those uh and that's it for my slides thanks everyone hi thanks Victor um oh it's silly there there's this really neat feature now that I can get the slides back but the presenters keep closing them and then we just need to tell you to do some UI tweaks yeah yeah it's true the system isn't really designed for what we're doing which is the entire slide deck is one thing um so just to confirm folks please review those PRS um and then we're going to merge them soon uh Martin I want to come up for uh for your there we there we go no but I'll try to fix that right now so stress this go ahead start and then let me fix it you can start talking while I fix it okay well I I would I would really need my slides though if you maybe could go to the next slide while you're yeah yeah I can do that"
  },
  {
    "startTime": "01:34:04",
    "text": "okay let's talk about stream resets again um this is different from what we talked about in in quick talk closer to the mic okay this is different from what we talked about in quick um so um just a quick quick recap when when you reset the stream you um you you stop re-transmitting your stream frames uh you only transmit the reset stream frame reliably um at the receiver side you usually report the stream reset error to the application directly without waiting for any stream frames since they are not delivered reliably anyway so next slide so this is how your how a general web transport HTTP 3 setup would probably look like in every stack at the bottom you have your you have your quick layer your quick layer accepts streams and hands them to the HTTP 3 layer and then HTTP 3 parses the first frame or as we've just discussed the first warning and decides what to do with that stream um it could be an HTTP request stream if you parse an HD an H3 headers frame um then you pass this past the stream to your HTTP Handler if you parse the frame type for the web transport stream then you put you you pass your your stream to to your web transport stack which then might pass the session ID how are we doing with the slots yes I just need to stop them to re-sure that ones sorry for that all right oh wait"
  },
  {
    "startTime": "01:36:05",
    "text": "nope okay nope yeah it's just I got this uh this one yes so so the problem is we we what what does your your HP three layer do when when it receives a stream that is already reset and the stream frame uh the stream frame carrying the the first byte was lost so we are now sitting there with this stream and we don't know is if it's an HTTP request stream or if it's a web transport stream and then which session it belongs to so next slide the first option is to do nothing like your what do you do in in H3 you receive the stream it's reset you're like the client doesn't want the stream anymore you immediately set a reset on on your side of the stream and the stream is gone so we could say we do the same when you're when you're running web transport on the on the same connection um you receive that stream reset it it's gone the the the downside of this is that application protocols that are built on top of web transport might need that reset as a signal for for some some signal at the at the application layer so if we decide to go with this option we limit the the the kind of protocols that can be layered on top of um on top of web transport next slide the second option is to to use a a reset capsule we've already defined a bunch of capsules and every web transport session has this one reliable stream which is not closed until the the web print board session is closed so we could use this that that um that stream to send a web transform"
  },
  {
    "startTime": "01:38:02",
    "text": "capsule and I just made up that frame format that's not defined in any PR but this is how it could look like um you just sent this capsule on on the on the on the request stream on the um yeah on the Control stream and you know that it will be desired and will be delivered reliably so this sounds like an easy solution but there are some problems with it next slide so let's go back to our our general stack and we are now at the rgb3 layer and we have received the stream that is reset now what do we do we haven't received the capsule yet so this could be an HTTP request stream but we don't we don't know that yet or it could belong to a web transport session so we now need to wait to see if we receive this capsule on one of our web transport sessions if we don't receive that capsule after a certain time then we can conclude it was probably an HTTP stream and then HTTP stream and then we can reset it which of course now we have the problem like what's what's the right value for this timer and there's probably no good answer because the your Capital could have been lost needs to be retransmitted um could could have been blocked by flow control um like there's there's just no good value for for this timer things get even more complicated if if you consider that there might be a second web transport session which is not yet established but the client has sent the connect request and has already optimistically opened the stream for that for that um for that session um is now canceling that session by by resetting the request stream so now you're sitting there like this was a web transport stream but you won't you won't get the capsule because that that"
  },
  {
    "startTime": "01:40:01",
    "text": "session has already gone away so it's it's it's not really clear what to do in that case you you would then run into your timeout and just reset the screen and maybe give a give a wrong signal to the to the transport layer uh to the application layer sorry next slide foreign that's the old slides okay I I it was I mostly skipped slides so this is fine so with the reset capsules there's there's like a lot of error conditions uh I've ex I've walked you through one of them but there's more like you could have you could you could receive the the reset capsule but not receive the stream reset reset because there's there's no guarantee that the client is well behaved right because the client could be attacking you and just sending you sending sending you nonsense so when you're implementing this you need to be prepared to to handle a malicious client um could also be that the client sends multiple uh reset capsules um on on different sessions all claiming the same stream and you also needs some Logic for that I guess um so there's there's just a lot of corner cases you have to think about with reset capsules uh next slide that was the next slide wasn't it yeah so um for the next option I made new slides so if you could fill those out it would be really great uh yeah I did and I hit the pull but let me let me let me run through it again one second all right hold on I'm gonna upload them with a different name we got this"
  },
  {
    "startTime": "01:42:11",
    "text": "all right tell us a joke quite a while I'll figure this out refresh import processing close present there all right okay um so the third option is to to solve this at the quick layer and in the quick reference group I presented one proposal called reliable stream stream resets that's not the only way to solve this problem but um it's just one proposal and there were other other proposals um uh floating around to solve to solve it in a similar but maybe less complicated way uh next slide next slide so the the question is uh so for for option option three you're solving it at the quick layer this has the the the obvious benefit of um allowing the the applications to to react to every stream reset um it has a very limited complexity at the web transport layer at the HTTP 3 layer because when we receive a stream we can rely on the um um the session the web transport stream frame and the the session ID being present um we're basically pushing that complexity to the quick layer um the reason we might want to do this is because web transfer is probably not the only protocol that is sending some kind of identifier at the beginning of a stream so solving it at the quick layer one might argue is the the correct"
  },
  {
    "startTime": "01:44:01",
    "text": "layering here um downside is we need to Define that um that that extension too quick or the quick working group needs to work on this um next slide or maybe there's no next slide yeah there is oh no no that was it that was it for your slides what do you think thoughts questions or Martin while people queue up do you want to share the other option that I think uh Matt had proposed that was a take on your option three or like option 3B so if I understand correctly the the the the the proposal was to extend not the um to to extend the reset stream frame not with a with a size Warren but basically with a data block and in this data block you would send the the web transport stream frame so we can call that 3B for the purpose of this discussion uh so just to set the stage we have 15 minutes left the chair is going to keep five minutes to wrap up so we have 10 minutes to discuss this Alan go ahead Alan prindell um originally when we talked about what is now called 3B so this with some instead of a reliable size some amount of application data which we get delivered to the application uh when it received a reset I had thought that that wouldn't solve the case where you still don't know if you don't receive this you have to wait for a while you gotta like what do you put in here if it's not obviously I don't have a good idea I was thinking it had a problem with HTTP streams but I don't have a clearly formed video I'll get out of the queue are you concerned about receiving a stream with a variant and only being able to read like the first"
  },
  {
    "startTime": "01:46:01",
    "text": "bite of the Warren but the warrant is actually longer I mean your stack needs to handle that anyway of course Mike um just repeating what I said when we discussed this in quick um this is actually a problem that H3 discovered it had just before we shipped the RFC um so it would be nice to see a solution to this more generally uh whether it's 3A or 3B I really don't care odds are good you have two varins that you care about um it's probably shorter to just stuff them in here versus re-transmitting but if you already sent it and it goes then acknowledged then sticking this in shorter ultimately it doesn't matter um it's a couple bytes but it fixes a real problem I'll bet one that doesn't happen very often we think thanks Jonathan uh yeah jonathanics would this um quick extension B mandatory and Implement from web transport implementations because if it isn't then you sometimes get the unreliable resets case which I think would be even worse because then you couldn't predict whether you could use full use as an apple as an application signal so I think if you're going to do this it would need to be MTI for web transport implications but it has its own unfortunate implications so I think that needs to be thought about and just uh jump in his chair we already have the datagram quick extension as mandatory tutorial to implement for web transport so that's totally an option we have yeah I think we just add this to the checklist that we that we had on that previous slide there's four things now it's five things um and Counting I have a slight preference to the um to the sort of"
  },
  {
    "startTime": "01:48:00",
    "text": "partial delivery uh option here as opposed to the metadata one I think the metadata one creates some interesting uh challenges so can you explain what you mean by those two options yeah so the this option that's on the slide is partial delivery I'm going to say that I'm only partially delivering the contents of this stream up to this point um there's it's like saying oops I I may have not provided you with a finbid or I've provided you with a thin bit but I'm not going to deliver up to that I'm going to deliver to something less than that right so for for this application we can say that web transport streams you have to provide a number in this one that is large enough to cover the session ID and the other other piece that's in that frame uh the type that that's at the start the other option also works and I think I could probably live with that which is to to have some chunk of metadata in here that's arbitrary length and would be defined by the application there in in some way there's there's some interesting challenges with that one in terms of what happens if it's different to what the stream sent in the first place and this is the sort of thing that I think Martin really wants to avoid here is that there's there's never any ambiguity with this design as opposed to the one that has oh here's the here's the information that you needed to process this stream oh so let me jump into clarify because it's very relevant here in what the one that I was asking Martin to present was also the beginning of the Stream it was a separate metadata at least in my view there's no guarantee that those bytes match right you're sending them in a different context in the same way that you could send two stream frames with different bytes of different at the same offset right you you would have the same here that's but that's fine we can already handle that potentially so or at least in my view just to clarify I was thinking of sending the beginning of the frame up until reliable size as part of this Frame not easy as a way of framing it yes part of this this you know Call It Whatever that way it's easier to"
  },
  {
    "startTime": "01:50:01",
    "text": "implement because it and it's bounded to one packet sorry just wanted to clarify yeah you still have that problem but but quick implementations deal with this problem today uh in a non-deterministic fashion which is really really fantastic and we could do the same here I guess so I'm kind of okay with with either one of them I think I have a preference for this one it's smaller uh you've already probably sent this information and we can certainly require that people send this information anyway and so from a practical standpoint it's probably better um I'm just trying to think size wise it's about the same uh if you have to send it if you've already sent it this is more efficient there's a number of different sorry there's always the mismatched chance but um the mismatch chances like a constant in this design and and we've just created a new way to do it in in the other design I think that's probably that's probably what it comes down to now of course we need to have this discussion in the quick working group because this is not the working group to generate the solution but the requirement and I think I'm getting the sense that the requirement is pretty solid yeah no so the purpose of the discussion today in this room speaking as chair is to decide if we want to let's say option one and option two were didn't involve the quick working group it would be we've solved this here we're done option three or option three B whatever we're calling them require we we now give the quick working group requirements so we can all trundle over there and put our other hats on and discuss it there I suggest trundling in that case um more concretely I think we've seen that this keeps coming up for basically everything that we ever build on top of quick and so I think it is very much worth trying to solve this in a generic way that will apply to web transport and others I would actually have a slightly"
  },
  {
    "startTime": "01:52:01",
    "text": "uh inverse take from Martin in that both of these seem workable and I have a slight preference for the other one um that we can sort out within quick it seems as though the ability to mismatch what you do in web transport and what you put in quick is going to exist in any case no matter what you do and so it may be that it's simpler to just say hey here's my attribution for this rather than trying to deliver a part of the actual stream data um but that's something we can take to quick because yeah so I think the two options that we have on the both ends of the table is if we want to fix this problem in a generic sense or if you want to do a quick fix and the generic solution being affixed into the quick protocol I think the concern is if you can reach a consists there in a short time frame and if that consists is going to be something very simple to implement because honestly those two conditions uh it will drag the standardization and the implementation of web transport but may I may ask a question but by consistent do you mean consistent spec wise or are you avoid about implementation uh complexity uh well so I what I said is icons reach a consensus regarding how to fix this in quick oh you said consensus okay sorry I didn't get it and regarding that constantial question is my concern about this specific uh proposal is that it's not concrete enough to solve all the issues that we had in history like uh recognizing a push a very very end of a large response and they're having to send reference to it so there will be"
  },
  {
    "startTime": "01:54:00",
    "text": "discussion like that if we move this to quickbooking also I think my slide preference would be to fix this in the dishwashing group uh David schenazi speaking as an individual well first speaking as chair I've cut the queue and please keep it short because we're running out of time not speaking as an individual um I initially really wanted to fix this in web transport to for the exact reasons because Google is saying to like get this done But like after uh seeing Martin's presentations And discussing like uh offline this week I'm convinced that there's a real problem and I begrudgingly I'm in favor of solving this generically at the quick layer and that's that Victor I also agree that we should solve it the quick layer because last time we had a similar problem and we did not solve it at upper layer uh we came to regret it and I'm referring to help yes but like in general if there is a correct layer to solve the problem that we should solve that problem at that layer uh and I don't think it is actually that much more expedient to solve it a 12 transport layer in this case okay thanks Victor Luke uh hi yeah I agree with solving it correctly I will say for web transport I would just send the reset stream after you get an ack of the reliable size like you don't need to send the reset immediately you can hold it until you know that they've got the reliable data um but I'd like to avoid that extra like round trip or two and this would be a way of doing it thanks Alan Alan Ferndale I'm not sure that works because a transport act doesn't mean the H3 stack has seen the data I can still get reset before um so I think we should we should be"
  },
  {
    "startTime": "01:56:01",
    "text": "solving it at the quick layer the I will say that maybe we are taking a little bit The Spicy take for the end of the meeting a little bit too narrow a view on what the problem is the problem is that applications like to group things and that we should quick maybe should provide a way to identify those groups on the wire not maybe at least in reset stream but maybe also stream um and that would also potentially make some web transporting things easier or the server push thing easier or other applications people want to build um it might be interesting that would be an opportunist 3C then I'm sorry I would assume that would be an option of three C I mean that that one is probably not expedient um it's probably going to generate some controvers or maybe not I don't know but this is something we have talked about internally we've actually implemented in our stack already the ability to group streams and have that be part of the API and an extension on The Wire setup it could be something interesting thanks Alan hi Lucas Lucas party wearing no hats um not being a web transport implementer yet just a keen um backseat Enthusiast uh yeah the character thinker kind of work solving it this way whatever Final Solution we pick seems better to me hence why you know we we wanted some of that discussion in quick um I think yeah it's good to see that other people are kind of agreeing with what I thought well it doesn't matter if I was wrong or we were wrong that's fine but yeah like let's I think it seems like it's emerging that we should try and solve it properly web transport could have but you know if we got in a paging enough context in now to understand the problem a bit like try and write that and codify the solution thanks Lucas and stay there and put your hat on I'm going to meet you soon um"
  },
  {
    "startTime": "01:58:01",
    "text": "speaking as chair I'm getting a sense in the room that most folks prefer solving this at the quick layer um because you can you live with that um and or does anyone else like object to solving this at the quick layer um and we're not prescribing a specific solution but it would be going too quick and saying we need this problem solved at your layer plays I believe that yeah I think we can discuss this the big quick parking group I'm not sure if there would be a consensus that's my only concern right and to be fair if it starts dragging on forever and quick we would we have the option here to change our mind like okay so I'm gonna say as chair we're gonna um start moving that we're gonna move the discussion too quick um saying that we have this problem and we would the folks in the room at web transport preferred that and that thread people are still completely welcome to say that they want to absolutely do it in web chessboard and not do that that's still fair game we're not declaring official contestants here but we're gonna go in that direction and so Lucas like as chair can we perhaps try to like maybe have a specific quick interim on this topic or something you don't need to reply to right now but it's completely in scope of work in our Charter to do this kind of thing um we we have a fairly quiet work key right now so we have the capacity um in terms of interim I'll need to go away and chat to people I have a think um obviously we have stuff like the mock interim coming up in January potentially um so scheduling might be difficult there I don't know what what timelines but yeah let's not consider everyone here right now to figure that one out we'll take it offline all right I that's that on that topic thank you Martin"
  },
  {
    "startTime": "02:00:00",
    "text": "uh um okay I think we have plans this went well uh Bernard do you have anything you want to add uh no uh just uh we should probably start to keep track of all the things we need to do to close out web transport uh because we don't want to let some of these things drag on for years agreed uh I'll I'll take action items to uh go talk to the HTTP chairs and the quick chairs and we can all play the game of swapping hats to try to get this done quickly and that's done thanks everyone for coming to web transport we will see you on the list uh if you're not subscribed to the quick or HTTP best lists uh you should because we're going to have discussions very relevant to web transport there um thanks for everyone and see you virtually right yes yes"
  },
  {
    "startTime": "02:02:06",
    "text": "foreign"
  }
]
