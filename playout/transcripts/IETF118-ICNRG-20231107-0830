[
  {
    "startTime": "00:00:25",
    "text": "So there are still a few seats here available in the front. If you don't want to sit in the back, don't be shy. Okay. Good morning. Welcome to IC Energy. My name is, and my culture, Dave Oran. It's, on the screen. He's joining remotely from Boston. Good morning. And, yeah, let's get started, with a meeting, great to have you here, quick usual But Nope. Just a moment. Do you want me to drive the slides? Should be able to do it, but it doesn't work. Okay? Never got. Here we go. Okay. Just the the usual housekeeping notes. So please be aware that we are operating on the, the IIM IETF IPL rules. So that in short, that means you have to notify us if you contribute anything, was IPR relevance or if you, see anything with IPR relevance. And, yeah, please make sure you signed in using the, on-site meeting tool when you are presenting locally there are two ways to, run your slides. You can use this clicker here, or you can,"
  },
  {
    "startTime": "00:02:02",
    "text": "use the online tool on your mobile phone, for example, Yeah. That's just, remind remind ourselves that we are doing research here. So this is not a standard setting, activities. So we are in the IRTF. And, we are producing specifications that we hope to publish as experimental RCs, but these are not internates done that in, in any way. And, okay, just, linked to our main list and so on. Most importantly, we, the notetaker, we cannot run the meeting without one. And, thank you very much for you. Can we have someone, helping real? So then it's quite useful to have 1 main notetaker, and then in case there are some he misses something that, somebody can chip in using the the online native tool. So we don't expect, this be a very tough job today, but, still, maybe go to have someone Okay. Cool. Thanks. Yeah. So it's linked from the IETF agenda. Yeah, thank you both. That's that's that's more useful. Okay, our agenda, So we're talking about, flick first. Dave's going to about, It's a forwarding, and, we have, David talking about, and the untested activities and Kehan is talking about collective communications and Azure team is talking about, microservice architectures."
  },
  {
    "startTime": "00:04:00",
    "text": "Anything that people want to add or change on with the agenda? Great. So just a quick few updates, or, let's just review our the drafts that we aim to publish, So, we have recently been able to move a few drafts forward So, like, both both trace route and ping have been sent to the ARC editor. So we expect some outseas coming out soon. Same for, past steering, And, So time Tlv, had seen, a few minor updates So, thanks. Paying attention. And, so we're currently waiting for for calling to to move this forward. And, yeah, flick we are going to talk about, today. So, that's the one we want to get, done next. Alright. So, let's start with, the forwarding update, from from Dave. Do Dave, do we have slides for that actually. No. Because there isn't much to say. So you can probably get through this pretty quickly. So so for those of you who are not familiar with the spec and haven't written haven't read it yet. This is an extension to the CCNX and NDN protocols. To allow them to do better than 2 way handshake types of operations. For applications that aren't simple content retrieval. Applications that are things like, getting sensor readings on IoT devices, for emulating the same kind of interactions that you see in web transactions"
  },
  {
    "startTime": "00:06:01",
    "text": "restful web interactions and a variety of other, applications like remote method indication that require far a multi way handshake and what we've done is attempted to preserve all the properties that we have in the CCNX and MDN architectures of of consumer anonymity and, there's all the security properties that we see on the return of data. So this has been, worked on for a while, it's still not adopted yet as an ICNRG item. But there it has been implemented. There's implementation work still going on, actually, in one of Dirk students is is doing work on it. And there's some probability that we'll get some work done by the nicked folks in in, Japan. So I think the status here is twofold. One is we need wider review of this specification. Number 2, it seems to have sufficient interest due to the implementation activities and some of the directions we're seeing in ICN in general in terms of what types of applications seem to be a good fit for the architecture. And hence, I think it's time to consider adopting this as an ICNRG item. So I think after this meeting, Dirk and I will issue a, an adoption call for this And, hopefully, that will, provoke people to give it a more serious, detailed review. Thanks. Thanks. Thanks, Dave. Are there any questions or comments on that?"
  },
  {
    "startTime": "00:08:01",
    "text": "No. No. No. No. This is, reflexive forwarding so we've built a number of slides for that. So in the safe There's no real need for slides because a whole lot has changed in in the in the application itself. The main update is that we actually have some experimentation and, research work coming on using the spec. So it's become active now in the community and hence, I think it's time to call the question as to whether you want to adopt the work Yep. Yeah. So this would be, needed for say more transactional communication in ICM. So normally, we like to do things, in a data oriented way. But, of course, they are also interaction scenarios where you need to, for example, modify some state or issue an RPC request these kind of things. And so we think that this is a good vehicle for achieving this and, would be really grateful if people could have a look and also tenor's concerns, because it's modifying the forwarding behavior. So that that's why it's good to have a broad review of of of this specification. Great. Yeah, I'll also be available after this meeting to discuss this morning if somebody questions on his Cool. Let's move on. And next up is Mark and I give you the control of the slides. Okay. Hello. Let me just Check my control here. 6 if Uh-huh Yes. That seems to be keep pressing now. Alright. Thank you. Alright. So, flick perhaps, we figure out what's the longest running draft has ever been"
  },
  {
    "startTime": "00:10:02",
    "text": "and, maybe we would qualify. So I'm gonna go over the, 5 update. So there were just a few changes since 4. I'll start with a real quick recap of what flick is trying to do. And then what the updates were. So flick is providing a manifest of a object, and it provides all the hash values so you can request every specific object by hatch name. It's hierarchical. So you can, retrieve either more manifest or more application data depending on what the hash points to. There's a canonical traversal order, And if you retrieve all the application data in that order, it should reassemble the original file as it was intended. And that will be important for later in the presentation. And then it says, like, good. I'll skip the rest of that. That's not important for our, Oh, right. So the interest construction techniques So there's several interest construction techniques. This is how a consumer will construct a name based on the information in the manifest and the where it is in traversing the manifest. And, the the update that I'm gonna go over is to one of those name construction techniques. So there's something called the segmented schema. So this, you know, is is used by CCN or NDN. When the publisher used a segment number in the name of the content object. So I took my file. I split it up to a 100 objects, and I called them fu/onefu/ 2 and so on through FU 100. So when you use the segmented schema, That means you have to,"
  },
  {
    "startTime": "00:12:02",
    "text": "direct, you know, figure out what the segment number is for every hash value that's in the manifest. Let's see here. So for normal sane usage, you would want to make the segment numbers, be the same as the in order traversal the manifest. So, basically, you're retrieving segment 0, segment 1, segment 2, segment 3, you know, if you're following the, manifest in order traversal. The the problem is that doesn't always have to be true, and there's some exceptions, and those are gonna be some corner cases that'll go over. So In the previous draft, the default concept was the manifest would say using segment numbers for this prefix And so you, the consumer, need to track them and figure it out. And that means that the consumer would need to remember The segment number between manifest objects. So when I, you know, go between change manifest. I have to remember what my previous segment number was and it means that I basically have to retrieve every manifest And every object in order. Because yeah, I need to track this number that has, you know, no explicit value anywhere. The other option that we gave in the previous draft was to use what we called annotated hash pointers. And you would give an explicit number for every hash. And so there there'd be no remembering anything I would just tell you. For everyone, what what the number is. And"
  },
  {
    "startTime": "00:14:04",
    "text": "you know, for some things like audio video, you know, this this is kinda useful because you might wanna skip around and just say, you know, go to this other place, and then it'll tell you what the segment number is when you go there. So you don't have to keep counting, other types of uses might be for, like, deep duplication apps or things like that that might know, want to say, you know, use this segment number, for it. The new option, this was discussed at IETF116 in the slides there. It then and and it then got put into the 5 draft This is what I'm going over. Today. So Instead of doing option 1, where I just say you segment numbers and you, the consumer, figure out the number by going in order every manifest Object. Has a field that says what's the starting segment number? So I don't need to remember anything from object to object I could retrieve them in any order I want, and it will always tell me where to start. And and then I just know the offset in the array of hash values that are that one object. So it it it makes the knowledge all a lot more local. And, it's it should be much simpler to use in practice. The issues that, come up, well, you know, first, just segment, some notes on segment numbers. So In the o five draft, The only real requirement that's in there is to say that that for a given name prefix, a segment number should only be used 1. That is There's a unique cash value for that segment number. And, you know, I don't duplicate segment numbers when I'm segmenting my my object."
  },
  {
    "startTime": "00:16:04",
    "text": "So that's a totally normal thing to do. It's not enforced anywhere, but that's what ask for. What flick allows is that In the manifest, I could use a segment number more than once. I you know, segment numbers, may not be used for the publisher. Maybe the publisher skip 5. If you never put it in the manifest for me to retrieve, it doesn't really matter. And the consumer is allowed to skip segments or go out of order. So the those are all things that are allowed know, they might or might not be good ideas. And there we go. Number 2. So, you know, for general saying use, you know, the publisher should do the obvious thing. Goes 0 to n -1. And the manifest know, should use a single method like the start segment ID you or the annotated pointers. If you start mixing those, it gets messy. And you would typically want the in order traversal to follow that you know, 0 to n minus 1. So if you do all that, it it it, you know, it it all makes sense and, it it shouldn't confuse anyone, and that's that's that's what you would expect. But none of that is mandatory. We we just ask that you do that. So what happens if you don't do those things? So what happens if the publisher uses an annotated hash group but only includes a segment ID annotation for some of the pointers. Well, if they included also a start segment ID, then you're kind of mixing the two ways and and and and you could figure out Numbers, numbers, but it's gonna be really confusing for someone to debug, and I don't know a good reason to do it, like, this. But that isn't allowed use and and there's a way to handle it."
  },
  {
    "startTime": "00:18:01",
    "text": "Complication number 2, is what if the hash group uses segmented naming, but the hash group doesn't have start segment ID. So you either have to use a start segment ID, or you have to use annotated pointers. If you don't do those, then it's a mouthful manifest and you discard it. Alright. So a publisher uses a regular group, with the start segmented naming, it includes a start segment ID for each hash group but the numbers overlap. So this is the publisher did something weird. You know, for example, the first manifest starts at 0 and has 10 objects. And the second manifests starts at 5 and has 10 objects. Well, when I reconstruct the application data, it has 20 objects but 5 through 9 and 10 through 14 are the same pieces of data. Don't do that. I don't I don't know why you'd wanna do that, but know, if you did it, that's what would happen. You know, it's not an error. To do that. But it's probably wrong. Okay. So conclusion here. So, just just to reiterate. So, when, the data associated with with this name constructor is assembled in the manifest in order traversal. So whatever that traversal is, is what is supposed to reconstruct the data. The segment numbers, don't tell you how to reassemble it. They just name east each piece of the assembly. Right? So, normally, they would be a one to one thing. But they don't have to be. There's no way to enforce that."
  },
  {
    "startTime": "00:20:00",
    "text": "The publisher can use segment numbers in a non sane way but as long as the traversal works out, then you know, whether or not there's a screw way to use segment numbers, you know, it's correct. Really the only use of doing something whacky like this would be for data deduplication. That's the only real use cases that I could think of for it. Alright. So, hopefully, that wasn't, like, too confusing, but, you know, I I can take any questions or discuss this. Yeah. Thank you, Mark. Are there any questions? This is Alicia John from UCLA. This is not a question for the comments. Wasn't sure. Why you offered all this, flexibility not offer those flexibility. That's really up to the producer which are away it wants to name the segments. Right? Right. We are actually we'll try a implementation No. Equivalent of this, I think we're gonna do something very simple. For the very systematic. Mhmm. Just the number oh, the segments sequentially. That's makes, you know, a graduate of all this, potential confusions and other complexities. Right. Yeah. And so so I'm not saying you should do any of these non same things. You know, the the the preferred thing is you segment your data object like, 0 through k and and when in the manifest they just are retrieve 0 through k, you know, that that that that's the obvious thing"
  },
  {
    "startTime": "00:22:01",
    "text": "and that's what I would hope someone would do but we don't say you must do that. And and and and and so, and I guess the the the the the the the tricky thing is with the manifest you reconstruct the object via the in order traversal the manifest. Whatever the segment numbers are, they're just naming the data. But it's whatever you put in the manifest in order traversal is what constructs the the data. Let me just, let's say one more thing. I think maybe you want you wish to leave flexibility. But the years of observations suggest that at least in the spike, if the suggest the safest way to do it. Because otherwise, Yes. Oh, can that to the wrong way. I can tell you an early example, in the DNS specification. There's an example to say, oh, you can put the to be in 2nd. And we watched a large number of implementation in the put that process number in the implementation, which is not the right number. Yep. Thank you. Yeah. We we we do recommend that you do it. The obvious same way. So that that is the recommended use, use, Next question, Rio? Olliana Gita from University of Glasgow. Thank you. I think this is very interesting one. What would be the next step? Right. So what I'd like to do is, you know, get these get get slick reimplemented. There's some, like,"
  },
  {
    "startTime": "00:24:01",
    "text": "know, 2 or 3 draft to go code that's out there. So that needs to get a needed, and we need to experiment with it. I'm willing to you know, help anyone who might have resources to to work on that, whether it's you know, CCN or NDN or you know, you know, anything. Yeah. I I just don't have time too. Implement it myself in something. Are you looking for? Anyone that do that? Is that is that the is that the call here right now? Are you are you soliciting a volunteer? Oh, Sure. Sure. If if there's someone interested in in in working with manifests, I'm I'm happy to help as much as I can. So thank you. So, Mark, you you had this, Python implementation Right? So that's still available online somewhere Yeah. There there is a Python implementation. It it was so so that implementation would essentially take a file and create all the content objects out of it. And and and just serialize them under the disk as you know, in CCNX wire format. So you know, the the low hanging fruit would just be to update that code. To the current draft, but I I'd really like to either use like Indian Python or or something to to get, you know, a live version going. Hi. Michael college. I'm also working on this is my first time seeing this. But it looks similar to some of the work we do or we have, large file constructed from any patches. When we're editing the file over time and is very convenient to have runs of contiguous blocks. Be numbered sequentially. But when you do edit the file, you'll end up with different segments of contiguity."
  },
  {
    "startTime": "00:26:02",
    "text": "And so possibly I'm just imagining that what's happening here is nice to have that property when you can, but you wanna allow it not to happen sometimes as well. And it might be the case that just when doing optimizations it'll it'll become actually meaningful when it exists and when it doesn't exist. And if that's the case, I'd be happy to speak more or if there's anything if this touches anything in your mind, I'd be happy to speak more with you and improve things. Yeah. Yeah. We we we had done something called difference based networking a long time ago, like, 20 13 or 2014 around there where you know, basically once we had the data encoded in these manifest trees, we could then essentially apply diffs to that and and just stitch out parts of the manifest and and, So so, yeah, that that that that maybe that would be interesting to to talk to you about Great. Thanks. Yeah. Mark, just for your info for everybody's info. So there is a group of people, here currently this week who are, bringing forward some proposals on state synchronization, and we're trying to figure out, you know, what of this work could be, say, IIT, for our IITF relevant I think this connects, a little bit to this work and also to, like, data a reconciliation that people in the in the, ICN committee have done. Maybe there could be a topic for, for next meeting. Okay. Great. Yeah. Thanks, Mark. Thanks to everybody. And, so let's move on. Some."
  },
  {
    "startTime": "00:28:01",
    "text": "So in, in IC Energy, we generally want to encourage, experiments, more practical work, you know, learning about how real systems work. And, that's why we, invited Davida and his, co authors to share her their work on, in a MDN test bed and traffic traces. So there was a paper at the ICN conference this year. I think they would probably mention it. And, that was really interesting. So when we invited them to, kind of inform the community and, maybe also get some more interested people to use this and, work with them. So I'm happy to have, the video. I hope that I pronounced an incorrectly here. And give you control of the slides you should be able to lose your cursor keys. Okay. And I hope you can hear me. Yep. And you should be able to see me as well. Yep. Okay. I have a timer here that says, 1 minute, the 30 seconds. Let me fix that. Okay. Thanks. Alright. So before I start, thanks, I'd like to thank I'd like to thank, their you, and Dave, for inviting me here. And I don't know if any of the other co authors of my co authors are here. I think that maybe SUSMait might be here, but I'd like to acknowledge all of them, Sakaalpa, and SUSMait from 10 to deck. And, Tushau and Lotfi are my colleagues, at Neste, So this, as Derek said, this is a sort of expanded and updated version of of a recent presentation was just a month ago, less than a month ago, that we we did Sussmit did that the, ACM ICN in Iceland. And,"
  },
  {
    "startTime": "00:30:01",
    "text": "I'd like to focus more today on the collection side And on the despot side, of the presentation, So I change the title because of that. And starting from that, I wanna say what the limitations and the caveats of our work are and from that, in turn, see where where the community where we would like to get feedback and input for the community. To, you know, to take the next steps they take move this work forward and make it as beneficial as possible for for the entire research community. So me start with the the y. I think let everybody knows why traffic traces are important. For for research. Some of the reasons I can mention are the they enable compare in different protocols and designs in a sort of a apple to apple comparison they allow us to get reproducible results out of our simulations and not just simulations, but a number of other tests in a sort of controlled environment, so that in turn, we can we can have better comparisons of different algorithms and and and protocols, in the case of NDN, specifically there's been a constant, request for this traces because thanks to the traces, we can a better test, potential designs for for all of these strategies and cashing policies that are especially the foreign strategies are key elements of the NPN for their architect her, And so, lots of research opportunities there. And we need to enable this research, and traffic traces,"
  },
  {
    "startTime": "00:32:03",
    "text": "are one of the elements that enable, research in this area. More traditionally and also not just for in the end, but this probably applies to to a networking more generally, performance measurements and, optimization and tuning based on the traces, and troubleshooting, issues with the network. So more generally debugging, not just with the network, but also application developers that want to know how their application is behaving on a certain network. We have looked at looked at some of the approaches that have been taken so far in the, let's say, attempt, to produce traffic traces 4 at the end. Mainly in 3. I don't claim that this is a, you know, on exhaustive survey of all the methods, but the the main approaches are starting from existing, traces of existing protocols and white widespread protocols such as or MFS that have a sort of a hierarchical name structure in in the, you know, path components of the HTTP request or, what URL really. And, in the NFS because you're you're moving essentially files. And file systems are typically hierarchical So and there's this long list of issues been doing this. Most notably, I will mention that this is this may not really capture the full semantics of Indian names and it may not reflect, or represent at all, how native Indian apps interact with each other or will behave in the future. When when these applications are being designed, for MDN and not just copied over from an HTTP world."
  },
  {
    "startTime": "00:34:02",
    "text": "The second approach is as in the synthes synthesizing Traces. And, again, this is, sort of the chicken like problem because how do you synthesize it based on what parameters. And until applications are developed you don't really know what to base your synthetic traces on. So we took a third approach, which is try to use, realistic or as realistic as possible deployment, of Indian and, around some real applications on this on this deployment. And capture the traffic. It's as simple as that. But there's a lot of details. So the main goals of our work is mainly the dataset of these traces, and a toolkit, a software toolkit that allows anybody to use these traces but also to capture their own traces. And so each piece of this trace of of this tool kit is supposed to be modular so that if you don't want to or if for some reason, the the hour data set doesn't work for your research, you can take the scripts that we have and the the programs, the tools that we have developed and, capture your own traffic, for instance, on your own topology, or using your applications, and then you you can replicate and And, know, replay those traces. In your simulations. Another part of the toolkit is a proof of concept Tracery player, that can be used for instance in NDSIN. Which is an simulator and then simulator based on minus 3, but let's move to the Let's talk about how we did the stress collection. So we created, a traffic damper specifically for for this purpose."
  },
  {
    "startTime": "00:36:02",
    "text": "The damper, simply dumps the Indian traffic, from any threat adapter that you want to run it on, and also for from the loopback interface because on the end, the end aspect, which is where we run a damper on as we'll see as we'll see later. The, WebSocket traffic goes through NGnglexproxy and then through the loopback interface. So in order to capture WebSocket, the end, and the end over WebSocket traffic we had to also capture low pet traffic. But this is not really important too much. What I want to focus on is the dumper eventually creates, a pickup or a pickup in g. File with all the traffic in there the traffic is, anonymized in a so far a very simple way. We are simply zearing out all the content the content field of the NDR bucket, of the NDAN data packet and the application parameters field in the NDAN interest packet it's this in addition to giving a little bit of a randomization. It also greatly increases the compression efficiency. See. And, for as for as far as the lower layer protocols are concerned, we're simply, you know, sort of masking the, least significant bite of of the IP addresses or the MAC address with a random key that's generated where the tool starts. So this is an open area of, you know, we hope that there will be more more development here in the future, it could be even an area of research as far as the, you know, NDA and anonymization techniques are concerned. You may say, yeah, there's there's, some information may leak through the name itself. So that's that's an open an open question. Sexually,"
  },
  {
    "startTime": "00:38:01",
    "text": "So we use this tool on a combination of the Indian test bed the Indian, what what we call global Indian test, but and and the fabric test, but to the and the n dumper, the n d n t dump that I just introduced was deployed on 4 NDA routers in North America. Yeah. And, yeah, I'll I won't say more about this later. While the applications additional in addition to the traffic that is, you know, organically flowing on the test bed, we we had to generate. There's not much of that kind of traffic all the test bed or there wasn't at least in in earlier this year when we did our experiments we sort of had to generate some additional traffic which is you may say might say not super real, but it's at least realistic in the sense that we used the real applications that were developed for real users in order to generate this traffic And these applications were deployed on fabric. In, locations of the united in the United States, So a bigger picture here, this is I realize not gonna read the ball. So I put a better picture of the global and the adjusted with all the the locations of the routers, the the routers not super well maintained historically haven't been super well maintained. So they go up and down all the time And so it's not super stable. The topology is not super stable. There's always Oh, it it's almost always working, but the number of links may not be the degree of the nodes may not be very high at in a given point in time."
  },
  {
    "startTime": "00:40:00",
    "text": "But it works. So as I mentioned, 4 4, 4 routers in North America where we deploy the our trophic damper, at UCLA. At the Washington University, Saint Louis, the University of Arizona in Tucson and, the University of Memphis in Memphis. And the the, the end hosts so that we're I said, running on fabric. We deployed, to to to kinds of applications, one is a file transfer application that is simply sort of emanating the sort of bulk data transfer. And another one is a video streaming. YouTube like we ran this over a number of weeks, but the main part of the traces that we collected and and the the the data set that we later published was captured over the course of a week. For 3 hours 3 hours per day, for 7 days. Basically. So 21 hours of traffic. The total capture, the traffic amounts to about 320 gigabytes. A little over a 1000000a100000000 packets. And it's it's published. It's public. Anybody can go to to that repository and download download the bucket traces, and use them for whatever you need them for. That's it. We, classified, the traces in 7 scenarios. Depending on the type of traffic that was flowing on a desperate in in that particular scenario. From a baseline, from baseline scenario where there was just a basically an an NSR traffic. NLSR is the NNDN routing daemon. So, basically, controlling traffic and other test with the users. But as you can see,"
  },
  {
    "startTime": "00:42:03",
    "text": "front table here, there was not a lot of traffic just with the baseline, so we introduced our applications as as I explained earlier. File transfer video streaming scenario b and c and then increasingly more complex scenarios where we interleave the the applications, we we changed the number of producers and consumers rather, I should say, the number of producer locations and consumer locations. The number of actual instances was was random or randomized and and would would change over time. The applications would come online and offline randomly over the course of the of the 3 hours. But they were connected to either or in one location or or a spread across three three locations of 3 routers, And then in the last scenario, we also were also spreading them across, different areas where the Indian test, but does not have a presence but the fabric test bed does have site there. So the letter g, has essentially potentially higher latency in the last hop. Compared to the previous scenarios. Don't wanna spend too much time on analyze on the analysis we did of the traitors but we did some analysis. I think the main one of our main goals is to produce the traces, make the traces available, And then you know, we would hope other researchers would come in and analyze these traces and tell us more about how the forward there is is behaving out there routing protocol is behaving of the"
  },
  {
    "startTime": "00:44:00",
    "text": "you know, control plane is is handling routing changes how the 4 of these strategy is behaving on a test, but and so on. And any kind of insights that can be glean from from the traces. Require much more in-depth analysis that we've done here. For this paper, So I, yeah, so I don't wanna spend too much time on this. Our hope is that others would come in and do a more in-depth analysis. But, yeah, we did we did look at how the, name components and name length was distributed and the name prefix is here, you can see, for instance, the file server So the file self individual servers, which were our applications are those that generate the most traffic, the majority of the traffic, but there is also some NSR, some sync traffic I'm being the traffic Here you can see the the throughput and and you can infer that there there is some, there is some benefit from either in degrigation or or cashing at uh-uh some of the routers just for instance, as you can see, UCLA was the producer in this case and the other three locations were running consumers. As you can see, the amount of traffic received at UCLA is not the sum of all three of this, which would normally happen if you just had a and traditional protocol, let's say, in this case, caching or aggregation are are beneficial in reducing the amount of bandwidth. That UCLA that that UCLA router is receiving or has to as to serve. More detailed, more detailed look at the interest lifetime field in the in the"
  },
  {
    "startTime": "00:46:02",
    "text": "packet and the freshness period in the data packet, add limit. Here, it's interesting. It's interesting to see that how the to basically all the values are clustered around 3 3 peaks at 30, what is it, 32, 60 4255. Which are basically the default, settings for the help limited that are used in different than the implementations. It could be a forward there. Adding the upper limit, if there was none in the incoming bucket, or it could be, the client library that encodes the, a default op limit when when the package is sent. And, here just to you know, show that we can drill down, into one specific, one specific application in this case, it's an SSR, so kind of a special application, but we can look at how the routing protocol traffic behaved, and you can do that the same for any other application that's in the traces. You can filter, by name prefix and and get, get only the traffic that you care about. So I think it's important to mention what the limitations of this tree set of this, dataset, r, so would we are aware that the traffic makes traffic, makes in this data set is probably not a representative or what, future NDA network will look like unfortunately, this is a kind of sort of a chicken neck problem, until there is such a deployment, we and and real applications running on it we we cannot know it'll look it will look like. So this is the best approximation we can provide at the moment with"
  },
  {
    "startTime": "00:48:00",
    "text": "with the tools, the, applications that they're currently available. The traffic and anonymization as I already said, it's it's a very simple. So we hope that, other researchers can, implement and add a better algorithms. And of course, we're we welcome contributions to to the tool if you want to implement a better algorithm, please submit it and we'd be happy to incorporate it the test bit scale, is not very So the the data set that that we have right now is based on the four nodes that they mentioned earlier, and it's a US centric, basically, we did everything in the, the United States. But in the past, there's an update small update here is that in the past month, we were able to deploy the capture tool in a 10 more No. On to on to 10 more routers on the on the Indian test bed. So hopefully in the near future, we will have a bigger or yeah, bigger, a bigger dataset. With more collection points. And finally, the data set is it's just collecting, packet traces. So only packet traces collected you may say, okay. Obviously, it's a data set of packet traces Yes. But, and, Ian, he is, and Vienna is a stateful forwarding plane. Right? And, Nadia forward their has has potentially a lot of states, that influences its decisions when it has to forward the, interest packet So just by judging from that packet traces"
  },
  {
    "startTime": "00:50:01",
    "text": "it may be hard sometimes to figure out what the behavior of the forward there was and why the forward that decided or more specifically a foreign strategy decided to forward a need just packet onto a specific path rather than another path. And this is especially true if you have, partial traces of your network, which is the case for our for our dataset because We have Ford notes out of 30 and now with them or we will still have 14 out of more than 30 nodes. Generally speaking, it's not practical to assume or require that the the collection that trophic collection happens. At every single router in your whole network. So generally speaking, it could be a hard problem. To reconstruct the form of the behavior based on a partial traffic taste. So what what's next? And from you know, let's talk about some potential next steps. Based on what I just said on the limitations, I think a number of next step actually derived directly from the limitations and caveats I just mentioned, One of them is is expanding that tourist collection, or rather expanding the data collection to more than just packet traces. So we want to be able to have a full telemetry of the node including data data planning telemetry and control plane telemetry. So for instance, telemetry on on the bit the pending interest table of the forward there. Or, telemetry on the routing"
  },
  {
    "startTime": "00:52:03",
    "text": "on on several routing aspects like the routing table, And this this would make it much easier to figure out to understand the behavior of the 4 order. And in turn, this would make some of the some of the goals that I mentioned at the beginning much easier, like, troubleshooting or debugging. Or performance optimization. Or for application developers, one of the requests I've I've been hearing for I think years, Eers now is you know, an application developer wants to test their application on to the NDA and test bed. They connect to the test bed the stats and in traffic. At some point, things don't work. As expected or their traffic, goes I don't know, the the latency is higher than expected or just things are not as don't work as well as they expected. So they wanna know what happened to do their packets. So how do we in real time or almost real time, debug this problem and tell the application developer which path that their packets went through and why they went that way. Was that an, the application developer you know, was there a mistake in in the way they design their main space on the the way they're used to I don't know, a multicast strategy, for instance, or is there, a bug in the forward there? Or there's an opportunity missed opportunity for our optimization in a fordoming strategy or or elsewhere. Or was there a routing problem Who knows? The the these are questions that we I've pin pin pin pin pin I've heard for many years and it would be nice to gradually move towards almost a semi automatic mechanism to answer this question or at least partially So real time troubleshooting of the test bed"
  },
  {
    "startTime": "00:54:02",
    "text": "from the point of view, both of the network administrator and the application developer And, this implies that we need some sort of on demand automated and on demand collection of the traffic filtered by name prefix this is specifically application developers that only want to know what their application is doing or even like a subset of their name hierarchy. What is what is it doing? You don't want to over burden the test, but with with, collecting more traffic than necessary. Especially if there's a lot of traffic and in the future, hopefully, there will be more traffic on the test, but that the traces can be at quite large, quite quickly. Finally on the Well, I already mentioned, you know, anonymization, the implementation well, the design first and then implementation of better anonymization techniques, and not just for IP addresses that are in, you know, the underlay but also for Indian names and Indian Indian pockets. And finally, developing additional metrics, we have a set of scripts that can analyze traces already. We've only implemented a few basic metrics but there's many more that can be added So, again, contributions are welcome there? And moving on to our last slide, this is where, you know, the community can help with this. The data set is there. The data set is available. If you think you can it can be useful. Please try and download it. Use it and you know, let us know if if it was useful or not useful,"
  },
  {
    "startTime": "00:56:00",
    "text": "for you. Let us know what else you would need to improve your research or to to optimize your research, to make your research faster or more accurate, are more reproducible we'd like to hear your feedback on this And if that, if our dataset is is doesn't work for you, and you'll have audios. If you have some special needs, then you can still take our tool kit and use it to capture your own traces on your topology or in any other way that you want And we hope that if you do that, you you will also, you know, publish your traces that ratio that you capture so that everybody else can benefit from from the availability of those traces. And finally, on the test beds, the Indian community is having some discussions right now on the future of the test bed and which I actually like to call a pilot deployment rather than test bed. Test bed is a bit of an overloaded term. But it's too late for that. So We call it test bed, But, anyway, so the the test bed, the you know, if you're developing applications try to use the test, but the once you've reached the stage, of course, that is fairly advanced, in the development, we'd like you to you to try it out your application on the test, but and if something doesn't know it doesn't work here, let us know. So we can we can fix that. So that's, That's all I have. And, I put a few references here to all our code and, scripts And it in the dataset, of course, and and the paper that was recently published at, ICN And thanks for listening."
  },
  {
    "startTime": "00:58:04",
    "text": "Okay. Thank you very much. Let me know. Very useful work. Okay, we have a question. Yeah. No worries. Hi. Rio Yana Gita from University of Glasgow. Thank you very much again. Like Doug said, it's a really interesting work. I think it these are very important. I'm I had a few questions. So Could you sorry. In the beginning, you mentioned something about synthetic. Could you kind of recap on that. I I didn't quite get what you meant by that. Yeah. So I meant traffic traces can be synthesized you basically can write a program and we've seen a few programs that simply mechanically generate a set of packets in a certain order essentially randomly based on certain parameters. For instance, the average name length, the average package size and so on. With a given distribution. Right. So this is a bit bit like how the quote, unquote, custom applications on NDSIM, for example, does something like So you're that's the kind of thing you're talking about. Yes. Actually, yes. Okay. Had I have 2 more questions. Sorry. One question. Could you just show me the, the throughput diagram you were showing earlier. Yep. Okay. Did you say the UCLA has the, producer? Write this. Okay. And I suspect so you're saying that the they're less traffic that that data traffic on the Memphis is because of the caching. Is that what you suggested? So if every interest packet from all three WashU, Arizona, and Memphis If for all, authoring"
  },
  {
    "startTime": "01:00:02",
    "text": "if all packets sent by these three routers where know, if you forget about cashing aggregation, all packets would reach UCLA So the total amount of traffic you'd you would see at UCLA, it would be the sum of the of these other three. But that's not the case. I see. I see. So what you're saying is that the the traffic you see on the UCLA plot is the largest However, it's not quite the the addition of all three other Yep. Folders. That's what you're saying. Okay. Correct. Yes. Yes. It is a little more. You're right. It's a little more. But it's not the sum. It works for summer, it'll be much, much larger. I I mean, it's quite obvious that it has the most traffic, most amounts of traffic. Right? Then it just, it's not quite the like, one to one aggregate of everything else? Correct. Yes. Yes. Yes. We don't expect it to be exactly, you know, the what, you know, it's normal that it's a little more you know, there is more traffic because not all packets can be aggregated Right. And not all consumers, will they be requesting the same files or the same video things. Yep. Yeah. And plus the the content store so that, you know, the amount of caching the and the investment is fairly low. It condos store is pretty small. Which makes sense. Then the last point I wanted to bring up was with regards to the troubleshooting, right, how far that pocket lend. Do you have any particular ideas? I was thinking the only way you would do that is to have sort of audit log of what the forward did did at every forwarding and somehow I guess, you know, mechanically sort of correlate them. I guess it's the only what I can think of, but, do you have any thoughts on this? Yes. So"
  },
  {
    "startTime": "01:02:01",
    "text": "of course, as you said, if we had all the logs or let's say a snapshot of the state of the forward at at every point in time, from just before the packet arrived just after we would be able to reconstruct everything that happened that's, highly inefficient in terms of storage, probably and and bandwidth necessary to move that data around So we would like to get to somehow compress that state compressed that state to something more manageable that is still, you know, useful enough has enough information in it that allows you to reconstruct what happened. At least, you know, or maybe on a larger scale, not necessarily that packet to scale, not for every packet or a bucket by bucket. But, sort of a sampling, you know, sort of a sampling technique. I thought I sis I suspected that the sort of the logs of forwarding decisions. So, like, the timestamped interest name and than the full face, which face it went out if it were to go out. That sort of pain pain lane would be particularly potentially useful as I thought. Yeah. Yeah. If the know, that that's that's possible today. If you had the logs of NFT, of the photo that's every node that's already there. It would already be possible. And so on the, actually, another another piece of this, achieve this goal would be to automate that. And you don't wanna be reading logs line by line Yep. That's the painstaking. Process. Amazing. Thank you very much. Thank you. Next question, Usaku. Hi. I'm Yuzaka Hamz from NCCT, Japan. I'll thank you for your nice talk. I think it's very important to walk and, I'm interested in, video streaming research especially the dash or HRS over CCNX or Indian."
  },
  {
    "startTime": "01:04:00",
    "text": "So I would like to know, that about your implementation of the NDA NDA applications video applications. So you just did it in the in the exhibits. Yes. So the video stripping application we use is is also open source. I I didn't put a link on the slides. But, essentially, it's, unless you're familiar with the soccer player, so for the let's say user facing parts pieces. We we use the the shaka player and underneath the checkup layer, we're plugged in the NIN library. An Indian library that runs in the browser It's a TypeScript library that essentially, packages, the the stream requests in any packets and just sends the the the requests as Indian interest packets. So basically replacing the networking layer of the shaka player with with an NPN interstate exchanges. Okay. I see. Thank you. Thank you. And then they so a couple reflections. One is by the way, this is great work. I mean, I I we've really needed stuff like this pretty badly and, hope it I hope other people glom onto it, and we get a lot more work done. But I I had 2 quick Yeah. reflections. One is that as this stuff may sure is we have to realize that the instrumentation interests of the application developer aren't necessarily aligned with the instrumentation interests of the network operator it's operating the forwarders. So often if you're building or operating routers, you don't actually want to spend a lot of energy to debug people's applications for them. So I I think we need sets of mechanisms that are"
  },
  {
    "startTime": "01:06:02",
    "text": "properly tuned to the needs of the 2 sort of like sides of this equation. And when you mentioned the question of where did my packet go, you really ought to look at the path steering draft because that path discovery we'll actually tell an application where my packets went. So if we get that implemented on MDN, applications will in fact be able to ascertain where their packets went. I didn't I didn't hear a question. Could k. Yeah. Yes. I did read. I did read that draft. In fact, I sent you some some a long time ago. If you remember, But, yeah, sure. And they've been accommodated in the latest draft. So, so, I can always At least I hope it has because it's about to be published as an RFC. So we'll we'll take that under advisement. Yeah. Maybe it will see maybe it will see some implementations some implementation in the May forwarders, and and we can we can leverage that for sure. On on the 1st part of your the first part of your comment, I I completely agree that the needs of the 2 sets of groups of people, eventually will not they're already not aligned, but eventually, they would probably get less and less aligned I think, however, we're it's early enough right now that we should probably prioritize the needs of the application developers because it will be the application developers that push NDA forward and allow you know, the the just the increase adoption. Think it's it's critical that we increase adoption of NDA and and until the application developers develop applications until there are more applications"
  },
  {
    "startTime": "01:08:00",
    "text": "based on NDN, that will not happen. So we need to make the ecosystem as easy to use as possible and as easy to debug and troubleshoot as possible. So that's, you know, at least the early on that's what should happen, I think. But I agree with you that eventually the needs will will will we'll be we'll we'll have to, you know, balance the needs of the 2 groups of of people, or users. Thanks. Okay. Then there's another question by Yeah. It's here from Jangang SunLab. And, it's a good walk. When do need some real traces. I do not to do research evaluation. Maybe we need, Like, some models to scale to different parameters, different situations. So is is there a future plan to building some model with these real traces, that's that's a very good question. Actually, Yes. We we we don't plan to do that ourselves. But it is something that we discussed at great length, at the very beginning of the project we thought that that would that was something that, we should do. Then we moved, you know, we kind of had to choose and pick what we would work on and we couldn't do everything. So we're we're we're not our sell right now as as things are And with the manpower we have, we're not planning to directly work on that, but we hope that you know, our work enables someone else some other groups some other researchers to do that. I think that would be very useful. Yes. Thank you. Okay. I see. Thanks. Thank you."
  },
  {
    "startTime": "01:10:03",
    "text": "Okay. Then, yeah, thank you once again, and really useful work. Thanks for all the questions. Thank you. And, so now we are moving into the territory of a ICN. So we know that you know, many applications it from a data oriented and oriented, model and data and networking. And there's a sweet spot of applications that you know, work, did you or anything, but also require, some principled way of, in network computing support. And so this is exactly what the civil machine learning is about. And so next we have Kirhan talking about some ideas this direction, called a collective communication. Me bring up the slides. Thanks, Doug, for, for the introduction. I'm currently from China Mobile. And, today's topic is about collective communication optimization. So previously, we submitted to drop to TSB area. And that's, thought the the applications listed in the trust may be interested to to I see Nagi. So I and today I will present this topic So next slide, please. So what is collective communication? So collecting communication is a term that is used in computing, area. So it is used in a parallel computing. It defines, enterprise process communication model that used in distributed AI model training and high performance computing. So you can see that there's a there is a word collective inside the term because it will involve a group of processes, participating in the collective operations. So is it will you know, include several behaviors like one to all"
  },
  {
    "startTime": "01:12:02",
    "text": "auto 1 and auto auto auto mode. And, the behaviors define, like, data reduction and data movement and also data synchronization between different processes. And you can see that the use case in here in the draft, but, we we it can be used in a distributed AI model training, and, pick data analysis like, box shuffling and also it can also be used in distributed storage. So next, please. Yes. So what is the problem here? So basically that that, currently, the implementation in the underlying network of these collective operations, it's realized in a point to point mode. For example, you can see that, the in the upper, in And in in in the upper, phase of this, slide, the collective operations define several logic like, the process 1, we'll send 3, 3 pieces of data to, different 3 different process in the a far away. So in the underlying network, host one needs to send, the same data pieces one by one. And also, you can see that on top, 3 different processes and will generate 3 different pieces of messages and they all send they're all sent to process 3. At Farway. And also in the on the line network, a host 123 will a need to send a 3 different pieces of packets to the other hosts that, one by one. So this mode will inevitably, you know, lead to some, bandwidth occupancy and also a large overhead in in the applications. So it will, inevitably leads to the women's degradation. So next slide, please. So what we think that to solve the problem to reduce"
  },
  {
    "startTime": "01:14:03",
    "text": "the the data movement to save bandwidth So, one potential way to solve it is to offload. There's a different collective operations into the network. That is to use a network node to act as a whole to monipulate on the packet, do some processing capabilities and then improve this performance. So next up, please. So how to do this? So, there are some design issues inside the protocol design. For example, in the minute 1 mode, there are some, transport issues were listed in the drops and also in one group mode, as I said, that currently in the underlying network. This data is sent, you know, in point to palm mode, which which means that we should design some mechanism like Met ip multicast to, you know, to transmit the message but maybe IP multicast, maybe they're not the bad, may may may not be the best, but there is a need to design such, a mechanism. And also in the drops, we list some design issues in the the management and operations, Next slide, please. So, regarding the transport issues, The first one is reliability. So if you want to so currently the network node the intermediate, the node, we can they cannot do the computation because they are not aware of the messages it the the the package sent So the current point to point end to end reliability mechanism cannot work well in these, scenarios because when there is packing loss, when there is retransmission, of the packets, the intermediate note cannot may not be able to, you know, So to get the, correctness of the computation It may be, you know, when they wants to do the computation of a 1 plus a 2 plus a 3. It may, when the packet is lost,"
  },
  {
    "startTime": "01:16:00",
    "text": "it can only perform a 1+a2 or If the package packets of a 3 is transmitted for twice. So it will, you know, the computation may be a 1+a2 and then plus 83 for, twice. So the computation needs may be, affected. So how to solve this we need the intermediate network node to be aware of the messages it, you know, through the competition on and also the transport function needs to be extended or it has been modified to to help, and reach, to help solve the problem. So there are 2 options. The first options to build to make the network note, have the full transfer function, that means we can we need to build establish the transport session between worker to switch and the switch to server. But in this way, the switch needs to be it needs to maintain food transport functions and stays and the the the their native lot of space inside the network node and also the encryption will make it worse. So another way that the intermediate node doesn't act as a endpoint So the end to end principle is maintained But in this way, the switch doesn't need to maintain, full transport function states, but needs to be aware of the operations. It needs it should perform on the packets and needs some lost recovery and the correctness guarantee mechanisms. And next up, please? So in terms of, Sorry. Sorry? On next slide. Is this the last leg? No. Actually, think, some slight meet echo hiccup here."
  },
  {
    "startTime": "01:18:01",
    "text": "Let let me try to reload this. Let's see. Yes. So, I will go, quickly go through it. So for the intermediate network note, it needs to, you know, be aware of in messages of inside the, collective communication. So there was a semantic gap between the message carrying message sending in in collectives, between the, and the the upper on the layer on the line network, the the packet's transmission. So what is the semantic gap because the message is it has no limitation of its size but the package, it may have some upper limitation, like MTU And also, it will impact the, like, the the the network node, you need to find a way to combinate to compute and reaffirm the the different packets into a whole message to perform So it will, impact the the the the switch buffer and end to end message sending rate and also other relevant issues which will impact the transport, function and the performance So there is, it is a semantic gap between the a message sending, passing, in the collective operations and the the underlying network. And also, we have defined some, like, transport issues listed in blocking and non blocking mechanisms because it will, it will, it will, it will, this, mechanism should be adjusted went, to the one with want to introduce the network computing or collect your operations offloading to the network So, these are 3 prospectus, we list it in the drops, about the transport issues And these transport issues, what are we are they major issues we wanna talk about in the"
  },
  {
    "startTime": "01:20:03",
    "text": "manage to one mode. So, yes. So how's the network working for everybody? Because I don't have any connectivity on the IITF network. Okay. Yes. And so if, if the the slides is okay, I think I recommend people you can, view the slides on your laptop, XC. Yes. Okay. Sorry about that one. I'm back online. Last page? Yes. Sorry. Previous page. Previous page of, one? Previous one. And to slide previous. Yes. That's fine, please. Yes. Rec recording 12 all mode. So that's what I said that we need, low latency, multi destination delivery mechanism, maybe like, IP Monica to know, to improve the behavior of, the one to all collective operations, but maybe IP Monica's may not be the the good one or but it's still worth trying. There are some like, standardize, they standardize IP multicast protocols, like beer and the team, may be able to extend it to support, but, within the scope of ICN, I I think that another mechanism to implement 1 to all mode. So"
  },
  {
    "startTime": "01:22:01",
    "text": "I think this can be a reference. So next slide, please. And, also, we, in the, design issues will list some of the, issues relative to the, the the the management and the and the the operation level, like, and and data and control, because, you know, when you need do some network, computation within the network. The the controller or the the control plane is know, what operations what behavior you wanna do. So, relative in network primitives will be stored or will be defined in the applications But currently, the in-depth primitives, it designed for different applications case by case. And we call it a chimney mode. So we we should have a more standard definition on these in app primitives to avoid wasting network configurations like, the common data structure and a common data type to implement this different, collective operations used in varaya's, applications. And also about the the the network topology and to, you know, there is already some already defined topology awareness and algorithms but currently, these algorithms are not and designed with, I n c natively. So the new at the topology awareness should be based on collective operations avoiding. That means when we, you know, when we want to do some computation inside the network, we should know, it's it's especially when the network scale is very large, and we should know that, what network nodes should offload this operations, and we need the new algorithms For example, in classmate topology finds the most suitable and natural tree node for offloading. There's"
  },
  {
    "startTime": "01:24:01",
    "text": "operations is very helpful. And maybe the switch memory and distance and available issues will be concedered in this case. So next slide, please. Yes. So for this, different, and, you know, design issues. We have a listed several requirements or a protocol design. And, here are the details, I will not go you know, due to time limitations, I will not go detail into all of this requirements, I can view them in the drafts. Next up, please. And also in in the draws, we have, prevented a pre presented some analysis this analysis and not technical analysis, but some, you know, analysis at the only the other ongoing work that may be interested to this topic, first talk, NASA is a koi. Because there is another research group. So the coins mainly investigate on how native work a network data plan programmability can improve the internet architecture and also, it, you know, covers a broad applications like network function offloading, like, in network control, in network caching, and also the machine learning acceleration. So it its application is very broad. And also that, in our case that we focused on the collective communication the offloading. Right? So it's an it's necessarily not necessarily designed with natural programmability. These capabilities can be, you know, embedded into the network So another work is presented in the industry as originally presented by, Mellanos and then and currently is, you know, embedded into nvidia's, product products called, Quantum 2. And the this app, a technique is called Sharp."
  },
  {
    "startTime": "01:26:04",
    "text": "Scalable hierarchical aggregation and reduction protocol. So collective operations like our reduce, our broadcast, and others, afford it to, the switch, and that's embedded in in the this whole, they call DGX, AI Computing like, it's a giant server. Right? So currently, you know, this technology is sharp is based on InfiniBand Network Architecture. So there is interoperability issues with the internet, open internet architecture. So not the, you know, group or, SEO is called the UCX. We investigated. This, this group is unified communication framework So it focuses on designing a framework for collecting communication implementation and address the cross platform functionality and form is portability challenges. So it focus more on like a building or common platform that different underlying network architecture or different underlying network. You know, a protocols can all fit for fit in this, you know, framework. And also, it can based on the the framework is can, you know, provide some common APIs for different programming models which include collect communication, like MPI, OpenMPI, and pigars and also other terms, which is currently used in the computing parallel computing, no community, but I think in the not, in the future, not far away. This, you know, these models may be used into, like, a distributed AI networking. So that's the analysis part. And also, finally, we found some we also discuss some, like, like, issues in the security and operational considerations And, if you wanna do offloading of these collectives, it may introduce some security and privacy concerns"
  },
  {
    "startTime": "01:28:01",
    "text": "because it will definitely impact data the integration of the integrity and authentication. But, you know, since these applications are performance driven, it suggests you to deploy this techniques in limit domain first because there is, it does it does not have to and pay the penalty of, expensive crypto or authority operations and applications can choose to trust the network within the limited domains or they can trust, the the in the network and applications and trust mutually So I think, these techniques can deploy in the domains for on the application first, and then maybe we can introduce some security security, security, mechanism insight and extended of internet. Yes. Next up, please. So, yeah, finally, that, quick broadcast of, upcoming set meeting on Thursday. We will talk about this collect communication of loading issue in the technologies and protocol designs, relative topics on the side meeting is it will be held on, the on on Thursday, the the 12:30 to 4, 14. So the agent has been published on GitHub and also there is a online meeting Webex tool for you to join us. So we'll come from discussions on the contribution. Thank you. Thank you, Kim. Thanks for this introduction. This question by Mark. Yes. Hi. Hello. So you know, It it it's hard for me from from from this presentation to figure out you know, kinda what the target of this work is you know, people have been accelerating collective Collectives. So, I mean, Finnebanned"
  },
  {
    "startTime": "01:30:00",
    "text": "you know, omnipath. Cray switches, you know, the now HP Enterprise. You know, all of that. So I mean, is the goal to figure out how to do this more recently at an IP layer versus custom layer twos or or what's the target? Thanks for the question. I think it's a very good question because No. You know, yes, as you said, I IP InfiniBand and Cray Slingshot they have very, you know, good solutions from the top, from the very bottom, like link layer, to the upper layer to the transport layer. They have, you know, host stack solutions. So for us, we want to present the work to why to, IETF because we want to introduce light like, the internet architecture to, to be suitable to the application for distributed AI training or other application that will be, widely deployed in the open internet in the future. So I think it's a good opportunity for internet to think about how it can be evolved to suit, for these applications. Thank you. So, one more call, so some, one more one more thing to say that, we will focus on and postcode design on transport and also maybe, on there are some relevant issues in the the IP layer So I think it can it's a cross layer design. So I will just today, I wanna present, there is a design space. So but, what how to limit it in our specific area where we'll on move the work, to the future work. Thank you. Okay. Next in line is colon."
  },
  {
    "startTime": "01:32:09",
    "text": "Hi. Colon Perkins. This is this is working right here. Hey. So, an interesting talk. I think it's Good good to discuss this sort of work, very, very widely. You you mentioned that that you you know, you you just mentioned sort of evolving, you know, the the internet to make it suitable for these of application and you mentioned, sort of the thought there were some limitations of the the IP layer there. And, I mean, you're in the in emission centric networking research groups are presumably you think ICN style protocols that can can help here. Yeah. The talk focused much more on, things relating to my cast and possibly reliable multicast. Can you maybe elaborate on how you see the ICN protocols or or ICN style for calls, helping. Yeah. I I know what do you, because, you know, these applications, are very, you know, may be interested in ICN, working group. So But, you know, I'm not the guy very, you know, so I'm not a specialist in ICN, so I might not have the the, you know, I'm I'm I'm I'm I'm not maybe the right guy to answer your question like this. So but I think the these topic may be interest to, I think, so sorry. Yeah. I'm not so familiar with. I see So maybe I can quickly step in. So, So the intuition is that, So this, say, multideastronase and push could be also seen from a different perspective, in using these, like, the implicit ICM, kind of multidisciplinary"
  },
  {
    "startTime": "01:34:02",
    "text": "feature request, response based, And, so that would give you potentially the advantage that the, say, the application or the the note does, actually, doesn't have to care whether it's a, like, multicast group UNICAS transmission. And, so could be attractive for, also, concluding these applications. Yeah. Sure. And and and then and that that's what that's what I was expecting it. Yeah. So to be something like it would be interesting to discuss some of the details. Right. So this is just the first introduction today. But, yeah, I'm I'm totally agree. Yeah, the the other point, I mean, you you mentioned that, you you thought it would be a appropriate to deploy this in limited domains initially. Because of the the security and authentication challenges and so on. And, you know, if if you're building a product, I suspect that's exactly the right approach. Again, since since we're in a research group, I I would encourage you to think about you know, the research challenges around how to make you you you broader deployments feasible, and to reduce the cost and the challenges of you're doing the security and, and the trustworthiness Sure. Thank you Okay. And then we have to I think that the issue I have in mind, the column already mentioned. That is the security. I don't know if you remember. I was sitting at this, CCO tibao, someday and the hack sound thing. Brought up the security question. It's a great that you have a slight on that, Although, I'd like to see further elaboration exactly what You people plan to do addressing security challenges. You mentioned that this design largely focused on the transport. As you know, to this transport, No doubt is using plain CCT anymore. Mhmm."
  },
  {
    "startTime": "01:36:00",
    "text": "SOTLS. So I don't think one could just say, oh, the the trade off. As the answer, I think a security it's not the option. If you plan to do this, over distributed environment. It is a must. Thank you. Thank you. So for a full comment. Yeah. Great. I mean, to to be fair to to come, I mean, this is, the very first interaction of this topic, to the IRTF IETF community and so this is basically just opening up, all the options And, I think it was great to get this feedback. So So we think that there is a really good work, that ICN con con con can contribute in the selection because what Lisha said is, is, Yeah. Very correct. So the current, say, really performance oriented deployments in data centers. They are partly using TCP, like, RDMA, like, protocols, And, they don't do security because it's too expensive And, so a new protocol design could, maybe try to marry this, different concerns of performance and security. And I think that that's interesting challenge was Thank you. Thanks, Graham. Okay. And, So we are continuing with, like, distributed computing. And, are not talking about, microservice architectures. And, I'd like to welcome, shooting to present the topic. Yeah. Can you hear me? Yeah. Let me just give you the control. Yes. Hello, everyone. My name is searching. I'm from China.com, and my top"
  },
  {
    "startTime": "01:38:02",
    "text": "today is, an area of distributed architecture for my Christian race communication. My presentation will run this as part occurred in background and the motivation overview of our architecture and some come comparisons and the future development considerations. And the is the link to our draft. If you are interested, please feel free to the very and the next page case you you can control the slides yourself with your Kusokies. Oh, yeah. This is July land, Can you see the second page Yes. We see service mesh concepts and challenges. Oh, yeah. And, in recent years, with the rapid girls, of micro stories. And the seismized has played a crucial role as a case washing, microstorage communication, and the minute on each is to automate and manage communication of microservice provides that capabilities like security, observability and traffic management. And, the following thing, there's just a volitional service governance patients. And the the source governors capability has involved with recognitious, you know, for me, current source, mice, And the the first enbiting business coach, and it consolidated into SDKs. And the note that's integrated in choosersmice"
  },
  {
    "startTime": "01:40:02",
    "text": "And do these changes towards the governors or scholars? From business project, focusing on infrastructure and tricks solution. But The ServiceMaster still has some problems and the challenges And, this figure says that capture of the this team is still so smart. And, it's realized, it's realized on proxies for to own traffic and, use the palette component. Is a control control source registration and to retain those this centralized approach can lead to potential issues such as perform Botemax a single point to failure risk because I could disrupt the entire sorts of mice and so And, considering that above 10 year and turn our telecoms 20, 7.1% year on year growth. Means a cost to raise market. Way repair on innovative solutions that as for the dump to chisel contouring, going through Mars of my crystalized communication, and the feature in source telematics capabilities and problems. And, offer flexible scheduling capabilities. And the most important as should the information center communication and just because, networking moment is ongoing on a presented transformation resistive towards, Zentank Centric Padepardem come crystal made prominent."
  },
  {
    "startTime": "01:42:00",
    "text": "And during the course of this revolution, so a small sacrifice as a or extension architecture, which aligns with the goals of, informations and tree net works. And the buyer combines, can content centric nature of is a source the centric folks, are surmised. We can't achieve a higher degree of contemporary sure of, a content and socialize, prepare I'm at Christopher's network. Towards promote distributed, hala, adaptive, and vision, communication, architecture. So, we have pro proposed this item dropped. That wants a new communication of texture called distributed architecture for micro storage communication. And the My purple is a drug to propose is to combine that Information concerning that for conception. So it's much to has the overall performance your liability of my crystal is communication. And, dear Anselia has following kind of terroristic such as content centric. It's prioritized content and stories. And, it's distributed, protests processing and thorough collaborative by a source gateway on roaches, and, it's kinda optimized to restore the patient, solar mass, sculptrinous interim. And, it's a context that involved in one out on that one. So here are more details about have our PMC"
  },
  {
    "startTime": "01:44:02",
    "text": "And, our architecture, because this job are okay components and trade source gateway. It's Monday control communication traffic, And, it's a up to mass routine based prefix and the project. And, there's pre perfect thoughts and passion SPA what it's it's It can validate perfect usage by microsaurus. And, Service Miles Communications Veterans Center is Kyle team, optimizing, application process. If In some way, I've had our architecture decentralized through team decisions where So it's which way I'm supposed to return and looking optimization with as they say and then you know, it's the security, they are perfect, self impatient. I need to ensure a smooth communication to Virgo's components. We have designed it so following my stage of to your subtracted location component, Shaza, extras issued to to ensure propagate transmissions or network and, is, detailed information on this nearly messengers. And, such has been it should hold out a certificate way. It sounds perfect. It's an announcement. And, My crystal is the same is called communicate serials the Swiss prefix to the SG And, the test and, surveys is the source prefix essay."
  },
  {
    "startTime": "01:46:02",
    "text": "And, as didn't ask for at work source perfect and of drilling literary relationships. It's the courage and, it turns as agenda as PA, this safe, service, prefix, authentication, So I still set a third case to the SPA requires demand code is a that is psycho. And, mouse, SGSR, and as I said, this, Mhmm. This is source pure as tenant chef, source pure as pro sick And, this plan from a patient called 2 reporting process between microsaurus choose, I say, And the next is a tech, orchestration process in GMC because this is a delay. I'm sorry. Can you actually We are now looking at slide Number Eves. Comparison between the aim, Oh, yeah. Yeah. This page in this page and the communication process begins of contributing and the first time my pre my personal race little tidbits there, neonics, so it's perfect to connect us with Getways and to them. Service goods we work by. So it's perfect. So it's always perfect."
  },
  {
    "startTime": "01:48:01",
    "text": "Link the the advertisement And then we use, to communicate with the source routers and, Azer, the macro survey center, this is reason. Sound similar, process for a notification And so it's good to interact with So it's filtered to generate mixed text interface, with recent discoveries, perfect, links data, advertisement. And, for working information with cats transact it's fantastic for loading and rooting for Optima Optimum has select And Once the components is a control free complaint talk our our our coordination and decision making the swerving team again, should have backed when the pack director runs this risk free, it's sent back a bus pass and next home called according to the real sensor, for work information, please. To forwards, the package, choose a topic, 1st. Target macro stories, And the units raised a source case for non service worker have a couser to work gets packets, allows, up to pass ensure effective efficient transmission and crack the road tool of traffic. And, I'm gonna ask some comparison between James Diana's Joseph's Mars. And, compared to a still personalized DNC can and and and not only achieved a minimum options of traditional Swiss mass"
  },
  {
    "startTime": "01:50:00",
    "text": "but more important parts information and took medication lesser. This provides a new approach for the evolution of filter filtering that for which is to implement information and turn that for from the net forming 1st chapter level So we have chosen to process. Propose such, distributed architecture instead of using original resource from Mars. And However, However, our president, for the whole architecture is Julian and preliminary stick, and just has not cured for the metrics or for a way undertake undertake a significant amount of works for to further refine the phone is, timeline for our project. This includes some current work and filter considerations And, no, no, of Well, act naturally fine and, would cause to find the architectural of our, distributors distributors or masks encouraging distributors, approaching approaching culture quotes. And, Zara Way pass it to a lot of pitch risk resource to invest in research and the dark and then a response to corporates with electric sense of field of seismized find, other automate appointment of dancing. And here are some references from our draft"
  },
  {
    "startTime": "01:52:04",
    "text": "that's a main content to a virus King, and, any call that's preferred for to contact me there are female sanctions. Thank you very much, sweetie. Okay. Do we have questions? Colin. Hi. Colin Perkins again. I'm sure I'm not the only one who quest I'm, so, I think this is great. It's it's something always interesting to, hear about, people trying to build live scale systems using the ICN style criticals. I was wondering if if you could maybe say a little bit more about how the, ICN concepts were applied in the design and and how they helped or perhaps about what are the ongoing challenges you see? In in, applying these the the style of, protocol in this domain. Did you understand the question? Yeah. Yeah. I heard and my network is not good here. Will improve can I ask my collections that you had been hours versus production? Yeah. Adrian from are understanding your question correctly, you ask what trend, yeah, we are faced now to accomplish this"
  },
  {
    "startTime": "01:54:02",
    "text": "Acetra? I guess I was asking either how how could say a little bit more about how ICN protocols or ICN style protocol helped. Or or what are the problems you see with applying these ICN style protocols. You know, I mean, yeah, you you seems to be building a really interesting system. I just like understand a little bit more about some yeah, what what are the challenges? What are the successes for this this type of approach to building this sort of system. know, the main aim of the You proposal is 1 to build 1 infrastructure to facilitate the communication. Even the server, different maker service. So, currently, the the the infrastructure is provided centralized centralized, infrastructure, like, install. And, there there are some problem for the No. Excess accessibility and the, mandibility. So we we want to or to the similar service, while the distributed architecture, and the and the key point, that we want to use the ICN technology is currently, the maker stories, the communication is based on the based on the URL not not based on the, IP IP address. So this is the the same aim as the ICM. So, you know, we have designed the SDG and edge router as our router. We, you know, if as if as are there, the for the traffic based on the content or business content, not, the IP address. So, maybe you're and the most challenging things here, I think it might be the"
  },
  {
    "startTime": "01:56:02",
    "text": "extensibility are all the all the for the efficiency of the ASR route because it they are forwarding the traffic based on the, you've based on the container and I suggest Okay. So so the challenge is doing it efficient name basically. There are some person. Folks on the research and the challenger. So I think they have some solid pay, experience to solve the challenges. So I think we have the confidence to talk build such resource infrastructure, step by step. Okay. Thank thank you. Yeah. Maybe one, related question. So when you want to design something like microservice systems, using ICN. There are, of course, different design options. Right? So and So here, it seems you, using, like, kind of bespoke entities. So like service gateway and, and these kind of things, that seemed to be inherited from maybe the existing microsource architectures a little bit or from some, maybe, deployment constraints. And I was wondering, since you are, apparently at the beginning of the design phase, would you also maybe consider different design options so that, maybe even more distributed, maybe require less of, the Facebook, gateways, entities, and so on because there have been other, other work in an ICN for distributed computing and I'm just, I think for maybe if we discuss this next time, it could be good to understand"
  },
  {
    "startTime": "01:58:02",
    "text": "the constraints a little bit and maybe also discuss different design options. That's that's my my comment. Yeah. Yeah. I I can't really see the the the drop the proposal for our architecture, I think we can and incorporate other element from ICN to you have the line of the Overlock data. Okay. So would you be interested in getting more feedback from from the group on, like, design options for for this problem. We we just want to find the some entity to Well, to implement the I see him paste the, ROTIA and the body. So I if if there are So many of you can provide such such product or protocol product that we can build on some, some protocol network to to verify the concept architecture. Okay. Okay. Thank you. And one more question by real. Hi, Rio Yanagita University of Glasgow. So one of the design motivation or at the aim was the end to end telemetry, So improving on that end. Given the earlier discussions, we've already talked about how difficulty test to trace things end to end. Do you have any particular, maybe approaches you're thinking about trying to solve this issue because I think it's it's a challenge that I think a lot of us are already discussing here, like, throughout the research group. Yeah. We we For for service elements, we just want to use current, traditional solution because you know, our design architecture the the service telemetry, it also"
  },
  {
    "startTime": "02:00:01",
    "text": "I can't place the or why the central either solution. It is a this is a similar with the kinds of solutions. So maybe maybe the the SAS entities, you know, send some tendency, command to the to his end to his head and and the service is a hand and indicated the service taste the required. So it's called tested required for the service, the And and then report the result to the s to the centralized entity. Is a traditional solution. We're helping. Optical, for such a designs men men folks on the zeolization of the writing architecture. Okay. Great. Thank you very much to all presenters. And, just, a few pointers at the end. So there is, a metaverse site meeting today. If people interested, and that's at 3 pm in, call in 4. And, just a quick reminder. So, in addition to, the, collective communications meeting that Kehan mentioned is also So say, a more say, a hardware or performance oriented, meeting on, AI and data center. So that's, also today, at 5 pm, Thank you very much for coming. And, yeah, looking forward to continuing this discussion next Bye bye. And thanks to, Dave and to Mark for for joining at this crazy time of a day. Take care."
  }
]
