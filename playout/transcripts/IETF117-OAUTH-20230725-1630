[
  {
    "startTime": "00:00:10",
    "text": "when when 2 I answer. Okay. Let's started Level One second here. 1. Maybe you're with myself. Yeah. level 1. Welcome to the 1st meeting. So Before we get started, I would like to mention that we have blue sheets So I'll I'll start this. please make sure to use this or Just use the the one on the screen. Thank you. We need this to make sure we know who's attending and for you to be able to And contributor or join join the mic and Right? So so that's important. Hannes and Kalea will be helping us with the taking notes. Thank you, guys. appreciate that. And So we have as you noticed already. We have three sessions. This time, And the thanks for to Roman for happiness. Get that third one. So we have lots of topics and and we used to have some side meetings, and now we have 3 meetings and then appreciate Romans help with this. So and and Roman will"
  },
  {
    "startTime": "00:02:00",
    "text": "have some some words here. Good morning. Yeah. If I could just have a little bit of an administrative note. I mean, I got the feedback loud and clear up to this disappointment about how to play the side meetings. one of the things I try to do is I've worked with the chairs and kind of an armament with the ISG to do you know, more tracks, kinda more days at the IPF, have special slots for potentially working groups that want even more to to really kind of overflow. weren't able to kind of pull this off. and we have a kind of 3rd session. So the the signal that I'm really looking looking for is is 3 enough or you really want even more sessions than that because if we have a more long ranging plan looking at Prague, we may have, for example, flexibility with that venue that we didn't have with this one because it was it was actually kind of so near in how all that all that hotel contracting goes. So, Osidio, I would love to hear maybe by the third meeting is do we feel like that was enough in or is it would you have wanted 4, would you want it confined? Got it. And that'll help me decide whether I I'll carry the mantle. really kind of push forward for something very know, very experimental for even more time in AT. Awesome. Thanks, Ron. Appreciate that. That's awesome. Okay. -- area, anyone? The OAuth area. Yeah. Okay. that's good going. So the well, again, this this applies here. So the know well. governs everything that we do at the IETF. from IPR to how we interact with each other. if you're not familiar with this, please pay attention to this and and go review it. Hello? and meeting tips You probably have already familiar with this. If you're in person. So use the the light tool to log in"
  },
  {
    "startTime": "00:04:03",
    "text": "and use that me take all applications to join the mic. And please keep the audio and video off. if you're a the moment, And make sure that a audio and video off unless you wanna speak up. And we hope that you could use also a headset m we strongly recommend that. k. Okay. Quick update on the latest. rc9278. or rather rich authorization request was published m a few few weeks ago, few months ago, that that's that's I mean, Few few months, I guess. So congratulations to Thorsten and and Brian. So Thank you for for your work on this. Appreciate that. we have 3 documents in the RFC editor queue, DeepAP, step of authentication, and your response for token introspection. That last one is still waiting for the security PCP, which is now with Hannes and Hannes We'll start working on this soon. gonna say anything about this, Harnesh. Very good. Yeah. reviewing the document. There were few changes since the last review the version. But, obviously, a lot of work has gone into that, so it's It's a very solid document. Trying to figure out that. k. Okay. Few announcements."
  },
  {
    "startTime": "00:06:02",
    "text": "you probably heard or some of you at least heard about that I am ident ID identity program. So few of us have been talking with IAB about identity at the IETF in general. And the IAB has decided to create a program around identity. aim. And Chris would will be talking about this to today, actually. at 1:1 PM at the IED open meeting. So we encourage you all to join that. And Colin and I will be talking about this also on the SAG meeting. on Thursday at 3:30. this is a big deal. I think If you wanna shape a future of identity of the IETF, you better show up there. Right? So that's your chance, guys. Right? So it's it's great to see this, and we hope that you guys all participate and and contribute. Yes. It is. Yes. I IAB open. that's yes. ID open, and it's part of that discussion. Okay? k. k. a or security workshop, and this year is gonna be in London. and the registration open. So Please please register if you plan to attend. Okay. Our agenda for today. Christina and Brian will be talking about SD Jot. Aaron, which I don't see him yet here. Oh, here. He's is hiding there. So he will talk about browser based app and all to that one Mike will be talking about resource server metadata Peter will be talking about cross device flow."
  },
  {
    "startTime": "00:08:00",
    "text": "And Hannes will wrap it up with the attestation in DCR. So that's for today. we have tomorrow tomorrow's meeting. So this we'll be talking about job embedded tokens. tool will be talking about transactions tokens. Peter would be talking about trust to main identity chaining, which builds on the above. And I'll be talking about 1st spot in native apps. and on Friday, and notice that we don't have Thursday meeting. k. So it's today, tomorrow, and Friday. and Paolo will be talking about European Digital Identity Wallet. All of what we're talking about is the jot based verifier credentials. Tobias will be talking about JWT and CWT status list and authentication based client authentication, At the station based client authentication. And if time permits, And Tobias will be talking about also about client ID scheme. Any questions about the agenda? what we're doing, Today, tomorrow, Friday, Tek. Gonna say something. Dick is good. Life. I just wanna say that the overlap with GAAP on Fridays very, very bad. Yes. Wood. Congratulations. Like, if we're clear, I'm used on my Yes. posting a post on a note that pitches me from being there, and I'm actually one of the few people is actually involved in the that you, ID, wanted work yeah, I take responsibility for that conflict. The only way we could get a third slot is if I told the secretary, we will accept all conflicts for the for the 3rd slot request. That was where we put it. Yeah. Thanks, Ronan. Okay. Let's start here again."
  },
  {
    "startTime": "00:10:04",
    "text": "Now let me just stop sharing. And Christina and Brian. You wanna join us here. Okay. you wanna drive it from there, or do you wanna drive it from here? I wanna drive it. I don't remember. that request. I I just sent you Let's see if you can work. 4x, I think I screwed it up. Yeah. Let me try it again. That was my fault. Maybe I'm not chatting. Hold on. Access. it with you? it works. Yep. Perfect. Alright. Sorry about that. technical glitches interrupt inoperability by the user here. Okay. So I'm here to just talk about SD. Selective discloser for JWT. on behalf of the working group and my distinguished, coauthors. So we'll jump right into it off of than normal. photograph of the city. That's kind of my MO. So just a real rough agenda for what we'll be talking about today. I wanna give a brief overview a refresher, I know it's always hard to sorta come into these meetings without any context and kinda pick things up. So I'm gonna try to walk the line wines, providing a little bit of overview for those of you that might just be touristing the session while not going to beep or too much time for those of you that that knows some of the contents. about the changes since last time overall and then take a detailed look at few of the more specific changes since last time, and then just"
  },
  {
    "startTime": "00:12:00",
    "text": "take a little bit look ahead. So Generally speaking, SD Jot is a mechanism for the selective disclosure of individual elements of of JSON object used as the payload of a JWS structure. And, really, that's a lot of words. It's really about selectively disclosing JWT claims. You know, Jot is a assigned token. you can't alter the content of it without breaking the signature. So SDJOT as a mechanism to allow for pieces of that token to basically be redacted or selectively disclose without altering the signature. some of this awkward wording kind of comes from the fact that we're playing with this world of what is a JWT versus what is a JWT or JWS and kind of a or JWE, so it's a little bit awkward. But, really, it's a it's a select disclosure mechanism for JWT or JWS with with JSON payloads. that was a lot of talking without saying much. But I do wanna reiterate that Carry on. Thank you. Thank you. I'm struggling up here. That simple is a feature There's a lot of different ideas and approaches out there to doing private preserving schemes, selective disclosure, and so forth. The goal of DJOT is to build on existing techniques and functionality that the world and developers are already familiar with provide a relatively simple mechanism to do SD selective disclosure. within the constructs of Jot and JWS in the Jose world that that that is already widely deployed and well understood and do it in a relatively simple way. So quick recap here. This is an SD Jot. You have your normal Jot construct of the JWS with the the header, payload and the signature, and the actual select"
  },
  {
    "startTime": "00:14:02",
    "text": "disclosure mechanism comes on the end here with these the parts in green, which are tilde sub rated, base 64 encoded chunks that we call the disclosures, Breaking those apart a little bit, decoding the JWT, Within the payload, you have an underscore SD claim that itself is an array of hash values Each individual hash value maps to and ensures the integrity of an individual disclosure item. And the disclosure itself is a base 64 encoded Chunk of JSON that contains the claim name and claim value as well as a random salt, that prevents sort of reversing the hash from from brute forcing and and guessing the hash value. so you can't go from just the hash value to understanding what the claim is, And the Obviously, the name and value of the content are within the within the disclosure, and they're mapped to the signed content is over these hash values, within within the actual payload. So the Maybe this wasn't a good idea. The holder or the receiver of the SD Jot can then selective select from those disclosures on presentation of the Jot and decide which of the information within it it wants to reveal. In this case, is We've selected only the birth date, which is, you know, referenced from within the the payload itself, take that there. and throw that back on the end of the SD Jot and this is the content presented that reveals only a subset of the claims that was in the original issued issued SD Jot. I'm doing a terrible job presenting. I apologize. The idea being though that you can the the holder can mix and match and choose which of the disclosures actually wants to reveal."
  },
  {
    "startTime": "00:16:03",
    "text": "without breaking the signature, thereby selectively disclosing the content. Do you wanna You know, it's a good time. Yeah. Go ahead. had a A clarifying question. So if you go to two slides before the last one that you presented to before the last one. Yeah. So this one the relationship between The between the the things that are in the underbar SD array. Yes. the relationship between that and The you know and the 2 things on the right side, that is the like, what that is called versus what the string on the right hand side of the screen is called. That was the thing that was super unclear to me reading the document. Okay. the Oh, The on your right hand side, the green part the encoded content is called the disclosure. Inside the disclosures, the actual JSON content of the claim value, claim name, and assault the SD claim within the token itself is a list of digest values that point to the disclosures. and the digest is calculated over the top of the base 64 encoded content of the Of the disclosure itself. So it's both a reference 2 by value because it's a a hash of that value, but also ensures the integrity of that piece itself. if that makes sense. And if there's, you know, ways that could be further clarified in the document, we'd be happy to Think about that. Okay. So some changes since Yokohama. We published draft 4 right afterwards and"
  },
  {
    "startTime": "00:18:00",
    "text": "draft 5 just last month, was in the last month or maybe in July? I don't know. I wasn't in Yokohama, so I didn't get to put a picture of it here. But draft 4 only had one change. Improve the description of of the disclosures. This is a bit of a euphemism for the fact that the there was actually pretty major bug in there that if you read it really carefully and followed it, you couldn't actually do select disclosure without rendering the whole thing invalid based on the the normative wording there. So this was really kind of a bug fix. that went out with 4. try to get that fixed quickly, subtle, but important. And then in 05, we have a larger number of changes. I'm gonna go through them. Try to do it quickly. Basically, we try to consolidate sd.terminology and format. So we had some Yeah. Yeah. I'll get into details a little bit more. The the blue ones will be discussed a bit more in detail. also consolidate the processing rules for the holder and the verifier. We had independent sections different rules for processing the functionality, whether you're the holder or the verifier, and they're really functionally pretty the same thing so we consolidated those. we define the structure of the key binding job. We use the term key binding now rather than holder binding to be more specific that it's really about buying into a key me not a holder. It's a little subtle, but it really was only proof of possession for a key. So we try to be more more clear on that. Added support for selective disclosure within an array element, which is a new new feature, talk about the details in a bit. Added a JWS JSON serialization of SDJOTS. added some recommend sorry. I added initial on a media type and structured suffix registration requests, We added a recommendation for explicitly typing SDJots. added some security considerations about what it means to forward credentials and and sorta"
  },
  {
    "startTime": "00:20:00",
    "text": "maybe potentially continuously redact information. change up some examples to try to make it more clear and make detour decoitte Digest, a little bit more obvious. improved the example around what was allowed in terms of variations of disclosures. It's not normative just trying to clarify the wording. added some text to the abstract and introduction that'd be more inclusive just plain old JWS, with JSON of some of the pain I was alluding to there in the abstract. it's really Jot is JSON in the JWS, this is a selective closer mechanism for JSON and JWS, and the line of whether that is or isn't a job is a little bit unclear, but we wanted to try to make it obvious, continue using the name Jot, but make it clear that you can do this with just JSON inside of a JWS tightened up some security considerations, tech, around the scope of what the key binding jot actually accomplishes which is just to do key binding and proof of possession for key bonding, It's not providing more or additional integrity of any of the message structure. Try to align some example structures try to clarify and continue or consistently use the term input claim set for the the set of content that's used prior to redacting or selecting which pieces are selective due goes sort of the raw input replace one general sd.vcexample, with one based on a a PID from the European Digital Identity Wallet Architecture And Reference Framework try to give it a little bit more real world. meaning when you're looking at it, it and clarified some private privacy considerations, stopped recommending a claim name for envelope SDJots, the name itself. Like, it it was just sort of recommended. applications that wanna do enveloping will are our our our free to and would likely use their own name anyway, so we just pulled that recommendation out."
  },
  {
    "startTime": "00:22:01",
    "text": "We did mention the prospective future postquantum algorithms for JetOS would be supported. It's sort of implied, but we made it a little bit more explicit. We included the public key in the draft that's used to you can use it actually verify the examples now. clarify that the SD ALG Clan can only be at the top level of SDJot payload or doesn't have any meaning unless it's up there. So you only get one hash algorithm for the whole whole structure, and the default being shot to v to 6 that that's there if if it's not specified. And not really meaningful to the draft, but meaningful for other work is the the SDJot library that underlies this and is used to produce all the examples was split out completely from the repo. and is now lives in its own world. And we tried to improve the security description of the security properties a little bit and be more concise about what what the actual re desired security mechanisms were or not mechanisms, but property that were achieved by this are. So consolidating the terminology and format. previously, we had some terminology that was a little bit awkward and hard to use sometimes. The combined format for presentation and the combined format for issuance are no longer used. everything now, the whole structure is just called an SD Jot. You can refer to it in context like a presented SD Jot or an issued SD Jot It's always just an SD job. without these long cumbersome names. And it's always in this format, which is the issuer sign, Jot, the the main chart there that has the selectively disclosed payload within it, the the hash values, the SD under score claim followed by the tilde separated disclosures followed by another tilde and the optional key binding shot. and that final Tilda is always included."
  },
  {
    "startTime": "00:24:01",
    "text": "this was the the sort of the main change at least from a wire protocol level or wire level on the format, is that the the trailing Tilde is now always part of the SD job. And then the the terminology kinda consolidates and and follows from that or or the other way around. I don't know how you wanna think about it. We define some around the key bonding job. Previously, there was a lot of hand waving and saying, you would wanna kinda do way, but there was nothing normative around it. seem like it would make sense to be normative at this level because it could be reused in other context. And so it's relatively straightforward. It's signed. It has a a type value, and it just requires a nonce. an audience and an issue that time, with some verbiage around that it has to be received within a time frame that's acceptable that is yet. issued at, and that the nonsen audience value come from application specific contacts, but this is the the general structure and requirements around the key binding job. We added support for selective closure of array elements. Shown an example here, use a very similar construct to the normal selective disclosure stuff where there's a hash value within the main content that points 2. a disclosure somewhat different in the disclosure only has assault, and the value And within the actual payload itself within the array the sort of redacted or selectively disclosed claim is represented by a JSON object, with three dots, as the name and the hash value of the disclosure as the value of it. giving it some sort of pseudo name spacing and and non likely to conflict ability to recognize specifically disclosure within an rail on that. versus some other functionality. So this gives the ability to"
  },
  {
    "startTime": "00:26:00",
    "text": "within a particular array element, select to disclose individual elements of that, which wasn't possible prior to this. Update. We added a j JWS JSONserialization. which is a lot of text on the screen here. But for general and platinum, JSON serialization wins, There's now a disclosures array that you can place at the same level, top level, next to the payload? Payload? And that contains the disclosures. Those base 64 encoded JSON bits that are the the disclosures without any tilde separate in or anything because we have JSON here. It's just an array of strings that contains the disclosures, And then, also, KB Jot, if applicable, member occurs at the same level. You can see those here Just providing on top JWS JSON serialization a way to serialize these additional elements that that that are defined with an SD job. added just requests. They're not actually registered, but media type and structured suffix registration requests both for application SDJobs media type in general. and a plussd.stuffer structured suffix syntax. syntax suffix registration, and this is useful for being able to explicitly type SDJobs in a similar manner to the way that it's recommended to type Jots in general and the JWT BCP. And correspondingly added language in SDJOT itself to follow the same sort of list of typing recommendations. So SD dot itself isn't isn't isn't types, types but there's a stressors. It could be, but it's not particularly meaningful. But doesn't there's a structured structured suffix for that that allows for application specific uses of SDJOT to explicitly type themselves. I'm a little"
  },
  {
    "startTime": "00:28:04",
    "text": "unsure about the the proliferation of media types for all this stuff, but it's sort of following the the guidance that was provided in JWT and more or less giving the equivalent and similar functionality here. that's a briefish summary of the the changes that occurred coming up in here. Looking ahead a little bit, there's a few open issues documented as of last week. in the in the issue tracker for this work. we need to actually make registration request for the the Jet claims that hasn't been done yet. There's some 3 sort of minor ish example issues that need to be fixed up. and a consideration to improve the the structure of the whole overall doc So there's a few things that need to be done, but looking at it and kinda getting a sense for you know, what's been presented here, the scope of the changes and the scope of the things need to be done, starting to feel like maybe things are are settling a little bit. You do this few times, and you you get a sense that the the minor or the the the sort of significant changes maybe are behind us. there's a lot of coalescence around sort of the main function on it. It's starting to feel like the general specification is is Yeah. Settling ad. It is sort of congealing. I don't know what the right word is. coalescing. Thank you. Doesn't mean things won't change. I'm not calling for, you know, working group call last call or anything, but just providing a general sense that feels like things are coalescing and and and and starting to stabilized nicely. Not that it's been unstable, but but, really, coming to that point. And with that, thanks for your time and maybe, you know, pending travel budgets and various other things. Global pandemics will see you in prague. Right? I've been having a lot of trouble get on the hand raise tool. But And"
  },
  {
    "startTime": "00:30:00",
    "text": "Did you In terms of the array disclosure, yeah, heard to me that the the way the disclosures are listed right now it reveals potentially private information that for example, in your in your example that the person has you know, listers, blisters, Yep. Yep. Yep. and that there is another way that you could do the where wouldn't reveal that in the disclosure itself when you list all the disclosure, somebody would that there are that there that there are any array types or not. curious if anybody had any thoughts about that. Just Well, so I'm not not sure I entirely follow. There's a couple of things you can do. One is what I showed there was the disclosure of the individual or redaction, the wording is hard. The individual elements within an array But that array itself can be selectively the disposable. So looking at just payload of the JWT itself, you wouldn't you could the remove or not reveal any information that nationalities was even listed. within the nationality itself, you could also add individual, what we call decoy Digest to sort of mask or cover up the the true number of redacted content within the array itself. So there's some things you can do to to sort of further obscure what's actually in there, but I'm not sure that's actually touching on what you're question was or what you were asking or suggesting Yeah. Yeah. I Okay. k. Thanks, Ron. Mike, Yeah. Mike Mike Paroc here. Yeah. I think follow on to that. like, length of array disclosure sometimes can actually like, how many items are in there can be an issue. I I like the idea of possibly giving some guidance around"
  },
  {
    "startTime": "00:32:03",
    "text": "you know, how to properly randomize or select a number decoys to include based on the size and things like that because that does seem at least, like, the least complicated path. rather than trying to everything in there and stuff like that because you could get way too. over the top from a from a nested structure standpoint. practicalities point. Right? So one of the issues is select disclosure is you can go to deep to where it becomes basically almost. you know, useless. Right? So that's why as long as there's some guidance. Can I get closer to the mic? Mike? Yeah. Is that better? Yeah. So as long as there's some good guidance added in the privacy section, I think that would be very helpful from an implementer side. Okay. Yeah. I'm honestly not quite sure how to give specific guidance on that. lot of it is gonna end up being, you know, very specific to the application of the deployment. But in general, the ability to add at decoys, like, nationalities, for example, you know, the issue of that type of credential might always include to nationalities, regardless of the true number and and, otherwise, know, otherwise, obscure what what would be there, but I'm not sure that kind of advice applies generally, but certainly happy to to look at some suggested text along those lines or or consider suggestions -- Mhmm. -- about how to do it generally. Dick, do you do you wanna say something? Yeah. Okay. That's fine. Go ahead. Just -- Go ahead so much. State your name. Hi, Dick Hart. The National that syntax it looks like a hack looks really horrible. frankly. Thanks. I think there's other ways to do that. I'll write up and post some ways, since you're wrapping JSON, like, the the the thing that's being"
  },
  {
    "startTime": "00:34:02",
    "text": "You're creating a house chef. You could have a bunch of those things just be separate items. effectively. Like, you can have each the nationality doesn't have to be an array. You can have Each of those be effectively acclaimed. Alright. And -- more time. You could model the data differently, but there's Okay. then a lot of suggestion that that deployers implementers want to model things as an array. and have individual elements underneath that array be selectively disclosable. They they could be models and objects and use the other syntax but Yeah. I mean, the what's that? I write the validation. Right? Yeah. Tobias, do you wanna go with the mic? No. No. Go ahead. But another big piece of feedback is I was super confused. through the whole presentation on exactly how it works and even looking through the docs. I think you need to start off with with Here's the state here's some data about people and how does that end up getting in being the object Once again, I'll write up some suggestions. Okay. But the whole buildup about how all this stuff works. if there's you're in the middle of it and you understand it, but nobody that anybody coming new into it, It's super hard to parse what's really happening. It's not not an uncommon problem. So yeah. k. Thanks, Dick. Anybody else? Okay. Thanks, Brian. Thank you. Aaron. Which one do you wanna start with? think it's in the right order. like, significant in the same deck. Right? Oh, is it? One one deck? I I see 2 here. or student 1. Oh, actually. Yes. You're right. No. No. No."
  },
  {
    "startTime": "00:36:03",
    "text": "great. -- And -- -- Yeah. Let me hand you down. That's right. Ready? send it to you. Do I have to do something? set one of these buttons. Let me try it again. Try again. doesn't just pop up. No. It's not working? Let let me try it again. Exact control. Hold on. me try it again. figures, k. k. Alright. Hello. Let's start with OAuth for browser based apps. So quick recap of what the scope of this draft is. It's meant to be recommendations for people who are building OAuth applications that run-in a browser as in code is executing in a browser, which means either JavaScript or other scripting languages that are in a browser environment. aka, single page apps. That may or may not include a back end component as well. folks So from 13 to 14, pretty minor changes since we last talked. bunch of editorial cleanup stuff, updating some references some of the new RFCs. which is always fun. And there is a new paragraph talking about the possibility of a browser generated non exportable key is still having the possible risk of exfiltrated from the file system because it really only the browser API, so that only guarantee non exportability from"
  },
  {
    "startTime": "00:38:00",
    "text": "browser APIs from the browser context, but ultimately, the key is sitting somewhere on disk Possibly. There is no guarantee that it is a hardware backed key. just wanted to point that out in there. That's the web crypto API if you're curious. There are currently no open issues on the draft. we've had a lot of good discussions, and managed to work through everything, I think. So have anything else to say about that. I don't That is a very short update on the draft. Yeah. So let's Yeah. Yeah. We'll let that Anybody has any comments? Any questions or comments? you think you're ready for a crew less call then? I think so. I don't have any anything left I to do our draft, and I think we've had a lot of good discussions in the last couple of meetings. So Correct. Yeah. Gotcha. So we'll do then. Okay. That's on the mailing list. Right? Yes. Yeah. Great. Anybody has any problem with starting our wakefulness call on this? 3, Yeah. Well, it's it's way too blessed on. expect people to review it. Right? Okay. Thank you. Yeah. It's all on. Great. That was making up for some of the the try to make up some of that time. You might have to use it for a lot 2.1. So 2.1. This draft, we've had a couple of changes since well, a lot of changes actually since the last draft. since we last talked, This is IETF 117. That should've been 116 from the last IETF meeting. There is a new introduction section that kind of rephrases what"
  },
  {
    "startTime": "00:40:00",
    "text": "how the whole draft is is positioned. So please give that a read. Again, a lot of references to things have been updated since there are new RFCs from the group. But the biggest change is that I've been working closely with Daniel Feth to Get oh, 2.1 and the security BCP back in sync. because it turns out over the last, like, years or so. 2 stuff has happened to both drafts independently even though my one is supposed to be a consolidation of the security BCP, but discussions have been happening in both places. and they've kinda started to get out of sync. So went back through and compare notes and maintain just to both drafts to bring them back in sync. So this is a short list of the summary that of things that changed in 2.1, which were changes that we've already talked about in the security BCP. So I just hopefully not news to anybody. now those are But correctly reflected in the 2.1 draft The other significant change is based on the last discussion, the in the request of the token endpoint, the redirect URI parameter is no longer part of that Request. Request. Request. request. Request. Request. because it doesn't serve any purpose anymore in in the context of this draft. So we talked about the last time, and now that is is in the draft. So there are still more things to do before this one is ready to wrap up. There's still some trailing normative language in some of the security considerations sections. So that's been an ongoing project to sort of identify those and move them into the appropriate part of the dock. Part of that is because this is a merging of the security BCP, which is a combination of security considerations and normative changes as well. And then there's the sort of admin admin task of describing the"
  },
  {
    "startTime": "00:42:01",
    "text": "the differences from OAuth 2 and for which role things are actually going to be different and break. And then 128 is a new one. this is something that was pointed out that that OAuth 2 draft actually has a description of how the how it uses the form encoded syntax. which Apparently, is, like, one of the only places that description exists. So it needs to get added back can't remember exactly why it got removed in 2.1. I think it was part of some other section that wasn't important anymore, but it it turns out it is. So I would appreciate some help with that because that's dealing with, like, a string manipulation a level that I care very little about. So, yeah, if anybody wants to jump in and write some write some text for that, that'd be great. There are still some more open issues to discuss. And then happy to continue that on GitHub. I'm gonna be doing working with the other editors to do a big push to close as many as we can soon, but still still there's some more thing that's left. As far as how I expect the rough timeline for this to go. We have now finished The security BCP sync So that's done little green check mark there. we do basically, this before we can get the point of asking for working group last call and 2.1, we need to the security, basically, need to be published, and we need the browser VCP to at least be through working group last call since it also contains things that are in 2.1. And I would also love to get i. an earlier review from maybe the HTTP working group. on some of the stuff because some of the"
  },
  {
    "startTime": "00:44:00",
    "text": "I know that some of stuff in o r 2.0. was not doing HTTP things exactly right. and I would love to make sure that we're not repeating those mistakes again. So I was hoping to we can get somebody from HTTP to give it a read through. And then we'll be ready for last call. So still a little bit of work left on this one. Yeah. I wonder whether the this IETF meeting may be a good time to talk to the Yeah. Yeah. to find some people from the HTTP community to to do a review because that would be fairly soon. We just talked about doing a working group last call on a browser PCP, So so that would be timely and given the vacation period. So maybe they they could do that in August and so we could start then a booking group last call. Like, way before the next IETF meeting. That would be great. That's that's the idea. very great I feel like it's an optimistic timeline, but that would be wonderful. Yes. And and do you have more information about the the the h issues that that you Yeah. I feel like anytime that they have looked at other droughts, drafts, they have a list of things that they are very tuned to spot. that other people are not So I don't know if I would be able to make a list of things that I think are It doesn't have to be a list. Just few examples so people would know what what is it that we've talked about here? So one example is anytime there are example request request request, request, request, response bodies in the spec. making sure that the the syntax of the the headers is now is correct and up to date. That's one example. I remember one example from earlier was the content type application JSON The example is all then also specify the character set, but that's actually redundant it's the JSON Content type specifies the character set already. Okay."
  },
  {
    "startTime": "00:46:01",
    "text": "So we fixed that one a while ago. It's just little things like that that someone who's better tuned to working with us all the time spots very quickly. Okay. Mike. You wanna see something. k, Mike. And after that, Hannes make Jones. I would suggest if you can get Mark Nottingham's eyes on it. he will catch all that stuff. I have recent experience with that with depop. where as we were doing the INA registration, and Brian will attest to this, He suggested that we use syntax description that's now current in HTTP RFCs, which he's an author of. So a busy guy, but he's a nice guy. He'll help you if you can get his eyes on it. Yep. Yep. Yep. Yep. Yep. Yep. Great. Honest. Yeah. he might be a good kid. guy, but maybe also we just reach out to those and talk to Roman on what sort of they have a process for doing these type of reviews. So We just Santarindia in in Yep. Greg's Okay. Dimitri, Hi, everyone. Nice to Teligent back based on the keycloak. So could you please get back to the slides as enumerating the items from BCP. That's why I'm going to So incorporate, especially course, So Which side? which which slide, Dimitri, again? So there was an a list of items from BCP that we are Plainting Humphrey."
  },
  {
    "startTime": "00:48:03",
    "text": "the most importantly yeah. So we are planning to explicitly prohibit calls at the authorization point. At the same time, there is a document cold. or else, or else, Just a sec. So the official name is of multiple response type encoding practices. The document published at openid.net. And Mike Jones, was one of the co offers, so probably he he could give like, on the grounds of the doc. The document says that it is expected that additional response modes may be defined as the notifications in the future, including possibly once utilizing course. So there seems to be some sort of conflict between the documents. So Any ideas help how we could approach that. Thank you. I I don't think there's a conflict. I don't think that anything having to do with the additional response type would would require cores at the authorization endpoint. The reason for that was a security BCP was brought up in the context of the security BCP to prevent bad things were happening because the browser should not ever be making a JavaScript call to the authorization endpoint, the are supposed to redirect to the author's authorization endpoint which is also true with other response modes. response types, and response types. Yeah. I'm giving a thumbs up from Mike. So thank you. So the of 2.1 will have precedence. or what we have in the document that I mentioned. k? k? Okay. Thanks. Dimitri, do you wanna repeat that? So just wanted to say that while the 2.1 will sort of health have precedence and priority over the document that I have mentioned. atopenid.net. that open any document shouldn't be in conflict with this though at all. It also would prevent request at the authorization endpoint. Core's"
  },
  {
    "startTime": "00:50:00",
    "text": "because it's not needed for that. draft either. Okay. Thank you. Thank you very much. Mike. Hi, Dimitri. This is Mike. If you'd like to right to the list on what you perceive the conflict as being. I know Aaron and I would be glad to look at that Thank you. Thanks, Mike. Great. Keep going. That's it. That's all I have for this. So Give me some time back. And -- Okay. Any but he has any comments, questions, Hold on. Somebody says it in their But go to Mike. This is Brian. My my memory is probably bad. But I thought I remembered a sisting discussion about removing the redirect URI in that in the token and point call. where the conclusion was not to change it And then so I was I was like, I was a little surprised at it. The conclusion was remove it, remove it, But leave a note that once we get to the end, if it ends up being the only thing that is breaking, compatibility, then we put it back. No. No. So the expectation is that there are probably a couple other things that are are technically not backwards compatible And if the redirect URI parameter ends up being the only thing that makes a client break in in cases. yeah, we will put it back. But if it's not the only thing because there's already other things that make an older client and compatible with a newer AS, then It's not. then it still serves no purpose being there. Okay. Okay."
  },
  {
    "startTime": "00:52:00",
    "text": "I I was kinda on the fence either way, but I was mostly just trying to film -- Yeah. Close it to the mic. was on the fence. I could see I good and bad in it either way, but I it would just you can couldn't reconcile it with my memory of what happened. I think we discussed it like, during pandemic in an interim was was No. I think it was last meeting. so that would maybe be a more recent that's what it is. Yeah. Thank you. my own, my own, my own, Okay. Anybody else? Okay. Thanks, Aaron. Great. Thank you. Okay. Let's see. Mike, Mike, Shoot that dumb. Yes. Good morning. I'm I'm Mike Jones. I'm here to talk with you about the resource metadata draft, which I've worked on in the last months with Aaron. k. The floor is yours. And thanks to Aaron for helping me do these slides, you'll find that he makes more interesting slide decks than I do. So that's been great. As as they say when you know, Hawking wears on TV, now with extra stuff. And this is now with authenticate, which we were asked to do. in Yokohama. So here we go. Next slide. So since ITS funds 16, we were asked to consolidate the two drafts that we had, the resource metadata draft and the authorization server discovery draft, which used"
  },
  {
    "startTime": "00:54:03",
    "text": "www.ethanicate. Aaron took a stab at it. He didn't like it. I took a stab at it. slightly differently, but using a lot of the text from this draft, and he liked it. I liked it. I liked it. And so here we are. next. So what is this for? And this was the key message of errands that I think resonated with people in Yokohama. that this is for use cases where you have a client, like an email contact calendar client or whatnot, which occur in the wild. that doubt now in advance, what resource they're gonna use, or what authorization server they're gonna use. They have to be able to dynamically, connect with those even though there's not a pre established relationship between you know, the rogue calendar app, the Ori wrote, and Google, I'm I'm totally jerking you around. Highway. So you'll have these apps that work with many resource servers with many authorization servers. that you don't have pre established relationships. And so it's useful to have metadata to be able to establish those relationships. on the fly as needed, at least at configuration time. next So the new step 0 that you can do is you can Go to the resource without an access token, maybe with an options for Quest. and have it send you back information about what you need to do to connect to it. So in this case, our example, WWW, ATHEDICATE response has the resource identifier"
  },
  {
    "startTime": "00:56:01",
    "text": "and it has a scope. You could have other things. This is part of an extensible HTTP framework, as most of you know. next So there's gonna be three slides on step 1. because this did resource metadata requests and responses look like. this is not a very surprising looking request. It has a well known URI and a host, and you do a get to it. Next. And you get a nonvary surprising or spots. You told what the resource is so that you can double check somebody's not spoofing you. You potentially are told what authorization servers this resource is prepared to be used with. Maybe some things about OAuth protocol messages that are and aren't supported. documentation pointers, etcetera. the particular metadata values are intentionally very parallel to those in I think it's 8414, the authorization server metadata. Obviously, with differences where it matters that it's a resource rather than an authorization server. Next. So going back to our calendaring example, Let's say we found out that the resource identifier was calendar.example.com. We get the metadata from it. and For instance, we might learn an authorization server that we wanna years. And, again, some things about a lost protocol elements"
  },
  {
    "startTime": "00:58:01",
    "text": "options that are and are not supported. and and see Aaron does these yellow sticky things. I never would have thought of Oh, next. now we're getting authorization server metadata. Many of you do that many times a day, and sometimes you've written could do this. Next. And then you use this thing called OF2. to make an authorization request using the parameters that you discovered through the discovery request, the metadata requests. And down at the bottom are some pictures of what this might look like real servers, what some of the UX elements are. Next. Next. And so you get back an authorization response. In this case, you've got an authorization code, which you'll later redeem at the token endpoint, and go to town. Next. And then, finally, you get the pretty access token and you supply it to the resource that you did metadata discovery for, and you get the calendar data response. in our example. Next, So as we were working on the details of the text. one of the questions which is really a security question that we talked about, and I thought let's just put it in the slides get people's brains on it. Would you ever want the WWW authenticate response? to return a resource identifier that was not"
  },
  {
    "startTime": "01:00:03",
    "text": "at least at the same host as the place you made the request. Aaron pointed out that there may be times that it's hard to host well known protected resource. And, you know, that's true of any use of well known. This draft sort of assumes that you can, and there's a lot of cases where you can. But this is a security question which we're clearly gonna have to narmatively address in the document and probably in the security considerations. John Bradley, would you like to -- Just junk. Are you in the line there? line. So -- Yes. Yes. In the So the you can use that, please, though. Thank you. John Bradley Yubico. So I don't offhand see any problem with having the resource at a different host because lots of lots of people have problems deploying.wellknown on on central infrastructure. I've heard that any number of times. So I don't think that's the the main security problem. I guess my question is we when we looked at this many years ago, The reason why we didn't do resource metadata was that it was a great fishing opportunity. that that a resource could create a phishing page that was Google and you know, random. I would need access to Rander random calendar app could force a legitimate client to take you to something that looked like Google and ask you for credentials. Now if you happen if everyone's using pass keys. That's not a problem. But until until everyone adopts that."
  },
  {
    "startTime": "01:02:04",
    "text": "Are there any mitigations to stop this becoming yet another phishing vector. because I don't see any offhand. Aaron is standing, my short answer is that It's often the case with these apps that you can dynamically established connections. They do have a wait list. they they understand you know, that certain Okta servers are fine and certain Google and Yahoo servers are fine. and they might you know, warn you if you're typing in the server address into those forms. that it doesn't recognize, and that is a practical mitigation Aaron or or, John, you're still on the queue. Can you go back to slide 2, please? I was about to say the same thing. website. Number 2. Number 2. all the way into numbers. All the way to number 6. -- 0, I think. Okay. Next. Oh, next slide. This one. Yeah. Yeah. So This is This screenshot is the current user experience in many, many applications, And this is also a fishing vector. as in someone can be instructed to type in Good. Good. password and a server address that is the wrong server. And, currently, it client will then go send your password to that server. So there is currently a problem of risk of a of a fishing antenna company. I don't think that it is Worse If this instead of asking for a password,"
  },
  {
    "startTime": "01:04:02",
    "text": "opens up a browser to the discovered authorization server even if that authorization server is a fake one that is person, they need a different authorization server. reason I think it's not worse is because There are more opportunities to see that something is wrong, in that case. And we also have technology, to solve that problem which I think John is intimately familiar with. web often, and pass keys. So that lets us solve solve the fishing, problem. And at the very least, have it be more obvious that there's something happening because you can can see that the address bar is not the same as actually google.com or whatever. not whereas the current experience is worse because you just give your password to the wrong server in the first place. So that's I think it's an I think it's an improvement. And as we get more and more deployments of fetching resistant authentication mechanisms, it's just going to get better. k. Neil. needing can pass now. Yeah. I just wanted to so, actually, I I I agree with that. I think, you know, this definitely an improvement still on the previous situation. ideally, wouldn't be talking any server addressing here at all. We got various auto discovery mechanisms now. So as long as the user can type in their real email address and don't mess that up. you should get a real server auto discovered which can then do this phone, you obviously will get to the real authorization endpoint as well. with the bearer response Just wondering, do we need the intermediate well known? There's a lot can we can we just we're all return which authorization server we want directly"
  },
  {
    "startTime": "01:06:01",
    "text": "in that. I just wasn't clear why there was the intermediate step for the well known for the resource server first. that's what Aaron's draft did. 8 months ago. And what that doesn't do is give you ours. just like you can have a lot of different kinds of metadata such as protocol elements supported and not supported. in 8414, the authorization server metadata This gives the resource an option to in the future for instance, say only give me dpop tokens. I won't accept a baratoken. There's lots of other things you can do with a general metadata mechanism. once we have it. And so I think it's quite valuable to extensible OAuth Ecosystems, particularly ones where per Aaron's use case that you don't know the resource server, and you don't know the authorization server in advance. you need a data structure connections with it. Okay. One one final comment just on the Sure. may want a different domain to the So if you're thinking to could definitely make it work with the same domain, but it would be easier if you could give a different one because We we have things like card dev.fastnet.com is proxy straight through to a card dev server and doesn't normally have to serve up. separate files. And so you'd have to do some hackery on the NGINX config to make that work. So definitely easier if we could -- Okay. to mean the -- Who would like us to help write the security considerations for what you do to mitigate problems that might arise from redirecting elsewhere. If I don't get any volunteers, I'll just get a Santiago and talk John Bennett I don't wanna have to do that. sounds like"
  },
  {
    "startTime": "01:08:04",
    "text": "cease who you are. Okay. Tobias. Yeah. So I was just on on John's consideration, one of the one of the ones that I think is probably being discussed, but as as worth, like, elaborating on as is in situations where the client can somewhat provide a little bit of UX friction maybe at at the very least around, like, I've never interacted with this IDP before and just letting the user know, that of that fact, right, versus an IDP that is perhaps well established and the client has some Inesolve and has redirected users to on a consistent basis, that that can be somewhat of a mechanism that can mitigate perhaps some of the more harmful phishing attacks and and maybe that is just a good security consideration to elaborate on in the draft is set, but the client can be can take that responsibility to mitigate some vectors of possible fishing. Thank you. Thank you. Thank you. I think next slide, Good. Good. Good. As John alluded to, been a history. I mean we did this at the same time. originally as AS metadata. The thing that made this current again in my mind is Roland Hedberg and others in the OpenID Connect Federation World, decided they wanted these data and to use them. I know Dick has told me privately he has used cases for it Aaron and Benjamin did the resource discovery thing. or the the AS discovery thing. It was enough like this that in Yokohama, we decided, you know, what's combined forces, And so we merged, and here we are in San Francisco, next, next"
  },
  {
    "startTime": "01:10:01",
    "text": "I would like additional reviews by working group members, obviously. That's always goodness. The step that was added is strictly additive, that didn't change anything normative about the past documents. And I think following some reviews, I'd think it's appropriate to ask for working group adoption. if the chairs concur. Okay. Any questions, thoughts, Can we get volunteers to review the document? teacher, Lace. wanna speak up? You But I just wanna speak up and support. I mean, this there's as Mike mentioned, this has some applicability. And even though it's not certainly not officially in any way that or or even spoke there is no consensus around the use of Federation in in OIDC Federation and the UID 1. It will definitely get used in the large scale pilots on the way as a as a mechanism for organizing some of the by piloting activity. And, like, my personal belief is that we'll actually have have a use in production large scale production in the UDI. wanted space. So it is definitely appropriate to get this done. published and published Thank you, Lyft. Dick. Yeah. Yeah, Kirk. echoing leaf comments that I see lots of use for it. very supportive of this. I also wanna go back to the SD Jot because I think I was kinda hard on, Brian, that I think an amazing cool technology, and I'd volunteer to read Mike's thing, but I'm gonna spend my time on brand sync because I think"
  },
  {
    "startTime": "01:12:00",
    "text": "that needs a little more help. and is super cool tech. Thanks, Dick. Okay? Anybody else has any comments? So we got 2 volunteers to review it 3 or a dick too. Right? No? That's that's right. He's following the directions on my t shirt. Thank you all. will also review Yeah. Okay. Brian, I did actually do a a quick review of it. So while we have the time here, I I struggled a little bit with the whether the resource metadata is is intended to be for consumption by the client or by the authorization server. or both in some cases, and that could use some either some more clarity or some further separation in the draft and So there's my review. But and, also, I I continue to be worried about the future if in fact this gets adopted and worked on what's gonna happen with the way that the the well known, is handled in in resources that contain half constructs. As I'm sure you know, that's Yeah. I've I've arm wrestled with Mark Nottingham. far he's beating me. Yeah. And I don't know that this time will be any different. So I yeah. I guess you're aware of that. maybe thinking out loud a little bit more. Is there is there a reason in this construct the challenge returns the resource, would would it make sense to just return the actual path, like, full path into the metadata rather than a resource identifier at that point. and and avoid all the well known construction. I don't but but It's not a fully formed thought, but in following all the pieces that are in here. I'm not sure we actually need the"
  },
  {
    "startTime": "01:14:01",
    "text": "the the well known resource like construction the way we have in in other places. sniff about. Okay. Go ahead, Diane. I like I like that idea. Alright. Go ahead. And I think one way to bridge the 2 is to suggest the path should be dotwellknown. but not make it a requirement. So if you are using the double the authenticate discovery that actually points to the actual metadata document. whatever that path is. It doesn't matter. It's not defined in the spec. Yeah. that points to and then we can suggest that meeting a good place for it is you know, this dot well known resource metadata if you don't have a better idea. In Yokohama, I do remember standing at the mic and saying, could have WWW authenticate return an identifier called something like resource metadata. which was a URL to the metadata document rather than the resource identifier. I I don't think This is just me. I would like to get the thing adapted in the working group and then incorporate some of the feedback that we get on the last. Okay. It was just an idea to sidestep that. you're not the first to have that idea, and it's not a bad one. k. Alright. agree with all the comments, especially about the, you know, not putting dot well known you know past certain other path elements The original reason I queued was I'm interested in in why the the history behind WW authenticate being added. And if there are other Are there other structures that serve a sort of similar purpose to WW authenticate that are relevant here just trying to wrap my head around how that came to to be added afterwards as opposed to being there from the beginning just some of the history around that."
  },
  {
    "startTime": "01:16:02",
    "text": "This was part of the 2 different drafts. So originally, MaestroF was only about the resource metadata document didn't have any mention of how you would find it or how you find it will be you know that it's at the dot well known path. And then separately, I had worked on a path that didn't talk about resource metadata at all. it was just that of the above authenticate header pointing to the issuer. So this is the combination of the 2 Thanks. Okay. I think we're good here. So we're gonna wait for a review and then they call for adoption after that. Sounds good. Thank you, k? k? k? Thanks, Mike. Okay. Peter, citing. Okay. So again, thanks everybody for being here. my my my 48 close. No. Okay. Thanks everyone for being here."
  },
  {
    "startTime": "01:18:01",
    "text": "And thanks for opportunity. It is always such a privilege to to be at the IITF. So I'm gonna talk a little bit update on the cross device flow work that we've been doing over to the last sort of 9 months or so. And this is an update since your karma. So as always, I've gone out always with A beautiful picture of San Francisco as imagined by Dolly. because I don't have a camera to go out and take some pictures this time around. Okay. So what are we gonna cover? Quickly, I'm talk a little bit why we're here. Just a recap of the problem for folks who are not familiar with it. quick update on where we are, and then kind of what we go next with this work? So why are we here? So so, typically, when we look at a tax, A lot of our focus is on you know, focusing on analyzing the pro call, looking at design, technical issues, implementation issues, One of the things that we've discovered is that there's also this sort of social engineering aspect. Right? That's turned into a fairly big term for people finding ways to steal identities and get access to the system And, eventually, this these attacks results in sideways or lateral moves, lateral moves, and tokens getting infiltrated, etcetera. And so one of those attacks that we've seen is an attack on what we we call cross device flow, social engineering exploits or we actually have a name for now. We call it cross device consent phishing. And there's sort of a couple of flavors of this. But in general, the way this works is that there's an attacker that controls an initiating device They initiate a session They obtained some kind of artifact, a code, a user code, or QR code, and then they changed the context on that."
  },
  {
    "startTime": "01:20:03",
    "text": "They send it to an unsuspecting user, And we've seen a number of variations of this. putting it, you know, physically putting something up on a bus stop and hoping that somebody will come around and scan which does happen or in email more typically with some way, you know, it's either fear or greed. Right? click to win or scan here and sign in, or we will delete your SharePoint site. And people do that. They happily scan. They authenticate, and they can use any number of authentication mechanism. So MFA kind of gets bypassed by these attacks. The user authenticate to the authorization server, which then releases access and refresh tokens to the initiating device. And so the core of this problem is really this unauthenticated channel between where the the session is initiated and where the authentication happens. And so So this is sort of the problem that we've been looking at and and trying to find solutions for So sort of launched a couple of different approaches, not just work here, but also outside of the IDF. I think We've started looking at very pragmatic mitigations. What can we do now? also exploring alternatives and making recommendations about using alternative protocols, And then also looking at sort of more foundational underpinnings, can we use can we use formal methods And there's some analysis that we can do. There's some suggestions Even just to assess the effectiveness of some of the countermeasures that we're proposing. So okay. So where are we on this? So we started back, I think, at the open or at the oauth security workshop in 2021 where we first identified the problem. And since then, we've gotten as far as having"
  },
  {
    "startTime": "01:22:04",
    "text": "the working group adopting the draft for set of practical mitigations, And we've just updated that to second iteration of of that document. So there's the BCP. There's a QR code that you can scan if you dare. I I felt I I felt conflicted about the QR code, but I thought it up in case somebody wanted to scan it. or felt brave, So, really, what's new in this latest version is, I think last time around, we had a discussion about what to name the the attack And I think we came out with calling this cross device consent phishing And so we've updated the draft to sort of consistently refer to this attack or type of attackers cross device consent phishing attacks. The other thing that we did was in the previous draft, we identified sort of 3 different types of cross device flows that are being exploited by the attacks that we're seeing out there. The terminology for describing, it wasn't I think we got feedback that that was not very helpful or not very clear. So we picked this through the mailing list as well. And so three new names sort of focusing user transferred session data. So this is where user has to scan or reenter a code. the back, and and that is typically what is used by the by the device authorization prompt or Device code flow. And then the back channel transfer session pattern, so similar Siva, the Severflows from open ID. And then the last one is this user transfer authorization pattern this is the typical flow of I send you a code, and you can go and enter it. somewhere else. Right? So it's sort of the user entering the authorization date."
  },
  {
    "startTime": "01:24:00",
    "text": "So those are the three names that we that we changed and also consistently updated throughout the documents. So that's a new So things to do next So the first question so this is something that I also took to the mailing list. I haven't seen any response yet. When we originally wrote the document, we didn't put any normative requirements or any normative in. Right? So there's a lot of recommendations about what you should do. And then as I went and I looked at other security VCPs, I noticed that while they're our normative requirements. And so my proposed or so we prepared a PR. You can again. If you feel brave, scan the QR code, have a look. But, really, the idea is if we add normative requirements, it will give clearer guidance on what's to implementers, what they should do with authorization servers, what they should do with clients. Also, the importance of specific mitigations can be emphasized. And also, it makes some sort of conformance or adoption meaningful. Right? If somebody says, I am adopting or using or deploying mitigations as defined in this BCP, it should give some indication at least of what you know, what people should or or be able to expect. the proposal is to adopt normative text. There's no masks at the moment in there, so it's all things that you should or to do or is recommended to do or that you may do, And I'd like to actually, that's a question for this group here to see if there's any concerns with adopting a normative text or or any reasons to not do it. or if there's any support for doing it. Any thoughts? Like, the the use of"
  },
  {
    "startTime": "01:26:02",
    "text": "the normative language makes a lot of sense in my opinion. It's not just 4. like, in general, it's not this. Not being said that in a PCP, you can't use normative language. So Okay. Thanks, I missed. Justin? Yeah. I agree that the use of normative text does sense here. It's as with any RFC document, it's optional to follow a particular RFC. So You're saying that this is best normative or best current practice. And if you are following that practice, then, yes, these are the requirements for following that practice. the agreement to follow the best current practice is a separate decision. And if you don't agreed to do that, then you're not bound by any of that in any any meaningful way. So I agree that Adding normative statements to this document where they make sense, where we want to be clear about the decision space. makes a lot of sense. Thanks, Justin. Nothing, Joe. It's ahead of me. I can't my I'm not on the Internet. I can't do Roman. soon. Hi. Roaming Didio putting on the AD hat. I I think the idea of of normative kinda guidance is kinda good. only thing I would kinda caution based on how I see as discussed things in the ISG we talk about should may and recommended. great to use that normative language, but make sure you talk about the trade offs of so if it should, there's a reason why you didn't say must. So kinda talk about it would be the corner case. Why not to do that? And then, you know, with May, the rest of it. So explain the back half of why it's weaker anonymous. Excellent. Thank you so much. That's very helpful. Joe. Joe. I was just gonna say what Roman said. So Thanks, Stuart. Yeah. Okay. I think that sounds like some good clear guidance. Couple of open issues. So we've got 5 of them. We"
  },
  {
    "startTime": "01:28:00",
    "text": "I think 2 of those are related to specific guidance. couple of editorial things, a big the the other big outstanding issue is updating the section that talks about formal analysis. I think right now, It reads. along the lines of, yeah, that's a good idea. You should do it. And so we're hoping to progress that at the OAuth security workshop at the end of August. So moving to maybe the next slide. Here we go. So we've been working with researchers from the University Stittgart. So they've been working quickly on the device authorization grant, and will be presenting some results at the overall security workshop in August. Following that, we will update the draft to reflect any specific outcomes. I think there's a 1 or 2 small things at this point, but that is sort of an expectation that we'll have that that that section gets updated after that. cancel And and then I think the other bit of interesting something that I'm quite excited about. And I think Justin suggested this back in in London, and IIT 415 is we've been also started a collaboration with Rolly Allaway University of London, to do some research specifically around UX guidance for cross device flows. So Miriam Mermezat will be you will have an opportunity to present at Iostouble some of the initial literature work. I think one of the interesting things that there's currently no research available on cross device flow security UX. So there's some more work that will come there that we might benefit from in the future, probably separate from work that we document in this BCP. But, again, I wanted to share that folks who will be there This will probably be in the on conference section. and an opportunity to engage with the researchers on this as well."
  },
  {
    "startTime": "01:30:01",
    "text": "No. And I think that is everything. So next steps, I think, we close on what to do about the normative environment. So that's really good. updated formal analysis section coming, couple of open issues, and then one thing that I wanna check with the chairs, the possibility of maybe issuing a working group call prior to IATF118. And, you know, at the latest at 118. So that would be a goal. Seasonable. call it depends a little bit on on the group to whether it's possible to finish the open issues that you just flash up on the screen. Of course. Right? And so if we can I think my ask is if we can get those open issues closed Before 118, do we need to wait until 118 before we issue a last call? Okay. We should be able to start it before that, for sure. Yeah. And I I think the other thing that also want to signal that we want to signal as the editors is know, we we sort of we do want to sort of move this document along so that it doesn't you know, stay in draft state forever. Yeah. Okay. k. That sounds good. Okay. I think that's everything that I had. Any any other questions Anybody. Okay? Thanks, everyone. Perfect. Thanks, Peter. Yes. Yeah. I would talk briefly about the document I wrote. The background is that there's currently a lot of work going on and attestation in the IETF in different working groups. In fact, I've just realized this week that Nick Smith and Tomasacciano"
  },
  {
    "startTime": "01:32:00",
    "text": "who, you know, are going to have a site meeting on using attestation in OpenID Connect something during the week. We try to forward that to the to list in case anyone is interested in So put this document together as a as a contribution for discussion on Sort of using some that technology also in OAS. And at the same time, Tobias also submitted the document. So so this is I think something we we should be looking into. as a technology for OAS and improving security next slide. So Why is this suddenly? attestation is a fairly old concept. If you remember the early work on on in the trusted computing group on TPMs there was already working the IPF standardization work with the trusted There was a group working on how to use the attestation for network access authentication. are called NEO, long, long time ago. got a little bit quiet over the time. sick. whatever reason, but suddenly there was a renewed interest in this area, I believe, mainly driven by the work on confidential computing. and also the availability of the hardware In mobile phones in in laptops nowadays most of the tablets and laptops have some form of either TPM or some other at the station hardware. also on the server side as well. and that has triggered work in or the formation of a new working group and the idea the IDF rats remote at the station procedures working group in case you have not seen that the bunch of good documents being worked on, including terminology harmonizing terminology across all these different attestation technologies, which was really needed As well as some ways to To do remote attestation,"
  },
  {
    "startTime": "01:34:03",
    "text": "in IETF protocols, for example, network management protocols. in that group. But there's also work on adding attestation to transport layer security as well as later this week. for using at the station in in the big kicks environment with CSRs certificate signing requests, So in case someone is interested, the Lam's working group meeting will discuss this later this week. And let's also work on which I believe is related specifically to the dynamic client registration on IoT device onboarding. So in a nutshell, There's some work going on, and it looks promising what will come out of it, we're seeing a couple of years, I would say. The the downside is lots of different organizations and companies have developed independently attestation Technologies, And so one has to deal with all sorts of different ways and has different properties. different formats, encoding formats, whether it's a keyboard based or 549 based or Some are the proprietary formats So you can look at things from TPMs 1.22.0 all the way to the TCG which is a more modern technique and a lot of things in between. And, of course, the details matter there. Next slide. So why why do you want to use it in the first place in case you have never looked at any of the acetylation. In in principle, it's quite simple. it's kind of a document assigned document, Biff information about the device, about who manufactured the device It includes information about the software, typically also with measurements about the about that software, meaning a hash is computed over that software"
  },
  {
    "startTime": "01:36:03",
    "text": "and also, like, low level software, like firmware, and and, like, other other low level software like let's say, put loaders, for example, but also the layers above, so it can be quite flexibly applied, There's also indication about the security properties of the device where it has certain, For example, the with a the the the Deepak port is locked and something or whether a secure boot is used and so on. And All that information can be communicated, and that information is document is then signed by the low level software slash hardware. It's typically a combination of software and hardware that works here. and it signs that document and makes it available using remote attestation using some of the Internet protocols we are working on. if you want to look at the full story of how this looks like. There's a the rats working group published an ROC on this with different glory details on on all of this. And if you want to see what sort of a collection of items, information elements that get posed with different attestation technologies there's a document called the eat entity attestation token which which elaborates on these on these data elements. Okay. So there's there's there's a lot to to look at. The rat's document also talks about different patterns on how remote attestation works And one they're 2 primary primary patterns. 1 is called the passport model. The other one is the background check model. only flashed up here there. the passport model because that's the one I described in the document but the other one is also applicable in in in the scenarios of interest here in this group. And It's it's quite simple. There are 3 parties, The Tesla is the device that has this"
  },
  {
    "startTime": "01:38:01",
    "text": "at the station technology in India, and it makes produces that document. I'm any this information is this point, not At really trusted in any sense. It's just a signed document. It's called the a rat's group calls it evidence. and that gets passed to the body that consumes it. But, typically, the relying body we'll not be able to really make a good assessment about this because it needs all sorts of information for example, in the previously mentioned hashes of firmware, for example, obviously need to have The reference values. So you need to know what you expect The device to run as a low level software, which an ordinary relying party, like a web server, Typically, there's no. It also has no information about for example, the certificates of the the vendors that produce those present or the of the certificate that corresponds to the signing key, for example, It also doesn't know anything about devices that have been for of keys of devices that have been removed So that's why there's another role entity the verifier who has that information or it's supposed to have that information. and thereby the evidence gets Uh-uh. center that verifier kind of delegated outsourced and obviously, needs to be trusted by the relying party to do this and what comes back is sort of a standardized result called the attestation result. And that's what the relying party then uses to make a judgment together with policies that it has locally on whether that's good enough for executing that request. So that's kind of the the the model in case of the this fast word pattern. And that's also, like, the basic terminology. There's obviously terminology, but I'm I'm I'm abstracting here a little bit for the for the benefit of this meeting. Okay. Okay. Okay."
  },
  {
    "startTime": "01:40:00",
    "text": "Next slide. And if we map this to To the OAS case, the Adesto, is kind of inside the the Owa's client. And the relying body is the AS in in case of the dynamic client registration. There's also A nonstop comes into the picture because some of the attestation technologies in order to demonstrate that this document that they expose is fresh. it has to use some mechanism in many of the attestation technologies rely on nonsense for that freshness guarantees. There are other freshness guarantees, but not all at the station technology, unfortunately, use the same freshness mechanism. Surprise. But So I had to In the write up, I had to take account for that. For example, the TPM or DICE based data station uses nonsense for freshness. as an example. Okay. so what does the document do? It attempts to improve dynamic client registration by conveying this evidence In the registration also using, defining on how to get the nuns in the first But it's agnostic otherwise After ye, At the station technology it uses. because we didn't want to settle for 1, and it most likely Alright. Already today, you can see that Some attestation technologies are used in some environments, n. for example, in a mobile environment, you obviously have technologies by by the by the big brands, But in a desktop. Uh-huh. laptop setup You have a TPM based attestation in the server side with confidential computing. It's yet another Technology. And And so as I mentioned earlier, you you"
  },
  {
    "startTime": "01:42:01",
    "text": "with attestation, you know, if he wants if he claims to be secured, typically combo of hardware and software that needs to work together there. And you see some of those technologies being mentioned, like Enclave security execution environments, secure elements, You name it. All of them Like, different technologies prefer different implementations, so to speak. and the suggestion with the document is 2, look into this area and see how OS can benefit from from sort of this ongoing industrytrend and then also collaborate with some of the other working groups in the IDF to see what it is something that can be we can come up with that is harmonized across different groups. then next slide. And And then maybe, like, look at some of the details think there's a lot of value in that can begin judging from the discussion I have with the buyers in looking at some of the running code like, the subtle nuances on on that the technology we are looking into here So I've and it has implications for for use in OAS So getting our hands dirty as as people in this group always like to do anyway. would be beneficial here. And then there's more talk about at the station with with the work that Tobias has been doing. So I think I think there's something there to look at. Okay. Air. Hi, Aaron Parackey. I agree that there's it seems to be reaching a tipping point of a lot of interest in this topic, and I'm also very interested in solving this problem as well. back in Back last year at the OS security workshop, I actually did a session, about this as well, about using"
  },
  {
    "startTime": "01:44:00",
    "text": "at a station as either client authentication or in dynamic client registration. And there was generally interest in it, but nothing really immediately came out of it. However, I did hear too. examples of people who had already deployed stuff like that in the wild. And since then, I've also come to learn about other similar deployments that have been done using some large, any providers, in thinking through this a little bit more, I'm I I'm starting to lean towards not overloading either dynamic client registration client authentication. with this new functionality. But instead, making it another layer So kind of paralleling what's already been done with the resource server world of you can like, you can use the Apple APIs and and send, you know, generate one of these annotations and send it up to an API, and people do this However, they do it in addition to other API access control. So they'll still send them the access token and then they also send this conversation. And I think that might be a better way to parallel it for the rest of the OAuth role as well where might have a dynamic client registration that has you only a client ID, no client secret, and then you also send out a station or you have a different scenario where you can How about some sort of other authentication using for your dynamic client registration, but you also still want to add a station to it. And same with other forms of client on So it just seems to me like it's probably better to pull this off as its own thing that we can then repurpose in a bunch of different places. rather than trying to make it fit. client registration or client authentication."
  },
  {
    "startTime": "01:46:04",
    "text": "Yeah. Thanks, Aaron. Yeah. That was exactly the type of I was looking for unfortunately, I missed the last year's our security workshops. So I missed also your talk. Thanks for pointing me. I will there's recording, I will look into that no recording, but the slides are. Okay. That's good enough for me. So yep. when I checked it with Tobias, he thought it would be good to have a chat, a conference call, maybe we could expand that to whoever is interested in that topic, Because I think Obviously, there's there are different design choices, and we should look at the pros and cons of each of those and I'm not surprised that some of the IDPs already make use of those technologies. appears to make a lot of sense now in retrospect. Awesome. Alright. Ori Steele. So I was hacking my way through a webauth end implementation, and I was trying to make sense of what the connection point between Web auth then and OAuth should be in this context. And I may have just missed the relevant document that completes this picture. But, you know, for example, with the the skit work, that we, you know, we've been doing for securing software supply chain. you we have this desire to have the really, really strong authentication coupled into a relying party that is storing a lot of cryptographic material that's very relevant to the the a tester or the authenticated entity So if if you could point me to the way to do you know, access tokens with webauth end and, like, that that document that kinda completes that particular picture or, you know, maybe I'm using the wrong words to describe the request. I Yeah. know. I think you do. Yeah. but but but but Definitely using the wrong words."
  },
  {
    "startTime": "01:48:00",
    "text": "Yeah. Just I I We're using the right words. Oh, I'm I'm not sure he's using the right words either, Mike. But he can go to the but maybe that's a that's that's the type of discussion we should be having specifically, like, you have a very specific use case I built a thing, and I I have no idea whether it's, like, legal or a good idea. So I'll come talk to you. Sorry. Yeah. Tobias, I just wanna, obviously, throw support behind this. There will be more conversation and a presentation I do on Friday on it related to this and and just wanted to also call out Beyond kind of native apps usage of these platforms, I think you sort of talked about honest, but work workflow identity use cases as well, and I've had conversation with Peter about this, and there's there's know, it's not just constrained to certain client types. And perhaps, like, the current state of the presentation we give on Friday might get that perception. I wanted to kinda clear that out that I think the usage of these kind of ATS stations generally in our look to apply to a variety of different client employments. and we should be trying to join that conversation up and and do it in a holistic manner. yeah, definitely. And suits. So, like, you just heard Ori had modest back. application focus. There's the Obviously, the app focus that also have you on in your presentation But then the workload aspect is is interesting, and we had various debate on on this as well because there, you exactly have this problem that you have the the workload coming up. It's not configured, but it wants to use OAS It has attestation information but no credentials at this point in time beyond that. And so how do you get to a working configured OS client at this point in time And so There are a couple of sort of"
  },
  {
    "startTime": "01:50:00",
    "text": "different areas we need to look into. And maybe there's huge in amount of differences to warrant different solutions. but maybe not. We don't know yet. k. k. Joe Salloway. And and that's one of the reasons why I think kinda separating this out as its own thing is probably a a good idea because you're gonna wanna be able to to support these different kinds of use cases. I kind of I would like to see some things like, improvements in client authentication Right? But that I think is a separate thing, but we may also have to pay some attention to how these things will link together at something. small Yep. And the the great thing is also that we have experts here in the idea of who worked on some of the attestation technologies, people who cheer up the groups who define those. So there's an opportunity to get sort of like the the first hand knowledge on on those and see what the nuances are and what the state of the fair sign in terms of deployment Peter, Yeah. So definitely very supportive of this work and the conversation and I think figuring out how it fits with some of the other proposals that's being made. I think thinking specifically of some of the biases. proposals. in the context of workload identity, I'm also curious to get your thoughts on how it fits with at a station concepts that may already exist in the workload identity space. So for example, Spafield already has this idea of attestation. would you think about a spiffy identity as an tested, identity, How would that fit with this? I think that that's gonna be an interesting set of conversations to work 34. Yeah. I I've actually I was very much inspired by the discussions we had on on these workload identities be honest, specifically since our spiffy takes an interesting approach on"
  },
  {
    "startTime": "01:52:02",
    "text": "what the interoperability goal is. So they are the as I don't tell you, but the the rest of the group are that the interoperability is more defined at least in that project locally at the APIs between the workloads and the agents running on that on that device So it's kind of what we would consider in the idea of, like, programming language API almost But the interaction between the agent and the servers is is kind of nonstandardized. This is a implementation specific detailed And that's where Something like this could fit in instead of using some proprietary APIs. to configure the OAS client, you could use some standardized mechanism and how that technique in detail would look like, I think that's something the group needs to work out, but I I see potential there. to come up with a standardized mechanism, and I would kind of nicely aligned with what spiffy does. sort of, like, providing an end to end standardized solution Mike. Mike. Yeah. Mike Jones. This is a question for Joe. You kind of intrigued me with your line about you want to see improvements to client authentication. What are you thinking? So this is specifically the thing that I've run into is this thing called private key jot authentication, which is one of the only ways to do client certificate authentication without using TLS. There aren't many other ways to do it, and that mechanism sub you know, it's okay, but it suffers from some problems, like, mainly this freshness problems. It doesn't have the knots. Right? The the the the client's just signing a a self sign jot in a sense. you can put a time stamp or something in that, but that could've been signed at any time and then replay it at a later time, and applying no longer has access to the key things like that. And so that that's the kind of thing."
  },
  {
    "startTime": "01:54:01",
    "text": "I'd like to see. And then I'm not sure how that relates to what Ori said as well. There's you know, They Client auth seems like it's it's not it's kind of been on the outside of the specifications at least the ones that have been worked on here And I think that shows a little bit. Yeah. But that makes a lot of sense. because also the the effort in lamps is specifically motivated by the ability to indicate whether that private keys in hardware stored in hardware and cannot be exposed. So that may be An interesting thing to know. and also some of the attestation mechanism go beyond platform attestation. They do more than what I initially said about signing a document, they actually provide key attestation, so they are more powerful. it could actually, ramp up the the level of security quite a bit Done no. Okay? Thanks, Sarnes. But Yeah. Yeah. But maybe if if like, for those who are interested, like, if we have a call in August, talk a little bit about this. with Tobias, we we wanted to do that anyway. But if I see like orient and and and a couple of the other guys. So Choe and, obviously, Peter. and just Maybe maybe Refund. Yeah. may sound like he can communicate at that point. Yeah. George also was interested. So Yeah. Yeah. Yeah. We'll do that. Okay? Okay. I think we are done. Any Anybody has any other business Okay. We'll see you tomorrow, guys. Thank you. 3,"
  },
  {
    "startTime": "01:56:06",
    "text": "essentially, Exactly. Absolutely. Yeah. Yeah. did deepening to the topic. You Right? Like, instead of -- You would have got to get rushed. Yeah. Yep. Yeah. Yeah. Awesome. Thank you, man. Sure. you know, like, So"
  }
]
