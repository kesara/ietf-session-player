[
  {
    "startTime": "00:01:24",
    "text": "Oh just a little two-minute warning we\u0027ll probably start in about two minutes though how\u0027s that that works all right we\u0027re gonna go ahead and get started if if you\u0027re not here for the Rock and Roll Hall of Fame you can step outside now sorry Joe alright everybody this is the deprived working group if you weren\u0027t intending to be here too bad we locked the doors I\u0027m Brian this is Tim where your we\u0027re your host for the evening afternoon whatever first things first everybody loves us I had to put it on two slides note well behave yourselves follow the rules read this alright so thanks to Chris Paul and Dan we have our scribes so Tim doesn\u0027t have to come around there and beat anybody to get them to do it and so we can proceed "
  },
  {
    "startTime": "00:04:25",
    "text": "here\u0027s our agenda for the day I\u0027ll give you thirty seven seconds to bash it is there anything up here that looks wrong all right so let\u0027s get started document status really quick the the DTLS and TLS profiles are in all 48 technically it\u0027s actually can off 48 done I can tell you notionally what the RFC number will be it should be out pretty soon and as of this morning our ad put the padding policy document into IETF last call any questions on the document status all right excellent so turns out that Sarah is not feeling well so we have a guest speaker who\u0027s going to talk about the DNS privacy BCP Rowland okay thanks yeah Sara asked me to stand in for her so any mistakes are mine and she made really nice slides today I make stupid mistakes but and Sara\u0027s gonna be online on Jabar so Dan is probably gonna jump up and correct me if I say something really stupid so sara has been spearheading a draft with recommendations for DNS privacy service operators Alison manking been over any feminine attempts and I are co-authors of that draft and this is really a first version and we want to talk you through sort of our thinking as we were writing this up to give you a short overview the document is currently about say operational policy and security considerations for operators that that offer DNS privacy services and we haven\u0027t necessarily limited ourselves to DNS over TLS although that has sort of been in the back of our minds and it should also be a framework to assist people in writing a DNS privacy policy and practices statement similar to the intersect practice statement that that already exists is an RFC and it helps people sort of write up how they do their key management how they refresh their signatures how what kind of data except here zones etc so the status of these traps is that it\u0027s very much a draft right it\u0027s full of to those we submitted it here for four to get some initial round of feedback and as I was sort of going over the slides to know what I had to tell you comments were actually coming in so we\u0027ve had some feedback already and one of the questions that we\u0027re going to ask at the "
  },
  {
    "startTime": "00:07:25",
    "text": "end is is where this is something that people would want in this working group or whether it would be better place somewhere else it could be for instance in a ripe DCP track and we\u0027ve heard some feedback from Stefan as well and I\u0027m gonna channel Sarah and say thank you Stefan now there is some existing implementation guidance if you run DNS over TLS there is Profiles RFC 8310 just out that has some must some shoot so the musts are to follow sort of t respect best practices some things about seal accession resumption resumption barbecues etc and there are some shoots in there about whether or not to use eating as you\u0027re partying and to say something god Idina s-- zero client subnet there is a question already yes phone system i see have concern about the shoot is he s en su ok on some day it kills so performance on kids are cashing which is pretty bad for privacy yes completely agreed so we are actually we were discussing this so we discussed the craft the four of us this Monday and and ECS is one of the things that came up so is it should not in so we haven\u0027t got anything in our draft about it yet and i said there should be something in a draft and it should probably should be well at least you should be transparent about whether or not you do it whether it\u0027s a shoot not i don\u0027t know we can discuss so to be clear this is not what is in our drive right this is the existing implementation guidance francis so and then some bits and pieces from the dns over TLS RFC about public key pins now we we needed to sort of find a definition for a dns privacy server and and we sort of came up with what is in the green box which is that it is a service offered via a privacy enabling dns server and there is some sort of document that has an informal statement of how you as an operator handle people\u0027s data if you run this service for them with this particular focus on privacy and there could be a formal practice statement that has some sort of structure like the in a sec practice statement does now if we look at operational guidance that we have in mind then this is about things that like server capabilities that maximize the Innes privacy right so there\u0027s there\u0027s a shoot for things like you know minimization connection management not to require a TLS session resumption and and things along those "
  },
  {
    "startTime": "00:10:26",
    "text": "lines and certainly something like EDS crime submit is something needs to be considered there there\u0027s question it\u0027s already yeah it may be worth looking at the port recommendations and distinguishing between port 443 for TLS and port 443 using this over DTLS because there\u0027s a much larger chancer I think some potential issues with quick eating D machst on to the same fork there so we may may want to look at that guidance and make specific guidance for four for three TCP and four for three UDP okay thank you yeah well for for three is gonna be discussion anyway with dope so Dan York pretending to be Sara to clarify the draft draft IETF deprived ETLs and TLS profiles has passed all 48 but is not yet published in in that draft the guidance is that recursive should honor a client request do not send ECS upstream right oh yes thank you thank you Dan for channeling Sara that\u0027s very much what we discuss so if he there is this EDS client subnet option as a client you can request that your data is not forwarded to any authoritative upstream by setting a slash zero scope in the in the requests to your recur sir and the draft very much says that you should honor that I think by these implementations that I know of do that yeah sorry yeah anyway any mistakes from mine so then there is the the may I guess which is that what the question was about where you should also run a service on port 4 for 3-4 people for each port 853 is getting blocked but then you get into a discussion at some point whether or not that\u0027s gonna work in the presence of DOE so that\u0027s something to keep an eye on and there have been some suggestions that you could run both things simultaneously and that would lead to something really horrendous so No then you could have roots on on loopback of course that make that ensures that your when you do a recursion that you\u0027re not going to be exposing some of your traffic if you have an empty cache - getting sent to two root servers and you could also be using aggressive at the intersect but cache stuff the N SEC aggressive insuk thing where if the recur sir can synthesize an annex domain for you from n SEC data that it already has available that saves you an extra query going to somebody who who then learns that you\u0027re interested in something in their zone that doesn\u0027t exist there\u0027s been some debate about client query obfuscation for a very small deployment where basically users can be very still be very traceable because there are very few users using a single over cursor where you would mix "
  },
  {
    "startTime": "00:13:28",
    "text": "in other traffic to sort of obfuscate a client traffic really haven\u0027t really had time to debate whether that makes sense or not so Sarah asked me to remind you that this might seem obvious but we we were we\u0027re going to include recommendations about a certificate management because that is where things have been going wrong operationally now certificates almost expired and things going wrong and and it seems so obvious but this is something that people need to take care of when they\u0027re operating a DNS privacy server and we\u0027re not quite Korea what the best practice is on that are whether you could if you reuse your key you have the same public key pin but it doesn\u0027t make sense to reuse your key that might not always be good practice so that\u0027s something that we\u0027re very much thinking about yet and uh no fee ously you need to monitor whether your search expire right especially if certs are in there they\u0027re gonna be lasting multiple years we I mean I personally have configured DNS over TLS on on our operational service at my employer and I generated certificates I were just valid for 10 years because this was experimental but I just put notes in my calendar to remind myself that I need to check those certs every year or so another thing on operational management we want to discuss whether what the limitations are if you use it a TLS proxy and then send a traffic on to I say an ordinary DNS for curser over over TCP what happens indicates you of any caste that is still blank in the draft but is something that needs to get discussed and I hope that Sarah is going to channel through Dan if I say something that was already in there any that I forgot about now data handing this is something that is sort of closer to my heart it\u0027s something that we\u0027ve been in discussing and is this is about if you do dns over TLS you\u0027re solving one problem because you\u0027re protecting people\u0027s privacy on the wire as they communicate with their recur sir but then the operator of that worker sir still can do a lot of stuff with the queries that are coming in right they can do logging monitoring etc so a lot of the focus in the drafts is going to be about what you do with that and you can you can decide to minimize or anonymize logging and monitoring but there might also be valid reasons why you are looking at certain traffic because you want to for instance detect whether there are malware infection area network or other indicators of compromised and and after this I\u0027m going to talk a little bit about how we\u0027re sort of doing an experiment with a technology that that sort of does some privacy preservation there to see if we can do this in a privacy conscious manner where we achieve some of the goals of detecting stuff without actually storing everybody\u0027s queries then you need to think about if you\u0027re "
  },
  {
    "startTime": "00:16:28",
    "text": "storing data what period are you storing that data for how long are you going to keep it anonymous when are you going to analyze it who is access to that stored data are you going to be used are you going to be using it to track users or not and are you going to share with their parties and in both cases we\u0027re saying well you shouldn\u0027t be trekking users and you shouldn\u0027t be sharing this data with third parties and right now very much as I\u0027m clear about things like Google says well we\u0027re not going to share that data if you use Google for the DNS but is that the case what I mean and I mean one Department of a huge corporation that talks to another is that sharing or not and that also sort of ties into who has access to stored data some of the things that we\u0027ve been discussing is how do you quote unquote pseudo anonymize or do other sorts of the entity identification on the data that is that you\u0027re recording there was a talk at the DNS privacy workshop in NGSS last month from virtue eridan office in the room yeah about IP cipher if you haven\u0027t seen it I recommend having a look at it the Bloomfield of thing I\u0027m going to be talking about next so I\u0027m not going to go into detail here but we\u0027re very much open to other suggestions so people that have suggestions on how you can have some logging facilities but may ensure that not all your users are visible and that anymore are not visible anymore after some time that is used for information for us to have in this draft then the DNS privacy policy and practice statement the deep PPS the idea is that you in terms of policy you specify things like what data are you collecting how long are you keeping it is it getting shared what are exceptions what are third parties that have access to it and whether you\u0027re currently you\u0027re doing data correlation between this data and other data now this is something that people that have to comply with gdpr and it\u0027s probably pretty much everyone will have to think about anyway right so it is it\u0027s worth thinking about and we\u0027re gonna be thinking about providing some guidance in the draft about about this how you have you set this up how you you write up your policy around that and that might even be used so if you have to be able to comply with gdpr anyway now in terms of practice how do you deal with a temporary or permanent permanent deviation from your policy how do you communicate about this what kind of capabilities are you providing on on certain addresses or certain ports if you look at for instance the operators of quad 9 they filter some traffic if you use our quad 9 address but if where they filter out "
  },
  {
    "startTime": "00:19:28",
    "text": "say what they think is malicious are malicious names but they have a secondary service that they talk about that does not do that filtering and we are thinking about whether we need to mention in the draft whether people should specify if they do this or not maybe it\u0027s not privacy it\u0027s it\u0027s some form of filtering or censorship or whatever but it there seems to be a relation and we\u0027re not quite sure where that should go yet and again eating as clients um that uses usage right Court 9 again has a statement on this where they say if you use our main court 9 thing we will not do it UNESCO and subnet but they have another one where we I think the unfiltered one does do EDS client subnet and they are transparent about this and and this is something that\u0027s important why people should be transparent about what they do and in any case and I\u0027m I\u0027m gonna so correct myself they must respect clients that request that their information not before worded in India that et miss client submit extension and other things are inner or authentication credentials how do you know that this is the correct DNS prophecy server that you\u0027re talking to and contact and support information obviously I think this is the the for last slide there are as far it\u0027s gonna be tricky if you write a practice statement like this to somehow do have technical solutions to validate whether people are sticking to this policy or not right there are some things that you can check right things like eating ask line segment you can probably check if they\u0027re sending this someone there there are test services for that but whether or your queries are getting stored your your your sort of have to going to take the operator at face value for that or your you\u0027re going to have to go there and ask them or send them a data access request again this might be something that that gdpr might be useful for because if you\u0027re an EU citizen you can now start asking companies what they\u0027re storing about you and they have to tell you they have to comply with this but where did that whether or not that\u0027s gonna scale if you have enough privacy nuts to actually start sending these requests to two operators I don\u0027t know I plan to send one to Google just out of I mean I want to know um so what it really boils down to is are you if you have such a policy is this a trusted service or is this a trustworthy service and given that you can\u0027t check everything that is their probably trustworthy is a better term right because if they\u0027re being transparent then you might sort of give them the benefit of the doubt do you think well they\u0027re they\u0027re worthy of my trust so I\u0027m going to use that service because they\u0027re transparent about what they do whether or not you can make claims about whether it\u0027s services trust or not that\u0027s very much up in the air in it it seems unlikely so we come to the end with the the questions for the for the room one of "
  },
  {
    "startTime": "00:22:32",
    "text": "the things about the scope of the document should we have a section in there about a third of servers or not about what they do with queries that they could in and and data that they store on that analysis that they do on that whether there should be exemptions or special provisions for research data there are there are lots of people that do useful research on on DNS query data do do we somehow need to recognize that in the draft and then there are questions about the generality right during the talk I already mentioned that Gigi for a number a GDP are a number of times many of the issues that we are we\u0027re discussing in the draft seem to be somewhat generic in the sense that they are actually included in in the GDP are but it might be useful to have specific guidance for people that are operating such a service right so that will be the focus of our draft and then whether there should be in something in there about filtering or not like I discussed before and Sara if you\u0027re listening correct me if that\u0027s not what you meant by saying filtering but if you are doing this whether or not you should mention this is that something that is within the scope of this draft or is that something that\u0027s outside of the scope of the draft and finally it\u0027s about our approach or the approach is is currently very respect prescriptive with it RFC 2119 words like must intrude or which can be useful but we could also go for text that it\u0027s much more discursive and says well if you\u0027re in this context you should be thinking about doing this if you\u0027re in this context you should you should think about doing this and then it turns much more into a checklist that says if you\u0027re operating a dienes privacy surface you should have thought about at least these things and and here are some guidance on what you could do but it would be less prescriptive prescriptive and we\u0027re open to suggestions on whether to go one way or the other and before I go for the question the last obvious question is is this something that people feel that should be part of this working group or not and and and and Dan\u0027s gonna channel Sarah just to say no correction needed what she meant okay excellent good said Hardy really a point about the approach are there a couple of places in the document where you recommend a very specific answer to what turns out to be in in fact a particular mitigation against a particular threat for example you recommend that in certain cases you run a dot onion note and there are other approaches to doing similar things that would not involve running into an onion note and so a more discursive more contextual approach would actually be helpful for you to pick other options in particular if you have reason to believe that a one approach that you might have in the draft later turns out not to have the privacy characteristics you expect "
  },
  {
    "startTime": "00:25:32",
    "text": "because a compromise or some other issue yeah I also would really appreciate this hat sort of a a ranged approach although I think it\u0027s very very useful to have hey if what you\u0027re trying to do is to provide a DNS service with a specific goal of providing a DNS privacy service it\u0027s also the case that will be really really nice if people just turned on some of the transport level confidentiality capabilities on enterprises and other things where it\u0027s not the case that they\u0027re providing a DNS privacy service but using the facilities have deprived just in in the course as you say of normal DNS and so having a bit of a ranged approach to say hey if you want to provide confidential confidentiality over the web for your enterprise customer or your radio network customer or whatever here\u0027s the minimum thing that you can do if you are constructing a service that is intended to provide privacy at a greater level here are the things you should be thinking about and if you\u0027re providing DNS service even without all of these things you may want to think about some of the data handling practices because they may be required in your jurisdictions okay although honestly if you\u0027re going to write a primer on how to handle the GDP are normal or do you answer i lord love you for taking it on but really i think a little bit more contextualization would really expand the utility of the document and it would really encourage me to say yes to the final piece okay Thank You Stefan if I\u0027m not my I think the good thing about a very prescriptive approach is that it makes writing the policy statement or data privacy part is not simple if you have a sweater annaliese dayes detail options etc it\u0027s much more complicated to explain this in the data privacy statement but I wanted to talk mostly about the choice of the forum for the discussion you mentioned the why for instance I think that today there are very few people who have actual experience with the DNS privacy Shadow it\u0027s something very we see and I guess that most of these people are in this woman I don\u0027t really see outside of IETF who can after experience because if you want to talk about best practice you need some sort of practical experience before so today I think uh I don\u0027t think that was the first place on the disco right okay thank you back back Mike hi so my name is Amelia I come from article 19 I had a couple of questions on thank you for your feedback before he started I just got the email from Sarah but yeah okay right so those were the things that I wanted to bring up in the group as well that I think the terminology that you used in the draft is not really conformance with RFC 69 73 and and I like author referentiality and documents so I propose that you use like pseudonym ization instead of pseudo a minimization but then I\u0027m also wondering why you make a distinction between logging and monitoring and data "
  },
  {
    "startTime": "00:28:33",
    "text": "retention because to me data retention much like gdpr is quite closely connected to policy debates in Europe and that a retention means that you do logging or it\u0027s logging for the purpose of monitoring in the European legislative context but I\u0027m wondering if there\u0027s a technical saltier that I\u0027m missing so there are some provisions in at least in GDP or there are some provisions about data that is in in memory for a very short time right if you\u0027re operating a router and your processing personal data but you\u0027re not you\u0027re not storing it and there are some provisions in there for for handling that that situation equally so yes you\u0027re right so logging logging and monitoring and data extensions I\u0027m I\u0027ll have to they have to do with each other right logging is if I have to say logging is probably something that you do to be able to see why something went wrong in the past monitoring is is something that you do to see if there is abuse on a surface or there\u0027s other stuff that needs your attention immediately so that\u0027s sort of guaranteeing the continuity of your service safeguarding their security and logging is something that you look at after stuff has gone wrong right so these are there some subtleties in there and so no but so also as a final point I could say that in the GTA in the gdpr come from the European Union zone and I\u0027ve worked the GD part for some years there is this section that talks about state-of-the-art technology privacy by default is the state of the art technology and so effectively I guess what would be defined by this group in the 980 F concept could could actually itself be used to define what the legal obligations for privacy protections are in Europe since since the law refers to the state of the art technology if you produce a draft standard here an RFC or recommendation that could itself influence what is the expected level of privacy in Europe and that might be valuable information for this group to take into account if it goes forward to this process okay well that\u0027s so that\u0027s a very good comment and also puts a huge burden on our shoulders but yeah it\u0027s team foul so I generally would be supportive of doing this kind of work I think I agree except and it\u0027s hard to say where else you could do it I would have a little concerned that maybe we are a bit early for BCPs on this I think it\u0027s no harm to start the work and but I don\u0027t know that we have great amount of actual practice to rely on and one thing that\u0027s it might be were thinking about you know to what extent do you want to include things that are bit more speculative in here like they don\u0027t filter things that are mentioned or maybe they should be in you know handled in other documents or other times as posted in this one documents well and thank you for that for a for the comment and for support I mean that is still that\u0027s also why this is we some I want this to be a living document "
  },
  {
    "startTime": "00:31:34",
    "text": "which can be a bit tricky which is also why we were opening asking the question to the room is this something that should be here should we consider doing it as a ripe document which might be more of a living document and yes it might still be quite early for to do something like this but we I mean the DNS a practice statement RFC was also at a time when very few people were we\u0027re doing D in a sec so having a some sort of framework that helps you sort of construct your your your privacy service might might be useful hey Jim Jim reads um pretty much what Stephen said I think some of the things here are premature I also think that\u0027s trying to come up with a koozie overarching potential policy Fremont discussion in analyses or soloing about Internet document in this working group is going to be a very difficult job and I think it makes why we\u0027re trying to boil the ocean so my suggestion for what is worth would be to first of all start by getting some of the people are deploying privacy services to document some use cases and things these are the things that we thought about will realize their service and these are the problems that we encountered once the service was noised when the data protection authority started knocking on our door and state repeating over her shoulder and asking questions I think that by good a better place to start but I\u0027m trying to find an overarching solution for everything which would probably never terminate and thought you would just seem for Roland with Medina sec policy statement that was a relatively simple easily constrained problem space by comparison so it\u0027s relatively easy to do simple math of programming rate but in this context what we\u0027re trying to achieve is much much more difficult there\u0027s a bigger problem space it\u0027s much more rapidly moving in all sorts of different contrasting directions and I think it\u0027s probably very very difficult to try to come up with something which encapsulates everything unless end or something so generic is completely useless yeah okay thanks Jim all right I\u0027m gonna cut the mic line at EKG pinnacle Teaneck so I really like this document it\u0027s a very good very very good starting point I have I am not sure about the the target audience and whether there is a single one because you already mentioned that there\u0027s the part that would address the potential provider of a privacy service and somebody has already said at the microphone that the considerations may only may also apply to a random resolve operator whereas the other part the the privacy statement or privacy practice statement so to speak would probably address even an end user and that needs kind of different skills and different language and so on and so forth I\u0027m not sure actually I\u0027m sure that not the ITF should engage in policy discussions or debates especially if it goes along the lines of what is in the gdpr and not because we have other jurisdictions and whether or not they follow the example of the GDP that is probably something that will never end "
  },
  {
    "startTime": "00:34:34",
    "text": "yeah so in in a in a updated version I think that there could be could be a split of documents by target audience and then a void for the for the operators for the ITF part avoid the policy definitions which does not mean avoid the enumeration of policy options but lots the the recommendations in certain directions like especially at issues with the onion for example that doesn\u0027t really have a ever places therein so just just to clarify a short clarification would you think that if we were to go for a more contextual or discursive way of writing this document that that would address some of those concerns because it would be I mean making it less prescriptive and more of these are the options that you have this way you can do if you\u0027re in this context you should consider looking at these options if you\u0027re in this context bar than saying you should do this you should do this so yeah that\u0027s that\u0027s probably it I had a bit of interference here so I couldn\u0027t really completely understand what you said but the we do have the privacy considerations in the DNS but there is not specifically focused on the univer on the perspective of the resolver operator or the user of a resolver only so focusing and that might be might be a good starting point and then for the policy part I think another venue might be better I don\u0027t know which one but I am as I said I\u0027m pretty sure that the idea would be the wrong one despite what Stefan said that people would have to be educated about the technology however we do have human rights people well we did have human rights people here in the room which is great but more of them and data protection practitioners and so on and so forth we need that on the scope and of course being partly an operator of an authoritative server I don\u0027t like being in the scope of this no seriously no that\u0027s not the point I was kidding I\u0027m sorry I think that makes little sense if you talk about the server because many zones are served by servers in different and under different management and getting that out as a statement of the sown owner might be more important but then again who\u0027s gonna read that and for whom is that report yes that\u0027s a completely different yeah actually you defend against some of these things by the measures that you suggested this not so keep keep keep keep the good work maybe split this and and make sure that you engage resume can talk offline and get with other people that might be more focused on the user site to get the language and the details a bit more crisp for for user consumption thank you okay Thank You MP so Warren Kumari both relaying a comment from Jim and my own so firstly various privacy organizations or agencies view the gdpr differently and so it\u0027s sort of the GDP are viewed through a lens not the GDP are and then "
  },
  {
    "startTime": "00:37:37",
    "text": "also following up from what both Peter and Ted sort of started saying um I would really like this technology to be widely deployed and I\u0027m kind of concerned that people who look at this document are going to assume that unless they\u0027re doing this specifically for privacy you know they shouldn\u0027t bother doing it and so I think it needs to be clearer that you know even if you\u0027re not a privacy DNS resolver turning this on because it\u0027s a good thing to do is you know no that\u0027s a good point we actually had that discussion already and it\u0027s the app yeah this is dkg so thank you for working on this I do think this is worth pursuing and I think this working group is a reasonable place for concluding the policy section I think the positive section is going to be tough but I think that coupling it with the deceptive discussions about specific technical measures is worthwhile a couple of technical points you mentioned IP Center or IP crypt in the draft I don\u0027t know if you followed the discussion on CFR G it looks like there are some significant concerns about IP pips and so we generally take care of that as far as I think Stephen was saying we need more practice before we can get to best current practice I don\u0027t have any problem with documenting the best current practice from a small pool of current practice if it causes other to start practicing and saying hey we\u0027ve got better practice we\u0027ll make a new draft bread so so I think making sure that those of us who are currently trying to operate services like this get together and encourage each other to make better practices by documenting them I think that\u0027s a very valuable thing to do and we do not need to wait another year to do something like this let\u0027s start the conversation and we\u0027ll change it later if we need to one thing that seemed like it might be missing from the draft is any question of you\u0027ve got padding there in terms of that\u0027s like the only piece of traffic analysis anti-trafficking elseis or traffic analysis countermeasures that you\u0027ve got in there and I wonder whether there shouldn\u0027t be some section on aggressive prefetch as a means of and we can talk about this more offline yeah but I feel like something about aggressive prefetch actually has both [Music] optimization wins and yeah it\u0027s also something that we at some point it came up in the discussion I don\u0027t remember when we talked about it yeah yeah that\u0027s a good idea yeah thank you all right um well while Tim gets to the slide switch over the next talk I just we\u0027re both interested in seeing how many people actually read this document all right um how many people think this is actually a document worth working on regardless of the venue great thank you very much oh and you\u0027re up again oh yeah but but this time it\u0027s my name on the slide so if I make mistakes now it\u0027s even worse so I asked for I asked "
  },
  {
    "startTime": "00:40:41",
    "text": "the chairs for a little bit of time to talk to you about an experiment that we\u0027re doing at surface so surface national research in education networking Netherlands and they\u0027re my employer and sort of privacy is a value that we hold really strongly within the organization and so that\u0027s why we\u0027re involved in the in the Dames privacy area as well so we run some of the servers that you can use today the the DNS prophecy experimental servers and and one of the things that we thought was well okay can we do something about this collecting query data because we are as an operator we want to know if some of our colleges or universities are getting hit by say for instance some indicator of compromise there\u0027s some malware out there that we can recognize by looking at the NS queries how can we do this without sacrificing user privacy and and this is one approach that we we have I\u0027m gonna go and talk a little bit more quickly about this because I have only ten minutes so so that\u0027s this is our main question right how can we detect if certain DNS queries were performed while respecting respecting the privacy of users and what we did was I III was talking about this to a Dutch company called a quarantine net that are that\u0027s very active in our community and they they have some sort of detection apparatus that will detect if there\u0027s Mel wearing your network and they and they were looking at this using bloom filters release so I\u0027ll explain what bloom filters are and and we are now starting to experiment with this in practice we\u0027re going to run this against our operational DNS recursos and see if we can use this as an alternative to to registering queries hands up who knows what a bloom filter is Wow okay good should I skip the slide analogous III I went through all this trouble to make really nice pictures about it so think of a bloom filter so a bloom filter is something that was this originally designed in in 1978 as a space efficient way to index large amounts of data right so if you have to find your area and the database if you if you do a query in a traditional database database it like Postgres or my sequel then odds are that they\u0027re using a bloom filter to to work out whether the thing that you\u0027re looking for is actually in that table or not or in that column or not because it\u0027s it\u0027s it\u0027s a fail fast way of looking up data in large datasets but if you take a step back you can think of a bloom filter as a probabilistic set membership test right you so you you have this unordered collection of data that you stop keep cramming distinct items into and then you can ask that a question is this element that I that I\u0027m now looking for is that in this data set or not and if the filter says no it\u0027s not endured and it\u0027s guaranteed not to be in there and if the filter says yes it is in there then there\u0027s a small probability of a false positive depending on how you configured your filter so how does it work in practice you take a domain name say here doubled "
  },
  {
    "startTime": "00:43:41",
    "text": "up example comm you run that through a shrinks your set of hash functions and then you use the output of that to pick a number of indexes in a bit array that you then set to 1 if for certain specific values that came out of the hash function and then if you want to do a lookup you you run the the lookup that you want to do through the hash function again you compute the indexes that should be set to 1 if this element is present and then you look in the end of it or a whether or not that element is present or not and so that the picture shows two examples of things that hash to different array indexes and then you can also immediately see why you might have false positive because some of the bits that are hit by my one name might be set because there are some overlaps in other names that trigger those bits to get set so there are a certain number of things that you can tune about one of these bloom filters that you can you have to pick the size of the bit array at the number of hash functions or the number of indices in the bit array that you\u0027re gonna be toggling depending on the outcome of the hashes and the expected number of distinct elements that you\u0027re going to be putting in there and then if you stick all of those parameters in this formula and here even sort of calculate the probability of a false positive and I\u0027m gonna save you the trouble of doing all the math if you pick a reasonable sized bit array say 16 megabytes 128 megabytes and you cram a few million queries in there you have a very low false positive probability which means that this is actually a really nice way to be able to detect if a query was executed now using this kind of technology in a privacy context is really interesting because these filters don\u0027t store the original query names right and there are no enumerable because I\u0027m not storing Lee if I were to store queries as the hashed query name then I could still presumably with some knowledge of the data that\u0027s going to be in there reverse-engineer what query was performed when what query it was and somehow reverse the hashing with things like remote tables or just brute forcing it with GPUs but that\u0027s still simply not possible with this if you sort of mix enough queries into that bloom filter you you don\u0027t know what the original hashes were that there is no way to reconstruct that and if you mix queries from multiple users tracking users is going to be become increasingly hard there are some exceptions to that though another nice property of this technology is that you can later take the bit array the the fit arrays from two filters and if they have the same parameters you can combine them into a single new filter that has a higher false positive probability but you have all the data that was in the two filters combined which is really useful because "
  },
  {
    "startTime": "00:46:43",
    "text": "for instance a we want to collect one of these filters every hour then we can aggregate at the end of the day and still know roughly with a slightly higher false positive probability what point of our queries were executed during that day and that a sort of allows for gradual data aggregation now there are some other considerations there there are some privacy risks right if you if you know of a query that unambiguously and identifies a certain user you can still track them say I record a query sorry collective filter once every hour I can still if I know that some user is always going to this one site that only that user is going to and there\u0027s the NSP for query for it I can check if if that query will query was in that filter or not and know that that user was active at that time it is almost impossible to correlate it with other queries for that user though so you will simply know whether that user is active or not so whether that\u0027s whether a serious or not is something that you need to think about but that is one of the risks and of course there are additional benefits this is way more space efficient than storing all the DNS query because these filters have a fixed reasonable size and it is time efficient lookups are fast so I think I\u0027m gonna skip over this so maybe a little bit about this picture what we want to do so we run a network for like I could academia in the Netherlands right that means that we have roughly about 200 institutions of higher education and research on a network about a million million and a half end-users we want to use data that we collect on the resolvers sort of strategically and tactically so we want to be able to see say if we have this indicate indicator of compromise that says that there is a very serious breach of security we want to be able to say which institution was hit we don\u0027t we\u0027re not we don\u0027t really care anymore which specific user that was because that is the task of the individual institution but we want to be able to say they were hit so we\u0027re gonna be aggregating or at least that\u0027s our current thinking users from certain networks into certain filters for that I have a master student working on this who is going to be sort of designing a system that not only collects the data but allows us to query the data we we\u0027re going to deploy this in in practice on on our on our busy resolvers I\u0027m not going to bore you with the details you can look at those slides in the materials for the session the master student will be using looking at three particular use cases so we get indicators of compromise from our national cybersecurity center and they come through the intelligence services so they claim that these are sort of serious things that we should be looking at and currently we have no way of looking at the NS data for this because we don\u0027t want to store a query data and "
  },
  {
    "startTime": "00:49:45",
    "text": "this gives us a way to do that we have a particular issue that young students in our network seem to think it\u0027s a good idea to DDoS their institution if they don\u0027t want to go to class and we want to know if they use booters for this and we thought it would be interesting to see if our mail filtering service hit certain names on black lists whether those names we get resolved by other people as well in the network I think this is the final thing I want to say the bloom filter library that we that was developed specifically for this purpose we funded the development of that as an open source solution so we\u0027re going to be erasing that under a BSD license and we also funded an outlet labs to to somehow do some integration with Unbound so that people can start experimenting with this we\u0027re expecting to release that code somewhere this year we don\u0027t have a definitive date yet um that\u0027s it I got time for two quick questions I alex me over here in that implementation that you did is there an option to dump the bloomfield thing to a file re-read it from that because I yes yes yeah okay yeah cool because what I like in bloom filters is I do it that way a portable format to actually transport new features from A to B because I\u0027m never quite sure is that begin yet little India and yellow ever so yeah that is in there yeah okay yeah cool Thanks oh hi Edward Dean this is really cool the one problem that you might have is the bloom filters lose the cardinality of events so while you can detect that it has occurred you don\u0027t know how many times is there anything that you\u0027re looking at to consider that as part of the design so yet yes there yes there is so there are options one thing that you can do is have multiple filters side-by-side that have different that use slightly different hash functions for inspired by pre salting them and then you enter your data into separate Bloomfield\u0027s you can then combine them to see to get some sort of cardinality there are there is such a thing as a counting bloom filter but we\u0027re not using that for the moment it\u0027s not so we are actually from us from a strategic tactical point of view were really interested in whether aquaria query occurred and not necessarily how frequently because whether a query occurred is then probably going to be a trigger for we need to look into this more with much more detail and then how it occurred is going to be the next thing to look at that answer your question yeah great thank you sued in York relaying for OMA cunt Ramaiah see and he said from the presentation it is unclear how the author intends to use bloom filtered names especially for checking if some query was performed before yeah because there\u0027s no guarantee for lack of false positives the bloom filter might tell you that someone that example.org was "
  },
  {
    "startTime": "00:52:46",
    "text": "queried when it was not yes so this is something that I think well McCune is referring to is the risk of a false positive and this is something that we actually want the student to look at we don\u0027t mind so much there\u0027s a risk of a false positive what we want to know is what is the impact of a false positive right because for the parameters that we\u0027re going to be using the risk of a false positive is like something like 7 times 10 to the power of minus 7 so that\u0027s a very slim chance but if we\u0027re going to be basing a decision to to actually start inspecting traffic on a hit in the filter or not then a false positive has a much larger impact on privacy then then you you you might want so that is something that we need to take into consideration now I hope that answers this question Christian Rita ma I that\u0027s a nice idea nice presentation but I\u0027m a bit worried whenever I see things that are based on hashes because a bloom filter is effectively based on hashes I\u0027m worried about the attacks on ashes in which the specific names for example of botnets could be chosen so they collide with also names or combination of names in your botnet so in your in your filter so they hide that\u0027s a really interesting premise so actually in this implementation where you\u0027re using or quarantine that is using sha-256 which to my knowledge at the moment is still collision resistant that - but yours using shaft 256 then you\u0027re taking eight buckets and you\u0027re taking each of the bucket you\u0027re taking the module oh yeah what in it so it\u0027s I\u0027m sorry sorry decrypt encrypted analyze at the mic but you can use a private salt for the folks who are building the bloom filter and avoid that yes and that\u0027s right yeah okay thank you for your time okay hello everyone so as you know the charter of deprive expressed the idea that we will walk first on the stubs over to resolve a link to secure it to make it more private with other clean off with the approval of ITF padding policies sorry of TLS supporting policies I think that this first part is done so we can congratulate ourselves we "
  },
  {
    "startTime": "00:55:46",
    "text": "managed to do everything which was in the Charter now it\u0027s time to think about the future and mostly about with over two authoritative link which creates some interesting challenge I already ordered draft about the possibilities for this resolver to authoritative link with a lot of different possibilities apparently there was very little discussion so I decided to do instead a specific proposal with a specific solution for the wizard road to authoritative link and I would like people to discuss it now so the idea is of course to use DNS of a TLS DTLS is done seem to be used a lot up to now so DNS over TLS which means tcp RFC 2766 etc the big problem of course with a resolver to authoritative link is authentication a stub resolver talks to only a few with ulvor sometimes only one so you can have static configuration of will enroll a resolver talks to a lot of authoritative servers so you cannot have a static column notes you need something else in my opinion the best solution is then it it\u0027s something that DNS people know it works it\u0027s already used for the web so it can be used also for authenticating authoritative resolvers this is described in this draft we did commented etc there are few questions which are still open in the draft on which I would like input from the working group is people are interested a good thing about then is that it\u0027s a signal that the server supports this protocol so in theory with then you don\u0027t have to prop the server you can you know that it will work you can try it immediately the problem is that in the real world many things can go wrong because then I can only signal that the server is willing to serve you but then cannot dwell on tea that you have a clean path with the server if you have a middle box higher water that where are you posted also if you use Dana you don\u0027t get the data always from the dns you can get them directly from the TLS server through the chain extension that\u0027s why currently it was recommend that you try TLS even before just before looking at dinner because of the high risk of port 853 being blocked I know that it is a deviation from what from the original idea behind them so it may require discussion also because for a long time a lot of authoritative nameserver won\u0027t have a dns or TLS it will be necessary for the way cursor to do some bobbing on for instance to try 53 on 853 more or less at the same time "
  },
  {
    "startTime": "00:58:48",
    "text": "in the spirit of the IP eyeballs so v2 RFC today the draft mention that a resolver can operate in strict mode we hiring authentication successful authentication or opportunistic murder well you don\u0027t have such a requirement of course today there are no authoritative servers with TLS so strict murder is impossible today and will probably be unrealistic unfortunately for many years so some people said that it should be dropped completely from the draft I heard that the TLS working group decided that years 1.3 yes it\u0027s really done it\u0027s okay so we make for DNS over TLS Monday it\u0027s use it this would require walking on this draft would require we shuttering of the group you have seen the new charter proposed on the mailing list because the current chapter only talks about the link between stub liens on the full resolvers so the previous charter said that we may consider mechanism but it\u0027s probably better to have a new charter I support the proposal also on unfortunately we have a big problem because the first draft about this idea of a second stage of deprive met very little discussion I mean there have been very few discussion not even strong opposition so I\u0027m wondering and this is something that we have to consider if there is still interest to continue the deprive working group or if we lose steam after the success of the first stage that\u0027s something interesting and of course we have to update the Charter if we want to do it otherwise deprived it is closed and we can go back to something else thank you now description 2 etcetera Tara speaking thank you very much for making the presentation I I note that your your concern that you you\u0027re looking for a mechanism to provide security here that relies on familiarity with the DNS rather than other mechanisms I wondered if you had considered using the DNS challenge for the acne protocol which simply requires you to provision a specific DNS record to demonstrate control of a particular name and then from there provision a standard CA certificate from acne it seems in many ways to be simpler and the tool chains for acne are definitely coming along nicely so I wondered if you would consider that as either as a replacement or as an alternate I didn\u0027t think of it there is something I really don\u0027t like in CA it\u0027s a fact that if you don\u0027t find the record you climb back the tree up to the TLD which means that dot FR dot com could put a recorder used by aldermen some dummies I always thought that it was a bad idea but "
  },
  {
    "startTime": "01:01:49",
    "text": "yet maybe something to consider hi John Dickinson firstly ice ID support recharging and now with the ban idea very I\u0027ll be wondering instead of using deigned with indicate the server\u0027s you already have keys in zones and you could potentially I guess authenticate the zone rather than the server I don\u0027t get it because you can authenticate the zone but what you want is to be sure that you talk to a server on that no one is looking so if you with it\u0027s always it gives in a zone that you if the zone signed yeah and can you not make use of public heat or something but you do but this is I mean maybe I don\u0027t know Society John Dane is doing functionally what you want already this is West vertical USC I say I like the idea of going this direction absolutely add the one question I have is the happy eyeballs comment because it sounds like you want to send it over the clear and encrypted at the same time is that is that really the the goal what one possibility is to try API both do not actually require that you send at the same time but one just before the other and with the opet you get a reply because today the problem of course if you send that if you wait a very short time and then you send the request in clear you don\u0027t have any privacy but today because most of the authoritative server not mask all for that if server don\u0027t support the DNS of our TLS yeah there is very if you want to save her Latin Caesar with little choice oh I I agree that it\u0027s bad for privacy but that\u0027s a difference between strict on the populace it\u0027s not by the way if you walk in strict murder you never try a 53 but today it\u0027s simply impossible let me give you a counter proposal because if you use Dane you can actually send a query for the DNS key in the Dane record at the same time and then the Dane record could be as a could be used as a signal that that port should be open so that will allow you to know by the time you get down to the point of processing the DNS SEC chain down to the Dane record you\u0027ll actually have both of those at the same time and then can decide where to send that the actual real data requested problem opportunities mode the problem with then is that then signal that you should be able to talk to the server but in practice and this is something that was often mentioned about DNS or TLS that there is a I are some probabilities at 853 is blocked so even if there is a dinner record you may be "
  },
  {
    "startTime": "01:04:49",
    "text": "unable to talk to the server on by the way this is one of the reason why doe was developed Jim Reed Stefan I\u0027m sympathetic to the idea of having some kind of encrypted channel between resolving servers north of servers well in my opinion is very very premature to talk about me chartering at this stage there\u0027s so many other variables to consider I think it\u0027s far far to have to stop or not work right now first of all we have very little way of operational experience with this door so with depriving this current state they\u0027re only a small number of experimental servers set up for that just know we don\u0027t have a great deal of operating operational insights and try to run these servers what the impact is going to be what the impact is on the end user what the impact the end users plus what all this horrible policy could coming down the track for all these privacy considerations and GTR will have the same thing on the authoritative side as well so that\u0027s a concern number one concern number two is there\u0027s our other stuff going on another deal another idea of working groups particularly in door and the lots if there\u0027s a lot more mayhem to paint or than the rest beside the workings in deep life in my opinion so we should also take that into consideration too I think I thought I thought very very important point is we need feedback from the people that are operating these authoritative servers note a cliff for Richardson T or DS because if they feel that this stuff is going to harm the service they\u0027re going to they\u0027re not going to deploy this pneumatic water so we need some expertise about what will be the impact and their stuff some modeling some data some testing some analysis before we start doing that path so good at least and understanding is something that if we come up with something from this working at some point in the future there\u0027s a reasonable chance it\u0027s actually going to get backed up and used and what I\u0027m concerned the rotate with this encrypted channel between the dissolving servers enough authority services we\u0027re opening up a brand new channel for really nasty DDoS attacks in which case nobody can get service from the thought of service because of too busy doing all the crypto regarding the last point first I can switch my ad can go from IETF participant to engineer a technique we operate authoritative name server for TLD I discussed this of course a lot with my colleagues before presenting this because I don\u0027t want to propose a draft that we can create trouble for us later on the problem does not seem impossible for instance the risk that the last risk that you mentioned we can have things like already doing some authoritative server to have to set up servers one for UDP one for TCP maybe a third for TLS and to use some front-end like DNS DS to dispatch between them so in that case even if the TCP servers are completely dead the rest will still walk yeah I\u0027m just saying hang on before we go down now we should try to get some data before we go down a particular path we need to do some analysis yes you can talk about these techniques define and maybe they were about maybe the world but that\u0027s "
  },
  {
    "startTime": "01:07:50",
    "text": "not the point I think before we start down that path we should start dying with the basis of empirical evidence rather than six but this seems like a good idea let\u0027s go ahead and do it which okay I\u0027m exaggerating for effect but that that I think is perhaps the wrong approach to take here and we should also bear in mind I think what was also said yesterday in their effort in the in assault back encryption or adding a lot of complexity and a lot of stuff already to the DNS isn\u0027t getting used so I think no stuff to feel that main to as a general principle that if we had the stuff is it actually going to get used in real life and will it make a difference all right hold on so I\u0027m gonna cut the mic line at all of her but keep it keep in mind that we do have a charter item to talk to talk about too so some of the stuff is if it\u0027s related to the to reach our Turing you can hold it till that but you know so let\u0027s focus on the comments for first up on the drop this is dkg I support recharging in this direction Jim I\u0027m a little bit confused by what you said because it sounds to me like you said we need more experience to see how these things work and we shouldn\u0027t be working on them and and it\u0027s and I think that that by by advancing a draft like this we will encourage DNS operators to come forward and say I did this and it worked or I did this and it did not work and here are the concerns that I have and having the draft in an active working group with a bunch of operators and it is the way to get exactly the information that you\u0027re looking for so I fully support working on this I think it\u0027s a good idea and I also think it\u0027s a good idea even for those recursive resolvers that are not doing DNS privacy to the endpoint like there\u0027s no reason that a a recursive resolver today that isn\u0027t offering DNS over TLS or doing or doing doe couldn\u0027t use something like this to protect the queries on the upstream leg so I fully support this work we should be doing well Phil hamburger I\u0027m very skeptical I\u0027m skeptical I 99% of the time when our DNS resolver receives a hook it\u0027s going to be served from cache we don\u0027t wait if the cache element is about to expire we will refresh it before it expires so the only time that we\u0027re ever looking doing authoritative to recursive whatever in response to a request from a user or or whatever is in the rare case that is the elements is not already in in cash so what we\u0027re looking at here is a fairly small subset of the traffic and what we\u0027ve also got to look at is okay I may not be able to see the bits on the wire because you\u0027ve encrypted them but the next problem that you have is the traffic analysis and leaking the "
  },
  {
    "startTime": "01:10:51",
    "text": "information from the DNS server that you\u0027re directing to and given the amount of effort that we have to go to to achieve the encryption I\u0027m not sure that the privacy improvements that we get our are justified by the number of attacks that are blocked by the encryption that are not blocked by traffic analysis so I\u0027m extremely skeptical of smaller percentage of queries I love to run TCP dump on the authoritative name servers and I see a lot of requests on a lot of very private because because many people don\u0027t use kuna minimization so I can see very long queue names already going in so maybe this is only a part of the request but it\u0027s an important part still now for the traffic analysis were already of padding on we could have other stuff like introducing arbitrary delays that\u0027s costly but or we could have what reduce traffic to try to fend off analysis but already we\u0027re spending we have already some a good way to address some traffic analysis issue I believe I stream peril I guess I like about what TKG said entirely I think it I think starting work on this is a very good thing to do I think and I\u0027ll be writing we should be doing all the things Jim was talking about while it\u0027s doing the work so the only other thing I have to say is on the authentication issue I\u0027m not sure that we so I think you\u0027re probably right to try and just pick a whole bunch of things to get people at disagreeing with you but on the other education one I think may be the right thing to do would be to try out and you know do some tests on various different mechanisms and see what looks better after tests are supposed to just by writing draft yeah this was what I suggested in the first buff before this one but that was absolutely zero discussion so yeah no I think I think your tactic is good but I think you should do the work Ben Schwartz so I think that yeah this is a hard problem although maybe not not so hard that there\u0027s a lot of consolidation of shared authoritative servers so seeing the IP address of a particular authoritative server gives you less information probably than it used to about what name is actually being resolved or what what subtree of names is being result I I disagree with a lot of the the design choices in here and that\u0027s fine I think that\u0027s that sort of an argument for chartering for recharter hola gloom Sun Thank You Stefan I think this is a topic we should be seriously thinking about I\u0027m not sure whether we should go forward with this document right now I worry about the fan-out from a resolvers "
  },
  {
    "startTime": "01:13:52",
    "text": "to authority-- lives we have a lot of authoritative addresses compared to how many resolver addresses other and so probably what I would suggest is we started studying a little bit more how we could coalesce connections into sites that are all hosts many authoritive servers and then scatter them locally and I\u0027m thinking of using possibly something like the NS dist to be the Terminator and so we need a protocol in here that we can tell it what address range is descent on it and that will also help defeat some of these traffic analysis that people are doing Cheers I I missed a comment that came in before he closed the mic line but Sara Dickinson had just said that so I\u0027m relaying for her plus one to DK G\u0027s comment she supports working on this now as the best way to understand the issues and while I\u0027m here I\u0027ll say the Tony Finch said +12 that alright so while while Tim pulls up the one slide we have for this the slides referred to a charter - I did send out a link to a charter 2.1 let\u0027s stick to charter - because the only thing that\u0027s different between charter 2 and charter 2.1 was mention of a potential work item related to the BCP that that we talked about earlier so the most for the most part what I want to focus on you can you can look at the the Charter text if you haven\u0027t already but in essence it\u0027s really the work items that are probably gonna be of most interest to people we can wordsmith the Charter to fit so what I\u0027d like to do is solicit comments from people who have either positive things to say negative things to say or questions about the text that we\u0027ve thrown up on the github and we have and I think we\u0027ll have to probably recharge slightly so we can actually start even studying some of this a little more in detail which probably isn\u0027t a bad thing and even if we say we want to recharter some but we\u0027re not gonna move forward on resolver authoritative do we have more substantive data I think even the ad is probably okay with that you know I know when I spoke with Terry about this we both felt that we could actually if we reach our turd we would also be considering the idea that the whole thing would be an abject failure because we you know we could get some result 30 of servers to work on it but we could never walk the chain all the way to the top without a whole bunch of political stuff right so a lot of people when they think of 30 or they think killed root servers and I started thinking about just people\u0027s authoritative zones it\u0027s start there and start collecting that "
  },
  {
    "startTime": "01:16:52",
    "text": "data because you\u0027re gonna have to prove each step of the way you you know you know will it work operationally right all right coming away hi I\u0027m Shane Kerr so these work items look good I guess the thing is it feels very much like we\u0027re in an experimental space here every I think every can all agree we really don\u0027t know exactly what the shape of the final solution would look like we may need to add functionality to the DNS which doesn\u0027t exist today which is outside of the scope of this in order to get efficient efficient operations and things like that so while I\u0027m very very much in favor of having the work proceed of trying to trying to encrypt or otherwise at confidentiality from the resolver to the authoritative side it\u0027s not clear to me that it fits well in the ITF working group model and I guess you probably considered this teri that maybe there\u0027s some better way to do this I RTF or just have independent researchers and developers work on it outside of this this idea teri Magnuson responsible ad yeah I thought about that that\u0027s why I put in experimental on the second bullet point just to start people thinking about how this could go forward whether it\u0027s in the working group is always an option for an ia by RT F work area I\u0027m still just here to listen to what everyone here thinks first I\u0027ve not made any decisions so I want to get a sense of really is their willingness how do people feel about going for various modes of attack on this sort of a problem Alex Mia Hoffer I have a similar comment I\u0027m happy with the first two bullet points yeah that\u0027s fine also experimental sounds very reasonable to me the third bullet point i I think in agreement with what you guys said I think we should push that to the irt FMF archie or somebody else I idea working groups are not great at doing measurements performance data may be the definition which means couple to working through but everything else about trying to gather statistics about operational issues that\u0027s not fetish projects is ethnic I\u0027m very much to support this work and the proposal seems to be okay to me at least the experimental part and maybe I should reply to Stephanie\u0027s question why there was a silence at least if I speak for us and not resolver developers we just had full hands with the DNS over TLS from stop the liqueurs if it\u0027s not that we are we are interested in implementing core banquette ideas how to do recursive to off what we just didn\u0027t have time before right so Simon\u0027s doesn\u0027t necessarily mean that there is no "
  },
  {
    "startTime": "01:19:52",
    "text": "interest just nothing I\u0027ve had any other comments or ideas board for this while we\u0027re here okay so run that run now for just on the last bullet the map RG research group are actively soliciting the input from IETF working groups where there are where there is measurement work that they would like done so that might be something you could consider i we know the RTF chair so we can talk to her and she may have some good advice for us on that as well yeah and I know the map party chair so there you go but you we know people so we\u0027ll take that as an action item to sort of to chat with them and and solicit advice from from them and Terry you seem fine with that as well yep I figured so okay that was great all right so my esteemed co-chair actually put this Charter up on on github so if you have comments and/or suggested change this to it feel free to do a pull request if you don\u0027t have a github account and don\u0027t want to get one then feel free to either post at the mailing list or send it to the chairs any other things that people want to talk about in the seven or eight minutes we\u0027ve got left all right going once going twice enjoy the recipe we quit very just bury with we\u0027re done you can sort of wake up down thank you see you in Montreal "
  },
  {
    "startTime": "01:23:11",
    "text": "you "
  }
]