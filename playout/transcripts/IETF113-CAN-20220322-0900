[
  {
    "startTime": "00:00:10",
    "text": "good morning welcome to the chem buff can everyone hear me okay i hear you loud and clear very good very good okay um so this is the computing aware networking buff linda and me are the co-chairs for today we'll get started right now first note well um please note that you agree to follow the ihf processes and policies including ipr policies and also please be cautious to your colleagues here escape the details here some meeting tips uh if you are here in person please uh join the onsite session of mid echo if you are remote make sure your audio and video are off unless you are presenting or skip the resources uh for this so this path what it is about the computing and we're networking aims at the computing and networking resource optimization by steering traffic to appropriate computing resources considering not only the routing metric but also computing resource metric"
  },
  {
    "startTime": "00:02:00",
    "text": "and service affiliations we have a million list dimecast at iatf.org we already have the note takers thanks to david and jungkook much appreciated so the purpose of this path is to increase the awareness and uh and participation in computing and where networking so that efforts can be uh organized coherently at this stage of researching to early engineering transition we will have a few words from our a.d jung later during this uh bob um we want to have these questions to have in mind um so that when when we come to the uh end of the discussion meeting to this in the discussion phase you will have some sort of uh um for example are the use cases important are there already existing insufficient solutions do you think the proposed solution will be useful or harmful in any way um would it be ihf work for example if yes is it in routing area and which working group or somewhere else or also there is their energy to continue the work so um we will for the agenda we'll start with the problem statements and use cases and requirements and then we're talking about two potential solutions one is load balancer based the other one is uh this dynamic anycast architecture will then come to the open discussion for 15 minutes and"
  },
  {
    "startTime": "00:04:00",
    "text": "then finally we return to those questions with shares and ideas to facilitate the discussion there i'm sorry it's hard for you oh okay i'll speak louder and closer okay um so i think uh for now we'll just uh turn to our ad john scott thanks jeffrey good day everybody thanks for being here um yeah i don't have uh a ton to say beyond what uh jeffrey already said to introduce the the buff um so uh thanks to to jeffrey and linda first of all for agreeing to share and i think they've done a great job of pulling them off together um yeah so um when we were approving the buff there was some you know sort of uh it seemed like the the history and discussion was largely around um is there you know well actually the basically the questions that jeffrey already uh projected which is um is this new work um what group should it land in and um is there is there energy to tackle it so that's what i hope the the participants will stick with in particular um in the ietf we have a uh a love of immediately diving into debating about the details of solutions and i hope we won't do that today"
  },
  {
    "startTime": "00:06:02",
    "text": "although debating about solutions is of course very much fun um so [Music] yeah please please do keep in your minds as we're as we're going to dip off today the questions that jeffrey just projected and i hope we're going to come away with this with some idea of what our next steps are thank you very much and let's go i just want to add a few words um for people who speak or answer questions please check the notes make sure your questions and answers are captured correctly and also your names okay thank you so now we will get started uh the first presentation is uh updates uh on the religious uh industry and standard organizations so sorry jeffrey let me um interrupt for just one moment with a question for the chairs i see there's a hand raised in the queue and i just um maybe you can say a few words about how you want to manage the queue and um you know uh q a during talks and so on so um i hope that the questions uh during the presentation only for clarification like say for example you can ask hey i heard you said this what do you mean for the debate let's wait to the open discussion about alternative solutions and different ways of achieving things so we see there's a georgia as a question yes my name is georges garagianes from hawaii i'd like to mention that we had some side meetings that are somehow related to uh you know to the content of this book and i like to uh so we had i think one on uh during the itf 110"
  },
  {
    "startTime": "00:08:02",
    "text": "and another one uh on the atf 109 so the name of the side meeting was dynamic indicas so dance and we had uh you know during the outside meeting the last one we had actually also three questions where the use cases that were provided there uh were uh well useful so there were some 40 from 60 people that were in the same meeting said yes then from uh there was also a question on whether uh you know the content of the of of the diecast was related to surrounding area so there was i think some uh 47 percent that from the people in the side meeting i said yes and then the last one if there was an interest to work on above and there were some 15 percent of the people inside me just wanted to to make a connection to what happened previously thanks thank you thanks hello everyone this is luis contreras from telefonica i will present a refresh on two initiatives that are being moved forward in formal standardization bodies in etsy and itut and if time permits i will also comment some other initiatives that could somehow complement the overall picture so the i will first talk about the initiative in etsy mech the initial idea of of mech you saw in the title when meg was conceived was the idea of exploiting let's say it's computing capabilities uh distributed across the the network basically thinking on mobile access right this is why the initial"
  },
  {
    "startTime": "00:10:00",
    "text": "acronym of macbooks is standard for mobility computing but along the the time the the the work is being done in etsy the purpose is somehow generic so dealing now or changing the city scope to multi-access technology computing in the sense also considering fixed accesses fiber axis and so on so far so what was the original motivation of a cmec the the the idea was to put into value the some ideas that some purposes that could be achievable through the project's computing capabilities in the networks first getting contextual information so the information that could be valuable for applications and services to exploit let's say to provide better mechanisms for delivering services contextual information such as the where the user is located what kind of access technology is uh using even which kind of terminal and so on so far in order to improve the delivery of the of the service also to have advantage of proximity with proximity we can enhance uh several parameters several service level objectives such as latency or throughput and so and finally having a a number of uh facilities able to host applications in in the border so this was more or less the main motivations of the work that we started in nc along the time er etsy mech has been working also integrating this solution with other solutions like hcnp 3dp problem forum and so on so far so trying to get really a consistent approach to deploying this edge computing facilities across the network so what you can see there are the number of participants in hcmec and as also all the specs are available and you can check with more detail so next please well the idea or max somehow changes a little bit the story on how the"
  },
  {
    "startTime": "00:12:00",
    "text": "applications could be developed so the idea is to transition from the original client server approach to something that involves another additional party right so we have a client the the edge part and the remote part at the time of delivering or creating the applications this could have some implications in terms of how to handle the traffic because we i mean there could be different procedures different processes for stealing the traffic across the different parties into the network so key is used to to understand how influence uh make on the on the routing and so uh are somehow listed in the slides so how to discover the edge by the users how the users connect to the different edges so what is the determination of anchoring one user in in one edge or one another or directing one user to an another what could be the capabilities of the different edges uh in terms of service to be provided to the user how to guarantee keos and what happens when the user is is moving no this is probably well this is immediately takes or heads to the idea of mobile but also we can consider seasonal periods where maybe the fixed user is moving from different locations and and probably could be of interest to take with him or her the contents alone he is located in different in different places next please so typically in etsy in etsy mech the developers the developments take periods of three years so in the case of fcmac we are now in the third year in the second and the third there have been interesting developments that somehow highlighted the integration with ie network so how to make a mecco existing with uh what is being developed in 3dbp we will comment a little bit later on on this and now in the third period we are er of the etsy mac is working in in some other capabilities that could be the deployment of mech facilities in uh in enterprise environments so this is linked with the idea of the the vertical industries and"
  },
  {
    "startTime": "00:14:02",
    "text": "so so how to leverage on those facilities that could be in different analysis domains in the private one and the public one and also it's not highlighted here but also make is working on federation so how to integrate resources from different providers and this could also have implications in in terms of routing the traffic because we are moving from the single domain environment to the multi uh multiminister the domain environment with could have some implications on on that so next please so here in in this picture you can see how mac is being proposed to be integrated with a 3dpp network with 3pp core the 5g core essentially so the idea will be to the initially to deploy mech capabilities after the upf so and from the point of view of how to handle the traffic there could be different ways of doing that one way could be uh when i say far way is just to to make all the traffic pass to through the mac environment for whatever processing for the applications and so on but also there could be another i mean the purpose we could either pass for processing the information and then uh sending the the process information to the uh to the next hop to the next environment and so as we saw in the in the picture for the applications but also uh other ways of handling could be to implement local breakouts for whatever application that could be local so somehow splitting the traffic and doing some processing in the traffic for improving the performance and uh and essentially to provide the the with the user with the service and he is he or she is demanding next please so this is an example of that so making this case would behave as an application function within the fidget core architecture and according to certain characteristics that could be uh identified for the for the end user for the term the user equipment the terminal in 3d terminology"
  },
  {
    "startTime": "00:16:00",
    "text": "uh make could drive some actions in in the traffic so probably could divert part of the traffic local for implementing this local breakout or giving leaving pass the the other traffic to the next data network uh exit let's say that would be the one that is on on the right so at the end the point here is that through mech we will have the possibility of influencing the way in the in which the traffic is still across the network so that there is room though there could be room for optimizing things from the routing perspective in this respect and next please we'll comment a little bit now about the another similar initiative which has been uh developing atut it's name computing network convergence and so how is is creating also a framework for control and management with the purpose of of taking into account the awareness of compute environments at the time of allocating our organization resources including computer and networking so next please so the this project was here um well it's an ongoing project so it's been developing sg13 uh was the study group 13 in within atut and then the main purpose of the the motivation of this project was more thinking on advanced services uh with the idea of the transition to the beyonce and so so far so in this respect they they are considering cases of high mobility and time varying features and with the idea of reconcile or or take into account the resources that you could have in different environments that are spread across the network and manage in a in a common way with the networking resources in order to reach those different environments requirements that were considered at the time of moving forward this this work was for sure the compute awareness so understand what are the resources the cpus the storage and so on but also what are the capabilities in the network side to reach those those environments also"
  },
  {
    "startTime": "00:18:01",
    "text": "considering fast routing are routine processes or situations in order to reach the different environments different services and applications being run on on these environments they were protocol programmability and flexible addressing for dynamically deploy and instantiate services on top of these capabilities next please so crc is considering three three or three volcanoes and at this stage one about the requirements another one about qos framework and another one about management uh an orchestration so the scenarios or the use cases that they are considering for illustrating or for developing the capabilities are low latency and high computing requirements service consistence and huge scientific data applications these are the use cases where they are elaborated the needs that are expected to be documented in the iut recommendations later on next please so um the work is yet on progress it's ongoing so there is no too much let's say mid immediate at least available in the documents so they have proposed they are proposing this kind of architecture that somehow is inspired on 3dpp architecture which is known as service based architecture but essentially the different components are connected together through a kind of service bus and in this service there are different capabilities for a network control for policy and and so um yeah so essentially this is the the point where where they are so considering as we mentioned before steam low latency high compute high computing high mobility dynamic services that could be deployed in different parts of the network and energy services also as well so next please well this is the final one this was just simply to summarize uh i mean two initiatives that are being developed in formal seos just to briefly comment there are some other initiatives for"
  },
  {
    "startTime": "00:20:01",
    "text": "instance in the linux foundation there are some initiatives for for these computer capabilities to be deployed across the network and also in the gsma there is another one which is named operator global platform but at the end what the proposes is to federate different environments across different providers even connecting to hyperscalers like amazon web services google cloud microsoft azure and so on so far so essentially to create a substrate or compute environments and and also well the objective of this on the purpose of this work that we are trying to move here would be to optimize the the reaching the way of reaching all these compute capabilities spread across and with that i think that i'm done thank you all right thank you are there any clarifying questions uh so eric not mark so in this mech and cnc work are they viewing it purely as a routing function or are they looking at like how do we enable end-to-end security like tls in this context or is it purely routing well they regarding routing they are considering capabilities of influence since the stealing of the traffic so the possibility of inserting rules and so for this local breakout and and so so far they are in the point of view of security uh i don't have an answer right now i um i i don't have an answer for you right now so maybe i can uh comment offline in the mailing list okay thank you i would get that this is related to the applications that are running on top but i will look for that and comment on the list okay thank you oh there are another question oh my name is george garagianes i need to uh put my name in the queue you know"
  },
  {
    "startTime": "00:22:00",
    "text": "why um just a question uh luis so you mentioned that uh the work has done and mecca and cnc might have an influence on on what will be done in the idea for example for this war what do you think what what what kind of requests do you expect to bring to atf from mac and cnc well i i think that the purpose would be to optimize the the the wage and we could reach the applications and services that are running on the different compute environments so to have ways of identifying or optimizing the the proper edge in such a way that the delivery is the most efficient as possible no behind efficiency we could have better experience higher qos higher throughput and so necessarily to optimize the delivery of the services okay thank you a quick reminder please state your name when you come to the mic i will uh have two more questions from jung and ac okay um i'm actually holding a place in line for jim yutaro who put a question in the chat his question is please provide an example of a huge scientific application okay [Music] it would be for instance the the transfer of uh datasets that could be distributed across the network so yeah the interchangeable data sets between scientific research centers and so on so that could be a way i mean there will be ways of optimizing the transfer of of these data that could have very high volumes and optimizing that transfer essentially ac ac lindem uh cisco systems what is cnc i found i found the multi-edge computing under etsy what is cnc i i looked it up and it seemed to be"
  },
  {
    "startTime": "00:24:02",
    "text": "something about machine tooling so i don't think that's the same one same standard so i'm not sure i got the question properly it's the cnc standard i've never heard of that i couldn't find that one cnc is computer and conversion what is it compute a networking convergence is that a division of etsy as well is that a subgroup or so that cnc is done in uh developing idut and mac is developing that team the problem will be clarified in the next slice the difference between cnc and the cn sorry for jumping yeah there are different initiatives here different architectures and so so different initiatives okay sorry the queue is closed after a win or we have to move on yeah my name is wim hendrix from nokia my question is the following on so today if you look to the 3dp architecture you go to the upf and then you have the mac behind right so normally to select the proper edge location already there are some 3gpp semantics happening to actually select the right upf to get the best performance for that particular application if you look at this work if i what you're presenting here what is is is this behind the upf you try to optimize where the resources are coming from that the application is going to provide to that edge location or are you trying to influence the 3gbp mechanism to make a better selection to select that upf location so my so that's my question regarding this bring new routing work to itf and which location or at which part of the architecture are you trying to do that traditional uh"
  },
  {
    "startTime": "00:26:01",
    "text": "let's say logic yeah okay thank you so the what he makes is proposing are different use cases of integration they are looking the way of how to integrate in the 3dbp what we have seen here is just one one example one case right so in this case they yeah the idea would be the mac identifies the the specific user and then instruct the epp to to somehow implement for instance local breakout and so there will be other ways of integrating on not only this one but this let's say pure your mech architecture so there could be influence on on that in the routing for sure but um as i see at least this will be let's say out of a scope of icf the atf would enter in the in place once we have to do some routing or as consequence of this integration from hc mechan and cpp i just want to add one more point here yes please um the mec and cnc by itot is not the entire work done by ietf so the later presenters will show what the work they expect to bring to ieta yeah this presentation is mainly to talk about the big environments mec and and cnc the work going on outside the ihf and next we will have the specific use cases move on to the next one now okay can i hear me go ahead okay uh this is from you from child mobile and i'd like to introduce in same use case here and play"
  },
  {
    "startTime": "00:28:02",
    "text": "next okay this guys can clarify clarify some questions for the previous part of the sensei and ken problem so um the cam aims at computing and network results optimization by steering traffic to appropriate computer cells considering not only using metrics but also complete resource metric and the service videos which were shown in the trail slides and we see it as a problem demand for item routing and the similarity of things is that both of them considered computing and network resource joint optimization but since we focus on the vision scenarios requirement architecture and network function enhancement for future mobile code network and telecom fixed mobile satellite convergent network but not for internet or routing area that i can be concerned so i think this question can answer uh this until you can answer the question before next time please and before the real use case i'd like to introduce some facts of the rapid development of integrated isaac infrastructure different from providing the network's infrastructure only operators has been developing the city and outside the viewers based on their own sites which do provide both network and information infrastructure so at this stage so many student nodes with servers installed which can be appropriate to visit and at computing infrastructure while more diverse computing results need to be provided compared to the cdnos original content cache results"
  },
  {
    "startTime": "00:30:02",
    "text": "moreover more edge computing nodes will be set up in an on demand manner here's a typical analysis result with the product number shows that we may need to build so many edge nodes around a company aggregation network access aggregation network and on-site so not only for channel mobile there are more and more service providers over in the integrated ict infrastructure so next size please so why does the infrastructure develop so fast it is because of user demand here are two points first is that users want the best user experience such as low latency and high reliability between the emerging new services such as high definition video vr and live broadcast and so on another is that the stable service experience will move into different areas as we know uh the mobile network developed better providing more convenience for users to use lightweight clients to get more application service however only the new infrastructure themselves might not only enough to fully guarantees uh quality of service more need to be done we summarize three points first one is provide the functional equivalency by developing instance for the same service across each side for for better availability and then keeps load balance for both static and dynamic scenarios by both up layer and network layer solutions as we know there are some load banks or traffic engineering for computing and network demand but only for them each of them and the third one is stereo traffic dynamically to the best service instance"
  },
  {
    "startTime": "00:32:03",
    "text": "it can be seen as traffic is delivered to optimal exercise according to the more starters for example aid computing and the best should be uh defined for each service uh sometimes it might be the appropriate one but not real best one okay next guys please um so don't we have the thoughts to meet the mind but the fact is that edge computing has advantage of clothes but sometimes the clothes is not the best which is the point of the use case the problem some reason is that closest sites may not have enough results because the load may dynamically change and another is that a closed site may not have related results and heterogeneous hardware in different side stats we next please and here we use three tries to describe why the closest is not the best in some cases this is a common way to develop the edge computing there will be at the center for metro area which has high computing results and will provide service to more users at the working time because more of its building will be in the metro area and there will also be some remote exercise which has limited computer sales and provide the service to the us cloud to them so in the case in this case the service quest and the results are messed with some potential traffic steering may just need for special service requests or some small scheduling demands so please remember the location of the ue that will change in next slide so next place so we can see that in this slice it will move from metal area to the remote side in the right side"
  },
  {
    "startTime": "00:34:00",
    "text": "uh it is because it's a weakened or some of the daily nights whatever it's not some working time uh well you will move to the remote area that is close to their house for some weekend events so there will be more service requests as remote but with limited results committing results while the rich community resource might not have been used with lesser in the metro area so it needs to steal some traffic to metro center because only for one or two days you can justify adding servers to the remote site okay next please this shows there also be some common common variable of network and computing results for someone who is not moving back at a politician sometimes because of other use moving a large number of requests for temporary even certain vocal concerns shopping festival and so on and there will be also the normal change of network and the convenience of status so it is more optimal to steal traffic from you some uvs to others dc um next place okay from above three slides we get the first considerations the high computing results need needed by ue at remote site for short period of time which is not long enough to justify adding more competing results at the remote site so the traffic needs to be still among different edit sites look intense please so it is enough for just the one consideration and the conclusion most thought is that when during traffic what factors should be considered because some applications require both low latency and high competing resource"
  },
  {
    "startTime": "00:36:01",
    "text": "usage or specific computing hardware capabilities such as local gpu hence joint optimization of network and computing results may be needed to guarantee the qe and next please this is a typical application of beyond vr as an example the upper bound the upper bound latency for motion to photon includes frame rendering and requires less than 30 milliseconds to avoid motion thickness consisted of four parts first is the sensor sampling delay which can be seen as 1.5 milliseconds and the second is display refresh delay which can be seen as 7.9 milliseconds and both of them too are in the client and not with control by the network or the cloud or server and the frame rendering computing delay waste gpu could be optimized timing to 5.5 millisecond millisecond so the network delay budget could be calculated as uh 5.1 millisecond so we can get the first point is that badges for computing delay and network delay are almost equivalent and there is a picture in the right side shows that the client could the client request could go to the headstart one two or three uh to uh to get service and uh the corresponding uh network delay and complete delay show here so we can say that if we choose as sides according to the competing load only uh it will be as the one and the total delay will be 22.4 milliseconds"
  },
  {
    "startTime": "00:38:00",
    "text": "and if we choose edge side according to network only it will be the inverters at 2 and the total delay will be 23.4 milliseconds but if we consider both uh it will choose slot three the total will less than 20 milliseconds okay the total delay i include the delay in the client showed it is 9.4 milliseconds so we can get the second point is that it can't meet the total delay requirement for uh of finds the best choice according to either the network or computing resource letters um the final conclusion of this two point is that it is required to dynamically steer traffic to the appropriate edge to meet the end-to-end delay requirement considering both the network and the computer company resource status and what's more company resource has a big difference in different edge sites and the clothes may may be good for literacy but lacks gpu support and should therefore not be chosen which gives more factors to considering the computer sounds the next place and not only for the and vr more applications such as intelligent transport uh includes connected car and video recognition at the inter section we also have the requirement of joint simulation because both of them require low latency and high bandwidth and high computing results moreover due to the mobility the load of network and that site may change dynamically and rapidly"
  },
  {
    "startTime": "00:40:08",
    "text": "hello are you are you still there we cannot hear you hmm okay uh in that case should we move on to the next one yeah maybe somebody else help finish the presentation i think this is the last slide we have uh three more slides maybe i'll just show the slides and see uh people can read off the screen uh introduce the uh slide okay okay we will have more application uh uh we will need some new solution uh right so as you can see from here we have multiple edge sides one and two and three right but they have different requirements of the network of the computing resources right so we need to uh consider post okay polly is back do you want to take over the right yeah yeah yeah yes yes so i lost my network uh yes i i don't know where i worked so this slides just to show that there are more applications require the joint optimization of the computer network source and the mobility will bring a higher challenge of them that will cause the network and edge"
  },
  {
    "startTime": "00:42:01",
    "text": "site may change dynamically and rapidly so next slides please okay so uh i can't see the screen do you want me to have some next one uh yeah yes yes um so oh no no no previous purpose sorry maybe network is good no not not good yeah complete no no no privacy one i think we need slide 13 uh the consideration before this time before this slide yeah yeah yes um here is the second consideration is that those apps require both low literacy and high or specific convenient results have the almost equivalent budgets for community and network delay and the load of the network and the edge side may change dynamically and rapidly so when steering traffic the real-time network and the convenient resource data should be considered at the same time in a fast effective way okay next here we summarize two preliminary conclusions of its uh birthday the traffic needs to be steered among different edge sites and when steering traffic is real-time network and computing results data should be considered at the same time in an effective way okay that's all thank you thank you um we have two minutes for clarifying questions jung genuine you are next in the queue"
  },
  {
    "startTime": "00:44:04",
    "text": "come hear me yeah i want to ask you a question why computer resource is different from any other resource okay a good question community resource includes the load chip category and cache it is different from the network jobs which can be measured by bandwidth and delay so it is more complex to model measure and represent the computing results that are in a higher variable way at this stage so maybe the computer source is a new work item this information model yeah hmong show uh hi hi uh thank you the use cases here are very meaningful but i think some other applications like short videos live streaming may also benefit from the joint optimization of computing and network resource i hope they could also be considered okay thank you here we just show some typical use case and more applications will be considered um in the future work so we also welcome anyone who has an interest when uh where madrix uh nokia uh i have a question so i understand uh the context right so but so when we say we want to steve the traffic to the proper edge right what do so do we say we have to select a upf based on that application or do we go beyond that upf so it's related to my first question that i asked during the session and i also believe that probably you want to do the steering per user or per let's say i the end"
  },
  {
    "startTime": "00:46:00",
    "text": "point based on application right is that so it's not just an anchoring to the upf but you actually want to do it with application awareness that you say okay ar goes here uh something else goes on this side because it has better resources is is that uh my proper understanding of the context that you're trying to address here uh okay thank you uh i think they may be playing two different areas to solve the problem uh we uh there's a way to to uh choose other sites based on the application or clients structures but we think uh force the critical use case like rvr um the application based solution may be not as quick as a roading or the other rebased solution and i think those those details could be discussed in the solutions part yeah yeah so the reason my question is the following to understand at what level we are trying to solve the problem because i think there is potentially three options of doing this and i'm i'm not precluding it but if it's really per application you probably are you need some application awareness right so you have to have a tie into that the second way to solve it and i believe 3gbp has a lot of mechanism to even do puri and per application already today to say okay you can select based on this application ue a dedicated upf so that's already in place so if that's true then i think this problem will have to be solved or is being solved in 3dp space and not in itf and then third is you could say okay you do something you have to do something beyond the 3vp level and actually do it in the in the routing system"
  },
  {
    "startTime": "00:48:00",
    "text": "but you have to if the context is really 3gbp or 5g and stuff like that we'll have to have that interworking with 3dp somehow so that's the reason i'm trying to understand a little bit the context of what and at what level and which parameters we want to use in order to do this thank you bro can we come back to it at the open discussion case i think that my question is quite specific i wanted to ask if computing resource is measurable and thus it's a its own service level objective or it's rather uh unmeasurable and then it's a service level expectation thank you um yes as a previous uh question the computer south measurement is not so uh so so uh being a really either way directly uh we may just consider two ways one is the user index to represent its level for the load or um to bring more informations um for small uh that um for more specific using yeah and that that will bring specific new work and may also can be discussed in the solution part but if it's not measurable that how it can affect site selection so yes it could be no matter what i think but it's just to uh to choose to marry it um in uh in different ways yeah"
  },
  {
    "startTime": "00:50:01",
    "text": "you cannot improve it so it should be measurable in my opinion thank you uh let's come back to it uh during open discussion we're moving on to next presentation gap analysis uh yes it's also me to introduce this part and based on the use case discussed before we can get the preliminary conclusion of joint optimization of network and computing results so here is the gap analysis requirements next please okay next here we list some existing solutions based on the assumption of supporting the network and computing joint optimization and almost four to one as a dns use rebounding to explain safely bind from the service identification to the network address and geographical location to pick the closest computing results and the health rack to realize load balance and prevent single point figure and the load balancer could be seen as the external components of network designed for complete demand to support the load balance goodness please first is for the dns yeah we analyzed it from three aspects one is the early binding and the health check and the load balance over the dns and for the elevating it is for the price reserve iphone and then steel traffic and these always use the dns entry cached as at client the information are owed and not be so real-time and often the reserver and load balancer"
  },
  {
    "startTime": "00:52:01",
    "text": "are separate entities which incurs even more signaling overhead by needing to first resolve and then redirect to the load balance for final decision so the resolution is layer 7 of application layer level decision making for example the database lookup it is originally intended for the control but not a database speed in words it may be a little slower to your usage and the for the health check is um a frequent basis so each when you're over um the but the limited uh computing results um edge will change rapidly while more frequent health check is prohibited in cost and the load balance over dns really focus on edge server no first then utilizing lower latency loading to the selected server's ip address it lacks a combined consideration for load and latencies for better end-to-end guarantee and and we also have the problem of how to obtain necessary metrics for decision okay next please second is for the load balance load balancer we will show two common ways of the load balancer one is a single load balancer in a single site for all server instance um it can be found in the edge side two there's a load balancer and worked on as edge one two and three so the advantage is that it is easy to deploy uh to be deployed and about the comps includes that it can it has a single point of failure at the load balance and the network path from the load band to a server instance for"
  },
  {
    "startTime": "00:54:02",
    "text": "other site might might not be optimal for example as read and dirty the path showed um there's an additional path from sli two two as one and another way is that each site has its own load balance um the prompt is is a deployment but there's no load balance among multiple sides because it has only worked for itself um so it can't meet the use case of all the other requirements and okay next please here's the summary of gaba analysis uh uh first one is the dynamicity of relations um the existing solution excavates limitations in providing dynamic instance affinity there are two aspects first is dynamically and then to keep the instance of anything to extend we list the thing as an example is not for on design for this level of dynamicity and it's made many minutes left originally and declined to flashing the local dns cache and frequently resolving may lead to over load of the dns and the efficiency problem is that the existing solution may introduce additional latencies and efficiencies in package transmission under complexity and accuracy the existing solution require careful planning for the placement of necessary contribution function in relation to the resulting data plan traffic which is difficult and may lead to the in accuracy of the scheduling and next is metric exposed and using"
  },
  {
    "startTime": "00:56:01",
    "text": "existing solutions lacked necessary information to make the right decision on the selection of the suitable service instance due to the limited semantic or due to information not being exposed finally the security uh it can business as the existing solution may expose countries whereas data plan to the possibility of ddos attack on the resolution system as well as service instance okay next please so here's the requirements next please uh we just to consider from the use case and the gap analysis here the main goals to meet this use case one is open choice consider to access the location of multi-computing results and dynamically considering to collect the appropriate computing results dynamically and then using the multi-metric to select the edge the next place so here is the potential requirements in this format is wrong but doesn't matter first one support multi-access to the available outside dynamically based on any cast or other potential solutions and second is support considering they're using both network and computing magic as discussed before the computing semantic model information may be a potential work item for it and the read control signaling of matrix should be considered to not to bring so much pressure for the network"
  },
  {
    "startTime": "00:58:02",
    "text": "and the third one is support effective complement source reference retention reference representation and the capacitive by using the single index for example for the cpu threshold or multi information for specific purpose and the fourth one is supports the interface between network and computing components maybe by centralized or and decentralized advertising and signaling and next is supports the session continuity and service continuity to realize the functional equivalency in different areas and the last one may support the management of network and company results i think this is the last size so thank you for this part okay we uh have two minutes for quick uh clarifying questions uh for open discussions we have 30 minutes arranged at the end how uh hi i am not sure if there are any other potential existing solutions need to be analyzed so i hope to include more analysis such as sfc i think we should be more persuasive for the world thanks okay thank you we analyzed the modern show in the slides at that user case impact and we will consider more analysis of other existing solutions we need it we will update in the draft thank you should learn the network status to meet the use case demand right"
  },
  {
    "startTime": "01:00:00",
    "text": "uh so sorry i didn't go to your question uh for what yeah for the load balance you should learn the network standards to use case manager okay thank you um as i know at this stage the load balance doesn't really know all the network leaders it is a possible way most details of the solution could be discussed in the following part thank you okay well we'll move on to the next topic two potential solutions uh but then we'll come back to open discussion just one thing shraddha hello can you hear me hello yes we can hear you yes we can hear you okay so this presentation is about uh moving load balancer based solution for the requirements discussed for uh computer where it works so just to reiterate the can problem statement so requires the traffic to be steered based on the computing resource or the load metric should also [Music] consider the network availability and the network metric the third requirement is to have a service opportunity that is some computing same computing resource should always be"
  },
  {
    "startTime": "01:02:01",
    "text": "used by certain clients so this seems like a very familiar set of requirements next slide please so the definition of load balancer right as we see from a google search it says it's a traffic cop sitting in front of your server so basically it takes the client requests and then um distributes them to the available servers that are serving that particular application based on the the workload on the servers so and it also keeps track of the health of the servers and then the ones which are online it makes sure it sends the requests to the ones which are online next slide please yeah so load balancers they they ensure high availability and reliability right so by sending requests to servers that are online and also ensuring the client requests are properly load balanced across these servers so and it also provides flexibility to add or remove servers as and when needed next slide please so the load balancers are also known to you know support these session persistence which means a certain client is is a is a allocated a certain server to to use that application will continue to use that same server for that particular client and this is called a session persistence in load balancer terminology"
  },
  {
    "startTime": "01:04:01",
    "text": "uh another use case for this uh session persistence is also when there is some sort of client-based information caching that is used and that also you know using the same server uh you know allows for using the uh using that cache related to that client which means you know better performance next slide please yeah so the modern load balancers also support service discovery health checking and you know intelligent load balancing algorithm so service discovery is sort of figuring out where the services are their location and their names and addresses and they're capable of finding out the load on them and then route the traffic to the ones which are less loaded and the load balancing algorithms also keep track of i mean they're capable of you know considering some network information such as keeping traffic within zones and so on so most of the information that that we discuss in this slide deck is from the publicly available information right like i i am a routing person like most of us in the room and this information is mostly taken from you know google search where it landed me onto some official blogs on commercial load balancer products which talk about what the load balancers can do today and where i mean how their what is the future for these load balancers look like next slide please so the types of load balancers um layer 4 and layer 7 load balancer so layer 4 load balancers look at mostly tcp and udp headers and the load balance based on that"
  },
  {
    "startTime": "01:06:02",
    "text": "information which is so this l4 load balancers are highly scalable and better performance but there may be some efficiency problems due to application layer invisibility and l7 load balancer solve that problem they look into the application layer and then they um provide the load balancing they're the most efficient but they may be slower due to because they have to observe the packets up until the l7 application level information so there is also a hybrid model that many solutions provide were in a mix of l4 and l7 load balancers so there's a first level of l4 load balancer and then which sort of load balance is based on tcp odp headers and then there is a l7 load balancer that will further load balance based on application layer information so this is also sort of existing solution that has been that's available with the load balancers next slide please so we all know that you know network layer can provide paths with strict sla guarantees right so it's responsible for delivering strict sla so if you if you request the network to you know provide paths from point a to point b which are bandwidth guaranteed or you know latency bounded for example uh a path with uh you know within five millisecond delay and then uh that should guarantee one gig bandwidth that's that's kind of supported today by the network layer it can it can it can"
  },
  {
    "startTime": "01:08:00",
    "text": "uh either through distributed traffic engineering or centralized controller-based traffic engineering that the solutions are available in the network layer that can provide paths from one point to another point with strict sla guarantees and additional guarantees would also be served with network slicing solutions such as reserved queuing and packet prioritization based on the packet types next slide please yeah so so this the slide is showing uh you know from point a to point b you know uh paths satisfying strict um slas and network controller can you know it's capable of providing this um strict guarantees uh pass from point a to point b uh and then if if a path is not available for example here from the top uh node uh to dc3 the there is no um there there is no path that satisfies you know five millisecond delay and one gig bandwidth so there is no path there you can see that network controller ensures that paths are created only when these stricter slas are guaranteed and paths are not available to a point if if you know network cannot provide that path next slide please so knowing what the load balancer can do and what the network controllers can do sort of um analysis of whether the load balancer can be used for the requirements um posed by a can so the load balancers and the servers are at the are at the overlay they are"
  },
  {
    "startTime": "01:10:01",
    "text": "not really in the routing layer they are they are in the application layer and then they turn the server address to an individual on any cast address the individual site address and that is and when they when the load balancers do that they use the information uh of the um the compute resource availability the the load on the compute resource and when when they do that they also consider the uh network information that whether the required sla path uh the required delay measurement and the required bandwidth constraints are met and a path to the particular site is available they can take that input from the network controller and a combination of load balancer and the network controller talking exchanging information can ensure that the uh the right site is chosen uh for uh the for choosing the location uh for serving the application next slide please so this is this is the uh load balancer architecture uh sort of this is where the future of the load balancing architecture is the load balancers are deployed on the ingress uh it's very close to the upf uh there are various options that the uh that that are uh available for the load balancer it could be virtualized or it could be dedicated device or it could be um as part of you know uh software that resides um along with the uh"
  },
  {
    "startTime": "01:12:00",
    "text": "along with the upf and then there's a global so some sort of uh global um input is also helpful in making the most appropriate decision while choosing the sites where the traffic is diverted so the there's a global load balance controller that sort of provides collects input from the from all the locations on the service instances and the load on those service instances and provides input to the load balancers on that information so it can also collect the network information from the network controller so whether for example on demand it can ask for information whether for this particular site there is a network path available that satisfies particular latency and bandwidth constraints or other constraints that are required and based on that input the load balancers can make a decision to choose the optimize the right site where the traffic need to be steered so most of this is all uh information on wire line networks but it does it looks like most of the things are really common even for the wireless or the mobile use cases the additional information additional requirements would be to take care of ue movement in wireless environments from from one location to another location and using some sort of storing session information looks like load balancers would be able to support uh those use cases as well next slide please yeah so so in summary the can requirements involve selecting service instance based on current state"
  },
  {
    "startTime": "01:14:01",
    "text": "of the service instance and modern day load balancers they perform sophisticated functions of choosing the right service instance so the load balancers run in overlay and they abstract the applications uh uh from the network and so a combination of intelligent load balancers along with uh smart network layer so they they can probably able to solve the uh can requirements okay thank you yeah that's that's um that concludes my talk okay let's have a quick character and questions dirk um hi dirk cross and um why are we um looking at the previous item saw there they were not numbered i'm not entirely sure which slide i'm going needing to go back to um you mentioned address rewriting um so it sounds like a what you're proposing is a layer 3 load balancer but isn't that conceptually the same as what the diencast draft calls the router and the second question i have if you have this slide on here and i think last ask a similar question i reply to his question in the chat is isn't there a lot to be talked about if you have load balancers now at every upf and i want to mix and match load balancers i need to understand how the control traffic from the load balancer controller to the load balancers look like in order to have consistency of sessions if i want to mix vendor and vendor b on upf 1 and upf 3 i need to make sure that the the entire signaling of the metrics the metrics that are being exchanged are somewhat understood and be treated the same way otherwise i'm moving as a ue from euph1 to upf3 and suddenly my behavior changes because the"
  },
  {
    "startTime": "01:16:01",
    "text": "different so it's the question about where do you see you know what's the difference really between the l3 load balancer and what i think the diecast architecture later in the next presentation called the d router and how do you see the coordination between the controller and the load balancers being done yeah maybe you can listen to the next presentation about doncast and then come back to the open discussion okay thanks a couple of comments uh one alt has been formed 2008 a lot of the problems have been defined there and partially solved metric definitions there are a lot of documents that are either rfcs or very close to become rfc please take a look at them number two i think using an abusing 5g terminology is really dangerous thing to do here it goes actually to vm questions a lot of this issues have been solved in 5g packet core and control plane it's not a routing problem so we are trying to get a user to write location upf could be there could be something that could be bng i think if we abstract terminology the solution would become much more applicable it's definitely not a 5g problem so abusing terminology is the best thing here number three would be looking around every cdn and hyperscaler including my employer we are deploying hundreds of each location every month they are not connected by black magic let's take a look at what's been done we don't want to take re-version 2 and go to adr and you know offer them to do inter-domain routing with it there's existing technology that really works thank you thank you um okay well very quick one then we'll move on to the next one"
  },
  {
    "startTime": "01:18:01",
    "text": "uh dan boganovich so what hyperscalers can do with the existing technologies their application and network requirements are aligning but for the individual enterprises and the network providers they they might not be aligning and for that reason some of the existing technology that that we are using today cannot answer some of the problems that the enterprises are asking okay now we're moving to on to the next presentation hello yes while we're queuing up the presentation let me just remind everyone to state your name at the mic i know that if you're using the uh um you know the the mic line management app it does pop your name up in the display but um that doesn't help with the recording so please do remember to state your name by the way my name is john okay okay hello guys my name is jeremy from huawei so the topic today is about diecast architecture so what is the cost the cost is dynamic uh any cost which has been uh proposed in the uh draft the diecast architecture so next please so the cost uh is a potential uh solution for can right so this is overview of the diecast service model suppose so first of all you can see that we will have multiple service instance to be installed and running in multiple edge sites right and this"
  },
  {
    "startTime": "01:20:02",
    "text": "kind of services will be presented by several anycast ip address and this kind of fip anycast ip address will be distributed to the client by the dns system right but the key problem is that the key question is that how the client can find the best server the service instance among this kind of uh service instance running in different edge sites that is the problem that we can we will try to solve in in can in diecast right so we define some elements for example d router dma something like this uh and i i would introduce the detailed information in the preview in the following uh slides so uh maybe we can go to the next slide thank you next okay we define some new terms service uh it's really easy to understand it's yeah it's kind of functionality to provide some yeah service right so the service instance is a running environment that makes the functionality of the service available right and one service can have multiple instances running in different edge sites in at a different network locations right we also define some new elements called the router dinette diecast route router it is a node support site cost functionality and we have we also defined the mma the custometric agent it's an agent to collect information the collective uh uh i'll say the computing a metric and send a metric among the uh ma and the routers"
  },
  {
    "startTime": "01:22:00",
    "text": "but it does it will not perform the uh forwarding decision right so in order to identify the service we proposed two uh uh terms right here diecast service identifier uh which is uh dc uh standing for right uh it is an anycast address address identifying a service intercost and all service instances running the same service are identified by the same dc and in order to identify the service instance we would propose a new term called diecast dividing identifier the feed and it is a unicost and just so so that the the the client can reach to the specific service instance by this address right so next slide please okay so in our design the die-cast architecture have two modes one is distributed and another one is control cancel centralized right so uh i will go into the details of the uh distributed modes today and let's take up uh take a look of the distributed mode at the left side in distributed mode that that constant node will be aware of the status of computing resources and this kind of metric of the computing rate source would be distributed among the die-cast capable nodes so that the uh optimal uh forwarding or routing decision can be made by the ingress d router right in the centralized mode we will have a computing resources management platform to collect all the status of the resources and send this kind of information to the network"
  },
  {
    "startTime": "01:24:00",
    "text": "controller so that the network controller can make the optimal decision decision like the one in the distributed mode right so next okay this is the distributed mode of the die-cast as you can see from this figure we have multiple uh elements like the routers running in the network this kind of uh the router we provide the cost functionality and in order to collect the uh uh computing resources status and distribute them among the routers we define the metric agent right dma so you can see that the dma will collect the information and send to the router and and dma can be can be a logical function running on a specific router right so by this way we can collect the information and distribute it distribute the information among the router so so the router can have this kind of uh computing uh resource status so uh combining the network metric and the uh computing resource metric the ingress director can and do the best uh a decision of voting yep next please okay so this is the format of the service metric information in order to support that cost we need to define a metric associated to the p seat and the deep beat right and and it should be calculated i mean the metric should be calculated and advertised but uh regarding the matrix right here it can be a single dimension value for example a number right it can be a a multiple dimension value it can be a tube of with multiple numbers"
  },
  {
    "startTime": "01:26:01",
    "text": "it will be discussed in the future in the in the draft and let's take a look at the example here we will have a anycast ipv6 address to be a like dc uh which identify a service right we will have a unicost on 56 address 2001 db 8 1 com1 right identify a service instance so with this kind of information the ingress d router can make the best a voting decision next please okay this is why i saw uh how to distribute the uh magic among the d routers for example we have bc one the beat 21 and matrix for example one right it's gotta be this kind of information will be uh uh distributed yep next please okay if you take a look up this take a slide you will see that it is really similar to the to it it is really similar to be uh to the solution provided by the previous uh uh speech right the load balancer in the ingress router right uh actually they're really they're really the same the similar one right we providing we provide the uh house ingress any cost you can call it ingress load balancer maybe that's okay for the client so that the client can get the best service experiments right so in this case you see as you can see right here we have two vc right here we have pc1 and dc2 which identified two services right"
  },
  {
    "startTime": "01:28:00",
    "text": "but for each services we have two uh respective uh uh two uh uh service instance 21 31 22 32 right and for and we have a follow uh voting entry here for each uh i'll say die cast voting entry we will have the metric information so we have two types of metric here network and service instance uh metric so for the network metric it would it would have it would be something like a normal contrast or something delay uh something like this right for the service instance it can be it can be a a measurable memorable uh index or house a number right relates to the load uh the resource availability something like this so this is a really easy case for uh illustration right so in this case a service demand with the destination address as dc2 will be sent from the client to the d-router and at the d-round one right if you look at the vape you see that okay this is dc2 let's see which service instance is the best so you'll find the best uh service instance by look up the feed you see that okay beat the speed 20 22 we provide the best for this uh request right so you update the destination address of the packets from like dc2 to db22 which is the unicode a unicast address right so by using this address you the package can be forward from the router 1 to the service instance db22 right so"
  },
  {
    "startTime": "01:30:03",
    "text": "which is very easy to be understood right next okay so this slide talks about some potential work as you can see that uh it's really easy to understand we need some uh flow affinity work on diecast to provide a better uh performance right but this still this topic is it's still opened since the last sign meeting we have uh collect multiple uh solutions for uh flow affinity and one of them uh one of them is this one we provide a binding table in the ingress d router as you can see that we have a flow identifier for example it would be made by a classic file to value the source id that's that's ip vertical something like this right and if we associate it it will be associated with a d i d a b i d for example the b i d 22 right here and we will have a timer uh uh as well so by looking at the feet the package will be forwarding to the uh bid 22 directly without mapping again so this is some potential work in the future and you are really welcome to uh to provide any comments and and question of this part yep so next okay perfect the comments are welcome any question comments okay so we now move to open discussion phase linda will moderate for us okay so now is the open debate and here we have joe on the queue"
  },
  {
    "startTime": "01:32:02",
    "text": "okay so i do have some comments for the open debate but before i make them i want to clarify the proposal i just heard in the d router was the assumption that it encapsulates packets or not because earlier proposals did not talk about encapsulating they were very clear that the address routing in the infrastructure had to be related to the selection i looked at the draft it is completely fuzzy on this now i can't tell therefore it's not a proposal in terms of the slides there is nothing that clears clear is it or isn't it proposed to encapsulate okay uh joe uh actually we're not proposing some specific uh uh encapsulation uh solution here it can be an easy uh adjustable writing but if we have a tunnel from the director one to the beat id 22 right it can be a okay encapsulation yes you can't rewrite destination addresses that is not permitted by the ips architecture sorry that's a good comment if we move to an overlay architecture and stop trying to inject this stuff into the underlay routing we could then have a discussion about whether there was even a problem to be solved we have multiple overlay techniques that already can tunnel where edge devices which you want to call a d router but it's just the same as a lot of other edge application handling can handle selecting a tunnel to deliver something so i'm left really confused because your architecture either asks us to move stuff into routing for no good reason or it isn't really doing anything new and"
  },
  {
    "startTime": "01:34:01",
    "text": "we don't need a new working group to make use of tunnels in the routing space maybe we need a transporter application one or maybe we need something that works on how applications tell the network edge what they want that's a good thing that's a thing a lot of my colleagues want to work on but yeah having an edge that encapsulates a packet and delivers it over a tunnel to the right place that we don't even do working group for that yeah yeah i'll go with that comment received and i think you are proposing a good comment yep okay next okay next one um do i think this layer three load balance is about the solution for the load balance mapping any cost to a unicast address can provide a good way to select the best service instance this map this mapping can be done in year three in this situation the whole network can work as a distributed load balancer this layer three load balance there can both obtain the network information under the computing information and it is closer to the user so i think it's valuable to explore this uh layer 3 load balancer just a comment thanks thank you next one daniel juan"
  },
  {
    "startTime": "01:36:00",
    "text": "[Music] my comments and questions is for diecast draft i'm a little confused by the part of the metrics of servicing instance in the uh in the slides um uh for me when it comes to the time span from the beginning of this the service in the service instances to the end of the service it could run from minutes um seconds and milliseconds so uh when the time span is about milliseconds so the matrix has to be updated and so high frequent to the remote the d router where what whatever uh where all the forwarding decision has to be made and actually i i don't think it is possible for the for the node for for the router make this uh makes this decision because it's too fast when you meet um so um that's um uh that's my my comments and questions for for for this yep thank you comment received i think you are proposing some very important uh things of the uh updating yes we will agree with that so it would be uh update it will not be updating per like milliseconds something like this it would it will be a nightmare right so it's so we need to set some bar or something like this and it will be a completely an engineer a task so we believe that we will have a way out right we'll find a good way out yeah okay next one jim jeff jeff concerto the question is about metric normalization"
  },
  {
    "startTime": "01:38:00",
    "text": "so as joel said if you want to change destination you need to impose additional header you cannot change destination addresses right so we are going back to past computation and even looking traditional psep and very limited number of input computation is complex at large scale it takes minutes if not hours here you are talking about an abundant number of inputs where it's not really comparable even you cannot compare cpu law to gpu load to memory utilization to something else right so how are you going to compute a path for a particular destination with about number of metrics that are not comparable i really don't don't see it reasonable yeah thank you so so good question uh well uh i think we can discuss more on the mailing list because it's a big question yeah how about that jeff thank you okay eric uh eric nordmark so i i mean it's good to have example solutions but i think that there's still some big gaps in in what the requirements are in this space i think that people have talked about session continuity and i think here was flow affinity but the way what that means from a networking perspective as opposed to an application perspective are miles apart and what we know from networking today is doing cdns where you tend to get things from the same place and if you don't you can restart whatever content you're downloading up to the application but if if we're doing some you know computation well that could be you know have this gpu that i found somewhere in my network near me this gpu will compute on this stuff for an hour right and then i want to get the results so is that what we mean by compute or is it something that finishes in 10 milliseconds because the actual notion of continuity"
  },
  {
    "startTime": "01:40:00",
    "text": "or affinity are completely different and then it's not only over time it's also over space because things move if i kick off this gpu computation when i'm sitting at the airport can i go access it when i land back home right or is it actually tied to the particular operator running this network having some service instance ids or whatever a solution would have that it's all local within scope so it would be good to actually try to flush out what do you guys actually think is compute and for how long time does it run and and from where do i need to access it because otherwise this is still just another cdn thing right which you know we already know how to solve as an industry so it would be good to clarify the requirements yep good good comment hello in fact i do some clarification work in the chat box uh first point that the people talk about the the before work i mentioned that's the kind work to some extent that is similar the implicit thing behind the before and the kind work is the operator can hold both the network status and the application load status so they can achieve this the better traffickers theory result so i think this is the scope because maybe in the other scenarios the maybe these providers application providers only know the application of the status and cannot know the network status but maybe"
  },
  {
    "startTime": "01:42:02",
    "text": "in other scenarios the network service provider only know the network status and cannot know the applications later so i mean that's the scope of the kind work is that the uh that's the scenario that the operator can hold both the network status application status this i want to clarify the first the second one i think now this is the user case and also this the problem statement has been clarified and presented but we know that the solution is open but for the load balancer i'm not uh i'm not i'm not certain about it because i'm not sure the load balancer is always co-located with the upif or not if you co-located with this the upif maybe this belong to the 3gpp worker and not the ietf work this is the first one i think this we must determine the second one i think that's for the load balancer i wanted to learn the network status i think maybe a little different a little challenge because that's in the network there's the multiple this the past the past had different status i'm not sure how this network provides these status to the load balancer for the better traffic theory so i think these are just my comments on the load balancers work okay okay thank you so uh regarding yeah i i have some comments further like uh regarding the diecast solution i have to say that actually we only provide the solution for the uh for for one use case that the operator have the network and and computing resources together so they can use that"
  },
  {
    "startTime": "01:44:02",
    "text": "we will not uh adjust the request to another edge size which will be operated by another operator so that that would be impossible yeah okay thank you so just want to emphasize that those are the questions we have in mind when we're doing the open discussion uh the use cases are presented by pull i um so focus on those use cases and um not random one okay so robin do you have more things to say oh you finished okay next one uh uh yes uh thanks uh i think that for the can uh the key is the community and network uh droid optimization with both computing and network information and we finally hope to choose the optimal path and also the optimal service endpoint so i think here the dyncast provides a potential solution for khan because i think that for the operators we can hold both the network information and also the service load and so then the network can learn the application load and do more optimization and and also uh on the other hand uh here uh some people propose a service continuity problem uh in fact i have noticed that in the uh then cast solution here is the flow affinity related issues from my understanding i think that dyncast will select the service node when the session starts and this service notes will won't change"
  },
  {
    "startTime": "01:46:02",
    "text": "until the session ends so i think from this point of view we can solve this risk continue the problem from a certain extent and so uh in conclusion i think that uh as for the landcaster solution we can go it further and to explore more yes uh thanks thank you um next one katan yeah caitanya here uh and i'm kind of maybe adding on to jeff jeff's comments here so the key takeaway for me here was this notion of network metric and you know there was congestion there was computing load and you know probably other more stuff i think that part is somewhat interesting but i did not see it being clearly specified as to what it is uh what kind of metrics are there how are they injected uh how are they measured uh how would they be used in routing protocols let's say uh i think that part is probably within the routing area and perhaps something to look at so yes exactly proponents have some very specific fleshed out or you know idea then perhaps i would say routing area might be a good routing area working group routing working group would be a good one to discuss that yeah for the rest yeah for the rest uh i'm not very sure if this is a routing problem or not thank you kevin so one comment right here like uh yeah you are right the magic has hasn't been uh described specifically right now and this is a big work that we should focus on the future so i think that this kind of what would be what would belong to the rtc area for sure and yes i'll go with you yeah okay next one dean"
  },
  {
    "startTime": "01:48:01",
    "text": "yes hi dian bogdanovic so throughout this itf we are seeing some common themes that people are bringing to the groups and trying to solve and it's pointing out that we have some underlying fundamental problems that we have to look into it and we have to think and start having an open discussion about those so yesterday there was a problem with how to set how to route in the satellites um we are hearing that hey we would like to add more than just where to route that we want to decide also why are we routing and what are we routing and yesterday there was a good presentation in the rounding working group that addresses this uh problems that we are hearing and the use cases that we are seeing in different working groups and in different drafts that addresses uh fundamentally that so we also have a issue that there's more and more mobility being brought into the mobility problems are being brought and as the 3gpp somewhat owns the mobility architecture they are trying to push the 3gpp restrictions that are very much telco orientated and you know that are done with the telco architecture in mind and push it out into the rp world that's another thing that we have to look and see how that how that mobility problem can be solved and not trying to continue with some patch solutions i think it's about time for us as a community to look into the fundamental problem and trying to see what can be done there there are some bits and pieces of this work but we need a place"
  },
  {
    "startTime": "01:50:00",
    "text": "and this is my ask to the isg first to the routing area directors and then to the isg a place where we can have that discussion where we can have that conversation about the problems that we about the fundamental problems that we are seeing and that we are trying to solve i agree i agree so thank you thank you um so we don't have much time left we only have like five minutes left uh 10 minutes left um so let's go quickly uh focus on this work thank you then we'll bring up other bigger problems we need to address or i yes you need to address so next one great right erickson um so it seems to me that this is um we're discussing is a new or presented as a new performance metric um so i think that it might be something that itf can work on uh if um it's uh different from for example a latency introduced by computing uh i don't know if we are in the position to do um computing capacity measurements or how to guarantee that using idf work but i'm not sure that if this is about uh performance metric that the routing area is the right place i would point to uh ip performance measurement working group that uh works on various uh performance metrics and the measurement methods uh [Music] active and hybrid as well so uh"
  },
  {
    "startTime": "01:52:00",
    "text": "if there is anything to do with a new performance metric that expresses uh or reflects computing resource then it might be idp and working group thank you thank you ac ac limit system systems i just want i mean i i agree totally with both what uh joel and uh jeff said and my comments would be the same the um the dynacast architecture is as such it's very uh wishy-washy it just kind of throws together oh yeah we we have these new metrics i think i'm worried people are going to start working on all these details in the end there's only a single routing decision it's got it you know injecting all you know 12 a dozen different metrics doesn't really do you any any good because you gotta know all everybody's gonna normalize them and figure them out and it and it's it's um um with the load balancer you already have a solution and an architecture uh i think mixing these things up is misguided and i'm worried people are going to just start start working on details without agreeing on a good a good without having a good starting point you look at it also with this with this anycast address if you're not tunneling everybody's got to be using the same algorithm in the same metrics otherwise you're going to have loops i mean i there that's that's that's a well-known fact in routing so uh let's not let's not have i don't want to see a bunch of uh a bunch of drafts with the details of this before we agree on our architecture thanks"
  },
  {
    "startTime": "01:54:00",
    "text": "thank you that's a good point icho yeah actually i i'd like to provide some of the preliminary hints on how could how the magic could be defined because we do some we have done some preliminary implementations on this area so the whole work is trying to use the joint optimization for the computing metrics and also the number matrix so basically we can have the normalized metrics for the computing resources and normalize the metrics for the networking resources so we are talking about normalize the computing resources here the simplest way is could just be to to use the number of sessions over the total number of sessions can be supported for example per cpu core remember that we are using the ipn cast to denote a service so basically when when the id system trying to deploy the services it knows that this one i use uh maybe choose a few course too for it so roughly there is uh there is a normalized metric that say the total capacity of the number of in terms of number of sessions can be supported so that's the that's how the um any class ip addresses or the destination ip addresses coupled with the normalize the computing metrics of course the computing resources and the network resources should be calculated in conjunction ultimately but here it's just saying a simple example how it could be done so i just want to provide this kind of information thank you thank you we're running short on time uh changing"
  },
  {
    "startTime": "01:56:00",
    "text": "can you just quickly state your questions or maybe have longer discussion on the mailing list uh okay uh sure well i have just you know some very simple comments regarding the the the 5gs as the example here i'll use kids i think it's uh it's a very uh significant thing so you know even right now in the fgs system uh it starts to introduce some projects uh the seeds are wait to even expose the upf uh information throughout the external world and then likely for like trust uh trusted af those things so that will be uh some paths to introduce uh to uh to bring the nano metric our computing metric those are the concept to integrate with the the networking part and the five parts so i think this work is uh uh is important so what if uh i left the first for the use case mentioned uh in the presentation just thank you thank you so thank everybody for the presenters and also people asking questions um last acknowledged that's our a.d john say a few words about his feeling about this session okay so um thank you linda thanks everybody for for your participation i think that this was a really good and really um well-engaged conversation um so the when the proponents proposed above they they said their goal was to increase awareness and increase participation and i think that from that perspective this off has already been a success i believe the proponents have got gotten a ton of valuable input and a lot of homework to take home and work on and it should keep them busy for you know some weeks or months to come um so"
  },
  {
    "startTime": "01:58:00",
    "text": "and you know it would be really nice to not see the energy that we've you know built up today dissipate i'd like to remind everybody there's a mailing list to continue the conversation on um and i hope you will use it and in particular take your your comments there that you've you know pasted in the chat room which i've only vaguely kept up with because as usual there's too much um information streaming past between chat and what's being said the mic and so on to follow it all um so so please do follow up on the on the mailing list with that um with regard to sort of the the questions that we've got here on the slide um you know i don't think i saw any disagreement um that the use cases are important um i heard a lot of um reference to existing solutions i don't i don't i did not hear a consensus uh that um you simply need to apply existing technology and we're done um although i did hear a great deal of you know have you looked at um x enough um you know for example uh jeff mentioned alto and there were other things um and i'm so i i think that there's certainly a question about whether uh existing technologies have already been paid enough attention to regarding whether the proposed architecture would be harmful in any way i heard especially from kind of traditional routing area people um many people saying um you know what wherever this work is done do not put it in the underlying um i there was a loud plurality of apparent opinion in that direction um"
  },
  {
    "startTime": "02:00:00",
    "text": "and regarding where the work should continue um there uh doesn't seem to be a consensus there does seem to be a consensus there are various pieces and that at most only some of them are part of robbing i think that we're going to have to continue to chase that question one other interesting thing that interesting to me anyway was the sort of in the discussion of um load balancers versus you know something else uh was um the point that dirk brought up about well the the the d router in um and dyncast is really you can think of it in in terms of it being a load balancer um and there were some other comments in the in the chat about um well well gosh is really what we're looking for is standardization of load balancers because right now they're you know all proprietary secret sauce um so yeah we're at the top of the hour so i i don't want to make us run over um but uh you know just to to reiterate uh i think that um you know we've we've had a good buff today we've surfaced a lot of valuable points um i think that this discussion can and will continue and it's uh that there is not to me any clear next venue for um for the uh the work to land in other than on the mailing list but um you know you have a lot of people's attention let's keep it uh thank you and if the chairs would like to say anything to wrap up um please go ahead thank you thank you everybody uh just make sure go back to the notes um if you ask questions make sure your questions are captured and your names are captured correctly thank you thank you thank you guys so please don't don't forget that nelly least tell us anything if you want"
  },
  {
    "startTime": "02:02:01",
    "text": "that's right mabel is a dynacast dimecast yeah diego thank you okay goodbye thanks hey jeff so the do you get the blue sheet like do you know how to get the blue sheet is it automatically captured russia is a automatic okay okay um i find the the chat window has many interesting questions interesting suggestions okay okay thank you so much okay take care"
  }
]
