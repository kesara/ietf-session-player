[
  {
    "startTime": "00:00:02",
    "text": "Hey now and again, like, a way to study for a month. More tools. There we go. Alright. It's 9:30. You wanna do it? Record. Alright. We're getting started here. It's, this is the TLS, session for Iutf 118. This is the 1st meeting of the week, so you may not have seen the note well. This is, the rules that govern the IATF with respect to, behavior and, IPR and things of that nature. So you should make yourself familiar with these rules. Next slide. A little bit more about, making sure that we all treat each other with respect. Keep the discussion civil. I'm doing real well with that. So hope fowing Continue. Yes. Please sign in with the meeting tool. So that your attendance is recorded and so that you can join the queue to participate in the discussion. Thank you. Alright. I think we No. This information Okay. So we have, a notetaker We have the agenda up here. We will note that, We have a full agenda, so we'll we'll try to get moving pretty quickly here. Can you go to the next slide so we can move and here, We have, adjusted some of the time to make room for as many present patience is possible. So We'll ask that people try to keep to this time."
  },
  {
    "startTime": "00:02:03",
    "text": "So that we can get as much in as possible. Any, questions on the agenda? Alright then. Just wanna do a quick working group status update. Been working on 8446 BIS for a while. Basically, the document is ready to go. There might be some, a sentence or 2 based on some discussions we have and one of David Benjamin's drafts, but it's basically ready to go and it's been waiting for April for 7 biz. To get out the door. And so we're hoping to get that wrapped up today, and so we can get everything done. But There was, another call that we had for the tl DTS 1.2and1.3rc Internet draft and talking with the, authors, we found that there were no implementation. So we're gonna wait till we Instead, we're gonna have an early code point assignment. So we'll expect to see that message coming out shortly. We have a The TLS flag draft was also pinned for the same reason we're waiting for implementations, but Jonathan now has a draft on using flags. So we may actually have some implementations that we could unstuck those too as well. And everything else, I think we're basically gonna talk about. If you have any questions specifically about it and the status of the drafts where you think we've blown it somehow. Please make sure to let the chairs know text, Yes. And then the queue. 1st next again. Alright. We have somebody in the Azua? Thomas Yes. I'm Thomas as well. So I, we've started implementation of the RRC stuff already. So But, regarding the quote points allocation, I'm not sure. I understand what's Oh, so that so we have have to go through a process to make sure that everybody agrees that it's stable. I think it is because we've already gone through a working group last call. So it's a mere for me to send an email to be like, hey, object in the next"
  },
  {
    "startTime": "00:04:00",
    "text": "you know, 2 weeks. And then I will send a message to Paul, and we'll get the designated expert experts to give us some, co points assigned for the that So I thought it should be quick. It should be done before December. And if not, feel free to both foot in my butt and my butt. So Alright. Thank you. Alright. The next presentation. Yep. Yeah. Okay. I stopped. Alright. Cool. Okay. He's stopping over there. I share. Slack Motor Place. Side this It's here. It's not there. I guess, while we sort that out, Yeah. Why don't you go ahead? Hi, everyone. Arnold from Broadcom. So we we can make comments on the draft, right? No. Or not. Sure. Right? So on on the ECH draft, I'm struggling on it's it's mostly editorial. I think the overview part of ACH is really not giving justice to what is CH is doing. So I'm trying to find a better way to improve that to explain better And in deployment considerations, for a non English speaking person, for people who are not"
  },
  {
    "startTime": "00:06:02",
    "text": "tuned to that is very, very difficult to understand. I'm struggling to find ways to improve that part of the text. But but is going to be a couple of traps there. If we start to expand, we will basically end up to our own Internet draft. That's not the goal. But today, it's very difficult to really understand what it is. So maybe offline, I can discuss with you, Chris, and try to find at least a direction where I can try to find ways to make it clearer or better. But expect at least one PR for the overview to make it a bit better. Yeah. Great. We welcome editorial improvements for sure. Yeah. I could go ahead. Yeah. I think, or no, and our possibilities, if you wanna file issues that indicate the things that you think are confusing, try to cross some new text So Either way. He he gave a thumbs up. So Okay. Alright. Any extra time. Let's get going. So, walk me over on to the what was hopefully the final presentation on ECH As a reminder, for those who we it's been a while since we talked about this. So if you're unfamiliar with ECH or if forgotten. ECH is a protocol for encrypting the client hello as it suggested in the name. Clients get a public key from the DNS or an ECH configuration from the DNS or elsewhere by carry a pigeon, whatever. And use that to encrypt an inter client, hello, as we call it, shove that into an outer client hello and send it on its merry way to a server to complete the handshake. Everything that would be considered sensitive, like the SNI, ALPN, whatever, go inside the line. Hello. And stuff that's, like, perhaps less sensitive, such as the the name of the service that you're connecting to, the public name is call it goes in the outer client. Hello. Everything else is more or less the same. Slide, please. There are some deployments of this. The Wiki page tracks a number of implementations, browsers, like Firefox"
  },
  {
    "startTime": "00:08:01",
    "text": "Chrome have support. Cloveler has support with an asterisk. There was an issue on our side, and, we had to we had a bug that in in our control plane, we had to turn it off temporarily, not do policy reasons, but due to we had a bug, and we hope to turn it back on soon. Next slide, please. Okay. So the objective of this presentation kinda go through the remaining open issues. And see if we can come to some resolution to shift this draft forward, given that we have implementations in the wild. It's and this has been floating around for quite a while now. I I think it's time. We kinda move this thing over the finish line. So the open issues on the draft are those that are on the slide. I've I've sorted them in what I think is, decreasing Actually, there's no sorting order except for k. No there's no particular order. I hope we can go through these in time allocated. But if not, we'll, hopefully, take the rest to discussion or you know, discussion on the mailing list, or maybe even bachelor of them in working group last call. Okay. So the first one is on the, public name. Its implications on compatibility. Basically, there's an open issue, around, the text that says what clients put inside the, outer client, hello, SNI Field, and what server should do with that particular name, So, of course, like, what goes in this name and how servers enforcement goes into that name has interoperability and compatibility implications. And whether or not you put something in the name that is, you know, what you find in the DNS does have potential implications on whether or not you permit domain fronting or not. So basically the there's a PR open, that sort of resolve this particular issue with the intent of making it clear, that the an honest and faithful implementation of the spec will yield,"
  },
  {
    "startTime": "00:10:00",
    "text": "interoperal implementation, but we also wanna bake in enough flexibility to allow a different service type policies in future, did watch it permit date domain funding. So for this particular one, the PR has received, some review. And I suggest we just merge this PR, and close the issue. I'd like to know if there's any objections that Narquist Corolla. So I can live with that, but I think I'd like to talk about the normative language for a moment first. Sure. So the current normative language is that you should produced the right thing and you may check it. As I understand it. Right? I think I switched it to a must. Oh, is it now saying must? Thank you. Thank you. So Yeah. So I think this is like this is like I I read this means the district attorney to elucidate it, which is that conformative implementation is gonna on price. I think it'd be better for the internet if we said, if we said must and we gave the condition on know it's a must is allowed. You shall divide the must. And and those conditions are, you know, the server is not checked. And the consequence of this is you get much better get the the properties that are indicated in, you know, in this IB. I can't remember. They are seeing it right now. 9147 is it? About, you know, about not allowing things to like rot in weird ways. Right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right so I would, I would prefer a, I prefer a, a must do it. And a shared check opposed to a may should do it in a paycheck. I'm not gonna like light on the road over this, but I guess the right answer and, and so I'd like to have discussion and take a Sue. That's steam power. Yeah. So I I I think it's on the think they should have done the client of the man the server side landed in the right place. And, I think there's been some discussion on the b o r. So Yeah. Mean, I I don't know. So I think you were proposing to kind of ask people to kind of confirm on this. I'm working with West Coast or something, or"
  },
  {
    "startTime": "00:12:00",
    "text": "my proposal is to merge this, and then we'll we'll confirm. The the the entirety of the draft in working with last call. Yeah. I I personally, I think that's a better suggestion, but rather than having a home right now. Price. Yep. Okay? Any other questions? The queue is, I think Yeah, Mike. Go ahead. I'll just point out that a must that you don't follow in certain conditions is called I should. Well, if you explicitly say you must do this, in this case, you must do this in this case. That's a must. A must do this but under certain circumstances, you might choose to do something else. That's all what I'm talking about. What I'm talking about is you must do this, accept accept what else other condition dictates Okay. So it's not a show. It should is you should is you can do this for any re you could do that to this for any reason whatsoever that you consider a must is that you must do it unless this unless it looks at a congested. There's someone else Okay. Great. So we'll merge this and then move on. Padding. So an issue that's been open for a long time in the draft now is what to do about padding. As a reminder, so ECH, the security and privacy properties of ECH require that the server, behavior, is effectively consistent across all, you know, domains that are in the anonymity set. Behavior means like what's expressed on the wire, what the size of packets are on the wire. And this is important because it the difference in size could like, leak information about stuff that you've otherwise encrypted such as the server name. We've had a PR up for, adding padding via a an extension, I believe, or a handshake message, I believe, been such a long time. I forgot exactly which one. The gist of it is that these seem like orthogonal things that we can address in a separate draft later on. Given that we do not have this and we've shipped some support for this, my proposal is to"
  },
  {
    "startTime": "00:14:01",
    "text": "basically and do nothing with padding right now. Acknowledge that we can address this in a follow-up draft later on. Effectively fund. And, to hear what people think about this. So this means fine, but I wanna point out the text actually currently says, have to pad the record Is this you have to, or you Well, it's not like a it's not 2019. It says, how you do it at the record layer. Got it. So I think that's fine because the regular kenpad but I mean, it's like one of these are one of those, like, you know, This is, like, logically evolved the structure of the system as opposed to, like, as opposed to, like, a normative So, yes, that's just fine. I'm just, I just need, like, the state state of affairs I understand it right now is that that tell you how to pad on c h. Yep. And we'd, like, say, well, if you're gonna pad the 3rd crop, you gotta do the record layer and you're on your own, And so the and so the proposal in this case is if we wanna add a new mechanism, we've done some I think is totally fine. Right. And I think we should go when we should go look in last call, we should, like, read this text to make sure it doesn't veen Sounds good. We'll also happen to add text. It says, like, you know, at the record layer or a future extension or something like that. Yeah. Okay. Any other comments, concerns? Lovely. Next one. Alright. So, other issue is about what goes in the acceptance signal for non HRr paths. Currently, the non HRR case, we can send the accepted signal in the server hello random. There's an argument that potentially may just shove in an extensions for alignment with the HRR case. For somewhat aesthetic reasons, but also somewhat to avoid ossification reasons. But again, on the basis of ship this. It's working, and, the interest of moving things forward. My proposal is to, again, do nothing here. Close this issue and move along. Any objections? Fantastic. Next slide."
  },
  {
    "startTime": "00:16:00",
    "text": "Oh, alright. Yeah. So there's also a similar issue or a related issue about, greasing the HR accepted signal it's in an extension. And there's not currently tech which says what you do with the contents of this extension if you're not actually doing ECH? So I guess in in for good hygiene reasons. We might imagine greasing it, but, we have not yet done so we have not done this so far, and it's not really clear given the prep model, whether or not this offers meaningful benefit. Artificial kind of, like, complexity to the draft for the sake of complexity. So you guessed it. My proposal is to leave this as is and do nothing and close the issue. Any concerns. it. Next issue, please. Love Okay. Extensions. There's 2 issues here. There are to to GitHub issues here. They all are around the extensibility mechanism that we have in the ECS configuration. Effectively, the argument is that ECH extensions add plexity did the protocol, and we do not yet have a use case for them. Like, there's nothing that that has, you know, have no defined ECH configuration extensions. But there's been various different points of time, different possible extensions have been tossed up. So, for example, maybe you can put padding details in extension, maybe you couldn't specify how to you know you know you know you know you know you know tweak with the public few tweak what goes in the public name, whatever. There might be other various extensions you might imagine. Given that the libraries that have implemented DCA I've already added support for the extension capability. I propose that we leave this as is and do nothing. At any objections. Yeah. You you could just go up. Hi, Steve. Yeah. I I'm I'm not objecting. I would like to see it go away, but I'm not objecting. I'm not quite sure it's true that all over his have added supports in a meaningful sense. There is I don't think anybody's gonna break if"
  },
  {
    "startTime": "00:18:01",
    "text": "speaking of, but it's not clear. I think there are some libraries that have kind of ignore this. And So it's it's not clear to me that if you use them, it'll actually work in the end. Nonetheless, I'm not objecting. What would you mean by ignore in this case? So there's so there's the extension has this kind of critical bit whatever we call it. The management thing. Yeah. Yeah. I think there are some some other libraries that not not the not the one I've been doing, but that's might break if you use that. Interesting. Do you know which ones? Well, not not necessarily break nicely. So they may learn fast, but, you know, they may learn in 5 years time when after one of these for eventually invented it. So but nonetheless, I'm not objecting. Let's let's talk later about potential what those implementations are because we should probably those fixed or checked. Okay. Any other comments, questions, concerns, If not, then we have, the last issue, which is on, just generally ECH and its complexity, ECH is a complex protocol. There's no way around it. We we spent a lot of time in this working group trying to figure out simpler ways to do it. What is the right way to do it. With with with like, the, you know, sort of analysis that gives us confidence that the thing that we have now does meet the desired security and privacy goals. We do not yet currently have, a better solution that's been seriously discussed. I mean, the the draft used to have like, previous designs for things that would solve the ECH problem or encrypting the SNI. But we took them out just because, you know, they kinda lost steam. So I'm not really sure what to do with this issue other than to acknowledge that this a complicated protocol and it's a shame that that that that that That's the way it is. I think everyone in the work group would welcome"
  },
  {
    "startTime": "00:20:00",
    "text": "know, a simpler version of this if we had one. And if maybe we have one that could be yet another extension that comes up in the future, that deprecates and replaces ECH. So on that basis, I think know, we just comfortably kinda close this Any objections? Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Michael. Hi. Michael, UK NCC. Not necessarily on the complex t, but, related, just noticed the first, paragraph in the in the draft is a disclaimer that, on security analysis so just wondering if you could include that in the next version saying there's any kind of extra work to be done just links to references. Thanks. Yeah. At we'll we'll make sure to tidy that up before we do the working request call. Thank you. Alright. Is that an Okay. Next slide. Fantastic. Okay. So with these resolutions, merch things, close things, and then I suggest we kick off working group last call. So I'm gonna us turn it over to Sean. Thanks for that. Do you have a timeline for when you think you might be able to pump out the next version? This week. Okay. If you do this week, it'll probably be a longer than normal 2 week last call just because of the holidays in the US. Maybe we'll give it to the early December or whatever, but we'll get going. I have one other question, though, which was I sent on the mailing list. For the early Cool Point assignment, we've got agreement that we're gonna go ahead proceed for with that. Do we actually wanna make sure that we request the numbers that are in the draft I assume the answer is yes, but I just want people to say yes. This is a question for implementers. Do you care about the Cove Point values? So Leave him as is. I see oh, okay. That's it. Yeah. Okay. So I'm looking at specific people, and I I think leave him as is. It's like response. It's like That that message will be coming to you at lunch."
  },
  {
    "startTime": "00:22:00",
    "text": "Okay. Cool. Great. Thank you very much. Joe. Alright. So this is are we doing 8447 best Yeah. So, We've, been working through the issues on 8447bis, the latest revision we we on basically, sets the discourage value, for some of the curves in cyber weeks in basically What this draft does is for any curve that's less than 255 Bics, We, mark that as discouraged. And then as far as Cyprus Suites go, null encryption, anonymous cipher suites, export Cyprus Suites as Adia and RC 4 are all marked discouraged by this draft. Any other discouraged entries we expect to be marked nearby. It in a in a different draft, such as in the obsolete key exchange. Or some subsequent Draft to deprecate or discourage, the use of the other types of Cyprus. Chris? Chris Patton, by DES, do you also mean Triple DES? No. Just as. John. Yeah. Yeah. Saying great that you incorporated a lot of this. I I plan to update the draft maths on based on this, but I think the sooner the better this is done. Great. Okay. John, I noticed in the in your draft, originally, you you tried to deprecate, like, PSKE or one of those, and we decided not to do that in this draft. So we figured that that was better to be fought elsewhere. Yeah. K. That's okay."
  },
  {
    "startTime": "00:24:04",
    "text": "That's fine. I think, the the conclusion in the group last time was to also update the registration requirements for for for central non encryption so that you cannot register this in in the or they were automatically not recommended. I I will try to do everything you are not doing Yeah. In my draft. That that'd be great. Ritz, I had already moved as an idea to historic. Is it drawing a distinction between that and not recommended. 8996. Well, we've moved So, We now have the discouraged. So it it, you know, d could be discouraged or deprecated, Right. But, I mean, so that's you know, suggested not to use it unless you have some real specific case. So I think that the thing is that there's some Status for the RFCs where it's historic, whether you're on standards, track your informational, So it's moved to historic on the RFC track. What we're doing here is just filling up the the column And it's the same thing with the Kechs draft. Right? It's it's, like, deprecated, but there's no real deprecated in the ISS of it's discouraged. So we have to, like, square the terminology began with the one of the reasons why we were putting discouraged in here is because it's made historic, and we know it's broken. So it's kind of like it's the ammunition we're using in which to to to market these. And I did note, Rich, in your draft, and you'll get to this in a second that you might wanna add a registry or a new column to many things. We'll have to decide whether we do that in your draft stick it in this one as part of working group last Okay? You have Yes. So, we're wondering why we're not deprecating, triple this. I mean, or anything that's uses a CBC."
  },
  {
    "startTime": "00:26:00",
    "text": "We because right now, we wanna get this draft out and, I don't know that we have consensus to deprecate triple this. I'm not sure about that. Okay. But I I think if we wanna deprecate triple des, then somebody can, you know, we can put together a draft and and see how that goes. Alright. So we believe we're, ready for last call. So, hopefully, we can have a quick last call and get this moving forward. John, did you have anything additional CTS. Yeah. Another update is, for CTLS, There has been some, recent work on this, basically, formal analysis has been conducted for, many parts of the protocol. So hopefully, Hannes will post a link to to that as well as the link that's in here to the list. And then there's been some additional work on, reducing the size of the keys that's part of John and that's his work And so I think that's all we have for CTLS. Alright. So I guess this is a this is a me a couple from the chairs. We have this SSL key log draft that, Martin Thompson, suggested that, you know, Mozilla was basically giving over"
  },
  {
    "startTime": "00:28:03",
    "text": "role of this SSL key log file and a draft to us. Think it was ITF116 where we took a poll of he was interested in working on this, and there was quite a number of people who said yes. And then we took it to the mailing list, and we got kinda crickets. And we basically said we weren't gonna adopt it. Martin went back to the eighties and said, hey. Would you 80 sponsor this? The eighties reviewed the minutes and said, hey, Sean, I think maybe you screwed this up. So, basically, what we're doing is we're gonna adopt this draft, because we clear consensus to actually do that already. And so all we really need to do is confirm that there that are gonna be willing to review and edit the document So can we do a show of hands of people that would be interested in Working on this. Really was looking for, like, two people. So I see at least 2, and that's really what I'm hoping for. So We'll just let the record show that, we had a couple of people that were willing to review it pretty easy draft. It's well implemented. It's all over the place. We'll just go ahead and get that Jonathan? If we have change control here, Can we do fun things like adding ECH keys to a silky no problem. We can do anything anything we want, barely. We just have to make sure we have consensus to do so. In which case, ECH case. Alright. Now we're on to Tom. Is he here? Sorry. I might have stood on you there. You might have to try to reshare it again. Let's try that again. have a request out, I think. I"
  },
  {
    "startTime": "00:30:06",
    "text": "Try it again. Alright. Crap. I just clicked in the way as you confirmed it. Try again. Value. Awesome. Thanks. Ask him Let's go. Okay. Good morning, everyone. I hope pride is nice. I wish it could have been there. But I'm afraid I'm alive. So I'm here to very briefly and quickly talk about off cam, off cam PS k, I'm trying to do this as quickly as I can so that we have a bit more time at the end. I make the explanations, stuff on the schedule. So of them is basically can base authentication for TLS, so not using signatures interview of doing things in the post panel setting. So This draft is a bit of history. Originates in a bunch of academic papers, we also did a bunch of security analysis there. Then in 2021, we wrote, first version of the drops, Ofgem, relates to KMTOS in the sense that it is the authentication part of Kentillas and off via Can. This draft was a bit long, a bit complicated. Of probably got some feedback, which we partially processed in, early 2022, and then also gave a presentation and then it was quiet for a while, but I managed to manage to manage to manage to get back to this work after finishing my thesis and having a baby. So, yeah, I was busy for awhile. So in the meantime, some other people did some analysis work that of a system that's fairly similar to this idea, analyzing what postpontum can based authentication would do for NQTT."
  },
  {
    "startTime": "00:32:03",
    "text": "On embedded devices, and I found this, this quote a nice result, that they found that the user can for authentication resulted in that 71% savings of the connection time. Saving 25 milliseconds, which I think is is quite significant. So where are we now and where do we need to go? So, few weeks ago, I split a draft into 2 proposals because I realized that actually results putting forward 2 things that can be done independently and should probably be considered independent say, so that is the, putting 10 public keys in certificates parts and separately from that, 10 base PSK mechanism. I hope, I've aims to greatly improve their presentation and have added a bit of comparison and motivation section offhand drops. Today, I'm here to briefly explain these updates as I've been doing And, the main thing here today is to ask for comments and support because I definitely cannot do this on my it's an I I like this proposal, but I come just be one guy pushing for this. And then down the line, the idea is to move towards, working group adoption, So, yeah, splitting these two graphs, the first part is a chem authentication for TLS so that it's using a chem public key in your leaf certificates, perhaps, shake off, that saves a lot of action traffic. The postpartum setting you compare it, khybrid to the lithium, then it says she ran a kilobytes at level 1, if you go up to this level 5, which is necessary for CNSA 2.0, or what the French people want you to do, then you're talking like 4 kilo of data This is intended for full TLS handshakes, and"
  },
  {
    "startTime": "00:34:03",
    "text": "we expect the savings to be especially significant for the applications, because they also have other benefits like being able to reuse the implementation of the can for both the key exchange and the authentication and then you don't need as much, protected code size, for example, for the web, PKI, web PKI has a lot more signatures. So just getting rid of one of them is maybe not super motivating, but I think that off cam combines very well with merkel tree. So bridge certificates. So if you can avoid sending those signatures, then ask him. I'd like you to avoid yeah, it's another signature. The new draft is can base these case style and shape So basically use a cam ciphertext instead of session tickets that allows you to avoid symmetric key crypto, which is generally a lot easier to handle in devices and storage and provisioning Kent publications have probably got fewer tracking issues with opaque session tickets, and this combined spell because you can cash of cancer certificates and then use this mechanism. So I think that that is a nice interaction of these 2 but you can implement the second part completely separate doesn't rely on anything. That is specified in the other draft. So now what's This is my main question. I want to I would really invite people who think that this idea is interesting to submit that comments all my drops, all the main things, all my kids have issue tracker. Would like to hear from people who would like to use these protocols who would like to implement these protocols, who think they are interesting my employer definitely thinks that these protocols could be interesting to our customers, particularly for the for the embedded space and the reduce code size and the, especially reduce"
  },
  {
    "startTime": "00:36:01",
    "text": "protected code size, if you're talking about, for example, partially hardware and commence it. Stuff, stuff, But, yeah, please do reach out, and and show your sport because, without your support icons. Keep pushing for this. That is it for for me? There's a bunch of extra slides in this deck with extra colds and that I invite you to look at on the data tracker if you want more sort of motivating stop for these traps. But that is it's for me, So if if my questions, I'm I'm here, Tom, that was impressive. You got through all that in record time. Thanks. Chris. Chris Patton. Yeah. I I mean, like, I think this is a great idea. I I think have 2 buckets of questions. The first is Are we aiming for the same security properties as TLS 1.3? And the second question is What is your vision like, long term vision for this protocol is this extension to TLS, or is this, TLS 1.4? The second one is a very, question for somebody else to answer by myself. Tough I think this approach just generalized to a bunch of other schemes as well. So that is something else. But for TLS, in particular, I think that is something you could negotiate. You can indicate which kind of certificates you want was kind of sick signature algorithms used for authentication algorithm should that say, And then you could use Ofgem, if that makes sense for you. In terms of security properties,"
  },
  {
    "startTime": "00:38:03",
    "text": "the discussion here is slightly nuanced because you comps if you want to do everything in sort of 11.5 hop around trips. You can't get exactly the same security properties but I don't think that the difference is material to what you get in practice from TLS 1.3 already And I do agree that the security analysis needs to be done very carefully. I have tried to very carefully in the KMTOS versions but part of the things that would I would like to see on the agenda should this go forward is to model, and really Kathy and said, are the IETF specified version of this protocol So that we have, like, really careful things here. Do we sacrifice foreign secrecy? I don't think Alkin sacrifices for what he perceived. Hello? Eric Skorla, Thanks for presenting this. And thanks for, doing some type to clean up, I'm sorry to say, I don't think this has likes. Like, as I include the presentation's better, but, like, It's the same, like, major structural changes the TLS that, like, just seemed like much too aggressive. Like, the relative module performance benefit you're getting. And give, and given the, you know, the fact that we're like nowhere near to playing any of, like, any post quantum, to fix it all, like, making optimization, premature optimization to, like, attempt this kind of structural change at the state we're in with post quantum affaircation so, so, so, So so so I I, again, thank you, but I I I I think this is getting Okay. Thank you. Just to be clear, you know, if it's 3 years from now, and everybody's like, well, I'm down way through PostgreSQL signatures, and it really sucks."
  },
  {
    "startTime": "00:40:04",
    "text": "Like, you know, I mean, maybe a conversation could happen. But I think, like, in the state of play now, we're not suffering that and there's no plausible story about how we're gonna have a push on PTI at all. I think trying to, like, compromise TLS at this point is just Yeah. So what's your the second point, the the waiting, I think that if we punch this too far into the future, then we don't get the opportunity to work on the PKI that could support this. So, yeah, I I don't think that we There's a bit of risk there. Well, I I sure. I mean, we jot this offline if you but I think, you know, the major problem is that CA don't have post funham roots. And, you know, on so, like, you know, if we if we had a postponed CA, and it was a matter of just, like, adding new keys And he, like, bottom line is, like, if all we do is, like, take, like, which occurred and, like, and, like, a place like to curve with, like, columns and shower rooms all the way. Still totally work. There would be slower than one would like. And then this is not becomes the optimization we can decide with you or not. But like right now, we're not in the state. Right now, we don't have anything. And so I I guess I don't quite understand the timing issue So in sort of chances point to Rx that I think it takes so long to get any changes through the PKI, that if we don't start now, well, don't start, like, 2 years ago, then we will be stuck in a that world for about 40 years. So I guess I should note that the place to, I think, affect PKI things as possibly in lamps and not here. The last thing I wanna do is have a session where we wail on the the web PKI again. For 10th time. Let's try to avoid that and head to the elsewhere. And I guess this is also a point where I can save me by to, Mike Owensworth who requested time for something to talk about in this space, and I completely missed it. So apologies. Chris. Chris."
  },
  {
    "startTime": "00:42:00",
    "text": "Chris that it looks like the queues closed. Or, there's a My name's Red. Don't know why. Okay. Well, I just wanted to pose the question where do we think the change in the BKI is gonna start from from from from TLS, or is it gonna start from the root I super doubt it's gonna start from the roots. Does it make sense for us to kick this off? Like, we kind of have this, like, you know, what do you call it? Kicking up. Problem. Right? And why why don't why don't we just start Thank you, Chris. Yep. Promise it has to start first. Seconds left. Am I am am I hyphenom am I audible? It's are you are audible, Richard. Go ahead. Yeah. Yeah. Yeah. And so sorry. I haven't debugged my video yet on day 1. I I think there is a PKI ordering problem, but I think it's more of the the character that Ecker raised that, you know, you could have you know, a normal shaped PKI, the who you have a peak you have, whatever shape you have, whether a normal shape like we have today, but just from postpone signatures or something exotic like royalty certificates. And either of those work fine. If you leave the one signature, that we've had. We haven't TLS. Like, so the shape of the PKI is orthogonal the the authentication scheme in TLS. And I think it's actually, they think you get more and more more, effectiveness out of changing the rest of the PKI, then out of changing the because after all, it's one signature versus several. Yeah. I mean, the the higher the bit here, right, is that"
  },
  {
    "startTime": "00:44:00",
    "text": "unless you have seen insurance that are hot for that route that are set price quantum, nothing else than than no no there's no matter what else you have. Right? And and rolling up the new roots is, like, super expensive and hard. And, Like, at the point where you have post wellness interest from the roots, then actually deploying new new key new keys that will use it, like, comparatively easy. Like easy, but comparative music. So, I think I think, like, So I think, like, I mean, if you just ignore, like, any of the other questions, like, having like, having a post communist industry. Keys the lease is, like, useless since they have pushed Vonage and so the syndrome so so I think we're we're looking to do a show of hands on this draft, so let's keep it quick. So Sorry. I I wasn't able to get into the queue. Just a quick comment. So from John Gray from Entrust. So We don't have obviously not public PKIs. I can do PQ, but we obviously have private ones So that's something to consider. Right? Obviously, web PKI is very important, but there's also all the other places that don't use that. And right now, we can do post quantum state. With RCA total Wanted to make that comment. Alright. We'd like to do a show of hands. If there is, interest in adopting this work now. In the meantime, I would like to also clarify that the the the second draft, has nothing to do with PK So you could do the whole chem based resumption scheme. Separately. I mean, obviously, it makes less sense if you don't have postcom security for full handshake yet, but that can be done independently of of this particular question. We're just using this to assess interest in the draft right now."
  },
  {
    "startTime": "00:46:13",
    "text": "Okay. Alright. So the poll shows, 29th favor, 12 against we'll talk and, follow-up with the author's off list Thanks, Tom. Sorry. This is frozen. Richard up next. Next, Queue already? Okay. Yeah, I presented this last IETF because the IETF 4. I phone to to write it, Nimrod, helps helps contribute a lot of text. The basic content is we're not gonna accept any new extensions for TLS 12 except for ALPN and key exporter labels, Speak closer to my okay. The intent is we're not gonna accept any the IETF, and therefore, the instructions to the designated experts. Will not accept any TLS extensions other than ALPN and key exporter labels. For TLS 12. We need, an annotation that new site that are defined should have a comment in them that says for TLS 13 or later. Such as all the post quantum, It now said that the draft now says,"
  },
  {
    "startTime": "00:48:01",
    "text": "explicitly, this is to post quantum will not appear available in TLS 1.2. Previously was sort of implied by saying you can't register them. And also as a clarification that the draft is only about TLS, not DTLS because the state of dtlsone.3 is Not a happy one. Next, The impact on other protocols was split out to a separate draft. And will be intended for UTA. Working groups, Next said it? There should be one that says next steps. Once again, seeking adoption it's pretty short. Me at home. Like, I the eye Sorry. Emax, whatever you like. It's shorter than the, list of references in markdown. Right? It's like two pages printed in no blind printer page. So so, That's it. That's it. That's it. That's it. That's it. That's it. That's it. That's it. That's it. That's it. That's it. One adoption. I think got we only one person in the queue, Chris. Did you mean to be in the queue? Okay. Alright. So I just have one question. So do you think that that registry tweak to add for the Cypress week should be in the App. Is that a better place for it, or do you think? I think it's better than your draft because it's one unified place for the United to make change we will, take that on as an early working group last call Yeah. Gonna just show up hands again. We'll do another tool. There's pretty clear interest yet. Last time we talked about potentially adopting this or is very clean and interested in the room, I don't think we need to repeat the show of hands, so I think we'll just go off and, start the Doctor. Nicole on the list. Okay. So I'm Wait. Do the 8 the confirmation call, you want me to submit a new Okay. Confirmation bill. Alright. Fine. Thank you. guess I should just note that this draft does not say on x date I"
  },
  {
    "startTime": "00:50:01",
    "text": "stop using TLS 1.2. There were a few people that actually asked that question on list. Just wanna make sure that we discussed this, I think at 1:15. There was a whole bunch of, like, when it gets to a certain percentage of use that maybe people will feel more comfortable turning it off. We're nowhere near that point. We're nowhere near. Yeah. It just, yeah, it's not gonna change. It's not gonna get better. Maybe we'll fix bugs if we find any horrible the bug fix may be used TLS 1 for Alright. Andre. Just just say when and Awesome. Hello. I'm Andre Papolfin. I would like to, talk about the proposed reintroduction of, RSAP KCS, code points for TLS 1.3 in a very limited, context. So this draft was originally, published by, David Benjamin and I would like kind of kind of restart the discussion on this. So in TLS 1.3, we deprecated the use of RSA PKCS, for, you know, very good reasons. Known kind of issues with the with that, signature, signature scheme, And, so it can no longer use can no long no longer be used in the certificate, certified messages. Instead, we, would like to see people use RSA CSS, obviously. Unfortunately, there is, as as we're deploying to less 1.3, especially in price environments, we're seeing issues where, people tend to protect client certificate private keys with cryptographic devices, and the lot of those devices cannot produce, TLS compatible, RSAPSS signatures. Of basically, some of those devices don't support PSS at all. Only TPM 20 specification, it even includes RSAP SSTPM is one example of of, this class of devices. We've also seen indications of issues with, smart cards but I will focus on CPM a little because I have more data on that."
  },
  {
    "startTime": "00:52:03",
    "text": "So basically, only TPM to 0 includes RS APSS support in the specification And, you know, the the specific, salt length that is required for TLS is only available in those devices that are compatible with with FIPs 18 6 point dash 4. And that's according to our telemetry in windows. That's only about 15% of the currently deployed TPM devices. So that means a lot of enterprises are actually running into issues where once they enable TLS 1 23, their clients cannot authenticate anymore. Next so and and like the reason this is a bigger issue is that, generally speaking, the client, in the TLS client, doesn't necessarily know that they're gonna use a certificate until they've negotiated the version. So they, first, they decide which vertical version they can negotiate then eventually a certificate request comes in, then eventually maybe, you know, some certificate selection process happens, then they figure out what, devices used to protect the if if a device is used to tech. The private key. And then they see that this device cannot produce a compatible signature at which point it's too late to renegotiate, right? Like, you you already stuck with 3 and you are failing. To authenticate So, a possible workaround on the client side would have been to have some form of, TLS version fallback, those things tend to cause, vulnerabilities, we would not like to to recommend that option. So in practice, all of this means that, essentially a 2 s server not enable TLS 1.3 And, at the same time, you know, you have TLS 1.21 enable, and negotiate 1.2 with only the affected device. Right? So that that just doesn't work. So in practice, what people do is they deal disabled TLS 1.20. On the server and, in some cases, on the client as well. Just just to get things to work."
  },
  {
    "startTime": "00:54:00",
    "text": "So which results in entire deployments being stuck with US 1.2, with no, post quantum support And, basically, you know, potentially they're leaking client certificate details on the wire. So all of the all of the disadvantages of CLS 1.2 that we know about. Next slide, please. So the proposal is, to add, these 3 legacy code points that can only be used in the client certificate verifier essentially. So these are you know, the, BKCS shot to 56, 34, and 512. The idea is to to say that TLS implementation will disable this disable this call points by default. This is not something we recommend that people use. It's specific for those deployments that have the Right? The, these code points would only be defined for signatures in the client certificate, verified message. You know, servers servers keep using the existing RSAP KCS definitions, when they advertise support for, PKCA signatures in the certificates. Clients are not supposed to advertise these values and must not advertised as values in the signature algorithms extensions, and clients must not accept these values in the service to be verified message. Next Okay. So so basically, this is a very, very limited scope, in only for the client side certificate verify. This is this is what we would like to enable. You know, again, disabled by default, but to to give an option for for, you know, deployments to enable this functionality and basically, that's that's about it. I would like to, to ask adoption working group adoption of this draft. We would like to see some, implementation. We're planning to implement this in in the Windows TLS stack I believe, Chromium will also support that, but we would like broader support for this so that as an option to to unblock TLS 1.3 deployments."
  },
  {
    "startTime": "00:56:02",
    "text": "Any questions, comments, a question and then a comment. So can you go back to the, the second slide, I think, but when we switched out with the problem, Right. So, Do you know what fraction of the devices can do PSS with a wrong salt length? So that is a difficult question, unfortunately. Yeah. So so like, telemetry won't won't tell us directly we know that there are specific vendors whose devices, you know, don't don't don't don't don't don't don't don't don't don't don't don't don't who whose devices, basically support a safety assess, but they don't use this whole thing that we want. Right. I guess so I'm on I I think the answer to this is gonna be no, but I just wanna try it out. It's like it's like Like, first, I mean, I mean, well, they may not be able to lead. Like, this is gross, but we're probably do I. Right? Right. So, but just to, like, try it out before I say that, like, it would not be it would not work. The other option of, like, well, of, like, saying PSS relaxing the salt restriction would not get us enough. Right? Mhmm. That is that is that your opinion? Please say that again. I Yeah. So another option we'll connect you considering Right? You say you must use PSS. Will, like, the client sign with a different salt, like, instead of the one we require here. That is another option. Yes. Wait. Would that would you think would that not get us enough I have no opinion. I'm just trying to understand what you are. Would not so that would then block, TPM to 0 devices, but anything below that, like, 1.2, and that's a huge percentage. Depth. So that's not as good that's what kinda what it thought. Next. Two questions. The first, why do you need, a public code point, why couldn't you just use one of the reserve code points? Well, we would like this to be on the standard track so that it gets why implementation. Right, like, in different US tax, because our customers use all kinds of"
  },
  {
    "startTime": "00:58:01",
    "text": "So just chromium and and Windows. there's, like, it's not just chromium. It's not That's that. We would like to see this and open this up for as well as an option, disabled by default and everything. Another question is, Have you explored post handshake authentication options? So post handshake authentication is in the same way limit right now. Right? So so it exists, or or do you mean, like, at the at the application? Maybe not form. Yeah. At the Yeah. Well, that's that's certainly available. Right? So you can basically say, okay, if you have this issue, don't do TLS plan authentication, use application layer authentication, but that is a huge you know, change to all of the deployed system. So it's it's kind of difficult. You basically, you're saying, you know, scrap what you have and implement it from scratch. Yeah. But that yeah. I mean, if if it go that far I'm just wondering if it was explored. Okay. Yeah. Hi, Andre. So this is Deb Cullier from NSA. I worked DODPI and a bunch of the other PKI systems that use, I don't know, smart cards. So Have you found this with our Smartcards? Well, I I I cannot comment on this. He says I don't know. Yes. So are there particular smarts? Yes. Alright. Fine. So are there particular smart cards you've seen this issue with? Yeah. So so we've seen, so I know less about markets than CPMs. It's just happens that they have better telemetry visibility into TPM, but I have seen issues with smart cards as well. Not able to produce CSS. So we do use smart I mean, we do do clients authentication for in all of these places. Right? So if for example, curves that card in your pocket. Doesn't do this, then we're sort of in trouble, right? I guess we can try and ship them. But, I mean, really, we're only looking at using these cards until, 2035 or something, right? Yes. When everything changes. So it's a short It's a short term problem, she says. Wow. What?"
  },
  {
    "startTime": "01:00:00",
    "text": "Yeah. Hey, I got less than 60 days. So whatever. Not not gonna be my problem pretty soon. It's But there's also a shift that's gonna happen 2027 that we possibly couldn't maybe change that. I don't know. It's not something I actually thought about, and I don't know how much one point three usage we're seeing. So I guess we should experiment and see whether this is an issue for us. The smart card thing to me might be a bigger issue. Than the than the than the than the TPM issue. You've only seen the TPM issues mostly, right? Well, I mostly know about TPM issues just because of the nature of lemmetry I have access to Right. Right. Yeah. So I do encourage, you know, I do encourage governments to look into this we know there are entire, like, the government that issues smart cards for all of their citizens, for example, Estonia. Right? That's millions of smart cards. If they're not compatible, it's a big issue. Them expensive to to replace. Okay. Do you know if they're doing client authentication? They're doing client syndication. Yes. Yeah. Alright. So, that that anywhere. That's just my comment. Yep. Alright. We'd like to do, quick show of hands for adopting the, pkcsone call it pkcsone Draft. Yes. Right. Yeah. Everything is gross, duly noted. Alright. Well, it's looking pretty clear here. We know what the answer's gonna be. So, I guess we can stop it. I I can't read the numbers. I'm getting old. It's a 36 36 to 1. Alright. So I guess we'll go ahead and,"
  },
  {
    "startTime": "01:02:00",
    "text": "I'll mark the things in the data tracker, and we can get you to resubmit it when you have a chance. That'll be it. Thank you. Right. Thank you. Next, Yes. David Benjamin. Paul. Sorry, Pavel. I was speaking with my AD head on you should really confirm this on the list. Fair enough. We we can do that. Can you share prediction? And they Oh, alright. So this, I uploaded a draft recently about, this smiling her, ambiguity in TLS 13 around the key share stuff. Next slide. Sorry. I gotta so as a quick recap from how key shares work in TLS 13, we actually have 2 extensions rather than 1. The client sends so key shares are how we do the Diffie Hellman and TLS 13, and it's getting, extended to Duques Conbecomes. We have 2 extensions. The supported groups, the which contains the full client preferences, but then the client also sends key share where it sends keys for some subset of the supported groups. And then based on this information, as usual, the server picks what it wants, and then based on whether the group was in the key share subset, it can either do server hello for 1 RTT, or hello retry request for 2 RTTs. And as usual with TLS, we have left most of these policies up to the implementation, we want you you to select the best cipher suite but but but but what best means can depend on exact policies. But at the same time, we do need to specify the semantics of the side that send stuff. Otherwise, I cannot implement a Cypress with selection algorithm if I don't know that the client list is in preference order. We have specified the, semantics for supported groups. Next slide."
  },
  {
    "startTime": "01:04:04",
    "text": "But we didn't give any semantics for what it means when the client omits some key keys from key shares, but not keys from other key shares. And as we'll see you later, this ambiguity has led to leads to some issues Next slide. So the main question here is, is this server behavior okay? There are several TLS 13 servers that implement what I would call a key share first algorithm. Where first you'll look at key shares. And then if you even find a matching group, then great send server. Hello. Otherwise, go fall back to supported groups. Then if you can find that, alright, send hello retry request. And so this is an algorithm that tries to avoid hello retry requests at all costs and you know, all else equal. That's pretty reasonable because it saves round trips. You compare this with what I would call a supported group's first algorithm, where you pick a group based on supported groups, and then decide whether to do server hello or HRR based on whether that's possible. And, you know, you could do something in between where you sort of have an a quick preference grouping between the two, but this is sort of the, 2 extremes. One thing I'll point in mind point out is that the supportive group's first actually looks at a field with defined semantics. Whereas, the first one does not. Next slide. But this should be fine because clients just predict their most preferred groups. Right? Next slide. So currently doing a post call and transition. I doubt Kyber will be the last cam that we ever deploy. Perhaps someday someone will come up with a less large cap let's call it awesome new cam. So we've got awesome new cam and Kyper, which post quantum and we've got, you know, our existing X250191 that it's not. But, post condom chems are kind of a large, it's unlikely the client will actually want to send both in the client hello. But during this transition, we won't know whether the service sports awesome new chem, Kyber, both, or maybe neither. And so somehow the client needs to figure out which one to predict. And if it doesn't have the right prior knowledge, the wrong thing may happen. Next slide. So"
  },
  {
    "startTime": "01:06:01",
    "text": "As a basic example, suppose one of the groups is more common in So maybe the client predicts awesome new chem. This is one of the older service that only supports Kyber. If the server is and so the client might predict Austin Yukhem and maybe 509, it hasn't gotten that. We haven't gotten rid of that yet. And since that's free to predict, we'll predict that too. But now a cyber server that implements a key first algorithm, we'll first look at key share and go, oh, well, I don't have awesome new chem, but I have 2519. So we'll go pick that. We're sad because we'd rather have picked Kyber even though it would have cost us much. Next slide. Might imagine trying to fix this by adding some kind of out of band hit. Like, we've got this wonderful new DNS record all this extensibility in there. But DNS is not. Authenticated in many contexts. And so the attacker might hint 2519, even though the server actually supports Kuyper. We get in the same situation again. Where the client goes, oh, I'm only gonna predict X Five Nine X Two Five One Nine. Why would I waste a giant client hello on a server that doesn't support Kyber. Oh, but the server actually does some work hybrid. But because it But because it implemented a key share first thing, We're, again, at the wrong option. Next slide. Or I hope we don't have to do this, but, I think someone on the mailing this said that they have to deal with a compatibility hack where because a large client hello doesn't get through existing servers they under some circumstances need to, avoid predicting Kyber, but still leave it available for HR. If an attacker can trigger this path that you know the server supports Kyper, once again, we pick the wrong one. Next slide. But it's not all bad. Here's an example where maybe a key share first algorithm is line. If the server has no security preference between XC 519 and PGP 6, then you may as well pick the one that doesn't require Hello Retirecrest because we don't really care, then why there's cool Next slide. So this draft is trying to clean up this mess. We clarify that key shares are predict the key share subset is a prediction It does not necessarily reflect preferences, and the server should not assume the key share list reflects if you pick one that is in key share, when"
  },
  {
    "startTime": "01:08:00",
    "text": "more preferred one isn't like you you need to assume server. Hello. Sorry. You that. You need to look at supported groups for the full set, and then you can make your decision based on what you prefer for security and what you prefer performance. And then additionally, although maybe we can push this into a separate draft, I goes ahead and defines the DNS hint because I suspect we'll need one in the future, and it's sort of was easier to motivate this problem if I also gave an example of like, a thing that would break without it. Next slide. But we do the there's a little footnote here. Is that the older TLS 13 service still exists. So this draft tries to sort out some compatibility issues, by classifying groups into prediction safe versus prediction unsafe. Basically, the existing ones are prediction unsafe. Ideally, all the newer ones specifically wanna make sure that all the post quantum chems are marked prediction safe. So that no one will implement them without implementing the new server behavior. And then correspondingly, that means on the client side, you can do interesting prediction tricks with the new prediction safe groups, but for any existing groups, you have to assume that that, Akeesha First Server might exist. And so for those you need to reflect preferences and only predict a prefix of your support group, set And so that means that The DNS hint will only work for prediction safe groups. I think this is probably fine because no one has, like, found a huge need to do a DNS hints on, like, X2519 versus PGP 6. But once we get Kyber in there and once we get awesome new chem in there, you know, some 10 years later, we're we're gonna wish we have this Next slide. So the answer to the original question, is this server behavior okay? It's Sometimes, if you truly had no preference between any of your supported groups, Like, they were all totally equal security wise, and you were willing to let an attacker pick them. Yeah. This this is slide But if you support both post quantum and classical options, if you have pluggable algorithms and don't know if you support both post quantum and classical options. If you promise to your public a in your public API documentation that you were configuring a preference order, then maybe you don't want to do this one."
  },
  {
    "startTime": "01:10:04",
    "text": "And there's a certain popular TLS implementation that is in all three buckets or at least the the second two buckets. And does this. So perhaps they should change. Any questions? Hey, David. Nice catch, by the way. So I think my service had emailed this and you know, I'm back for a little bit. As I understand it, the attack problem is only created by situation where the attacker allowed to something which ordinary don't allow is a single and insecure way with groups that serve my support. Right? Yes. Although the other the non attack cases are ones where you just always get in the wrong state rather than sometimes get in the good state the attacker can get you in the bad states. So whether that's better is a little unclear. Well, I think that, like, Right. I I I guess I guess I I think I think the statement on that previous slide may have a little bit strong on what's allowed and what's not allowed. Obviously, there's the API here. Obviously, you shouldn't promise that this is, like, you know, you do something you don't do. Right? But it's like, you know, it's totally legitimate to be like, I certainly prefer 2509p26, but not at the cost of, like, you know, not at the cost of other app. It's like, oh, yeah. It's like, like, those are not equal preferences. Those are preferences, but they're, like, not equal Yeah. That's true. Yeah. I I guess I guess what I should say is this. If if if you have no preferences between your groups that are stronger than the preference of a retro Yeah. Yeah. Fair enough. So I guess I wanna try to break this into different pieces. One, I think, I think we probably do need since I think think we should not make normative changes 8446. This, but I think we should add some tact to the effect that you should be implying here, which is a that you should not infer from the fact that a group does not exist So I I guess what I what I would actually suggest, is minimally, which is if the server's not infer from the fact that something is not in key shares, it is not preferred. Think it would not necessarily be unreasonable to also say that clients should not Should should should should do a prefix actually for now?"
  },
  {
    "startTime": "01:12:04",
    "text": "That, to adopt basically the unsafe percentage you're talking about. Is what I was saying was considering, but I'm not, I mean, I shouldn't necessarily do that. I the Secondly, it's probably how does all the problem in the future. I guess I'm not I'm not totally sold on this this solution for the future, to be honest. Let me pro may may propose an alternative a couple alternatives, which I've only I'm only pulling out of the air, so I don't I don't say they're good. One would be one would be to have a signal that said effectively back, like, the old SCSVs. And, like, look, I tried this before. I got a hint, and it do this, and I'm doing it if if you didn't send that, then, like, should be sad. Right? So I was DNS hinted And that's why I'm doing this. And if you didn't send a hint, then you should get so, and another one would be, a TLS slide, which said I actually do mean I admit it when these actually are in preference order and a mission a mission means there at the end of the list. Price. So I don't know if either this works, but I I guess what I'm saying is this is, complicated thing to reason through and so fire with the whole thinking before we decide exactly what to do Yeah. I I think I would need to see those what those options are. Yeah. So so so put these in one document just because, like, it was easiest to present this way. Like, if we wanna put it, like, split it into, like, an RCA, 446 business, if it's changed or whatever, all sounds great to me. I think So Having the new server behavior is one thing. I'd I think one possible answer is it doesn't really matter enough, but, like, the the there was another part here, which was to say that If you implement post quantum things, you must do the new server behavior. And having that in the post quantum, like, like, I think it it it had I I wrote something that was, like, it to be prediction safe. You must include this sentence in your in your draft. Yeah. Which was in part just so that people would notice it because at least just stick a day for over 6 is, I'm sure no one will find it. And then because"
  },
  {
    "startTime": "01:14:01",
    "text": "flip side is I suspect most or maybe at least some of the possible solutions for the, like, DNS hint or whatever, will require that we'd be able to classify them and say, like, for sure that the post quantum ones are safe to do this and I don't I don't like, like, I don't know if we can do that classification after the fact is easily. Yeah. So I think I think what I think the 846 change should, like, minimally say do not assume that clients did not the clients admitting things meant they they were the, at the tail of the preference list. And maybe you should and maybe you should say that client should not, and and may and maybe we should say that clients assume things that are not the Delta preference list, but I'm not sure. Should not exclude things in teleconference list, but I'm not sure So the reason is yours. For the reasons that you're they're indicating it's complicated, right, So I know I think it was cloudflare on the list that that they already need to do these sorts of things. So if we stickers should not, and don't give them some kind of, like, allowance to not have to do to to, like, make that safe. We might run into some issues. Sorry. I think sorry. I think there's two questions. So on the so server behavior, I think we just say, no. You can't you can't rely on any client behavior in this in this passion. Right? Yeah. Yeah. I mean, for the client. Oh, the client. Okay. The client should. Here's in the there are clients already, like, how like, jungle do Chrome does not. I'm hoping we can keep it down. Who does who does disselective admission on the client's side? Simon, does selective admission on the client side? Right? Cloudflare based on the mailing list. Ideally? Okay. Thanks. like to get the Yeah. Yeah. And and maybe, like, less the better than in that case. Sounds good. Yeah. So speaking with my cloud flare hat on, I I really like the DNS hint, and I think that's, like, a really nice part of this draft. Sort of agree that the, maybe, the the out like, the the selection algorithm can maybe use a little workshopping. But I think I I wanted to ask whether you considered, actually defining an extension to signal the new behavior or support for the new behavior, that I I haven't thought about this, but"
  },
  {
    "startTime": "01:16:02",
    "text": "was looking at, like, the kind of the backwards compatibility story, and I'm wondering if, explicit signal would be helpful. So If we get a signal from the server, it's it's Sorry. From the client. So, like, the client says, Yeah. I think the problem is the older servers will ignore the signals. So we could make a key shares to extension that contains some of the other ones. This is I haven't think this is most similar to it with Ecker. We probably need to see it written down and think about it. This was the the simplest thing I could come up with at the time, but maybe, yeah, maybe there's something better. And just as a general thing, is it it do we actually, like, update documents in this fashion? I'm just, like, trying to understand as a Like, like, we have a new RFC that, like, kind of extends, 1.3. That thing we could do? I will defer that to these folks here. I just put it in this form that I because I thought it easier to present. The answer is yes. We can do that. Alright, Tom. I think that this that the addresses in problem that we need to fix. The main question or thought that I have is that reliable DNS on these souls things that are connected to the public internet or at least have a DNS, and there's probably a lot of clients that do direct addressing or otherwise, don't rely on DNS and conditional sort of use this this kind of solution. So I'm be in favor also specifying something that the server gets configured, but I like to use these groups these will only fall back so that we avoid these kinds of situations. Thanks. Yeah. There's there's 2 the the so the the half the concerns with TLS with the drafts is intended to work for, like, any kind of game like this, like, some kind of out events, any kind of out event story will most likely need some answer here. DNS was more like an example of, like, Here's the thing that we would probably want for DNS based things. Obviously, like you say, non DNS based service. Probably need to solve this problem a different"
  },
  {
    "startTime": "01:18:06",
    "text": "Alright. So I think what I heard was there might be some quick iterations with Edgar to get some text in the April 1st 6 disstrapped, and you guys will everyone else will continue working on this in the repo and other places. Yeah. They're hilariously connecors points out that they're actually just texting the craft that makes exactly this point that we may not strongly enough. There actually is text in 8446 that says, basically, Actually, the emotional for things might be a minute. Like, sorry. So, like, maybe we should, like, make it more uppercase for something. Yeah. Evidently, some people didn't notice it because I think there several implementations that do this, and I don't know if all of them were aware of but, like, I mean, some might have I mean, I'd I I wasn't aware of the text existed until I until very recently. So It's me again. Although now also with Bob and Devin, Bye. Everyone, I'm Devin O'Brien, and I'm here to introduce, TLS Trust Expressions. Next slide. So this is a little dense. I'm gonna start with a brief summary. At a high level TLS trust expressions are a way for relying parties to communicate trusted certificate authorities to subscribers as well as supporting mechanisms for subscribers to select a trusted certificate to serve backfitter line parties. And the intent here is that it does sewn away that's flexible enough to solve some real world PKI use cases. Looks like so as a motivating use case, let's say you wanna rotate a CA key. Right? The the simple approach is, like, just stop or just create a new key, go into your data center, go into your cage, generate a new root and then just start issuing. Right? But in reality, it doesn't work that way because of a lot of complexity. Let's say you get that new key trusted by, a root program."
  },
  {
    "startTime": "01:20:02",
    "text": "Those keys, new relying parties may only trust the new key. But older line parties may only trust the old key here. How do you satisfy both? In practice, this is, solved by very, very long overlapping inclusion periods, So so you have an old key and you've already generated the new one. And you wait, say, 5 years until enough relying party support it, for you to stop using the old one. And despite the fact that we know key hygiene, is or sorry, key rotation is very good key hygiene. In practice, the web PKI has twenty five year old root keys because this is just very hard to solve in practice. It's just easier to keep using old In practice, relying parties don't tell the subscriber what CAS they trust. David's gonna cover it a little bit a little bit why existing mechanisms to do this are kinda cumbersome. In addition, different relying parties have different requirements. As I mentioned, different versions of a single relying party, like a single user agent, may trust certain, CAs in one version and different see is in another version. Also different, relying parties made by different vendors, like different browsers, different operating systems, may also have differing, trust stores And these requirements aren't actually coordinated in any meaningful way. There is the possibility that these requirements can conflict. And at the root of all this problem is that subscribers need to serve a single certificate bundle a certificate and certificate path that is supported by all relying parties that they wanna serve, traffic to. So what this means in practice is that subscribers are limited to the of choice of all relying parties for Next so describe what I mean about the the being stuck in the here, we often talk about the web PPI as the singular framework, but in reality, it's a lot of overlap frameworks on top of each other. And we're operating in this intersection."
  },
  {
    "startTime": "01:22:04",
    "text": "So in this diagram here, we have, say, stores maybe by 4 different relying parties, and within each circle are the CA's that they trust. Now despite the fact that trustor A and trustor B have decided that CA 2 over there is perfectly valid to issue certificates to, their, that'll be trusted by their relying parties and practice that CA can't be used by subscribers because trust stores C And D here don't trust it. So we're stuck in this intersection where, like, CA's 5, 6, and 7 here, are the only usable, CA's that subscribers can select from. And this poses a few challenges for for actually all parties involved. At the CA level, only roots that are ubiquitously trusted are useful, to provide certificates to subscribers who are their customers. And so, again, this looks like very long periods of time where they they stand up a root and wait many years for inclusion in enough relying parties to be able to start issuance. And it's also difficult to support old and new relying parties these changes as I mentioned because those requirements can diverge. Now for subscribers, you you you often thought of his websites and TLS, but just broadly subscribers. Their choice is limited to only of the seas in the intersection, but it's actually kind of difficult to know what will and will not work. There's no authoritative sort of information that they can use to pick pick from to to determine what CA is to use. They just kinda rely on general knowledge of of relying parties and what CA's we'll sell them to, to to be able to use a certificate and sort of the other challenge that is posed to subscribers is that one relying party making a change to their trust score. Can impact their ability to, to use an existing certificate. And these can change during the lifetime of a deployed certificate So there's there's deployment risks here, for breakage. And speaking to that breakage point, relying party has the challenges"
  },
  {
    "startTime": "01:24:01",
    "text": "that when they wanna make a change to to push trust or distrust, in a certificate authority to you know, better serve the security interests of their users, they're forced with a choice. Like, push the the change out now because that's what I wanna do, or do I have to and and risk sort of incompatibility to breakage, or do I wanna wait a while and sort of coordinate this until this decision bakes with the ecosystem. And then we can make the change. So they're they're always posted this this trade off. And the crux of this is because they have to do one certificate only have one certificate to serve to all relying parties. So, underlying this proposal is sort of a change from these single certificate model, to a multi certificate model. And what I mean by this is that subscribers will obtain certificate paths multiple certificate paths that the collective set there's at least one certificate path that will work for all relying parties that they care about. Rather than what exists today where we have one certificate that needs to serve all relying parties. But to get to this world, that's sort of easy to describe to get to this world, there's 2 major changes needed. The first is a certificate negotiation mechanism that allows subscribers to picks the right path. As and we also need a a easy issuance mechanism that subscribers when they obtain a certificate when they request a certificate, they get back a set that sort of represents that collective set of all relying parties, needs that they exist today today. So to talk about the first bit, I'm gonna hand it over to David gonna talk about certain negotiations. Alright. So are various pieces in our certifications Yes. What was going on So But first, let me ask a perfect right question. As I remember the situation, tails of point 3 protects you to 1 and any certificate has been arbitrary number of"
  },
  {
    "startTime": "01:26:01",
    "text": "an arbitrary number of of change certificates. Right? So I'm getting for for so if lots of grip, for instance, has both a trust anchor and across sign. They can apply both of those. Think they're gonna put those. Correct. Yes. We we we cut this out of the slides for time, but, yeah, so the path building is. So so I think what you what you're describing here is this is a path building where you send, just a bunch of stuff, and then the relying party leaves their way through. And so you can support different set of trust anchors in one bundle. And this is sort of what we do I would argue because we don't have a better story here. Like you say, the identity certificate has to be shared. So not something that, like, as a subscriber, you can use like, the the CAs have to, like, agree a cross sign has a lot of other implications to do that. It punts a lot of complexity, the client, which have to solve this exponential time algorithm just to verify a search and fundamentally, it means we are sending stuff that not every client wants. Sure. Which right now is mostly okay because signatures are free once we get into plus quantum land when they're 2 k a pop, we'd really like to not send those extra values that are on I'm just trying to tease that to be, like, help. Yeah. So second, it seems to me there actually are 2 problems here that, like, that you kind of glued down a little bit, Devin, One of which is the servers, is measurement of, like, the environment to know what you have to have and what you don't have to have. And the other is And that is a, that is a measurement problem, but not a, not a, not not a problem in individual connections. And the second is what David just said, only because then it So, like, when it's like, like, when to imagine, I guess, a hypothetical, that, you know, they they I mean, I mean, So so so I I guess what what I'm getting at is, like, one thing to know. On this particular connection, I gotta send, you know, a certificate, and then I wanted to send additional It's another no. Actually, I can actually, like, everybody now supports the LE root so I can stop sending so I can stop sending across ice, rice, rice, rice, rice, rice, rice, rice, rice, rice, rice, those are just different properties and, like, and so I think you wanna say, I think,"
  },
  {
    "startTime": "01:28:01",
    "text": "David, if I hear it correctly, that you need the per connection information not just the measurement. I just wanna point out that if we want, but we need the measurement, we we have down to a different solution that we have Yes. That's right. So this is this is primarily about the per connection thing because as we'll talk about later. We we think that the Being able to do it per connection makes a lot of things in the web PKI a little bit easier. There's sort of the, like, the there's a footnote that addition to that problem, like, we can't even manage single certificate very well the measurement issue you know, it is just a measurement issue, but I think anyone who has deployed a certificate change across a widely visited website will tell you this measurement issue is Alright. So next slide. So you may remember that in our 4 46, we promoted the certificate authorities field to an extension. So you actually can send it in both So why don't we just use that? The problem is it is a big list of X 509 names, and X 509 names are not very there. These giant overly complex human readable strings when we really just want an opaque identifier. Also, at least in the web PKI, relying parties often trust many CAs. So give a couple examples. In the Chrome root program, we would have to send a 131 names tolling 13 kilobytes and mozilla's would have to total about 14 kilobytes And as client hello sizes, a leading cause of latency and death in TLS connections, we probably do not want this. Next slide. what are we proposing instead? Well, if we can't actually So say that said, the full list will give a short name to this list. So we're gonna, define a trust store which is gonna a collection of trust anchors and give it a name and a version which is for sort of extensibility. We'll talk about this later. And this so the client will send the relying party will send something like I support everything and Chromev2, with this exclusive solutions thing. And the subscriber has metadata for each of its certificate paths, which named entries correspond to it. And then based on that, it can go do a matching operation and pick the best eligible option."
  },
  {
    "startTime": "01:30:00",
    "text": "For in this example, certificate a is only in some enterprise PKS, so it does not match. But D and C both match. We assume these are in preference order, so the subscriber will pick they might they might prep order them based on size of the certificate, or which things sign faster, whatever you want to order them based on. Next slide. So you're probably asking, Where did this information come from? Like, somehow, someone everyone needs to know what Chrome V2 and enterprise PKIV1 mean. Next slide. And the answer is we leverage the existing communication paths that already exist. So broadly on the subscriber side, the root program, which already has a relationship with all c as in it. We'll publish what we're gonna call a trust store manifest, which describes all of the lists that it defines. The CA's will consume that. And then when it issues subscribers, because the CA's already talked at primers to issue certificates. It associates certificate path with this metadata. And that's enough for a subscriber to do a tap. On the relying party side, the root program, which is your browser or OS vendor, for instance, is already somehow provisioning relying parties either you know, hard coded in the source or just or an up to by an update mechanism. So alongside it, it can send the corresponding short descriptor of, the trust tanker list. And if everyone sent the sick corresponding information, then back at the bottom in the TLS handshake, things will interoperate. Next slide. So starting at the root program, We the trust or manifest is we've currently picked a JSON format. Doesn't hugely matter. It describes the current and historical versions of a trust store. So their contents and Also, along with each trust anchor, we're gonna store some metadata this label's mechanism and a max cert lifetime, which sort of to do which have to do with, version SKU, which we'll talk about later. And over time, the root program will update this list by defining new versions. The existing versions are immutable. So Chrome V2 will forever mean Chrome V2 because we don't to change the behavior anyone who is already shipping that list. Next slide."
  },
  {
    "startTime": "01:32:01",
    "text": "Then the CA, collects these manifest from every reprogram it participates in and computes what we're calling a trust or inclusion list. Which is just a list of entries for every single, trust store that this path corresponds to. And we send that to the subscriber issuers for each path it's got. One thing I wanna keep in mind is that because we want to reuse existing communication flows, we assume that this metadata is not updated until the certificate is renewed. So if you got your certificate in January, then you have January's worth of information, and we need to make sure that works correctly. Next slide. The relying party side, the re the reprogram computes or calling a trust expression or a trust expression list for which describes this, the the set of trust stores. Sorry. The set of trust anchors. And So each trust expression is, reference to a trust store by name and version. Then a list of exclusions. And so it matches is in the trust store minus the things that you have you have punch that. And then The a path is eligible if it matches any of the trust expressions in the list. The reason we have these exclusions is partly so that you might have some entries, like, for instance, I'm we might have, like, Chrome V2 contains some CAS that we only want to gate on a particular version of Chrome. But also more importantly, because of this this version SKU issue, we need to be able to handle removals in a way the subscribers with slightly stale information can handle, the sections, those sections in the draft talk about it in details. Next slide. One thing to keep in mind is that by sending the list of trust anchors, you have sent the list of trust anchors. So whatever the anonymity set you're trying to go for, this mechanism is only targeting the trust anchors that are common to your identity sets. So for instance, whatever routes are trusted by your browser vendor or OS, those are probably fine assuming your sorry. I don't know where to start. There's like, everyone running a Chromium derivative or everyone running windows or whatever."
  },
  {
    "startTime": "01:34:02",
    "text": "If you are not in this situation, then this draft is not quite gonna work for you, but it doesn't make things worse. The other like, the other things continue to work as they were before. The selection algorithm is can't find some match via trust expressions, just go do whatever you're previously doing. Maybe you have default cert, maybe you do, some heuristics you know, whatever. And then hopefully in the future, someone can define other mechanisms. Yes. I see someone's, like, visually do that or the next slide. Okay. Next slide. And over the So to, partly tie a bow around it or or tie a partial bow around it. We did a little stuff for an acne extension, which wasn't very much. Next slide. As you can imagine, before a subscriber to be able to multiple paths from a CA, you have to have a way to get there. And Acme actually already had a way to send multiple certificate paths in RFC 55. If you look at the text in there, you, Acme is allowed to answer with, multiple link relation header fields for alternate certificate chains. And the language in there currently says clients can touch these alternates and use their own heuristic decide what's optimal. What we've actually done is we've added a new application type to include the trust inclusion lists in there, at which point you don't need the heuristic anymore. So this lifts you can also lift the same end entity as long as the CA is okay with issuing everything at the same time and renewing everything at the same time. This doesn't really solve all the use cases that might be possible in terms of certificate issuance. If you have multiple paths that you wanna issue, renew at the different times, more complex cases, multiple orders, we're just going to sort of save that for future work here. This is just, as a starting point to show how"
  },
  {
    "startTime": "01:36:00",
    "text": "the existing mechanisms can work to give you multiple certificate pounds. Next slide. So we've defined media type for the to add the certificate property list at the front of the existing acme type. PEM certificate chain with properties adds effectively a container, the certificate property list type encoded as in the TLS handshake. We use this to include the trust store inclusion list, when the CA makes the trust store inclusion list, It adds it in here. What you get back, what you request in Acme is then a PEM certificate chain with properties. You're using the new type And what you get back is the certificate properties, which is the contains the trust store inclusion list, and then the certificate path. Below it. And we use just use the HTTP accept header type to negotiate this the acne request. Next slide. The net result is CAS can transparently issue multiple paths that together cover all relying parties. You might not get one thing back. You might get 2, 3, 4 things that you have enough information that the subscriber software can choose which one matches any particular trusted trust or expression. This important thing here is the root ubiquity problem goes away you can have things that only certain clients support. Next slide. So to just go over a couple of multi certificate examples, Next slide. So key rotation as Devin, alluded to at the first. The CA operator generates a new root key and you can issue from both of them in parallel. The new relying parties get the new route. Old ones get the old root. Out of date relying parties still keep working as long as the old root key is in operation, and assuming the recognizes and understands certificate properties. No subscriber changes are required during a rotation."
  },
  {
    "startTime": "01:38:04",
    "text": "Subscriber might magically get a new provisioned when they request a certificate, and they don't need to know why they're the why there are now 2 paths. They just need to know which one to send where based on who supporting what can we take questions now or bigger? Daryl, do you wanna do it now, or do you wanna wait till the end? Let's keep going. Almost done. Next slide. When you're lighting intermediates, if we let's say you're you're a browser vendor, you decide to align all your intermediates together. A pre distributed, pre distributed intermediate list is effectively the same as a short lived set of trust bankers. It's just a lot of them. So we can emit the intermediates just as in our cert a they, draft for Sertabridge, at bridge, Jason. The minute I the CA just sends the short path and the long path the Described subscribers. The up to date relying parties that have done have a light at Intermediates they send a trust expression that indicates They just trust these as trust stores. And correspondingly to subscribe to software. He'll pick and send the short path. The older relying parties just still get because their trust or expression didn't indicate that they have all of these short lived trust anchors in there. Next slide. For Post Quantum roots, post quantum roots can now be gradually deployed. This means that CAS can introduce post quantum roots at different times. For different relying parties. Might have a relying party that trusts some post quantum roots, but not a specific post Quantum root, and you don't have to rely on a hint based on other agent behavior to decide whether you're going to pick post quantum roots or not. And so certificate negotiation, again, fixes the root ubiquity problem. We can have some relying parties moving forward, others not moving forward at the same pace."
  },
  {
    "startTime": "01:40:00",
    "text": "Next slide. And finally, with subscriber yourself where being able to pick from a select of certificate paths with information on what's supported and where A subscriber can combine output from multiple CAs. Because the same negotiation method will work. Just a slightly different deployment model, You can go request certificates from several CAS, even that even the and what you end up with is you have a backup if one CA is unreachable, compromised, or removed. And so it can be used to be compatible with either also be used to be compatible with multiple ecosystems if let's say one side of your world is web PKI and one side of your world is something else. Next slide. And so I'll just hand it back over to Devin to recap. So just to bring this all back together, TLS trust expressions, right, we're top we're proposing a TLS extension between the relying party and subscriber, but in order for this to be usable, we need to propagate the information through the existing workflow from the root program to the relying party for the trust expressions. From the root program to CAS to subscribers for the, ability to the appropriate certificate this enables a multi certificate model by allowing subscribers to know which certificate to serve to which airline party. And as Bob covered, it covers, this improves several pain points in the, the web PKI today that are rather problematic. So that, again, Alright. We got 2 more presentations, and we got about 20 minutes. And their queue is like, 6 deep. So let's keep it quick. Thanks. Dentists. Hi, Dennis Jackson, Mozilla. I'll try and be brief. It seems like the key security benefit of this draft is making it easier to remove CA's. Which is great. But as part of the draft, this really relies on those CASs to help provision those backup certificates in the first place."
  },
  {
    "startTime": "01:42:02",
    "text": "At least it's like, I understand kind of the ACME extension. You're gonna really kind of be requiring that the CA has some kind of partnering agreement with another CA provide these kind of backup certificates and stuff. And I think you know, you know, there's not really an incentive for a CA to do that. They don't want to be easy to remove. They're incentivized to make it very difficult for them to be removed So I'm not sure whether we will actually see those benefits in practice. We're short on time that the bigger concern I have you talked a lot about making it easier to sort of add CA's that are different between different root stores. I want to pitch quite hard that this is, this is not a good thing. And, a big part of what keeps the web the way it is. Is that everybody is kind of forced to align on the same set of CA's, which are essentially globally shut. If it's easier to introduce CAs on, like, a national basis, I do think we'll see more countries start to do this. And sort of the the endpoint of that, that's a very long process, but the endpoint of that is a situation where a particular federation or country. You can only or union. You can you can only access a site with us, that's from a CA recognized in that country. Effectively this becomes a very effective censorship mechanism. So speaking of the first part, The CA Distrust is not actually the primary goal here. I think one of the things we covered is the adding the new CA's for, like, say, existing CA's like key rotation. Nuclease coming in. It's a huge barrier to entry right now. For adding UCAs, and they have to operate a secure audited service for, I think, 3 to 5 years on average, before they can start issuing their first usable certificate. So that, I mean, that that there's there is benefit here, that to your second point, your first point. Is this doesn't actually require the CA to collaborate with other CA's"
  },
  {
    "startTime": "01:44:00",
    "text": "to provision backup certificates. We need further work to allow subscribers to obtain multiple certificates here. But we're not proposing that this requires a CA to have a contract with another CA for a for a fallback solution. Right? Like, we're we're not opining on any things, and that can be solvable outside of this draft. Okay. But then the subscribers gonna need to have some kind of arrangement. Some kind of financial to to what, Bob mentioned, like, there's a lot more work needed on the acne side to enable this. We needed to get a draft out, with sort of a plausible description of what could work. But there's multiple other options for subscribers to obtain these certificates. How do you feel about the what country based this year around. So That's a hard question to answer. I I think the the reality is is that you you say that it's it's better that we have a common set of CA's but but the truth is is that there are differences here. Right? And so that their seas that are left in this periphery that are not able to be serviced simply because a single user agent hasn't yet gone through their process, right, and I've I've worked on a couple root programs myself, and sometimes these things can take arbitrarily long periods of time for no real defensible reasons. Before they get added. And so this can reach sort of a usable critical mass. Without waiting for the slowest actor in this entire ecosystem that you care about. Yes. But I want to point out that everybody that's relying on that small left out CA gonna have to maintain multiple subscriber agreements with different CAs, until that final user agency comes. Although they'll start being able to use the new CA on some connections, they're still gonna have to pay the cost of multiple CAs and relationships. Until that last user agent buckles. Is true. Thanks. So to answer that slightly, the So so the there are variations, not just within different relying parties, like, different, types of software, like, different versions of one relying party. Will naturally vary as we like. You know, remove this old key, add this new key. So I don't think focusing. So I think, like,"
  },
  {
    "startTime": "01:46:00",
    "text": "There's, like, a whole space of variabilities that, like, will be resolved if we can do this more cleanly. Jonathan O'ildan, I'm not a big fan of these groups of CA's because the set of CA's will grow much more slowly than the set of sets of all as CAs ever. You're you're gonna find that you you've gone for groups of CA's because they're smaller now. Within a few years, there will be exponentially bigger than just listing the CASU support. So the client, like, on any individual connection, you're not going to list very many. The subscriber information may grow a little bit, but this doesn't gets sent on every TLS connection. So as long as it's not ginormous, I think it's okay. So which is why on our, like, we actually omitted an optimization to some, like, version ranges, which we could do, but, we did some sort of back of the envelope math and as long as they're not, like, like, we're not expecting these to be minted every, like, 5 seconds. So It's not actually, like, we don't expect it to be a huge size issue. Of course, we condensative, like, it does become 1, but Well, it it's just that it grows double exponentially. So then the size this year is gonna get Where's the exponential come from? So the every time you have an UCA, then you have to end every set of clients That supports it or doesn't support it makes a new certificate less financially. I don't see where the exponential exponential comes from. So every root program that adds that CA will mint a new version of their trust store. So I suppose it is, like, number of It's number Number of root program. Like, for for each third path, we might have number roughly number of rig programs. Bits of information. Which is linear for. Number of potential different client configurations. So different so I guess you will keep hold on to, like, the historical"
  },
  {
    "startTime": "01:48:01",
    "text": "Historical information for each growth program. Yes. This is where, you know, you assume that they get minted, you know, once every, like, you know, maybe, like, ten times a year is, like, already pretty aggressive. Then that's already not gonna grow very much. So Chrome V2 We can probably take this offline. I think this is, like, mostly an encoding question. Yes. Nicola? Okay. Nicole Tuveri, Tampa University, I I wanted to go back, to the concern about, lagging out. About censorship and surveillance. So the moment you have these, extensions that marks what you are including from whatever group you have, you are basically giving your internet service provider a signal if you are in for example, deliberately excluding the government issued certificate authority from your trust list. So I was wondering if this was considered and I would displace with ECH, maybe, or your thoughts on this. So I think this goes back to the, like, you you should communicate the thing that is in your anonymity set. And, Like, We are so it is already the case that, like, browsers broadly, like, tell you, like, which, like, the Chrome's clientele is very easily distinguished. So as Firefox is and that already implies whatever the decisions Chrome or Firefox made. And so you you you should only communicate that granularity of information and no more. Or, like, whatever granularity you're willing to communicate is kind of a technological Yeah. But I guess the added signal is that is the user configure is to disable some things across in the group then that's a new signal that can be used for surveillance or sensors. So the draft covers this"
  },
  {
    "startTime": "01:50:00",
    "text": "if you have, you should also not reflect user configuration in here unless you know, again, if it's part of the on interview set, like, if the admin if it's like, enterprise deployment, you could imagine enterprise saying, like, I am okay revealing this in this context whatever, but by default, the expectation is that user configuration disable routes that will not get reflected in rare enough that it's I don't expect it to be a huge issue Hi, Seembro. Quickly, I an echo Dennis is, concerned as to have making it easier to add UCAs and maybe have downsides. I'm also not sure about the it takes 3 or 4 years to get issuing certificates because I think experiences from new HCAs tend to start as intermediates, and then get into the root stores later. So I don't I'm maybe I'm misunderstanding if you could clarify that. And, and, lastly, I would thank you for not claiming that this is a simple thing. So, it's nice to see somebody presenting something and kind of admitting this is a kind of a long complicated So thanks for that. Alright. And let's see. So I'm already lost track. The The 3 to 4 year thing was to clarify. Yeah. So there's a 3 to 4 year thing. Some cases. So, okay, so if you do it by a cross sign, yes, but that has some interest in security and operational applications that, probably are longer than we have time to go into. If you don't do that, it can take even longer because the the 3 to 4 years, I mean, so It's it's long it takes to be added, but then there's also you have to wait for the oldest relying party age out. And if for instance, you serve point of sale devices that are never updated in, like, storefronts across, like, the world, then maybe this 3 to 4 years is actually infinity. There. So let me let me maybe change the clarifying question a bit around. Is there a case of somebody getting into the root stores. I'm waiting that long to start issuing and never having been an intermediate. So, yeah, I I think requiring a CA to approach what is ostensibly a competitor to purchase ability to issue certificates is its own set of problems."
  },
  {
    "startTime": "01:52:00",
    "text": "Yeah. Yeah. There are many CAs who don't have the leverage to do that. To purchase a cross sign agreement. And so I think the Mozilla root program, for instance, just because they operate fairly transparent program and timing information is easily available. I I can go double check my numbers, but I think 2 plus years. From stand up to inclusion el Hire, Dennis' It's less than 1 now. So so, I have been looking at historical information. Things have been getting faster for better or worse, inclusions have been speeding up but again, there's multiple periods back to back with this, but I don't think, cross signs are actually the panacea here. Okay. Thank you very much. Obviously, we need some more, discussion on list. Thanks for bringing it forward and, you know, list and get up. I am gonna apologize to Kyle and get in. Please take your comments to the list We have 2 more presentations, and I think we're only gonna get the 1. So, Jofen, good morning, everybody. So, hopefully, this is very short because it is, about a draft that is only 11 sentences long. I tried to keep the number of sentences in presentation to less than that, I failed. Distinguishing bots is hard. Because many bots don't run their own infrastructure. They just run-in public clouds. And they say, oh, you can identify us by us sending a special user agent. Next slide, please. But it turns out that anyone can rent space in a public cloud and set a you know, publicly known string. Next slide please. So we want to use, mutual TLS but that has to be initiated by the server in GLS 13. There is post handshake authors and exports to authenticators,"
  },
  {
    "startTime": "01:54:02",
    "text": "that they add an extra round trip, and they have to be negotiated at the HTTP layer. So, They, don't really work very well for us. Next slide, please. So, could just send a different request every time. If we incorrectly send us different requests to a user, they probably won't know what to do. Next slide please. So this is a proposal to add a flag the flag says, I have a client's certificate. Configure. And we proposed to use the TLS flags for this. Next slide, please. Do people think this is useful? Is there interest in working on this questions. I have a key. I believe Tom is in the queue. I think Glenn was from previously. Tom? Okay. Yeah, this might help solve the problem that we have in Oscar. Because offhand, we have a bit of trouble authenticating a specific request message due to the way that the authentication works. And wanting to do things quickly, and this would probably help partially addressed that issue. With maybe slightly different semantics, but I think there might be some opportunity to align things there. Sockets. Rich, yeah, Rick solved. I think this is useful because we have some customers who, by policy, want to do mutual authentication. And if we can, like, rejected early at the client thing. It also cleans up an issue because most browsers don't do TLS 13 post handshake auth. So yeah. So this is aimed strictly at bots, not browsers, but I've done Yeah. It's"
  },
  {
    "startTime": "01:56:00",
    "text": "Yeah. Andre. Andrew Pope, Microsoft. Just a quick question. Does this need to be sent by the client or could the server in this duplicate request since they'd say, only send get you if you have a hand coded already readily available one. Would that also solve the same problem? Sorry. Can you repeat that? So if instead of the client indicating that they have a certificate, yeah, the service certificate request, would have a new extension, for example, that tells the client only send a certificate you have it, like, hardcoded in those so the problem is if that hits Chrome or Firefox. Right. Chrome will say, oh, I should ask the user if they have a certificate. No. No. No. That will be specifically an extension that says, don't ask anybody. If you have it already, you know, send it we'd we'd have to ask the browsers if that works, but I wouldn't have thought so. Yeah. You have to send a search different requests to 1st So that server needs to Right. And and so the idea would be the certificate request with that actually indicate, you know, only answer this request that if you have a certificate handy, senate Yeah. The I I mean, it can reply with an empty certificate frame. Yeah. We allow empty certificates. Yes. That's I mean, that's already allowed, but prank. Yeah. Yeah. I I I don't think it works, but we can talk to the process. Crispy. Yeah. Just to follow-up on that, that point, quickly, like, quickly like, It it might be fine for Cloudflare to send like, a certificate request to every eyeball, but it would be really weird. It's just seems picky, to send those bytes that are not likely to be used. I wanted to ask though, Jonathan, what work do you think is remaining for this draft? Like, is there actually any work for the working group to do besides, say, this looks good I don't think so."
  },
  {
    "startTime": "01:58:03",
    "text": "It is predicated on the TLS Flagstraft. Which was blocked on lack of implementations. So I now have 2 interoperate implementations that I've written. And I'm trying to get them open sourced but, yeah, I've got a patch for boring, and I've got a patch for a go line. And I think we're key slides. Okay. Thanks. I guess what we'll do is we'll take this to the list to see if people are interested and go from there. Alright. So I'm gonna flash some slides up. Dearja, I apologize. Or, running out of time, basically. So they're they're actually 2 sets of slides in this, about 2 other drafts that were posted. 1 is about Turbo TLS. Another one is about batch signing. So please have a read of these. Take it to the list. There's actually another presentation that's on there, which is a year in the life of a sting, of the designated experts. We thought it would be useful for everyone in the working to know what's been registered. And so there's slides up there and we're trying to have that every time. So thank you very much. Thank you to the scribes. Appreciate it very much. I will see you at the next meeting. Thank you. Bye bye. How are you?"
  },
  {
    "startTime": "02:00:04",
    "text": "Right. Right."
  }
]
