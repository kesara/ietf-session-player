[
  {
    "startTime": "00:00:09",
    "text": "uh okay oh yeah that's right is it just one page maybe no I'm wondering that looks better it does why did that do that okay sorry foreign foreign command minus there you go"
  },
  {
    "startTime": "00:02:02",
    "text": "ask me for sure [Music] all right after a two-minute launch today we are ready to rock and roll uh let me welcome Kevin uh who will be here with us in room to represent project Callisto an extraterrestrial collaboration with webrtc and ab1 if you're in this room and you are part of the RTC web working group raise your hand okay so several people um cool other codec and other friendly people here take it away thanks Ted uh it's an honor for me to be here speaking to all of you uh esteemed internet engineering task force members thank you for having me I'm Kevin I'm with Cisco and I wanted to share with you a brief version of the story of how we came to participate in Project Callisto we partnered with Lockheed Martin together with other companies in the industry like Amazon with their Alexa Technologies and Apple iPad Technologies um to try to solve the problem of real time or as real time as we can do given the latencies uh Communications and deep space exploration and I want to give credit to the the folks who worked on this implementation and uh and built the original version of this presentation um I'm just here to share it with you all so what is Project Callisto it's a technology package on board the Orion spacecraft to test the viability of commercial Technologies in space exploration uh and I mentioned those Technologies already as WebEx by Cisco Amazon Alexa an Apple iPad tablet mounted inside the"
  },
  {
    "startTime": "00:04:03",
    "text": "Orion spacecraft to allow future manned or crude excuse me crude uh space missions to collaborate in near Real Time with folks on the ground and Orion is the deep space exploration spacecraft built by Lockheed Martin and Artemis is the series of missions to fly that spacecraft to the moon and ultimately to land on the moon and to perform Moon exploration and and ultimately Mars uh exploration okay okay sure thank you you can scan that QR code up at the Top If you want to learn more or go to that URL and sing tiny font up in the top right hand corner Lockheed martin.com and find the Callisto page there so Artemis one is the first of the Artemis missions that will launch from Kennedy Space Center now targeting November 16th launch window at 1am Eastern time that's 6 a.m here in London for those of us that live here and it will circumnavigate the moon and return to Earth as a test flight of this system we're all super excited and uh crossing our fingers that that November 16th date holds um they've been monitoring uh the hurricane weather and there's they've had a few uh resets on the on the calendar but November 16th is the the current scheduled launch date so we'll see if that happens and the challenge that we were asked to solve is real-time video HD collaboration in space"
  },
  {
    "startTime": "00:06:00",
    "text": "and there was as you can imagine a few technical challenges the first one is It's a Long Way to the Moon you know our industry standard is 300 milliseconds round trip for real-time collaboration uh with project Callisto we were asked to engineer it to up to 20 seconds or 20 000 milliseconds round trip which is uh awfully a long time in the world of Video Communications as those of you who work on video now and if you want to see what to 20 000 milliseconds looks like uh oh this is not a build slide I lost my bill it's because I converted it to PDF never mind the PowerPoint version that line draws out over 20 seconds so you can kind of experience it so obviously the questions are are we going to have delays in the various protocols not only at the video bitstream layer in our ab1 codec but also in protocols you know setting up signaling uh you know connecting the Call Etc and how effective are our error resilience and Recovery techniques going to be in the face of these huge latencies and packet loss and Jitter thank you I've got seven seconds remaining what does that mean oh thank you Ted okay thank you yeah do that do that okay well there we go so this is how long it takes to send a video frame from the Earth to the moonlander and respond right awesome thanks for the demo tip so the second problem is the satellite"
  },
  {
    "startTime": "00:08:00",
    "text": "network uh has pacquelos and Jitter and very low bit rates so it's an asynchronous network of 200 kilobits per second Upstream from the ground to Orion and one megabit down from Orion to the ground and of that 200 200 milliseconds 160k of that is video and 40K of that is audio so you know that's a challenge to how do we get high definition 30 frames per second video to work at 160 kilobits per second um and there's also pack of loss and Jitter to contend with the third problem is the first Artemis Mission Artemis one is an uncrewed flight there's no humans on the thing to to touch the iPad and launch the app and place the call and all of that stuff so how in the world are we gonna solve that you know how are we going to launch the application how's the application going to know when to join the call how you know what happens if the app crashes what happens if a pop-up gets in the way of the application um and so there's no buddy to touch it and there's no you know we couldn't use Audible commands either because our system is the thing that is receiving audio from the ground playing it out of our speaker uh on the iPad tablet and then you know we could try to Loop that back into the microphone I suppose but like what what we'd have to we would have to have a call up in order to have that pathway established so like uh so we had to come up with clever uh Technologies for that our clever techniques to solve that problem so our solution was to build a custom version of our WebEx app highly customized for this mission and we built a new protocol translation server that sits on a container co-resident with our conferencing server on the ground that we called the ground"
  },
  {
    "startTime": "00:10:03",
    "text": "control server and we implemented a new UDP based signaling protocol that gave us a single round trip transaction request response to join the call eliminating all of the normal TCP and TLS handshaking and multiple round trips to get a call up and that protocol converter simply converted that new UDP protocol that we implemented to the normal standard webrtc HTTP websocket based Communications protocol that we do normally on our server for our normal application and we set up a simulated network of 20 milliseconds of latency and pack a loss and Jitter and surprisingly it just worked like out of the box we were shocked except uh h.264 video Codec kind of fell apart at these low bit rates and looked pretty bad so we introduced ab1 into the project which we had wanted to do but we tested it with 264 before moving forward with ab1 so we said yep okay confirmed 264 is not going to work let's let's go ahead and Implement everyone so uh just a few words about av1 I'm sure many of you in the room are aware of it and many of you I'm sure have contributed to it but av1 is a new video Codec designed by the alliance for open media which was uh sponsored by several companies but three of those were Google Cisco and Mozilla contributing our very our respective video Codec Technologies into this effort to produce a codec that would be as good or better as h.265 while being open source and royalty free and you can"
  },
  {
    "startTime": "00:12:01",
    "text": "read more about it at the you can read more about R contribution to that at that link down at the bottom and I just want to shout out Jonathan Rosenberg in the room here for uh initiating and leading this effort when when you're at Cisco thank you Jonathan um so we have our own implementation of the Cisco av1 codec and that's primarily because the aom version is not super optimized for real-time low latency bi-directional video conferencing real-time communication so we have our own implementation of the av-1 encoder developed by colleagues in UK uh uh Norway and China and highly optimized for real-time latency sensitive Communications for decoding we use the open source davit decoder from video land that was adopted by aom and that gives us these uh our implementation gives us about 30 percent uh better compression or 30 percent less bit rate at uh the same complexity or the same CPU consumption as our reference open h.264 codec that we uh publish in lots of other companies use and we've integrated av1 into our WebEx product in WebEx meetings and uh we also implemented it into this custom version of the WebEx app and the server the conferencing server that we created for this project Calista so what were the challenges and solutions at the video Codec bitstream level that we had to solve so first of all it had to have great quality or at least good quality at extremely low bit rate 160 kilobits per second and to solve that av1 itself has inherently uh in it you know lots of tools and techniques for getting pretty decent"
  },
  {
    "startTime": "00:14:01",
    "text": "quality at very low bit rates like quad tree super blocks and context adaptive entropy coding and various other techniques so we employed all of those Second Challenge is the huge uh latency up to 10 seconds in each Direction so obviously uh packet loss requesting a keyframe uh is not going to work so we just simply ignore keyframe requests and we generate keyframes periodically um and then there's packet loss so we implemented normally uh and I really enjoyed Luke's presentation earlier about quick over media uh so if you guys attended that this morning then you remember the IPP or IP BP you know Gob structure that Luke talked about so we implemented a a broadcast like Gap structure with discardable P frames and uh to make it more resilient to pacalas and then the problem of keyframes being traditionally very large and subject to being just uh corrupted by packet loss in in transit we downscale have to half the resolution then encode and then upscale on the other end when we decode and and we also allow the quality to kind of build up over several frames if there's not a lot of motion in the video and the server and the app switch between normal mode and this error resilient mode described on the right hand side of the slide based on the frequency of IDR requests so if we start getting IDR requests we switch into this resilient mode and then we switch back out of it to try to increase quality when IDR requests are not coming through so we ignore them but we still get them and we switch into this mode when as needed so uh lastly I'll just say that um the no touching and no audio interface the"
  },
  {
    "startTime": "00:16:02",
    "text": "solution to that was a custom like MDM like uh thing that's sort of like just a URL that says you know push this URL to the to the OS and it will launch the app and then we just automatically join a predetermined meeting URI so that's how we solve the the no interaction problem and I just wanted to close with giving credit to my colleagues who contributed to this I was the director of engineering at the time uh and Thomas and Dimitri and Alex on our team worked on this together with many other uh Engineers uh at Cisco and our colleagues at Lockheed Martin so just wanted to say thanks to all of them for making this reality fingers crossed this thing Launches on November 16th thank you for having me [Applause] the queues are open so if you can please use the tool I realized it was a little bit hard for people uh because the because of the URL uh problem on the agenda um but uh if you if you can't get into the tool you can get in line and we'll recognize you anyway but uh if you could use the tool to to form a queue that'd be great uh Darren Dukes your first yeah um so what was that what was that user experience at 10 second delay you know in One Direction is that going to be a usable thing for when you tried it in the labs we did yeah that's a good question it is you know to be honest it's a bit of a walkie-talkie kind of mode um you certainly can't interrupt each other uh like you can on a normal video conference uh even in normal video conferencing interrupting is you know you can accidentally step on each other because of the end latency here that's"
  },
  {
    "startTime": "00:18:01",
    "text": "just exacerbated right that you really need to kind of wait and let them finish talking and uh before you try to speak over them um but other than that it works great and the uh it's not just video but it's also real-time whiteboarding and and content sharing I should have mentioned that in the presentation so imagine you know we could draw together it would take a while for what you've drawn to show up for me and what I've drawn to show for you but it works but so in those space movies where they've got you know something's gone wrong and the engineering team's figuring it out they could like whiteboard the solution exactly in somewhat slow real time exactly all right thanks thanks uh I'm sure yeah uh I think that uh you you choose the uh av1 over H2 264 is because it's very efficient right yes yeah but H2 uh 265 is also very efficient so what's the benefit between everyone and yeah yeah I think from our perspective and I don't know that everyone in the industry shares this perspective but from our perspective at Cisco uh the challenge with h.265 is the patent um okay uh challenge right so for us ab1 is is open source and free to use and uh so it makes sense even if they're roughly equivalent technically thank you Jonathan yeah I can't I've tried a million times and I can't get on the on-site queue so I apologize Jonathan Rosenberg super happy to see this this is awesome um normally there's a trade-off for video encoding between computational complexity and bandwidth uh and so to get the bandwidth down you know you could do a lot more work on the encoder side did you also have computational constraints but it's computational complexity leads to I guess weight or power or something that are all considerations in the moon so what what's the compute environment here"
  },
  {
    "startTime": "00:20:00",
    "text": "uh that's a good question I don't know the details of the Apple iPad uh because it's a it's an Apple iPad mounted inside oh I missed that it's literally an iPad it's literally an iPad Pro I thought there was something then then I withdraw my question thank you laughs yeah it's a it's a very customized version of our IOS app running on uh Darren uh yeah so just uh just maybe um one more with with the uh protocol that you'd invented the the UDP based one to get to the spacecraft uh do you see are there any advantages to that did you did you kind of discover anything interesting with having to come up with that is it usable outside of this use case uh that's a great question actually I guess from our perspective we didn't think that it was usable outside of this very constrained use case because you know we basically are doing you know we disabled srtp we disabled TLS you know so not the kind of thing we would normally recommend you know customers to do um so it was very like purpose Built For This closed Network system where confidentiality and and data integrity and all that are less of a concern okay and it just there was a previous uh group above that was in where we were talking about you know low power stuff and you know uh it's particularly um things that were time sensitive as to how much bandwidth was available and whatnot it'd be kind of interesting if you were to build up from what you got to with that and minimally add back to it what you'd end up with that could be very low bandwidth but still have that high quality in order to reach those kind of rural areas yeah maybe on the"
  },
  {
    "startTime": "00:22:00",
    "text": "moon but yeah it made me feel like the moon so it's an interesting question yeah yeah because I do think that there's a huge opportunity there and like you know remote farming communities or or other places where you're yeah near Earth orbit satellite networks and being able to do really low round trip transmission yeah Communications yeah yeah I'm from more Northern ish Canada not very Northern Canada but uh yeah once you get outside of the cell ranges right there's not a lot of bandwidth right yeah thanks okay Alyssa um hi Alyssa hey nice to see you good to see you thanks uh can you talk a little bit about the the limitations in terms of the features and conferencing like could you have two people on the ground joining a conference with the moon like like in terms of our normal typical experience of video conferencing like what's available in this context versus what we are accustomed to is terrestrial users of WebEx I love that you ask that question because I should have mentioned it on the slide because I lost the build I kind of maybe missed some points um so on the ground they have normal WebEx devices and like our board and our room systems and our desktop systems like the um uh The Desk Pro for example and they're they're all connected in a conference with the Orion uh spacecraft right so they can all have a you know be having a real-time meeting and the application that I believe NASA wants to use it for is to invite you know students kids other people from the public into their Ground Control uh facility to experience this and actually collaborate with astronauts which is pretty cool yeah that's awesome thanks Juan Carlos"
  },
  {
    "startTime": "00:24:12",
    "text": "yeah so I was curious because this is definitely very interesting uh first use case and looking into the future uh we probably will face situations where we will not have line of sight right because this is the first time to the Moon the yeah that's right around the back side go around and even further into the future right you can think of Mars and that's when normally Leo and stuff like that right will come into picture when so that we can work when there are situations when there's no line of sight in which cases most likely there will be satellite relays right so have you thought or do you have any idea in this case you showed that architecture showing the proxy how you simplify the the signaling uh onto the space station but uh if ever we put more relays or an Leo satellite network with that also work or have you guys thought about that multi-hop architecture that is a really good question and and we didn't because we didn't actually have a lot of detail from NASA about the in in trick you know the the inside details of how their network works but it is a satellite relay-based Network which is why the latencies are up to 20 seconds because the average distance from the Earth to the Moon is much less than 20 seconds it's like three but they said you need to engineer for up to 20 seconds and that's because it's going to be bouncing off these satellites when it's like on around the back side of the moon it has to hit a satellite before it comes to the Earth and so forth so but I I'm not as familiar with the you know the underlying details of how that satellite network works and what we could do to optimize it further so okay so there is already multiple release yeah extraordination release it goes from their near-earth uh satellite Network to"
  },
  {
    "startTime": "00:26:00",
    "text": "their deep space satellite Network as as it as it goes out even further away to the Moon I think it switches to their deep space Network but you don't know how many hops to to I don't know how many hops okay no yeah yeah thank you you just joke what you just answered my question because I was curious how the 20 seconds do come into place how they would decompose given the architecture you showed in the beginning yeah so so it's it's multiple realize they are further out and and Bridge large distances and there's just no one not an easy shortest path yeah exactly okay would there be any details on that available at some point Sorry would there be any details on that structure available at some point that just let's just be curious yeah we're super curious too those details would have to come from Lockheed and from NASA we were asked not to I mean they didn't share it was sort of like they shared with us what we needed to know and and nothing more okay understood and I had to get permission to to give this presentation because even this amount of detail is more than we had previously disclosed in our uh you know respective marketing announcements and stuff so I had to go to them and ask for permission to share this with you all right cool thanks yeah oh yeah duncs like maybe you know when your comment about that tells me you know and someone asked my customers you mentioned you disabled all the TLs and srtp was that just for practicality or was that a policy like you know we want you know people on the ground other people on the ground people to watch it live or no is they uh that's a good question the disabling of TLS was for practical reason you know to eliminate around multiple round trips and eliminate TCP and go with UDP um but for srtp that was simply a convenience thing that's like well we don't need it it's an enclosed almost like a closed circuit television kind of network you know it's not connected to the internet at all uh they're only wondering and if you had any thought maybe this isn't directly what you're working on we had any thoughts"
  },
  {
    "startTime": "00:28:00",
    "text": "like if you did need to encrypt it how would you do keying when you have a 20 second latency yeah exactly and like rollover counters and stuff like that come into play right did you have any thoughts about that or just you turned it off yeah we just no we didn't think through that very hard we're just like oh we don't need srtp we'll just disable it and then so therefore we didn't have to worry about rollover counters you know so so we'll point out that if we were doing this super quick you could do uh zero rtt resumption if you started the sessions before they left the Earth that then you'd always just be resuming something that you already had um uh set up with the tickets anyway um oh uh sorry something's wrong with the um the in-room tools not letting a lot of people in so uh yeah if I wasn't clear about that if you can't get into the tool you can get in line and we'll just recognize you from the line sorry about that so um mosinati um just wondering if uh so this was obviously for Converse or for human to human use but I assume that there's a lot of video you know from you know Telemetry systems coming back and maybe even you know robotic control that's you know delayed in a lot of autonomous within 20 seconds but maybe human controlled beyond that is this is some next steps to maybe think about broadening this to use this core real-time uh communication technology to go across all the video feeds all the or even any sensory feeds not just the video but any kind of sensory data that's streaming back to ground stations and then maybe something that has a 20 second you know reaction time that could usefully feedback and and change the sensory systems is there any future work to look at doing something like that I I don't know we had speculated on some things like that too like for example somebody on the ground could say hey um Alexa you know turn the lights on or turn the music up or whatever to the uh to the Alexa that's running in the Orion spacecraft right um and I don't know if this is true at all this is a total rumor but uh I"
  },
  {
    "startTime": "00:30:01",
    "text": "thought that I understood that they also had a GoPro mounted inside the spacecraft pointing at the iPad so that from the ground they could see what's being displayed on the iPad so there are other systems and then I don't know about the actual spacecraft itself and all of the Telemetry and instrumentation and all of that on the spacecraft itself I have known but this was a human to human intent intended communication right okay um while you were talking I I wondered I know some of these uh WebEx and things have the ability to do um closed caption real time do you use the closed captioning in real time did you try doing that because I think that'd be quite useful because of the time delay being able to refer to the text so that that's a fantastic question and there's a challenge with that which I can't speak to authoritatively because I'm not uh on the Amazon Alexa team but they had the same challenge as uh you know normally the device is able to interpret the Wake word so but then all of the actual um you know automatic speech recognition and all of that stuff is done back in in the cloud well this system is a closed system there is no Cloud there is no back end so they had to build a custom version my understanding is Amazon had to build a custom version of Alexa to do a lot of that locally and we would have the same problem within the WebEx app is for real-time closed captioning and real-time translation we rely on back-end systems to do all of that ASR and text-to-speech and natural language processing NLP and so forth uh all of that would have to be built into the app itself or into the server on the ground and not connected to the internet and you know it's all of those dependencies would be the challenge that we would need to solve yeah maybe in the future Mission they'll ask"
  },
  {
    "startTime": "00:32:00",
    "text": "us to to work on that foreign so um I'll take a moment then to thank you again and I have to say uh I'm going to reveal myself as very oh there's somebody coming to the queue now just just speak no worries okay sorry um I just had a quick thought you said that the terrestrial WebEx clients were just normal ones right so did you ever think about um relaying the cloud processing through those so that you can do all the captioning of those kinds of extra Services because those aren't in the closed Network only I imagine they're kind of fuel honed so they are on the closed Network my understanding so I think the entire system is not connected to the internet is what I was led to understand oh uh so I think it would still be a challenge too but but yeah if you could you know if those could be dual interfaced with one leg and the NASA Network and another leg connected to the public internet then absolutely we could do something like that yeah yeah excuse me okay all right I can't remember whether it was in your slides but do you sort of took a FEC for uh some of your Transmissions because it seems like a kind of useful thing you're right you can't do arq for yeah you're right that's a very good question and and we should have we did not use FEC just for this simple fact that we didn't implement it in that custom version of the app but you're right in normal WebEx we absolutely use FEC and we also use now RTX re-transmission uh and in combination so like we can dynamically switch between forward or correction and RTX free transmission and we can protect"
  },
  {
    "startTime": "00:34:01",
    "text": "the RTX packets so that the re-transmissions have a higher chance of getting through but we didn't have all of that in this custom version of the app so um but yeah maybe a future version of it if if NASA asks us to be a part of Artemis 2 or Artemis 3 maybe we'll do that because you're right effect would definitely be useful I guess sort of to drive that potentially when it might be useful to understand what's all lost patents are around the um transmissions and what drives those whether it's solar storms or uh weather yeah or some other kind of space weather that then you could maybe alter the level of FEC that you're using depending on whether there's a sunspot or something like that yeah yeah you're right yeah okay okay uh so let me let me say thank you and let me also say uh this is a wonderful Blast from the Past for me my very first ietf I was here is a representative of a contractor to NASA um helping out with uh the very very early days of the web so uh seeing this work come here uh and get talked about picking up some of the work that was done here in webrtc uh some of the work that many of the companies here have contributed to an av1 and AO media it's really great um to see how far we've come and how close it looks like uh the experience they'll have and Artemis two and three when they become crude missions uh to what we can give our customers so that's great thank you very much for coming thank you Ted all right that was great thank you very much well it's been a long time since I've"
  },
  {
    "startTime": "00:36:01",
    "text": "had to fight with lawyers"
  }
]
