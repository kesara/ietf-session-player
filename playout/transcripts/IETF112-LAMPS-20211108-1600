[
  {
    "startTime": "00:00:05",
    "text": "michael uh yes i posted them do you not see them i i just i hadn't had a chance to look i just wasn't sure you on the same time zone as me might not have seen them either i saw them during the first session i think it posted them okay let's go ahead and get started by my clock we're at the top of the hour so uh welcome to lamps this uh is the last session for today uh at the virtual itf meeting and remind you of the note well these are your obligations if you want to contribute please make sure that you've reviewed this and i want to highlight on the next slide the bcp54 the code of conduct remember that we're here to work on standards for the global internet that means a diverse technical and environment and operational environment and we're going to do that being courteous and respectful to each other we're going to have impersonal as opposed to bullying or attacking attacks rather focus on the technical issues and please be prepared to contribute to the ongoing work of the group so that we can reach consensus and get done"
  },
  {
    "startTime": "00:02:02",
    "text": "so the agenda for today um is pretty full um so let's make sure that we be concise where and focused this is the first slide of the agenda here's the second one so the first question is are there any agenda bashes okay hearing none um we'll turn to the status of the documents that are uh with the rc editor or the isg the first one is lamps rfc 7299 update this is in the rfc editors queue there's uh really nothing to report here therefore no slides the um it is really just registering two object identifiers and uh by the way that has already happened ayanna assigned them and um pointing to this document that is in the rc editor's queue so we'll probably see an rfc out of that in a month or so we're now ready to go to the cmp algorithms update and i think hendrick if you'd come to the mic i'll share the slides hi everybody so this is the cnp rfcs or 2b rfcs i splitted my slide deck into two because this draft is already advanced little bit so next slide please"
  },
  {
    "startTime": "00:04:01",
    "text": "what happened since last itf we fixed some minor formatting nets the document proceeds to working group last call rus provided his feedback and also roman provided an area director review thanks to that i think we discussed or tackled most of the comments from roman on the list i will have some slides on section 7 which may need some some little more discussion next slide please so section 7 what is it about the introduction to section 7 provides some general guidelines for implementers on how to choose a set of algorithms we advance the text a little bit and on the next slides i will propose also an additional table to yeah explain what an balanced set of algorithms would be section 7.1 updates rfc 4210 appendix d2 which is an algorithm's use profile with a set of mandatory to implement algorithms for the pki management operations specified in appendix d and e of rfc 4210 these pki management operations focus on managing person certificates that was the main focus back in that time for example the initialization"
  },
  {
    "startTime": "00:06:00",
    "text": "request requests for a signature certificate and an encryption certificate where the encryption certificate could be supported with a centrally generated private key and these profiles use encrypted value even though we proposed to switch to envelope data for providing centrally generated keys we thought that for these profiles for backward compatibility it it it is okay to stick to encrypted value here um and therefore the section 7.1 uses the algorithm identifiers also used in these appendixes and are also focusing on usage with encrypted value as one types section 7.2 uses our lists the algorithm identifiers [Music] provided or are introduced in lightwide cmp profile lightweight cmp profile utilizes envelope data for transferring centrally generated keys and section 7.4 does not specify any mandatory algorithm sets but just explains for which algorithm identifiers which kind of algorithms from this document could be used that was kind of decision we took last itf having that said for this introduction next slide please"
  },
  {
    "startTime": "00:08:02",
    "text": "ah sorry one step back in rfc 4210 appendix d2 in this mandatory in this algorithm use set for from rfc 4210 some outdated algorithms are listed and in section 7.1 we will we propose to deprecate use of some of these algorithms specified in in 4210 especially md5 and char-1 should be deprecated dsa i think is not really a good choice if you look for interoperable implementations that is also something said in sp 800-57 part 3. therefore we would also propose to to deprecate that rsc rc5 and cast 128 should also be deprecated from our point of view as well as triple des even though usage with three keys it is already deprecated as of nist sp 800 131 a with regard to password-based max we do not deprecate it as it is yes specifically introduced in crmf and used in cmp quite widely and we just introduced this year an alternative pb mach 1 in the update rus provided to crmf"
  },
  {
    "startTime": "00:10:00",
    "text": "and therefore we keep it or propose to keep it as an option but state that it is recommended to use pbmek1 are there any comments on on this slide on deprecating algorithms yeah sean please great good job let's do it okay thanks okay and next slide please this is the in the updated introduction um of section seven so roman um [Music] um commented that the current section seven introduction was too brief and not clear enough we worked on that and i even provided some some further update so in this introduction we said okay the first yeah first argument for for cryptographic strength is the algorithm and key size or key strengths of the keys and certificates that are to be managed using cmp and all other algorithms used in this pki management operation should be at least as strong as those keys that are managed finally of course the algorithm set is as strong or as weak as the weakest algorithm in in a set of different algorithms then the message protection consists of three different parts so"
  },
  {
    "startTime": "00:12:01",
    "text": "typically cmp protection is either mac based or signature based therefore the [Music] entropy of the shared secret information of course is quite crucial but also the key and algorithms used for signature based protection if central key generation is used then of course the protection of the centrally generated keys is crucial and therefore on the one hand the key management technique and on the other hand the symmetric encryption of a content encryption key or of the private key is is crucial but finally to to avoid to to over consume resources of the devices it is recommended to make use of an algorithm set that is kind of balanced and examples for this i would like to [Music] provide on or give an example on how to provide this on the next slide please so this is a approach we discussed in the group of editors this focuses on the bits of security in the first column and then the key size or algorithm of the keys to be managed in the next column there is cmp protection which is indicated with these two algorithm identifiers the next which is typically signature based or mac based protection the next two columns focus just on central key generation"
  },
  {
    "startTime": "00:14:01",
    "text": "where we have one column on key management techniques and one column of key on key wrapping and symmetric encryption so this could be one um table to add to section seven introduction which kind of points out what um [Music] balanced set of algorithms could mean with regard to cmp usage next slide please this is an alternative proposal looks a little bit leaner maybe is not fully complete but this does not focus on on the parts of cmp pki management operations but on kind of algorithm types and therefore would need to be kind of yeah applied on cmp a usage then so the question from the authors would be what does a group think about adding such a table to section 7 and which table would be preferred roman proposes to take both we could do that of course well i think the table is helpful i think the one that fits best in ascii art is the one that makes the most sense but that that's uh that will be especially i"
  },
  {
    "startTime": "00:16:01",
    "text": "leave it to the editors exactly roman says use svg yes but yeah you still have to end up creating an ascii version at some point uh sean then deb yeah hi i just wanted to echo what russ said i think it's a good idea to to put this in i think this is an entirely sane approach to kind of make it matchy-matchy to line up the bits of security with the algorithm so i i to which one you should include i'll leave that to you okay thanks so unless you can reference something that already has it already laid out in a nice table like that i don't know whether nist has anything like that i don't know whether you have access to anything like that we have references to to nist and to ecrypt which which has some input which we already used there is also some similar approach for i think using names named curves with x509 which we also use but there are some more algorithms we yeah we actually didn't find a proper complete source for such information okay i'm hearing that everybody thinks the table is a good idea and that they leave it to the editors to figure out how to do it okay thanks then we will go ahead and i would propose an update or submit an update of cmp algorithms yeah hopefully by end of this week incorporating the changes the proposed"
  },
  {
    "startTime": "00:18:00",
    "text": "tables and would be happy to to get feedback um yeah also on the tables if there is something we did not catch or specify correctly okay and this is it or maybe there is one next slide i don't know was that something no i think that was it okay thanks okay dkg is there anything to say about samples go ahead can you hear me yes great um there's been a review uh just this past week um from the area directors which identified a few minor textual changes i'm actually um about to reply to that on list uh i don't see any um any concerns but the i think that i think it's moving forward in the larger review space now okay roman go ahead i've clarified the document's in really good shape it's actually an itf last call already okay very good all right so i i saw that there was one uh i don't know error or something in one of the formatting but uh good just good to hear that we're getting more eyes on it okay so the next thing on the agenda is the cmp updates and the single slide deck for that and the"
  },
  {
    "startTime": "00:20:01",
    "text": "lightweight profile okay hendrick you're back so here i am so this is a slide deck on cmp updates and lightweight profile next slide please so what happened since last itf on cmp updates so thanks to john gray's um yeah intense review and very valuable comments and good discussions uh in the last weeks we yeah added into the list of of authors so thanks to john we fixed erratas on 4210 which were on in in the backlog and yeah mainly minor editorial nets we moved as discussed the hash elks field in the third conf message to the end of the structure we added a new crl update retrieved retrieval support message to cmp update so introduced a new general message type finally and due to this containing the relevant input in the request message we also changed the root ca third message where we as of yeah then back then we contained the or transferred the old root ca certificate where we request an update for in the general info field and we switch this to"
  },
  {
    "startTime": "00:22:00",
    "text": "transfer it in the request message in the body of the request message we extended as so as introduced or asked last itf we wanted to extend the polling mechanism in cmp currently 4210 offers polling only for enrollment messages and we had the the requirement to provide also kind of handle delays for all kind of messages and last itf we sketched one approach and we worked on that also with discussion um with with john and proposed um yeah an update on extension of the existing polling mechanism i will give details on the next slide on that so we updated the version handling we shifted some security considerations to [Music] from lightweight profile to cmp updates we yeah edited some nets in the asm1 module and we switched from or re reword it from transport to transfer mainly in the the section 7 section 6 as this is more appropriate when talking about http or co-op next slide please so what else is to do in cmp updates we need to register oids for the new crl update retrieval and as"
  },
  {
    "startTime": "00:24:00",
    "text": "we changed the root ca third update mechanism we would like to to reorder some of the pre-registered oids but i don't know whether this is is possible if not of course we can can stick to the to the ordering as of today but maybe rust we can what do you mean by reorder change the values yeah we have i think six oids registered already and we would kind of rename one and place it in a switch the places with off two but i can mean yeah but what you mean by switch the places if you mean where they appear in the asn1 module that is fine uh change the the the bits that appear on the wire i would object okay i understood so okay we we put this um our proposal for the the ordering of the oids in the in the draft but um if you say changing the values um is no good a good idea then we can can stick to what we have the point of getting the early assignments was to not change the price yeah exactly okay uh i don't want to dwell on that but we have a lot of stuff to go through here okay so next slide please lightweight cmp profile what happened since last itf so mainly we"
  },
  {
    "startTime": "00:26:01",
    "text": "um [Music] specified all that what we prepared in cmp updates in more details and profiled in the lightweight cmp profile we also added references to to sntp csr and brisky ae to the lightwide profile to the introduction main mainly we updated this root ca3 update retrieval mechanism we simplified at one place the sender recipient non-handling together with delayed delivery so with polling we added this new support message on crl update retrieval we generalized this delayed enrollment to a delayed delivery for all kind of messages and also updated with this regard the end entity state machine we updated section 6 a little bit with regard to delayed message transferal and also with the wording topic switching from transport to transfer where appropriate we moved some security considerations as set and we edited some yeah minor topics like capitalizing pki never mind um next slide please this is the approach we specify in the current draft cmp updates and in more detail than the lightweight profile on the left hand side you see how polling works today just for enrollment messages ircr"
  },
  {
    "startTime": "00:28:03",
    "text": "and kur and on the right hand side the updated version it also works for the other message types used in the lightwhite the mechanism is for in an ipcpup message we can have a weighting status in the certificate response body we do not have this in other types of messages but we could send instead an error message which can transfer a status weighting doing so the polling would be initiated for the non-enrollment kind of messages with this error message containing status weighting and then the polling mechanism kind of goes as usual for enrollment the certificate request id in the poll message is the one of the certificate request of course for all other messages it's a minus one as paul certificate request id which is also um available today for for those cases where no certificate request is available in the request message and then the polling mechanism goes as currently also as usual no further changes needed so the only thing we added mainly is to introduce the error message with status waiting to initiate polling for non-enrollment messages any comments on this"
  },
  {
    "startTime": "00:30:00",
    "text": "seems okay to me the next slide please this is mainly what was discussed on the mailing list so um introduction of two new general message types um one the request message providing um a status of a crl which contains an or less a pointer to source and a timestamp of the crl and in the response message then an updated crl or no update if there is no more current more recent crl available next slide please what needs to be done from the text is kind of complete from one feedback from roman we need to do a minor or a little update in section 4.1.6.1 which is the key agreement key management technique for centrally generated keys but that's it for the moment so this is it with a presentation any comments so my big question is does anyone um have concerns with going to working group last call when the author after the authors make the next update okay i'm not hearing anyone so uh let's plan to do that you guys make the the"
  },
  {
    "startTime": "00:32:00",
    "text": "changes that you've talked about uh here on this slide and then we'll do uh the call do you [Music] have a preference for an order or do you want them to go together i think it's best to take cmp updates first finally this is the basis of syntax changes which is then used in the lightwide profile therefore i think this is the best order anyhow all three drafts kind of are interrelated so i would propose not publishing any of the three before review of all three is done just to be sure that if something pops up which has effect on the other drafts we did not publish too early okay that makes sense to me anyone else have comments on these two documents okay then we'll start uh the working group last call after you do one more update yeah thanks great and now we'll go on to the next presentation i think dkg is doing the uh speaking on the header protection i'm not seeing it why not"
  },
  {
    "startTime": "00:34:12",
    "text": "i uploaded the slides but i don't see them let me uh do it this way then uh now okay go ahead hi folks um sorry for being offline for a second there um so the lamps email header protection document has been uh stalled uh next slide please um so uh recap for folks who haven't looked at this in a while um the draft specifies at least two major options um for how to protect headers in signed messages and encrypted messages and it's been unclear how we select from them about what guidance we give for generation for generating encrypted or signed messages um in the last round we propose"
  },
  {
    "startTime": "00:36:00",
    "text": "a list of criteria about specific problems we might see um and uh we got basically no feedback so uh yeah so next slide please this presentation i basically just want to suggest a way to get unstuck um and see if folks have other suggestions for how we might get unstuck um i think one of the things that we've been seeing is that um of the proposals that are specified um any of them will work uh for new clients that all cooperate um and the concerns we've been stumbling over is what happens how protected messages are handled by legacy clients i see bernie in the cube bernie you want to jump up okay just spin on your knives yeah i pretty much agree with the statement uh daniel made and i've been thinking about the way forward which i would like to throw into this discussion not necessarily that i'm fully behind that but to summarize we have no clear we know in a way between the two between the legacy between the wrapped and injected message scheme there is sometimes the interrupt and sometimes they check that the scheme is better so to change the standard this is basically two weak argument if you change the standard two from wrapped to injected in more detailed if you have signed and encrypted the current standard dropped prevails it's overall better than injected and it's easily fixable because it's minor issues basically need to tell the clients to avoid that the use has to open an attachment designed only it looks a bit different there we make the difference between s mine capable and non-smart capable clients in s mime cables clients the two"
  },
  {
    "startTime": "00:38:03",
    "text": "schemes they are more or less equal uh in one you have to open attachment in the autobahn uh is only protected it's only the unprotected subject shown in the injected so this is kind of balance i don't see any kind of prevailing in here for non-smine clients in case you have a client that doesn't understand any mess mime they are not only there and only in the multi-part scheme the injected message scheme has some advantage because you can make in this scheme you can make or reach more let's see more recipients that can actually see what you're right based on that i suggest to discuss about some compromise like which would basically be go on with the current standard which is wrapped not change anything here except clarifying and help fixing those clients that do require showing attachments however to help clients which i just described like legacy clients that don't understand mass mimes allow an option to use the injected message help scheme is multi-part signed for but this for sign only message only the default file would remain wrapped but for this case we would introduce the injected message head scheme i'm not sure that this got a bit clear but i think that could be a way out of this situation and hoping for comments here so uh thank you bernie that's a that's a useful suggestion it would be great to have that in in writing about what we specifically want um you know a proposal about how to move forward there um i i actually have a different set of uh so so my concern about"
  },
  {
    "startTime": "00:40:00",
    "text": "um sticking with the standard as it's as written which is not currently implemented is that people have not been implementing it for some set of reasons and uh one of the reasons i think is that people are afraid of damaging how their messages show up on the other side so i wanted to propose a different in particular to legacy clients and when we say it's easy enough to fix i agree with you that i don't think it's actually these are hard problems to fix in male clients but we haven't seen folks fix them um and so just saying we just need to specify it better is is a troublesome so let me let me the slides actually have a separate proposal about how to evaluate these things that i think might be useful can we take the next um the next slide um and you know i'm hoping to hear some feedback from the rest of the working group about how we do this so this is a proposal this is my proposal for how we think about evaluating these um i think we could in this proposal aim for minimizing any change in experience for legacy clients is a legacy client shouldn't be able to really notice much of a difference between what they're doing right now with regular emails that have no header protection and emails that do have header protection so minimize the change in experience and that means also ignoring any security increase for legacy clients so if a legacy client could get a security increase by doing some additional you know with one of these schemes by doing some additional uh workarounds um or or uh you know interaction with the with the message and that gives you some sort of protections i'm i'm proposing here that we ignore security increases for legacy clients and let me if you go to the next slide let me explain why this is the proposal why i'm proposing this next slide can i drive the slides here there we go"
  },
  {
    "startTime": "00:42:00",
    "text": "okay the rationale is um i want to incentivize clients to adopt this so we want to give clients that can adopt this a reason to adopt it that is give them the security benefit once they've adopted it um and uh and and hopefully this set of decisions will break us out of the existing log jam which is we have a specification nobody's implementing it um we're i think people are rightly concerned about what it will do and so if what we do is we say hey look if you adopt this your messages are going to get through just as likely as they are before and if you implement it on the receiving side um then you get additional your users get additional security benefits so it gives a clear incentive on both sides to adopt and hopefully that would break up the long term um so next slide please uh right so that's the that's my proposal um and we can run down what we think the outcome of that proposal would be i mean i have i have some guesses at it but i think it comes close to some of what bernie is proposing in terms of allowing different mechanisms so so i i think you're partly right but partly it's because the document contains two um approaches that we haven't sent a clear message to the community of what they should be implementing right so uh what i'm referring to is so bernie's bernie's claim earlier when what he just said was this doesn't warrant changing the standard right i think the document takes as a starting point the idea that um i'm forgetting now the number of s mine that said oh yeah here's how you protect headers you just wrap a message um that has been around for a long time even before this document was present"
  },
  {
    "startTime": "00:44:00",
    "text": "and no one adopted it right people had the mechanism to do it and i think people were concerned about doing that um maybe they were just lazy maybe people don't care about the male user agents anymore in which case everything is hopeless uh but maybe they had good reason not to adopt it and the the main reason i could see was the the effect on legacy clients right well the previous one was basically just use uh rc 822 message right encapsulate the whole thing that's right and people didn't do that right very few people actually generate those right and it's i think it was the ui the fact that it looks like a message inside a message but that's uh that's my guess i'm not an implementer i'd love to hear from an implementer that that's my guess as well and that's why i'm proposing that we can reduce that fear by picking a standard that will reduce the what happened like minimize any experience for legacy clients in terms of changes from a non-header protected message bernie right um i'm not don't fully agree with the conclusions here i think clicking having a message in a message that you can click and view is not the issue having a message in a message that you don't see like that you just see gobbling garbage i think this is the issue just to make that clear i think both of those are issues michael michael so we have existing experience here uh with the uh rc 822 message wrapping that mailman does for dmarc right um we've submitted this in the itf lists and some other lists that i've run i've done this and universally um"
  },
  {
    "startTime": "00:46:02",
    "text": "it confuses uh the less technical the user the more they're confused by this so that message attachment really is uh this point a serious non-starter to me for older older clients now if you're going to tell me that that does not apply to latest version of outlook then i say go ahead let's do it um but it's primarily these most vulnerable users that don't seem to understand what's going on we have any implementers who want to share their experience go ahead bernie um what here is missing like the what i said is that it's easily fixable this message in message thing and if we give instructions how to fix that i believe like microsoft outlook could fix that and then we have a big proportion of the clients of the user base that has fixed for this so this really easy thing and if you do this auto scheme the injector scheme it's more difficult to fix or more difficult to implement because the instructions are not anymore so clear straightforward as for the wrap scheme that is currently standardized do we have a anyone from the outlook team who has committed to fixing it i'm concerned about um really like claims are really easy to fix coming from someone who's not working on the client i guess that means no right so so that that i mean claims that things are easy to fix by the implementer is different from claims that are that that something like is actually going to be fixed and um uh and i i tend to agree with"
  },
  {
    "startTime": "00:48:02",
    "text": "michael's concern about um i think you coined the term confuser there but the confused user is a is a risk that people are grappling with so i i recognize that the that um one of the pieces that are in the current so so let me let me let me just outline um a set of ideas that that come from the um the proposal for how we might uh try to break up the log jam here um it looks like we don't have anything that um really addresses the problem of uh for encrypted messages with protected headers that include confidential subject lines um they end up with either an attached message or they end up the the legacy display or the subject line is totally invisible or the legacy display option um doesn't render well on some on some major clients in particular on outlook so none of those proposals actually seem to fix um seem to meet the goals that we laid laid out so you know there's anoth there's another approach which we could do which says um we're going to solve the problem for messages that are text html um where we don't introduce the legacy display we use a wrap message um approach uh sorry not a wrap message but an injected headers approach so there's no additional attachment and we say that html generating male user agents should include a div at the top of the html with a particular attribute that they put the the obscured headers in particular the subject header in that obscured attribute"
  },
  {
    "startTime": "00:50:00",
    "text": "and then a male user agent that's capable of that that's compliant can hide those divs from that they can avoid rendering those divs because they can identify them correctly there's no additional attachment and people who are rendering the message in html form who are in non-compliant clients will actually see the subject in the html rendering so that seems to me to to give as close as we can get to the um the the scheme that's described here which would mean dropping the legacy display proposal um and uh and and minimizing the amount of sort of mime shenanigans that are going on so i'm happy to write that up as a variant of the draft and see what people think but but it looks to me like that might be something that would that would break out the log gem here right we could we could set along wrapped sorry injected headers drop the legacy display proposal and include this variant for the html for html specific messages that would degrade nicely okay bernie then michael so two things um i would again like say confuse the user is in with any proposal we use we are confusing the user in some way and the other thing is what you propose i'm not quite sure i understood it correctly but is this something pretty close to what the pep has implemented as a pep message for mart 1 basically just add on top of the text at the subject line or on top of the html right the subject line so that it's visible by a legacy client this question for clarification yeah that's actually what i was inspired by bernie was early workbench okay then i understand thanks so can i have um"
  },
  {
    "startTime": "00:52:00",
    "text": "um this is the do nothing situation does it result in the rap message is that what i understand the do nothing situation would be that we keep the standards as they currently are which says uh use this wrapped message and no one implements them as far as i can tell which means we give up basically on people actually protecting the headers of their messages so this the sorry i don't mean to do nothing in terms of not protecting the headers i meant not not a con not doing anything to accommodate legacy clients um if if we don't do anything to accommodate legacy clients then any of the proposals that are present in the draft seem plausible but i think that one of the reasons that we're that we're struggling here is because people are afraid to emit messages because of their interactions with legacy clients so so just to be clear these are encrypted messages not just signed ones they're both okay because we don't currently protect headers from either signing or encryption encrypted messages typically have to go to somebody who actually had you have the identities for right or you can't encrypt and so there's a possibility in theory of some negotiation where signed messages go to mailing lists in other places and people that aren't ready and so there's you know a different different analysis that i think matters and if you're signing it then you're not you're not necessarily you're caring about disclosing the subject line because you that's right just signed it okay you might be in care about um um making an integral okay the meeting is on thursday not on wednesday as someone fabricated um and so maybe repeating it is more is is sufficient that's that's that's enough accommodation in the signing case um and it sounds to me like we just shouldn't do anything to accommodate legacy clients in the encrypted case that's that's sort of what i'm thinking"
  },
  {
    "startTime": "00:54:03",
    "text": "so the the injected headers approach suggests that we don't do anything to accommodate legacy clients and the result is that legacy clients will render the message as though it had no subject that's without the legacy display section right the wrapped message situation says we don't do anything to accommodate legacy clients and the result is an encapsulated message which some clients will render one way or the other and i'm a little bit reluctant to say screw all the legacy clients if you're having trouble sending an encrypted email to them you just can't expect that to work at all even though they're running a tool that claims to be s mime compatible because the user will end up with a new with an encapsulated message and then they have to do something to view that message and then when they reply to that encrypt encapsulated message they're not operating in an effective context there are a bunch of situations there that make me pretty nervous right if we say here's how you generate a message and we know that that's going to cause problems and say encrypting replies that strikes me as a as a pretty risky gamble i i i i'm gonna say that i don't care that much about legacy encrypting clients because i they so rare at this point alas um and so let's just move forward on that on the car but you're telling me that in the sign case the user might have an empty subject even if it's signed no i'm not saying that in the signed case i really hate the encapsulated message and in the sign case i really don't want to do that and i am agnostic as an encrypted case for whether or not it's encapsulated or not got it thank you for registering that that just like uh is pretty close to what i proposed that we distinguish between signed and encrypted and we"
  },
  {
    "startTime": "00:56:00",
    "text": "would allow something to make the signed case legacy clients better and in the encrypted we just go forward with the much easier case as currently standardized if understood correctly okay what i think we need to do is see this written up and i think the easiest way to do that is probably just to modify the header protection draft to implement the the choice you're picking here and then we can do a last call and see if we get agreement i did have a commitment from a manager at microsoft that they would pay attention to the last calls so hopefully we'll get their feedback at that point okay sorry go ahead bernie i was just i wasn't clear if we have like a consensus here already i'm not too sure about this i'm not either um and bernie maybe what should happen is you and i and maybe alexei if he's willing to join in should have a meeting sometime next week to to just to look at some proposed changes and see whether we can agree that those are worth putting up as last call we won't find out the consensus until we've given a concrete proposal i think to the group i think that's the case okay dkg you want to say a few words about mail guidance the meeting's already half over so we need to pick up the pace yep sorry little to report on the end-to-end encrypted uh mail guidance draft uh there's a bunch of fixmes in the draft i'd love to hear some suggestions um from other implementers about things that they've noticed or things that they've read in the draft that they think are wrong we've been pretty much stalled since the last ietf i hope to get it installed"
  },
  {
    "startTime": "00:58:01",
    "text": "participation would be great okay thank you uh so that's a plea for review uh yes it is okay and contributions yep all right sean i think you're next hello um i want to start off with a uh an apology for uh publishing this document last night super late um but i would like to thank you all for getting up super early and reading it already um i'd like to note that my co-authors are actually online here they're here and so they should feel free to jump in if they have anything to add um so this is just a kind of an update of what what uh happened with our document signing eku draft next slide so basically what we've done is we've made changes to the draft based on um either direct or implied comments that we received on the list um before so the first thing we did was we clarified what it what you know document signing is um mostly to address the concern that the definition wasn't technical enough and it's basically just adding more words around what it means for uh you know the document is digitally signed contents that are consumed by humans you know that as opposed to them being uh just processed by machines um we added a new section with uh lots of new text to address concerns that the handling process was undefined and to address concerns that an eku as a policy identifier was the was the way to do it so um the way we did it was we basically said um there's an example in there for how to do it uh and it kind of walks through how you would do it and the example is based on the the the um the rfc that russ wrote which is how to um digitally signed"
  },
  {
    "startTime": "01:00:01",
    "text": "internet drafts and so it kind of walks through the you know what you would do it's 12 o'clock sorry about that and um the the basic plan is that um you have the the implementation examined the extended key usage values if there's no restrictions then you know it's happy and it's happy to use it if there are restrictions and it can block it now the way you can implement that is with something that's very similar to the um you know certificate policies constraints and name constraints stuff with the excluded and permitted um eku's um that an art relying party is perfectly happy to implement um to make decisions one way or the other um and then the last set of changes were just to kind of add more text and security considerations about cross protocol attacks and to note that there are really no privacy considerations added as a result of this draft um i know it's kind of quick but uh that's basically it and so the next steps is the working group adoption call um we're getting lots of great comments and so i snarkily uh suggested to my uh co-authors that uh if we keep going at this rate we won't need a working group uh to adopt it because we'll have all the comments addressed and we can just go straight to an ad to do it but um we are actually asking for working group adoption because we believe we've addressed all the outstanding comments at this point and it's a starting point so again if there's things that we've got wrong we're perfectly happy to you know hand over editing and move forward so i guess that's where we stand thanks does anyone um who's here i noticed the most uh vocal person against this document is not here so we'll take it to the list but does anyone who is here have concerns okay hearing none we will uh revisit the call for adoption on the list yeah russ i just want to make sure that you know we're not i'm not trying to"
  },
  {
    "startTime": "01:02:01",
    "text": "like run past ryan just because he's not here so i appreciate you taking it back to the list okay michael you're up next i'm gonna check my slides if i push the right button here you're doing it all right yeah if i could find them there they are in front of my mouse instead of in my head there we go uh okay so this is about a new document rfc uh which is esp and this vfr attribute part next uh slide and we've collected uh three or four offers um and i think maybe a couple other people that have some opinions um so the story so far um 1730 was unclear about the csr attributes um in the brewski and autonomic work in anima we made some assumptions about how they could be used and um to be fair uh mack fritikin was an author of 7030 and of eight 995 and he seemed to think that we were doing it right when we designed it so um i think we had some reason to believe we weren't wrong um and then it was pointed out that it belonged that it did not match the easn one and one was sufficiently complicated that some people said they didn't they wouldn't like partly in that list um we had a virtual interim meeting recordings you can go back and talk about the relationship with the slide and we created the design team uh to do some work next slide please and this is really the short of the proposal at this point um that's actually not yet in the document um there's been a long thread of muskin uh among the document authors which has not quite made it to the mailing list for i don't want to copy people's"
  },
  {
    "startTime": "01:04:00",
    "text": "private emails to the mailing list um hoping that they will start again on a list um but the short of it seems to be that one of the proposals is that we essentially have um a very specific uh uh callouts for the values of a couple of things that we need to do and that we're not going to basically allow any arbitrary [Music] attributes and yes bob asks is that a typo yeah it should be a generic name so if it's a name then it can only be a dn but a generic name can be subject alt name as well which is really what we're interested in doing um did i write generic okay so sorry it was you know 11 30 last night at night um and but that's what we have right now um this document is not ready to be adopted um it is very useful to discuss it on the mailing list as to what the goals are and what other people might uh people other people might expect or think that they want to do with it um i don't i'm not sure that i want to have a specific you know here's the part that fixes my problem and everything else is uh screw that i'm not sure that i want to do that but maybe that actually is the simplest uh simplest way to do it it's the least number of things we did conclude that we did not want to break from being backward compatible with what was there um even though most of us the specific use needs are in a somewhat greenfield application so we probably could cope with anything we liked we could even cope with having a negotiation via mime type if we needed to um so i think those are all on the table but it's not clear that we need to do that and i think that's the last slide next slide maybe no yeah that was a discussion here's a squirrel eating tim hortons"
  },
  {
    "startTime": "01:06:00",
    "text": "sean hey um sorry uh that this wasn't clear i think uh maybe would have been better back in the day if we had more people review it um i i guess i'm concerned that you would just take the attribute and modify it i think you'd need to define a new attribute um okay yeah because it's just i think that was what was intended i think that was intended that it would be a new attribute yeah yeah and if you think that there's a new attribute and you want to have specific things to call out because you need them great we'll include them we can use some fancier asn 1 stuff to allow it to be extensible um so there's ways to do this um yeah so i my my attitude is feel free to make the changes that you think are necessary to get this to work with what you need to do i think the question is whether or not we want to have you know a specific thing that here's the name here's the three values that people wanted to to specify and if there are other attributes then that's a future revision uh right versus being able to put any attribute with any value in the in the in the thing which is what i thought we were going to wind up with in the first place and as you say there's some asn 1 that makes it all uh happy i just don't know how to write it i mean yeah you could we could we can find people to help with that but uh including well i i think we have enough enough people in the authors they just i don't think they're here dan's here um i don't think david is here um and uh i don't think the other author uh owen is not here because it's middle of the night for him another alternative uh is to define those three things as attributes and just stick them in yeah oh as new attributes as new attributes or look because there might i didn't look real closely at the options but that that some of those might actually already be attributes buried somewhere next murder right right and that's the part that that"
  },
  {
    "startTime": "01:08:02",
    "text": "where the existing asn one was was uh unclear to non-non-experts we thought we could but uh it turns out that there's no value there isn't a value thing there but it didn't stop me and several other people from uh putting a value in uh because asn was self-describing and we thought we were doing it according to the to what was there um and even interoperating you know pretty much as far as i remember uh we just like yeah we did it the obvious way and the other says well i did it the obvious way and we did it the same way so we could just record that was essentially what we thought we were doing we're just going to record this this uh extension or whatever you want to call it nasa1 so that it's actually clear that that's what we meant um and then these somewhat other proposals are are showing up anyway i'm hoping we'll have that the authors will be less shy about posting the mailing list um and we can have a better conversation sean that you can actually uh uh contribute to so michael like seems to be like you're ready to do one more spin then a call for adoption yeah i think that's about right i think uh um assuming that we can get people to talk uh um that you know somewhere in january i don't think this has to take very long no i should hope you're done in march yeah okay i'm done all right okay sean come up again all right so this is a document i guess that i volunteered to write at the last interim which was about how to put nist's um pqc chem"
  },
  {
    "startTime": "01:10:00",
    "text": "algorithm in a certificate um again i apologize for not getting this draft posted the link there is to a github repo i will have it posted shortly um and since it's not yet in there i don't have any ipr i'm not planning on inserting anything et cetera et cetera et cetera um so the ids contents pretty straightforward i was looking around for drafts to basically follow this on which we've done a couple of these and so i picked rc8410 um i think that's the right one for the ed25519 stuff that drafted the kernel um put the those the the safe curves into curdle and i just basically followed the format so the basic premise is um to put the winners in there um they have an algorithm identifier um that with oids with no parameters um and multiple algorithm identifiers per algorithm to count for parameters that's what i have in there now alternatively we could just use the nist specified oid and then have um another oid for the parameters identify the whatever the parameter choices are like um kyber has like two different or three different sizes i guess there's some others and people can tell me what those would be um then we have to say what uh other bits and certificates would would matter so the keys are the ones that come to mind obviously i think key agreement is the one that we'd include um i put in cipher only into cipher only as maze and then i thought well i don't really know if you do this but i put them in there anyways just to have a think about it um then the format for the subject public key fields and then we went ahead and i added one for a private key format um just to be complete because i think sometimes when we left it out in the past it caused problems and obviously we'd have an asm1 module to kind of wrap this all together for reference purposes for anybody that really wanted to use it and that's really it um and so i'm hoping so i want to challenge your one assumption here that is must be key agreement"
  },
  {
    "startTime": "01:12:00",
    "text": "didn't the rsa kem use key transport oh jeepers you know what i forgot to check on that you might be right i i don't have it on my screen at the moment but that's my recollection i was trying to find it before you finished your presentation that i didn't it's rfc 5990 and it uses key and cipherman i was which is key transport so i think that's the thing to debate uh probably should go to the list yeah absolutely okay um but that's basically the idea so the the option is the real i think the points of discussion are how to to specify this and i think you know whether it's it's one oid um where the oid equals the parameters or whether it's the oid for a generic algorithm plus the the algorithm the parameters being another oid is kind of the the big discussion here yeah i think i like the i like the no parameters approach myself uh mike you're in queue um yeah so um chems don't really fit cleanly right there and they're a new api they're not really a key agreement they're not really a key exchange um we're having the same i'm going to present in a couple slides about getting chems into cms for content encryption we're having the same problem here is is it is it a key agree is it is it is it an exchange should it be its own top level structure uh so maybe this will dove like maybe those two drafts sort of need to sync and there's probably gonna be some others that crop up probably all need to choose a direction and synchronize on it absolutely i think um because your the drop with multiple keys would include the same things and you'd have to"
  },
  {
    "startTime": "01:14:00",
    "text": "indicate the um the usages for those individual keys we we basically have to agree because if you pick one and and you know you have two drafts that pick different things it's like it's like a foot gun that we're firing off for fun yeah okay john yeah how would this um how would this relate to the final new standards would this be the plan to start working on this and not publish before the final standards is done or would this be temporary or ids and then if the final standards are slightly different then there would be new ids would hold sorry go ahead john no i wasn't gonna say it was gonna hold i don't i don't really want to pick any winners yet um you actually look in the github repo it says candidate one and candidate two so i even put the names of the algorithms in there because i don't want to be perceived as picking a winner no but it has been like i i guess the winners will be picked in just a few months if i understand in this schedule but the final standards will take two years or more so well i'm hoping what they'll do is what i'm hoping they'll do is uh publish a list of voids that'll go with that and then we won't have to wait for two years okay okay i think the way forward is shawn to figure out this key agreement thing then post another draft and then we will do a call for adoption thank you for your time okay and by the way i have this red box here"
  },
  {
    "startTime": "01:16:00",
    "text": "so what we did is also extend the score option with a new blank bits and a field called id detail where we practically okay allie i think you're doing the presenting no hi can you hear me hear you just fine all right great um i'm ali um and i'm gonna just be talking about joint work i'm doing with rebecca and daphne who are also here today uh just on like a general framework that we're developing for a post-quantum migration discussion so we're excited to introduce these ideas and hear some feedback uh next slide all right so um once the post quantum key exchange and authentication algorithms are selected and standardized by nist the adoption of these into quantum resistant uh protocols really depend on the progress that we make in integrating these into protocol standards so we know there was a lot of past work put into building these in a crypto agile way so you know it's important to maintain that agility as we move forward and migrate to post quantum framework this idea has led to a lot of recent focus on hybrid designs that use both traditional and post quantum algorithms together and we understand that these designs are useful for interoperability reasons or just transitional purposes during the migration but coming from nsa we feel that hybrid is not necessary for security since we fully trust the vetting process of these algorithms um and we've assessed the needs for national security systems and we really require a solution that allows for a quick transition to just post quantum protocols so we want to focus on"
  },
  {
    "startTime": "01:18:00",
    "text": "post quantum only solutions as the end goal of this migration so we view transition as a hybrid that should or sorry a hybrid as a transition that should allow for an easy move forward to strictly post quantum so a lot of the work so far has focused on using hybrid to ensure backwards compatibility um but we also want to ensure that they allow for forward compatibility and by that i mean the ability for a hybrid system to communicate with systems that prefer to use strictly post quantum or next generation algorithms so if the idea of this forward compatibility is built into the current designs then the transition you won't need a further transition from hybrid to strictly post quantum and this way you not only ensure that your system can interrupt with one that's fully post quantum but you also build in the capability for a protocol to be strictly post quantum right away uh next slide okay so here's just the general definition of hybrid in a very broad sense that we've seen basically the security of a system is not compromised as long as at least one of the component algorithms is secure and then there's several design choices that go along with looking at hybrid for this architecture so again we want to make sure that you can interrupt with non-hybrid aware systems so those that are using strictly traditional algorithms and ones that are using strictly pulse quantum algorithms so that should both of those capabilities should be there if a design is backwards compatible you could should be able to use almost the same framework to make the design forward compatible since in both cases you're just telling the hybrid design hey only use one of these two algorithms so if you design protocols to handle forward compatibility now that minimizes the changes that are necessary for strictly post quantum solutions and again it avoids a further transition down the road from hybrid to post quantum since you've already built it in uh and then we also want to make sure things"
  },
  {
    "startTime": "01:20:00",
    "text": "like we don't want to have these hybrid designs be prohibitively expensive in terms of computational performance and then things like the time to establish a connection between peers should not increase exponentially either so if you look at a few of the working group drafts out there for hybrid methods right now there's a ton of different terminology being used to describe these designs so we've seen dual signatures or combined negotiation algorithm pairs you know multiple key shares things like that but if you break it down there's really mainly two approaches that are gaining traction in the working groups and these choices fall into one of two camps the idea of a non-composite design choice and a composite design choice next slide okay so here's the definitions that we are using for the idea of non-composite and composite and this is really the motivating factor of our talk today so we feel it's really important to define this framework within the general hybrid umbrella as a way to invite a more structured discussion about hybrid designs that allow us to really make the best decisions moving forward into a post quantum so on the left we have a composite design which would be a solution in which the traditional and post-quantum algorithms function together as one entity so that would be for example negotiating a traditional and pq algorithm together as a pair that would be composite and then in contrast to that we have non-composite a solution in which the traditional impulse quantum algorithms function discretely as individual entities so in this case that would be like having two separate certificates one post quantum certificate and one traditional so these ideas show up in a lot of different parts of a protocol though they're not just exclusive to certificates so it's important to sort of introduce this framework in a more general sense but today we're going to talk about it from the concept of authentication so"
  },
  {
    "startTime": "01:22:01",
    "text": "really how a hybrid non-composite authentication method would look and we're working on writing a paper detailing the specifics of this approach and we may want to introduce it as an informational draft to lamps if there's interest next slide okay so here's the basic structure of these two approaches in contrast to the composite design a non-composite authentication is one where we have two separate certificates so one traditional and one post quantum and again we're looking at this under the lens that this is solely for transitional purposes but given that lens we want to use this structure to allow this design to use a forward um transition to strictly post quantum authentication so the biggest difference between these two methods is really that most of the work for non-composite is put into updating the protocol to handle two separate certificates instead of just one so most of the work goes there versus the composite approach however the structure for non-composite of certificate signing and verification doesn't change the protocol just needs to adapt during the process twice once with traditional and once with pq so for the next two slides i'll go over like the pros and cons of each design in the context of our research of how this would look in two different protocols ikev2 and tls 1.3 next slide okay so for composite authentication for this slide we'll consider using a composite signature and composite certificate so as far as deciding which algorithms to use a composite design can really just build on the existing structure of the protocol and avoid having to introduce new protocol logic here so for example in tls you can negotiate the algorithms in a composite way the client can offer a list of pairs of algorithms that it can support together and that can be put right into the existing signature algorithms extension structure and this also builds in the ability to match security levels between"
  },
  {
    "startTime": "01:24:01",
    "text": "algorithms if you're using both simultaneously however there's a few downsides so first you'd have to define new composite voids or or group identifiers to describe the pairs of algorithms together so in essence your protocol really has to support three types of identifiers the traditional hybrid and the pulse quantum again because we're thinking about this as the most straightforward design that allows for the protocol to be forward and backwards compatible um the next point we won't get into too much detail but uh the validation process for composite signatures is different from the validation process for just a single signature um all right then there's some questions regarding deprecation of algorithms so what happens if one algorithm in my composite gets deprecated since it's composite you either need to revoke the entire certificate or revoke the deprecated algorithm and then this opens up questions into how you handle root certificate authorities and start chains so like is the whole chain composite and what happens if one gets deprecated things like that um the last point then is regarding the transition to strictly post quantum systems so if we move forward with composite authentication it's not very straightforward with regards to backwards and forwards compatibility so how do you drop one of the two composites to a non-hybrid aware system and it's really important to maintain that interoperability when we're going to backwards and forwards to just pulse quantum so essentially the hybrid composite approach requires implementations to possibly face another entire transition period from the hybrid period into just the post quantum period and we'd really like to avoid that and use the hybrid as the transition to post quantum next slide so then the opposite of that would be the non-composite approach that we're looking at so there's several differences here from composite so first the"
  },
  {
    "startTime": "01:26:00",
    "text": "computational process for validation doesn't change you just have to do it more than once so this will probably work different for comes and stuff but that would affect the composite design as well um so this does however result in logistical changes at the protocol level so if you think about it ipv2 you'd need like a new node notify payload to be defined in the i guess i init and that would signify support for composite authentication and then sending this payload would indicate that your implementation is going to support two sets of cert requests and authentication insert payloads where one would be for the traditional algorithm and the other one would be for the post quantum algorithm there's a similar story that happens for changes required in tls 1.3 to implement non-composite however in the long run if the goal is a jump forward to strictly post quantum solutions making these logic changes now allows them to be forward compatible and strictly pulls quantum ready right away without a further transition using two separate certificates also makes it quite easy to be compatible with non-hybrid aware entities so the same signature algorithm points are used in a hybrid as they are for a traditional system and a pulse quantum system and then if you have support for one or the other the unsupported certificate just won't be sent right so for example in iv2 only one set of cert requests or an off payloads will be sent that indicates a non-hybrid status for the client so overall this design allows for broader crypto agility since you're really just using the same sets of algorithms and no new set needs to get introduced um also for search chains this is straightforward so the non-composite approach it's really just a matter of a policy update to support more than one because it'll use the same root certificate authorities and the chains are unchanged as well all right next slide uh yeah so we're really just looking to get feedback for this on the list um"
  },
  {
    "startTime": "01:28:02",
    "text": "like i said we have sort of an informational draft uh in the works that gets into the gritty details of how this non-composite authentication design looks and then we have a more technical report where we look at the details of this in the lens of two different protocols but overall we really just want to introduce this hybrid terminology of composite and non-composite into lamps and maybe into ietf as a whole to use this as a framework for post quantum migration and that's all okay uh dkg then joe salloway hi there this is daniel kahn gilmore from the aclu thanks for this presentation uh it's really useful to see the kind of framing that you're talking about i wonder if you have any thoughts about how this would map to your analysis i feel like is very specific to authentication here and i wonder if you have any thoughts about how this maps to key agreement or encryption schemes uh yeah i think that this framework of composite and non-composite can definitely be used for um key exchange as well it's not just for authentication so i think in some of the working groups like tls their hybrid approach right now is a composite using composite negotiation for key exchange as well but you could use this idea of non-composite there too sorry i don't think that tls is doing key exchange right now tls is doing authentication right these are modern tls does signing of the separately diffie-hellman negotiated key agreement oh yeah i was talking about there's a hybrid draft in tls that's uh looking at um for post quantum migration how that would work of the but of the analysis that you presented you seem to have a lot more pros on the non-composite than on the composite i'm wondering whether that analysis applies to whether you think that the analysis you've presented here applies to key"
  },
  {
    "startTime": "01:30:01",
    "text": "agreement schemes in addition to applying to authentication schemes oh um yeah so our our pro con list is mostly looking forward to what structure would make it easier to move to just a post quantum framework so yes this does it was not you know just authentication specific but we were using that as a framework for today's talk yeah okay joe oh yeah so a similar question to daniels i think just to come i think it would be useful to kind of go because i think the key agreement uh hybrid structure is going to be a little bit different than authentication because at the end of the day i think you need to end up with one key or you know some some shared secret so i think there's some differences so i think it would be good to if you think this is going to apply to kieron agreement as well which makes sense that it would uh but i think it would be good to go through some of those pros and cons lists and kind of the analysis specifically thanks scott i've already talked to the tls working group of at least some some people in there and they really uh want to go with non-composites uh signature certificate design because uh basically if you they don't want the bandwidth choose a bandwidth for something for a legacy client which doesn't need these huge post quantum signatures public keys uh the what i'm taking but from that is maybe this is not something that the lamp should decide but it's really something that the working groups need to decide and lamps needs to do maybe needs both options out there beginning to think that myself scott so uh that we need to"
  },
  {
    "startTime": "01:32:01",
    "text": "give both tools to working groups uh to implement or to pick from in their protocol environment um mike a couple of comments uh first scott so i've been viewing the composite stuff as existing within a multi-cert environment so i'm imagining that you'll provision your tls server with an rsa cert and separately an rsa plus pq cert is how i've been imagining this composite would get used and if you're already sending a pq public key slapping an rsa public key into the same object for you know good measure is nothing in terms of bytes on the wire so i've i've i've actually been imagining that composite exists within a multicert framework for exactly the don't send it if you don't need it reason um i don't know what if that's commensurate with the discussions in tls or not um second while i have the mic and i i'm about to present right after this on composite um but ali thank you so much for this framework i think this is really really useful work um comment i'll make so i think i've speaking for myself not for all the authors here but i think i fully agree that for online negotiated protocols ike tls i think i totally agree with your analysis multi-cert gives more negotiation flexibility yada yada i think that's great where we keep getting stuck in our own internal design sessions is the offline protocols code signing s mime those type things where you're you're signing objects or you're encrypting payloads you're just firing them into the void and you have no idea who's going to pick them up that's the cases where we we don't we just haven't found a way to make multi-cert click you know if you get an exe and you're an exe running framework and you're validating the signature on that exe how do you know that there were supposed to be two signatures on it"
  },
  {
    "startTime": "01:34:02",
    "text": "you know how do you how do you prevent that stripping attack in a totally offline non-negotiated so i would love to see your framework also address offline protocols possibly completely separately from online protocols i think that's a good suggestion so i was commenting about eye version 2 i question 2 is actually not defining at all for authentication it's only doing the agreement currently because we see that the authentication is coming coming from us to us from pkx or something like that that we don't we just use the certificate and hope that everything works but in our key agreement when we are doing non-composite method we do separate rounds and each of the round is actually finished before the next one starts and each of them actually updates the keys that are used for the future rounds and the first round is always going to be traditional development and we are not going to be go away from that you know i don't think so and the reason being that it actually provides us quite good security in a way that we actually know that the person we are talking at at that point is going to stay safe so it gives us this kind of continuity uh even i don't think anybody is going to have you know a quantum computer that can break tiffa helman in seconds it would be required to be able to break this kind of you know because three film is only used to protect the next 10 messages or a couple of messages after that there is also one of the things that we have been seeing that people have been complaining about because some of the post quantum methods are the keys are big and we don't want to do that before the authentication or some form of authentication so we have also a way of doing"
  },
  {
    "startTime": "01:36:02",
    "text": "uh we do a couple of rounds you know we might purely filament first then we might do an authentication with traditional you know some method of doing out the case like a preset key and then we could do some more you know post quantum key exchange p agreement methods to actually be written protected by the authentication done by the preset key and the precinct key is actually post component safe provided the preset key comp is itself or ppk is uh strong enough to be protected so so it's it's a little bit different it's not completely non-comp composite and we are never actually probably going away from the original dfa helmet because that's so fast and it only provides the security for the next few exchanges after that yeah i guess i'll just say that these ideas definitely show up in different areas of the protocol so it's not just in authentication um and i know ike v2 has uh you know specific things set up for the intermediate exchange and things like that to handle this um but i still think it's a nice general framework to have when discussing it see that the queue is empty allison and your co-authors thank you i heard a lot of interest in the chat for um a paper so i hope you will do that and uh i heard suggestions that you had a store and forward based protocol to your analysis okay so the last presentation was the one that mike"
  },
  {
    "startTime": "01:38:00",
    "text": "already alluded to on composite and so might come please come to the mic hello okay um aware that i'm the last thing in the day i will try and move quickly i've got a this is sort of a grab bag of different stuff because i'm in we're we're involved in probably six different drafts at this point which i've now got less than 20 minutes to power through so uh go next so sort of two different bags of topics here one i'm going to throw a single slide about the work that i've been doing with the guys at crypto next so that's not composite at all that's just trying to figure out how to how to how to do the pipe the plumbing work to fit a chem into a cms content encryption enveloped data so i can just do a single slide update on how that work is going since it hasn't been to the mailing list yet and then into the meat of composite where we're at updates um ali ellison's presentation was a good load of information so i'm curious to see if any of this shakes out becomes unnecessary wants to be re rewritten given that analysis i think it's you know we don't have any horses in this race we just want to see the technology move on so that's amazing that nsa is stepping up to give guidance here hopefully that will help help to settle some of these design decisions okay next so uh this is a draft primarily authored by ludovic pereira and julian pratt um i'm they didn't sign up for a speaking slot so i'm taking this for them um chems chems are a different structure structurally different from either a key trans or a"
  },
  {
    "startTime": "01:40:02",
    "text": "key agree it's i mean you can sort of convert one into the others you can convert either a key trans or a key agree into a chem pretty straightforwardly but it's slightly different api so it's i like to think of a cam like a diffie-hellman sort of key agreement but there's only a single public key involved so your your sender does not have a public key only the recipient has a public key but otherwise it works the same way you take the public key a shared secret falls out and decipher text falls out so you don't get to choose the content encryption key you're given a shared secret which is a slightly different api so the question here is how do we fit that api in and one approach is to generalize what rsa chem 5990 did they decided to turn it into a key trends and publish a key trends external api and that's the way ludovic and julian's draft currently is written the other option although it's that's the weirdity there is that you need an algorithm id that says actually i'm not a key trans i'm a chem and then you need to see algorithm params which i think has been hissed at already here you need algorithm params on that dummy oid to say actually i'm a chem and actually here's my chem and here's my kdf and here's my keywrap which is a little weird especially i know some other rfcs reference you know allowed encryption algorithms for cms and so now you have a loud encryption algorithm which is the generic chem dummy oid so it's copying what rsa cam's done but it's a little little weird in some places other options are to use the other recipient info which would have content similar to one but probably semantically clearer that this isn't actually a key"
  },
  {
    "startTime": "01:42:01",
    "text": "trends the third option is we define a new top level recipient info called chem recipient info that is basically the recipient info as defined in 4210 as a choice of key trans recipient info key agree recipient info password keck other we'd be adding a sixth element to that list um and so i think we'd have to look carefully at whether that is a backwards compatible change or whether that would require a bump a rev of the the version number of cmp which i think is probably unacceptable for a change this small if we can safely add an element to that choice list then that might be preferable otherwise one or two or a little clue g but probably more backwards compatible um so russ i'm gonna i don't know if we could take a straw poll or a hum or something is the question here is this a significant enough design choice to be worth a full-blown discussion on the list or are these all sort of equivalent and we should just write one up and submit it as an oh well i'd like to make a few observations then if people want we can do a show of uh a straw poll thing the observation i i would share is that the biggest difference between in the cms structuring between key trends and key agree is the single public year two public keys and so given that the kems have one i kind of lean naturally towards let's see if we can use it i don't think we end up necessarily with parameters if we assign oids that say use a particular kem with a particular ke kdf with a particular wrap we end up with a lot of oids that are very specific but no parameters so i don't think"
  },
  {
    "startTime": "01:44:02",
    "text": "picking at that level guarantees the complicated parameter structure those it's a trade-off you can always enroll params into a future exactly and and that's what i uh that's what we've seen in the tls environment them doing more and more because we want to avoid strange parameter interactions so does anybody disagree with that who would like to come to the mic so you're just to be clear you're proposing that key trends with unrolled oids yes that's exactly what i'm proposing your face says you're thinking all sorry joe go ahead she would be is with with respect to calling this key trans does that have any any implications of like well ketrans i usually think of i'm using the public key to do encryption of some sort and and on not all cams you're really doing that does that have any implications further down the line or is this just a naming issue um i think i think the big implication is it has to have one public key can i can i take that russ sure so i've got the core idea of this draft is sort of sketched out on the side there so the idea is you use the chem to derive a shared secret you use the shared secret to derive a kek you use the kek as an aes key to wrap the cek so you are in fact encrypting and i and we've because of that kdf we've kdf out any particulars of the chem you chose"
  },
  {
    "startTime": "01:46:01",
    "text": "so i do think it's actually fair to call this construct on the side of key trans question mark hopes for agreement so i agree i agree it's not key agreement did i say key trans yes but you asked for agreement with your statement john go ahead i was just thinking because i've thought of a lot about this too but i like clean implementations and the fact that there's going to be a lot of can like chem is happening a lot more right like all the pq algorithms a lot of them are are chems and you know rsa obviously has a chem as well so does not having its own recipient info kind of as it kind of alludes it to its own family of algorithms so i think in that way it just seems clear like semantically it seems clear at least in my mind um so yeah i know i know we can make it fit into the the key trends and it has been done but is there an issue for semantics to to just not have its own kim recipient info or is it a big issue with you know we think it would cause incompatibilities if we were to add a new recipient info type so i guess that's that's where my thinking is on that because it's semantically cleaner and it seems to be the way forward with these new algorithms that are coming so hi um yeah i also i i think that um that the other recipient info direction would be better like if we choose key trans recipient info we're kind of locking in that we don't have the flexibility that key agree recipient"
  },
  {
    "startTime": "01:48:00",
    "text": "info had for uh including optional user keying material whereas if we did allow um have a new structure specified by other recipient info we could add that if we wanted it that's a good point the the ukm field uh go ahead sean just not knowing the answer is this leading us down the path of trying to say uh to specify another key usage type in x509 this is what i alluded to during your presentation was the exercise okay you were good so i did i did read the tea leaves all right so i guess my question is how much of a absolute pita is that going to be uh and do we think there's any a chance that that will get implemented in any kind of timely fashion by both um you know cas and relying parties i don't know that we need a different ku but you know which ku we're going to support here i think is relevant all right thanks it's pretty clear to me this is a big enough decision we should take it to the list um i do think opening cms which is a uh full standard does mean that we need to think pretty hard before we do that but if it's the right answer it's the right answer and i hadn't thought about the lack of the ukm field right next slide i think we've got about 10 minutes perfect let's go okay so the back half of my presentation is basically this slide unrolled into sections uh in the interest of time i could probably do it all off this one"
  },
  {
    "startTime": "01:50:00",
    "text": "slide and leave the rest as an exercise to the reader to go find my full slides so this is just sort of an update on where we are so we there's been a lot of work done by our author group here against these lamps milestones that are probably still sufficiently in the future that i don't know that the working group is ready for knitty details maybe question mark so once again i'll present a landscape um i've structurally chosen to break the dual composite hybrid stuff up by keys inserts signatures and encryption i think they are sort of structurally separate so in the keys inserts there's our two drafts composite keys and explicit composite keys i put a nod here to ali's presentation because at time of writing i wasn't sure if it was going to be a concrete proposal or or a framework or but i'm really not aware of any other work in this sphere at the interim it was suggested the interim we had in september it was suggested that explicit if we are going to go with composite public keys explicit pairs of voids is preferable to a generic container and that's consistent with the no params let's unroll everything discussion here today so i think that's well received so we'll probably end up dropping the composite keys draft and go with the explicit composite the asn 1 is turning out to be a bit of a bear we're trying to use the new object class structure so you can just factory out pairs of voids super easily but we're really struggling with some of the details there could you flip forward one thank you um we have a plan to still support generic so if you need something that doesn't have an explicit oid although maybe that's not a use case we should care about but if that if that is"
  },
  {
    "startTime": "01:52:00",
    "text": "a use case you want to use a pair that doesn't have a defined oid we we could register an oid for pkne with any which would still which would be an explicit pair but open if that nomenclature makes any sense so there's there is still possible to make a generic uh oid within the explicit framework um yeah the bottom half of the slide is well covered by ellie's presentation um yeah don't do that all right point taken um yeah well i guess we'll have to see how much if there's interest in generic at all or we think it's you know do people need to go off-roading outside of the established pair of pairwise oids you know do we need a generic at all or is it fine to put up fences on that road you must use the established pairs of voids any with foot gun yeah fair enough okay um interest of time signatures haven't really done any major work on this in a while i think it's sitting fairly mature we do have some design decisions that will bring up if and when the working group adopts this but it hasn't really been worth chatter on the mail list yet um we also can make this explicit currently it's a generic structure we can also come up with the sn1 modules that allow you to define explicit pairs of essays signature algorithms i will point out that if if we decide to go multi-cert and we need a way to stuff a multi-cert single signature so if you have multiple certificates generating a single signature you're still going to need a container of some format and so we believe this work is still relevant even in a multi-cert world unless protocols really do want to"
  },
  {
    "startTime": "01:54:02",
    "text": "carry a second signature field everywhere so we again my choice to present this as separate from the public keys is because i think this survives a multi-cert draft or is still useful in combat in comparison with a multi-cert draft mike i agree with you in some environments but not cms right because sine data allows multi signatures yeah that's a nuanced because sine data sometimes implies that that's an or relationship there's there's already a document that provides an attribute whether it's an order and that's right that's a yeah right right okay so there is a mechanism we could tie in to clear that ambiguity okay okay uh next um the font's a bit small here so uh the last piece of work we've been doing this is where we've done most of our work in the last six months is composite content encryption for cms how do you how do you say you come across come across a recipient who has multiple public keys again i don't particularly care whether that's in a single cert or that's across multiple certs but you have a recipient who has who declares that if you're going to encrypt for me i'd like you to use multiple public keys to do it what does that envelope data look like we've put out an 0 this is i think we proposed three completely different mechanisms in that oo draft we're still working on that quite heavily i think we've found a way to combine all of them nicely together into one max single mechanism we're debating here also the key trends versus chem debate what is the external interface that this should expose this is probably going to couple into ludovic's draft will probably make"
  },
  {
    "startTime": "01:56:00",
    "text": "composite encryption a expose a chem type and then it'll fit into what whatever ludovic comes up with um although you could also imagine it exposing a key trends and it can go straight into key transverse up info where all there's also debate over what the underlying mechanism should be and how that should function should it be sort of based on a one-time pad xor for wrapping the cek or should we throw in an aes key keywrap layer uh that decision sort of will dictate the key trends versus chem decision uh so this one's still it's an oo but it's it's still and there's still a lot of design decisions to be made here and that's the end of my slide deck with a whopping four minutes for discussion and wrap-up anyone want to come to the bike john i'm just gonna add to what mike said he mentioned the um the composite chem so we're actually thinking about um creating a new draft just for composite kim construction because we as part of our debates for the um what he was just talking about composite encryption we came up with the idea that perhaps it's just simpler to have a composite construction and then if if there was such a thing as like a cam recipient info or just you know a chem usage type it just fits in there much better and it seems simpler so you might see us request um you know a zero zero draft for a composite kim because i think it'll be a yeah i think that's it's separate enough that it would um be worthy of its own draft so i just wanted to point that out i guess stated i'm not scaring my i guess this is stated differently what john just said if if the composite cam draft is already going to define how you do the kdfing in"
  },
  {
    "startTime": "01:58:01",
    "text": "the aes wrapping then great we can just provide the chem part all right uh given that we're down to two minutes anything else as always direction here would be lovely i feel like we're trying to solve these problems with very little input yeah i think i think that you should start a few threads uh you know on the higher order uh design decisions and maybe see where they take you and then we'll see where we when we get to a point where we can adopt a document after having a few of those design level discussions does that make sense yeah and one one of those discussions is the one you alluded to is any of this work necessary do we have use cases that we're going to want composite and dual atomic structures exactly is actually a question i don't know the answer to if if so we've got one but is anyone going to use it question okay well so this has been a very interesting and diverse session so thank you all of the presenters and we made a whole bunch of uh action items thank you deb for taking the minutes appreciate it and so i think this is the last session of the day thank you all and we'll see you next time and we'll see you on the list we have a few things to deal with on the list like the eku document"
  },
  {
    "startTime": "02:00:00",
    "text": "uh immediately so thank you be well [Music]"
  }
]
