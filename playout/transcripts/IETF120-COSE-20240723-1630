[
  {
    "startTime": "00:00:00",
    "text": "you It's very important Hi think so. Yeah to have here? I think so. Although I've lost my window in which I joined so that would be good to find that First time about it Shit Okay, I'm just going to exit all my windows Let's start over Thank you Lowering them It's called expanded I would really like Thank you really could use yeah, he really could use a a right so let's begin, so let's begin are at time, so let's begin. Welcome to the Cozai Working Group session on Tuesday I'm Mike Jones, my co-chair Evo, is also with us for"
  },
  {
    "startTime": "00:02:00",
    "text": "virtually. Hi, Evo So the note well, you should be familiar with All of you in the room please join the light client on me Meetecho, which you can do from the agenda that will record your attendance Failing that, you can use the QR code but we want you to use the client so that you can queue for being in the microphone line and other things So there's the agenda which I'm sure you found or you wouldn't be here Meadowacken information information First request of the room I need one or more note takers to type into the collaborative meeting notes tool, the link of which is both in the agenda and on the screen michael richardson, a man of my men, a hero in the room A person among persons is anybody willing to tag team with Michael? Just make sure that you're fixed his mistakes, okay? Oh. Oh, that Anybody willing to find out Justin, can you correct? Michael? Sometimes, but I've got others. Okay"
  },
  {
    "startTime": "00:04:00",
    "text": "Okay. I see also Christian will be helping. He wrote on me chat. Oh, thank you And thank you, Eva, for monitoring the chat. That would be good So, content from your chair We have two new, our RFCs, yay The type header parameter is done. 95, 97 95-96 and the CWT claims in headers is done 9597 Then, we've also submitted the because I see key thumbprint for publication Yay! Honest breaks out into cheers. I believe the IANA status is approved And so at this point, I believe we're waiting for AD follow-up by Paul is Paul in the room We are minus our AD race now, but there we go So there's a couple drafts we haven't touched since Brisbane and I just thought I'd call them out. We haven't touched the BLS key representations Before Brisbane, we did update it to use the X uncompressed key representation And in fact, the Jose Jason Webb Proofs were uses that key representation now. There hasn't been a sufficient changes to BBS signatures to"
  },
  {
    "startTime": "00:06:00",
    "text": "warrant touching that I believe my pro-rock will mention this, but we haven't updated the Falcon draft in part because well, I'll let Mike speak to that We have a full agenda You can look at the agenda online but I'm going tom strickx to it for time because otherwise we want get through it. We have a lot of good content Wrong button, not share screen. Let's share slides. With that, let's have hannas come up for one of many times Talk about HPKE Yep, giving a presentation on behalf of the authors listed here. Just a quick summary minor hiccup during the submission, I was in a wrong branch. Submit wrong document, apologies But corrected that version on is fine. I'm going to speak about the changes we made from since the last idea meeting from 7 to 9. Okay, next slide Um, so there are a couple of changes in that document And I think most importantly, we change the way we deal with the context information thanks to contributions from Lauren Previous versions of the document used as indicated above this, meanwhile, famous COSI KDF context structure which was an input to the HPKE, which was then led to the derivation of different keys and that is a parameter and the HBKE info field of one of the API I think the setup API and now we switch to a difference"
  },
  {
    "startTime": "00:08:01",
    "text": "structure. Lauren has created a new one. It's called the recipient structure, which is the name indicates it's used as part of the computation of the recipients field And it then has a consequence takes the promise that are parameters of that structure and include it in the authenticated data so it's works a little different instead of going into the key derivation, it goes into the authenticate data. However, I had a reached out to Paul Vanuarshot and he said both approaches are fine from a security point of view Of course, assuming that you put the same information in there, but the structure allows you to do so It just deals with it in a different way and I'm have an example to illustrate what that means in the next slide, and so I get to that explaining on like the difference in case you haven't followed the discussions on the mailing list. We also changed the terminology. Previously, we were talking about the single layer or two-layer structure our multi-layer structure, and now we call it HBKE direct encryption mode for the case where we see the data to one recipient so there's no recipient structure in the in the payload so it's sort of kind of the optimized version. And then there's the other mode, which is this key encryption mode which is sort of allows you to send encrypted payload to multiple recipients So those are the two modes. We had that for a long time. We just gave them different names. Now we changed the names, not in line before the wholesale works or there may be some further changes here. But it's probably something, if you look at the document editorially, that looks quite different. We also changed that couple of other parts in the document"
  },
  {
    "startTime": "00:10:00",
    "text": "smaller changes or like my minor edits, the initial cyphersweet list was reduced to only include those algorithms that we cared about most. So we asked probably half of them of course there's always the possibility to register new algorithms later when the need arises but we didn't want to stuff too much in there. We also showed the labors, like those are just the representations, so it has no means there we also shortened the labors like those are just the representations so it's so it has no meaning for the on the wire representation but uh it's for readability it's probably better we also changed the name of the key to get it in line with what we have in the course you work It's probably for better readability if you happen to read both documents side by side There was more text for the cozy key representations so we had somebody in time, we added ways to represent those HBKE related keys in the, as a cozy key structure and that there's more text now, and a bunch of other editorial improved So like, if you look at the diff, looks like, a lot of change but so yes here's the here's the thing so the cozy recipient structure that Lawrence came up with is on your left hand side and you see it has it includes the protected header fields, which is the important part here So it's a slightly different construction so in the example on the right hand side what would that what that would mean is the in the protected head field of the recipient structure, which is the one in here here that has one protected header field here in this case named the algorithm. So the algorithm would be included in that recipient structure and thereby protected So that would be, that would be the con"
  },
  {
    "startTime": "00:12:01",
    "text": "the algorithm would be included in that recipient structure and thereby protected, so that would be the context that is bound to that HP HBKEE invocation. So now what we still have to do is like have sort of examples on what other fields we would include in here, so like the sender and the recipient which this example doesn't yet show And in general, because of the change, we have to update the code, the implementation, and we also have to read re-compute the values. So the values that you see in the year, the hexadecimals they are not for like for the ciphertext and so on is not correct, needs to be fixed. And we need to add some more examples but that should be like uncontroversial uncontroversial So I have the impression and hopefully Lawrence to and Ori that we are getting closer to finalization so clean up and so on. But obviously, like we had lots of discussions and a long way to go with this so and as said we need of discussions and a long way to go with this so and as said we still need to be compute the examples so they match actually they are really verifiable and a real example rather than face ones and include some of the parameters in the protected headers. So we accomplish the same what we had with the previous structure but of course you have to literally carry them in there which is from on a positive side it's probably it's easier to um to for a developer because they literally see what is in the header field and that's where they, that's what they use to create the as input today the HBKE invocation versus previously you had to create this structure with values where like, if both sides got them somehow wrong because they got it from some other context, which we didn't specify so there's a potential to break things quite easily so that's where we are"
  },
  {
    "startTime": "00:14:01",
    "text": "Any feedback on this? Yeah, hi, I'm Sophie Schmeek, a cryptographer at Google. You cannot actually protect the algorithm with the algorithm that is doing the protecting That has to come from the public key Like you have to have external confirmation of the algorithm Otherwise, the algorithm, like, as an attacker, I can change the algorithm to, say, none which in Cosei doesn't exist, but like assuming it does, like can change it to some algorithms that I can break. Yeah. And so if the public key doesn't tell me which algorithm is supposed to be used in this topic you're broken. So there's a security problem if you attempt to use the algorithm field in the token itself you need to have the algorithm information must come from some other thing thing Can you go back the slide? You cannot send you it, but the way that you authenticated is by checking that it's the same as in the public key Like you can you can add it to the authenticated data it just doesn't do anything. Right so what is the algorithm that we protect here and this So this, let me so the algorithm we are talking about here this is the protected header field it includes this algorithm and anything that is in this protected header field so in this example, it's just one, this is straight up of the document. So what we would include here, what would be something that is in the structure that we had in this HKD context structure was the body, you, body, we identity That's something we would have to include in here but it's just not an example because, but that those are the identifiers of the endpoints and I believe that's important"
  },
  {
    "startTime": "00:16:01",
    "text": "to include it's not an example but if we stick it in there, it would be included in the protection yeah that's that's the identifier of the endpoint good thing to add in the associated data the algorithm must come from the public key like you can put it in the associated data yeah doesn't hurt. It just doesn't authenticate it Well, we have to put it in there, because for other reasons we can't just leave it out I mean, ideally, like, I know that that ship has sailed and crossed, like, gone around the world by five times by now, but ideally we wouldn't even have this algorithm here. Like this algorithm should be only in the public ever right I happen agree with you. The main thing that we need to point out in the RFC that nobody like you must not rely on this header to determine anything no matter whether it's in the associated data or anything The only thing that we do with this algorithm is to check that it the same as you expect it from the public key otherwise you ignore it. Yeah associated data or anything. The only thing that we do with this algorithm is to check that it's the same as you expect it from the public heat. Otherwise, you ignore it. Humans look at it pretty fun. Yeah Well, I argued with Jim back in the old days in Kosi to not carry this stuff around, but I lost that argument but yeah it is what it is Hi, orie steele. You're correct So in Hosey and Cozy in public key representations, the algorithm is marked optional. So when we when we define new structure, in Hosey and Cozy, we encounter this over and over again One of the main motivations for doing Hosey and Cozy HPK together is so that key represent can have a consistent view of the algorithm that's used with HPKE Even though that's an optional field, at least they can all use a consistent view of the algorithm that's used with HPKE. Even though that's an optional field, at least they can all, you know, you could use a cozy key and you could do hozy HPKE and the algorithm identifier would be that correct one and the same thing in the other direction So the in public key"
  },
  {
    "startTime": "00:18:01",
    "text": "or, you know, or private keys when you're identified the algorithm that that key is supposed to be used sometimes we use the term key restriction for that that property the purpose of registering the algorithms with IONA is so that when a public key contains an algorithm and that publicly key is only supposed to be used with this algorithm that you can look up that algorithm in the Iona registry and you can identify and make sure you trust everything that comes from the association to that algorithm That algorithm is then also shown in the header here So agree with everything you said. Thanks Okay Any other questions? All right. With that, Mike Pro Rock, let's talk about the post-quantum world Thank you chairs, and in particular Mike Jones for letting me talk about the post-quantum world where everything is fuzzy evidently. Now, we're going to talk primarily today about dialects and sphinx plus, but there will be a note about Falcon here, right, because that's definitely a topic so next slide please so quick draft update on dilithium. This is now, of course, way trimmed down from where we started because things are getting better to find elsewhere and we can do things like point out to NIST documentation and say, hey here's this, right? We're now, we've now got two of four we started because things are getting better to find elsewhere. And we can do things like point out to NIST documentation and say, hey, here's this, right? We're now, we've now got 204 to point at. And, you know, did a little bit of cleanup, basically cleaned up, I think, all the I on a cell sections. This doc is in pretty good shape. So I think there's going to be an open question about like probably an editorial pass, you know, take any cleanups and I would"
  },
  {
    "startTime": "00:20:01",
    "text": "defer to the chairs as to when it's ready for working group last call. So that's suck think where that one's at. And I am open to being wrong but that's, uh, that's basically the status there Um, Mike, uh, any, um, two standard questions Who has read the recent draft? Not a lot. So who in the room? or virtually in the room is? willing to volunteer to read the draft? Michael, turn around and so Roy anyone else hannas thank you who has implemented the draft? Mike has ori has has, did they interoperate? Ori, have we done full testing on that yet? Probably will, but have not gotten there yet because things changed parameter-wise, so Okay Okay but have not gotten there yet because things changed parameter-wise, so. Okay. All right Um Um, can die? Thank you so when I was going to say I'm going to ask a question um I'm going dang at next um in this drafts um are we doing the uh the poor uh signature or are we doing the pre-hast version We ought to have two different versions for four these drafts, are we doing the poor signature or are we doing the pre-hats version? We ought to have two different versions for those. That's a great question"
  },
  {
    "startTime": "00:22:01",
    "text": "It's the, it's straight according to 204 we can add additional guidance and this is one of the things that i think is a little bit open is if you go through and look at the lamps draft right they call out the notes around you know hash first then then sign etc. I think we're relying in this draft on the bill built-in, like, hashing internal, right? So, but there's options there. So I think that's why we need working group feedback read it. If you want additions there, please comment on the list so that we can incorporate okay thank you All right sorry sorry still yeah so the word we're, I don't think any of the tests that we have or any of the examples in the draft or pre-hap and all of it's the IPD stuff So, you know, it can it can still all change and part of the concern around moving these documents forward is like we want to make sure that everything's solid before we go forward So as we get ready to start doing testing, we want to make sure that we're testing on the same parameter set So I do think this is a case where it would be really awesome to have some tests and to use the implementation section in the document to refer to implementation. So if you'd like to work on an implementation, of IPD or the other versions, you know, come talk to us and we're happy to add your implementation to the references Can, as a subject matter expect, can you go to the mic for a minute? Yeah, I have a question for you What at what point do you? believe we should have working group last call? are there things we should be doing or not Since we have a result, we have point do you believe we should have working group last call? Are there things we should be doing or not? Since we haven't seen the, um, the final versions of both"
  },
  {
    "startTime": "00:24:01",
    "text": "algorithms, poor signature and rehash signatures So I think, um, it's not a really recommended way to make a final call on a document which it's not done yet so I think we better to be patient and wait for the fifth to be published Thank you. Okay, Mike census chair is we should get more reviews and we should do this things that the reviews say Interop testing would be great and let's keep pressing on That totally works for me. I know we're somewhat waiting on this to come back with, you know, when are we actually finalized? etc so yeah okay thank you great thank you Next slide Similarly, and I did get some good Iiana feedback just prior to IETF 120, kicking off, so there's some editorial and some updates there on the IA get some good Iiona feedback just prior to IETF 120 kicking off, so there's some editorial and some updates there on the Iona sections that I'll be adding this week I my personal sense from like a the next steps here following on the prior conversation is let's just incorporate that. I would ask the chairs we can get some folks to make sure we read uh, because I suspect the usual suspects around post quantum reading but it'd be great to get some extra eyes and it's closely related to dilithium. So if we could uh, some assistance there. I'll ask the same question of the room and the virtual room Who's willing to read this one? Roy again? I know Hannes, really wants to. Do you want to read this one too? Hanas? The deer in the headlights look Okay, thank you"
  },
  {
    "startTime": "00:26:01",
    "text": "excellent and this is now aligned fully with 205 with references out to 205, which is in, IPD. So once that moves out of IPD, then we can read with references out to 205, which is an IPD. So once that moves out of IPD, then we can revisit the last call topic, maybe in Dublin. I don't know, we'll see Next slide, please big questions for the COSE working group Due to personal things, I kind of checked out of work a little bit for a good chunk of last year and kind of plug back in this year But during the course of that, kind of noticed that like, hey, there's not a lot of activity around Falcon at least in my little world right, that I live in, and that's my little world Is anyone in the Cozay working group planning on using Falcon? Or even if we aren't, do we think that that's going to happen? Very happy to do the work. Like we've got to go in and do a little bit of polish and things like that, but it's described working but if no one's going to use it, I would defer to the chairs as to like, what should we do here? But I really kind of want to know from the group, like, is this plan for usage there? are definite use cases, particularly when smaller keys exist and things like that roy williams, I was in a meeting in the hall where somebody from Arm was just talking about using Raise the mic, we can't hear you I was in a meeting in a hall and Falcon came up in the context of memory constrained device, so embedded devices So they did voice a requirement for a viable Falcon implementation But once against its hearsay yeah hearsay that's kind of the hearsay I'm hearing as well, which is kind of like, yes, there's an embedded case We need smaller keys, but I'll defer to the chair Like I am happy to go through Revit, get it as polished as we can I don't know if anyone has heard heads or tails from NIST plans on"
  },
  {
    "startTime": "00:28:01",
    "text": "Falcon Good news, we are working on us and we expect to have a draft sometimes later this year That's the that's what I hope That's what we hope. We work on it. Excellent That is great to hear. So with chairs discretion and feedback, what I will do is probably get the draft back alive with some editorial cleanup and then as soon as we see an IPD or a draft out from NIST, we will rev it to align with that similar to what we've done with Dillithium and, well, MLDSA and SHS now. That makes perfect sense, thanks all. Awesome I think that is it for my slides I was trying to be efficient since we are a little bit packed, and I think defer to the chairs if there's any other next step aside from that which we've covered No, we appreciate you doing the work Thank you so much all Okay, with that, let's move on to Seabor encoded certs So Do I ask you to change slides? So, this is C509 and here are the update We have submitted two new versions The good news is that we have gotten very much comments The bad news then, of course, is that we are not as close to publication as we thought some while ago, but I think this is processing steadily"
  },
  {
    "startTime": "00:30:01",
    "text": "towards publication, being more and more steady Some things we discussed in the past was that we updated the certificate types to not to avoid collision with some early implementations There's been a lot of comments from Le Jun Liao There are bug fixes. Go to the next slide slide So one of the main changes is that the signature algorithm, the position of the signant algorithm has been changed, both in the certificate and the CSR structure. This is to enable more efficient parsing of the structures Then we have removed, added quite recently on the request and then removed the special encoding for pen after doing all the calculations showed up that it was it was a it saved some bite but didn't save it very many bytes due to that you need to have a tag and so on so it was not considered worth it due to the add complexity In this self-science that we have a new value null to save space let's say it's relatively much space and then the certificate according. Next slide so some more updates and the first they remove null option that's only changed to the CDDL it's not to change it first they remove null option that's only a change to the cddl it's not the change this was not allowed before but now we have updated the CDDL to be more strict Then a null option is removed from Key Addent identifier Next, and all the examples has been out updated. Here's the updated C"
  },
  {
    "startTime": "00:32:01",
    "text": "all option is removed from key identifier. Next, and all the examples has been updated. Here's the updated CSR format and there's some more details on challenge password formatting So it's a lot of small changes here and there based on feedback. It's very good to have reviewers really reading the whole and implementing the draft So next slide And here are some pen have reviewers really reading the whole and implementing the draft. So next slide. And here are some pending issues about IP address block certificate QC statement yeah and then here has been discussing how we should handle this mixture of seabor and encodings and their encoding So to be able to support compression of current certificates without specifying everything but also in a good way, enable extensions in the future. And this we are continuing to discussing Please review the drafts and look at this issues if you have any feedback Next slide Happy to report that we have a new software that handles for a long time we have had software example, reference software support X-509 to C-509 Now we have roadways and we have an updated version of that software. It's got quite a lot in the in the specifications, with some shortcomings in in the software doesn't support everything we are discussing that software. It doesn't support everything. We are discussing whether some things that are specified are not sure that it works We would like to see example"
  },
  {
    "startTime": "00:34:01",
    "text": "certificates for things, otherwise something that we are not sure working might be renewed could then be added in a draft later if needed We don't want to specify something that is then ending up not working We would like to test things. Next slide Yeah, that's it We would like even more feedback, of course of the changes, but I think this is moving along steadily but it will be some more round before it's ready for publication We still have open issues Questions? Let's see, given a set of open issues as chair, I would prefer that we find resolutions to the issues and some of the possible feedback from the chat before we do a working group last call. So I would ask the authors to let the chairs and the working group know when you believe all the issues have been addressed Yeah we are so far it has been new coming new new issues we have been fixing a lot of all but it's popping up some new we will let you know when we think we are ready for working group last call All right. Anything else for John? All right. Thank you, John Next, we move on, I believe, to Cozay receipts"
  },
  {
    "startTime": "00:36:16",
    "text": "Hello, I'm orie steele I'm here to present on the Cozy Receipts draft As you can see, this draft was originally titled Cozy Markle Tree Proofs, and I think if you've been coming to IETFs, you've probably heard me stand up here and talk about this draft several times, so I'm hopeful maybe this will be one of the last times that I'll be here to chat next slide please so what are what are these restrictions? You know, why do this work? So they enable COSI to express these proof type for verifiable data structures. What's a very verifiable data structure? It's a term that we've used to generalize the transparency log infrastructure systems like what's used with certificate transparency and that case, it's a binary, you know, Merkel tree with the Shaw-256 hash algorithm, but in general, a verifiable data structure is some data structure that allows you to sort of provide certain kinds of proof So proving that a given series of bytes are in a particular data structure is a useful building block for certificate transparency. It can be a useful building block for selective disclosure schemes So in general, this document is just describing how to put these data structures and proof types in the COSI and CBOR encoding And as you can see here, the primer use cases are, you know, transparency logs in the in Merkel trees, the side inclusion proof is typically what, you know, we call a receipt, and the receipt is sort of the"
  },
  {
    "startTime": "00:38:01",
    "text": "most common proof type that we see floating around but there's also signed consistency proofs which are also called checkpoints in other systems. So you'll see these this technology is sort of a evolving since the original certificate transparency work in particular in software supply chain scenarios in the Go-Lang ecosystem, for example, you'll see these things popping up. Next slide So what do they look like? Here's some seabor extension diagnostic notation This is a typical cozy sign 1 structure and you can see this unprotected header tag 394 includes some receipts and those receipts are encoded the rest of the structures standard cozy sign 1. Next slide So when we look inside of one of those receipts you can see that this is a receipt that is also a Cozy Sign 1. I've got the protected header decoded here and you can see this was signed with ES-256 and that there's this tag 395 with a value of 1. And what this means is that we're using a verifiable data structure That's what tag 395 says And then the one is the RFC 9162, SHA-256 binary and Merkel tree RFC 9162 is the second generation document for certificate transparency, which I think the original one's like 6962 Don't get hung up on the you know, the topic of no one implements RFC 9162. It's the same SHA-256 binding Merkel tree in the unprotected header, you can see this tag 390 with a map and then tag minus 1 for inclusion proof and this this might be a bit confusing like why why have this maps structure in the unprotected header like this"
  },
  {
    "startTime": "00:40:01",
    "text": "So as we looked at the different verifiable data structure, possibilities, we want to plan for the future and we thought that this map structure here could be a good way of handling some of the different possible encodings for proof types we might see in the unprotected header in the future So the minus one is an inclusion proof, but that minus one is associated to the 3951 in the protection header for the Shaw-256 binary Merkel tree So for each verifiable data structure, you kind of you give that verifiable data structure and identify like a one or two or three and then for each verifiable data structure, you count down, you know, minus one, minus two, minus three like a 1 or 2 or 3, and then for each verifiable data structure, you count down, you know, minus 1, minus 2, minus 3 for each of the proof types that that purchase data structure could support. So the shot, Shaw-256 binary Merkel tree, it supports inclusion proofs, minus one, it also supports consistency proofs, those are minus two If we created a new verifiable data structure for the Merkel squared you know, transmitting system that the key transparency folks are looking at, we would give that a different number, maybe like a two or a three and then we would have inclusion proofs, but we'd also have some of the prefix tree proof out algorithms that you see with the other other Merkel proof systems the rest of the data structure here for the inclusion proof is the total size of the transparency log at that time That's the number of leaves at the time at which the proof was created The index of the particular object that we're providing a proof of inclusion for, and then the rest of the inclusion package that's the path from the leaf to the Merkel root And you can see the payload here is null So that forces you"
  },
  {
    "startTime": "00:42:01",
    "text": "as an implementer to recompute the payload in order to verify the signature and that's a design part of the design process for this particular system is to try and avoid a scenario where you might verify the signature and verify the inclusion proof, but not actually confirm that the root is the same for both. So we need to make sure that we're the signature that we're verifying is over the Merck route, and we also want to check the Merck proof so we check the Merkel proof first compute the route, put it in the payload and then check the signal we can encourage folks to not accidentally forget to do that check Next slide. So now we've got some CDL structures. This is kind of just unpacking the EDN-SEBOR extended diagnosis notation you saw previously These are very simple, so I think we'll just zip right through these next slide Like I said, the receipt that some of the language that we're using here is a receipt are signed inclusion proofs. It's the important part is, you know, what extensions do we need to make to Cozy to make these happen? So the verifiable data structure tag, which is just another algorithm identifier but we want to make sure that's going in a protected header. And then in the unprotected header, these proofs. Why? are the proofs in the unprotected header? that seems like scary right so the reason they're there is that these proofs, you're performing operations on them in order to get a value and that they're the authentication process for them is a separate authentication process from the digital signal authentication process. So that's why they're in the unprecedented header. It's also easy to add them later to something that was signed. So the unprotected header is a great place to put stuff, but you'd be careful what you put there. In these cases, you can always verify"
  },
  {
    "startTime": "00:44:01",
    "text": "these verifiable proofs So it's sort of okay to put them there, but, you know, again, with the unprotected header, be cautious I think next slide This is just another another look at the encoded version of a receipt We've seen this in the earlier slides We can skip ahead so why why do this work well originally we needed a way to represent some of the transparency structures that the SCIT working group at IETF security supply chain, integrity, transparency, and trust working group, which is looking at software supply chain security scenarios and we needed a cozy structure that we could use to represent these Merkel proofs So that didn't seem like we're related to software supply chain That seemed like a general security feature that everyone could benefit from. So that's why we brought this work to the Cozy Group. And the use case there was, you know, maybe you would like to prove that a particular binary was in a transparency log. And I'll just and that certain policies were applied at the time the binary was included in that transparency log so I'll just sort of ad lib of bit up here about some of the work we did at the hackathon So at the hackathon on site, just sort of ad lib a bit up here about some of the work we did at the hackathon. So at the hackathon on Sunday, one of the things that I did was sort of look at incident response and how binary management can be a part of, you know, responding your presentation incident. So if you're going around to data centers, plugging in USB keys to recover devices, you might want to be assured that the USB C contains authorized recovery material What is authorized recovery? material mean? Well, one of the scenarios could be that you have a receipt that for this data center"
  },
  {
    "startTime": "00:46:01",
    "text": "this recovery material is authorized to be used in these computers. And what is that receipt? convey? It means that before you let the recovery team into the building to plug in USB, you know, you're checking that the binary is in an append only log you have a signature on that receipt that's from a root of trust that that data center is associated with and that the binary itself is, you know, signed by the incident response team. So that's an example of like, you know, why, where might you want transparency when you're dealing with a particular security incident and putting these things in a log is one of the things that we're seeing evolve in the supply chain ecosystem Next slide. So where are we at? We're at 05 now. We've requested early allocations and I've been speaking to the chair about the process for that. And the reason we're asking for these early allocations in IANA is those tags 394 and 395. We like those numbers we want to be able to do implementations on top of them, and we think, you know, maybe we shouldn't have to change them at this point so let's ask for early allocation There's some interoperations work that's already been done here. I think there's at least two implementations of these receipt structures at this point Although I will say part of the agility around the verifiable data structure piece is that people like to make different log formats. The SHAA-256 buying Merkel tree is a pretty good log format and I think it would be great if there was more interoperability implementations around just that shot 250 binary Merkel tree. That's the implementation that's compatible with Trillion, but there are other Merkel tree systems out there that, you know that produce different roots and if it if for the same binary, same set of messages, you get a different route, that's the sort of signal that you're going to"
  },
  {
    "startTime": "00:48:01",
    "text": "get a different verifiable data structure. So when we talk about interoperability in this space, we need to make sure we're talking about, we both support the same digital signature algorithms, but also that we both support the same verifiable data structures in order to get these inclusion proofs There's been some feedback from Robin, gave a great review of the document on the list. Authors need to respond to that review and complete and address all those comments. And I should mention, I have co-op What's Robin's last name? Bryce, I think Yeah. So, um gave a wonderful review of the document I should have said at the beginning this is work with co-authors, Hank and Cedric and Antoine who I don't know, hey, I don't think they're here but they've been helping along with these documents as well and so I'm hopeful that they'll respond to Robin's comments I think that's it. Oh, this is the most important part. We're really struggling to get reviews and this document I think is really ready for working group last call. We've got a couple of implementations So respectfully to the chairs, I would like to ask for a working group last call on this, but I'm happy to answer any questions from the room or from folks who are remote. Thank you All right, I'll ask my standard questions Who has read the document? Mike Perrach has read the document jon geater John has read the document We have a cue remote Okay Ah read the document. We have a queue remote. Felix, go ahead"
  },
  {
    "startTime": "00:50:01",
    "text": "Hey, just a question about the remark you made regarding under unprotected headers. It makes sort of sense what you said? but then I was wondering what are the purposes of the signature in that case anyways Yeah, it's a great question. It makes sense for a sign tree head because by definition that is signed, but yeah, why do you want to sign? Could you go back to any of the? diagrams that have one? more, one more? This one's good So here we've got the inclusion proof structure in the unprotected header. And that the the is the structure of the receipt is this is the structure of the receipt so the receipt itself is assigned treehead um And the authentication material for the Merkel proof side of that is in the unprotected here because you're going to use that information to re-compute the route. And then you're going to verify the signature. Can you go back one? more? more so it's basically in the sign received is two and one right sign yes two pieces of authentication material and one conceptual method Yeah, that's correct. But the other point here is, there's another unprotected header, and you see there's multiple receipts. So imagine I've got a really high value binary that I'm using in an incident response scenario and I want that binary to be transparent on multiple transparency services, maybe independent agencies, different regulatory environments whatever. So one of the nice things about the unprotected header is mutable without breaking the signature So we can add those other receipts over time for this recovery material. So I might mint the recovery material, go to a vendor and say, hey, you know, I've got the recovery material. You want, you know, can I? fix all your devices? That event is says, yes, but make sure it's transparent in our transparency log system that we support"
  },
  {
    "startTime": "00:52:01",
    "text": "for our data centers. So I would go, I would reg register the recovery material with their system. I would come back with a receipt for the recovery material fix all their boxes, go to the next guys at different data center, different infrastructure. I say, hey, I want to recover your devices. He says, yeah, but we have a different transparency system. So I could get a receipt for that same binary, but in a different system. And that's why you see multiple receipts here And you can see them in the unprotected header because we want to add them over time. And here, the protected headers again, a sign tree head so only for one of the receipts yeah so this this is the um this is the what we call in skit we would call this a transparent statement the payload is detached here think about filling that payload with some important binary in the incident response toolbox or an image that you're trying to secure or some other artifact that you want transparency on. So here, the payload is some application or domain specific binary that you're trying to secure whereas inside of the receipts, the payload is the sign tree head Okay, cool. Thanks. Yep My other standard question is who's implicated? it? Three, that's good Three and a three and a half half Good, have you tested with each other? So this is back to the back to the point about the Shaw 256 binary Merkel tree. That's the implementation that I've been used to test. And I have done cross-testing with the trillion open-source implementation to make sure that the Go ecosystem's Merkel trees are consistent with the implementation that I've done What open"
  },
  {
    "startTime": "00:54:01",
    "text": "issues remain for the draft? I believe at this time the primary open issues are the ones in the follow-up steps to review and respond to Robin Bryce's comment which he sent to the list some time ago and which I love for our co-authors to respond to I can do it, but I would love for other folks to work together on this. And then the early allocations piece as well, this is more of a process thing, not something to change in the document document okay similarly to the previous set of presentation why don't you tell me when you think you've addressed Robin's comments and then we'll start working group last call. All right, so let the record reflect that we're not ready for working group last call until Robbins' comments have been addressed. Thank you thank you Time stamp tokens Yeah, hello I'm here for Hank, who is chairing UPS at the same time so he couldn't be here, but this is probably one of the more obvious drafts that I have talked about So Arie's slot was a pretty good preparation for this because this is again about something that looks a bit like a counter signature that is put into the unprotected header but also sometimes in the protected header i get to that and this time it's RFC3 3161 timestamp tokens So this is a little bit of a blast from the past These things were standardized like 20 years ago But there is infrastructure out there that provides them. And"
  },
  {
    "startTime": "00:56:01",
    "text": "so if you just want to use this infrastructure to see this infrastructure here. And this guy over there vouches for the data structure, having existed, at that particular point in time then timestamp tokens are a good way to get existing implementations and existing services so that's why we are doing a little bit of some mixing here So I think the idea about saying next slide is that the slides advance when I say next slide. So the previous slide said that this is just to be used for signatures, cos design and coscine 1 when I say next slide. So the previous slide said that this is just to be used for signatures, COSI and COSI sign 1. And we have two modes and slides just to be used for signatures, cos design and coscian1, and we have two modes. And the slide you see is the first of the two modes the timestamp and cosy mode So in this case, actually the timestamp is part of the information or becomes part of the information that somebody wanted to sign. So that's why the payload is both put into the sick structure from COSI and into the TSA, the time standing, stamping mechanism. And the timestamp token that comes out from the TSA is then put into the six structure inside and in this case obviously the timestamp goes into the protected head up because the originator of that COSI structure was structure inside. And in this case, obviously, the timestamp goes into the protected head up, because the originator of that COSI structure wanted to make sure the timestamp is with the data and the timestamp cannot not be meddled with and next slide the other way of using the timestamp token is to do a sign 1 and maybe independently of that, maybe even at a later"
  },
  {
    "startTime": "00:58:01",
    "text": "time, actually ask the TSA to timestamp that signed structure. So that timestamp then of course only can go into the unprotected header just like the receipts we had before but the semantics here is not that of a receipt but of a timestamping token so this is all pretty much no brain And I can imagine not many people have read this because it's so boring Next slide, please. There was some recent comment on how we should deal with the fact that there might be some information leaking And we added some text to what the authors added some text to the security concerns section and I think that's the one thing that needed to be done and the authors think this idea is ready for working Glasgow And I should say, that's actively being used in the Reds context, so that's a good thing if we do with this reasonably quickly Thank you, Kirsten, emergency presenter Are there questions for Kirsten? Like the rock Sorry, trying to meander to the mic here Mike Barak, I was going to note, in addition to rats, we're doing some testing already with using this parameter in other contexts of signing evidence in external use cases. So definitely uses elsewhere and likewise, I think"
  },
  {
    "startTime": "01:00:01",
    "text": "it's ready for a working group last call it's able to be implemented cleanly thank you indeed it's a very general box that you can add to your kids and do a lot of things with Are there implementations? I cannot say Mike raises his hand All right this does a simple thing Hearing no objections, let the minute record that we're going to start a working group last call on this draft Thank you Thank you, Kirsten It is time for Kozai hash envelopes which Steve is going to talk about Hello, I'm steve lasker Let's see if we can get a non-animated deck here. So this was something that Ori, myself, and Hank have been working on It came as part of Skit, but it turns out this pattern is fairly generally used so we wanted to bring this forward so next So first, just kind of a reference point for what the current state is. So next slide So basically we've got the protected header, which has a content type in it that is what the payload is Great. So then we put that payload and then the content type of the payload and then other parameters in there, other headers. And then you have the payload itself. And that's fine when you're trying to pass something around next. And then you see those bytes but the signature is based on"
  },
  {
    "startTime": "01:02:01",
    "text": "the payload and the protected header. You need that combination next So when you're trying to submit this cozy object up to various surfaces, such as a sketch transparency service, you know, how does size matter, right? How big is this? payload that we're trying to send over? And is it referencing something that already exists? So in the software case, everything that we're talking about putting in the payload is already in a storage service of some sort. Why are we? flooding the internet, sending it around? Again, is it? the same thing? And is there any real benefit? So in the normal case, or not the normal case, but if you just take the protected Heather and the unprotected header, sorry, the protected header in the signature, you know, ah, it's 2K, big deal, right? Maybe for the Seabor group as a whole where conciseness was key, that's already too big next. But if you take any reasonable S-bomb or the VCon or container or some of the packages, they get awfully big and I don't think we want to be passing these things around So that's kind of the impetus to starting this Next. So then we have detached payloads. Sounds like a great solution Well, detach payloads just say they're detached and empty. So if you try to check the signature, you need the payload. So all it did was allow for out-of-band delivery of very large payloads which we already have another service. Now, we could use the unprotected header, or protect, doesn't really matter, to tell us where the payload is and if it's accessible, we can go get it next and then you'd be able to verify the signature the signature would"
  },
  {
    "startTime": "01:04:01",
    "text": "pass because you'd be able to compare those the payload and the protected header. But that's a big if, next, because in many of these cases, those storage services may not be a accessible or we're just back to the same size matters. There's a lot of content to be passing back and forth when all you're trying to do is check the validity of the signature is the issue or somebody you want to test get content from I refer to this as the Trojan horse scenario. I don't want to break the binary on to the machine to check if I want the bind I want to, right, because it's too late, right? This is kind of like you go to passport control you handle your passport only if they like you will they let you through. They don't let you through first and go up aha, I've got you and then validate whether you should be there or not So, give you your passport backwards Mike's comment. Next. So now, all right, so now I start thinking about some other parts to it. What exactly are we putting? in the payload just to kind of add to this? and this was meant to be a build slide you could have a equals B, fairly simple, inline content no big deal. So size doesn't matter in that case It could be a small file. We'll define small, or it could be a large file and defined large right? These things have varied over time and per industry Could be a collection of files It might be files by reference, such as an NPM package URL or a container image package URL. In fact, in those cases, those are actually manifest which are yet more files that contain links to files So what exactly is this? payload? Next, please Turtles, turtles all the way down. So now this is where we started evaluating the hash envelope please. And that's kind of the point here is there's a lot of complexity. Like, which one are we trying to choose"
  },
  {
    "startTime": "01:06:01",
    "text": "when we were rolling out skit and data trails we were trying to communicate to partners like, well, when should you use? this API and how should you use it? And it was already, like, they're trying to get something else done and now it depends. So as you go through this, in line, the colors kind of indicate where that's good and bad with this little legend at the bottom. Detatch didn't really solve anything because you still have to provide it. It's just out of band So what if we use a hash payload? Next please So in the hash payload we're taking the payload and hashing whatever they were original contents was. So now you actually have something to verify So you don't need to bring down the 50 terabytes of that large language model. You can say here's the hash of it and you need to make sure the hash matches but at least you have a verifiable signature now this has been a little bit of the, you know, accuracy is true problem in that we'd like to have used the content type that was already there, but the content type is a hash So we had to introduce another type that says, here's the pre-image content type So now you know when you're undoing that hash, what was i trying to get it to and the spdx example is an interesting one because they come in Jason they come in YAML, their XML, maybe you I and I forget. So you know what the original payload was supposed to be, or the content type Now the payload location is interesting because it's really kind of, I don't want to say it's option but it's like that's, if you want to, you can go get it. That may not be where you get it Best practices for any software is don't go out to the internet to try to get something you are can go get it. That may not be where you get it. Best practices for any software is don't go out to the internet to try to get something you already are dependent on, take possession of it and depend it locally. So your copy,"
  },
  {
    "startTime": "01:08:01",
    "text": "is still the same hash, even the location is someplace different. So the hash is really important in those cases. So what's nice about this, is when they're independently verifiable Size does not matter in this case because you have a nice compact hash. And we're not trying to recreate the data that's already in these storage services next so an example, so in this case, you know, the algorithm we're leveraging the new type RFC 9596 where and we can debate I think we already had some feedback, is that the right? anotype and you know we can certainly take that as a change you know what the algorithm was used to hash, so you don't have to guess. We'll expose what that is what was it originally and then where is it stored? But again, the where is it stored? is not hard because you're probably, that might be where it was signed in the first place but as you're referencing it like such as I already have a copy of it you can use the hash as long as the hash matches, the location is not really as important. Next so we've already got a couple examples of how we use this. This actually was one of those that came out in this necessity so we're referencing it in some GitHub actions we use for SCIT It turns out that did you cert was already doing this with their software trust manager whether how they're hashing their content, which of many people do this, so it's not a new thing And VECONs also are, can be very large in size, so they're also very interested in using this. So that's I believe, what I have next Yeah, so this is, you know, an ask for adoption. So"
  },
  {
    "startTime": "01:10:01",
    "text": "please review and any feedback And that's the info Justin Hi, justin richer. So the obvious issue with any detached hash base mechanism, right, that is that you still have to calculate and validate the hash. Otherwise, you'd just kind of blindly accept everything. We see this all the time in each message signatures that use content digest and things like that. I've seen a number of implementation in the wild that naively check the signature and then walk away without checking the content hash. Is there anything we can do beyond sternly wording? warnings in this draft? that would make people not skip the make people, yeah, that would make people not skip the hash check I know some data structures have inherent means of doing that. I don't see that here What are your thoughts on this? I mean, where is up next? I mean, my okay, I mean, I would just say it's obviously this, none of this stuff solves laziness and, you know, that kind of stuff. There's best practices to make it efficient does not mean you're still going to skip security altogether. Nothing, nobody asks, nobody confirms that you have to go check any signature before you deploy a payload unless you have something in place. So that's same logic I would say should be in place. Right Just, I do think that this particular, issue was a little bit more subtle than that because you can put in work to check the signature and can convince yourself that you've actually done the right thing That's where I see this particular problem in the wild it's not it's not oh I'm just going to skip security because that's kind of a bigger, dumber decision"
  },
  {
    "startTime": "01:12:01",
    "text": "Fair it up. Lawrence not, it's not, oh, I'm just going to skip security because that's kind of a bigger, dumber decision. Fair it up. Go ahead. Lawrence. I was going to answer this question. So, Roy, what? williams. So in the situation where we're using this, as a method to notarize or countersign, yes this makes perfect sense for here but the end user that gets this still has to validate the content because they're going to get the content. And you're right, we should probably put wording that that's where this gets stitched together. And I have no problem with that. In the mode that where this is, it a saves network bandwidth and we're not attesting to the content in some of these cases where it testing to the signature, which is slightly different but yeah I agree with your state Yeah, thanks. Thanks. That it is helpful in the more ways that we can have that kind of stitch the pieces together in here that are lightweight for implementers I think we'll be better off that way. Thanks Thanks Lawrence Thanks Michael here. So what I what I, what, okay Moving up the queue. What, what I was hearing and made in the question, and maybe, and I'm asking question or clarification, what I was hearing was, maybe it would be good to have a hash over the first 100 okay such that when you go to fetch the six terabyte file that doesn't fit on your disk at all, that you can start off and get a little bit and go, yeah, yeah, this is going the right direction And so it's worth my six hours to do download the rest of it to get the thing as opposed to well, that's just not the right URL. Okay, let's stop right earlier. That's what I was hearing in the question. I don't know if that's a good idea, but that's what I was hearing in the question of the approach"
  },
  {
    "startTime": "01:14:01",
    "text": "the process, right? No, it's it's interesting to say that okay, I've, to Roy's point, part of it is is this content from somebody I trust? But that's the main thing that we're kind of trying to address is because multiple entities can sign some content And I, in fact, what we define in Skid is multiple entities may agree or disagree whether they believe something meets some behavior and so you check the one you trust. You ask the person that actually knows about how to build a house, you know, advice as opposed to somebody else that doesn't. So I think there's a first check that but i think you're at that next part of from a validity of the integrity of the content, does it match the interesting optimization? Lawrence. Yes, so this is close to, this solution is close to a the solution for another problem that with COSI signing that I've run into. That is when you want to sign something big multiple times with multiple algorithms and you only want to hash it once. Yep So it just seems like, because there's, you can do that you can encrypt multiple times with Cozabache once. Yep. So it just seems like, because there's, you can do, you can encrypt multiple times with Coz A, but you can't sign multiple times with Coz A in hash once So I don't know if there's a way to combine them, but just That's a great point Mike. Yeah, Mike Pariah here, big plus one to Lawrence. Definitely a common pattern We see one option to one to Lawrence, definitely a common pattern. We see one option that might be worth considering is kind of forcing a strict mode And I think this goes to Justin's comment where potentially the hash itself is the what's in the detached payload in getting signed so it's just not present at all. You have to calculate the hash in order to generate to verify the signature right so if you leave the hash out of you know that's being signed outright, there might be a way to force that creatively So it might not be suitable for all cases, but there"
  },
  {
    "startTime": "01:16:01",
    "text": "are cases where, like, if you need this absolutely you know you want to guarantee that the person receiving this does compete the hash and verify right there are cases where that critical. No, that's a good point. You could, you know, in that case it's attached hash payload, I guess, if you will But that's a different, I would argue that's a different scenario though because in many of these scenarios I don't want to download, it's the Trojan horse thing which is discussed. If I download it to get that hash then I've lost already So it depends on what you're trying to verify Great. All right, or steal the Trojan horse thing we just discussed. If I download it to get that hash, then I've lost already. So it depends on what you're trying to verify. Great. All right. orie steele. michael richardson reminded me that Koz, Sign Zero exists. So most of the time when we're looking at these, we're talking about Cozy sign one, but maybe sign 0 with this this structure sort of solves the case that Lawrence you're talking about. I don't know. Do people use Cozy Sign 0? zero? It doesn't? it doesn't? Sorry, man So definitely people use because they sign zero. I'm a little out of date. I haven't been paying attention to this for the last year or so. But I know a couple years ago, I did look into trying to deal with multiple signatures, particularly for, you know, a hybrid PQ scenario, right? And hash once and verify and I, my recollection then is Coz A sign zero did not help with this that there was there was definitely something needed And I think if you go back in the mailing list, about two or three years, there's, there's, I think I posted something I have to download the whole mailing list or got a hash? Sorry Just the first country messages. The first couple of K, yes"
  },
  {
    "startTime": "01:18:01",
    "text": "All right, we're going to use advanced meeting features now All of you who haven't joined V via the light client, this is your opportunity to do so Get your name on record And express an opinion about whether it's appropriate to adopt this by the working group All right going once Who's still trying to join? Well, now we know where his vote goes He's been identified okay let the record show that the room and the virtual room were in favor of it adoption So I will follow up on list and or my co-chair but it looks like we're going to have a new working group draft. Thank you very much. Thank you I don't know if I mentioned because I left it looks like we're going to have a new working group draft. Thank you very much. Thank you. I don't know if I mentioned because I left it's, I mentioned Ori myself and Hank are the authors of the draft. I think I left that all. Okay and let let them minutes record the 22 Zoot Ori, myself, and Hank are the authors of the draft. I think I left that all. Okay, and let the minutes record the 22, 0, and 8, if possible Recorded 220 and 9 now With that, we're now going to start on a festival of Honest, presenting three times in a row The first one"
  },
  {
    "startTime": "01:20:01",
    "text": "Sorry that you guys have to go through this that Hanas has valor volunteered to talk about is following Yeah, it's a pretty long and complex title but you will you will see the familiarity very quickly as I go to the next slide So this is, so the and complex title, but you will see the familiarity very quickly as I go to the next slide. So this is, so there's this. If you have attended the last year November IETF meeting, the LAMP session, you've seen a talk with AAD to non-AAD downgrading attack to CMS and it's an attack where an adversary manipulates the content encryption algorithm identifier from, for example, AESGCM and downgrades it to AESCBC, for example, or counter mode and thereby if it is successful, set a couple of preconditions and there's the link to the to the lambs draft below but if the backer's successful, then he's able to um impact confidentiality and the integrity of the payload. And it's not a totally unrealistic attack and that's why there is a document in the LAMPS working group to mitigate that attack, which has, as I noted here, has gone through working group last call in LAMS already So it's a kind of mature solution The solution is somewhat simple Namely, what it does is it's normally you have sent a key key distribution algorithm, for example you use something like if, yes ephemeral static Tiffy-Hellman and then you derive a content encryption key, and now what that document in LAMS is indicating you go through another key derivation step"
  },
  {
    "startTime": "01:22:01",
    "text": "and you include the this encryption algorithm identity as well to make sure that you come up with a different key. So if an adversary is able to modify what? modifies that algorithm, he would then end up having a different key and then consequently the attack gets discovered so this document after looking at the cozy work which we believe this attack is equally applicable to we propose a mechanism that follows the same line of thinking and a applies it to COSI. Of course, considering the different payloads that parameters and so on, we have in COSI comparison to CMS And yeah, so that's in an nutshell what the document does. It's quite short but it's obviously important to address that vulnerability or that sort of attack before it becomes an issue I've been working with ken takayama and russ housley on this document, but the document, this specific version of the draft, the 0-0 russ housley on this document, but the document this specific version of the draft, the zero zero version was submitted in somewhat of a rush before the deadline so I didn't have their permission to include them as authors. And yeah that's why they are not there yet. So that's something I need to do another step is to look at how this attack could eventually be applied also to Jose, which I would then say we should in the same style also apply the same mechanism to Jose So this is when you remember my previous talk and the comment from Sophie earlier that this is the different algorithms. So this is like if you remember the picture with the diagram"
  },
  {
    "startTime": "01:24:01",
    "text": "which had these two layers. We were previously talking about the recipient layer, that was the HPCGEDIS discussion. This is sort of the outer layer the content encryption layer so it concerns this one So there's essentially then an extra layer of key derivation that is taking place, which in my opinion, is a minimum amount of overhead, but there's obviously benefits to be gained from that So that's for that reason I'm asking for documented option of this one and to process the document as quickly through the working group as possible to, yeah, to avoid having problems in the future Any questions? the alternative would be to also have that algorithm in the public key itself. So if you don't want to do the key, derivation, you can also say this public key can only ever be used with this envelope a bit with this data encryption key type mostly a question of whether you can afford an HDF or not yes good good by and so I should have mentioned that so um in the hbke case we since we are right now working it, we could include that mechanism and in some sense we did, but there are also all sorts of other key distribution mechanisms in COSI, which we don't want to change again Like we don't want to update the whole COSI thing. We want to be basically take what we have and add that on top of it And so the questions, of course, like as we work on right now on the Cozy HBKE should we have then a linkage to this document or should be incorporate the technique into HBKE? and have this sort of apply to the rest of"
  },
  {
    "startTime": "01:26:01",
    "text": "it? But yeah, that's I think that goes into the direction that you are asked as well. And I don't have a answer to this right now. I think there's something we need to discuss on a mailing list mike ounsworth You are muted You're still You're still mute Mike. Lawrence Yes You still mute, Mike. Yes. So ken takayama produced some very pretty diagrams that he posted to the mailing list at the ken takayama produced some very pretty diagrams that he posted to the to the mailing list that show a couple of the solutions to the attack that was presented in Prague And my understanding from there, is that the this is one solution, and this is the solution that CMS chose there are an alternative there is an alternative solution, which is to feed the identifier of the algorithm of the next layer down into the key derivative key derivative or the or more correctly into the authenticated data of the COSE recipient. This is what would Honest presented in the in his more warm-up to the festival And so I think we have to pick one solution or the other. I mean, and to me, I prefer in putting the- algorithm ID. I think it is a much simpler solution and much lighter touch. This adds a whole other layer of processing and just when I think about the amount of implementation work and object code this seems more complicated I'm not sure. I wouldn't agree with you there"
  },
  {
    "startTime": "01:28:01",
    "text": "So that the HP key solution is obviously something it's easy for us to make changes there because we are already touching on many other things. We are designing the mechanism right now But if in order for this approach to work for all the other sort of key distribution mechanism, we have to then touch all of them like we have to look at all of them and figure this out on how exactly this works and that could be that could be tricky like there is aes key wrap as a mechanism. There is ESC yes um um sort of ephemeral static tiffy helmen you have static static Diffy Helmand, you have all these sort of things and we then have to work through all of them That sounds like a lot of work to me And so for that reason, I prefer to be in line with what the the CMS are there the CMS or slash lambs guys came up with uh even if we decide for the HBKE case or for future mechanisms to have something else Yeah, agreed that we need to look at all of them and understand that. And I don't think that was that that has been thought through completely yet. Yeah Well, it's, we just like, I think two weeks ago, I submitted a document, so it's ori all right we're still I like the solution because it's simple two weeks ago I submitted the document, so it's. Ory. Hi, orie steele. I like the solution because it's, it's simple and it aligns with how LAMS solved this issue iq to to come up to basically say the public key restriction comment that you're making We talked about this a lot with cozy and Hozy HPKE, and cutting straight to the chase, in Cozy and Hozy, there's never been a way to restrict a public key to a content encryption algorithm as far as I'm aware, ever right? Well, this specific attack, so I think we have to distinguish between the outermost layer, which is the content encryption part, which this attack,"
  },
  {
    "startTime": "01:30:01",
    "text": "deals with, this is sort of the AES GSM, downgrade tubes, AES, CBC The other aspect which we discussed earlier is what happens if someone modifies the algorithm in the recipient layer, which of course is also a problem Which they're going to do because they control it, but to coming back to the point that has spent, we recipient layer, which of course is also a problem? Which they're going to do because they control it. But to coming back to the point that has spent, we've spent many, many hours discussing this on these lists and it just keeps coming up over and over again the algorithm identifiers in the keys are optional and none of the algorithm identifiers that are going in the public keys are restricted to a content encryption algorithm. You're inviting this thing forever, right? Yeah. Yeah think the reason why we have been discussing this topic up and down is simply because it's a little bit convoluted to understand it's not so easy for some of us at least. And it's the tax side it's not like oh if you if you omit this then here's the attack you actually the attacks and you have to construct them things about them. They, they, since we build it, since we come up with building blocks, some of those, omitting some of the context information structures, for example uh like the endpoints that we discussed earlier it's not that the attacks are immediately obvious And so that's why maybe it makes it more common complicated. Just one more comment. There's a, this draft draft fully specified algorithms i'm an author, Mike Jones is an author. It's been presented in the Hosey working group yesterday and that this topic of algorithm constructions for hybrid encryption, and when I say hybrid, I mean hybrid public key and symmetric encryption in this context. We've tried to write text around this topic in that draft And if we acknowledge the trend that we in this context. We've tried to write text around this topic in that draft, and if we acknowledge the trend that we've been on, that text would basically reinforce this pattern of never restricting an algorithm in a public key to a content encryption"
  },
  {
    "startTime": "01:32:01",
    "text": "So if you're passionate about this, I encourage you to all read that draft fully specified algorithms. I'll put it in the chart If you want to see text in that, that says something about restricting a public key to a particular content encryption algorithm, that draft could be a good place to put that text, negotiate that in that draft could kill that draft and we could talk about it forever, but we should that's it that's a place where we could put that guidance this stuff document, I'm not sure that I would mix them together at this layer because this is just about actually used the parameter that you're seeing in the header right So you're not talking about public keys here. You're talking about safely using parameters in an attacker attacker-controlled message. Yeah. So, yeah, I took one interesting point that was discussed yesterday at the Jose meeting with me, which is the bullet number three here use algorithm identify to signal this mechanism, because somehow we have to indicate of like, oh, you're doing this additional step of key derivation, you need to tell the recipient that you actually do this. And so I include the problem in here, but I actually liked the suggestion that was made yesterday in Mike's presentation better, which used a different algorithm number Since we are changing the algorithm numbers, or presumably, depending on how that discussion goes, we could actually sort of indicate that well, if you use, for example, ephemeral static diffiherment, then there's this new algorithm number, and it actually means that you do the traditional ephemeral static Tiffi-Helman plus this key derivation step, and then you're good I hope that makes sense mike ounsworth for the second time okay Let me try my audio this time better. Works Works. Okay"
  },
  {
    "startTime": "01:34:01",
    "text": "question is technical. I probably, you've probably said it and I probably missed it, but what are the backwards compatibility? implications of doing this Does it require new code points, new algorithm IDs? Yeah, new algorithm IDs in this case, yep for yeah yeah in my opinion like that yeah. Yeah, so yeah, that's a tricky thing um new for the a for the a for the a d's or new public keys or for the fully specified? like where are you how are you fixing this What layer are you? So there are few to be done here. So I'm, I think I'm what I'm, asking is like uh at this point in time is since this is like a very recent submission is like recognition from the group that this is a problem we need to add point in time is since this is like a very recent submission is like recognition from the group that this is a problem we need to address and there's a problem statement and we have some prior work from the LAMS working group on CMS. And to start work on this and not acknowledging there are some questions that's I think that's I don't have the answers to your questions sophie yeah it needs to be in the in the public key that you change it you can't do it in the age answers to your questions. Sophie? Yeah, it needs to be in the public key that you change it. You can't do it in the AED. The AED cannot attest to its own algorithm The other thing is, if you have a new algorithm, my identifier, you could restrict the algorithm of the data encryption layer if this is a direction you want to move to like it is okay to have more than one data encryption algorithm, I consider it usually bad form to have more than one data encryption algorithm associated with one public key so yeah it was according to my personal vision, I would restrict it in the public key already to just one data encryption algorithm"
  },
  {
    "startTime": "01:36:01",
    "text": "You're not introducing any vulnerabilities if you do the derivation but if you're already changing the algorithm identifier for the public key, you might take that as an opportunity to fix the public key to one data encryption algorithm if that is something okay so when you say it sort of tied to the public key, you mean like you, you envision something like a cozy key structure which has all the parameters and then there's one additional flag that says, I use it with this one okay if you look at the hpec that already does that the HPEC E already says I'm using this curve and also AESGCM if you do that for all of your public key types you've also mitigated it and you don't need any HKT things. That being set, putting everything into 80s your public key types, you've also mitigated it and you don't need any HKDF things. That being said, putting everything into HKDF is always a good idea, so do that as well in hbkey actually so that's a trick one because in HBKE it actually has two meanings. So there's one case, that's the single layer the integrated encryption, direct encryption, where the ESGCM usage really applies to the plain text you are encrypting. So there it works But in the other case, in the two two-layer structure, you actually have the AES potentially twice. Once you are there it works. But in the other case, in the two-layer structure, you actually have the AESGGM potentially twice. Once you apply it at the recipient layer to the kek and then another layer, potentially you use the different algorithms there you apply it to the to the actual plane text so in that case I would even call that that algorithm HPE-256 ASGCIM SGCM. Okay, and that's not what we do today yeah yeah I understand it's not what we do today I'm just saying that is another alternative that I think has some merit to be in the other. Okay, that's another thing then to dig into account, which unfortunately also says that, like, there's open issues Lawrence, then the cue is cut and then I'll ask a question. Yeah, so just record quick, the this all kind of gets intertwined with the cozy layering"
  },
  {
    "startTime": "01:38:01",
    "text": "you know because they layering you know there's a Cozy recipient and there's a CozE encrypt and you can layer them, you know, usually just two, but you could even do more. And I think this solution kind of hops around the layers So, anyway we need to think about the layering, because of layering and the module of the layering in whatever we do here Fair enough So I think we can't go directly to working group last call yet My and we've burned through our 10 minutes spare time at this point, but who is willing to read this draft and post a review? on list? Cory Lawrence Sophie, Kang yeah I quit Okay Ken thank you. Okay, thank you with that. We continue with the festival So I speed up a little bit to make up for the no, this is wrong. This is the sorry How about this one? That's cool Bikiki You have 10 minutes each for the two remaining drafts No, I'm not going to talk about this one You're not going to talk about it. Because I spoke about this one maybe a mistake in uploading I spoke about this one at the Jose meeting yesterday Yes, that's the one. So how many of you have been in the Jose meeting yet? yesterday? Raise your hands. Okay, actually a lot of. So I can skip a couple of slides. Next slide. So I"
  },
  {
    "startTime": "01:40:01",
    "text": "talked about like all this transition path. I talked about like all the work that great no work that NIST is doing Yesterday I focused on the foreign at this part where I was talking about how to encode chems in specifically codes and also Cozzi. Now I'm actually talking about the one in the middle to deal with a hybrid scheme, namely a hybrid scheme that one was as a cipher suite defined in HBKE which added hybrid as the combination of traditional, next slide, the traditional and the post-quantum crypto Here's the reference to this definition from the BQ cube draft and we had this in an early version in the HBKEE because there was work done in the C CFRG to register site suites for HBKE to support that functionality the hybrid functionality We stripped it out again in later version of HBKE because we said, oh, this will take much longer First of all, it takes longer for NIST to get the act together and then it takes even long for the CFRG to complete that work And so we do it later, and that's why now I think now one year later or so we now have put that specific this feature with the corresponding text into the into a new document and this is this document so there are relate there's related work who are conceptually at least work in DLS and in IQ version two where hybrid designs are specified but those hybrid designs are not using HBKEE, but this is HBKEE HBKE-focused. Next slide"
  },
  {
    "startTime": "01:42:01",
    "text": "um i should also point out that when you use the combination of the traditional and the BQC algorithms, you somehow need to combine these these shared secrets that get derived and there's this combiner work and there is the solution that we are using is currently specific in this CFRG document that is referenced in the in the in the in the draft and also later in the slide deck but there's a more generic solution that was just recently proposed called X-Wing by Deirdre, which may be used as well in the future. So there's some ongoing debate about this topic as well. Next slide Also limitation worth pointing out uh for this for this specific work uh HPKE has different modes. There's an unauthenticated mode called base mode and then there are three authenticated modes and this specific hybrid combination only works for the base mode, so for the unauthenticated mode which means that you additionally have have to use other cozy constructs outside the cozy payload to provide that type of authentication For example, you could use the cozy sign one along with it. Okay, next one And so this is the algorithm registry that this is document proposes. So this is in the middle, you can see that this is this hybrid sort of algorithm identify our algorithm labor that is being used is x-255 Kaiba construct that was proposed and this is based is being used is x-25519 Kaiba construction that was proposed and this is basically what the document suggests to to be added along with the text explaining what it means"
  },
  {
    "startTime": "01:44:01",
    "text": "Okay, next one, I think that's so yeah, so it's still sort of working in progress in terms of working at CFRG and also NIST and so on but it might be a good time to never let us think about adoption and to get some experiments being worked on to see how well that works and who is then interested in these hybrid modes modes Yeah, that's the short work version. Questions? What do you think? You care about hybrids? So if it does, yeah. Not everyone is a excited about hybrids. Some people think we should go straight to post-quantum crypto, but so your mileage may vary here But yeah, I think like as a big fan of HPKE, I find the solution using a hybrid with HP quantum crypto, but so your mileage may vary here. But yeah, I think, like, as a big fan of HBKE, I find the solution using a hybrid with HBKE good So, all right, or I still, can you go back to the algorithm identifier for a second? so the just because because you put it up here, I think both Hosey and Koz have moved on from putting the HBKE mode in the algorithm identifier. So you have HPKE base here, but you could have had PSK or, you know basically just PSK because hybrids don't support any off mode. So just saying that out loud, because if HP, if we do an HPKE hybrid and cozy it's sort of like, of course we'll do one in Hosey, right? We would want to be able to restrict a key to the specific algorithm. We would need to align around all of that. And then the other comment is, it says Khyber, but should say ML Chem and it should be the not IPD version and all the other stuff. Yeah, right. Yeah, so that's what we copied from the original specification"
  },
  {
    "startTime": "01:46:01",
    "text": "the CFRG specification, so that's why it looks like this And I agree, yeah, they should update that as well And the work is still ongoing. So it's I saw that Vesta Ban and and would refresh the document so it's alive and kicking So we channel that feedback to them And then, Mike Any more questions? All right like the last draft my sense is this is pretty new, right? right? Well, it's compared to the last draft, this was actually in the HBKE, Cozy HBKE draft as a red registry but without the text uh in a earlier, a year ago or so um so we just sort of took it out and took it in this draft, but so in that sense it's not totally new versus the previous version that was that was like the attack that was published was from November. So it's it is fresh okay who is uh willing to review this draft? At first, who? has reviewed this draft? I said this is that counted? It's true. Come to the microphone or Quinn said it's short, he just did Oh, okay. You didn't pay attention to my presentation, just read the doctor instead. Okay So, Quinn, can you? write something to the list? Now you basically raised you hand, Quinn, and now you need to review I'm Quinn, I think it's good proposal and I support adoption"
  },
  {
    "startTime": "01:48:07",
    "text": "I'm first looking for how many people have actually read the draft before we ask the adopts question Okay, I it's a it's it's really a code point allocation allocation Sorry, orie steele, so maybe a better question is who's going to deploy this code? point if it gets registered? Like this whole hybrid tradition know, pure PQ or hybrid debate like it's easy to get code points but who's going to use this thing? Come to the mic, tell us you're really excited You're only going to do, you know, concise, embedded ideas in hybrid because you care about concise you know that that's mic, tell us you're really excited, you're only going to do, you know, concise embedded IOT in hybrid because you care about conciseness, you know, that's, that would be my question And I fear the answer is probably not so easy because many companies haven't made up the mind on those issues yet except maybe Mike has Oh, you want to go straight BQ? Yeah. Yeah Yeah, but it's up i i know that we will use it if we use Kose for something. PQC. I'm not sure if we I know that we will use it if we use Kose for something PQC. I'm not sure if we're using KOSA for anything in that Well, right now, probably yes but I'm not sure how much we're using the encrypted KC. That is the only caveat otherwise we will definitely use hybrid PTC. Yeah. So maybe this is a sort of a call out to the community. I will obviously ask people in specifically"
  },
  {
    "startTime": "01:50:01",
    "text": "you like sort of maybe you have asked inside your company some amount your colleagues on, like, what story? you want to go for in sort of moving to post-quantum whether you wait and can go for pq directly or maybe you go through an intermediate transition path at least the work in in age Iquersion 2 for PQ directly, or maybe you go through an intermediate transition path, at least the work in TLS and IQAWR1 gave me some confidence that some people want to go along the hybrid path in general like the whole PQC topic is difficult for constrained IOT devices. I think that's not a, not news to anyone here uh so that may be a challenge uh all along but yeah anyway I'm out of it enough. I'm out of it. I'll say something then you speak up if you like I think I would like to ask Ori's question on less which is if we do this work, are people wanting to deploy it. I think the work is well defined, question is applicability Evo, do you agree with that course of action? Yes, that sounds fair to me Okay, so, Justin justin richer just as a general technical point and not necessarily specific to this, you need to keep in mind-induced demand for something like this. Some implementer won't touch it until a code point exists And it might be what somebody will or actually use, and it's very, very very hard to predict that, especially in a space like this where there are lots of different algorithms"
  },
  {
    "startTime": "01:52:01",
    "text": "and methods and ways to go about doing this Very clearly, as we've heard from the room some groups are very much not interested in doing this so i think it might be a harder to make that judgment call of is this worth doing? Because, you know, our people want to do it? Because are there people who want to do it? because they might not be able to say that they want to? do it until it's a thing that they can do? Okay, with that, unless I'm wrong I believe we are through our agenda other things people would like to say at the microphone, and if so please join the queue before we call it a meeting All right. Thank you all for good discussions, and thank you, Michael, for taking the minutes Thank you, Christian. The minutes are going to be very important to the chairs for us to be able to determine what to do next. Thank you all. Thank you Thank you Hey. I want to just meet you. Yes Thank you No, but we're just one"
  },
  {
    "startTime": "01:54:01",
    "text": "go"
  }
]
