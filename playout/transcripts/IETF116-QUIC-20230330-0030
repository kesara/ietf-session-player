[
  {
    "startTime": "00:02:51",
    "text": "Do that testing? Is this better if for remote people? Okay. Okay. Let's go. Work Thursday now, you should potentially be familiar with the know well if you've been attending all week, but we might have some people in time for today because we're so special. So you're not familiar with the well, please, do itself this contains a whole bunch of stuff. But your participation at the idea, including things like go to conduct harassment procedures, how your contributions in this room and then other the drafts. Kind of work with the Will end rules around Ip and payments on that's participation and stuff like that. It's so simple and a lot of information now if you're not familiar. And time nigel to take a quick look before you We have some basic meeting tips here. We will person some participation to be run by the on Me echo tool. So if you got not yet then so there's a Qr code just on the bar side of the room where you can track in."
  },
  {
    "startTime": "00:04:03",
    "text": "And then moved you if you would like to to have participate in the discussion and to yourself in the q via that tool. We'll run that queue and get you. And I same for the remote participants using this tool make it good to participate whether you're remote or local. Mean appreciate those and old people. So Caveat da. Please, yeah, we we have a mass policy for this. Familiar familiarize yourself for that if you're not yet done so as well. This requires you to where I mask all times in the room unless you are actively speaking. Or brief periods where you're eating or drinking. So Please do that because we'll enforce it. My participants as usual, you know, if you can wanna had headphones that helps a lot for the quality of the the audio. I've think we're pretty familiar with how meat echo is working these days. Some the minister of, we do need a note taker. Before we get into the the meaty parts of this do we have any new volunteers for that, please? K? Robin kindly volunteered to take some notes but Robin remote. And as a remote participant, tried that in the past it is difficult Do we have anyone who would volunteer to to help robin who's in the room? All need to do is is jump on the the the link there. To the hedge. An that away. M please. Yeah. Thank you very much. I just wanna make sure we we reflect the notes That's good. That's it."
  },
  {
    "startTime": "00:06:03",
    "text": "Yes. We have an agenda. Where we've done our updates. We've taken our five minutes already, but I can play me echo okay. We have some working group items. We want to go through multi path, like frequency and the key logs, that's locations and then we're gonna get into some of the items terms. Be called it the reliable quick. Be stream resets that might be a different title, but it's in kind of concept So we'll see the exciting developments another a presentation from some research on quick country to some of the challenges that we've got there. So Would anyone like to bash that agenda while we have the chance? Not seeing anyone. Same thing the truck... Nope. So right more do. Some brief updates since the last meeting. We have the quick version negotiation and quickly to draft rented all forty eight status. So would you have waiting for a few boxes to be checked, and then we should expect those to be published resolve, which is the next exciting time. And the remaining things this week, you know, quick quick is now becoming foundation for various other activities that go on the. There's been a few sessions like web transport etcetera and mass But the remaining ones this week in case, you know, familiar with media over quick. Where there's two sessions thursday day today, just know the man the one right after lunch and Friday tomorrow. So if you're not familiar with those, it might be something else that you're interested in. And that's all we have. So could we get the presenters for multi, please? I will eat the mic from now."
  },
  {
    "startTime": "00:08:12",
    "text": "Okay. Hello hello everyone. I'm from Alibaba. Today you invite and I will introduce the updates of not as extension. Next slide, please. There are several modifications from the version rate version four, diverse and the most important notification is is and we remove the use of sim tag number space. Multiple capacities as a foreign supported option. And and by the way, as as as conclusion joke from the last idea for meeting, we have a vote. And by the way, as as the zinc number space, I was to support the the lens connection Id use fields in multiple passes. And so we also removed the pass identifier and has identified type as we do not need to support animal. And we also remove the tracking number of packing number space Id. And this stream modifications soc eighteenth database trials. Please feel free to check the details on the github up And we also clarify the pass center form has abandoned frame, and we add some... Did I didn't enroll passes and expand extended vision the packet members spaces and commercial Ids used for cass And also we updates on scheduling guidance and these modifications are in the url below and please feel to. That's slide, please."
  },
  {
    "startTime": "00:10:00",
    "text": "And important things and we remove the past is as think the previous which. Sorry. Yeah. And the most important thing that we removed the use of single packing space in this version. It's a conclusion which out from the last of meeting with have a about if people remember, And and it's and the single packing number space, is for this support until your narrow lens national Id in multiple passes. So we also removed the... We we removed it remove the past identifier And and we also require that people must use non general commercial ids in those connections when we use not passive extension. And also we update the Item for enable multi pass transport to parameter carl also have a very very long parameter but or get shorter one before we make the last call. And we have two technical reports. The first one we make a larger scale expert experiments for for comparing the experience between the number space and the multiple packing number space. And also company has support another report on own compare, there's two just two single pack of space and the multi peg space. And we both joined conclusion that multiple of packet number please had a battery experience in most cases. So please feel free to check these reports. Now slide, please."
  },
  {
    "startTime": "00:12:04",
    "text": "Okay. By way, as we have remove the support of there commercial In multiple business. We also removed the past identifier and the pass identifier type to support it And we also have some other issues which is discussed in the values and in the indicate half. And the first ones is to attempt to use connection has constant Id as as if if we the Changes and the test and my outage But in our current version just use the sequence number of connection Id to define the pass identifier of each pass So have not discussion on the nest page will like to for the discussion. Okay. I thanks. So you can say from Alibaba and what M may has just told you is the things we have done for the version number four during the last a couple of months. Right now I'm going to cover a lot of issues that the authors are debating and we have a lot of discussion on the github and we would like to more feedback from the working group. I think the first issue is the biggest one. So right now in the current draft we remove pass identifier, and we only use Dc sequence number identification purpose. And for this issue, we have a lot of discussion on the github, if you are interested that you can look at the github for some of the discussion, We have more than fifty four replies I I believe I remember the name. Correct. So so... Yeah. So there there are lots of exchanged. But in short,"
  },
  {
    "startTime": "00:14:04",
    "text": "What we want to decide is whether to have a stable pass Id versus a lu test Id model by state of has Id, I mean that's you have a constant past identifier during their lifetime of a past. For example, when you open the first pass, the second half and pass and you assign each pass a constant identifier, and this identifier will not change even even if the for turbo changes, And by lu has idea model, I mean, to only use that this Id sequence number for identification purpose. And that sequence number can change if you for triple changes. So the benefit of using a pass Id is that it really simplifies your mental model for the designer. As it is quite straightforward and intuitive to. But the issue is that when you try to do the implementation, and and and you find that, okay, the for triple is volatile because due to reasons like net binding the for triple can change. And as a consequence, what you need to do is you need to differentiate what is net binding genuine past migration and opening a new pass. So, detecting that we're rebranding is not hard because you still use the old this id... The connection Id to communicate is just the four triple changes. But there are some corner cases like if your Cid rotation and net binding happened at the same time. And to detect this corona cases is not quite straightforward. And to for the lu pass model, we only use you said the sequence number and we do not speak past Id anymore It turns out that the dc Id sequence number is quite fundamental. Because it enables you to do almost everything including pest creation past that as update past closing and also"
  },
  {
    "startTime": "00:16:00",
    "text": "the the sequence number is fundamental linked to the packet number space and is used to generate the nuns for encryption in the multitask. So the benefit of using the Lu pass Id model is that you will have no problems in handling that we're bending, past migration and opening a new pass. And you also there is also no when the packet number space changes. But this advantage of using a lu test Id model is that the past is not stable and it may not be intuitive at the first guys. So, yeah. We we would like to hear the opinions from the audience and working group out this issue. So anybody in the queue. Sorry. My plan is slow, I couldn't get in the queue. But I to get any color. I think this change makes sentence from like, a a spec specification point of view. For implementations, we'll still need some kind of Id and using the the connection Id sequence number also makes sense. I don't know specifically about the implementation whether this change actually improves anything or not, but implementing it should not be that complicated. So it's fine by me, I think I think my We preference goes to lu parcel model regarding this stable pass id model, I I wonder. If the I... I mean. Stocks can have that concept they. People can have that concept if they want. But I'm not sure if we have to expose that as as a concept in the protocol design."
  },
  {
    "startTime": "00:18:10",
    "text": "I just wanted to add that actually, I think the loose model was in the draft before for. It was just like, a few... In places where it wasn't, like, really clear or, like, where... Or like, it didn't explain it as clearly. But like spelling it out, does did help us to make a lot of decisions protocol itself. And then the other point that you made is like, yes. In your implementation, you might still have this kind of stable class identifier, but then it's just really an implementation teacher. And and so for us it's really important, there have been a bunch of questions where we had to decide about to address the question how to, like, when to open new cars I close the new person want to see a new person having this module helps us to to clarify that. So that wasn't the main. Anybody else on this issue? no more in the queue. You got... Is No this good back for you to be able to make progress as a team Okay. Okay. Is it is the question? What think so. I think so. Yeah. you got what you needed from this? Yeah. I Yeah. Next exercise piece. The nest issue is not as complicated completely communicated as the first one. It's about the error code for meeting cid during the handshake. Because in the draft of version number four, we make a decision that we only keep multiple packets number space. And and and and so that now if you want to use multi pass, and you should not... You you must not use zero and Cid. But what if you have an enable multi pass parameter that one is received. And the current packet does not contain a non zero as connection Id and then you have a connection error. And and and then we need to decide what types of error this should be"
  },
  {
    "startTime": "00:20:02",
    "text": "can we... So right now, the other thing we could just use parameter arrow for this purpose. So does everybody agree on this issue. Hardy. I forget exactly how many error codes we have available to us that are unused. Just yet. But we have lots of them. Make a new one. This doesn't make any sense to me. And I think people will we'll we wanna know that this is distinct from other sort of configuration thing. So I think transport parameter error is is very generic and there's no transport parameters involved in this process that you're describing. I apart from them. Oh, the I guess you you're saying that the the multi path transport parameter is wrong. Yet. Yep. Whereas, you know, I don't know. Isn't it the fact that the connection Id is zero length? The wrong thing here. I'll listen you getting cloud. You can have zero line connection Ids. But you can't have zero like connection Ids and enable set to one. So you shouldn't... I guess, it's a matter of perspective like you should set the the the transport parameter if you have a connection z like connection Id or you should then use zero line connection Id if you don't have a transport Like, either way, it's fine, like, it doesn't changed that much. But as you said, like there's like a billion billions error code. So we can just create the new one. I've just added myself to the queue. Speaking as an individual I like error codes for this kind of thing with specific ones. People can always use the the most generic area code if they really want, but there is a difference between"
  },
  {
    "startTime": "00:22:02",
    "text": "probably in the format of the container or the the set of things that we have. And actual... Like it's a man a problem in a bug that people are doing. Having a clear indicator that can really help drop and those kinds of things. As an individual opinion. Near. Yeah. I have the feeling. It doesn't make big difference because we also... I think there's also kind of a How it called... Now comment field. You can put like additional information in the area code. Right? So you could add something there. So I'm wondering if it actually if there's anything from an implementation point you that you would like do differently if you get one or the other error. Because that might be the main point. I will respond to that. Because I want. But... Yeah. If for some implementations, we will like actively discard the reason phrase because it is basically I'm to stuff. So... And again, it's can put anything in there. So in interrupting and hoping that they're gonna tell you that there was a problem or something it's a code is simpler in my opinion. But I mean, at the end it's an implementation error and and the connection break and that's it. Right? I mean, like, can you really do something else? Yeah. I can call somebody and say what's going on? Something's things changed recently. Assuming some spike in some other thing and... Yeah. Okay. Thanks. I mean, from a, like operational perspective, it's easier to have metrics for connection errors than it is have, like, logs for connection error reasons. It's easier to aggregate I guess. Okay. So as chad, what I'm hearing is strong sense in the room. Finding a new area code. We'll fact that into the issue and ask people to review the P as a for of"
  },
  {
    "startTime": "00:24:00",
    "text": "consensus for that one. Thanks. Okay. Okay. Then, yeah, we can move on to the next slide Oh, the the next issue is So right now, we have a past that spring and because this is the base draft At the beginning, we decide that we only want to keep as simple as possible we only have two values. One is stand by and one is available. Of the past. And the question is do we want to add more alternative value into the past status free. Yes. Yeah. This is also the question for the working group. Do we see the need to do that? I mean, is the question do we want to at them now or like in general in the future. In in the draft. In the. Oh, yeah. I don't I don't think so about it might be fine to leave the option open to add more later. Okay. Okay. Okay. So I think in this case, actually the important question is to one here, like, what should you do if you if you get in value that you didn't that you don't know? About right? Yeah. I I guess the question is, like, if we add more later, should that be you know, we had the transport parameter and then the implementation that advertise that is required to do something with the new one or An implementation can just send a new path status and then if you don't understand it you just ignore it, it probably sort of depends on what the actual meaning of the past status would be"
  },
  {
    "startTime": "00:26:00",
    "text": "So I guess for now, we can just say ignore it. And then, I mean, if later, like, one actually need to be like, there would be a new job defining a new part status and that would say, oh, but this one like If you implement it, you need to know like, you need to do the whole transport parameter thing and if not then you don't send it. Good afternoon. Yes. I mean, city very well is no point in defining the very like on the if your means. And the way we do that big using the extension mechanism. So what I would say is that if people would want to have you value you to say I tattoos that says post is three for five seconds. That's fine. Right, an extension draft, Says get the acknowledgement that goes and understands it. And then you can use it. But if you see a new status that comes out of the blue Martin. Martin Thompson. I had a number of things at made me get up. There's There's it document the Ib published a little while ago that talks about ex and extension points somewhat whatnot. This isn't this is a really good case of you're building another extension point into the protocol and having a very clear understanding of what your expectations are for someone who receives the the next value is is super important. I a suggestion. I'm gonna suggest that you remove this extension point entirely"
  },
  {
    "startTime": "00:28:02",
    "text": "and use two different frame types for for the the the two different frame status. And so you would have path standby. And path available. And then there would be no way to extend using this particular field. What you would have to do then is exactly what Christian was was talking about is if you wanted to do a new type of status, you would define a new frame. And you would use the quick ex mechanisms. And then you don't have the problem that this extension point becomes rotten and unusable because people who implemented it only implemented two values and Implemented. Is it bull for instance. Which is totally natural because protective path not active is is exactly what I I would do in my implementation based on this. So you would find that people would would have the the code rotten you try to ship the third value and it just wouldn't work. So I I I think you want two friends here. Okay. I would agree with both of those. Part of the design philosophy and quick right. Mike bishop. Part of the design philosophy for the core protocol was to make it impossible to send something invalid as often as possible. And here you're just asking to receive an invalid value when something develops in the future. Make it an extension where you can only send the frame after you've got acknowledged the new value. I just wanna agree and I think that actually totally makes sense because it kind of reverse the mapping between class status. So now we send a status frame and we actually announced the pass within the frame and that also means we can actually put multiple connection ids in the frame, which is really nice, we can say all these passes should be on standby by and that totally makes sense to me. Okay. Okay. Yep."
  },
  {
    "startTime": "00:30:01",
    "text": "Yeah. So I as I said, we don't actually have news for for new statuses. So doing two frames is fine, I just want to point out is it... It's not that if you send saying what what Mike was saying, if you send the value that is not supported, it's now invalid. It's just not supported. The same thing you do with unknown Http three frame. For example. But we don't have that in quick. Right? So that's kind of the problem. So Sure. That's fine. So I think what we're hearing is that there's pretty strong support for splitting this into multiple frames and that any new paths in the future would also probably use new frames. Okay. Sounds good. I I think we we we got the idea. We can move to the next size. Oh, the next exercise is about the return task of pass act And and right now, the current draft says that the Empty frame should be sent on the same pass. We do not block the possibility of sending it on any password we just say some recommendation in the draft, the motivation behind this, is to is your Rt estimation because in Pass, you have a scenario where for example, if you allow p to return from any pass and for one sample, the Rt may be the add of a one short pass and one long pass, and for another sample, the Rt value is add all two short paths And so what's end up happening is in your sample, you will have this discrete steps or jumps. In your Rt estimation, and we believe that today's the Rd estimation module in the controller is not designed to cope with this scenario and we are a bit afraid of causing"
  },
  {
    "startTime": "00:32:00",
    "text": "some troubles in the controller it's especially for those one who we'll use Rt for the Contact control purpose. And and so the the the questions we want to ask the the working group and the audience is that should we in this draft encourage the returning of P from any pass And if so, what would be the simple and the most effectively algorithm for the Rd estimation in this types of scenario. Christian? I think that lot of issues is that we are trying to use single estimate mean many things. You are mentioning using Rt estimates it will quickly and you are using seeing estimate partition control I think the complex... Yeah. Only the happens if you rely on the other is method of condition multiple. If you only this first with company because he is not done. The only thing you need is twist you. Because if it your loss will be quicker than by year. Ra is the the insertion of blue transmissions. So if you were to do the naive implementation. Which is to say Whenever I receive an acknowledgement, I active package that is being collection. I I used that in my estimates units. So that that What you will get is that you will incorporate in your statistics both the network statements, and the algorithm implementation on the other side. And"
  },
  {
    "startTime": "00:34:00",
    "text": "as long as your p follows a predictable strategy, your will flagged both The past evolution And the strategy used By the pier. And it will be perfectly fine to use it to trigger a P q or something scene like that. We'd be it will just walk. I think that should be the best. And we should say that if people want to do estimate based They have to have a specification on how they do that. You joined to queue? Ian sweat. Yeah. I I second Christian comment that as long as it's consistent, everything should work out on. There are a number of cases where internet hats are highly asymmetric. Yeah. It's not uncommon at all. But if it was unstable that would actually start introducing some very interesting challenges. So I think Yeah. And in many ways, actually, for some reason you have a faster lower Rt one way delay path to send the on. Why would do not Right? It's faster feedback. So Yeah. So just to be clear. I think we will still have it cash in the draft about what the effects are sending it here or there or whatever. But like, the question is should we remove a short here. That's the main question, and it sounds like people want remove it. And then you can I think it's okay to remove the should on the same path? But I would keep it should for using a consistent path. Using a consistent. That. I don't know why doesn't"
  },
  {
    "startTime": "00:36:01",
    "text": "Why does it have to be norma? Because you... Otherwise, you're making the pure job of, like, doing proper Rt estimation and Pto estimation, and Spur re transcripts and other things quite difficult. Yeah. So I wanted to make another proposal. So the other way, and that's not what currently used and quick, but the other way to get an estimate of the rt would just send a ping frame. Is that something we could recommend instead? Like, if you want have stable, then you should actually initially use frames to get it on that fast Just it's just my. Yeah. Yeah. We can discuss that filter well. But I I think that and I pretty much in a agreement business of if you keep your this strategy your is relatively stable What will happen occasionally, we said have a breakup of your pass, you pick new one. But that's very similar to what happens when you working an event in the network, And Most pt workers are designed to do that. I mean, basically, the only thing risk is that your Pto will fire a little bit too soon. And you will get an acknowledgement of the Pto. So I think that encouraging consistency is good. And then we have to delay the auto problem which is if you do want to measure Rt, because you are actually interested interested in measuring that path then is probably because you use it in the position controller of some time, and you have to explain how to do that in the concession are going specifications. Okay. That sounds right just it still doesn't clarify Think I mean norma of the language or not for me."
  },
  {
    "startTime": "00:38:03",
    "text": "I I I I would I would agree with you it's should be consistent because if you sometimes send the acknowledgment authority ends of second and sometime after top five ten super per second, you're gonna mess up okay. So if you choose an acknowledgment pass, you should try to keep that stable unless you have a very strong change in the conditions. So I'm gonna jump in here. It sounds like we're kind of arguing over whether that... People agree on the problem, but whether it be norma of language or not. Is a little bit of for debate, which I think it's not the most important part of this issue. But everyone agrees that there's a there's an issue here. And maybe further discussion about what the recommendation should be. Should be. Maybe not having a should or should not. Sort of thing. So I think we can move on. We we can we open have more discuss. I just had one clarification question for you. You said use the same method, but is consistently using the same path to set the acknowledgment or using sort of the same strategy. Because if you use the same path, like a path might just go away at some point. And then you have to pick another path to send the acknowledgement. And that changes. Things. Sorry guys, we we have issues at can you guys take it offline? Thank you. Oh, yeah. Let's move on to the next site. Yeah. For the next size, it's also a github issue but I think that thought is a bit confusing, but we want to say here is that Now we remove... We do not speak past Id anymore. So the past status is linked to the sequence number."
  },
  {
    "startTime": "00:40:00",
    "text": "And and and so if the we update the Cid and the Cid change, we want to also update the past status as it's priest? Or we don't bother sending a new past status as we assume the state the past that status is the same as before. And and the second question is should we also expand the past status has frame to hold information from Cid. I I think we already got the answer. If we want to that we should do that being a separate free. And and the so certain thing is Also, we want to define something that could hold information for future ids. The benefits of doing this is that when you know the the the the the past for the future ids. And when you want to rotate this sag, you can just to pick this id that has a past status that is the same as the current task. So you'll can save you from sending another past status update. Yes. So for this question, any from the audience. Allison regarding Cloudflare. I I think the the should all the information for multiple here this is what Miriam Was talking about earlier here? Yes. I think I don't know like, from an implementation perspective that that would be useful like sending multiple frames versus just send... Like, I don't know if there situations where we might actually want to update many past at plans And then just sending multiple frames is probably just fine. So I'd rather keep it simple."
  },
  {
    "startTime": "00:42:01",
    "text": "Probably. Yeah. So your point is anyway, the past is not send as frequently. Right? So right yes So the the scenario is that you kind of changing your connection Id for whatever purpose for privacy reasons linkage reasons, or whatever, and you might do that on, like, all your passes. Right? And so you have to change the connection id and then you also have to change a bunch of paths updates It's like, not a big issue. But it's like a small optimization. And like, the other point is like you should probably... The situation where active change your connection Id is probably not having have often and might have other consequences. So it's like, yeah. One or the other solution might be fine. I don't know. But I think from from the model that we discussed earlier, I think there's actually no reason to not say in advance. Like, I provide you a bunch of connection Ids and disconnection Ids like can either be used like, for standby by pass or for non standby person, you can, like, define it in advance even if the connect are not used yet. I don't see, like, a big issue about that because it's really about just providing information about the semantics of connection Id independent of the question if it's in use yet or not. On the other hand, I think the only drawback is maybe that you're kind of respecting yourself about how you can use the connection at least in future and so you might need to provide few more connection Id ids or whatever. Speak the mike, please. Like, it's sort of limits how you you can use certain connection Ids like you might change your mind. Later. But you can send a new one. Yeah. Well, unless there's, like limits and then but you said the limit. True. Yeah."
  },
  {
    "startTime": "00:44:00",
    "text": "I think in summary both works and we take it Yeah. So to the github and have a little bit more discussion there, I guess. Yeah. Please with github up and have more discussion there. And next slide, please. Okay. The final issues is do we want an please it past setup frame, the current drive to in the car, we use a mechanism from the quick v one the connection migration we can to set up a new pass and there is another proposal is that we try to have a separate pass setup free But the issue with this pass frame is that you need to somehow include a pass Id into the frame. But as we just discussed, they author already agree to remove explicit test Id in the current draft. And the separate pass set up also D is the design original design requirement to just align with pass creation in Rc c. But we also acknowledge that there might be some benefits of using an explicit frame for example, you can include some past that signal and the past parameters into the free. Those parameters could be something like Max act delay or Max pass idle timeout or something else. Yeah. And so so the the decision we need to make here is whether or not, do we want the the pass and a separate up free. Any you it back for this one? Should we just keep it as in the current draft? Or we want the separate pass that of free. Question. Well my my advice might first leave that Is that some kind of e equal?"
  },
  {
    "startTime": "00:46:00",
    "text": "My advice will be to just leave that for for extension. I mean, I really think that when we have some debated like that we should leave it other the draft. And say if people want to the... After that, if they really want put this kind of things to describe and offer specifying in a bunch of parameters? They should do an extension to quick and present a new plan to do that. Yeah. Yeah. Agree. With christian. Yeah. Okay. Yeah. It seems that we have a consensus. Next size piece. On the next setup, first one is that registration for a transport parameter times and error, And then they're also many opening issues on the github. So they also want to final discussion on the remaining opening opinion issues. And also of course, more implementation experience is still desire. And right now we for my knowledge, I know that we have a couple of implementation by Eric Christians have implementation and karl fare has implementation and we have an implementation at Alibaba. And I I I think right now, we have already for the multi pass draft, we have already solved two major issues one is to decide whether to use a single pack number space or multi pack number space. The other one is about the the past Id. And I think after this, the particle will become relatively stable and maybe When those implementation are updated to the version number four, we can start I'm thinking about Something testing. Yep. That's it. Thank you. Yeah just add to that we... We're making the progress on this draft we we've turn to corner so say there's about love open. No twenty of issues. Okay? So we need to make a bit more progress, But we've done that today."
  },
  {
    "startTime": "00:48:02",
    "text": "Yeah. That's good. So what I'm as a chair what I'm interested in is interest in trying to do kind of rear hack interrupting adventures from the last couple of years ago. So of something, personally I probably wanna do, but if there's any other folks who were really interested in doing at the Max hack, to encourage people to coordinate and collaborate and do things like trying to define drop mat and all of these kinds of things. So we can just Yeah. And add to that I think, especially for some of these hit the ground running. issues like with the acting and the Rd d estimates like that something that could benefit from. Some of the inter interrupt testing we've done in the past with things like connection migration. So thing out issues both in implementation and the spec. So I see Marcus jumped in the queue there. Did he have tried? Yeah. It's maybe not really related the tool. This thing about General comment. So there's an ongoing discussion in Ts. On on multi cars. The main focus on this discussion is on parts use? Which I think also highly affects the multi pass and the question is if this is experimental. Or proposed standard end. And I already shared this customer a quick at the working group on the mailing list. And I think it would be really good of the people who are in engaged multi would also show up in this discussion to achieve a good consensus here. Just a point, we will Okay. Thanks. nice test after this meeting. So please feel free to join and we really want more feedback from implementations. Great. Thank you for your time, presenters Yeah. Come up."
  },
  {
    "startTime": "00:50:08",
    "text": "Good morning. We're getting an update on act frequency, which has made a lot of progress. Since last. Next slide? So this is just in our overview of the frame format. This is to what we talked about last time. We now have rear threshold we discussed last time and there's been a fair amount of work to actually make that readable in the draft? Next slide. Right. Let's go over some resolve issues and then we can go to the one remaining issue. We just discussed we entering Threshold of London. We decide to change or order to rear threshold. A number of P relating to it were merged. I hope now that is reasonably clear what it is and how it works. There are also two examples to kinda make it clearer in case people wanna walk through some examples. Please take a look at this if you've not already and you... Especially if you plan on implementing it and ensure that the text is clear. Yeah. Just something stuck out on the last slide there. Reorder threshold is an eight bit field. One set power. Mean it's it's not a big deal. Right? But I I think we discussed this in London and can someone remind me what we ended up with? I don't remember. I thought was under the impression that we agreed to laurent it because that's what we do in this working group. But I can't remember honestly. I mean, I wanna set it to a thousand. We can also also the draft to make sure I didn't copy paste it wrong and make sure it's not actually aren't because I might have actually made it environment in the slides micro room. Okay."
  },
  {
    "startTime": "00:52:00",
    "text": "Thank you. I'm find that we can do a alright. That's that's that's easy enough. Also an easier way to represent this disabled. It is our. Yeah. Just like I think we decided to make it a environment last time and then I just didn't change this. On dated do. So that would've have been a little bit awkward if it Okay. Alright. Let's let's keep going. Next slide. Bernstein time. So a number of us were changed to sheds. This is mostly done to align better with how Rf nine thousand. Talks about sending acknowledgment. There are few to know there are in Rc nine thousand, but it's mostly about what you should never do. Like, you should never act an acc packet type stuff. There are very few months about, like, when you have to send acknowledgment. And I put two particularly, like, simple, but like, you know, obvious examples, into the the side here receiving point should send at least one x frame when more than this number of aqua packets been received. Again, this aligns with Rc nine thousand. Where it says, you know, our point should acknowledge every other impact. Okay. Next slide. I. To some there were some kind of spur s muscle also about having dealing with multiple act frequency frames? They're also just generally, there was an awful lot of text around this that seemed somewhat necessary so it got minimized. So we kept the fact that the sequence number must be increasing. We do not require it started zero. Because that didn't seem like an enforce must, and it also is not necessary per from a functional perspective."
  },
  {
    "startTime": "00:54:00",
    "text": "That is actually a change though. So if people have a strong opinion that really it absolutely has to start at zero. Now would be great time to this. Okay. Next slide. Are a number of smaller changes, we actually added security considerations, so that's important as well as the end considerations. There's an unnecessary must about births. In general. There was a friday of text in the document that was pretty much du of nine thousand and two, but not quite as well written. So we removed most of it and just kind of said, like, do the thing that nine thousand and says to do this the document doesn't change anything about ours. There some clarification about what the default threshold actually is. We wrote the Transport prime code point because this is not backwards federal. And I guess removed yet another unnecessary must. Next slide. Let's go to the one open issue. So this is the is one act per Rt f. So the current access sender should cause a receiver to send an acknowledgment at least once per Rt they're un knowledge active listening packets in flight. This is not so just similar from what is in Our c nine thousand. If I remember correctly? But in this particular particular case, obviously, this extension allows you a lot more leeway in terms of what you can do with acknowledgment and so, you know, it could be more of a kind of used do properly. I will also note that when Min act which is the value that the payroll said not. Two is larger than Rt t. Say the time granularity is one millisecond and know, you have a hundred micro Rt, you know, probably, you're not gonna get more than one and a lot of circumstances. But what's... What's the assume data any use cases are? About scope of this discussion."
  },
  {
    "startTime": "00:56:03",
    "text": "So the issue proposes to change it to maybe two. Or maybe three or four. There are a number of options. We could do nothing. We can change it to two. We can drop the text entirely because really, you know, obviously, it's in the sender best interest to get congestion feedback that is useful. We can add some recommended values whether it's normally recommended or not recommended. Or we can probably do something else. I believe one person... So this machine open by going. Because we were commented I think suggested. The last option, which is to add some sort of recommendation around like, you know, numbers like three or four tend to work well. I can't remember if... Ka zero wanted that be norma or kind of more just No no, but So speaking as an individual. I'm I think we shouldn't have really any norma language around this. I think it having recommendations or color is okay, but anticipating all future use cases of when people should... Like, the data center thing you mentioned is is I I don't think it is necessarily out of scope because people could be doing this in micro networks and it may not always be reasonable to send or we I don't think we should really be anticipating all the use cases of x. So I would be... I'd be mildly supportive of some color, saying like this is reason to do these kinds of things, but nothing norma because there's no point at all point of this extension is to open up flexibility and acting. Would you like to keep the existing should if we did that or drop the distinction? Would I would prefer to drop it. Okay. That's clear. Thanks. Is Be next? Yes Okay. So I I personally would be fine with any number here."
  },
  {
    "startTime": "00:58:02",
    "text": "But I think I I would like to keep the norma shirt and I think it for the norma part, it should be one per time that's kind of the mechanical lower limit that you really need to kind keep everything working. So I think that is actually a good recommendation even like, that is kind of this lower barrier wire you could easily recommend a higher value I think that's like, still the minimum we should keep in the track. And also, I noticed and I developed a slightly more strongly opinion about this then before I had before the meeting because I noticed in T working group that we actually end in Tcp that we actually have other documents who also use kind of this barrier. I mean, I'm not sure if they use norma of language, but that's kind of very often the assumption. Yes. There there's a very similar document in. And I think they are currently borrowing our our attacks. So whatever we decide here may very well, end up kind of being reapply there just for people's context. Right. Because we hold. So my comment on was that You. I don't have a strong opinion regarding refresh keep the shirt or with the recommendation in some sense, but my point was that probably the only the lowest frequency that we know to work files like four. For example. And I can come up with but cases where it's like well. Are. I think my professor would be if we had to provide some kind of recommendation or weak recommendation, I'd say that just referring the safe file be a better idea that. Rather than, discussing if one would be quit on? Okay. Comments is illinois? Three. So I'm you hear me yet?"
  },
  {
    "startTime": "01:00:00",
    "text": "Yes. That's. Right. Okay. So I think the lowest number that works reliably with any return path which is lots of traffic and potential loss on the return is actually two rather than one. If you lose one the window stalls, if you set one then any burst of box will be extended by the deal any burst of date will be extended by I'm tired from time day. If the return channel has a list of data. Then the ax will get delayed and you'll end up with the same issue that we have in slow start growing the window as you using continually a data street. So having one is actually quite fragile to loss and we haven't done that in It protocols in general. Make the forward performance directly related to the loss or timing changes on the return path. So I think this is a quite a big change in the direction of a transport plot and I would love to see stability analysis if that it would going to go for one I I think it absolutely should be ignored advantage to have something that's stable. I don't think you're building a protocol that's broken. In a center well okay. Then you could say, if you're in a dataset set to do something different, maybe the dex that the case is so different because the Rt t is so small, you don't actually care about stalling for an rt two. I don't know. I don't know about did since. I do know about internet and I worry about this. What you do about three and four well, good work good talk about it, but it's it's a recommendation of what works in practice. You do real tests, so it's just recommendation. I guess as in case recommendation. But I will motivate using norma language, and I would say that two is actually the place where things that are actually stable to white loss"
  },
  {
    "startTime": "01:02:00",
    "text": "Thanks, For. Are you? Yeah. I I wanted to add something. So about the data center case I think this is like this is why we have a short here. Right? I think we should give a recommendation the internet white case, but it's not a mask because there might be other cases. So this is like not something I'm buying to reply to Corey. I'm also not fully buying this part about losing an egg because it's not like you will lose all eggs ever. Right? It might happen occasionally and then, you know, then it does work perfectly this one round of time, but I don't think that's a big argument for So I'm going to agree with individual I'm actually gonna agree myriad on that second point. Like, the the transport is not gonna break if we do this like, so I think should be clear on that. It's not like if we don't back every Rt quick just falls on space and dies. Thing on the the data center. Yeah. I should maybe should cover the Internet case, but I don't think that we should take that for granted and standards documents that we're only talking about things that run on, what we know as the Internet today. Think that's it. Fairly close minded view of what this document should be and what documents should be in general. So I would say that this is this document I think philosophically is more mechanism. It should be less light light on recommendations and recommendations could come in subsequent documents about how to use this brain for the Internet or four data centers etcetera, etcetera? Thanks, man? So none thompson and all of you who are not following the chat. I made a comment in chat that sort of outlines what I think would would be a nice seem to say here. I don't think we need recommendations. Because of the the vastly buried deployments that are out there. I think there are some facts that we can put out there that have fairly well agreed. Among, which is that if you send your racks performance may degrade in in terms of congestion control and"
  },
  {
    "startTime": "01:04:01",
    "text": "and loss recovery and and and things like that, maybe not in terms of your Cpu and the other side Cpu, but that that's of thing. And we certainly know fewer sending the other one taken you can have serious consequences for performance. And isn't any smaller numbers of variety you can have some a negative adverse effect on performance. And We can also say that if you have extremely low Rt and and and stable delay, you may be able to get away with your but don't say anything more on that point. I just wanted to add that the the main reason why there's currently in the document is because it's a shooting in Rc c nine thousand. That might be an argument for removing it from the document under the thesis that we we we haven't been in the in the habit of repeating should cost documents, especially in this one we we had a number of du in us and we aired towards getting rid of them whenever possible. But comment. personal But we kind of... Like, the the whole point of this document is kind of saying you shouldn't apply showed in Rc c nine thousand anymore. So but, like, know that's it's okay. For this particular behavior, I think, well, I and we can we can just cite Our nine doesn't... For this text what we'd like to do. Yeah. I think that's for the queue right now. I'm not that There's a little bit of a muddy conclusion there, but I think we can do some further discussion perhaps on a list or something to Okay. I'm I'm the takeaway I'm getting is our c nine says this, so we probably don't wanna weaken it even if it's kind of maybe unnecessary. And people definitely would like a little bit more discussion."
  },
  {
    "startTime": "01:06:03",
    "text": "Of practical use cases and potentially not quote unquote recommendations, but some some guidance around what values use such as numbers like that have shown to work well for in congestion trailers with relative large That. Thank you. That's all I have. Oh. Once we resolve this, what are we doing next? So thanks You've got to to say and in your updates on the document that mary had joined as an editor to help. Not that's Yes. think? So thanks for doing that. I think we're making good progress now. This does this issue. One was open just doing this meeting by because about error codes. I think that one's probably a quick fix from that point on I think we're ready for working group passcode call. So some folks asked us about that during the London and we've we've strengthened all of the issue keys. So we'll be making the preparations look out for that, and that's gonna be a great opportunity for people to review and and and really take a deep dive into the dock and that the authors know. What needs going? What it needs doing before we can go on and progress this drive? So great. Thank you. I did Thank you very much mary for all of your help as well as motivation to move this draft forward at a bunch faster pace than had been moving. So it would not be where it is today without Thank you. So next up when your agenda is me, I'll be presenting q log in place of robin because he's not in person and at a awful place. So I'm gonna jump up to the big Mic and matt's gonna drive my slides. So, yes, I'm not robin. These slides are no fun. Next slide? Since four five,"
  },
  {
    "startTime": "01:08:02",
    "text": "We've published one set of new drafts. You know, we've got the three documents there's been a small amount of consistency changes in those things. It's not as big as some of the other updates we've done in the past. This is mainly to do with something call the raw info type. What we have been a lot of events is the idea that you maybe don't know what it is. Necessarily like a strong coat because quick so it sensible. You receive something, you know the rough shape of it. And then you can log like the raw error code that you received on the wire, but it's an extension type you would've have ignored it. So and we spoke this out various places, but there was an inconsistency that's been tied up, that's kind of a breaking change or whatever. So something to watch out for if you are tracking updates to your q implementations. So that's got it easy stuff. Something that was more kind of controversial say at the last meeting? It was great to have the discussion in the room with people is is kind of the scope of q log. You know, it's been running on for a while now and people keep coming up with great new ideas and extensions for quick. Know, where do we draw this line of what we include in that document? That just keeps expanding the scope and feature creep of once our documents we don't wanna be doing this forever. We wanna cut some stuff. So The decision we came to is a kind of a auto group is that draw a line at the end of December last year. And we'll try to include everything in that. It's it's not too hard to include some events, but other things like multi raise a whole new set of questions. So some question about whether each extension to quick should think to find its own queue, or we define a key lock draft or whatever. Like we don't wanna adopt the system, and we're not looking just for big numbers of Rf. Got we don't wanna keep doing lots and lots of busy work for basic things. So we'll solve that feature that problem in future. But, yeah, we we have a clear scope of what we're trying to do now and that's what we're working to."
  },
  {
    "startTime": "01:10:02",
    "text": "We've also requested it an early sector review of the security private see considerations while q is more a format and approach collar or anything. Robin presented a lot of the security. I'm privacy angles of things about logging numb data that might include sensitive or confidential things. And and we have a general idea and we think looks okay, but that is a great opportunity for us to get way more input there and just to keep putting things in or clarify stuff where possible. So that that's in flight now. Hoping to get something back. But again, please keep reviewing these things and adding stuff and we've Yeah. And then we continued with on many other open issues and P. Next slide. So so I wanna get into some of these issues because we've got way too many, but a lot the editorial and not that important. We need input on certain other things though. Because they affect the interoperability of q. That's kind of future maintain ability. And then there's some other things specific to the protocol is a group of authors we're not quite sure. So we want the the good feedback this one is about version of q log in the additional scheme. Like I said, we have these three documents, the main sc, the quick sc. And the http should be three and q scheme. But represent all of those things who only have one vision field that the Q version in a in a quick log. Then so the chances for that is that the sc not really tightly couple, We do it as a editorial process. But at some point, probably gonna expect them to need to iterate independently as we address feedback. Kinda coming up to the the end and and I think weird artificial tight coupling is a bit annoying. We could manage a bit, you know, So not even for us now, we want we expect new additional scheme of documents becoming in the future. Around the extensions aspect suspect I just talked about before."
  },
  {
    "startTime": "01:12:02",
    "text": "And then like, this kind of thing that just because endpoint could log in event doesn't mean it it will Like, what does what does steven? We what does the Q version mean? Factory, what we wanna be able to do is this Effectively happen includes at the top of the q that gives you a clear indication, what documents the queue log events are based upon so that a parser has a decent tran of causing them and and and dealing with them properly. Next slide, please. So there's a proposal up in P r two eight four of adding an additional sc set. Just an array of scheme is based on some unique label. We don't wanna have to own that in the sense. So we don't wanna have to create register through for these things. We don't wanna go full Url either there like Xml sc, it seems a bit annoying as well. So the current proposal is just put the labeling uniqueness south to something like the data truck or the Rf editor. So here, for example, additional scheme is including the the quick q. Quick events and the the quick queue quick h three events. Might missed type that I can't remember. But, yeah. The idea is we have the version which explains with the main scheme areas the structure of the file itself and some of the base events that form up every queue log. And then on top of that, the additional things Yeah. Like does anyone have any opinion? Does this sign Small thing to do. I'm seeing one thumb up at the back and I'll take that. So we'll we'll we'll how out some of the final details I'm here about probably gonna be ready to go. We'll make job. Okay. Cool. Back. Naming things, it's really hard. Maybe I should be wrong first because it's one the hardest questions stuff."
  },
  {
    "startTime": "01:14:01",
    "text": "Of the way Q evolves, you know, it's got a queue in there. You could say it's quick. But but it's not, you know, that the main sc is like effectively agnostic to other protocols that could be running on the top. Not defining that now. We're not gonna expand the scope of this or anything, but when we try and Like I just said, look at additional scheme. There might be people who wanna take a queue log ecosystem and then say Oh what would be cool is, like, to apply what we've done here for H three in this analysis pipeline that we're have and retrofit fitted it back to two because similar problems there are similar or we developed some analysis tooling for congestion control and having some of the Tcp information might be similar. And so topped up is fine but the the problem we have is that the categories of of of buttons. So the categories that events belong to a kind of a bit too broad and then they spill into the events themselves. So what we have is these criteria, the connectivity category, the transport the security, the recovery, the hp should speed and the key pack. Looks slide, please. So the proposal is not to rename all of them. Because actually, some of them abroad and that's good, but when they're too broad that's bad. So the the proposal there is just to rename the Http category to h three. And we have things like http frame parts actually becomes h three frame powers. And then when we wanna do h two in the future, if we do. It becomes much clearer that h two frame cars and h three frame piles a different even though they're very similar, there's, like, subtle differences that can creep, and it's kind of annoying. And that was this most one I was just trying to do some net parsing. And things like window manage... Window updates with the management just start different enough, you can't come up with something generic. So that's that's my proposal there."
  },
  {
    "startTime": "01:16:01",
    "text": "And in the discussion, Robin said, well if we're gonna rename that, we might as well rename transport at the same time. So we should move transport be quick. There's all of the events in there are completely quick. Specific. Leave the other names know. This is a trivial fix to do. There's a editorial work doing the docs to to... But beyond that. It's gonna be a breaking change and might be disruptive for implementations, but now seems like the right time to do this. So This is the direction we'll take it and unless we had kind of push back. I'm not saying anything in the room. But if there's any any push going on the list a more or they get have me or so solicit that. Go cheers next slide. Multi pass supports, we have a current plan, so I don't know peak path Id top level field places just can be logged in each of event. It's not flexible. But we have questions about whether that's enough And And we're just wondering do we have a clearer review on on what the needs of those events are people are progressing the multi paths draft. Christians was jumped in the queue. He I could take the option. He's been commenting on this issues. It's just been helpful. I don't know if maybe the the stuff we've talked about the Hack home would help us actually understand there's a community if if if there's then other things we need to add, Christian Do. Jump? Yeah. That's my my general feedback there is that we we should probably wait a little bit before we try commit because we already waited two years since faq was open. So we can wait a little a bit more. And also, if you follow the previous event, We just make sure that we are notion of lu Id which is tied to the connection Ids And so the... Whatever we do in the model should be that instead of"
  },
  {
    "startTime": "01:18:00",
    "text": "Ids we are three years ago. So I would say, yeah. This way to bit Okay. I think that that's a clear signal for me. But Yep. I'll confer with my ko as well. Maria? I I think I agree we need a little bit more experience. But, I mean, I just wanna say we kind of the past so you probably don't want to introduce it again. But the problem we still need to solve was Q is that if you only use a connection Id, it's really hard to map kind of the events that belong together on both sides. So I think that's a problem we need to think about how to do that in an easy way. Alright. Yep. Thank you. I agree. Yeah. The they also issue the matching of events. I mean, if you have things that... We we are going to have multiple numbers spaces. And if you try to do multiple as with the current version of q your glass look like sheet. So so you you really want to have this notion of my space but inside the model that people know how to do with it and even event that says an I get twenty five It's within the numbers space. It's not for the whole connection. And seems like that that that... That's what kind of we have to do. And just to remind people you we have various other fields in you on like, literally stuff that's I'm on the wire. Kind of additional information. So that's possibly some of the way we could model this. But... Yeah. We'll let's take action to just away and keep new on this. I don't think we need an immediate thing, but something we do we wanna"
  },
  {
    "startTime": "01:20:01",
    "text": "provide accommodation for without going full multi. Because someone one wants to do that. Joking. Next slide, please. Cup park. Right. This is great. We've been kind of So Robin, do you wanna respond to the multi part thing? Yeah. If you can hear me. Yep. Just a quick one. Like, we decided to scope. Be everything published in an Rf or At the end of twenty twenty two? Is clearly not part of that. So this would be the only exception that we currently make. To find scope to do anything lot about. So keeping back q is a bit weird. To me from from what perspective. I would prefer just say we don't anything around multiple can drafts and do separate documents later. If needed did... But that's the course. I'll jump in with my response of my understanding is that that the request was that we block the q draft on that, but that we We just keep that issue open a while and until we get a little bit of more deployment experience to figure It. Yep. A simple the simple thing we can add, and we don't need to pick the exact shape of that thing yet. But Agree with... Then and if we can do that by time we want to finish you. That's fine. But if it would go over that then I don't think it should be a blocker. Okay. Yeah. And I think that this is the comment. I made awesome last time. So it shouldn't block a document, and it should go in a separate document. But like, we have to be sure that we have a good way to get it in there. Like, if we for the find q log and then they and figure out like, this did we did wrong we can't, like, easily at something that is needed for Multi. That would be a problem. Okay. Agree with both of you. Well we'll find a way. You back. Yeah. Has been the un child I think of of some of some of the q log stuff. Or just."
  },
  {
    "startTime": "01:22:01",
    "text": "But it's... We again, we took a very don't know what the word is like, looking at this back and saying, well, this is all the stuff this spec just create event for each thing and then you go great. Well who that works pretty well for quick and http should be through actually. The main events you wanna care about packets of arriving and frames in this and that. But the key packets it's potentially less interesting. Not about the functionality, but it's not about the behavior. So Yeah. Like said, we got his current events, but Lu and I'll end up and discussing about ways like, what's actually useful for implement people who were trying to tune nike like, investigate a bug that they might have trying to to doing this stuff. So the proposal here that's that's been written that is that we have higher level events for conditions in the encode, the decoder or the connection level. So we go to the next slide. We have this set of encode events that you've included a field veteran block or you had a blocked session and you've void raf blah blah blah blah. You know? Various things like that. We have decoder events are different too. And then maybe at the end of this the the connection, you have some global stats. For both the encode in the decoder. So got remember, running in both directions independently, but coupled but kind of reviewed people agree with. But thoughts of proposal. Don't think it's a P I think that was just written up into the issue. So I think what person I like to see is that written up as the p r. So we can actually see the of actual data types and stuff that was suggesting. But if the overall shape of this that's okay to people and there's no major rejections, we don't wanna waste time. During the harder work. If people think this is just as not the right approach. Not seeing anything. The the question I did have is"
  },
  {
    "startTime": "01:24:03",
    "text": "is whether this is in addition to the existing key pack events we have or a replacement for I don't know if Luca or Alan respond to that one. Alan From. Intense enthusiasts. I think it was viewing it more as a replacement then And if you look at the for folks who love as I do. Or have a implementation take a look and see what's their So Certainly having, like, the lowest level of events is sort of like the queue log is sort of replacing Tcp dump. Right? So you sometimes wanna see, like, every single bite that went there and recreate that. Header fields often have sensitive information in stuff. That's not what you want. And the reason you're looking at this data is so that you can tune it like You're saying? So yeah. That's one. And and and I guess the other question has I'm sort of interested in in actually implementing these events in our implementation because we've recently seen it Table actually does make a difference in tuning it is is interesting? But I guess, I'm curious if there are other people of q if they would are we just writing this down and everyone's like Cool. Like, that's in the, but nobody implements it or it's something that's gonna happen. I... Personally, I'd be more interested in these high level events, but also having the option to do the lower layer ones too. Like, a lot of stuff in q is like totally optional. What you you feel comfortable, but especially with the privacy security considerations you're right. Some of this could potentially be strike enough that it's Okay? Whereas the that the other stuff isn't, but Yeah. I I think keeping both is good. I would ask for the P that would proposed these properly to also update the security considerations if there's anything to think about so thank you very much for for that"
  },
  {
    "startTime": "01:26:01",
    "text": "Yeah. We can move on. I think. Clocks. This is my issue. A a recap that Like every event in the queue trace has a time. And and the value of that timestamp stamp depends on the format. That the log declared, things have. So Generally, the Uni timestamps kind of implied but they're not mandatory tree. That's what the Speck house potentially, not everyone wants to or can even use you next time, For example, you're on Windows, and you wanted to his Windows park. The spike would allow you to. Or if you you have, like a mono clock, is your base clock and you're calculating a a reference a relative time or deaf delta time. Based on that thing. You have this increment value in your logs. But it doesn't actually relate back to anything. In the physical space. Has come up in in the key implementation researchers wanna take a look at a queue log and try and link that back to some time like, a world clock time that they can then correlate to to other stuff that's happening in the system, which sounds something that's good, but there's the whole problem with clocks and drift and mismatch and all these of stuff. I don't think we wanna try and solve that general problem, but what we need to do is fix q just to make it a lot clearer that if you have just a number that's a delta, we need to state where that delta based on. We can't seamless information. So this similar proposal right now is that we have a field that concurrent an explicit updates in a format. I've suggested iso seven eight six zero one. Could be something different but that's sensible. And then possibly a special opaque tag or something to indicate scenarios where It's it's a mono situation where"
  },
  {
    "startTime": "01:28:00",
    "text": "system booted it up and just pick something as it starting based and then from that point on, you can query it and get some number back. See victor Jun in the? Victor Google. One thing is I'm not entirely clear for me from this Issue should do you. Intend to use iso eight two six zero one for every time sim. Or do you define it once or and then compute time zones relative to that? It would be once at the top of the file or, you know, once somewhere, you know, to to to basically provide that anchor for of these other events which are smaller encoded things. So for example, we have absolute value as potential format, which is the number of seconds since the Uni epoch. So it's It's kind of absolute but it's not really. It's a bit of a mis nowhere in my mind. Sure Robin disagrees with me that. Yeah. Wait to do you allow changing format like of every time stamp or do you just is this for four the time simpler to top. It's the format of the timestamp on every event. Be we only allow that format be declared once for each q log thing. One thing you might consider, is this is something we had a lot of successes list for our logging. We always put one. Okay. We always put one timestamp stamp in the beginning and all of our tencent are always relative to that timestamp stamp and since we use Lawrence, it's compressed six trent out. And it also generally means that you have to solve like the anchor problem only once. Okay. That that's good feedback. I'm not trying to have another discussion with you. Like we to we click he is potentially the serial utilization for what's open, like but the can't you know,"
  },
  {
    "startTime": "01:30:01",
    "text": "serial bar into the wire. That's like, or you can but it. Anyway, who's as a key andrew? Andrew. Plus one to the relative time suggestion, that's a great idea. Precedent on had represent times, do use that because just opaque for something like gl. That doesn't begin to cover all the possibilities for what you might get in there. And even even eight six zero one. Okay. But is it in, you know, t t a I, Ut, Google's. Thing, you know, what what time base was it reference to? Yeah. It we we have precedent for this. Please use it rather than just to go off and do something random. I obviously like, too, if you could provide some references to that. That would be greatly appreciated. On I I I like the idea of having a a sort of he's where we started And well is the epoch for the for the subsequent records. Because we're using something like mono and our implementation, the the documentation always says well, it might drift a little bit. Over time, and it's not exactly one nano a second between each one of the markers that that are in there. You you might find that this is not good for for time keeping and I think this is to Andrew's point. It'd be nice if we could periodically drop. An update to the epoch. In in the the sequence of events. Particularly when your machine comes back from sleep or there's been something going on. There might be relevant in terms of of getting a wall clock time. And that may be the simplest sort of way that we can do it but if Andrew's got some better references for us then I I'd uses. Okay. I think I've hit cunningham all here I posting the wrong answer getting"
  },
  {
    "startTime": "01:32:04",
    "text": "things. But but this is a the big later clock stuff has been something that I've been kind of n on for about a year or so. So This is useful fall in the broader context, and I'm willing to put more more work cycles into that. So that's That's good. Thank you. Of out of time. I don't know how many more slides do we have Ec. This is the last one. Okay. How and why to log in Ec markings? We have different layers of events, the data, like the Udp data, not the day from. But, yeah, That all quick packet events. Right now, we we're very basic. It's just markings as well nothing to do with probing or anything like that. And we have these names all bit van depending on the precise events And I think, you, the question is is east should Ecm probe be covered at toll That's tracked in a separate issue, but this one. Like is it was it okay? With what we're proposing as a solution don't know if I anyone's looked at it. Robin. Please dive in. I don't know much about Easier. Yeah. Robin in of time, keep brief than... Yeah. Other thing I've forgot mention on the on the slide here is for main questions was there, how do we deal with I I don't have enough context on that, but I know they they use something... Is that something that You will reflect or not and let me reflecting is a builder issue. I I would like people who have knowledge about the alvarez, things going on to comment on this. That's basically what we want to say. Yeah. I think I... Yeah. So I think way the best thing here is to follow up with irrelevant people and Okay. Very very quickly. Nothing special about Ifrs it's just using the One point and your covered. Yeah. You can have other L events, but that's"
  },
  {
    "startTime": "01:34:00",
    "text": "sc Anyway, so Ec enthusiasts e and I think should follow up with some the authors and that would be good to have that feedback. Incorporated here. Done? Great. Thank you for your time. Martin. Yeah. Bernstein. We're a little bit over best of that. Yeah. What you doing doing. Okay. Resetting and closing streams. Let's go through the mic. Nice the mac. Next slide. Next slide. Okay. There's two problems. That hit that we could solve. One problem that we definitely need to solve because web transport is relying on on that and the Web transport working group has asked the quick working group to present a solution so they can build on top of it. So the problem is you have a quick stream and you reset that quick stream, there's no guarantee whatsoever. About what the application on the other side will have received from that stream. It could be that that the application has received. Nothing from that stream at all. And it's just getting notified. The stream has been reset. Which leads to the interesting problem in"
  },
  {
    "startTime": "01:36:00",
    "text": "part that you don't know if this is... If this is an Http three stream or if this is a web transport stream, and if so which session would be So it would be really nice if there was a way to say like, to. Okay. The stream has been reset it be belong to this of that session. And there's a a second problem and we we actually discussed this during the during our work on the quick Rf. I link the issue here. So let's say you are a relaying proxy And you're just passing through bytes from an upstream server to a client. And the the upstream server has given you like, a really large content length you've already sent that to the client, and then at some point, the upstream server dies. What do you do as a proxy? Like you you need to somehow convey that error. To the client, so you'll probably send been reset, but then there are cases where it's potentially not desired to lose all the bytes that was server that the upstream service sent before it died. So we currently don't have a good solution for that. Next slide. So there's there's two two proposals around basically. One is the the draft. Which is currently the named reliable stream resets. That I presented at the last F meeting and then then a pull request to that draft, which basically completely writes it into completely different proposal. And I'm calling it and the the Victor proposal here because he's the one who offered that the request. So the the basic ideas that you add basically a payload field to the reset screen frame. Which can be which is a variable length but since this is a quick frame, it has to fit into a quick packet so the payload is effectively"
  },
  {
    "startTime": "01:38:02",
    "text": "limited to approximately one mt. This is pretty flexible in the sense that the payload doesn't need to correspond to anything that was previously sent on the stream. It could be could be something completely different that you put into that payload So it's it's in a sense a a kind of miniature stream that you attach to like an actual quick stream. So this obviously it requires changing changing the Api of your quick stack and depending on how how vertically integrated your quick stack is you might might or might not care about this very much. But there needs to be some method for you to to provide that payload on the sender side and then on the receiver side there needs to be some method to get this payload from from the quick stack. And as I've mentioned before, like, this since this is limited to to one mt we cannot solve the relaying use case. Next slide. So now coming to to my draft without without the P. And as as I mentioned before, it's currently called reliable reset stream. And in a lot of discussions that we had in the last in the last week on the meeting here, we realized that this is probably not the best name. Shows the the name because or on the wire, it pretty much looks like a reset stream frame on the left side, you have what's in in the Rf c nine thousand. And on the right side, it's what what's in the draft. And there's like, this one additional field. So was kind of obvious to call it something with reset stream, but I will"
  },
  {
    "startTime": "01:40:00",
    "text": "as I will explain now, the... When when you implement it, it doesn't really make sense to think of it as a research stream. Next slide. So let's let's look at the sender side. And at the one situation where where it kind of kind of is like, a like a recent research stream. So let's say you have the stream. You already sent like, a hundred bytes and these hundred bytes you really need to get through. Then you send an additional one hundred bytes and now the application is saying like, nope, reset the stream. So what do you do now? You send you sent this frame. With a reliable size of one hundred and the final size of two hundred indicating to a flow controller that there's... That they're only was, like, two hundred bytes on this stream and nothing else will be set. So everything's fine here. Next slide? But now there's a a different case where... Let's say you also need to get these one hundred bytes through. But you've only sent thirty so far. And this might be because you might not even have a hundred bytes of low control window on the street. Could be that the peer only allows you to send fifty bytes and you need to send these fifty bytes before you get credit to send the other fifty bytes. So at this point, you are not allowed to send a frame that says final size one hundred. That would be a flow controlled violates violation. So what do you do now? So so... And and this is where where then the notion of this is a reset stream frame breaks breakdown. So when you think about it, as kind of thin of on stream. Things get a lot easier. So think of it like, this is not a stream said, but I'm just riding a hundred bytes to this stream and then I'm closing the stream as as I would normally and send the a stream frame with a fin. So what would you do when you can send out these one hundred bytes? Well you would send out the fifty bytes that you have for control credit for?"
  },
  {
    "startTime": "01:42:05",
    "text": "And then you would wait for form of flow control credit and then send the the remaining fifty bytes with a fin with then. So you would wait until you've send all the one hundred bytes before you act on on that fin So now this this new frame that we have is more like a different kind, a different kind of fin. Next slide. So what does that mean for the for the Api? On the on the sending side. So this is like, pseudo python code here. I assume you have some kind of right method on the stream. That you that you that the application calls repeatedly to to send out send bytes. And one way to implement this is to have to add some kind of commit method which when you call it says, like, okay. The bytes I've written so far. Other bytes I want to I want to be delivered reliably, if the stream is reset. And everything that I'm I'm now calling right for in in the future, this is the thing that that gets lost. So you need this one additional method. And obviously, there are other ways to implement this. Next slide. So let's have a have a look at the at the receiver side. What do I do? I I accepted the stream I've read a few bytes from the stream, And now I I received this frame that tells me there's there's a reliable size with some offset I haven't received yet. What do I do? Now it makes sense to again think of this as a fin. Let's say you you receive a stream and you'll receive the stream frame that has fin but you haven't received other the data before. Like, they might have been technically ordering on the wire."
  },
  {
    "startTime": "01:44:01",
    "text": "You don't do anything with it. Right? You just wait until the application has read all the data up to the point where the fin is and then you do something with a fit. Like, you you tell the application the stream is now closed. And you do this exactly exactly the same thing here. You would wait until the application has read up to the reliable size then you would tell would tell the application. Oh, by the way, the stream has been has been reset. Instead of it. So it... The the implementation gets gets really easy if you if think about it in that way. Next slide. So what do you need to do on the on the receiving side? You don't need to change any Api. And this is something I really like. Because for... For any application, building building on top of quick with this extension. They don't even need to know. That this is happening. Like, they just read from the stream, they get like, for example, they the the web transport session Id. And then at some point later point, they get told like, oh, by the way, the stream was reset. No Api changes needed. Next slide. So if we don't call it reliable reset stream, should we call it? Don't have any strong opinions here. I've heard some people advocate for stream close, but I'm happy to to bite this and I'm sure we can come up with some name. Or maybe not. Next slide? So this is... To to give you an idea of what it takes to implement this. I've I've implemented this in in Quick. And Ka has implemented this in quickly. For me it was around eighty lines of code. For for the stream state machine changes. And and quickly, it was about fifty lines of code."
  },
  {
    "startTime": "01:46:01",
    "text": "And I have like this this end to end test where randomly randomly reset streams and and drop packets on the wire and just make sure that everything gets through at this as it should and and works and could go and quickly also have chief interrupt during the hack. So it It seems to work. Next slide. So where do we go from here? Should we adopt one of those proposals? So some slight guidance with Chair hat on here. I think focus, here should be adoption of whether the existing draft not saying that that is going to be final solution, but it's spiritually the the solution rather than the going with the attaching a payload to a reset. Would probably have to require a different draft to be adopted. Just to add quickly, like, we we take this as a dependency for other groups in the working groups in the Who would like or who need the speech should to be able to continue that development, and that's what we we've agreed to since Id one home five in discussion with those are the chairs. So please keep that mind too. Thanks. Mike Bishop, as I've said it previous times who presented this. The overall problem is one that is good to solve. I like this approach. Not wild about closed stream, but we can paint the back whatever color we want. Mostly because that is the specific term we use our actually nine thousand for sending event. Closing the stream. Question? I have one I the one is the happening lot is people dealing with the risk condition. Between the reset and the finger. Has seen an application as set"
  },
  {
    "startTime": "01:48:01",
    "text": "we say short message on And then believes that he has not been yet say, hey, I want to cancel that and then reset let's see. Yeah. But this thing it's a different issue that you're are not in but I wonder whether so you have to send an issue of great recognition between the initial. And the short finger. And by the way, short fin might be good. Alan out. I I'll try to keep this quick. I have a bunch of thoughts about it. So when we first were developing quick, we said, we're not developing partial reliability features. We kind of lying because resets stream is our partial liability feature quick. It's basically saying, the stream is unreliable starting at offset zero. And so you you think of this as an extension or you can do it the other way we're this is defining. This is taking a stream in dividing it do reliable half and an unreliable half at the office and stream is a specialization. That offset is zero. So I think my... This is easy it solves a problem that we have right now. But maybe we haven't thought holistically about is this part of the what this group wants to provide is a partial reliability surface. For quick. If we do add it as a partial liability surface, I think we need to make sure we also raise that surface in web transport. Right The web transport Api needs to also have this capability. Because least in my opinion I view web transport as an extension taking everything in the quick Api service and making it available in web. Hold on I a couple."
  },
  {
    "startTime": "01:50:01",
    "text": "Things that I'm not remembering. Oh, there I'm a little... There was... We talked to also about the ability to send this without an error code, and I'm didn't mention it here. So I won't spend too long on it, but I think that's super dangerous. For reasons, but you can take them for later. I'll jump out to the case lot people. Maybe I can respond quickly. Yeah. I I've I've avoided calling this partial reliability because when people that different notions of partial reliability. Right? That's that's the the the most general case of like, I have the stream and like, this part is reliable in this part reliable and this part is reliable, but everything in between isn't. And didn't want to open up this discussion because I think things get a lot more complicated. And this is obviously more than we need for for web transport and more than we need for for the relay case. Yeah. But I'm I'm I'm happy to concede that this is a step towards full partial reliability. David's its Brake shed Enthusiasts. Speaking with my web transport, chair hat on. What transport has been taking quite a while. I'm starting to wonder if w three is gonna publish their Api before we can publish transport underneath that. Let's not have a repeat of webrtc plays. This is critical to what transport we can't ship without it. So I would I would say I'm hearing a lot of good questions, like what to do when there's also a fin, what should we have in error code? These sound like great questions, to answer in the working group. So my personal opinion is, yeah, please adopt this. To everyone, if you have questions like this, please save them for once it's adopted and let us know if you think we should adopt. To, like, help move this forward and block web transport."
  },
  {
    "startTime": "01:52:04",
    "text": "And on the question of the name, I could not care less. Make it so. Under ga Cloud. So it seems there a problem to solve and this is a reasonable solution it's great to see that there's already implementations of this So, yeah, we should definitely adopt this. And then we can then spend the next... I don't know five years Deciding what to call it. I I agree that should this I just want to say that for the relaying case, you're a quick discussion. We saw at least to implement interested in having this kind of fix. Victor of. Is I for naming, I would the way Async think of it it's it's reset stream add as an reset at certain offset, that's the easiest way for me to... Right. Understand it. I am personally fine with either approach provided they work it sounds like what happens draft works, Thanks that's. That's for me. Yes. Doc. I like this better than the payload option seems more general of course the payload option has limitations on it that have come back here. Do you think we need a one stop sending. Please send me the first fifty by of the stream, but no bother with the rest of it. Let's not talk about that right now. A good question. Okay. So the... I think we're in a position where we're going to"
  },
  {
    "startTime": "01:54:01",
    "text": "make an adoption pull thingy here. Right now just to confirm what we're hearing at the mic that It sounds like we're supportive of adoption, but let's run a quick pull. Basically should we adopt? Without caring them about the name? Yeah. Please raise your hand if you're in favor of adoption. You can if you wanna just for for all time sake, but we're not gonna ignore it. Yeah. That's that's. Okay. Yeah. That's good enough. But I think we're we're gonna we will follow up and make an adoption call list. Thank you everyone for participating in our discussion. Just for the record, the the last kinda I saw on the screen was thirty eight raised hands to zero. Do not raise times, which is pretty clear signal. March. Would you like to come up? Did have more time from margin, unfortunately, like come on should have run on that, but we we got the answer that we needed. So appreciate your patience there. Yep. We'll share the slides now. But yeah, if if you have any questions on this, come and and continue the discussion with us, I think. Yeah. I, I'm imagine on a Employment was italy and this is joint to work with you ask and Thomas. Next slide, please. So Yeah. All this is based on the research page"
  },
  {
    "startTime": "01:56:03",
    "text": "they actually also presented yesterday g, but I will not talk about the measurement setup up and our methodology today. I just want to talk about the quick challenges that we identified and basically the purpose today of this talk is to get feedback from the quick experts here. About the challenges and to discuss different options. So next slide, please. The first challenge that we saw is that large tls data triggers multiple artists during the quick hand. Next slide, please. So what, I mean, by that as I think you're familiar with the quick handshake process basically, the client sends an initial message server dan restricted to three times the bytes that received from the client And this is basically an anti amplification mechanism and then the client acknowledges this data. And only then the... If the this data left, only then the service allowed to send rest of the certificates tls less data. And this what call in multi arctic handshake. Next slide, please. And unfortunately, based on our measurements of around two hundred fifty thousand quick domains, we saw that around thirty eight percent of quick domains actually exhibit the multi rt hand. So the design one R in the wall has not really been met. Like So just to give you a quick overview we looked at the reasons why this multi rt hendrix happen while we have a lot of Tls data and One of the reasons is actually that we observe a long certificate change chains and especially non certificates quite large So in this plot, for example, see that the intermediate note certificate gets which are gray. For example, for cloud zero around thousand bytes then you have a longer chain from Le Encrypt. And they quickly end up. So we have of change of around two thousand three thousand bytes."
  },
  {
    "startTime": "01:58:02",
    "text": "James guy clarifying question quickly. Yeah. Hi. David Con here. No. I can't say certificate so I just can't. When you... In in your previous slide when you measured and for this measurement, which is by percentage, is it percentage of websites that you hit from one client. Yes. Okay. And did you consider that when you hit those websites with a second connection and you have... Did you measure whether you have the is validation token to solve the amplification factor. So for each connection we basically later triggered a new quick connection. That's what we did. I buff from scratch without a source validation token. Okay. Thank you. Okay. Can continue next slide, please? So with a love Tls data and we checked for our future quick extensions would will actually make this situation even worse. And I looked at three parts draft, so There's for example, multiple path trough which currently set one single connection. So we have to quick and check and then that's multiple paths these paths do not create a new quick connection. So This is basically the same challenge. The situation will not be worse. Then there's the version negotiation draft for the versions. Also this is the same situation. Basically, it only prevents the version negotiate tickets before, But afterwards, we have the normal handshake process. So same challenge. And in the end, so we're trying to make the Internet quantum to improve from the future and are different approaches to this, but for example, if we look at the hybrid design what I saw there is that be mix or use both secrets conventional and phantom secure runs and this adds data. So there's there wasn't"
  },
  {
    "startTime": "02:00:00",
    "text": "aws and implementation for example that used around eight hundred bytes more. So for this case, situation will be even worse. Next slide, please. We have seven people in the queue. Think That's so many questions. Okay. My understanding that because from crypto photography and the tls would also make the client hello so large that doesn't fit into one packet, so you would need to send two initial packets from the client size client side, which actually solve the problem. Okay. Yep. Alright. So basically, this is my first observation here quick designed for low latency, but we observed a lot of multi Rt due to sort sizes and two questions I had here for example is should be encourage more tls specific compression because we saw a lot of server implementation supporting this, but clients actually struggle And another question would be, do we need something like doing practices for Tls and quick so that we plane how set that should be configured to to reach the one. Yeah. Next slide, please. So the second thing that we observed was that in case of incomplete time strikes actually, there is no efficient reasons strategy to. And what I mean by that, I will show in the next slide, please. So, basically, Fine. We use the client that only sent a single packet the initial message. And then the server response and our client did not react anymore. And then we observe what's how the server behaves. And what we saw is that several implementations actually keep on sending the initial ent messages. And by doing so, they did not even back the anti amplification limit. So Next slide, please."
  },
  {
    "startTime": "02:02:03",
    "text": "Next slide maybe. And this is just an example, but for example, we scanned the meta part, so we analyze their implementation there. And again, these transmissions should adhere to the reacts limit, but what we saw they did not and the around half of the handshakes were around five x and another half around twenty x. We also so three x. We res this two months later and the situation improved next slide, please. But it was still around x. So it seems like we still are above the enter amplification limit. Next slide, please. So to conclude the second observations we saw that three easily contribute to reaching education limit simply because we res resent the the bulk of of large deal data. So my question would here, do we need maybe some kind of another strategy for incomplete handshakes until the clients was verified So maybe the the server could recent data once it fits into the anti application limit and then changed another mode, but he may be tries to probe the client to verify the client with small packets. So for example, pink frames or something like that. We we have a couple of people in the queue on a response. We're time more time but you wanna say something. Say very quickly. So the value of three was chosen basically completely arbitrarily. When we wrote the specification. Could have been to... Could have three could have been four. Could have been five. I I don't really care. So as long as there's some limit, that's not like fifty or a hundred. Any any bug report that's like all your implementation that's forex x"
  },
  {
    "startTime": "02:04:00",
    "text": "and the rc says it's doing three x's like whatever. We are over time. We're probably gonna get cut off and boot it out. So her. You got something to say. I hundred give for the presentation. I just wanted to point out that don't have a limit on the client side. It's, which is more than more like ten packets. And there's way of tracking clients to send packets to certain locations that you want to. So I don't think so. Something we have to hold it. Yeah. So I think anyway interested, I'll also check out margins map g doc, which covered a lot of same topics. And if you're interested in doing standards work in this area. You know, feel free to publish, or also collaborate. And thank you everyone. For attending the quick working group. Thank you Thank you. Watching. But, like being on the Okay. That make As let you do it now?"
  }
]
