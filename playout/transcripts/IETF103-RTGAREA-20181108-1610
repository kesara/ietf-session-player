[
  {
    "startTime": "00:00:36",
    "text": "good afternoon this is the session you were all looking forward to not just because it\u0027s the last session of the week but because it\u0027s the routing area open meeting I\u0027m just gonna wait for someone to close the door then you can all person to applause and cheers and everything else nothing there we go thank you okay so welcome to the roadie rubbing every open meeting thank you I am Alvaro this is Martin and that\u0027s Debra so please don\u0027t get confused Bob okay I\u0027m the other guy yes so just to make sure yeah okay so this is not well even though many of you think that you\u0027ve seen it many times please look at it again first of all because I\u0027ve seen many working groups show the all-russian of the note well this is the actual right version now this version talks about intellectual property yes just like the old one also has pointers to things like the code of conduct how many of you were the ITF plenary last night okay maybe six of you so there was say a long set of people too many for my taste one is to many honestly who came to the microphone to talk about not the best conduct in the ITF people being attacked directly people not being given the chance to express their opinion and sort to explain their ideas and so it\u0027s important that we understand that that is obviously not the way we should behave in the ATF I have no specifics or no knowledge of anything of this happening in the routing area but you know it\u0027s important for us to to be on the lookout for that especially for the chairs as we conduct our meetings to make sure that we give everyone chance to to speak everyone a chance to present their opinion defend their proposals you know whatever they\u0027re doing and that\u0027s the other reason why again this is the note well it\u0027s important because it talks about intellectual property and some of the links at the bottom are about for example the code of conduct and the anti anti harassment procedures in the IETF "
  },
  {
    "startTime": "00:03:36",
    "text": "so please make sure that you read them and you\u0027re familiar with that there\u0027s also some links that we have here for other materials in the routing area as you can go take a look at absolute meeting there\u0027s blue sheets are going around somewhere is anyone on the jabber room by any chance can someone please get on the jabber room just in case we have someone thank you drew well there we have several people remote if the remote people are listening which I hope they are yes you can use if you have a room if you want to say something you can also come to the mic and we\u0027ll see you from here and we can let you speak as well so here\u0027s the agenda we\u0027re going to talk about the area of course first then we\u0027re going to have the routing directorate report and then we\u0027re going to have an update one year later of where we are with DC routing work and then hopefully at the end we\u0027ll have some time for for any other things that you guys want to talk about so as always we want to request that you review documents we s3 and the rest of the is you have to read everything and sometimes it looks like the documents were not reviewed properly in the working groups you have the routing area Directorate which does a lot of reviews and it helps a lot but please make sure that the other are people reviewing the documents through adoption and that last call and discussion if you need to grab volunteers or volunteer someone please do that to make sure that the quality of the documents goes up as much as possible Tony 20-piece the first comment so I was like no I was thinking that the Shepherd\u0027s were mildly useless I completely changed my opinion disrespect their excellent no I know specifically in this respect right if you get a volunteer especially your guy he will just come through this thing thank you thanks really good comment separates are not only supposed to review documents as well as the chairs they\u0027re supposed to also Shepherd that\u0027s why it\u0027s called Shepherd the document through the rest of the process so if you\u0027re a shepherd remember that your job doesn\u0027t end when you fill out the Shepherd right up that\u0027s just the beginning right you still have to go through the whole process in case you know there\u0027s some stick up with AG or you know some review later to you know help the authors go through that yes we want everyone to do reviews right we expect shepherds and chairs to do it but we want everyone to collaborate I mean this is why we do working groups right we don\u0027t do in the visual documents the the product is the "
  },
  {
    "startTime": "00:06:38",
    "text": "product of the working group not just with the author\u0027s one of the things that we notice is we\u0027ve been reviewing documents is that not all of you are aware of the new changes that came in in RFC 8174 RFC 21 19 is where all the normative language is explained must and should and all those nice words there sometimes is confusion when we use capital letters and non-capital letters in the text and so 8174 clarifies that this is the whole text that changed from 2119 which bracele says that when you use capital letters they mean what 31:19 says if you don\u0027t then it means whatever the dictionary says that that word is right it also says something else that is important in that not every specification to be normative has to use 29 18 21 19 keywords but you can still make a specification normative and clear without necessarily using those words so just the action here is please make sure that the documents don\u0027t have the alternate 119 boilerplate that we use the one at the bottom here that lists the key words it also makes reference to BC 14 which is 21 19 and this new RFC 81 so 84 we\u0027re always looking for feedback please talk to us about ourselves talk to us a lot each other you know anyway you want to provide us with feedback of things that we\u0027re doing well or especially things of me to improve please let us know this Center of the year is very important because as you know the NomCom or so I hope you know the NomCom has been interviews for routing at the replacements because Debra and I both expire at the next IETF so please go talk to the NomCom they\u0027re still here there\u0027s several of you in the room who are part of the NomCom Carlos you guys stand up so they see you Victor it said no one else and I\u0027ll come here I don\u0027t see you but in case you want to give feedback you can talk to them you can go to the webpage data tracker slash mount come slash 28:18 and provide feedback there the feedback can be anonymous if you want to I\u0027m sure that you can tell them and give them an honest feedback and that they can anonymize it for you as well usually they use that not only to make the selection for routing ad or for any ad in this case but they have been doing for the last couple of years they have given us feedback and what the community says so that we can improve so if you "
  },
  {
    "startTime": "00:09:38",
    "text": "don\u0027t feel like talking to us directly especially bad go talk to the NomCom and they can\u0027t take care of taking down into consideration for selection and to give us feedback later also this is not just about about any of you once we get feedback about some other ladies you can do that if you want to get feedback about the whole ASG you can do this well the feedback is important because we are of course a community yes and there were just remind me the other slate that\u0027s out there is the IAB and there\u0027s also candidates for the new IETF LLC and the ATF trust if you don\u0027t know what those are please go to the plenary next time oh the other thing they will say here is that we are always on the lookout to grow the leadership talent inside the area it was important because we the three of us are probably not going to do the ad work forever the chairs change once in a while so we\u0027re always looking to to find people who can do those jobs are willing to do it this time unfortunately 80 percent of the candidates for outing ad declined the nomination that means couple things it begins the head there was a good pool of people that were nominated you know ten nominees were outing it he was was a good poll but a tips on the client which means that only to accept it and there\u0027s two slots so yeah you can do the math you can add now that doesn\u0027t mean that it\u0027s an automatic selection the NomCom is going through the process anyways that\u0027s why I invite you to go give them feedback because if we are not the right people or especially if we need to improve right you know please let them know and the two people that accept it of course never and I so we\u0027re going to a third term I don\u0027t know many a these who go past a third term so we need to keep that in mind right for the next time and hopefully we have a lot more people who accept nominations the next time around so the area status is really simple we closed one working group we finally finished work insider and we published all the RFC\u0027s and weari chartered one spring we don\u0027t have any new work since the last idea this is the distribution of working groups hopefully you all know who your responsibility is we routinely meet with the chairs and about once a month or so at least two or three times "
  },
  {
    "startTime": "00:12:39",
    "text": "between each HF there\u0027s a lot of different things we do training sometimes we talk about area things we have obviously your management type stuff you have always loved this meeting because we used to give updates of the working groups we used to lighten up all the chairs that everyone will give a two minute update of what they\u0027re working was doing this year at the start of this year we changed that a little bit where we have been using some time to you know socialize a little bit more which was at the first ITF of the year when we had the routing ad change when idea was replaced by Martin and we\u0027ve been putting the status updates from the wiki how many of you know where the wiki is okay how many of you who are not a chair know where the way he is okay so we figured that you know the the wiki has been useful but probably not as useful as we would want so in one of the last meetings that we have the chairs we talked about changing the the audience that we\u0027re making the the updates for so what we hope you start seeing now is a status update on the page of the data tracker working group yes so you should be able to go look at that and get an update so you know or more importantly so that external people maybe people who come to the ATF too much maybe people who are not participating in specific working group but do come to the ATF get a sense of what the workgroup is doing what are they interesting things that are going on so we should start seeing that that now this time we\u0027re running this is an experiment we should still see the updates in the wiki which is the last link there at the bottom so that\u0027s that questions comments nothing okay everyone still there the other thing that we\u0027ve been talking to the chairs about and I actually heard it mentioned in a total of two working groups that I attended this week we\u0027ve been talking about implementation requirement policies this came from a question that was brought up at the plenary in ITF 102 where it was asked about implementation requirements in the ATF as a whole Thanks or the IAG had discussed that and we decided it was really hard to have one policy for everyone so we decided that this would be better served working by working group there are working groups that already have policies everyone knows that everyone in the ATF actually knows about ID arsh policy which is to interoperable "
  },
  {
    "startTime": "00:15:40",
    "text": "implementations and there is documentation of that on the on the wiki as well in the earlier wiki of them plantation-style etcetera but not every working group has an implementation policy so we have asked the chairs to go and think about that to consider what the implementation requirement policy for their working group is so we hope that this soon will come up in a list near you for that discussion this doesn\u0027t mean that every working group should require two implementations for interoperable implementations or anything like that this means that we hope there is a policy for the work so the work group may decide that the policy is five interoperable implementations may decide to may decide one and may decide that what we want is a RFC 79 42 type section and the RCS or in the drafts it may decide that there is no requirement there\u0027s many reasons but we want this for the chairs and hopefully in connection with their working you think about this and considerate so that you know we can actually articulate what that policy is I hope the working participants or by you anyone else who is or by you know a sir it\u0027s ever so Stewart you surely the name Stewart III didn\u0027t realize he\u0027d put it there but I was really worried that one size doesn\u0027t fit all in any working group so whatever your policy is you need the chair exception or the ADA exception or something or other because you know you know I\u0027m there are always cases where it\u0027s an information about something or it\u0027s a correction that everyone knows needs to be had or whatever there always needs to be an exception are you in history and that\u0027s part of the policy writing down that exception mechanism I believe I think it\u0027s so universal it\u0027s a uniform that it probably would apply to the whole area regardless of what the current chairs think because sooner or later they\u0027ll discover there\u0027s some some reason why they need to publish an RFC and they may or may not yet be any implementations of it early also but it doesn\u0027t it doesn\u0027t hurt to write it down explicitly okay yeah so there\u0027s been several suggestions of where we can put this it could be in the status update it could be somewhere else on the on the air tracker itself some worker groups "
  },
  {
    "startTime": "00:18:40",
    "text": "have a wiki page when we discuss this with the chairs someone\u0027s just so that maybe we could even make it part of the Charter so one size doesn\u0027t fit all and the ten here is for everyone to have a policy you know we are the IETF we will need an order code so you\u0027ll be good to at least substan what the policy is there are many reasons why we may or may not require from the protocol that we\u0027re that we\u0027re developing the market that we\u0027re serving the type of industry you know many many things why you would want or not to have requirement implementations in your working group okay so now we\u0027re gonna go into the routing Directorate report it\u0027s going to be John or Amy [Music] just to let folks know I\u0027m John has told us the very bad news and he\u0027s stepping down as pce chair and also for for this so actually we\u0027re on the lookout to help somebody to help Amy okay so if anybody would like to to step up to this to help out they can tell you what it involves and we\u0027d really appreciate it and we thank John very very much for everything he\u0027s done for us thanks Deborah okay so the ransom to rights report and it\u0027s Debra says it\u0027s my swan song for this role so I\u0027m one of the coordinators Amy is the one you want to give away baby yeah so just to remind everyone what the Directorate does there\u0027s a panel of last time I counted 49 routing area experts who are awesome people who freely give their time to help the ADEs in processing all the many drafts that we have to go through in the routing area they\u0027re appointed by the ADEs they\u0027re the purpose of having a Directorate is basically to ensure quality of the drafts so we review most of the routing area drafts as they pass through ITF last call we will review from time to time other routes and related drafts at IETF last call as well if you\u0027re a working group chair you always have the opportunity to ask the Directorate to perform an early review of any draft that you have in your working group it\u0027s useful particularly if you feel that a draft needs more review and you\u0027re not getting that review inside your working groups to get some eyes on that from the Directorate and from time to time but "
  },
  {
    "startTime": "00:21:40",
    "text": "the rector will assist the ADEs in making judgment calls about particular issues although that hasn\u0027t happened for a while you can find out more on the public e I got some stats to show you these are the stats for 2018 cover the whole year so the graph there on the Left shows the reviews have to come in and reviews the blue column shows total than the orange shows the reviews that the 80s sent to the Directorate and the gray shows the reviews of the chairs sent to the Directorate and and you can see but at the start of year we had a lot of reviews because for chair of the the 80s of a keeping is very busy with with 40 reviews of the ITF 101 period that\u0027s tape it off from the ADEs in the next two periods but the the chairs have increased for load that they\u0027ve been putting on us so it\u0027s nice to see where we\u0027d be getting somewhat early reviews requests coming in from the chairs I\u0027d like to see more about because I think it\u0027s actually useful but when Dawkins comes ITF last call of the Directorate have already seen them then we already have someone ramps up on the draft and the draft is presumably already had the benefit of them looking at it but the graph on the right shows which working groups have been sending reviews to us and as you can see there\u0027s a mixture of working groups that don\u0027t send us anything and working groups and there\u0027s quite a bit but actually most of the reviews or probably nothing like one third of reviews come from outside there at the razzing area altogether and certainly no one working group loads as much as the rest of the ITF so few more stats what do we find in our reviews the graph on the Left shows what do we find when we actually review documents from inside the area well half of those documents we find issues and occasionally we will send the document back through the working group and say look this is not ready where there are major issues and we don\u0027t think it\u0027s ready to be published obviously that\u0027s the chairs in the ad to really decide what happens to the document but it does sometimes happen it must the three-percent slicing the pie charter sometimes we just think that reviews are perfect and the rest of the time we\u0027ll find some needs but nothing to block the draft part of the right is the same thing but for drafts coming from outside area so again but pretty similar I think that generally we find slightly fewer issues in those sorts of drafts probably because of the background required to review them in depth but but we still do a pretty good job of haunting out issues and one thing I think is interesting is of these types of graphs are quite stable across time so I was looking at a presentation that I did one year ago and the pie chart I showed there and they pretty much look the same as us in terms of the distribution of issues or not "
  },
  {
    "startTime": "00:24:43",
    "text": "clarifying question I mean it\u0027s as in ID myths or are they nits as in minor trivial comments yeah thanks to it they on this as in editorial and or minor comments which would know a lot of Blocker publication we think you know fix this in passing no that\u0027s fine yeah so that\u0027s it so yeah summary the the rate read do do very useful work very good at finding issues please use them as much as you can thank you so now we\u0027re going to go into an update on that they are Center routing work so if you remember a year ago we\u0027d met in Singapore and in Singapore we had a a bar about DC routing the intent of that bar was to talk about the requirements and potential interest of the community in working on new road and proposals to be used in a data center that both we asked you know how many people are interested in a couple of the represented there and the other thing to be interest in that so now when you\u0027re later would want to do is provide an update or where we are and also at the same time to try to renew the interest in these proposals and you know people participate in the work groups as well so we\u0027re gonna have an update from Ella\u0027s VR and from rift on where they are and what the thing was G is about so Gunther I think this one percent this one hello everybody so what I\u0027m doing here besides freezing is you know coming to the realization that I\u0027ve been blessed to entertain you all with my you know least eight victor routing you know technology so indeed we started this journey about like you know about a year and a half ago when we start to explore this space and about a year ago we started with like you know think about charging this this particular rocking group so I\u0027m gonna be covering like you know more like you know what it is about and some of the topics which you know keep us like an old you know kind of warm and where we are right now with the working group so initially you know when the working group actually got started I thought I gave is a very clear message actually said like okay guys you have like one year to actually you know deliver like a set of documents and after the year I will actually assess how well you know everything actually "
  },
  {
    "startTime": "00:27:43",
    "text": "has progressed and if to also understand if you like any real major you know gate stops or something like that and then we\u0027re gonna see you know what will be happening and afterwards with a particular work so I think at this point in time so the actually you know that gave us like the scare of our life because it meant you know one year to actually do anything in the idea that\u0027s quite dramatical you know challenge so one of the things we were you know let me see if I can get okay so one of the artifacts what we realized is that a lot of work actually is happening each time you know when people go towards the ITF do a lot of work and then it\u0027s like nothing and then you go to write you lot of work again and there is nothing so knowing out very short you know timeline what we had available we said okay you know in between IDs we have to do some interim meetings so that is what you know we are doing also and and so you know from what I\u0027m seeing it really helps well in keeping continuous evolution actually in your deliverables so if you\u0027re not doing it actually I would highly recommend you know to really start not thinking about it it really brings you know progress in the work you\u0027re delivering so initially when we started you know our journey in the data center you know we were just trying to understand you know why is data center routing different from any other kind of environments now about a year and a half year ago we actually did some you know some further analysis about it now I think about like a week week and a half two weeks ago there was an anode meeting and actually it was a very good you know overview by by Tony Lee and by Chris Martin on white data center you know routing environment actually has some slightly different properties than routing in the traditional you know one networking environment so it actually speaks about some of the problem and of problematic since wards now at the same time this presentation also has like some no interesting comparison between the different kind of mechanisms so I put the link in here just you know as a background set of information so going to my agenda I have about like 120 slides have about 30 minutes so I\u0027m trying to keep up with everybody here huh so also you know just be aware you know make sure you know I am the chair but I\u0027m not the smartest person in the room it\u0027s like it would be half if there would be any person here with a very difficult question then we have like smart people that mean room actually wrote those particular specifications so they were actually you know give you the answer and the one thought actually I will give you is that you know the one thing that is more scary than a question is an answer so think about that one so there is something I\u0027ve learned you know my journey here at IETF some very smart people here so my agenda is first to actually go over like you know where we are with you know least I depicted routing so what our milestones and an embedded we are I know what are the deliverables then I\u0027m gonna give like a very high-level overview about like you know what is the technology about and "
  },
  {
    "startTime": "00:30:43",
    "text": "then at the end something you know I only have like one slide because I didn\u0027t really know you know what was going to happen exactly my working group today because you know every day is a surprise and everybody it\u0027s always like a miraculous kind of thing what happens unite your working groups so now I know I just lost it so and that\u0027s still alive so let\u0027s go on so this is where we are we started in Singapore a year ago we are almost at the end of our journey at the next ideas we\u0027re gonna not really you know try to assess know how stable is our specification where are we and you know and also try to understand like you know where is the you know growing interest in you know from the people you know applying these kind of technologies so going forward we have like one in two incoming and then at the end you know ITF 104 in Prague you know we\u0027ll see you know what\u0027s going to be happening yes so so from a milestone perspective we only have a few because we only had a few months work to actually you know given to us to work on these things so the main thing is we have an applicability statement like you know we\u0027re you know does it make the most sense to use links that vector routing how can you apply it because there are like different kind of you know application models you know how you can\u0027t really you know use this thing and then we have like two other deliverables you know it\u0027s like speaking about like you know how to use links as Victor out of extender to Dykstra and how to use link States Victor you know distribution using BGP transport so the last two we put into one single document just you know from a simplicity perspective and from a readability perspective and also because you know we already had like some work you know you know previous alternate space so it seemed as a logical thing to do you know to progress the work forward because we only had like limited amount of time we also were given the task to actually look into yang and so we\u0027re waiting a few dependencies there on some other working groups to to progress also once that is done or more stable we\u0027re gonna keep on progressing at work also now the good thing is that there is some sort of an ambition to keep this thing living because March 2019 was kind of like our deadline but this deadline for this yang thing is like in July so it sneaky done at the door a little bit so we still have hopes so looking into the LS of your components so the way we see link state vector routing it\u0027s sort of you know exists sort of like four different you know areas here so the first one if you look at the ground you know at the bottom one is like each router yeah and I need to describe itself me to describe these neighbors and B to describe the cost of artists neighbors and it\u0027s actually I saw you know assess also some other attributes to it but the minimum set is like Who am I who is my neighbor and I\u0027ll do you know what is the cost of arts my neighbor so you need to harvest that in some sort of a way so that is something you know which can be done via and our whole set of different protocols we have been you know discussing the solution space for that the different protocols what actually are out there "
  },
  {
    "startTime": "00:33:43",
    "text": "the two most you know obvious ones which actually provide us the right hooks to that information would be like you know link state over Ethernet or lldp and right now you know in the in our working group you know we actually are going to start a working group adoption con for the link set over Ethernet elements so from the moment actually of harvest that set of information you need to encode it into something so and the way we encode it you know we actually encoded into what we call like link state vectors so this actually is just you know an encoding you know mechanism to describe you know the router itself with the neighbors and wanted to post well if the neighbors as a minimum set so you can actually compare this as the same is like you know really nice yes like a link set packet or like you know SPF you can actually compare the two links that you know total as a basically so that\u0027s what you\u0027re doing now the mechanism what we are using a link state vector routing because we are you know looking very close into like you know in some previous art and what worked actually well and what actually can be scrapped already so we don\u0027t always have to reinvent the wheel so we say okay you know for these kind of things we just use like bt pls encoding it\u0027s very out there it\u0027s proven everybody knows how it works and from my experience we can grow it as big as you know whatever it\u0027s like you know a big massive thing we can do it whatever we desire right now our desire is just put like only a few things actually into it that is just the encoding now from the moment you describe your router you link state vector you need to distribute those things I know those elements of the router between all the and routers in the environment so that is actually our floating mechanism so the way we are doing that and so each link state you know victim can be reflected as as an NL or I and so it can actually be distributed by BGP and that\u0027s what we\u0027re using so in our case we are just using BGP as a distribution mechanism now again from a link steady vector routing perspective there is only one of the choices why do we use BGP I will explain later on but right now you know it is seen as you know something which is out there and it seems to make sense at this point in time from a time to market you know perspective and it seems the correct thing to do at this point in time now at the end so the only goal is that each router will actually have the links that the vectors from all of the other relatives in the network environment so that actually means each router will have like a full view of topology just the same as if the router would be like an ICS route that having all the other space you know the topology looks like and for that moment onwards you can actually start doing dextra and if you do the dextra the end result will be your routing table so that is where we are so that is you know what is happening and for what you can see to top things here you know in the red square i should not really use red because red means bad in this case it\u0027s a good thing is actually what we call like links at victor out using bgp SPF so it\u0027s a very high level you know overview it\u0027s reasonably simple "
  },
  {
    "startTime": "00:36:43",
    "text": "so why are we using bgp because bgp is probably one of the most cool protocols ever invented it is because it actually pays for a lot of people you know their you know their salaries and things like that it\u0027s like a never-ending stream of like wonderful things you can do with it so that\u0027s why we\u0027re using you know BGP in our technology because it is just ultimately cold now at the same time you know it is you know it\u0027s robust and simple now that is debatable of course you know some people come up with you know things to do with it which is not really that robust and need of simple at all but what we are doing with it is actually you know we are using it in a very simplistic kind of fashion and if you actually read the specification you know you actually will understand also that what we are doing it\u0027s not really rocket science it\u0027s actually just using BGP in a more simplistic camera version and if you\u0027re looking to you know even spinning SPF into it you know you will see that a lot of the forwarding and a lot of the the ways of you know distributing all these pieces of information has been simplified also so I will be covering some of those elements so BGP provides is a few things it provides reliable transport is guaranteed an order delivery it\u0027s incremental updates you know there is like so unlike in link state routing we don\u0027t have a flooding problem here okay so there is no 25 different proposals for floating there is one and it works really really well and it\u0027s proven to work well it\u0027s loop free and it\u0027s fantastic it\u0027s awesome so and at the same time we also have like different mechanisms to actually you know bring this into the network so you can actually use like router flex you can use like controllers to actually program no more information downstream and then you know now the most important thing probably from this slide is that the way the the routing actually works everything is tisha view you know it\u0027s computed in a distributed fashion so there is no one piece in the network which computes the topology for everything everything is calculated you know from a routing perspective distributed and each single node itself so that is an important artifact and at the same time you know a lot of people you know running data centers already using you know you know BGP so you have some massive scalable data centers running like I don\u0027t know like ten thousand one hundred thousand boxes they run BGP you have some other set P of C you know some other set of people are unlike massively scalable data centers existing I look like 50 routers they also run BGP because it\u0027s like really really cool now we actually offer them you know like a new set of technology to actually know run with this so this is another you know vo lots of text here okay oh this looks very weird okay that\u0027s a surprise so the high level you know perspective from the insight vector out there so the target use case for reset vector routing is actually you know the the massive scalable data center so the plan is to actually you "
  },
  {
    "startTime": "00:39:43",
    "text": "know bring your political awareness and to actually do dextra in networks you know of gigantic size to actually not speak about networks of like $50 or a thousand routers but like 10,000 100,000 and more because that is the size of what BGP can scale to so that is really really nice now the advantage you actually will have by having the topological in our environment is you can do potentially smarter things with your environment because if you know the topology you can do you can actually start doing things like loop free alternates you know you can actually avoid risk you know reach between groups and so on words you can do some traffic engineering know whatever crazy thing you can dream off you know if you know the topology you can actually do this you know with this by extending the technology itself the target also is to actually use this as an underlay routing mechanism and so you actually will reduce the underlayer outing and on top of that you will have flow layer 2 VPN BGP and whatever you know you know all the VPN things happening layer 3 VPN happening on top of that this is just underlay from an encoding perspective so we could have used or reused the BGP you know Safi from bt pls now from a backward compatibility perspective we said ok let\u0027s not do that even though it\u0027s actually perfectly possible we actually select a real selector we get or we get allocated like a new stuffy for this just from our backwards compatibility perspective it also means we need to actually have like a new capability for this you know to be exchanged so that is important to be aware and now for the rest you know we\u0027re not really changing that much about like you know the you know right distribution like if you think you have to change but it\u0027s morally simplified now here you see my so the reason actually I was laughing with this so I have like his new iPad and it\u0027s actually you know iPad pro and a pen you can actually make like very nice graphs with that you know it make pictures but it\u0027s not very useful being a very pro in this if you make a PDF out of your slider it looks like this so my graph actually is gone so that\u0027s a bit sad so actually what you would be seeing here just visualize this close your eyes so close your eyes you know dream you\u0027re in this room you know fantasize apart my picture okay and what you see here is like another smalls you know the different routers on the left-hand side router one two three four and five and they look like routing logos and you have like a nice blue lines between them and next to the routing locals visualize you know close your eyes take your time okay you\u0027re like in Bangkok okay visualizer but not out I thought about anything else and then mix it around visualize yourself a puzzle piece yeah and that puzzle piece is actually your link state vector and that is what I\u0027m drawing here so I see everybody\u0027s smiling you\u0027re probably thinking about my puzzles I think so and the important thing is that a puzzle actually is encoded as you know in a way of like you know like with the BGP "
  },
  {
    "startTime": "00:42:44",
    "text": "LS and low-riding coding itself you know with the new stuff which is you know plan to be proposed so that is my magic invisible slide here which I didn\u0027t really check I think of how to block my slide is clicking on the button thing so I blame him anyway so what sort of peering models do we have so traditionally you know if you look into how massive scalable you know datacenters are configured by using BGP if you actually have like all routers are not directly connected peer-to-peer and your prefixes ago you know through them so there is something which is possible also here with the link States you know vector routing you know mechanism but it doesn\u0027t have to be because if you know the topology you know of course lots of massive scale that is know the topology you can actually download it it is actually very well possible to actually not put like you know like a route reflector in place or a controller in place and P with that one directly so that you actually reduce the amount of feeding configuration in your network environment so those details and those specifications and some of the requirements and what can be done is actually you know this you know documented very well in the applicability draft so if anybody would have a you know a nice question about that be you know feel free to come to the mic you know again we have people here to actually answer your difficult question so that is where we are so the other thing to keep in to mind is that what we are doing here is not a new technological principle so what is being done here is sort of like I wouldn\u0027t call it reinventing but more standardizing an approach which has been used by you know which has been disclosed already by Google in one of the sitcom papers like you know which is know like Jupiter rising has they could have cost a pop you can see what it is so it is you compare it\u0027s open source it\u0027s all open available and what we\u0027re doing here is actually you know giving you the capability to go into the same kind of you know you know technology like technological architecture you know to make that available by using eg this picture actually turned out better which is fantastic because I didn\u0027t make it with my ipod Pro and my pen so that\u0027s like a thousand dollars thrown away so anyway I\u0027ll give it to my kids so so a few things actually changed in BGP so what you see it on the left hand side is your classic BGP you know decision process what we have done with link stage Victor out them but Victor routing we simplified that so I know everybody knows BGP inside out you know in the audience here yeah so face one normally you know what you will do is that the calculation of degree of preference so all of the rights you get for one of your neighbors you sort of like give it a certain preference you know so you can compare it later on in phase two you actually strano compare off all the previous you have with the preference thing and you figure out the best one and you put it into your local rib and then at the phase three no you actually start distributing goes round again to "
  },
  {
    "startTime": "00:45:45",
    "text": "watch your neighbors so there is a traditional process and phase one and phase two is what most people commonly know or actually what is known as you know the part effective algorithm and that is what we are changing here so phase one and two in this case is being replaced by this new thing by the SPF algorithm so that actually means you know we\u0027re gonna be doing the BGP and a right selection and at the same time you know we\u0027re gonna do nearly in parallel you know the SPF attached to it so the route selection and node to it it also means that our phase three actually is simplified so in traditional classic BGP phase 1 phase 2 and phase 3 they are consecutive from each other in the Lynx and Victor routing algorithm it doesn\u0027t really have to be the case because we can actually do those things in parallel which actually makes it that if you have a piece of information that needs to be transported through the network it can go really really really much faster very similar the same speed as a traditional AGP like a SAS or OSPF so some of the advantages is already you know spoken about is a little bit all the notes we\u0027ll have a complete view of topology so you can do like really crazy stuff or you can do smart stuff and so up to you and what you want to do with this it another benefit of that is that if something actually breaks in the network environment just like with the traditional link state protocol you only communicate the failure of what you have because SPF will pick up I will understand and recompute the impact of that particular failure you know truly topology with classic BGP if something actually happens you have to really knows all the routes were sitting behind that failure again which makes everything much more heavy slower and more complicated than you know a little bit harder you know from that perspective at the same time if you at the same time yes if you know the topology then you can actually make smarter or more optimal routing decisions you know for the traffic through your network you don\u0027t always have to go to watch you know the shortest path towards your next hop because you know the topology you can make smarter decisions it is up to the implementer you know to actually you know to create a code or actually you know do those smarter things so in essence you know that reality is there so almost to the last slide so what is hot in link state vector routing well right now you know I think I\u0027ve the impression that the draft section you know or have it\u0027s me as chair of course trying to you know market my products here yeah so the draft selection of incredibly good quality easy to read it will make your day happier even if you\u0027re in Bangkok it\u0027s fantastic yeah so it\u0027s super it\u0027s wonderful so the BGP you know SPF draft itself so we\u0027re gonna be doing a working group last column that you know we\u0027re gonna be releasing that very soon I invite everybody in a room here to "
  },
  {
    "startTime": "00:48:45",
    "text": "actually have a very good read on that so what we actually need to further improve these documents because you know they actually went through the writing Directorate I went to the operational Directorate all of the commands actually have been addressed but at the same time you know it does really need to have like more inputs from you know a lot more people the more people who can actually give like you know constructive feedback or give information about what you know can potentially be changed what is good and what is bad you know please let us know so we can really really you know further improve the document and make sure that you know what we\u0027re doing here is developing the right you know the right material so that\u0027s point one two and three and then the other thing you know what actually has been hot very you know heavily discussed is you know as a remember you know as you can see actually could not see on that picture with that you know with your eyes closed the little puzzle pieces so that puzzle piece needs to be created now you can create this you know either by by some sort of a divine resource probably you configuring all of the link States and you know identifying that but it\u0027s not going to make like you know somebody operates router is very incredibly happy because you don\u0027t want to do that so you want those puzzle piece so you want to link state vectors to be created by themselves and automatically so that means you need to have a technology out there that can harvest the right sets and the right hooks of information for you to create that link state vector so we have been looking you know around you know all the different kind of technologies we have been you know being pulling the ball left and right and all the different things of what is available we see the same kind of movement you know I can you know in the idea all working group and we started to compare them now one of the key elements here is that the requirements you know of what we have from al instead vector routing perspective are actually different from the requirements which there are from an idea perspective so link cell vector out technology is you know a little bit you know little bit you know it\u0027s not really deployed that much because it doesn\u0027t really exist so we\u0027re not really restrained by the fact that whatever we do has to be a technology which proven you know track record yet so we can do a bit more you know we can be a bit more creative so what we have decided now you know in in our in the lsv our working group is to actually know start a working group adoption call for the links take over Ethernet technology so that is one of this I had to know just a quick you know quick summary here on what you know the ELA stories I don\u0027t really want to go too much you know into it so in essence you know it\u0027s a very similar thing as lldp it\u0027s a simplified version out of it and the simplified means you know in the first phase what we are documenting here is going towards the absolute minimum requirements of "
  },
  {
    "startTime": "00:51:46",
    "text": "what we need from an ALICE of your perspective so there is actually no overhead which is a good thing now at the same time what we want to avoid is that it\u0027s very simple technology excludes potential further innovation or like you know re usage by other working groups for other purposes so the way we are doing this is by making it extendable by using the magic of tlvs so these are like wonderful everything is with deal of each nowadays so we use still these because it is almost as cool as PGP so so we going down that road so that is where we are and that is what we have right now and again I love the way it\u0027s you know it\u0027s it\u0027s almost over trivial simplicity and there is no IPR test which is something that Randy Bush seems to love a lot really a lot and me too so that\u0027s fantastic so that is where we are right now so that is a quick update about you know Alice VR I hope that you know I was able to entertain you a little bit you know with my blessings about Ella\u0027s VR so any questions please come to the mic but don\u0027t expect me to answer them because we have smarter people in the room nothing that\u0027s scary cool thanks now we\u0027re going to have Jeffrey talk about rift I\u0027m learning to drive this thing okay so my presentation is good no not going to be as entertaining except I can say that the truth coaches are Jeff and Jeffrey that\u0027s the only entertaining part I can talk about so why rift this is about data center online writing protocol we have seen the evolution from ICP based 3db BGP and what we would like to see is that we evolved to reads for scanning convergence and OPEX reasons so the first I want to talk about the issues with existing solutions why did we move to ebgp the first place the two main drawbacks with a GP in mstc is that the first one is the failure impact scope some people call it plus radius a small change or link up and down anywhere in a small corner of the "
  },
  {
    "startTime": "00:54:46",
    "text": "data center is flooded everywhere and that triggers SPF recalculation on every note and that applies to lsv r2 as well another issue is the rich connections in the data center network makes flooding unnecessarily redundant and inefficient so those are the two main problems with a GP that\u0027s then people move to the ebgp solution but there are also two issues with that the first issue is that with a well-defined technology class network in data center ideally the routing tables could be very simple for example a leaf node all your needs is a default routes on the next level you only need a default route and more specific subset routes to destinations destinations south of it that\u0027s under normal situations but if you just if you do that only and then in some situations you may end up a black hole the next issue is a BGP is that some because we have massive EMP paths in the network for example and node could have 32 64 100 128 years and for every prefix you will learn the same periphery from all those peers and you have to keep all those so that\u0027s in the control plane it\u0027s a lot of resources wasted and lots of stay talking to keep so how do we solve solve those problems yeah enriched this is the hand-drawn picture a picture hand-drawn by Tony he didn\u0027t use a iPad pro my second point is in the telling points ok so if you look at this picture we have three layers the purple purple layer green layer and then the pink layer so we do linked States and distance vector in two directions on the right side where we are showing that we\u0027re flooding the linked States all the way from on the northbound all the way to the top well actually on the on the left side we do the same thing as well basically link States is flooded all the way to the north side I\u0027m not too the more spunk to the top and it also the next ad is also further flooded down on the south side just by one hop and then reflected oh yeah so on "
  },
  {
    "startTime": "00:57:53",
    "text": "the side look at this pink nodes its link state is flooded down south by just by one hop it stops here and then it it can be reflected back to north so that this may note at the same level will keep it what we\u0027re doing it same thing the link state from this green note is flat itself by one hub owning and also reflected north so that the other green node at the same level will also learn it why do we want to do that it would become clear later now anyway so because we fly the link States all the way to the north then every node will know the topology full topology south of it and under and then on the southbound with we use link States we we do a distance vector routing to to propagate default owning by one hub for example this pink note was Center default routes to the green node by stops there and then the green note was sent its own default route south now we we mentioned earlier that if you just do this to the default routes plus some specific routes to the for this destinations south of you you will have a black hole knee issue when when something happens and here is exact because his example well this slide is basically what I just talked about some the northbound reading state and southbounds a distance factor so I\u0027m going to escape those slides now here is the backhoe knee issue I mentioned earlier that if you don\u0027t do anything further so for now ignore that P don\u0027t don\u0027t you nor anything just look at the picture we have this prefix p1 here on this corner and these two purple notes here they get the traffic from the server\u0027s down there need to reach here so let\u0027s say this leaf node gets the packet it has two choices you are following the default route they can choose either a screen note or the screen notes as fine and let\u0027s say if it shows this note and it again has two nodes a two choices to go this one or this one but if this link is down and this one still choose to go this way and the "
  },
  {
    "startTime": "01:00:54",
    "text": "traffic will reach there and has nowhere else to go so that\u0027s the blackening issue if you don\u0027t do anything else now how do I solve this problem we do automatic the aggregation remember that earlier we talked about that the link States from any node is flooded south by 1/2 and then reflected back so in this case the two pink nodes will know each other\u0027s link States now this new pink node down here it does SPF calculation based on the topology flooded northbound then it will realize that he had a route towards p1 using this link here he also will realize that his body here does not have a pink to this note here so his body will not be able to reach p1 once he gets that conclusion it will send a specific route for p1 using the link using the distance vector part of this protocol and notice I also also note that this p1 routes will stop at this green node is not propagated further down it\u0027s just one half it stops here now if you have a packet arriving on this nook trying to reach p1 and let\u0027s say this node picks its node as a lookup you find the default routes and then the packet ends up here now this green node here now has two routes one is the default routes the other one is the most specific p1 routes that this kink node has automatically inject it now the packet will follow the p1 routes reaching this pink note down here instead of going to the top so that\u0027s how we solve the Brioni issue so with this automatically aggregation we can use default routes and plasti were specific routes through the destinations south of south of the nodes and if link fader happens in somewhere if there is a needs to do the auto this D aggregation it will happen another important component of this rift protocol is zero-touch provisioning if "
  },
  {
    "startTime": "01:03:55",
    "text": "we go back to this picture the owning these two top nodes we called top of the fabric needs configuration very simple convictions indicating that they are at the top other than that no configuration is needed on the notes all you need to do is to power up connect the cables and that they were the nose will discover each other decide to mean set up the routing adjacencies and if you happen to have me miss keep learning and the protocol will make sure that the logical topology that we obtain from from the routing adjacency that we decide to do that\u0027s the topology topology will be still conformed to a strict north north bound South Mountain a class type of topology that way you don\u0027t run into routing notes and that kind of thing so this zero test provisioning makes DC fabrics just like memory banks today nobody configures Ram banks you just put it plug it in a new work and what rifts zero touch provisioning to does is make this a fabric like a memory bank just it\u0027s plug and play no provisioning except on the top of the fabric nodes there are a lot of other features either peyote or ed ed on of the rifts of automatically optimal reduction flooding flooding reduction and not balanced we mentioned earlier that either is a issue with a valina ICP routing the flooding are unnecessary unnecessary flooding and that\u0027s is reduced here and it has built in mobility support key-value store and fabric bandwidth balancing so sometimes you may have links going down and now you have different notes at the same level have different bandwidth to reach next level and we can know balance in the traffic based on the available bandwidth it will it will support segment routing we also have participated prefixes though the segment routing and politic IV prefixes have been moved database back to their "
  },
  {
    "startTime": "01:06:56",
    "text": "own separate specs in summary we combine the advantages of link States and distance vector from the next stage routing we get fastest possible convergence automatic detection and topology we have minimum routes and information on that torus default routes normally you know and so a removes the disadvantages of big States or distance vector for example you have reduced imbalanced flooding you have automatically per detection and you don\u0027t have the easy NP burden there there\u0027s then there\u0027s unique rift advantage it\u0027s true zero touch provisioning minimum for us the readers radius on fader and so on so for a lot of them I\u0027ll just keep those small details it\u0027s not yeah I guess that\u0027s the last slide so I uh I thought I was only going to give overview of the protocol so I didn\u0027t put a steady-state there but I can talk about it so the working group was chartered immersed in London we have we had one intern meeting in May and we have been that the core team have been working having having weekly sometimes twice weekly design meetings that those meetings are most of them are recorded and announced we welcome open party participation so but typically it\u0027s just the core members of the team but it\u0027s open to everyone our original all the open source implementation has been going on brutal righteous men it\u0027s doing been doing a fantastic job with his helpers and that overall protocol we right now we are at zero three revision that zero for revision is evolving and our original plan was to submit to iesg for the pace based protocol in February 19 I are going to have to delay that by one ITF cycle but we we are working very hard on solving the the issues that we will encounter and fascinating issues and Tony and his his team can talk out "
  },
  {
    "startTime": "01:09:56",
    "text": "of those things endlessly it\u0027s but I wanna I will skip those here so that\u0027s just my report and Jeff at one point the way we develop protocol we do it the way IDF should do it everything being prodded as we develop the spec we found number of wishes in code that were fixed in the spec so both going Marla we make sure the stuff actually does work it\u0027s not on the PowerPoint in beauty another thing I forgot to put there and I know that some Lara wanted to hear about is the the thrifter model we actually last time we actually talked about this extensively in in the working group meeting so the in O\u0027Day\u0027s routing protocols are specified with packet formats and despite and that beats reader for what for whatever and with rift the pack we don\u0027t have packet format the old-style packet format definition any more everything is RIF model-based that makes development a lot easier you just use a tool to compile the surf model and then you automatic a general automatically generate codes to handle the the coding and decoding that speeds up the development extensively we a lot of people were last time had lots of discussions on that it\u0027s it\u0027s truly a wonderful thing that\u0027s why I have all right Victor coursing one quick question how does any cast services work on the underlay with the in within the Rif model I say Tony\u0027s is standing up by alright so Enterprise I mean lots of stuff has been suppressed so rift is loop free which means you can take any path to anywhere so if you have a rift is doing through any cast so not this any cast like IP which is bound by a CMP basically but rift when you see the same address on the fabric doesn\u0027t matter what the distance is and you can split the traffic also and you know based on the bandwidth distance whatever you want more than that what we have is a fast mobility because when you start to move things on the fabric at a certain frequency you start to confuse mobility for any caste right depending what gets an update first so Pascal booted in and we actually change the ipv6 low pan for the purpose because they facing the same issues that if the "
  },
  {
    "startTime": "01:12:58",
    "text": "fabric has a clock and we don\u0027t care how precise is the clock we can actually make a distinction between a move and then any caste and because we see the time stamps only the newer direction has to get there for us to flip over and we don\u0027t have to wait for the fold for the old address to be withdrawn so those are all things which cannot be achieved with normal IP protocols which rely on a CMP and cannot do the time stamping so that\u0027s so far for the anycast I think nothing comparable exists the questions nope okay so now we get to the part of the agenda where we\u0027re just stopping up before anything you guys want to talk about comment on tell us a story complain coffee\u0027s not there yet I think we already had the last coffee for today so no Anderson I have a real name we got the mail or the working group shares got the mail from the ADEs how we in the future need to update the working group status I think it\u0027s a brilliant idea it\u0027s the right place to have it though when you look at the working group page it\u0027s extremely hard to actually find the working group status where you need to click the finally would it be possible to talk to the data tracker team and to move a new bottom bottom up on the top line so we actually can find it easily sure you can talk to them no I think it\u0027s actually okay a selenium Cisco Systems I was able to edit the main working group change and and put a put a link URL link right there to the status on the LSR page so so I don\u0027t have to have two separate page so you can show us okay you see that current working group status right there you can push it click on that no no no down count up one no hop on there quick yeah "
  },
  {
    "startTime": "01:16:04",
    "text": "so what I\u0027m saying I want that bottom up on me oh this is fine contest is fine no it\u0027s the previous page yes a Syrian yes so instead by on the same level as a brow yeah you see it\u0027s an it wasn\u0027t it so if I talk to the the data tracker team can I say that we discussed it in the routing area and we agree that it would be good idea yes actually if you if you for those of you who I guess have privileges on the tracker for the working group I guess it\u0027s chairs and the 80s when you click on the status update to edit it at the bottom the tools team put in a little history of why they put that there and actually the history has to do with with us with the routing area it they put it in there because we told them we were doing summaries and so they they they they put that there so we could put this on my said I we had never used this so I originally thought that what would happen is that there would be a little window like thing right here that would show the actual summary so that\u0027s why when I sent this was chairs now we said you know let\u0027s do this a couple paragraphs or something but I think a tab is this a great idea and and since yeah they do it for us anyway said it would be especially a since you said it\u0027s for people not kind of very actively using the data tracker meaning they need to find it directly and I think it\u0027s a good idea but an improvement needed to it so if you\u0027re gonna find it where you expect to find it in some ways it really belongs on the bed on the bottom of the Charter because the Charter has got the current status of the working group it\u0027s got what you what it\u0027s work our package is it\u0027s got what it has done and it\u0027s got what it is expected to do and isn\u0027t that exactly you know status information and where you\u0027d expect if I may be an amplification of the status information well so I think we close those PF at the end of the year right the last time we reach our turd OSPF was in 1984 something like that so yes ideally that also ideally now that you bring it up I think it\u0027s a great suggestion for the chairs from an active chair to keep your mouths tones updated so that we can see that\u0027s a job for somebody bring us a free breakfast or just do it that so that we can see the actual you know status of when you\u0027re going to deliver things etcetera so the intent of the status update this "
  },
  {
    "startTime": "01:19:05",
    "text": "we\u0027re talking about is that here\u0027s a short summary because yes okay you go read the the Charter you know what the worker who was supposed to be doing we want to know especially for as we said external audiences what the worker was doing now you know if I\u0027m interested in in in any working group let\u0027s say LSR you know what what is it discussing now you know said work for me to go to the meeting what are the drafts that maybe I should go do it now because otherwise you look at the document agent there\u0027s a lot of documents and it\u0027s not necessarily easy for anyone not following the work group to tell exactly what\u0027s wrong so just you again may be the right thing because you should always do call by reference rather than call by value so that young it inconsistency problems may be of the right thing to do is not of the Charter paged have a pointer to current active status okay so this is obviously the first time we\u0027re doing this status page thing keep the suggestion scrubbing and we\u0027ll you know experiment with this further uh anything else anyone wants to say scheme amount has been submitted and whatever was in Miss Rhea for last 35 years is true so I have a Stewart again one other comment which is am I the only one that thinks there are too many routing group overlaps in the meeting agenda where there are important meetings that you need to be simultaneously at the same time and is there anything we can do to try and reduce this your first question I don\u0027t know who else thinks there\u0027s a lot of overlaps so yes there are many things or there are some things I guess we can do about them the first order is of course the conflict list that is put into the session requests and please revise that we have tried unsuccessfully before to try to prioritize that list so that would be easier for the Secretariat and for us to understand you know conflicts that we have we usually try as much as we can to avoid any significant conflicts however you know there\u0027s always gonna be something maybe we can avoid more than we have avoided now but but yeah that\u0027s those initial step the other thing that would be really useful for us is as the preliminary agent that comes out if you see anything that we should be avoiding those no and put it on the conflict list for next time as "
  },
  {
    "startTime": "01:22:06",
    "text": "well so that we try not to keep stepping on that but but yes I mean we try to do the best we can this week because we have on the last day or half of us they may be there were a little bit more calm yes anomalous yeah I\u0027m personally unimpressed with the Friday experiment that\u0027s going on here this week and I was hoping if the three of you have a consensus on that between yourselves you you bring that back to the next time the iesg meets so we can perhaps avoid this in the future any any one question for clarification in which sense unimpressed what is bothering you I think it\u0027s a waste of the day there\u0027s only like four small groups that are meeting tomorrow with that based on what I saw on on the room reservations I think it\u0027s is it\u0027s a waste of the resources that were paying for in the hotel and I think a much better use of the day is what we\u0027ve done in the past thank you yeah I do want to say that there are actually more than four meetings happening tomorrow there are meetings that are not on the schedule on the wiki or on the slides that ELISA put up yesterday they just haven\u0027t been announced they\u0027re still it\u0027s not a full load of working groups meeting Tony Lee arista networks I agree completely we should reuse Friday if we took all of our routing meetings and spread them out a little bit more we\u0027d have less overlap for the obvious support to previous speakers Gregory egt yes please even their time we used to have on Friday for group meetings helped to relieve conflict and another plea to work in group Cheers please be very considerate when you request working group sessions listing possible conflicts with other groups in the area at least in the area because otherwise running from one group to another to have presentations here and then presentation there it\u0027s a lot of stress say something then you can answer my question - in this income so one of the ideas actually kicked out which was might be even more revolutionary was that to just have one hour sessions for all the working groups said they more effectively made no use "
  },
  {
    "startTime": "01:25:09",
    "text": "of their meeting time and they could use interim meetings you know for other you know discussions but to go just and to one hour and are grouting our reactions one of the only ones that really requested you know their two-hour sessions to two and a half hour sessions whatever so do you really feel right that because I would reduce the complex to it right if everybody just went to one hours but do you really see the utility right to have the discussions in person maybe I\u0027m leading in but right that we have in person we have we\u0027re here and that we make good use of that time might have the two hour of sessions david black let\u0027s tell him here from transform them and i\u0027m here to help you i have ran a workgroup admit for three hours total this week and we could have used for and yes that\u0027s for face to face discussion is to work through hard issues not kind of support what David said I belong are going to take a different point which is that we do the we use the eighteenth-century method of figuring out conflicts right people who understand what\u0027s going on sort of figure out from you know what they know what the conflict should be we live in the 21st century with big data in all those sorts of things so though it should be possible to generate a conflict terms hint using you know what we know about who was in the meetings and you know who is on the draft authors are and the overlaps etc Stuart pegas who would be using information that we would need to be careful on how we use that information because that would necessarily point to people and understanding where people are at which time and so on well even if you didn\u0027t figure out from the blue sheets which you probably could do only online I\u0027m not sure with near modern handwriting techniques if you didn\u0027t do that you could at least figure out who was active in which area and try and minimize the the overlaps you could do that from the mailing lists which are public information you could do this from the author lists etc yeah I just want to point out not one of more excuse but one more circumstance this week this week for the first time we added a conflict with every working group for the routing area working group so it used to be that in the past we had other routing groups meeting while deliver our twg was meeting so this time we conflicted that which of course you know that\u0027s how things go ahead and then I want to ask another question similar to what they were asked before I want to give you something positive food was great too much but too much food but will take all "
  },
  {
    "startTime": "01:28:16",
    "text": "the credit for that you know take the blame for the rest of the AG will take the credit for the food so we talked about you know the fact that mostly the routing area of groups some of them are the ones who select some of the bigger slots one thing that we have to do this week was have maybe two sessions a two-hour session and the one-hour session maybe later and by couple groups met twice but at different times in the week do you guys think that was useful or will you have rather have one bigger slot that one shot just show hands who thought what bigger slot would have been better and who thought it was fine to meet twice different times so one in one so it doesn\u0027t matter okay great Jacob might Cisco this is not a comment judges for the routing group but I think the whole of the IDF is when do we move on from s key because every other standards body I know yes the RFC editor made a presentation about that last night they\u0027re already testing non-ascii characters you can do drawings except on news colors so that\u0027s it so there\u0027s a couple of our receipts actually they\u0027re talking about the changes and you can go to the RSC editor page and check it out of all the working group all the areas in this in the IETF colors would be most useful in this one because we have to deal with situations where you have multiple overlapping topologies and colors would be much better than the other alternatives I think the Ephesus RC - editor that some are enough maybe RC and RC by the way just in case you don\u0027t know the people who manage the RC editor activity or the IAB so sure we can tell them but please you can tell him yourself as well yep Jeff this from the IAB Jeff anything so you should have been used [Laughter] Heather presented twice our plans with regarding urs affirmative support colors to support different formats to show them properly and GML it\u0027s all coming just be patient they\u0027re not if you detect you can\u0027t use colors otherwise you can use colors you sure about that Jeff I think its color anywhere its color always full color days you could still do PDFs and in PDF you could use whatever you like right that\u0027s how much "
  },
  {
    "startTime": "01:31:21",
    "text": "better than that so please take that discussion to the RCA record list maybe there\u0027s something called RC and interest or something like that anything else that we can actually do okay thank you so much and we\u0027re gonna see you in Prague and then by the way we still have another half an hour of meeting time so you know stick around and talk to each other tell each other jokes and what the heck you\u0027re working on and all that stuff thank you [Applause] you "
  }
]