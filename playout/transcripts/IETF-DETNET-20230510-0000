[
  {
    "startTime": "00:00:05",
    "text": "foreign this is David not that many people I wonder if the mistake I made off by 12 hours and send out the agenda is the cause of this problem all right"
  },
  {
    "startTime": "00:02:49",
    "text": "foreign"
  },
  {
    "startTime": "00:04:34",
    "text": "all right foreign"
  },
  {
    "startTime": "00:06:13",
    "text": "okay let me go ahead and show the note well slide so we can say that that was done okay so that takes care of the note well slide foreign myself 11 people online that's a bit short of where we've been in the past I suppose we can try to make some progress here although so Peng I know you're working on a"
  },
  {
    "startTime": "00:08:02",
    "text": "revision to the requirements draft what's the expected timing on uh finalizing and posting that um because the updates are just to proposed by some of the course of notes all of them so uh I'm just going to send to the main list before that I want to know if there are any um comments within the capacitors but I haven't got any so I'm just posted them now yeah okay that sounds good so perhaps we'll have discussion and mailing list the next few days and maybe end of this week uh we'll see a revised version of the draft is that plausible uh yes but uh would you like to um that's we we just post a new version or we just send a updated version to the main list first I think a discussion of what you're planning to change on the mailing list first would be a good idea before you post the new version okay sure I'm going about my computer was really slow so I didn't finish it okay I mean I understand I had a lot of things I would have five or ten minutes I will send it out okay it'll be fine I mean I I had a lot of stuff I was planning to get done last week and uh other life is what happened but one is busy making other plans okay thank you um okay Chef who you wanted to say"
  },
  {
    "startTime": "00:10:01",
    "text": "something yeah uh uh up for the cup of TSN mechanism uh under uh begin the requirements to describe that my comments when you say separate document what are you thinking of uh because the maybe uh there may be money discrimination about the gap of uh the existing TSM magnet under the requirement document so I think you need to know that easy to add too many information in the requirement document to describe to that oh okay so I think I understand the question I'm not sure um it has its sort of implied in the uh wait a minute wait let me see if I can get all that blue background off I'm sorry I didn't mean to do that okay as it's implied in the um the agenda it'd be good run good idea to evaluate the TSN q and scheduling mechanisms against the requirements draft it'll give us some confidence that the requirements are that we that we understand the requirements and that uh the tsmic groups don't need them yes that ought to be in some sort of separate document um if it's convenient to do it as a draft that's fine if it makes sense to do it on a Wiki I wouldn't have a problem with that"
  },
  {
    "startTime": "00:12:02",
    "text": "but I I okay I think I'm agreeing with you the TSN evaluation should not go in the requirements draft I think Peng has his hands full already yes so uh so you know we could the the test along with the TSN scheduling mechanism uh is adjusted to to to test or uh it is necessary to somebody the document to describe or why why the TSM print scanning mechanism doesn't know the satisfied the requirement so I suggest the the latest assembly document may be necessary if you're willing to work on that document that would be fine okay something all right let me see if I can get some stuff going in the notes Here there we go um uh hi David I have one more comment for this proposal okay um I think I remember there is a published RC in the networking group it is called bandi latency uh and in this"
  },
  {
    "startTime": "00:14:01",
    "text": "document there is a summary of the existing uh TSN QE mechanism and the motivation of this document is just to show that the existing TSN mechanisms can satisfy the requirements of the net so I think the the conclusion that the existing TSM mechanisms cannot satisfy then that requirement is a is a little um I don't know how to say it uh because the requirement for example of scaling Risk by then that is um it's also Case by case for example sometimes the in a layer 3 Network it is quite big and a lot of flows and the we need some scalability but it doesn't mean I think it doesn't mean that all the existing tiers and mechanisms can satisfy the requirement of the net it's it's just some of them cannot satisfy some of the requirement so maybe I think it can make it Case by case rather than have a separated document because that will make people um think that all the TSM mechanisms is cannot be used that is my concern hang on I'm taking notes yeah just a minute and then I will then then then I will then I will try to remember what you said and respond to it uh there's only one of me yeah take her time um"
  },
  {
    "startTime": "00:16:04",
    "text": "well if I could spell shelf whose name and not mistype it okay okay so I think you saw if I understood your question it was are we expecting that every TSN mechanism will meet none of the scaling requirements or we expecting that some of the mechanism TS methods will meet some of the requirements but none of them will meet all of the requirements across the board is that is that the question you thought you were asking yes I think not only the existing TX and TSM mechanisms actually I think all the mechanisms that we have raised cannot satisfy all their requirements at the same time so I think we cannot give an impression to other um other people in ITF or in at Triple E that we have a conclusion that TSN mechanisms cannot satisfy these requirements it depends I think Case by case okay so I'm quickly writing down my answer here and then I'll read it um I think I agree with you that it is unlikely that any existing TSN mechanism or a new mechanism will meet all of the scaling requirements individual mechanisms will meet individual requirements"
  },
  {
    "startTime": "00:18:03",
    "text": "yes for example um I think today we will have a discussion about the tcqf and says qf are these two mechanisms is the is the uh some extension or some enhancement based on the existing TSM mechanisms cqf so the the basic idea here is that cqf has some scalability problem so we have some uh we have some modification based on that existing mechanism so that will be very clear uh with which mechanisms has what kind of scalability problem which cannot satisfy the requirement of that net and what kind of um more we can do in then and to make it work so I think it can be done Case by case rather than to to say that all the mechanisms in TSA cannot be used I will need to read everything I believe I'm scribbling down here is I hope I'm not putting words in your mouth a quick response to this discussion uh yes I agree with the situation that it would be kids by kids but my motivation is that there's a good place for separate document to describe that the kids were kids for the teacher curve or the sales curve for that is uh [Music]"
  },
  {
    "startTime": "00:20:02",
    "text": "remaining to describe the classical TSM thinker for under other mechanisms we welcome any enhancement to this existing mechanism thank you okay as you can read back when I'm busy busy writing down because I should be taking the notes um so she sung when I first wrote it she saw a David agree that it is unlikely any TSN mechanism or new mechanism will meet all the scaling requirements individual mechanisms will meet uh individual requirements and maybe not and it may be necessary to select multiple mechanisms to provide mechanisms that can meet each of the scaling requirements cells will be Case by case with individual method of selection based on what's important for specific usage scenarios yes that's exactly I mean okay I didn't miss that and then what I shout for what I think I heard you say was a separate document to capture classic TSM mechanism state with respect to scaling requirements would be a good idea is that correct yes okay yes all right she's going to cut you off briefly you should go ahead and respond and then I think uh issue is next so I'm thinking it's probably a good idea that each of the solution documents try to capture uh its own evaluate evaluation uh section for example for tcqf um it is quite clear that it tried to extend the cqf in order to meet some of the scaling requirements and for the I think for the asynchronous asynchronous"
  },
  {
    "startTime": "00:22:02",
    "text": "uh uh what's that called sorry that's draft asynchronous framework I I kind of think it should it probably can try to evaluate the TS and ATS because that's the most relevant uh um and the stable reference it can use in the for shuffles uh I might I might be wrong but I I kind of think it's also the ATS the asynchronous traffic scheduling is a good source that you can try you may try to start with for the evaluation for the for each of the requirements so my in summary I kind of think we can we probably can leave it for each of the solution document try to capture its own to explain why uh the such such new mechanisms or mechanism extensions can meet the scaling requirements rather than using a standalone separate document to capture everything oh okay I think you might accidentally be agreeing with shell Foods I think what I heard shafu say was that if we're going to evaluate the existing TSN mechanisms that ought to be Standalone dock I think I agree with you that the authors and proponents of each of the new mechanisms are in the best shape to evaluate how they're new they think their new mechanism meets the requirements my underlying cons and my underlying concern which is why am I wasting time on this is I think the first mechanism or two that goes through this evaluation against the requirements Doc is going to have a harder time than the subsequent ones and so I'd like to take something well known and existing that hopefully doesn't bias us one way or another among the proposed mechanisms to use that uh"
  },
  {
    "startTime": "00:24:01",
    "text": "to survive that does that make sense yeah so of that I if I understand correctly are you saying that if for each of the document authors if if the others would like to try to post or contribute to that post I mean leupon's requirement document that we can make it we can directly put it into current uh working groups requirement documents is that what I heard or I misunderstood let's see I let's see I think I I think I agree with you on who does the work I'm not sure I want to pile pile everything into the requirements so because the end of the day the requirement stock is going to have to stand alone as requirement stock yeah okay I see yeah yeah then we are in line now I got to capture what we just talked about yeah one more thing is the so-called classic TSM mechanism because the TSN actually not just a single mechanism it's a tour box so so it is it is yeah it is fair that for the for each of the solution uh proponent to uh to do this work it's more it's more fair yeah all right let me go"
  },
  {
    "startTime": "00:26:11",
    "text": "okay um I think I've got that captured in the notes and issue we were also suggesting that perhaps some of the um solution uh authors might want to take on evaluation of the TSN mechanism that's closest to our solution if each of the solution document draft can have such a section at least so that we are clearly so the readers can clearly know that this particular solution um how can why and how this particular solution address the scaling problem ah okay agree with that and are you also suggesting that the solution dock that that a dock for a new solution ought to also evaluate um an underlying TSN mechanism if it's if it's based on an underlying TSN mechanism in yeah to have us to have a section to at least to explain it if log if not the evaluation I don't know whether the evaluation means have to provide the data testing data or something like that but at least I think it would it worthwhile to add some explanation and it would be good if the uh because we have this interim meeting um some of the authors I think probably want to show show the testing data uh in the slides rather than in the documents because it looks not so common that the testing data appears in a draft right"
  },
  {
    "startTime": "00:28:02",
    "text": "so so I mean either the the the explanation or the testing data maybe every sorry every Solutions can evaluate themselves and to give well most rights just like uh our members in surface rise there was a evaluation or a result so after that we can put them together to discuss more about the performance I think I kind of think [Music] it depends on how we what and how we Define this evaluation it could be just explanation like a table a check against each of the uh check against each of the requirements in the working group document to say I need this or or halfway meet this or not cannot meet this so this is a form one of the forms for the evaluation another evaluation is to show some testing data so there are two forms at least two forms of evaluation I think so uh I might try to split those um certainly if I go back to school discussion earlier meetings something closer to your second alternative I think is more important so a quick summary of the extent to which a mechanism or solution does or does not meet the individual requirements testing data is always interesting and useful but I I tend to I tend to think testing data is more relevant as demonstration that the solution actually"
  },
  {
    "startTime": "00:30:01",
    "text": "works I think tested data could be presented during the interim meeting in the slides but for each of the solution documents it will be we we suggest that that a separate section try to do the uh uh something like the table evaluation for each of the listed listed requirements that's that's still called we we still call the evaluation right in the draft timing yeah and we may have to come up with better terms for if we were talking about here because we're using evaluation to mean two different things right now I don't think it's helping anybody and I plead guilty to being part of that problem okay I think I've got that captured um it's a chef who were you proposing to actually start the document to capture the state of the classic TSN mechanisms with respect to the scaling requirements uh um because it is a common to all a new mechanism uh for I think maybe Collision to add a section to describe that and I still have two opinions on that um"
  },
  {
    "startTime": "00:32:00",
    "text": "on the one hand I think a standalone document describing the existing mechanisms makes a lot of sense on the other hand I think I'm sympathetic to ease you view that for a new mechanism documenting how it does it doesn't mean the skill requirements might be best done by the proponents of that mechanism or draft for that mechanism yeah for the new mechanism document uh it is uh necessary to add a selection to describe the Chinese the based on the requirement yeah I agree with that but the fourth existing classical TSM mechanism because it is common is a common problem uh I'm not sure it is called the for each new government to describe the repeatedly that that is what I worry about Shuffle I I'm actually I'm a little confused about the the common uh common thing you have mentioned because I think um as lijo uh has already uh proposed maybe uh when we talk when we discuss one mechanisms uh internet maybe that kind of mechanisms that has already been uh discussed in TSN and what we have done is just to propose some modification or enhancement based on existing mechanisms and to that point in that document we can analyze uh what kind of scaling problem for that type of"
  },
  {
    "startTime": "00:34:01",
    "text": "TSN mechanisms because there are a lot of mechanisms in TSN so I'm a little confused you you have mentioned that there are some common problems in TSM mechanisms what do you mean is an understanding some uh some description uh I regarded the um for each new document uh to maybe unnecessary to add the section to describe the existing classical tierson mechanism for to describe the gap of the existing TS mechanisms are between and the the the requirement the document so if you think it work with the conscience that the existing TS americanism does not satisfied the requirement the documented I am another resist that we I am Luther the insist that we must have a simulated document and as I said earlier I would like to see at least one of the classic TSN mechanisms taken through evaluation against the scaling requirements draft so that we can learn from that experience about how well that works and maybe pain maybe we'll have some more stuff for pain to revise the scaling requirements draft again"
  },
  {
    "startTime": "00:36:05",
    "text": "uh what you have suggest is to take one TSA mechanisms as an example to analyze why it cannot satisfy the existing scaling requirement is that your proposal yes yeah on this dude actually uh I think um maybe a tea stick you have and this says qf can give a a proper example for that because it is the very clear enhancement to the existing secure problem and the the secure problem for scaling is uh it is not suitable for uh long distance especially the the link delay is very big maybe we can go into it when we discuss these two mechanisms okay so I think you said is that much of the evaluation of cqf against the requirements draft may already have been done by the folks who are working both tcqf and csqf is that correct I think so okay there's uh requires the time synchronization and our requirements first of the comments that your uh require not really for time synchronization that's expected yeah okay okay sure so for other sorry for others um maybe um I'm synchronized Edition based solution"
  },
  {
    "startTime": "00:38:02",
    "text": "uh like shall Focus erosion and channels maybe they can get more analysis if there is nothing thank you um so I I think for for the tcqf part or CSC curve anyway so um the original draft which is uh my draft is a ego c2f Orion it takes quite a long chapters or sections to explain why the traditional cqf cannot meet the scaling requirements and explaining quite details but it is not in the form to check against one by one of the requirement listed in current working group document so I think if if ever you you you think that it would be worthwhile that we have a separate we have at least a example document to show that one of the existing TSM mechanisms which is cqf uh should be taken through the evaluation against a one by one requirements in the doc in the working group document I think I can modify that that draft to make it more clearly stated in this form at least it might be good you could modify if you could put that together and put it in the wiki or send it in the mailing list that would be helpful yeah thanks okay"
  },
  {
    "startTime": "00:40:11",
    "text": "okay and all right that would be that that that would be that would be a good start all right any other uh comments or questions uh did you have slides on the uh Sr base bounded latency draft I hope prepare some slides uh so the the tcqf will be uh presenting next time I think that's the plan I think the tcqf um authors the two drafts um could use a little bit more time to come to a common view of things and I um I guess we can start here I mean one of my questions is whether we have a common underlying um Extended cqf uh scheduling and uh queuing mechanism and we're looking at three ways of doing doing the communication instances or whether there is something fundamental about Sr that makes uh what you're proposing this draft different yeah okay I will give some uh"
  },
  {
    "startTime": "00:42:02",
    "text": "introduction to that um so I can assure let me go stop sharing so you can start sharing okay uh the Assumption here is that people has already been familiar with the the secure mechanisms and also the tcqf and the cesqf is kind of based on this expectation uh it seems like I have already gave a request to share my screen oh I'm sorry wait a minute there it is um I need to go I need to go say yes you can do that yes I'm sorry yeah too busy taking notes yeah thank you it's taking us is really difficult at least for me okay my screen yes yeah okay okay and would you please send me these slides afterwards so I can get them posted into the meeting materials after one of these meetings I get an urgent request of can I see the slides I'd like to do that promptly this stuff sure sure I will send it to you uh what I'm trying to introduce today is uh psycho specified curing and forwarding mechanisms we call it csqf and this slide is uh is something I have presented in this ITF uh there are three parts of mechanisms for guaranteed money latency the first one is QE mechanisms"
  },
  {
    "startTime": "00:44:02",
    "text": "which is the core of our discussion another one is encapsulation because this mechanism is based on SR so we I also mentioned this part and also resource allocation in this mechanisms csqf based on the the controller or centralized paths and resource calculation and the first I will give some brief introduction of the queuing or shaping mechanisms basically we have three or more than three cues and there are different rules for these three cues uh one of them is um the existing output queue and one of them is the the Target in input queue and another one is the burst tolerant Cube if we have more than three queues we have more than one burst tolerant Q so we can tolerant more more uh more burst and each queue will correspond to a cycle number the second number means that in which time slots the queue will be the output q and the the target second number second number will be updated based on the existing timeline for example in this this following pictures shows what will will happen in each time slot for in cycle one if we have received a packet which is have a label to indicated to uh to be sent out in cycle two it will be put in yeah I'm still looking at your title slide our final slide no what what slide are you on uh my screen is showing your title slide number one oh sorry it's it's uh so whatever here we go now you're on three now I see it uh okay so I I will I will quit the"
  },
  {
    "startTime": "00:46:00",
    "text": "presenting mode maybe you cannot see the the I I I I I I switch the the slide yeah here we go that will work better sorry about that I think meet Echo didn't meet Echo and PowerPoint didn't get along ah okay okay honest dude uh this is the previous slide that this has already been presented in ital 116 and now we're going into the query mechanisms and we have three cues uh it can have a different role and each kill have a correspond cycle number and for uh take it exam example when we we when we are you know times a lot of cycle one we have a packet of cycle two which means that the packet is supposed to be sent out in cycle two we will put it into the Q3 because that is the target input queue and the the target second number of Q3 is cycle two and you if we have received a packet that is labeled as cycle three we will put it in q1 because it is the first tolerant queue and if in second one we have received a which is uh has a label of Circle Four we have no cue to put it because the we have only one burst tolerant Q in in this example but if we have more uh cues for burst tolerant we can also put the cycle 4 packet into the queue and that is what happens in cycle one and if we have uh if the time slot has passed to cycle two the the second number for each queue will will also change and the rule of the queue will update it that is the mechanisms that is um quite similar to cqf or what has been changed is that we"
  },
  {
    "startTime": "00:48:02",
    "text": "add more cues for a burst tolerant and so the question is that how to provide bounded Jitter in each Hub the the basic idea is here uh we have you know three part of latency one is for uh processing one is for queuing and one is for output port and the link delay is stable so it is now discussed in this slide there the link delay won't cost Jitter and the processing delay will will have some Jitter and the the queuing delay is bounded by the mechanisms itself because the time slot has already been scheduled so the Jitter rule comes from the processing delay and when the processing delay is more we will give it a larger queuing delay to make it to make it abundant abundant Jitter and if the the processing delay is large the queuing delay will be smaller so the the case is that because there is Jitter in processing so in the queuing we have the corresponding mechanisms to tolerance that Jitter so what is happening is that after all these mechanisms each hop the latency can be expected and the cheat responded that is the the queuing part and so how we uh how we guarantee that in each time slot the packet can be sent out and there is no confliction no no congestion uh the answer is that the controller know that because the controller knows the the traffic specification of each flow so it will reserve the time slot for each flow and it will calculate the path and adds the same time calculate the the the time slot for each packet and to indicate that uh which times loss"
  },
  {
    "startTime": "00:50:01",
    "text": "the packet is supposed to be sent out in each hop for example in this picture the the calculation result is that the package will be sent out in second one in node a and will be will be received in cycle 2 for node B and send out in cycle three in node B and receive the insect of four for node C and send out in cycle five for normalcy so that will be the the calculation result of the controller and then that is uh the reason why we need the SR label because there will be a label stack for the path to indicate which output Port the package should be sent out and if we uh enhance that part we can uh the the SR label or s56 seed not only indicates that which part the package should be sent out it also indicates that wage time slot or which cycle the the package should be sent out which is also the result of the the calculation from the controller so in the first function we read the the seed and we know the output port for that packet and we also read the seed and know the the second number the packet should be sent out and based on the second number we know which queue we should put the packet into and uh when the the that Q will be the output Q the packet will be sent out in the indicated time slot so that is the whole idea and we give I I have Give an example it's very simple to to show how to work together first we have to uh give the controller some information about the topology about the meaning of the label and also some basic delay information for example the link"
  },
  {
    "startTime": "00:52:01",
    "text": "delay the processing delay maybe the processing delay has some Jitter so it will be a rank for example 10 10 milliseconds to uh 20 milliseconds and also the the proposed queuing delay and after the controller have already collected all this information it can calculate the past uh the it has the it in the past will satisfy the requirement of the end-to-end latency and also the end to end the end to end the Jitter after calculate after the the past calculation the the controller will also indicate that in each Hub which time slot the package should be sent out so it will will present the the result as a label stack and label stack will be allocated to the first half of the pass and then the packet will forward it based on the label stack of the label as I have mentioned not only indicate that which output Port the package should be sent out also which time slot the package should be sent out so it just will send the packet based on the label and the underlying mechanisms is the queuing the cyclic query mechanisms as I mentioned and because for each packet the arriving time is different so there will there will be different label stack for different packet in the same flow but there will be a pattern because then the traffic specification of the flow is known by the controller so there will be a set of level stack allocated to the first half of the pass and when a packet arrives it will select the right one to indicate that packet to go through all the paths and if there are different flows"
  },
  {
    "startTime": "00:54:01",
    "text": "um the the intermediate nodes will not recognize which flow uh the packet belongs uh so it just recognized the label so it um so there will be no flow status maintained in intermediate nodes the the nodes just send out a packet based on label and that make it more scalable when there are multiple flows uh uh running the in the same time in the network and the controller will deal with the possible packet confliction because there there is a resource reservation beforehand even these two flows share the same time slot the pack the the controller will guarantee that the this time slot is enough for both flows to be sent out and because we can see these mechanisms uh depends heavily on the uh controller mechanism so we have done some work about the how to do the calculation uh both the uh the past calculation and also the time slot calculation and there's offline planning there is online planning and there are different goals I won't go to details because this is um related to the controller algorithms it's just some give some idea that we we have already done this and it can work and there are different kind of algorithms for example the the coolant generation or a Grady um and here is some um some scenarios we have we have used as an example for past calculation and it is a give some idea how many nodes"
  },
  {
    "startTime": "00:56:03",
    "text": "can be calculated how many flows can be carried in this network and here are some results and also we have done some work about load balance it means that because the controller knows everything it can give some mechanisms for load balance to make the network can carry more flows so here are some basic uh questions from David perhaps also from the working group so we have three documents are what about the query mechanisms are they share the same or common cream mechanisms yes the underlying mechanism is the same because it's all based on the The Psychotic QE mechanisms and there will be a time slot for each output queue and the other queue is for uh for Jitter tolerant so what is the difference between for example tcqf and csqf actually the the basic idea is that the mapping relationship is calculated by the controller here is the picture shows how the controller calculates the memory relationship um between each nodes and each time slot so the controller will calculate it for TC graph the the mapping relationship will be maintained in the each node and it is stable but for controller it is calculated together based on the collected information and so the controller can also adjust the mapping relationship based on the the reservation status for example if the if based on the previous mapping relationship the the time slot is full and cannot cannot carry on another packet in that time slot there can be"
  },
  {
    "startTime": "00:58:01",
    "text": "some adjustment for example if we have molecules we can put the packet into another time slot and it can also be indicated by the label stack so it is kind of more stable in scheduling because it is based on a centralized controller yeah that is my presentation uh maybe do you have any um any questions about this mechanisms I can give more explanation look like you're passing tooth and decent each label one of which looks like a cycle number was there a second entity ah and not really actually we have um give the label uh two meanings for example uh in the previous mechanisms for example traditional Sr each seed will represent one output port for example but now we we um we allocate a set of uh seed for one output Port it means that for example one or from 101 to 105 all these three labels represent part one but there the difference of these five labels is that it presents different Cycles so it's it means that if we have 103 first we know that the package will be uh be sent out in one of the output Parts could you go forward could you go forward a few slides what I'm cons what I didn't understand is I saw some uh keep going forward a few slides I saw some slides where it had things like 1-210 no no I'm sorry the other way two later slides okay yeah right there um what do you what does the top right what does 1-210 and 2-160 mean ah is it's"
  },
  {
    "startTime": "01:00:04",
    "text": "just um actually it's uh it's just is uh an example there is no meaning for for uh for a dash here it's just the same as the y o y or Y102 oh okay yeah okay so so it there you're only sending the cycle count and the rest information is is a port selector yes yes uh because this example is we we take srmps I as an example so the the the cycle ID will be uh represented by a label but if we um use srvc sr6 a seed for example we can Define the cycle ID in the arguments of uh as obviously seed it's it's similar so I I just take MPS label as an example foreign yeah okay thanks that was that was that was slightly confusing okay um let's see where am I okay uh shafu go ahead Shuffle if you're speaking the audio is not coming through"
  },
  {
    "startTime": "01:02:24",
    "text": "first foreign may be having audio problems can other people hear me yes David I can hear you wow okay shafu hasn't says he's he's having he's having a problem with being unable to unmute oh when he gets his mic fixed we'll try again at the issue go ahead thanks Debbie so uh I know this is for the asabi sex right basically for the SR vsx encapsulation and you try to use the set which is a concept in segment routing uh I'm not the expert in segment routing so would you please illustrate a little bit more regarding for example in in segment routing there are different types of said right so either ending um extensions or constraints um because of the encapsulation and because of the segment routing calculation we need to follow is there anything uh Yes actually uh we introduced new meaning for the existing seed for example for MPS label the previous label is only to indicate for example uh other other adjacency or no C it just used for routine but now we use it for a Time"
  },
  {
    "startTime": "01:04:01",
    "text": "information the the there are two uh to modification here one is that we we introduce a new meaning for the seed and it also indicates the new functionality and the another one is that we need more seeds for example we need more MPS labels for each other Port because um we we have to indicate for each other support the difference of uh different Cycles so that is the the two new things we bring to the traditional Sr MPS or Sr V6 mechanisms go ahead if your audio is working this time uh there is no conflict uh on the 27 node uh if you don't know that we see the multiple form uh multiple float from a multiple source oh that is really a good question because that is the the the sweet part of this mechanisms this slide shows that how we do that uh for example we have a flow from the destination source and we have uh give it a pass from A to B to C and to the the destination and because the controller has already collected the the uh the link and the processing delay"
  },
  {
    "startTime": "01:06:01",
    "text": "of each node so it it will give um uh it will give a time slot result for each node as I have mentioned in in this the the uh the result is that second one for a second three for B and second five for C and this is result for this flow right and now the controller knows that in cycle one there has already been a packet and for B the cycle 3 has already been a packet and you know the blue one is the newly scheduled flow and you can also notice there is gray one that means that that is the flow that has already been scheduled in that time slot because the controller knows everything uh even the pass is different the sources difference there are multiple flows but the controller knows that so every time the controller schedule a new flow into this network it will check whether the the the time slot in for example cycle one for node a is a four or not for example the for the capability of node a the cycle 1 can only provide times resource for for example five packets and of course there will be a maximum taxes size um and if if we have another flow that make it uh the sixth uh packet in that same time slot the controller has to reschedule because the node a cannot give the results for that flow in in cycle one so that that is the the most important thing for this mechanisms and that is also what we are trying to do in all these controller algorithms because we the controller has to uh to check whether the time slot is used or or not"
  },
  {
    "startTime": "01:08:02",
    "text": "and the the time slot is enough or not and then it can give the result of the calculation and when the controller can give the result it means that okay the the resource is still enough and there will be no confliction if if the controller cannot give the result it means that oh we have already uh all the the the suitable time slot has already been occupied there will no no more results for more flow so that will be the the maybe a richest rejection to the new request from that flow so each flow that that controller can provide the result it means that the results is reserved okay uh uh how a needle confused about the the uh sure you mean uh slide five uh yeah yeah yeah okay yeah also if we take a look at this big uh for the Transcendent node C yeah they may be multiple follows uh received from different incoming Port yes 10 for example the flow one and the flow two uh there may be full of multiple source so I'm not sure how the controller to calculate the for example in the note that flow one we arrived at the translator C for example it may"
  },
  {
    "startTime": "01:10:03",
    "text": "consumed the cycle suit in Transylvania the Sea Under again the flow 2 basically consumed the circus sleep that is at the same cycle are under transfer notices but the but these two flows May uh the third there's a large time with interval between these two flows but they just take the same cycle three so yes it is a large time interoperation is two flows so I'm not sure how controller to distinguish it is actually configured all data uh not actually a company that is uh actually the the point is that because we have a time slot lens for example how long the the cycle will be if for example it's um uh it's 10 millisecond and then that is scheduled beforehand right and then we know the capability of the output port for node three for example it's uh it uh 10g and then we know in each time slot how how many packets the the for output port for node node C it can send it out it's um it's um uh a number that we can calculate it or if the controller can calculate it so when a new flow arrives it it says okay there will be a packet in cycle five and then"
  },
  {
    "startTime": "01:12:00",
    "text": "the the controller will check how many packets that have already been scheduled in cycle five and whether there will be more space for cycle file and then the the packet Size Matters and what we use is the maximum practice size because the uh the parameters of that flow include some core information for the calculation one is the maximum package size another one is a pattern of the track traffic for example the the interval of the packet and the maximum burst of each interval for example you you can see the the gray the gray package in node a it means that in each cycle there has already been a flow there will be a packet in each cycle so that is the pattern for that flow and for node B there is another flow that okay there will be two packets in each cycle so for based on that pattern the controller knows that each packet will be will supposed to be sent out in which cycle and also based on that it can uh can decide whether that Cycles resources do enough or not a assumption that for each cycle these are green traffic on each side but uh uh no no there's it's just an example it can the the pattern of the traffic can be different it's just for this example it's um for each cycle there will be two packets and there they can different for example their 10 cycles and one packet"
  },
  {
    "startTime": "01:14:00",
    "text": "it can also be calculated by the controller but remember foreign but remember if the the cycle number of the packet uh for the packet to arrive is not determined it means that there will be Jitter for that traffic so we have we have to maintain more cues for that Jitter that is um that is the rule because if if you want to uh to tolerant mode cheaters you have to maintain more kills in the in the in the device so but if the which cycle the package will be arrived is determined there's no Jitter so there there won't be more cues for uh for a tolerance attitude uh one hour ago and one hour later the glue chart arrived the person of the sea oh it's um one hour is too long Jitter because for that there is some assumptions here because if we want to do the time scheduling the arrival time of the of the packet has to ha that can can be expected if you if you reserve the flow uh you have to pay attention to that if"
  },
  {
    "startTime": "01:16:00",
    "text": "you reserve a flow uh to the controller and you mentioned that okay our packet will be arrived one of late one another later it means that the timeline of reservation will be one hour later so the there will be no results reservation for the flow uh in this hour but it will happen one hour ago but if you talk to the controller and assess that okay I have one packet but I don't know when it will arrive it so there is no no uh deterministic for that flow because you don't even know when it will arrive there's no resource reservation or you can give redundant resource reservations even though your flow hasn't arrived but I do the reservation first and when whenever you arrive you can get you you can get your seat that's you cannot you cannot say okay I don't know when I arrive but but when I arrive you have have the resource reservation ready it's not reasonable you cannot satisfy this requirement in any way thank you but uh maybe we can't discuss in many is that the question is we need a northern related with the Jitter Corner lens it is exactly that for example social one send the traffic one hour later I want one hour before under social one hour later uh yes I I think I understand your point is the my answer is that if you arrive one hour later it means that your reservation begins one hour later but if you but the Assumption here is that you know exactly the packet will arrive one hour later but if you don't know you"
  },
  {
    "startTime": "01:18:02",
    "text": "just don't know when the package will arrive the the the the most um I think the most efficient ways to reservation to do the reservation uh beforehand it means that whenever you arrive your reservation is already there too many times uh it's actually uh you have to understand the Assumption of that net because uh for that net there is a traffic specification what's traffic specification means that it's the description of the traffic model of the flow and if you have already provide your traffic specification and for the results reservation will be based on the risk the traffic specification you have provided to the controller so if you don't send your packet based on the traffic specification for example you you have reserved a 1G uh bandwidth for your pack for your flow but you only send one packet it's it's your problem it's not a problem of the that net that is the case for example you it it that is the case for every mechanisms if you do the resource reservation you have to based on the results you have reserved or you you can you can get nothing while we discussed is based on the exist in Pittsburgh meters so I always let this Collision in Maryland is something yeah sure"
  },
  {
    "startTime": "01:20:08",
    "text": "okay so I have a question for you shoe song I want to check with I understand it you said that the um the queuing and uh scheduling mechanism is the same although is it correct that the centralized controller algorithm that you're using requires a label stack because the cycle number May differ at different nodes along the path uh uh David I I I don't think I get your question correctly you mean that the the sacrament of the label and the the queue the corresponding relationship between the label and the queue that what I'm asking about is it looks like you've taken advantage of the SR label stack so that so that same packet can have a different cycle number at different nodes is that correct yes yes okay that's what I was asking about because um uh some of the other mechanisms I've mechanisms I think I've seen uh would not allow the cycle number to vary between nodes and that that would that would be that might be an important difference yes because that that is also the benefit of this mechanisms because you know uh as the this example shows that in packet uh in this for this package it the schedule result is cycle while for a cycle three for B and cycle file for C and each cycle can be represented by the different Sr labels and if we reschedule the the flow for example to to move the cycle 5 to cycle six in node C we can just uh update the"
  },
  {
    "startTime": "01:22:04",
    "text": "label stack and the the the time slot can adjust based on the status that is the flexibility from the controller that is also the difference okay thank you Tron foreign the controller pass calculation and their location so uh this is there is there past planning is is that exactly the past calculation and the the time planning is exactly the uh resource allocation uh sorry um we missed the first part of your question can you repeat it uh I mean what's the difference uh between the path planning and the time planning and past learning the past calculation and resource allocation oh actually and path calculation yeah yeah I think I understand your question actually it it happens together in this mechanisms because it's all all done by the algorithm from the controller for example the traditional past calculation for the controller is that maybe we have to pick up a a path that can for example satisfy the end-to-end requirement of uh of a flow but now the the limitation is"
  },
  {
    "startTime": "01:24:00",
    "text": "more um is more we we not only have to satisfy the end-to-end latency we have also to find a proper time slot in each node for that flow so um if the if the the controller can't give the result of that uh of that flow it means that okay we have already selected a path that can satisfy our datency requirement and we also have already scheduled a proper time slot along the path and if that result come out comes out that means the the resource reservation has already been done because that time slot uh that has already been reserved for that flow if net flow goes through the same node in the same time spot the controller will decide whether the resource is enough or not and that is awesome thank you so um I think that is the the result of this algorithm there is a paper link I have already sent out in the main list you can also get more details from that paper [Music] yeah yeah you see it it I I didn't see your sorry I didn't see your full link oh it's in the mail list I have sent out uh email it is more additional information the last one is the link for the paper so this one is join rooting and scheduling for a large-scale deterministic type networks because you"
  },
  {
    "startTime": "01:26:00",
    "text": "can even see from the title it's joined routine and scheduling it means that it uh need to schedule times a lot at the same time with the selecting the pass okay thank you so uh what what timing that if we uh should add a past planning or transplanting it's a new item for the control plane so maybe we could pay discounts more in the mailing list uh it is related to their controller playing draft uh actually uh the controller I think that is a good point we can end some description uh in the past calculation because the existing uh controller framework document is just gives some very initial description it means that we have do the resource reservation we have uh we have to plan a proper pass for for flow but there is no description about the time scanning maybe we can add something to that yeah okay thank you foreign yes turkey uh can you hear me just uh yes we can sure very loud and clear okay sure uh thank you if you don't I have a question actually it's regarding the whole Behavior Uh here seems to me you're trying to give people either to all the devices around the past has that been installed already you know why I'm asking this question so"
  },
  {
    "startTime": "01:28:02",
    "text": "suppose you have in one example I forget which one you have been using you have a three notes uh um on a path so for the controller side the controller will be able to determine like the bonded delay or something for each node standardized yeah I'm asking Casa I'm facing the problem right now so yeah it's actually not yet because the the the core part of the standardization is the extension to the SR MPS or srv6 we have presented this work in Spring working group several times but the conclusion is that it has to be confirmed but then I'm working very first it means that Leonard green group has to to say okay it works it is requested by the net and then the screen can take it into their scope that okay the SR extension is reasonable or not so we are still now we are in the core point for this work the Dana wind group people will say okay it works and then we will standalize the the SR part I think been trying to to support this sort of distinction between the queuing and scheduling mechanism and the the protocol extensions needed to carry information for that mechanism we could easily be nice if we're in a world where we had uh queuing and scheduling mechanisms that were amenable to different protocols for carrying the information"
  },
  {
    "startTime": "01:30:01",
    "text": "yes I I think so so actually as you have mentioned uh David there will be multiple ways for carrying this information about for some of the routine maybe it has some benefit for uh for this mechanisms as as I have mentioned it can flexible it's the time slots for each node so it there will be some couples maybe it will or have some benefits okay um the way you mention the traffic expectation for a damn flow is that the one for the end to end back or in that one also is for no it's the description of the the flow it's the how the flow arrives inside so in that case suppose in this example you have ABC3 notes what are you going to split like let's use the delay among the three nodes from the end-to-end the traffic's back um there is no actually uh it's because in this picture you can only see one packet the blue packet is only one it's just leave node a to node B and then to no C it's kind of a timeline but for the traffic specification is uh the description of the behavior of a workflow it means that there will be multiple uh packets for that flow a long list so the the but the the"
  },
  {
    "startTime": "01:32:03",
    "text": "traffic pattern for that flow won't change it's just we just what we have done is to translate each packet in that flow from one node to another but from even from the view of the flow the pattern hasn't been changed okay yeah so basically I I if I if my understanding correct you have one one kill to give her compensation [Music] is guaranteed by each hop it means that if the the traffic pattern is um is as described the node a will make sure that traffic pattern won't change because the the the expected Jitter will be controlled in each node and it means that the traffic pattern will be the same in node a node B and node C it won't change because if if there is any change brought by node a for example in the processing it will be um it will be tolerated by the tolerant q and the it's like you know there is flexible for each Hub and the pattern won't change okay so since you have a coordinated uh management among all the three nodes in this example uh um not really it's just um you know it's yeah because it's uh it has already been scheduled by the controller it's like uh it is um it is supposed to be sent out in"
  },
  {
    "startTime": "01:34:01",
    "text": "cycle one but it processed so fast it arrives early and now we have a a Jitter tolerant queue we can just put it in that queue it can wait a little longer than before because it's a process fast but it is yeah okay yeah yeah so that the the basic idea is that it will be sent out in Cycle One um whatever happens yeah that that curing mechanisms guarantee that point sure thank you yeah thank you okay I guess you were next then then an issue you seem to be on mute again okay easy you want to go ahead while the shafu uh has a discussion with his audio pleasure I have a clarification question can you go can you please go to page five I guess yeah yeah so if I understand correctly it looks like uh this small picture you have the blue packet yeah so so it looks like there is a difference from the the tcqf is here"
  },
  {
    "startTime": "01:36:00",
    "text": "you want to in real time suggest that the blue packet when the blue package arrives in node B it could be possibly either put into cycle 2 or cycle three this is uh it this is a real-time determination depending on whether the cycle is already full or is is predetermined by the controller yeah it's pretty determined by the control flexibility is not real time it's just the the flexibility behind the controller when the past calculation is happening well the the controller will see whether the results of cycle 3 uh is enough it's if it's not it can put it in maybe other cycle later that is determined by the controller beforehand is not happening real time oh okay so that means once the controller determines this mapping then all the packets are following this cycle yeah mapping relationship if I want to change it I I need to go through the whole uh life cycle again so at a certain time point then I do it all at once it's not a real time put here and put there determined by okay I see you are right you're right it's not a real time okay so so so so one more small question why why at the node be there two blue packets and it's kind of confusing the the first one is means that it arrives and the second line means it is turned out it's the same packet actually it's just a different time uh or arriving time and the transmission is received and transmission time okay it means that it is received in cycle too and send out in cycle three there is also packet oh okay so basically okay so if that a case so basically the"
  },
  {
    "startTime": "01:38:00",
    "text": "um more likely the controller should say should determine that the transmission time or transmission cycle for for example for node B is from cycle one two three and at node C is from three to five something like that yes Yes actually it is decided okay I see thanks yeah thank you okay uh Jeong dog can you hear me okay yes we can uh okay okay thank you uh so if I understand correctly um cycle of each node doesn't have to be synchronized with the cycles of uh other nodes right uh yes but the frequency has to be synchronized your frequency has to be synchronized then uh how about the controller I mean uh does control only to know when the cycle of each node starts yes if the controller has to Ability exactly because okay so so we need uh we need some times in colonization between controller and each and every node yes right you're right uh okay so controller needs to maintain kind of a separate synchronization with each node to make sure what time instance the cycle of each node starts is that correct yes yes okay okay"
  },
  {
    "startTime": "01:40:01",
    "text": "thank you very much okay thank you that's it yeah okay thank you hang on taking notes okay uh uh tysik can you hear me yes uh thank you okay can you explain how to calculate the psycho duration when there are multiple flows having different traffic specifications can you explain that please uh [Music] um here is a picture but I don't know whether it can show that very obviously this is just a four one flow for example you have a flow and you know the arriving time of that flow and you just uh you just end all the collect information of delay you have collected collected including the the link delay the processing delay and then you know what site code package should be sent out right and then you have another flow you do the same is that your question my question is how it calculated cycle duration cycle and interval yeah you mean the psycho dance for each node in in the slide five"
  },
  {
    "startTime": "01:42:01",
    "text": "in Slide Five okay yes in the bottom of the slide that shows a twin latency 10 microseconds easy 10 microsecond or 10 milliseconds uh occurring delay here right King latency yes right oh sorry sorry I think it's a microsecond right yeah yeah my question is how to decide or calculate that and microsecond of King latency when there are multiple flows having different traffic space Oh okay I I understand your point you mean how to calculate the latency it is determined by this one the the QE mechanisms because we have three cues and uh when the packet is arrives it has to because there is one output queue it means that the this queue is only uh make the the packet out of the queue and don't receive Queue at this cycle and we have two two molecules that means that these two cubes only uh only put the packet inside and it won't uh send out the packet at this cycle so when we have a packet arrives it will be in Q2 or Q3 and in each queue it will uh the the the the output Q lasts that means that the lens of the queuing sending out packet is um 10 microseconds and because there are only three queues and the longest time the package will stay inside the queue is two cycle two cycles so the king lens is 10 microseconds it's in that is the longest time it will be inside the queue but it"
  },
  {
    "startTime": "01:44:00",
    "text": "can be shorter the Jitter will be tolerant um in that uh in this three Q cyclic mechanisms and I noticed that you also mentioned that how it can be guaranteed when there are multiple flows the that is also the the point how to do the resource reservation because the uh because the the cycle capability equals the the the link capability and multiple the cycle generation so if the the psycho capability is full there will be no more kills and uh ended to that cycle so that guarantees that all uh when the the packet is put inside the queue and when the queue is becoming the output Q all the packets inside the queue can be sent out in that cycle it is guaranteed by the this yeah yeah my question was uh so uh is the cycle duration related to the flow specifications it for example frame package interval for of some frame flow it's not related the cycle is uh is planned by each node beforehand and then when the traffic arrives the traffic specification uh will be uh will be different from the cycle for example in in this we just I just make it easy to understand to in each cycle there will"
  },
  {
    "startTime": "01:46:00",
    "text": "be one packet but uh based on the traffic specification there it can be quite different for example uh 10 Cycles one packet it just depends on the traffic specification not related to the cycle planning so so the cycle duration can be arbitrarily determined what decided by somehow right yes yes it can be planning by by the requirement of the network for example um okay anything else okay okay she sung please send me these slides but before you do that please remove the Huawei confidential footer and if the Chinese also says Huawei confidential that should also be removed please yes yes I I sorry I I just yeah I guess I understand this I've had I've had email with my stupid Dell internal confidential labels go to ietf list and I have to go go go fix it so it's I understand just please some of these slides without that footage and I will get them posted for you yeah yeah okay all these all these uh contents are are public so so I will oh I assume it's much the other thing is I saw what might have been patent application IDs here if if those are are important to the draft you might need to uh ensure that that is a super light a suitable uh IPR notices filed with ietf ah sorry sorry the second question is um on one of your slides I saw some large numbers that looked like they might be patent application numbers oh yes I I understand you mean"
  },
  {
    "startTime": "01:48:03",
    "text": "I think you yes yeah oh the one you just had up a moment ago yeah okay yeah please please look into it if if if those are inflows are important to what you're proposing um you'll need to uh you should arrange that they'd be uh disclosed to the ietf yes okay okay I will check thank you okay um let's see those patent number that was on which slide 18 I think it was uh 16. no it was it was either 15 or 18 no no maybe 14. 14 this one no okay there was one of those slides so it must be 18 then I've been lost I can't I can't remember to which side one of these slides numbers one more try 18 there they are it's on patent okay slide 18. okay okay um all right Oh you mean this one yes if that's a patent if that's a patent application um you should arrange to to uh um uh found an IPR disclosure without ETF okay okay I will do that sorry but uh it's okay actually this uh this is for the load balancing it's not for the mechanisms itself but I I will check check Isis I suspect your lawyers have a very good idea about whether this is necessary and how to do it uh yeah yeah okay"
  },
  {
    "startTime": "01:50:17",
    "text": "okay maybe I will stop sharing I think so thank you very much you've certainly uh certainly great reason of questions there's been plenty of time okay anybody else anything want to talk about or show food did you get your audio unmuted oh no more um okay I think we might be done any other questions or comments all right I think we're done I'm not quite sure how to turn the meeting off I think it will turn itself off at the top of the hour zhangdong anybody oh no I I was just saying goodbye okay thank you very much everybody goodbye thank you everyone bye-bye bye bye"
  }
]
