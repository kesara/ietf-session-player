[
  {
    "startTime": "00:00:08",
    "text": "so okay it is the right at the top of the hour and we have a pretty full agenda today so i think we should get started sound good um all right so welcome everyone this is ippm ip performance measurement um i'm tommy paulie one of your chairs marcus here is a new chair joining us so please welcome marcus and thank you marcus for stepping up ian is stepping down in his chair i don't see him here um so we may need to just bid him adieu uh virtually on the list but um he's been very helpful for the past you're in a bit okay this is pretty far into the week so you've probably seen the note well before um if you haven't if this is your first group of the week this is essentially describing all of the requirements and expectations for participating in ietf meetings the various processes we have around ipr as well as around how you participate and one thing we want to highlight specifically this time"
  },
  {
    "startTime": "00:02:01",
    "text": "is just uh some of the aspects of the code of conduct you know this group i think you know for the entire time i've been here has been very good at um interacting well with each other but it's good to just remember um and have it at the forefront of our minds as we're interacting in the group that you know this is a group with a lot of different people from different backgrounds and the most important thing we can do here is to treat each other with respect and to make sure that we're clear and making it easy for everyone to understand and participate and that we focus on having you know technical discussions um that are getting at the details so that we can help progress the work not uh getting into anything uh personal or just trying to stop work um and we're trying to find the best solutions for the whole internet so just keep this in mind in your contributions at the mic and on jabber and i'm looking forward to a great meeting for the meeting management you are here you are in meet echo um just as a note when you want to queue use the little join queue hand sign um that's up by your name on the side of meet echo you can turn on your own video and audio if you are a presenter all of the slides are pre-loaded um through meet echo and there's next to the hand button there's the file button that allows you to um share slides that will you'll be able to request sharing slides when someone else is no longer sharing slides we do have a lot of presentations and a number of quick elevator pitches so there are like 20 slides pre-loaded in here so make sure to grab the right one and be ready to do that the notes can be found here i guess they're no longer etherpad"
  },
  {
    "startTime": "00:04:00",
    "text": "um we should update that on the slide they're in hedge talk but you can find them here and lucas is helping us take notes um and yeah and if you see someone in jabber trying to say something on the mic who can't get audio please relate that and uh marcus can and i can watch that as well okay so on to our agenda we're going to start with uh a good amount of time um about an hour going over our primary documents the things that we currently have adopted in the working group we have some new things we adopted since last time around iom that we want to spend a bit of time going over and then in the second half of our meeting we have some new proposed work specifically we have three documents that we want to go over with 10 minutes each and this first one is related to some work that came out of a recent iab workshop on network quality so that is some of the background of the discussion that happened there but all of these had some discussion on the list and interest from the group and the remaining time will be a number of quick elevator pitches we're trying a new style this time where rather than trying to limit based on time we want people to summarize what they're doing within a single slide so that we can get all of the information up front and hopefully save more time for discussion and feedback and not just be trying to fill up the whole time of the lightning talk with um just you know a presentation of blasting information at people all right so that's all i have welcome ian and we we already mentioned that you will be stepping down and thank you again for your service um all right is there any agenda bashing or should we jump right in"
  },
  {
    "startTime": "00:06:01",
    "text": "okay i don't see anyone coming up so our first presentation will be about some of the iom data integrity and deployments and frank if you could uh ask to share slides do the session for uh for us this time on iom i just got my my third jab yesterday and i'm kind of okay but i'm not feeling that well uh so uh thanks for that yeah okay thank you so here we go um this is going to be a quick update i hope we'll have more discussion time uh since we have 25 minutes allocated for these two drafts these were the two new drafts which were initiated because of the feedback that was received on the iom data draft both these drafts were adopted between last and the this just before this itf um we had discussed data integrity draft in the last ippm last two ippm meetings and we had a bunch of options to meet the data integrity requirements for the um for the iron protocols carrying iom options uh the changes uh um just highlighting the changes that happened uh post while we adopted this work here first change major change was changing it from informational to standard stack because we are defining uh integrity based options uh which are parallel to the the iom data options that are defined are i options that could be defined in other graphs like the direct direct"
  },
  {
    "startTime": "00:08:01",
    "text": "export draft um then we based on the feedback from uh multiple folks in in the work group we uh we adopted method three uh which is a symmetric key based uh signature to protect the integrity of the options as uh the as as the proposed method and mode all the other methods that were discussed earlier were in the appendix that got removed because as as part of the adoption and feedback received during the adoption call and there were some editorial changes done for example we had given examples specific to the options that are there in the iom data draft but had not explicitly mentioned uh options in the direct export or any other iom drafts that could come come up in future but uh data integrity is quite generic it should apply to anything any iom options uh that are that are defined in uh beyond the data draft that that is fixed now and some terminology fixes we had called the inter i mean we were not following the the nomenclature used in the data draft which is now fixed uh so we we do have uh additional feedback and some of the internal discussions among the authors to improve the security sections we definitely want more input on uh yeah we have as2 as256 and chart56 plus hcsa based uh uh algorithms that could be used for diff for carrying out the signature but uh we appreciate feedback from other folks more familiar with what would be other reasonable combination of hashing and signature algorithms that could be that should make it into that list"
  },
  {
    "startTime": "00:10:00",
    "text": "and more reviews on the integrity methods that is adopted is appreciated and plus if anybody wants to try out the implementation uh of the data integrity option especially in the the kernel or in vpp where we have the iom data options implemented that is appreciated okay so that was about the data integrity draft i'll i'll just cover the deployment draft and then we could have discussions unless somebody has questions and we want to stop here specifically on the integrity draft okay actually i just jumped in queue quickly um a couple of questions on the integrity draft so yeah thank you very much for the work on cleaning it up kind of consolidating down to one option the two questions i wanted to check on was a status of implementing this solution and testing it um to see you know how it does this impact kind of the existing iom code bases and deployments and then the other question is should we um as a working group be requesting early sector review and when do we think we'd be ready to do that to get that input from the security area on the implementation i i think it's open for um looks like we may have lost sweat hit the wrong button i don't know um i'm not aware that anybody is coding the thing up right now i'm not sure whether justin is here who is driving most of the work on the kernel"
  },
  {
    "startTime": "00:12:01",
    "text": "oh yeah we have just in here maybe he can go and speak up from this perspective on what he's been covering for either the colonel or yes colleagues also within the vpp implementation so i'm not sure where that work is uh but i'm not aware of anybody else um being actively coding this thing up so maybe we can have other people speak up here from perspective i think once we have i i would not feel comfortable going for a security review unless we have completed the security section which is one big leftover in the draw so that is something that we want to go and fill in um there was a little bit of a hush-hush well you know tommy when you kind of ping me can you get that out yeah i could get that out and um but um there is still a little bit of work to be done on the draft i think before we want to go and go for a proper security review um yeah that's sort of fitting in section six is mandatory that's what i've used great great okay so essentially our next step on this draft is filling that in and then once that's done we can get a security yeah along with what what is also asking right so we have two combinations listed right now for what people want to go and do from a signing perspective and the likes so what algorithms you would appreciate if there's others that people see as high priority let's go and speak up on the list please so that we have a relatively comprehensive set of things included um so that we are at least i think from a from a working group perspective given that this document is really a document that has been kind of shepherded and requested by the working group uh that we have a relatively good representation of what is in there right yeah so please speak up and voice opinions of what you want to go and see included so that we're comprehensive yeah i i would suggest the small set of algorithms like just let's you know choose kind of the best ones"
  },
  {
    "startTime": "00:14:01",
    "text": "that we need but not too many uh in there because that often times is a bad right so it's symmetric the ones for asymmetric but if people have strong feelings around other things then let's go and get that in and as i said like um yeah i think we could probably give it another round for the next meeting that will hopefully be in person and uh then maybe we will really offer and hopefully we can also find out from implementations you know which algorithms are convenient for them to use or most conducive to their code base all right thank you that's all i had thank you sorry for the network glitch i'll i'll continue with the deployment draft again this was adopted recently and we have revised it based on basic feedback that was received some of the feedbacks uh some feedback is addressed in in the current zero zero version of the group draft uh we aligned the the limited domains per rfc 8799 and again aligned it with the ion data terminology which was which was good feedback that we received uh we are going to continue keeping uh this alive uh we want to keep it up to date with uh the new deployment experience that we have with the the kernel implementation as well as another open source implementation in fido vpp we do have iom support for wireshark"
  },
  {
    "startTime": "00:16:03",
    "text": "which we we need to update the draft with further reviews are appreciated and before we go into the discussion i would just i want to go and give a big hand to to al morton who caught a lot of nits and so thanks al for for all the feedback that you've been given until to improve also the language and the draft like show in the queue um sherman do you want to speak up during the working club adoption poll of this job i sent my support and also a suggestion to include iom encapsulation over beer into this chopped the scope of this job but uh it's not in the zero zero version working group draft [Music] is there any special reason why uh blm is not included i we have not addressed uh sorry good friend yeah you can blame me i think i forgot about that i'm sorry for that okay thank you we'll fix that good point thanks for bringing it up i'm sorry okay"
  },
  {
    "startTime": "00:18:07",
    "text": "yep um that sounds good and i think we gained back a lot of time which is very helpful so all the other presentations will appreciate it thank you so next up we have iom confistate and showman do you want to come back up for that great is my slide okay to you it looks good to me okay good thank you thank you tommy uh hello everyone uh it's xiaomi speaking this presentation is a accurate request to apply for enabled institution capabilities this is a working group draft and the latest version is zero one zero zero version of this chapter has already been presented at the last itf this is the summary of the two main updates in this revision firstly this revision changes the format of iom capabilities query and response from dlv to container and the reason is that for icmp v6 and taking example by rc 8335 iom capabilities query is not a tov of echo request but the echo request itself the same goes to iom capabilities response it's also not a tov"
  },
  {
    "startTime": "00:20:02",
    "text": "but the echo replied itself secondly this revision changes the format of response contents from sub to v to object and the reason is that for icmp v6 the extensions contained in echo request reply are not to sub-tovs but objects also note that in six-man working group and the zero zero version uh individual draft javascript uh six-man icmp v6 iom comp state has been posted before ietf112 and this new individual draft has been presented in six-man working group on tuesday my my personal feeling is that uh i've got positive feedback from there uh the internet id and six man chairs uh have no objection to extend icmp v6 for iom capabilities discovery as long as the ippm working group has a rough consensus is the right way to proceed this slide is about the first main update that changes query header and the response header from type lens to container header this figure shows the instantiation of container header"
  },
  {
    "startTime": "00:22:00",
    "text": "for icmp v6 iom echo messages it can be seen that the container header of icmpv6 does not include exactly uh type in the lens it includes a type code checksum identifier sequence number and a number of namespace ids so this change is needed also note that for nps lsb ping f sfc ping and vrp the container header is also applicable this slide is about the second main update that changes response con contents header from sub tube subtype lens to object header this figure shows the instantiation of object header for icmp v6 iom capabilities object it can be seen that the object header of icmpv6 does not include exactly uh subtype and the lens it includes a lens class number and the c type so this change is needed also note that for mpls ping sfc ping and the beer ping the object header is also applicable except for them two main updates there are also some other uh mentionable updates the first one that a list of namespace ids must be included in an echo request in last version uh may is used here we think master is more appropriate specifically if you know any other namespace id then a default one"
  },
  {
    "startTime": "00:24:03",
    "text": "zero x four zero is provisioned at the iom encapsulating node then the default one must be included if other namespace ids then the default one are provisioned at the i am encapsulating node then the provision the namespace ids must be included and the second dimensionable update is that for the feature described in this document to work more optional pre conditions are provided they include the explicit path is used or only one path can be used or echo request message experiences the same ecmp processing as a data packet the third mentionable update is that one new double bit is borrowed from the result field of iom pre-allocated tracing capabilities object and incremental tracing capabilities object it's used to indicate whether the object carries a 16-bit egress interface id or the object carries a 32-bit egress interface id so uh next steps for this chapter we also ask for more reviews and comments uh we'll revise this chapter to improve it and then we'll ask for working group classical and thank you all right uh thank you frank go ahead"
  },
  {
    "startTime": "00:26:04",
    "text": "comments um the first one is if you go back to slide six uh what we seemingly do right now is that we have a kind of opinionated choice of what we want to go and get included into one of these echo replies that you're transporting back to the requester which is kind of a bit field that we come up with here right and it's inspired by the data types that we have in the data draft but it's not the same rather than coming up with kind of new definitions here would it make sense to rather come up with an encapsulation or a translation of the yang model that we have that describes the various fields into an encapsulation into your container that you want to go and carry in your protocol i think that would make much more sense and it would avoid the redefinition of fields rather than yeah what we have here so i think aligning that and coming up with a mapping from the yang model that would go and be encapsulated over icmp or whatever carrier protocol you want i think it's the cleaner approach that's at least my suggestion and the other point that i have is we are starting to use icmp as a network management protocol so we should also go and treat it as a network management protocol here in the security section you say yeah icmp can be eventually secured with ah or even esp headers included um that's fine but i think we want to go on the top language language that is similar to what we use say for instance in the netconf rfc uh so there should be more less cans but more shoulds of what you want to go and use so that we have proper security in place because you probably need at least some form of integrity checking and even more right because you can retrieve a"
  },
  {
    "startTime": "00:28:01",
    "text": "load of configuration information from the notes this way between the requester and the responder that's it thanks uh thank you i i think uh i i i uh know your comments uh uh from uh previous itf meetings but uh i'm not sure uh how can i uh encapsulate the young model uh data into the uh into this response message so is is that your uh first suggestion to include the young model data into the response go and build an encoding for the yang model uh similar to what we've done for netconf right um into uh what you're transporting here and that would align that we have in indeed like the yang model represented in the communication that you do between the notes because end of the day i think what you have with icmp define a container and then you just ship messages over that particular container back and forth between the node and i don't really see a reason why we should go and treat icmp as a different protocol than any other network management protocol that you're using here right so the reason the wheel for a specific let's not create a specific encapsulation of a network management protocol into icmp rather than we have something generic for managing individual um icmp individual iom notes and let's stay with that and then you just treat icmp as a carrier or beer as a carrier or whatever to my understanding uh if if we use netconf here then we need to establish a net kind of connection between the encapsulated node and"
  },
  {
    "startTime": "00:30:00",
    "text": "each transition nodes right do netconf but i think you given that you want to go and carry network management information over a channel you don't want to use netconf you you're creating your own transport protocol using icmp but i think the there is no need to go and redefine what you do from an object's perspective because that is in the young model the reason why we choose yeah the reason why okay tommy yeah i think we're a little over time on this item we're overall ahead on time but um i think this is a great discussion um i think this is a good point to drill into um and maybe this is something that frank you know if we can take this to the list and just kind of go in depth on the different options about how we can not end up uh reinventing the wheel for the signal i think that would be a good discussion to have there does that work for everyone all right any other questions or comments on this okay it doesn't look like it okay thank you yeah thank you thank you very much this is good good update okay let's let's hammer out the details be good all right next up we have explicit flow measurements or i want more than one spin bit um"
  },
  {
    "startTime": "00:32:02",
    "text": "all right tomorrow hi hello hello hello we can hear you do you want to share your slides using the preloaded slides yes you can share my slide you can drive it yourself so if next to the hand icon okay document yep so if you click on that little file icon file icon is this okay yes yep exactly and so now i'm going to approve you and then you should be able to select through all of the slides and find the ones okay okay is verbs okay thank you i find sure okay there we go okay we can start okay you can hear me it's good to sound okay we can start okay i can summarize in a simple same sentence the specific measurement concept"
  },
  {
    "startTime": "00:34:02",
    "text": "explicit flow measurement techniques employ a few marking bits inside the head of each packet for los angeles measurement protocol independent evaluable for encryption either import protocols in particular the metrics described in this draft are several the first one is the rtt matrix that we expand the first idea of spin bit with the idea of delay bit and the new idea of hidden rtt that it can be applied both for spin bit and for delay b because it's possible to delay the signal from a certain amount of time in order to give them the real rtt for people that are not allowed to understand it after there is the round three packet loss that is made using the spin beat and the round three plus bit the t bit and finally there are two options for the one-way packet loss the first one is the square bit that is already noun techniques in 83 21 fc and they lost event beat as a second bit of in the in alternative the square bit the same bit with the reflection square with that reflection from the other side the square wave that they could be to generate again there is some implementation both in the academy and in the field in the last academics we experimented with other companies for example ericsson huawei and so on some experiments about this quick measurement there are some implementation in the field the first one that we displaying this transparency is the recommendation implementation on android mobile phones that is inspired the draft about user"
  },
  {
    "startTime": "00:36:00",
    "text": "devices uh monitoring that is presented in the last part of this meeting there is the ericsson implementation core network problem that detects the spin beat title at marking and make the measurement the orange akamai implementation that is the first one that implement on the field the packet loss using qubit and albeit the arcane university had an experimental implementation they presented a paper in an fbw that compared all the techniques that we described in this draft albeit arbit and tibit and they experimented it and concluded that they works with various pros and cons and finally also by way is starting to work on the topic and with presenting next academics or some experimental trials okay some words on the hidden beats that is the last last bit that we introduced in this draft in the last the version that we presented in july the idea is is born because the spin bit is not so much implemented we using our devices we spread some probes on our mobile phones that telecom italia uses for some experimentation in our network and we saw that there isn't uh market packets inside the quick quick is quite used for example by google application but also facebook application and many others but no spin bit is marked so it is uh implementation that is defined as not mandatory in the standards in the fc 9000 is not implemented in the"
  },
  {
    "startTime": "00:38:01",
    "text": "field uh in italy almost but i think all over the world is the same so we think that to add a feature to that we need that then did i beat but it's possible so to have the hidden spin beat in order to mask the real rtt and introducing this simple mechanism that adds some delay in the reflection so the packets are reflected the real traffic works in the same way there is no delay in the real traffic but the markings delayed so it's possible to mask the reality but it's possible to have some measurement but knowing the time that we added but also not knowing it because if the measurements are between an observer and another observer or between a server and the server the the measurement are correct the end-to-end measurement is not visible unless you know the other the additional delay okay the main change of this draft dementia is the first great news is the eppm working group adopted this draft some days ago and we updated the draft the new version of the draft adding the new name and introducing a couple of changes that are suggested during the last during the working group adoption call in the introduction paragraph we underlined the beneficial approach of the methodology described described inside the document as per the lfc 1965 thanks to the nikola scan suggestion so it is this kind of methodologies is beneficial in this case and we updated all the references using"
  },
  {
    "startTime": "00:40:02",
    "text": "the new rfc that are standardized so there are see 90 000 1965 so we updated all the references that's the slide okay this is the summary of all the methodologies that we present in this draft the idea is these drafts is not to make a clear choices over one methodology instead of another but we we intend to present all the possibilities and then we are the intention to present in specific working group that are devoted to specific protocol the right choices for this protocol because a kind of marking can be useful for a protocol and not so useful in another protocol a clear example this idea is in the slide that we presented the lost lost beats summary because the main two methodology bot uses the square bit as first bit to mark because it's a very simple technology well known because already implementing field using the rfc 8321 as a reference but we have to add another another bit to have end to end measurement because the square bit for this nature is not a 20 measurement but is origin to observer measurement we can measure only the loss between the origin the client and or the server and the measurement point because we mark the blocks of 64 packets and if the number of packets marked with the same color 0 and 1 is less than 64. there is"
  },
  {
    "startTime": "00:42:02",
    "text": "a loss between the origin trying to serve and the measurement point so to have and to animation we have to add the other another bit the loss event bit as proposed by akamai and orange in the their airdraft that we joined with in in this draft or the team recom italia proposal to add the reflection square bit the lost event bit generates a market packet every every loss detected by the protocol the reflection square bit reflects the square wave on the other side so it's possible to measure the round trip loss using this reflection all the two methods are quite good as the arcane paper demonstrates there are some differences because the loss beat the l bit is very simple to implement is more simple than the reflection square bit but it is dependent from the protocol so if the loss is detective of the in the protocol the lbt's market is not detected is not market so it works well with quick so in our opinion can be a right proposal for quicker it works less well for less is less good for tcp because for example the packet is not detected as losses so if i load i'll uh i know is lost the protocol the tcp doesn't uh measure it is lost so it's better to use for tcp in our opinion probably the uh the r bit but it is a as i said before this is only a general review of all the possible techniques"
  },
  {
    "startTime": "00:44:00",
    "text": "there is a next step will be to the will be to select the best bit to mark for each protocols next we can show this slide so we have many possibilities if there are only two bits for a specific measurement there are two possible options in my in our opinion is the most significant the spin beat and the t beat to have the round trip time and round three packet loss using only two beat but the tbt is uh is less precise that uh using a qubit and albeit or jubitan and arbit so is a we propose to use only if we have only one only two beats and only one for the loss the option b is to use uh the debate or the uh mask the diabetes and delay beat for rtt and to use the one-way packet loss they could be for the loss in this case we don't have the end-to-end measurement for the loss but only the origin to a problem measurement for the loss so it's a compromise if we have only two bits if we are we have a three bits that is uh the best option for uh monitoring on using a specific measurement and for example quick is possible to have is not defined in now but it's possible to have three bits there are four options in that we have two choice to have a choice but the first one is to use for rtt the spin beat or the idiom version of the spin beat if can be useful to mask the rtt"
  },
  {
    "startTime": "00:46:00",
    "text": "and to use one for the one-way packet loss qubit and albeit in order to have origin two measurement point loss or end-to-end loss the other the option d is very similar there are only the substitution of spin beat where the more precise but not so well known the beat and the option e is the equal to the previous one but we uh introduce the r bit in instead of the l bit this can be useful if we don't want a measurement that depends from the protocol because that'll be the signals the losses detected by the protocol if the protocol don't then take doesn't detect the losses the albeit doesn't signal the losses that bit is independent so is more complicated of the albeit and the rather problem is that there is a delay in the measurement because we have to wait a square wave of the qubit starting from the client reaching the the server and converting in the reflected square wave and come back so we have a two round trip time more plus the the time of the square wave to complete the first measurement but a little bit instead a little bit is very quick because there is a market packet when the protocol detects but in this case their bit is totally independent from the protocol so if also the protocol done doesn't detect the loss the arbit can detect it uh okay the last slide i'll spend the time for one minute okay so we can conclude uh conclude some thoughts about that is a draft they there are some implementation there are some on feed implementation the eppm working group adopted the draft we"
  },
  {
    "startTime": "00:48:00",
    "text": "presented some some sibling draft there was another one in this working group about the positioning of the probes the idea is to positioning the probe in the client in the client because so we can save hardware using the hardware of the client to make also the measurement same advantage that we explained in the presentation at the end of this meeting another sibling draft is presented in this session of the core working group about the co-op protocol that was another protocol client server that can have some extension to have some additional bit for marking so we we think that can be a good idea to present this in the future if the working group are interested we can try to present an implementation for quick having a choice of the right beats okay this is all thank you all right thank you um we do have some time for questions i've seen some comments in the chat trying to clarify [Music] the the hidden bits and exactly what each party can see and what can still be measured with them so be good to clarify that maybe okay the hidden beat the idea with it in beta can be applied to every bit that measure the rtt because it can be applied both for the beat and for the traditional spin beat the idea is to delay the reflection of the of the packet that detect the the the square wave for the spin beat or the uh sample delay sample that is the"
  },
  {
    "startTime": "00:50:01",
    "text": "single market packet that is used by the light beat so when for example for the spin bit when the square wave that is uh the the front of the square wave that uh signal the starting of the rtt or any of the rtt arrived to the client the client don't reflect the end of this square wave immediately but he continually continued to mark the packets with the same beat so if we are in the one period for example the rtt is 10 milliseconds and the additional that we add is other five milliseconds so when the square wave reached the client the client don't change immediately the front but it weighed other additional five milliseconds to change the front so the server don't measure the right rdt but the right elementary plus 5 millisecond this masked only the end to end rtt because if we measure using a probe dirty between the observer and the server for example the server don't add anything because it works in the same way that it work for this enormous pin bit or normal bit so the measurement observer server observer the rtt is right so it's possible to segment the network and to have a partial measurement correct but not end-to-end measurement the only measurement that is a masked is the round trip between client and observer i see okay and the only extra delay is added"
  },
  {
    "startTime": "00:52:01",
    "text": "on the client side not on the server yes only the client side perfect okay and i think that's roughly what the chat was getting to as well but that is helpful to have clarified right and it's impossible to to choice to choose that uh it is adding timing many times in many ways we propose to choose a fixed amount for each client so the position the client is moved for exactly the same amount of time so the same amount of kilometer let me say for all the time so it's impossible to detect if there is the right distance or a fake distance because they add all always the same amount of time that makes sense all right thank you thank you okay next we have the draft on connectivity monitoring are you able to find your slides in there there we go great we'll find it thanks um yep i made the presentation before i updated the draft so these uh presentation refers to the older version i mean while updated the draft on monday and it contains a packet loss based uh specification for a connectivity metric which is just announced here in"
  },
  {
    "startTime": "00:54:02",
    "text": "this i also have changed um the status from standard strike meanwhile to experimental because i think that's more suitable i not able to come up with an implementation very soon so i think that's fair um don't i think i moved to the other slide yep um and that is uh indicating how the loss-based connectivity metric is going to work the router sketch which is uh on the upper part is already part of the other presentations and there are three measurement loops passing each connection or path to be monitored and uh two go to the same direction always per uh upstream or downstream and there's always a contra the direction and uh there's only two measurement path going per direction either upstream or downstream and the idea then is if there is no packet received with within one measurement interval inc t on all of the measurement loops per monitored interface then you decide on connectivity loss and the simple definition of distance between two packets per measurement interval to me seemed seemed"
  },
  {
    "startTime": "00:56:01",
    "text": "to be to wait for the measurement loop which is producing the longest measurement loop delay and then double that amount and simply send packets only after that has passed on each individual measurement loop that means you only send a measurement packet along along the next loop once you've received that of the last one which is maybe not the fastest way of operating it but it's pretty reliable i think and then [Music] you simply count whether you have all those passing the connection which you monitor and i've used the colors to illustrate that down there and once you did not receive them within the time when you send the next one and it doesn't matter in which order you do that then you decide that this connection has failed the whole idea is to overlay all these measurements so what you see here is the individual combination of measurement loops passing this monitored interface and if you are interested in details terminology is adapted to try to illustrate that as good as possible and you can read how that works and i'd of course be happy for comments and i'd like to add that the question about timing has been put to me several times so i think or the intent now here is to to answer these questions and come up with a scheme how it works all right"
  },
  {
    "startTime": "00:58:00",
    "text": "and that is it from me it looks like greg is in the queue um still i'm not really comfortable with the terminology because traditionally the connectivity is uh state uh in a fault management oem so and if there is a connection um so actually when we are referring to something as a connection we understand that it's uh not only ability uh to receive test packets but uh on that connection that belong to this connection but not receiving packets from other connections so basically absence of misconnection uh state and uh misconnection uh definition uh usually specific um at itf since well we are dealing primarily with the ip and um mpls if it's a pmp-ls and not traffic engineered then we usually refer to the laws of path continuity and the protocol that used to that extent is a bidirectional forwarding detection uh bfd and one of the things that property of bfd is that uh their session goes down or path loss continuity state uh declared uh when i lost three consecutive test packets and uh even though the protocol supports uh doing that on the first"
  },
  {
    "startTime": "01:00:01",
    "text": "packet on only one last packet there is a good reason to have three it's not only similar to how ethernet oem works but it provides certain stability i'm somewhat concerned that uh in this proposal uh the miscon a loss of connectivity declared on a very first packet because then uh if that's the case then uh so the next packet what next packet will mark the connection as up um then uh we'll have probably states bouncing up and down interchangeably if uh we have a flaky uh connection um on the other hand the uh packet loss ratio or some other statistics uh will indicate that the connection um the path is not stable but uh from the uh fault management perspective um bouncing states and generating uh alarms and clearing our arms and that would cause a lot of uh confusion so um maybe that's something that needs uh further uh discussion and uh look at and especially how it relates to default management oh yeah um yes adding some text with a relation to fault management oim uh i probably need to do that i'm not a bfd expert the state of lost connectivity is declared after three packets have been lost if you look at the illustration below it's uh that red uh link lsr2 leri is disconnected that"
  },
  {
    "startTime": "01:02:01",
    "text": "what the text says also in the draft is you start with sending packet f2 uh index one and then you send f3 index one and the expectation would be if you send a packet at t2 it should have been received at t3 if you send one at t3 it should have been received at t4 and so on and if you look at the blue one at time t5 it should have been received at t6 so these are three packets and if they haven't been received until t8 which when when you would send the next packet on f2 then you declare the state to be disconnected so um yeah it's three packets three packets which should have been received for a long time then or sometime then at t8 when you declare it to be uh disconnected yeah uh i'll be uh happy uh to discuss uh with the bfd because i'm working on it extensively yeah sure that would be helpful yeah okay uh we can continue discussion on the list thanks yeah i would appreciate right thank you get on time perfect okay and last of our adopted documents uh we have the srpm do you want sharing your screen just share the preloaded slides instead of the screen button you can press the the document button try click that again sorry yeah you see it yeah yeah can you can you click the"
  },
  {
    "startTime": "01:04:01",
    "text": "document button one more time to ask to share okay i cancelled it and i'm asking again here we go yep yeah you are now granted you see i'm setting it now we do okay great yeah hi everyone my name is rakesh gandhi i'm presenting a very quick update on the stem extension for sr on behalf of the authors listed so uh agenda is a brief update and revision02 just to highlight the work happening in other working groups on the stamp extensions and next steps so there is very brief minor updates in revision zero two mostly editorial changes uh we converted ni into table format and we have no open issues at the moment uh there is uh extensions uh that's built on the great work done by ippm with stem spring has two drops on srpm and also there is one in mpls with a new encapsulation for pseudo wires so uh welcome your review comments on those traps as well so uh just uh we are seeking more review comments and suggestions for this draft"
  },
  {
    "startTime": "01:06:02",
    "text": "and we'll wait for maybe one one more itf before we request a last call so that's all i had any comments suggestions yeah thank you okay and now we're going to move on to [Music] our proposed work um actually before we do that before we do that there is one thing i uh slides which is we did we did uh publish rfc emergency indeed so i just wanted to say congrats to those authors and thanks for getting that work through all right kristoff i'm going to approve you here and get started okay hello can you hear me can you hear me fine good it's good good great um hello everyone um i will present our internet draft responsiveness under working conditions and uh as this is uh the first time i'm presenting and i'm giving a little bit a start with a little bit of background first um so first my what is it actually what we are trying"
  },
  {
    "startTime": "01:08:00",
    "text": "here to solve here what are we trying to address here um the first problem is that we realized is there have been 10 and more years of buffer bloat in the sense that it was made very public more than 10 years ago solutions quickly um started popping up and were being standardized and implemented but still today buffer bloat is a very common problem and why is that one reason we believe that is the reason is because there is first of all a lack of awareness and the lack of tools the awareness of buffer bloat for the end user would allow to use the end user as a forcing function to drive the solutions to being deployed and find a tool that allows to measure it would allow to actually measure the buffer load and allow operators vendors and so on to build benchmarks to to minimize buffer load a second problem that we realize exists is there's not really a clear definition of what buffer load actually is and if you ask different people um you will get different definitions of buffer bloat um it's also not clear how you can measure it is an icmp ping while doing the file transfer good enough do you need to um flood the network with udp traffic and then send tcp request response dns can you use dns to measure buffer bloat right it's not really clear and there are some tools that exists like dsl reports fast.com waveform and so on that are measuring buffer bloat but if you compare one tool with the other they have hugely different methodologies and when you run the tools they provide completely different results so it's really a problem of"
  },
  {
    "startTime": "01:10:00",
    "text": "we don't really know what is buffer blown and how does it impact the end user so we believe it's time to for standardized metric of what we call responsiveness under working conditions which is what is exposes problems like buffer blood so first of all we want to measure responsiveness for the end user and that means that implies a certain set of things first of all a realization that buffer bloat while typically you think of buffer bloat as something that is a big da a big q in a bottleneck router that is being filled up buffer bloat can happen at many different places right it cannot only be in the bottlenecks router it can be on the server it can be on the client it can be in the service nic it can be in the server's tcp implementation or even in the http implementation right and we have found that in many cases the buffer bloat and http implementations are way way higher than whatever you you can measure on the internet so sometimes the problem is at a different layer where you would not expect it so this implies that if we want to measure um buffer bloat between quotes because of the sudden buffer load is no more just on the bottleneck router but it can be anywhere right if you want to measure bar for load it means you need to use the modern protocol that the end users are actually using which means you need to use for example http 2 hp 3 you need to use tls and so on you also want to measure all stages of the connections right if you have a good solution to handle buffer bloat in your tcp stack but your dns is still going to go through a shared queue that is completely bloated well your user experience will still be very bad so you need to measure all stages of the connections dns tcp tls and so on and so on and finally if as if we want to use this"
  },
  {
    "startTime": "01:12:01",
    "text": "kind of metric as a forcing function we need it to be user friendly and we needed to be expressing the number in a way users can understand it so how do we create what we call working conditions because in order to measure buffer bloat in order to measure the responsiveness when under working conditions we need to fill the buffers right now filling the buffers can be done for example by flooding the network with udp that would definitely very reliably fill the buffers can guarantee that however it is not a realistic traffic pattern nobody does that and so in order to measure buffer build we need to create a balance between a realistic traffic pattern while at the same time reliably filling those buffers um and so for example a good choice would be running several http 2 bulk data transfers right now on the other side also with quick coming along well in the future we rather would want to probably use quick instead of http 2 because uh the buffering can be completely different for quick now in order to measure responsiveness we need to create those working conditions for an extended period of time because we need to measure it repeatedly and get multiple samples to have a stable number right and so we need to gradually add flows and monitor the good put evolution to create this kind of a stable condition where the buffers are roughly full and the good way to do is the way we do it is for example in as we describe it in the idea in the draft here is we start with a certain number of connections as those connections go through tcp slow start the good put is going to ramp up and it's eventually going to level out and at that point the only way to increase the good but is by adding more connections so we have more connections again you will be able to see it the"
  },
  {
    "startTime": "01:14:01",
    "text": "good part increase again and then it levels out again and then you basically achieve a state of saturation where your network is as full as it can be with a reasonable um with a reasonable networking load so once we have these stable uh working conditions we can then go and measure responsiveness right and there are two ways to measure it the first one is by using those connections that are creating the working conditions by using these bulk data transfer we can send an additional get request on those connections and measure the latency for those get requests this is great because it allows to um expose bad http 2 and tcp implementations on the client and the server side and it also exposes bad buffering in the network another the second approach and maybe or orthogonal to it is measure the latency on separate connections right for example creating a short-lived http 2 get request which then allows to measure dns tcp tls and the get request while the network is is fully loaded nick is allows to expose flow queueing in the network which is a good property right because it allows to work around some of the issues around buffer bloat and then we need to as we gather all of these latency measurements we need to aggregate those numbers into a single result because we want to have it being a user-friendly number and so we can take an average a 75th percentile and so on so finally as we are doing all these measurements we then expose what we call the round trips per minute and we do this round trip per minute instead of latency because it is more user-friendly which is one of the goals that i mentioned initially is we want it to be the higher the better we want it to range from the low tens to"
  },
  {
    "startTime": "01:16:00",
    "text": "a few thousand a few thousands and we want it to be a nice analogy to what we call revolutions per minute so the rpm number is a good way to present buffer bloat to the users now this methodology is something um is currently a work in progress and we are very much looking forward to feedback we have currently an implementation uh in macos monterey and in ios 15 and we also have published service server-side implementations for it on on github that i will show in a minute so we are very much looking to uh collaborations around this effort to define um to properly define a way to measure buffer load and responsiveness under working conditions in our internet draft that we wrote we are using http 2 and we are very open to other suggestions on how to measure it because there are many different ways to create those working conditions and there are many different ways to measure the responsiveness and so this is really a call for contributions for people to come and join this effort to um to give suggestions on how how to measure responsiveness we believe that this would be very um useful and we are already seeing how the two can be used to actually debug bad http implementations in the wide end so we believe that this would be very beneficial for the overall user experience so with that i'm very happy to take any questions thank you martin hi christoph this is uh really interesting really interesting um um a couple so it seems like there's two separate proposals here there's a um like a methodology and then there's a metric um so i actually have one question for each so for the methodology uh this this background these background connections racing are they just"
  },
  {
    "startTime": "01:18:00",
    "text": "downloading an arbitrarily large resource to fill the pipe yeah yes that's right um okay it's just an arbitrary uh it's basically an infinite file yes right okay and then the second question is about rpm um so what what exactly is a uh round trip how is a round trip defined so if they're doing a get does does that imply that an entire resource is arriving or is there some packet coming back so um in the draft we specify also the what what the the protocol would be and so what we what we require is that the server is able to provide one very large file one very small file basically just one byte and allow to upload data and so the small file is used for latency measurements and because it's just one byte it would be one packet um so that's that's basically it so in order to measure latency if we send a get request it takes it's just for the time it takes to get the response back now the assumption is that um honest on a cdn implementation the assumption is that this byte would be locally generated so the cdn wouldn't need to go back to the origin to fetch it so that's that is not this kind of latency in in the picture do you want to share your audio thank you you guys hear me ah no you can't okay okay great yeah this is this is uh very very interesting"
  },
  {
    "startTime": "01:20:00",
    "text": "yeah yeah i'm getting i'm getting an echo um hang on yeah no anyway i hope you guys are not getting an echo but anyway i think this is very interesting and um i would be very curious because our pdm is a performance and diagnostic metrics for ipv6 that is installed both at the server and client end and the idea of pdm is to separate server time and client time because this is a problem that many large enterprises have and i would be very interested to see how um what what kind of measurements we come out with using your test data so so as i said i think this is this is a quite quite interesting details of pdm so i will all need to look into it and learn a bit more about it sure i'll contact you offline all right uh lucas i should probably cut the cue after this hello can you hear me okay okay so just a quick one you mentioned maybe being able to detect bad http 2 or quick implementations but i just a word of caution that there's many ways to be bad um you know there's lots of things in these specifications that may be a bit optional and people choose just not bother implementing them so i just caveat or try to caveat what you mean by a good or this is bad this is for like raw throughput or scheduling these kinds of considerations it's a very minor point but i think for"
  },
  {
    "startTime": "01:22:01",
    "text": "for nitpickers like me um or people who are really into web performance where the workload's slightly different just quantifying good or bad might mean something the word bad was probably a bad choice of words sorry about that all right i think we're up time on this one um thank you stuff and it'd be good to hear more comments on the list especially from people who have a lot of deep experience with existing ippmetrics and now we have al wearing a deck all right are you able to find your slides in there al i know i know there's a lot still i'm still looking for the slides tommy maybe i should just go with the uh the screen let me try to see if i can find them there um yeah if you want to share your screen that's fine too all right cool"
  },
  {
    "startTime": "01:24:09",
    "text": "and i think you still have to give me oh yeah here we go still yes i do all right i'll do the screen and uh let's see screen one i think is this one yes okay and allow and slides all right i guess i'll just make this as big as i can all right so um thanks everybody and and uh uh for um joining in today and thanks uh tommy for the congratulations on on the uh one-way ip capacity measurement uh rc 1997 where uh was a long road longer than we thought so um last time about the protocol i gave a uh let's see here i've got the time covered that's not going to help so um what i wanted to do is is basically talk about some special features of the protocol since last time we talked about security features and didn't get much traction with that so it's it's kind of a unique protocol that we've developed to do this uh you know what so we're going to talk about what's new in the protocol where the functions reside between like a server and a client matter and first and foremost thanks to the reviewers jan that's how he pronounces his name lincoln rudiger and greg so on to the next all right so we've we've seen this in in various forms the protocol setup and and"
  },
  {
    "startTime": "01:26:02",
    "text": "phases uh you know we've got a setup exchange a test activation exchange and um the most important point i want to make about this is that you're you're actually testing connectivity when you're uh your client is setting this up and also um opening ports and and so forth in the firewalls and translators and and so forth so um you know these are these are important parts of the exchange uh and and it's always good to record when you've lost connectivity uh to your server or between your client and server uh those are the kinds of things that relate directly back to um you know whether a user has connectivity in general to the to the internet specifically to one particular host but that might be uh you know a sort of a catastrophic indication as well so recording failures is is just as important that's one of my workshop uh points um but then we're going to go on mostly today and talk about the test protocol on the test protocol is the um where we send test stream uh pdus and uh and the most important part is that we get measurement feedback here so the measurement feedback is uh is exactly what we really want to emphasize and so we're going to carry these colors through the load use our um in the uh in black and the uh feedback pdus are in blue all right and not showing anything uh else here other than that um and uh of course this is uh the protocol that we're currently using in uh running code so so here's the test phase operation i've got two scenarios side by side i've got a downlink scenario here where the server is in the network that's on the top it's in the role of the sender and the test controller always resides with the"
  },
  {
    "startTime": "01:28:02",
    "text": "server so that's an important functionality and it doesn't doesn't swap completely when the sending and receiving roles change places so let's look at this quickly you know the sender's deciding what uh downlink uh test track traffic rates it's going to send that for our our classic uh iplayer capacity measurement the receiver receives that traffic and it formulates a reverse path feedback message uh which includes uh loss delay and reordering measured on the the scent rate on uh and it sends it back every 50 milliseconds and i i didn't even include the fact that it measures the rate here but that's a fairly obvious thing that's happening so then um every 50 milliseconds that feedback message arrives at the sender the test controller acts on it it runs the load adjustment algorithm and uh controls the sender rate uh it can select a rate in the table with our current logic and um and that's kind of what you see uh depicted here down at the bottom so we're you know we ramp up the rate at first uh ipgr capacity on the y-axis and time on x and you can see us searching for the maximum capacity here in the typical uh you know rfc 9097 method and then metric so um we uh we reverse some things and change some information that's exchanged when we do an uplink test um so now the we've arranged for the sender to do the sending from the client side and so the uplink test traffic arrives at the receiver and now the receiver's test controller function is to perform the measurements and it keeps those measurements to itself it runs the load adjustment algorithm and it sends the next rate uh to be used over the uh the next feedback"
  },
  {
    "startTime": "01:30:00",
    "text": "interval back to the sender so the um the reverse path uh contrary contains mostly the sending rate structure which is identified in the protocol and this contains you know the size of packets the marking of the packets uh the rate at which they would be sent and um and so forth and someone's looking for me to go full screen which means i won't be able to see further comments like that so uh good so um what we've what we've basically enabled here though is that for the the test controller logic that we've currently defined uh what we've got in is the capability to change that logic and so you could create alternate forms of reaction to the network or or simply uh changing the rates and the and the time rates over time uh the packet sizes and their burst composition over time and and so forth so it's a it's very much a a a a a uh you know a very complete and uh uh easy control of the um of the the testing situation i i wanted also to mention that we we measure round trip time on on a sample basis and that's on the basis of these feedback uh messages so we always have an estimate of a round-trip time going on okay so let's see uh i gotta hurry through this now so we we've the we've got lots of motivation for the new protocol um you know it's different from a session sender in that you um uh you know or the reflector we're definitely not sending packets back every time uh it's different from owamp in that there's a fetch and sending results at the end of the session and the the uh uh the security for uh owamp and ramp is kind of old and was described as unusual it was a little bit"
  },
  {
    "startTime": "01:32:00",
    "text": "challenging way back then so um uh we've we've had some good comments as i mentioned and um uh one of the things i've decided which made it kind of easy to just to decide where we stopped with uh the zero two update uh we're gonna stop uh describing uh version eight after this uh version and so new updates will result in a version 9 or higher versions of the protocol so that's good that frees us up and of course we've got running code and the running codes available you can get that link from the draft when we see errors during setup there could be multiple errors right now we're using a hierarchy you know where the first bad thing that happens is what gets reported as an error but we could make that a field with flags both of those options are described in the current draft one of the options that jan asked for uh was uh options for the payload uh you know whether it be all ones or all zeros or alternating or pseudo-random that helps a pseudo-random helps out with compression links like on satellite and then um then we've got this last one here which is uh interface measurements where we're actually in the in the running code right now we're actually making diagnostic measurements on the interface uh that observes all the traffic so you know way back here in a downlink test if we've got test traffic sharing traffic with user traffic uh we can measure that at where two and it's a kind of a hybrid type two measurement at that point uh before that it's it's purely active so uh we've we've got that going now and um you know you could you could uh you could make that a make a case for that in the um uh earlier two as well and maximize on where to so um like i said next steps we we talked about the security features at"
  },
  {
    "startTime": "01:34:02",
    "text": "uh 111 uh the authors uh welcome protocols and and revisions to the security modes of operation um but today we talked about what i think are the unique features of this protocol proposal it can do more than measure capacity and and um you know we've taken a look at that uh we'd like others to take a look and um uh i had a side conversation with martin last time uh we uh with working group adoption we could get an early uh security director view and and that would help us uh solve that aspect for this protocol in a way that might uh go through the iesg a little easier so um thanks for your attention and i hope there's some questions well um any question all right i'm sorry if you said this already but like how does this relate to rsc 1997 it this is the protocol we're using currently in the running code for measuring rfc 1997 and with the logic that's in let me bring this back up again martin with the logic that's that's currently implemented in here the load adjustment algorithm this is what we do we try to measure the maximum capacity and we do that based on on the feedback that we're currently receiving and the point i'm making is that you could change this logic this load adjustment algorithm to do lots of other things"
  },
  {
    "startTime": "01:36:07",
    "text": "for example um you know a hybrid type 2 measurement where you're where you're seeking additional uh downstream load and you want to measure uh the performance of the passive traffic that's alongside of it you know at full capacity so where you may be building up your buffers and so forth okay sounds like we don't have anyone else in the queue thank you al you're welcome welcome all right hopefully we'll have some more follow-up on list as well okay and then next up i think we have greg talking about epm about it i can probably share my screen you should also be able to share the pre-loaded slides yourself do you want to click that button [Music] i don't see the button right right of the hand button okay here we go okay great thank you okay so um"
  },
  {
    "startTime": "01:38:01",
    "text": "this is update on error performance measurement in packet switch network and uh let's go to the next slide please okay so the recap their error performance measurement we define several metrics for the packet switch networks that reflect conformance to set of predefined uh service level objectives and among this metrics we have the availability and unavailability as a sequence of the time intervals that conforms on do not conform to slo since our last presentation we have two new coffers uh leon and joel joining us welcome and uh we updated um we edited the section on um availability of anything as a service and uh availability uh as um used uh in mobile communication and uh look at how are these two uh interpretations of availability relate to what we discuss in error performance measurement next slide please so what is anything as a service i think that we are all well familiar it's a concept of services related to the cloud computing and remote access uh and um almost everything anything is a service as a security platform uh software um so um sdn um as the van um so network as a service next slide"
  },
  {
    "startTime": "01:40:00",
    "text": "so as everything uh it doesn't come for free so it has some benefits but at the same time it has challenges and the advantages of anything as a service is it improves express model because um there is a lower uh capex and purchase a subscribe subscription basis and as more capacity needed from the providers and it allows uh the enterprise uh to uh faster adopt new applications and um use its uh expertise of its it on a specifics of its uh main business rather than in support but at the same time anything is a service has some potential challenges so because they depend on more equipment on the network connectivity and availability of computing resources so they might be constrained by their temporary loss of connectivity uh problems with the resilience low bandwidth and low computing power next slide please for anything is a service um using a dedicated uh environment uh the availability average is understood as a mean time between failures uh it's a equation between of a mean time between failures and mean time to repair and um example of uh failures that considered its hard drive malfunction in a data center or hypervisor reboot uh mean time to repair"
  },
  {
    "startTime": "01:42:02",
    "text": "is how much time it takes to fix a broken component uh our application to come back online um obviously um so we can if we look at this equation we can see that mean time between failures can be uh considered as a constant for the particular environment and the only uh way to uh improve availability is uh to minimize uh mean time to repair and that can be achieved by introducing uh redundancy uh in their infrastructure is like um with a web or database service or world balancers uh in epm um epm reflects uh near real-time availability by uh measuring the conformance uh to uh slos and the ability to communicate so basically it can it's a combination of uh performance monitoring and fault management monitoring their continuity of the path from the user uh to their cloud and um using uh the epm interpretation of availability it provides uh valuable data and more accurate realistic information about mean time between failures and mean time to repair so because these are giving us a theoretical estimation of availability while using their methodology of error performance measurement gives us a real time or near"
  },
  {
    "startTime": "01:44:02",
    "text": "real-time information next slide please so another um domain are where we can see there or hear about their availability is mobile communication so the mobile voice and data services the definition of service availability can be uh found in um baric communication positioning um and it's uh oriented uh for uh operators and consumers so and it's uses their percentage of the number of attempts to their access given services successful uh attempt but it's only reflects on established connection it does not reflect the quality of connection so that now uh when we see that uh it's uh not only a voice but a mobile broadband so their quality of uh the connection are becomes more important and that's where again uh the methodology of error performance management and the approach of how availability is uh determined and measured and expressed uh allows for a better understanding and better uh quantifying of availability for mobile voice and data communication next slide please so what we we always welcome comments and questions contribution cooperation and"
  },
  {
    "startTime": "01:46:00",
    "text": "we think that this is something that working group might be interested and would like to ask to consider working group adoption and uh i see fan um yes please i can't hear you if you're talking fan all right in the interest of time i think we're just going to have to take that list or you can drop your question or comment in the chat thank you okay thanks okay so now we're on to our quick elevator pitches these are ones like i will display the oh sorry yang can you come back on um i can display the slides now and we will start with some of the draftly ones okay all right and again for these we just want to cover them in like a minute or two and please focus on you know what should this group be interested about why did it uh why should people comment on it or read your draft okay okay i'm yami from china mobile can you hear me okay the title of my talk is one-way delay moment based on reference delay so the background is that entrance one-way delay measurements is very important uh for sla as in this fit and the figure on the left we need to know the end-to-end one"
  },
  {
    "startTime": "01:48:02",
    "text": "one-way delay of a video surveillance service in 5g network we can see that the and one to one-way delay is the sum of t1 to t4 we propose a new method to accurately measure the one-way delay using reference delay without deploying clock synchronization the reference delay is bounded and has lower data it can be obtained in deterministic networking in figure 2 on the left side the engine end-to-end one-way delay from the sender to the receiver is measured and the intermediate network device are hidden for simplicity we assume the cinder clock and the receiver clock are not synchronized and has some clock offset in this figure the delay of the reference packet is stable and bounded and deleted as the reference and the delay of the target packet is measured and the way denoted as the target we will time step both the reference and the target packet on the sender and receiver side respectively denoted as ts1 ts2 tr1 and tr2 uh for reference we're talking we're we're out of time um i i know you have another slide coming up right after this okay okay we're gonna switch to that people have comments you can get to those on the list um all right so your next one is again a one-way delay here we go as quick as yes okay uh they we we propose a new one-way"
  },
  {
    "startTime": "01:50:00",
    "text": "delay environment uh method also based on deterministic net networking uh the the way we can have a centralized control node as shown and used to collecting network information and the link from each network element to the synchronize the control node leverages delay deterministic links so that the delay are shown in the figure on the left side denoted at t1 t2 to tn and can be calculated in advance and have relatively stable and low jitter as shown on the right side the network element m and n are connected to the centralized node by delay deterministic network when the track traffic flows from the network element m to n they will upload flow information to the centralizer control load the transmission delay of flow information tm and tn respectively and the arrival time of flow information at the centralized control load is tm prime and the tm prime respectively all right then the delay can be calculated by this formula and more details are shown in the document thank you great thank you all right okay up next we have just yeah hello all right let me just pull up your this is the enhanced alternate marking yeah all right the single slide is light four if you can go on flight four but you're here yeah pitch it to us yeah the background is that in a few words that we already presented the alternate marking data fields for ipv6 and the relevant document is"
  },
  {
    "startTime": "01:52:00",
    "text": "an isg evaluation but during the discussion we there was some inputs from the sg to consider whether the flow monitor identification field can be extended in order to have more entropy uh considering this motivation we propose this graph to discuss in ippm how to generalize the data fields extension and whether it is necessary to extend the the flow monitor identification field for example the next header can be can be used to define this enhanced capability so this is just a proposal for discussion in ippm so we are looking for more feedback from the group and to we already have some discussion with greg on the list and we hope to have more feedback okay thank you all right thank you anyone any quick comments while we're switching slides we have tall up next justin we'll give you an update on the iom linux kernel implementation perfect thanks al so a quick update on the implementation on the linux kernel so last release of the kernel which is the 5.15 a few days ago has been released and uh it comes with the uh support for the iom prayer located trace uh next version which is the 5.16 and it is expected for end of december this year will provide uh tunneling uh support for in transit traffic so that we are compliant with the rfc 8200 and actually everything is configurable with the ip root 2 tool which most of you probably know with the ip command in the linux environment and so there is a repo so feel free to"
  },
  {
    "startTime": "01:54:01",
    "text": "have a look at it we provide some documentation an example on how you can deploy and configure your iom domain so that the floor is yours right so we have a new draft that describes an iom profile which is used by the linux kernel implementation and this means that by reading this draft you can create an implementation which can interoperate with the linux kernel implementation and we'd really be happy to get any feedback and comments about that so thanks thank you is this the type of thing that i mean it seems a little out of of what we normally do in ippm it seems more like an ops type thing if you're talking about a linux specific profile but be curious to hear that it's closely related to iom so that's why we thought this would be the right place for it but if you think there's a better working group for this we'll be happy to hear about that sure okay be interesting to discuss all right um next we've got some in-band flow learning all right um i'm not hearing any audio fan any other authors want to speak up or present this all right yeah seems like we're having some technical issues so let's move on the next one we have a simple direct loss now slide the six uh tell me if you have it yep and if you go to slide six uh there it is yeah thank you so um uh"
  },
  {
    "startTime": "01:56:01",
    "text": "this is a very uh simple um straightforward draft that defines um a packet format a message from it for the session sender and a reflector to measure the direct loss it's inline counter stamping just like inline time stamping and it's asic friendly because the counters are at the fixed location uh supports the alternate marking method as well as 32 bit and 64-bit packet and byte counters as well as if you're doing measurement for dhcp scope counters as well uh so messages are also defined for the authentication mode as well uh so it's fairly straightforward draft and welcome your comments and suggestions on this thank you all right thank you all right next we have self-contained automark hello everyone i am i'm zombonzo from mobile and this is a draft about self-content automated marking mechanism and then in the left is the traditional alternate marking method the right is a self-contained alternate marking method we will introduce each very quickly in the live the container or the ms will connect the information from the coloring point and the monitoring point the non-problem parts may maybe several many and they need to corrected the information by using the block id and in the right if we insert the block id information into the coloring point also with the color information by occupying another specific bit"
  },
  {
    "startTime": "01:58:01",
    "text": "we can replace the monitor report at the monitoring point uh directly uh target environment value if needed so we think it's very simple for the client to join in the environment environment thank you everyone that's how all right thank you except we have some postcard based telemetry um this draft has been extensively discussed the email list and a major question raised by the chairs and ads that is that's really worth to standardize this approach or isn't it already covered by some existing draft i think it's worse to clarify this point in the family of the on pass flow telemetry techniques there are two types passport mode and the passco postcard mode so the uh for the passport mode the ios trace is already on the standard track and in the branch of postcard mode for the instruction based telemetry is also the iom dx is also on the standard track and the pvtm covered in this drive is a standalone method as shown in the left side figure and so but it's also have some unique issues need to be solved um indeed it's actually actually this approach has already been used by the srv6 oam dropped but many uh open issues are answered as this will be covered by this drop so uh we hope that this is a word to be standardized in this working group thank you very much all right thank you i think the main question it's good to have this formulation the main question i would have is you know if the other ones are you know defined as iom [Music] methods can can we define this as a specific iom"
  },
  {
    "startTime": "02:00:00",
    "text": "protocol as well but we can carry that on our list thank you yes it can be yeah stay in the same family here all right and we're just going to keep going i know it's at time if anyone needs to leave they can but let's get through these last little talks delaney please go ahead yes can you hear me yes i can okay perfect yep so we're going to have a side meeting right after this and we'll tell you the implementation i'll just cut it really short is everything just about everything that i've heard on this ippm meeting could use encryption it's all really sensitive data and so we want to um you know we'd love to um work with anybody uh to do that too and i'll be contacting you um offline and because we're we're getting we're getting an implementation so that's it great okay so anyone interested go to the side meeting thank you all right we have some user devices explicit monitoring all right laura are you speaking to this okay this is the the draft that is a sibling of the previous one the idea is to put the probe on the user devices a smartphone for example or pc in order to have a point that is uh where it is possible to make all the measurements without dedicated hardware and the software inside the network or it can be also an additional point to interface to the props in the network we can have some advantages for example the"
  },
  {
    "startTime": "02:02:00",
    "text": "scalability the hardware of the user is not is very much so it's possible to have many measurements the measurements are more precise because we have the point of measurement that is on both the directions and it's possible also the network monitoring coordinated with with probes in the network so this is a about the positioning of the probes of the species measurement thank you we can discuss on the mainly list of this idea great thank you okay and then we have our final elevator pitch alexander um yes hello yeah this is a brief elevator pitch for a new draft concerning high precision service metrics uh the idea is basically to define a new set of metrics that capture whether or not the service that is being delivered complies with the service level objective uh for instance for when you have uh precision services that require a specific end-to-end latency uh you would want to basically capture whether or not uh yeah basically your your uh your your flow your flows are in compliance and so forth and multiple applications for this in accounting monitoring et cetera some examples of the types of metrics that we have in mind are fines you would want to capture a number of packets that were violating an objective the number of time units that were violated during um during the duration of a service and this basically gives you also second order measures of precision availability so not availability but available the uh during which a uh service can be accessed with the uh with agreed on uh pr uh precision so anyway so the the the just the elevator page and the next steps are of course to refine the steps and so forth and also we would want to"
  },
  {
    "startTime": "02:04:01",
    "text": "ask anybody who's interested in this work to to please reach out thank you okay uh greg did you have a quick question on this or comment i'm just curious how that is different from error performance measurement so we can discuss it probably in the middle because that seems to be the same idea okay so so um so i did not let let's let's put this on the boiling list yeah uh i think it was referring to the earlier presentation alexander that greg made on the epm proposal so it sounds like you know read each other's drafts and let's uh discuss on the list how we can kind of combine efforts here all right sounds good thank you all right okay um thank you all it's as as usual a full uh session but i think we made some good progress today um thank you to co-chairs thanks marcus for running the time um thanks ian for all your service we shall miss you um and thanks to everyone who came and have a good rest of your ietf if you're going to stuff tomorrow and we will see you next time bye you"
  }
]
