[
  {
    "startTime": "00:00:05",
    "text": "okay it is 3 30. uh Henry if you could turn your microphone off until sorry your video off and and unless you're you're speaking that'd be appreciated uh let's go ahead and get started this is http uh we have two sessions this week both of two hours uh we have a relatively full agenda so we're going to try and keep it on time if at all possible I'd like to introduce my floating head coach Aaron Tommy Polly Tommy Take a Bow um so uh first of all first and foremost uh the note well policy uh you should all be familiar with this by now but if not these are the policies under which we participate in the ITF regarding things like intellectual property and privacy and harassment code of conduct copyright there are many different aspects to it so if you're not familiar with them please do familiarize yourself with it it's important we take it seriously and you can find it by just searching in your favorite internet search engine for I ietf notewell wait any waste users here you may have trouble but otherwise ietf note well this meeting does have a mask policy I'm hoping you're aware of that by now too uh if you're not speaking uh or or eating or drinking please do wear a mask and and exercise common sense and yes I did notice that someone left their power cord here hi hi Lucas well I didn't want to name names so please do uh remember to keep your mask on and if someone gently reminds you take it in the spirit which it was intended uh can we have a scribe for this session is anyone willing to take minutes please anyone in the room there are some familiar faces that I could call on but"
  },
  {
    "startTime": "00:02:00",
    "text": "they have done it many times in the past so new faces would be much appreciated thank you very much uh and that's Jonathan isn't it I don't have my glasses on but I know it's Jonathan if you could uh um just take notes in the um what do we call them now I think it's a hedge dock it should be linked from the top of the agenda yeah and I I already filled out the agenda there so you should just be able to oh thank you thank you um and and if folks could help Jonathan out that would be much appreciated so that it's not falling just on his shoulders so the agenda for today yes I learned about Dynamic backgrounds in keynote this week so excuse me today we've got signatures alternative Services where we have a reasonably large amount of time reserved origin H3 a brief update cookies and then client certs now we've we've had a request to rearrange so that partition cookies can be after the cookies discussion just for to keep us on on topic there if no one's uh having trouble with that we'll we'll do that so we'll do cookies then partition cookies then go back to concerts and then finally we'll end up with an update from our friends over and the enthusiasts over in The Mask working group they are very enthusiastic if you can I don't think you can see that on camera but there's already enthusiasm uh and then on Friday we'll go over there Jennifer that uh then but we have a similar kind of lineup so like I said very packed any agenda bashing beyond what we already heard okay let's go ahead and get started then uh with the signatures discussion and I'm going to see how far I can take this just projecting my entire screen take it away"
  },
  {
    "startTime": "00:04:03",
    "text": "all right hi everybody I'm Justin richer this is going to be a short presentation next slide please on uh update on HTTP message signatures uh we've gone through a couple of revisions of editorial updates added more examples we added something called the tag parameter which was very briefly called the context parameter until we got some feedback that that was a dumb name and um so there's the tag parameter in there now it's optional don't need to get into it and we have gone through a one month long working group last call after which a lot of comments came in about the document so thank you for those that uh that have done that so far um right now there are only a couple of uh small things going in uh so first Lucas needs to apparently get me an update on uh the digest example in the draft I think thank you I guess apparently it's wrong I'm not sure how it's wrong but if you could make it not wrong that'd be awesome um and we can touch base in the hallway or something if that's easy to do um next slide though um but uh there is an open question about what do we do with trailers um Can the fields that we've defined can they be trailers currently they're allowed but uh does that do we need to be more specific about what that means when they're trailers um and can we sign trailers um and and if we do so uh there's a couple of things that we could do right now everything is just sort of defined as fields and we kind of mash them all into the same namespace which is what I thought we were allowed to do but somebody pointed at a line in HTTP semantics and I'm getting some head shakes in the room so this might be a very short discussion next slide please um so uh so obviously uh if we have a hypothetical field that can exist as both a header and a trailer do we both call these both food next slide because the naive thing to do uh would be to"
  },
  {
    "startTime": "00:06:00",
    "text": "just cram them together to look like this that's what the spec says to do right now I'm getting a lot of head shakes uh this is why I tagged you guys on the GitHub issue so I wouldn't have to have these slides but I'm glad we're here so next slide uh the alternative proposal uh is to just explicitly call something out as a trailer as a data source um using a Boolean flag that tells this uh that allows the signer to signal and the verifier to know where to Source the information and then otherwise we just treat it like any other any other field uh next slide we actually have precedent for this with the request parameter uh that's already in there when you're signing a response you can get the related request information and Pull It in there and uh so I think I already have the answer but uh uh let's let's go to the key I'll interject and then Martin might have something to say um so in in HTTP uh the most recent series of updates we recognize that trailers had some really fundamental interoperability and deployability issues and so we defined them as a separate namespace from headers so they are distinct you cannot just naively combine them unless the definition of the header field or sorry the field says yes you may do that oh gosh and so we flipped that so so your approach uh the approach that you talk about here we're using TR might be workable the only thing that I would add to that is you have to realize that it is completely legal to drop trailers on the floor both you know intermediaries and by recipients they can just disappear and so you need to account for that if you want it to be robust yeah we definitely um need additional implementation considerations for trailers uh in that case I think there's already some text in there but it needs to be more robust um for sure I mean you might even consider if it appears it should look like this is kind of semantic Martin Thompson goodness you wouldn't want to be short um Martin Thompson presumably you can add both TR and Rec"
  },
  {
    "startTime": "00:08:01",
    "text": "to the same field name interface that it's a trailer on a request this can you do that yes right so that's if uh I want to ask you two but if you go back to like several slides my final question on trailers is are they even real because I actually found that in some of the libraries I was using I can't get to trailers oh yeah this is a common complaint uh so they are real uh they're probably not a great thing to be signing uh for the reasons that Mark stated but yeah and it sounds like you're trying to get everything so yeah it seems to work yeah I I can't see a compelling reason to disallow it so I would rather have it be very explicit like if you're doing it this is what it is and these are the problems you're going to run into this is a great way to make stuff break if you sign these things but uh that's what people yeah want sometimes I guess yeah the observation I'd make is is that the the people who do use trailers tend to really like them and they tend to do weird things and so it wouldn't be out of that question for them to want to do a weird thing with signing them right exactly and this is this is definitely off in in corner space somewhere but um we wanted to make sure that it was covered so anyway thank you I will put in a PR to to add the TR flag uh with the definition for that and um and toss that around but um yeah apart from uh tweaking a couple of examples here and there the the working group last call feedback so far has been pretty positive um and I've also been discovering a handful of more uh implementations out there in the wild uh which next slide um I'm going to be talking about that a little bit at the SAG on Friday morning this week uh where I'm basically going to uh be presenting what the draft is and how"
  },
  {
    "startTime": "00:10:00",
    "text": "it works and very very briefly to The Wider security community and then tell them to come at it with pitchforks and pickaxes and whatever else they can get on hand and basically help us figure out like did we leave security holes in here that we don't know about are there weird Oracle attacks or gotchas or other things that uh that are hiding in this space um so it's going to be exciting time after that I'm sure um but uh oh right the second bullet which I'm pointing over here now um the second bullet is that if you have an implementation or you know of an implementation of the HTTP working group draft not the Cabbage draft um I'm going to be putting up a tab on httpsig.org our sort of demo site playground space to start listing these implementations because I've had a lot of people coming at me uh lately asking for that list so I'm gonna put it up and then just have a link to like make a GitHub pull request if you want to add your own um but you know get in touch with me I'm I'm seeing more and more out there and I think that's all I had great any questions feedback okay thank you Justin all right thank you and if folks are able to uh attend sag uh it conflicts with us on Friday but if you happen to be there uh that's a good conversation to watch because there's a an open question about what the appropriate level of review is for this kind of really pivotal spec ific great and and if you could do us the favor of maybe reporting back in on the email list or something that'd be great uh next up alternative services Mike"
  },
  {
    "startTime": "00:12:04",
    "text": "I'll skip over the joke that inspired the picture there but uh flood so we have all this uh nice complicated infrastructure of how we handle the user's request and where it flows through okay I don't know where that comes from all right um but slide what we're trying to handle is when the user accidentally winds up over there where we'd really like to get them on the red path that we had planned for them and we want to redirect them a little bit so slide there are a couple cases where that happens that we'd like to make sure that we handle one of the most common ones is when the DNS resolver is not near to the client and for privacy reasons or otherwise does not pass along the client Subnet in edns0 there's also for those cdns that use anycast anycast can wind up in the wrong spot it happens there's a lot of work that goes on to make sure that doesn't happen but it still does and in some cases we have endpoints that can offer you better service based on where you are or who you are that we didn't know when you did the DNS resolution so we might like to be able to point to to some endpoint that we control that special that would give you faster service and the most common use of alt service right now is for protocol availability so you spoke to us over H2 we'd like to tell you that we also have our H3 endpoint or you spoke to us over each one and we'd like to tell you that H2 is a different port hypothetically although that mostly doesn't happen in the real world we've got Julian and kids join it do you have a question of clarification or can it wait to the end"
  },
  {
    "startTime": "00:14:05",
    "text": "uh I wanted to mention that apparently the chat doesn't work or no it actually works so I had actually questions for Justin early on but um the messages didn't come through so apparently questions for for Justin so so the news is zulub is down uh from for most of things so all the chat is busted ah and so Julian's got some sort of low priority questions that he can't get answered ah there's an iits but it seems to be up now oh okay it's back again so okay sorry so and so perhaps that's a request for you to go into zulup and field some questions all right so we at this point have two main ways to redirect the user we can either do it before the request happens using DNS or we can do it after the request happens using alt service and those are both great options slide Trouble Comes when we have to combine them right now what the service B spec says is that if you implement alt service and https you take all the host names you found in alt service look up https records for all of those then filter down to everything that's consistent with both the https records and the alt service record and then attempt to connect to whatever's left from that combination which produces some confusing results notably there's only one resolution here that is even in the original Origins"
  },
  {
    "startTime": "00:16:01",
    "text": "domain yeah you can set this up but it gets a little confusing and we're trying to Define a better coexistent story moving forward and so the simpler version slide And Delay oh okay so the trouble that we have other than just using them together is what do we do when we get both sets of information because the old service is potentially old so how do we make sure it's still valid but it was received over a TLS connection directly from the origin whereas DNS comes through other servers along the way possibly unencrypted how much do we trust when they don't say exactly the same thing so we want a way that lets us make sure things are fresh before we use it one of the concerns that we've heard is an ALT service that says you can come talk to me over H3 but when you resolve the hostname you get pointed to a different CDN that doesn't support H3 and your connect fails in your timeout which is not great big slide so the draft that's been submitted um just before the deadline was to replace it with very close to the straw man that we had talked about last iatf which is this alt service B which provides you a hostname that you should go resolve slide for semantics slide or okay it's just lag so basically right now the first step of it is ignore any Legacy alt service that's there so that helps avoid any of the collisions that we might care about just do an https lookup for the hostname do all the service B required connection"
  },
  {
    "startTime": "00:18:01",
    "text": "stuff that's in the https spec and use that connection instead of this one so we're trying to move you over to a different endpoint now and then in the future remember what endpoint you wound up on and give that some preference when you do future https resolutions connecting to this origin if you don't see that endpoint oh well you just go on with what DNS says and you forget it the next slide and this does leave us in a little bit of a situation around stickiness which is that if you're not remembering uh or if you don't have that endpoint in the DNS all the time then you're going to go to origin get redirected without service the next time around you go back to the origin and it'll tell you to go go over to the alternative again so you might wind up flip-flopping unless you put all of your possible endpoints in the DNS some providers don't want to do that because they don't want to enumerate all possible endpoints in the DNS but if you remember it too long then you override the ability of a site to do multi-cdn or otherwise change where they're pointing you so this is a trade-off that we're going to have to make now we had a long conversation about this at the HTTP Workshop slide and we had over the course of that long conversation we basically redesigned the proposal and then wound up right back at the proposal that was submitted because everything else we tried didn't really work out or had some uh some conceptual difficulty that made us drop it so where we wound up with is DNS is always reasonably current for the time that you look it up probably have short ttls that's where CDN load balancing happens it always gives you the endpoints of the"
  },
  {
    "startTime": "00:20:01",
    "text": "the properties of the endpoint that you're actually talking to so we always want DNS to have more or less exclusive real-time control over who you talk to and what you should expect to do on that connection and ALT service is more interesting for once you get to that origin if it wants to move you to a different node so distributed origin CDN whatever it's mostly interesting for redirection in real time and stickiness may not be as much of a concern as it originally was for all service or as we thought it might be so um I think at this point we're just going to open up for discussion on the draft that was submitted the current alt service bis and how we want to move forward with this and I see Martin getting his phone get in the queue I also see them Ben you you beat Martin go for it hi Ben Schwartz uh this all sounds like a a bit like a good Improvement to me I'm for it I I don't understand the stickiness where did you end up on stickiness stickiness um so the issue about stickiness is how how does the client verify that the information it has cached is still valid for an old service that potentially has a very long long time so so you have conflicting we would like to have a long Lifetime on the alt service advertisement because we want you to remember what protocol to use especially at the different endpoint when you come back on a future connection but on the other hand"
  },
  {
    "startTime": "00:22:00",
    "text": "load balancing happens at a much shorter time scale so we don't want you to remember so we want some some amount of stickiness but we want DNS to be able to clear it or override it at the time of your next connection and it's trying to strike the right balance of that that's difficult right now okay um yeah I think the uh it's perfectly reasonable to uh to say that the alt service B is a sticky indicator of which of the alt hosts or which of the alt RRS is prep is preferred and that its lifetime is is the um and that it it applies after DNS resolution so on some you know a week from now I want to connect I re-resolve the name I I get a an RR set and then I check it against my sticky post name and if the sticky host name is in that RR set then uh the hint applies otherwise it's discarded um I think that gets you what you want right and the the current draft as submitted actually has a flag that you can put in an rsat or on a record that says never use this alternative unless you've explicitly told to yeah one thing that I wonder about here is should we just make this stickiness thing a like general property of uh of the https record of service bindings like you gotta you know you tried various service bindings in the past and you found that one of them was the one that actually worked like do you really have to try them in priority order next time since you know that so the other ones didn't work and this one did or your selection algorithm selected this one last time so from the discussion at the workshop that is actually something that certain clients do"
  },
  {
    "startTime": "00:24:01",
    "text": "that per se right it just seems like you could you could effectively just say uh this is just a special case of that yeah okay that's enough pardon yeah so I wanted to make clear here that the The Proposal from the the design team that's been working on on this whole service thing is effectively to take this or something approximating this as the complete replacement for Old service so the draft proposes that we I think that I've got to use the right words now obsolete not deprecate is that right um uh we obsolete 78 38 and um that seems to be the general sense that that I've gotten in discussions is we want to effectively say that all services no longer useful um there are some suggestions on how we might improve there are a number of open questions that we have um Mike probably didn't touch on all of them uh the more interesting ones for me is um uh https records have priority order that gives you some control over where people end up and you can always put these Alternatives that you don't want people to use as the primary entry point to your service down the priority list on your https are assets that you return but maybe that's not as not definitive enough so we also defined an attribute on on each one of them that says don't use this unless it's an alternative um that you've been told to use explicitly those two mechanisms both provide you with some amount of control over the use of an alternative we're not sure if we need those things someone on GitHub has actually proposed that we have an alternative way of spelling the the stickiness which I think would be quite interesting I've asked them to post it to the mailing list and if they don't I will because I"
  },
  {
    "startTime": "00:26:00",
    "text": "think it's an interesting idea but um we're sort of trying to get a sense of the general shape of this thing to see if people are interested in you know does this does this solve your problems uh we've heard from a number of people that simply deprecating old service and relying more on https records solves their problems adequately and they don't necessarily need this thing we've heard from others that they like the idea of being able to steer traffic using using the the old service records uh the old service advertisement as we've defined so that's the sort of feedback we're looking for here so just to be clear that the potential path forward then is once we get enough Comfort around this to stop working on service bests and to adopt this new draft correct that would be the idea but I think we at this point we're just putting this in front of people we're not quite ready for that time to to think about it right and also recognize that there's a few things that we need some input on as well but it does sound like we we probably should Park old service business until we know yeah the the alternate spelling of that is to incorporate the new draft into all service business there are lots of ways we can do this yeah yeah uh Eric knier Apple so I just wanted to reiterate a little bit and you were saying is this useful for people and so I thought I could say heck yes it is um so we we strongly prefer uh getting this kind of information from DNS it's much nicer because it's for the place that you're actually going um and it's something most importantly that you know up front at the time that you're going so rather than saying for next time you can say for this time uh and that has been shown uh I think via some data that was presented the previous ITF that that makes a significant and measurable difference in the amount of H3 that we actually use um so that much is awesome being able to take https records and say these are lower priority and have a separate signal for do not use this in less houses on fire uh both of those signals I think we find are super useful and we have a number of people where we are asking them to do that and they say we"
  },
  {
    "startTime": "00:28:00",
    "text": "do not have a mechanism so we can't do that so if this gives them that mechanism then uh like both of those unique signals are awesome yes please and then beyond that yeah we can go into the rest of what's left for alt service after we've moved that out but I just want to say we do very much have a need for that and we would be shipping it yesterday if we had it thank you um it probably is important to note that at least at 1 14 we did have some people saying they didn't want the ability to indicate H3 with a header to go away entirely so we may that may just be solved by okay you can use the obsolete thing if you really have to but it's important for us to remember that some people do still need that affordance for a little while that's a question what the time skills are and yeah yeah David schenazi uh that's pretty much exactly what I was going to say and just to explain that um Chrome and other web browsers today don't always have access to the https record because like apple platforms are awesome and they have good apis but if you look at Posse's cross-platform get Adder info gives you pretty much what existed at the time so realistically speaking in some platforms where Chrome has its own DNS resolver everything's fine I know there's some people at ITF weeping that the applications are all bundling their DNS resolvers now but for cases where we don't we'll still need to use the old thing I don't love that we're obsoleting the old thing because it's still useful but you know at the end of the day it doesn't really matter as long as we're on the same page that we might still make changes to Old service if we have a reason to then everyone's good so like empty was saying we can obsolete it but we're not deprecating it and that seems fine I forget what all those words mean anyway Tommy"
  },
  {
    "startTime": "00:30:00",
    "text": "all right uh this is a question for David if he's still up um I I think there's some comments on the list around uh can you know when are we going to update posix get at our info um you know I don't think that functions function signature is going to change at any point soon um just to confirm I imagine people would probably be okay with a separate function in some standard DNS library because you know get Adder info already probably is coupling too much of the a in Quad a queries synchronously and so you know your svcb lookups should be separate anyway so would it be sufficient On Any Given platform to have a somewhat bespoke DNS API for these things um yeah well David schenazi uh Happy eyeballs Enthusiast um yeah like in practice it's a matter of time at the end of the day like um and resources um Chrome today has like all the energy like we don't have a huge networking team as we used to and so the energy goes into the client DNS like I don't work on Chrome anymore um the the energy is going on to like the DNS resolver that is bundled with chrome and the like cross-platform fallback users get Adder info and pretty much is not going to see any love uh probably unless it becomes like a pressing issue so give an infinite time totally will do it it makes sense it's possible but it's in Practical things there's always another shiny API web API to do instead but just to clarify I think the goal is to ship the um its uh chromosome resolver on all platforms and that kind of makes this go away just it turns out to be like trickier than expected so I think at some point we'll get there and"
  },
  {
    "startTime": "00:32:00",
    "text": "this becomes a non-issue at least for Chrome I don't know what Firefox is doing when like they're not using dough Lucas sorry I didn't use the tool my phone ran out um no recovery from that um so is somebody responsible for advertising H3 and wanting to work and being involved in the design team I support the shape of the solution that we've got as Martin said that the the suggestion on GitHub the other day is kind of interesting be willing to see where that goes or doesn't but um I really like this because I don't have to do anything like I would support this because the clients need to do some things and change stuff and we already do HBS records and it would all kind of work very straightforwardly but I'm not in a humongous rush to to remove the old service header tomorrow or or whatever like we can leave it there and it has a place for me the important signal here is is for people who who are suffering now with the the problems of the old service header they're asking us to try and find Solutions around it and and having the ITF give them a clear signal that this is not the power to be explored for future Solutions but it's not a dead end either in the sense that it's going to be turned off and we're never going to speak anything and you're just going to be left in limbo with no way to use H3 that's not what we want we just want to make it clear with what the future is in our mind and that dates can just come in the future whenever it is yeah so Mountain Thompson I find it funny sometimes too when we're talking about lack of engineering resources at Chrome when it's often the other way around but um the I think I think that's the transient problem uh I think probably the more pressing one is the availability of https records and how able you are to to make a query for them we've done some research that hopefully will be published relatively soon uh"
  },
  {
    "startTime": "00:34:00",
    "text": "that that talks about the success rates for for different types of DNS records and off the top of my head I can't remember the exact numbers but it was something in the order of sort of two percent for A's and quad A's five percent for https failed uh it was more like 45 for our DNS Sac related uh Records for those who are who are curious about those sorts of things so um that that to me speaks to to having some amount of https uh sorry alt service Legacy style uh around it may be that we want to encourage people to to start shortening their max age on that side something closer to this sort of behavior from from the systems and we don't run into the sort of two caches problem that was a major issue with without service in the first place um that said I think uh this really hinges on like how much HTTP 3 you're willing to sacrifice to to the altar of just making progress I think probably at the moment for those people who are you know maybe strapped for engineering resources this is possibly you know too much HTTP 3 to to leave on you know unrealized but there may be a point in the future where we can sort of say well that sort of incremental you know three or two or three percent of networks that don't pass https records just if I get the H2 and that's okay but that's a discussion we'll have to have later any more slides that's okay all right so it sounds like uh We've made some pretty good progress we still need to do a little more work and a little more socialization maybe um so I think we'll continue to leave the old service best document parked yeah because please read the draft provide comments yeah continue to work on that and then we'll get to a point"
  },
  {
    "startTime": "00:36:00",
    "text": "where we need to do a call for adoption if we think we're right for him yeah and figure out the disposition of all the other pieces at the same time yeah any other questions comments for Mike okay all right thank you very much Mike that was that was very productive and also the next speaker and and you've got a little extra time too okay so uh next up origin H3 which I believe is this one yes once again okay um so this is the origin frame that we had on H2 recast in H3 however much you like it or you don't that's where we are so first we should recap all of the semantic changes from H2 there they are review them carefully next so structural changes uh stream zeros or request stream in H3 so we have control streams so we have to map those terms and then Lucas filed an issue that we hadn't caught previously that H2 has Flags H3 does not have Flags so here's what the original origin spec has to say about flags big slide which is we don't use them but we might in the future so then there are four flags that are mandatory to understand if the flag is set and you don't know what it means ignore the frame the other flags are not mandatory to understand if they're set and you don't know what they mean shrug and move on keep using the frame as you understand it so we have those in H3 we would have no way to set them if we ever did Define them in the future next slide so what do we do about that we could"
  },
  {
    "startTime": "00:38:03",
    "text": "take the very simple path of deprecate flag usage from H2 and say we haven't needed them so far we're not going to we could not say anything and fix the problem if we need to need to down the line although that could be kind of awkward if we decide to retrofit them into H3 later we can stick an always zero byte in the frame which makes me a little sad but you know it's one bite or we can stick and optionally present Flags byte on the end and if it is all zero you may admit it um none of these seem fantastic all of them will work opinions and then let's move on okay Martin Thompson before we go on I'm just going to note the very nice options pun on this slide well done yeah yeah so um we have mandatory Flags turns out mandatory flags are just called frame types so we don't have that problem uh if you want to if you want to define a flag that's mandatory to understand pick another frame type and off you go so problem solved there um the optional ones uh optional in which case we can solve that problem later when someone wants to Define one of those flags and we might do it in any number of ways by defining new frame types or by defining this stupid hack thing with the bit at the end that you cut off if it's not there I think these are problems best solved by Future Ross who I predict will probably never actually care to solve them anyway oh David uh dude it's kanazi similar to Mt I think yeah we have a fourth option which is Kick the Can down the road uh we're not painting ourselves into a corner because if we need it the correct thing"
  },
  {
    "startTime": "00:40:00",
    "text": "is the frame types we have one extension joint that we should grease well we don't need 17 of them so just say we don't use them done okay and sure maybe I won't even bother deprecating them from H2 like just don't use them don't don't accommodate them Lucas Lucas Pardo um yeah so I created the issue and I didn't think of any solutions for it sorry um I forgot I'd opened it but it was in a fit of late night spec reviewing um yeah I don't like any of those options I don't think we should change H2 at all so I agree with David there adding adding bites and stuff just seems weird I don't this is a lot of the time with with H2 and H3 we're trying to mitigate kind of proxies that might pass through frames even though you're not passing frames through you're reconstituting them from their parts kind of thing origin is a bit of an odd one I don't think there's many anyone kind of passing origin across multiple proxies like that like I don't think we know enough about the problem to be able to design anything that would make sense and not complicate stuff no good use so if we want to Define four frame types that just basically all know up so it's just this is these are all the types for origin in H3 and they're all the same but since fine it's not it's no harder to write that code than for one type do you think we need to define those frame types now or just leave ourselves the possibility to Define them in the future I I don't know I have no strong opinion I I had a weird idea a few years ago about maybe a use for one of the flags in the H2 frame um so maybe but without a concrete use case like printing on it would be fine we're not We're not gonna we're not short of space for frame types I'll just give my own feedback to me that the the clearly worst option here is the last one for the reason for the reason you point out it is not worth"
  },
  {
    "startTime": "00:42:00",
    "text": "doing that to save one bite okay um but it sounds like we might be converging on kicking it down the road giving the problem to a future us and closing the issue with no action I think is the outcome which I think is a fine solution I'm seeing thumbs up is it worth a hum I don't know um I've done a home for so long you know or sorry just or it's like never mind um I will point out that in terms of actual structure of the frame um reserving multiple frame types to account for all the flags is exactly the same as sticking one extra byte in in fact it's slightly worse because of the varanth and the two bits for that but you're saying actively reserving them not just kicking down the road correct if we if we were to reserve them then we might as well just stick a bite down if we're getting him down the road then we don't worry about it we don't know we don't discuss that part of the spec okay one more question does anybody really care about this hmm look all right that's all you got I will go close the issue so the remaining question which uh is implied by the picture are we at the Finish Line working group last call all right I see nodding heads and thumbs up things all right yes thank you thank you pretty well on time uh next up cookies and how long did we reserve for this I think we're gonna talk for 15 minutes at most foreign"
  },
  {
    "startTime": "00:44:02",
    "text": "hello all my name is Stephen bingler Google Chrome and I'll be going over a status update for 6265 this for anybody who was present at the last interim meeting these slides are going to seem very familiar uh next slide please um so there hasn't been a new draft since actually that's that's not true as of about five minutes ago when we just pushed a new draft but I'm going to talk as if we didn't do that there hasn't been a new draft since ITF uh 114 um so all these changes are since that previous draft during previous meetings I've stood here and read through all those bullet points and that felt stilted and weird so instead I'm going to leave them on the screen for a few moments and if anybody has any questions I can go into more detail about them later next slide one moment two moments next slide um let's see there's only one change here that's actually worth talking about um just landed one where cookie prefix names are now checked cased insensitively um previously they were checked sensitively meaning that you had to get the exact case for the guarantees for cookie prefixes to be applied these are the underscore underscore secure and underscore underscore host Dash cookies um but it turns out that servers don't always check cookies sent case sensitively because of course they don't so servers were setting prefixes without realizing that they weren't getting any of the guarantees from browsers and that's bad so we fixed that next slide we have three open issues currently um same-site cookies and redirects click recap on this um the there was a bug in the original spec where same site did not take the"
  },
  {
    "startTime": "00:46:01",
    "text": "redirect chain into account so if you redirected from site a through site B and back to site a we would consider that same site and happily send you your same-site cookies um that's wrong the spec was fixed but when Chrome tried to launch this or enable this feature we got a ton of complaints and there was a lot of site breakage so we disabled it and currently trying to figure out next steps we're collecting metrics on how sites are using this Behavior to try to get a better idea of what to do with it but with the US holiday season approaching I'm expecting I'm not going to get anything useful until until q1 uh the other two open issues internal white space and cookie names and values this was recently filed uh turns out that the three major browsers Chrome Firefox and Safari all handle internal tabs somewhat differently internal tab being that you have some other non-tab characters a tab more more non-tab characters the spec was modified uh somewhat recently to disallow control characters but it accepted tab characters what this means is that now the spec says you should accept those internal tabs but not all browsers do so I'm trying to figure out if that change to the spec should have happened and whether we should revert it um final one is a mouthful uh the spec should more clearly advise which parts a reader should Implement I filed this one because we've had a number of issues with implementers implementing the wrong requirements because they are confused on what they should do and I can't exactly blame them it's not an easy document to read so this is kind of a task for myself to go through and write some pros that makes it a little bit simpler for someone to know what they need to implement"
  },
  {
    "startTime": "00:48:00",
    "text": "all right next slide please um so we've already have some work plan post RFC 6265 this the first is cookies having independent partition State Dylan will be up here in a few minutes to talk in more detail about that the second one is Cookie spec layering um originally Johann Hoffman was going to speak on that unfortunately he wasn't able to make it so I'm going to say a few a few words about it um yep I'm hitting things on my computer here so um cookie layering is an effort being headed by Johann Hoffman and Anna van kestron the idea is that the cookie spec has kind of intermingled itself with the browser specs um with same site and partition cookies and blocking and this is an effort to sort of decouple the cookie spec from things that could be better handled by say the fetch spec um let's see um this was brought up during TPAC as like an initial idea and request for feedback and seems somewhat positive but there's a lot of work ahead for it that is all that I have do we have any questions so I I think the idea here is you want to close those three issues go through working group last call go to the ITF isgq publication process and then we'll we'll talk about starting almost an immediate revision again uh to address your your deferred issues and and these work items is that kind of yes that's correct once the once the file once the three open issues are closed I'm hoping to go into last call okay and the cookie spec layering and there's been some background discussion about that I think that's we've for a"
  },
  {
    "startTime": "00:50:01",
    "text": "long time talked about how to make the the cookie spec more accessible more user friendly I think we want to try and involve uh non-browser communities as well to see where the right line is to draw about making that separation but that that's a discussion we can have I think that's very reasonable uh David spanazi hi I'm failing to find the issue but I remember there being some discussion on the topic of uh utf-8 characters and it just allowed characters in general about how the spec allows a different set for setting cookies than for sending them and like I think April King kind of found some issues there that were even somewhat were worrisome from a security perspective where did that discussion go I just couldn't find it sorry um that discussion happened in a pull request rather than an issue uh that's why uh I spoke with uh April um just you know face to face and we decided that at the moment um okay so context April has found a number of issues where browsers will send in safe cookies that servers then won't accept this is a problem primarily because nowadays a server is not a single entity companies will have SAS products that they use that will send cookies but then their python framework or PHP or whatever won't accept back the same cookie that that origin sent out which when the spec was developed I assume the the authors thought that oh if a server is going to send something can obviously understand it when he gets it back um after talking with April we decided that simply changing the spec to say that oh hey server should ex should accept this expanded character set was not the correct correct route um I I think there is no I know there's a"
  },
  {
    "startTime": "00:52:00",
    "text": "deferred issue for the for the next version of the spec where we are going to more formally research look into allowing expanded character sets and kind of what the effect that's going to have um but at the moment it's the plan is to keep the status quo thanks that that's reasonable I like mt and I are working on an active protocol maintenance documents that talks about these considerations so having the spec match reality is important um maybe if you know I don't want to volunteer you for work but if we could have like a paragraph explaining that there is a foot gun in the spec um that might be useful just you know as a warning note that this is different from this and you you here be dragons might be good yeah that's exactly what that final long-winded issue that I filed is which is like make it easier uh yes thank you highlighting perfect I think that's exactly what that's supposed to be yeah that's been kind of an ongoing theme for a little while so it's good to see that addressed yeah all right should we go into partition cookies then yeah all right thank you all thank you foreign my name is Dylan Cutler I am also on Google Chrome um and I will be discussing partition cookies with you guys today uh slide um so just a quick overview um so when we say a cookie is partitioned as opposed to unpartitioned what we mean is that um when a cookie is and when an unpartitioned cookie is set in a third-party context it is available on essentially any top level domain that makes requests to The Domain that set the cookie"
  },
  {
    "startTime": "00:54:00",
    "text": "um and by partition cookies we mean that um these third party cookies would only be available on the top level site in which were they were created and then if the user were to navigate to a different top level site um then the third party domain would receive like a brand new cookie jar um also this is like a forewarning this talk is going to be like because it's partition cookies a little more browser heavy than some other like talks um so if that's not your thing feel free to tune me out uh slide um so the partitioned attribute is a proposal for a new cookie attribute which would allow sites to opt into this Behavior um and just to go over the design really quickly it would require uh secure um domains would be allowed up to 10 kilo uh kilobytes or 180 cookies per partition and we determine how much memory a domain is using per Partition by the size of the name and value of the cookies um and then another detail is that clear site data would also only clear cookies in the current partition that it was in and this would be to prevent uh cross domain entropy leaks essentially there's a tax you could set up where you intentionally call clear-site data on different top level domains in order to essentially like build enough cross-site entropy to develop a like persisting cross-site identifier uh slide so um today I'm just going to be going over some of the open issues we have for partition cookies um the first one will be how do we deal with Partition cookies in what we call quote-unquote unpartitioned contexts um also we want to discuss whether the partition key should have um a field called cross-site ancestor bit"
  },
  {
    "startTime": "00:56:00",
    "text": "um we also will discuss how to handle partitioned and unpartitioned cookies which have the same name and then finally we'll go over um should there be a way that user agents convey that they are sending the request from a context in which only partition cookies are allowed if we're in a future world where um unpartitioned third-party cookies are obsoleted uh next slide um so first we'll talk about partition cookies and unpartitioned context and I'll start by defining what we mean by an unpartitioned context um in this case it would mean a first party context and so in that case the um it's a request where the top level domain and the domain making the requests getting or setting the cookie is the same or it would be contexts which have received um a privilege essentially through user consent through something like storage access API for example um and um one like Nuance we like to point out is that um Chrome and other browsers particularly firefox's implementation of unpartitioned contacts differ um this is kind of where the issue arises Chrome supports both unpartitioned and partition cookies at the same time and uses null for the latter's partition key whereas in other browsers as soon as storage access API is granted um the partition key for that context essentially switches to that first that cookies domain as if it were like kind of originating from the cookies site um and so the question is how do we handle cookies that are set with a partitioned attribute in these contexts um you know do we set the partition key to be like the current top level site which is what we are proposing is the right answer um or do we just use like whatever the current partition key is we think that we should just set it to be whatever like the current top level site is even in these more privileged contexts um just because the site is including the partitioned attribute because they're opting into this Behavior"
  },
  {
    "startTime": "00:58:01",
    "text": "explicitly and there are also ways to use cookies in these contexts without using the partitioned attribute next slide oh and then one more note about that asterisk point when I say like Chrome supports partition and unpartitioned cookies at the same time what I I don't mean that Chrome will like continue supporting unpartitioned third-party cookies into the future posts it's third party cookie uh deprecation timeline um just wants to like kind of clear the air there in case I accidentally store any fires um and so uh moving on from there on the next thing we want to talk about is whether the partition key should have what's called a cross-site ancestor bit and I think the best way to explain this is visually so um let's say a server is setting a partition cookie in a first party context where the uh request domain and the top level domain are the same um in this case the crossline ancestor bit would be false because the request is originating directly from the top level frame uh slide please um but in this next scenario here we see that although the request is coming from the same site as the top level domain there is a third party ancestor or cross-site ancestor between the um top level site and this frame or context like making this request uh next slide please it takes a while yeah it's fine um so this cross-site ancestor chain bit was actually originally introduced in the w3c as part of like the storage partitioning effort um where browsers are partitioning JavaScript storage in the same way we're partitioning cookies so that they aren't accessible to sites across different top level domains um and the reasoning behind that was like primarily to like correctly compute site for cookies in Partition service workers"
  },
  {
    "startTime": "01:00:00",
    "text": "um and effectively by adding this bit it would separate the partition that top level contexts get from um context with a cross-site ancestor and on the question of whether we want to add this to the cookie partition key um there's a pro which is that um there are consistent cookie sorry consistent partition boundaries across uh cookies and storage which is nice for developers but there are some cons for example this would essentially be a re-implementation of same site because developers can already restrict which cookies are accessible in and out of these contexts by setting a cookies same site locks or strict um and then another con is that there are cookie use cases um if you want to know specifics you can ask me after um where the top level site and uh same site in bed with a cross-site ancestor actually need to like communicate with each other with cookies and so we think that adding this ancestor chain bit would be harmful uh next slide um and so the next issue we wanted to go over is how to handle partition and unpartitioned cookies with the same name um and it turns out there's actually already precedent for this um domains can set cookies with the same name as long as they differ in either their domain or path attributes um and so in order to account for partition cookies we propose adding the partition key to this Tuple of attributes that we use to consider what cookies are unique and that if a browser were to set a cookie with the same name and value but one had the partition attribute and one would not we would send both cookies and the cookie header and subsequent requests next slide um and then the last issue um how can user agents convey if a site us all right how can user agents convey if a request comes from a context in which um the browser would only accept"
  },
  {
    "startTime": "01:02:00",
    "text": "partition cookies um and we think that this shouldn't really be a blocker for specking partition cookies this is kind of a long-term question and has implications Beyond like just partition cookies um and so kind of our solution for now is just pump this down the line um next slide um so the next steps would be to continue to align with spec work with this group and also um the w3c to align with uh things like the cookie store API or document.cookie um and also chips or cookies having independent partition state is a uh good example of actually how iitf might benefit from cookie layering because essentially if cookie layering happens and we move some of these more browser specific things into the fetch spec then really all the ietf needs to be concerned with is how um how user agents parse the a partition token in the cookie line and then they can kind of let the fetch spec handle the rest of the partitioning Behavior um and that's it so anyone has any questions feel free so I think from a process standpoint here um when we talked about adding major new features for 6265 bits we had a relatively rigorous process for getting consensus around here's a proposal with a draft does the community want to add that to 6265 scope and so um this is probably too late for 62.65 this and I don't think that's a surprise to you which is good um and the question is you know when we do this next revision that we were just talking about you know are we going to use a similar process and if so you know what would our folks interested in taking this on as as a piece of work and as before I think you know in in 6065 original as well as this we kept the focus very firmly on implementer intention uh and and so you know folks who have cookie jars they're not the only people who matter but they do really matter to this discussion so"
  },
  {
    "startTime": "01:04:01",
    "text": "that's who at least we we should hear from Martin yeah so um during my Mozilla hat but the Privacy CG chair and w3c that that group has pretty broad support for this work and would very much like to see the work proceed and I I think we have agreement also that the ITF is the right place to do that um because the ITF owns the cookies back and it doesn't make any sense to put it anywhere else uh I I think we're willing to be guided by everyone else in terms of timelines and whatnot and it very much seems like this cookie revision is like this close is my impression um and I see nodding so that's good because I would really like to say it finished as well as much as it's been 15 years or however long it is so um I I think this is probably something that I would sort of advocate for some sort of signal that it's uh working in the ITF process uh so I sort of would prefer if this were adopted here um perhaps parked on the side so that we can continue to work on it and refine it and answer some of the interesting questions Dylan's asking here but not um block other important work that would be my preference here to me that sounds reasonable and I think one of the questions in my mind is do we launch that next cookies work at Yokohama or even beforehand but I guess that depends on a lot of different things okay any other comments thoughts anyone online as well Brian"
  },
  {
    "startTime": "01:06:05",
    "text": "there's maybe sort of a naive question but can you explain a little bit more the rationale for providing this at all uh versus the the browser just making its own decisions about how it will partition or not partition that it it's always felt to me like it's a a question of how the behavior of the client itself the browser or whatever behaves and putting it onto the wire and part of the cookies back um um it's hard hard to articulate it more than that but referring to like the attribute um and like the opt-in behavior and just say like yeah okay yeah like at least it's my understanding like uh Firefox Mozilla basically partition cookies right or has the opportunity to partition cookies in their client and they just did it they partitioned them top level domain lower level domain it just sort of happens so bringing this into a spot trying to give servers the opt-in behavior is never quite I've never quite understood the the rationale or the motivation behind that and it almost feels simpler to not to just allow it to continue to be a behavior that the the client decides on um at least Karma's philosophy on this is that um we want to encourage this to be like an opt-in Behavior at least in the time between now and when on partition third-party cookies are turned down and the reason being is that like a lot of servers rely on third-party cookie functionality for various things some of that's cross-site tracking which we're not okay with but then some of it are some use cases that we are okay with and um in this sort of transitory period where we move off of third-party cookies um we think that like providing this attribute and this opt-in Behavior provides developers with an opportunity to kind of migrate their systems over to this partitioned World um you know before we just completely kind of take the rug"
  },
  {
    "startTime": "01:08:01",
    "text": "out from under them and remove on a partitioned third-party cookies um so it's kind of a web compat I guess uh reasoning behind it wouldn't again I apologize for I'm not fully understanding but in terms of compatibility it always it feels like there's cases that are going to break then if you're expecting third-party cookies that will otherwise work in a partition context and you're not opting into them so like a server that you know does whatever it does in a in a frame or something and continues to get set cookies get cookies as they would you partition those it doesn't know the difference in terms of How It's behaving but if if suddenly it's changed such that you have to opt in with their or partition cookies then that would I believe stop working with unless you make the migration so it feels like that area is not compat at least not in the way that I think about it be a breaking change and require software updates to well continue working I think like kind of at some point there is a breaking change that needs to be made either it's like removing third-party cookies entirely or it's just partitioning them by default so at some point we're going to be breaking sites I think it's just like a matter of difference on sort of how we want that breakage to occur um I think that like our philosophy is that um you know the the server getting the lack of cookie back once we do turn down third party cookies is a signal that like it's not working as intended versus having the user agent just sort of like change the behavior of the cookie from underneath the site without really giving it any indication that that's what's going on um is like kind of just as bad in our opinion okay yeah I have almost the opposite"
  },
  {
    "startTime": "01:10:02",
    "text": "perspective that that just to have things continue working to the extent that they can without requiring any changes to opt-in a behavior that should just yeah it seems it seems unnecessary and sort of backwards um but maybe I'm often that weeds here kind of feels that way there is an explainer correct there is yes um I can if you want to come up to me like after this and if you have any additional questions to or I can also like send you a link to the explainer where we talk about things in a lot better detail um so yeah I encourage you to do that okay thanks so Martin Thompson this has been debated at length um in other forums and um it was it was a the consensus view I think was that that blocking blocking cookies in these third-party context was the desirable outcome it was not necessarily uh unanimous that that was the the outcome there were there were a number of reasons the ones that Dylan articulated uh for doing it this way I also believe that certain other platforms have a little bit of trouble when they tried to um implement partitioning properly and those were limitations around um devices not being particularly performant when partitioning was in place and so um and those were also rooted in the architecture of those systems as well which I think was a little unfortunate but um ultimately our experience with partitioning is that it mostly almost completely works and so you could do without this but we were sort of in the minority when it came to the discussions there and and we want to respect the"
  },
  {
    "startTime": "01:12:02",
    "text": "um the consensus process there and uh the ultimately this is fine it's not great but this is this is what gets everyone doing partitioned and um State properly so this is the this is the Compromise okay well and and you know we haven't formally adopted anything yet uh it's continuing discussion but it's a good start I think anything else thank you okay thank you very much and we're on time too uh next up we're going to go back uh to a rearranged agenda and talk about client certs right I recognize that photo I thought so in London some time ago okay so yeah client search uh I've only got five minutes here so this is me pretty short uh go to the next slide I Know It Takes a Minute Martin if you want to clear yourself unless you already have comments uh so Mark uh encouraged us to just focus on issues questions Etc and not give any context or anything it's hard for me but I take a shot at that in interest of saving time here so uh back in October we published uh 03 really um relatively minor changes stating that the certificate chain is presented in the same order as it would be defined in TLS rather than trying to copy a bunch of language from TLS that that is difficult to get right and sort of problematic did a bunch of reference updates to things that are now are now rfcs uh made HTTP semantics a normative reference some of the normative"
  },
  {
    "startTime": "01:14:01",
    "text": "informative stuff's a little tricky to get right here but that one made sense mentioned that uh in the case the origin server Access Control decisions um need to be conveyed at the HTTP application layer either by selecting specific response content or sending a 403 or something but uh be pretty clear that we're not trying to invent any sort of cross layer signaling about error conditions or Access Control decisions um October 30th started working group last call and um next slide I did this sort of last minute because I did have a saying that said there was no open issue um Lucas Conley did a review and put a number of things up here thanks Lucas um there are a number of issues that are open I don't think any of them are very controversial uh we have a little bit of a discussion going about sort of text and what it might look like in the future versus now in context and so forth but it will work through that I saw another one come up do that as well um but there's uh yeah the these are open I plan to address them um I don't think there's anything uh of of consequence of consequence in terms of progressing things along and uh we are still in uh last call for a little while um that's it that's sort of a boring presentation but that was I think the goal okay uh any questions comments have people looked at this draft Martin here in the queue I assume that's from last time hello Lucas it's here um yeah I just had a blast of the draft like you say loads of these are just really low-key there's a little things you can pick and tidy up but it got caught in some other reviewer um some other editorial like I say we disagree that's okay you're the editor if you want to do it that way that's that's your discretion so just just wanted to give some kind of"
  },
  {
    "startTime": "01:16:00",
    "text": "contrast and feedback so that in case you didn't think of it that way so I'm happy however we resolve them all right thanks for saying that I I didn't think about it that way until you brought it up but even as I think about it I'm I still sort of like the background and context but um let me think about it a little bit also in reflection this this is an informational draft that is correct yeah so I I think I might have forgotten that so um on reflection you know it's having some context is that there might be they might continue to be other drafts that or sorry other other headers that provide this capability I'm afraid they're almost certainly will be long under the foreseeable future as I think this this sort of came along a little too late and so it yeah and and so phrasing it as you've done is is kind of uh reflects the reality of that this is a way to do it but it's it's not the standard because it's not a standard yeah cheers thanks for that Jonathan wow you're already tall um Jonathan Hoyle and cloudflare um I I haven't looked at this draft so I just looked at it now um but the security security considerations is super light is that not absolutely terrifying um I I thought they were pretty well done but you know I wrote them so that doesn't uh necessarily say much the security considerations are meant to cover the I don't know how to answer that I guess it sounds like you might have some suggestions yeah if if they're specific so I I only looked at the security considerations because I was just curious about how this would work but how is the the proof that the client owns the certificate transferred to the oxygen in the way that it can tell it's"
  },
  {
    "startTime": "01:18:00",
    "text": "not in any way so the the there's an expectation that that the intermediary the reverse proxy is is trusted to do this and it's simply conveying the information to the back end in which case I stand by my previous statement this is terrifying and that's why it's informational that is part of why it's informational Jonathan thank you for your uh for to contribute to PR aise so actually uh to to follow up with that statement this is one of the use cases where this and the signatures draft uh are intended to work hand in hand and we actually call this out in the signatures draft because something that a uh a terminating TLS terminating reverse proxy can do with both of these drafts together is send back is is to do the TLs validation and then sign like add a signature for this header to the message on the way in that the original client obviously isn't going to add in itself so that the origin server sitting off in a back in a back end somewhere will be able to check the reverse proxy signature against those inputs and then that's how that trust is conveyed it's it's a transitive process it requires a lot of out-of-band uh configuration and knowledge but it is one way to string this together and you're still sort of taking the reverse proxies word for it it just is signing its word versus relying on other mechanisms yeah so there are all kinds of like obviously you don't design protocol standing on one foot but like the the easy or not the easy huh there seems to be an obvious way of trying this with sort of exported authenticators or like some kind of certificate that's actually bound to the TLs connection and then you just pass through a proof that the"
  },
  {
    "startTime": "01:20:00",
    "text": "the the terminating proxy controls this particular session and that that particular scientist client had signed that particular session like to prevent it mismatching and swapping and so that was discussed some I think when we talked about adoption and uh the place we ended up at was that this is the intention of this draft is is to standardize existing practice within the bounds of of described thank you existing practice and and align on a single header uh because frankly a lot of reverse proxies and cdns already do this um and and so uh that that's one of the reasons it's informational because we don't want to put too strong of a recommendation behind that realizing that there are better Solutions it's just that many felt that this would be an improvement and uh uh it would be more Deployable in at least in the medium term thank you thanks for saying what I was trying to say and sorry no no in better words I appreciate that I was struggling over it but that's a that's good context and I think the correct um summary of kind of how we got here and what we're trying to accomplish yeah anything else I think we're probably at time on this one all right working group last call will continue if other folks want to take a look and suggest some improvements uh we should we should be at a working group let's call pretty soon all right thank you thank you uh next up we have cap of the day a presentation about what the wonderful people in mask are doing and how it may or may not affect the world of http sit back get ready to enjoy a mask Enthusiast at work David skanazi hello hello everyone uh David scanazi mask"
  },
  {
    "startTime": "01:22:00",
    "text": "enthusiast big surprise I know um so uh the chairs of HTTP reached out and asked if someone from Mass could uh just give an update to the HTTP working group about whatever the hell is going on in mask because it's totally different people sometimes mostly the same people but not everyone knows and some people might care and they don't know next slide please geez that is slow uh so what is mask so the acronym is multiplexed application substrate over quick encryption which is quite a mouthful um we came up with the name back in 2018 uh it was quite unfortunate that there was then a global pandemic um for actually more reasons than this but um but so now everyone Associates it with a covet mask but that's not what we were going for anyway uh why do we care next slide please so in a one-liner sentence it's we run the internet over HTTP and if you think that it's completely insane you're probably not wrong next slide so just kind of a quick history lesson here back in the good old days of HTTP before they had this thing called SSL um like bandwidth was expensive and people will building cash servers especially if they were on other continents where things were really really far away uh now we call them intermediaries um and then there was the idea like an Enterprise or School networks that you would intentionally go talk to that terminatory because it's getting stuff to you faster because it's already has it cached um that was you know in what we call Web 1.0 these days um because everyone was loading the same"
  },
  {
    "startTime": "01:24:00",
    "text": "thing so you could cache it and nothing was encrypted um but then eventually SSL happened and as usual the security people ruin everything for everyone by making things safer and not working anymore um and so people had to deployed these boxes and were saying no if you want to reach the internet you have to go through our HTTP proxy because that reduces our internet bill but now if you want to do TLS through that you were stuck so the connect method for H for HTTP was invented so you could run a TCP through and then run your SSL everyone's happy again fast forward multiple decades and we eventually remember that the internet is not just TCP um quick is a thing quick becomes standardized as at the ITF ah crap quick runs over ADP how could we have predicted this how do we get that over http next slide please Q mask oh wow that is slow uh so the idea was let's we already can proxy TCP turns out that UDP is becoming even more of a thing now and there are things that are neither TCP nor UDP like the sctp people still talk inside ITF and there are other things so let's just add a add a thing for that so let's just do connect for UDP so let's call it connect UDP and then we got to arguing for about three years on how exactly to do that and you end up with a solution that's kind of as simple as you would imagine where you take the UDP and you put it in in the packet and you send it uh so we got that published a few months ago which was really nice um fun time and because we had to have quite a few bike sheds we decided to split the baby in half so there's one RFC for proxy UDP and HTTP and one RFC that it depends on which is HTTP datagrams and also the"
  },
  {
    "startTime": "01:26:00",
    "text": "capsule protocol because we didn't couldn't come up with a better name than capsule so HTTP datagrams the idea is that in addition to your regular HTTP stream which is a concept that we've had since HTTP 2 you can send datagram for little bits of data and that's really handy if you want to send UDP you just put them in there the really reason for that this exists is that you can then map it to a quick datagram frame which doesn't get retransmitted which is exactly what you want for connect2db because if you put it inside the stream you'd get bad performance um and the capsule protocol that I mentioned was something that we thought would be useful a it's useful for like HTTP one and two or you don't have the quick data grab frame and it's also useful for other things or more we wanted it for that and we said well let's toss in a tlv so it's extensible we have some use cases for it so it allows you to send something all the way through all the intermediaries um reliably and so those were our first deliverables here I've seen shipped a few months ago we are working now on proxying IP and HTTP we had a whole nice fun detour on writing a requirements document uh for that first which I was kind of annoyed at Mark when he suggested that at that first but he made a point that like oh you're not actually all agreeing on what you mean by proxying IP and you were right so we ended up arguing on the requirements document instead of arguing on the discussion on the solution document but at least when we went to build the solution we knew what we were going to build so that's been taken care of we're building the solution and we're pretty close to done uh so we'll be discussing this at the mask meeting which is sometime this week uh come if you're interested but we're pretty close to done next slide please so what why would you want mask um one of the things we discussed at the beginning of the the effort was do we want this to be over HTTP we all"
  },
  {
    "startTime": "01:28:02",
    "text": "agreed that it had to be on quick because quick is the best thing ever uh but then do we put it over HTTP 3 or other things and we're thinking well sometimes it's nice to be able to run over networks that block qdp so putting it out of http means you have access to http one and two uh I really like the fact that if you put it over HTTP then it starts looking like web traffic so it makes it really harder to block so now you have a VPN that looks like web traffic hard to censor I like that uh don't say that some people don't like that um another part that I hadn't thought of at all but that we realized was companies like Google have already put in a lot of effort in having a really good HTTP server and so a quick stack that's efficient and security reviewed and HTTP HTTP load balancers and if you build this over HP you kind of get to reuse all of this for free so we end up like in places where like oh can we use ipsec and people were like no we'd have to review that whole new stack and we don't want to can you just find a way to make it work over quick and then there's a fun story there where Alex and others back at Google actually implemented a VPN over quick way before the mask effort and was kind of the Catalyst for the whole thing and then we are closing the loop on making that use mask now which is fun um and then when we built this um folks that like to use buzzwords like zero trust and other things that and serverless and things that I don't understand said oh this is great can I use this too uh and they were apparently much the problem they had was they had VMS in the cloud somewhere that needed to talk to each other but there were HTTP load balancers in the middle and they wanted magic crypto and we said well actually they had built something using connect because that was the simplest thing for them and then they had a customer who wanted UDP so boom this actually works for there like reusing stuff is useful next slide"
  },
  {
    "startTime": "01:30:05",
    "text": "so where are we going from here uh the mass working group was very tightly scoped to make sure we didn't get too distracted and to make it to kind of get us to focus on shipping connect2dp and connect IP uh but now that we're almost done with that uh we're talking about a sculptory chartering for future things so that's also on our agenda um we don't I don't I don't think the current plan from what I hear far on my isg overlords is that they don't want to mask maintenance working group that lasts forever we'll just re-charter for a few scoped extensions do those and then potentially shut it down and say future things happen in the HTTP working group we'll have to discuss those things it's not entirely figured out but I guess that's what's going to happen but what are the extensions that we've been discussing that might happen before then so first we have extensions to connect UDP so connect UDP is similar connect kind of gives you a connected five Tuple but if you want to do something like webrtc where you're talking to multiple hosts you're one proxy it doesn't work for that so we have a little extension for for doing that we have an extension for doing quick over connect GDP you can run quick over connect2dp non-extended but Tommy had some clever ideas on how you can optimize that and make it better we have extensions kind of at the HTTP datagram layer Marcus and Erickson folks have an idea for adding sequence numbers to catch reordering when they're doing multi-path quick uh there's an extension from Ben um about uh having a way to figure out your path MTU through the entire chain between your client and your endpoint so that way it makes it easier to run protocols unlike quick they can't do it themselves Lucas has a draft about priorities in HTTP datagrams that he's very excited about next slide please"
  },
  {
    "startTime": "01:32:01",
    "text": "and we have some um generic like other HTTP extensions that the authors were thinking like mainly in the context of mask but could also be applicable to other HTTP use cases so we haven't selected the view in a venue like all this feature work that I'm talking about is individual drafts so Tommy has something about sending more DNS information as using the recently published proxy status header and Ben has documents on describing what mask services and HTTP origin has and on modernizing connect itself next slide all right so we are meeting this week on Wednesday we have a mailing list a GitHub like all the cool kids uh if any of this sounds interesting to you uh please show up please come and we're happy to bike shed on all the things as we always do that's it any questions [Music] any questions this is mostly informational and then some of the folks are already uh very familiar with us we just thought it'd be good to make sure that everybody in the working group here was aware of what was happening over there especially as you get a little bit closer to stuff that happens inside of http so thank you very much for that really appreciate it um and with that I think we're done for today let's check the agenda yes we are fantastic sorry oh what time is it well we have 25 minutes your presentation from Friday being which one on profited authentication I'm prompted um in principle I don't have a problem with that I'm just worried that somebody who was expecting it on Friday might be a little surprised by that but of course"
  },
  {
    "startTime": "01:34:00",
    "text": "there is always the mailing list uh where if if we do adopt something or whatever it'll make these senses so as long as whatever happens goes to melon must I think yeah which it would yeah um I think so sure any instructions to that Tommy are you still awake I I am I'm hanging in there got my coffee um yeah I think that sounds fine um yeah okay thank you reordering is something we're still a little unfamiliar here in HTTP land so you know I know we have a mask for that there's a better way to phrase that I'm sure all right hello it's me again um David's kanazi HTTP Enthusiast um so this so this is a draft that was initially part of the original Mass proposal so this is actually not a bad segue and people gave me very good advice at the beginning that you don't merge everything into a big castle in the sky and otherwise it doesn't work you split it up into small bits that makes sense and so this was one of those that then went dormant as we were all focusing on mask itself and now people reached out that were interested in it and I'm trying to resurrect it and see where we want to go with it um so this now we have multiple co-authors this work is joined with David Oliver who's I think attending virtually this time and Jonathan who's right there next slide please so um the the draft initially was called transport authentication and the reason for that was that the original mask proposal was uh I think the term is monstrosity in terms of HTTP semantics because it took over the whole connection and did things that were very evil by HTTP standards and so the new version of masks as we talked about fits into HTTP semantics but because of this the old version needed a way to"
  },
  {
    "startTime": "01:36:01",
    "text": "authenticate the whole transport um now we don't need that anymore so the draft has been kind of completely Rewritten the cryptography bits are still in there but now it it fits in HTTP semantics similar to how mask does uh next slide so the the motivation we have is we want the client to authenticate to the server uh to the origin as is commonly done with HTTP Authentication um we want to use asymmetric cryptography because there are some use cases where you want to be able to share the like access list with their public Keys across multiple Origins that don't necessarily trust each other and you want to avoid having an Argent be able to impersonate one of the clients and then the third requirement is we want the server to hide the fact that it serves authenticated resources so what I mean by that is if you try to get this resource you don't want a server to send you a 401 and the reason for that is let's say you have your personal website but you want to offer some mask services to authenticated clients you don't want someone to be able to probe your server and go oh no no that offers Mass that's blocked on my network bang bang um so those are the three like I'm gonna dive a bit into the solution space in this presentation but the the goal or the interest of this draft is really to get in see if there is interest in those requirements and that motivation because everything of the solution is completely like Up For Debate or any discussion I'm just this is what I care about personally with this proposal next slide just to be clear your third requirement there is that the server hides the fact that it can serve authenticated resources uh yes so not that it is serving ah so yeah let me rephrase that I guess that's not very well written um let's say that the the server offers a"
  },
  {
    "startTime": "01:38:00",
    "text": "resource to only authenticated clients that's a common thing and an unauthenticated client must not be able to find out whether that's the case or not so it can't probe the server to find out that the resources there you're just not allowed to see it okay I'm thinking about the very header but okay about what the very header yeah so the why don't we already have this in our very large suite of HTTP authentication methods um so if you're doing cryptography and you're using a signature you need something to sign and you need that to be fresh otherwise this is things are replayable so in common protocols today the way we do that is the server sends announced the client signs that nonce sends the signature back and the server goes great that's fresh um but that breaks our requirement of the server not letting on that it does this because if it sends a nonce you go oh I got an answer from you I know you all you you support this scheme uh so hoba is a is a means that that does that for example that's already standardized um but that leaks the fact that the server does this next slide please so the idea we had where I think the clever part came from Chris Wood I think but anyway is if you use TLS key exporters uh that gives you announce because both the client and server have fed information into the TLs key exchange so you know that a key exporter is fresh the uh I'm blanking on the name um Channel binding use that as well um but we're not doing Channel binding very different but like just that same idea of using a key exporter not to generate a key but just to use it as a nonce so that doesn't link any information because any side can export the key locally"
  },
  {
    "startTime": "01:40:00",
    "text": "and it can be replayed either empty I don't know if you've uh thought about this one but it it's possible that in certain contexts say like web browsers an adversary might be in a position to uh for example um make requests and [Music] um this only prevents the authenticator from being moved to another connection that doesn't prevent it from being reused on the same connection so that's but you like you still need the private key to be able to you don't need the property you just need to see the output and if you can copy the output you get to so how could you get access to that output or sorry what output so the headers that you're sending this is this is somewhat theoretical of course but if the if the head is on on one request leak in some way oh I I see what you mean reduced on that same connection again so this is the attack we discussed this at the at the last ITF and uh so Jonah Jonathan and I thought about it for a bit and that's a real Attack if you leak that you sent a header with this on one request you could put that on another request but the threat model there is an attacker that kind is already like inside the TLs and so we decided like that wasn't practical in practice so we added a paragraph to security consideration saying that that was out of scope uh but it's a real Attack as long as you thought of it that's all it just it just occurred to me yep no no we thought about it like we could if we wanted to solve it by putting something like the stream well the stream ID would be gross but something that's unique um it's not the end of the world but"
  },
  {
    "startTime": "01:42:00",
    "text": "like we thought that in practice it wasn't a problem so we document that if if this is part of your thread model then don't use this you could bind to things in the request so that's not portable between requests for instance the URL um I don't want to pull too much in but yeah no we could do something like that narrow the scope of reuse I don't know that that's worthwhile yeah yeah so the the advantage if you you have the same thing is that then it gets compressed by each pack or qpac and we thought that was a nicer benefit than this attack I mean that's totally we can go either way both work um it's a it's a you know security versus performance trade-off as we often have Alex sorry is there clarification or follow-up to the discussion okay different quickly uh yeah I I Alex fromowski Google um I just wanted to add that I also previously brought up a similar thing around the fact that this was a connection oriented export and it really did weird things around streams so like I think if we uh Incorporated Martin's idea about making it be request or stream oriented somehow it would also make it clear that this wasn't a shared resource so maybe somewhat repeatable but not 100 repeatable like URL is definitely a nice one that would still get you some of the compression yeah well we can we can figure that out cool next slide please oh boy come on there we go uh oh so this is kind of a description of the solution um we renamed the draft to unprompted authentication um I really wanted to call it masked authentication but I was told that wasn't funny um so we went with this at least it's clear about what it is um the server doesn't tell the client that it needs to authenticate the client does it without being prompted and it indicates a single request and you send uh what kind of authentication so signature hmac um and then which algorithm like for a signature algorithm or hash algorithm you're using"
  },
  {
    "startTime": "01:44:01",
    "text": "so initially we use the IDS and Mt found that gross so I grabbed something from the Ina registry and I managed to get that wrong too but that's fixable um I I got some good comments in the GitHub I'll that's easily fixed and then you know a username and the proof base64 encoded um next slide please but that's not a structured header is it ah I have a slide for that it it is unless I messed it up well that first you you messed it up um I'll I'll get back to that uh in terms like we kind of discussed this with the client search idea similarly this can't be transparently forwarded because it pertains to the TLs connection uh so the intermediary checks it and then tells Upstream what the result was that part we've declared it out of scope you could build something like the the previous presentation if we wanted to but I don't have a use case for that so we decided it's out of scope of this draft for now and it can be built separately next slide so what we changed since last time because we got some pretty good feedback when we presented this so we renamed the draft we removed the oids we added the security concerns to discuss this the issue that we just talked about uh Jonathan joined as co-author to make sure that I stopped shooting my toes off security wise uh and we switched to structured Fields maybe I got it wrong again I'm an HTTP Enthusiast not an expert but I tried to switch to structured Fields because I hear they're all their age I did a bunch of editorial work to try to make the document better um next slide please so we have an independent implementation by The Guardian Project uh so multiple entities kind of interested in this uh we're wondering is it the HTTP is working group interested in seeing this progress here should we take it"
  },
  {
    "startTime": "01:46:00",
    "text": "elsewhere what do people think um is this completely insane is this a good idea do other people find it useful um any thoughts questions this is my last slide so come on up uh Mike Mike Bishop um I do think it's useful I feel like you're kind of re-implementing some of what's already an exported authenticators so you might be able to just get one of those and then base64 encode it but I don't know I don't know what the Gap is on that but it might be something to explore so exported authenticators don't have that property um I I think from memory and someone can correct me if I'm wrong do you need like that kind of exchange that kind of leaks that the server does this um yeah okay it has been to a request then okay all right so we'll um building many of the same mechanics without binding to that request should be fine um yeah at the end of the day it's not horribly dissimilar yeah um but more broadly written yes I think this is of interest it's uh it's a useful property and there are already HTTP servers that will refuse to admit a resource exists unless you're authenticated they just have some other endpoint that you off to first so this would be a nice Improvement in security for them thank you uh Ben hi sorry my Network's a little unstable uh so uh I definitely want this uh I've even sort of been involved with deploying A A system that attempts to achieve this property but I still don't understand the the use case that motivates this design um thanks for helping me understand a bigger piece of it I'm closer but uh"
  },
  {
    "startTime": "01:48:02",
    "text": "the thing that I'm most confused about is this the if we assume that there is no indication that a given origin supports this uh then client presumably must be configured out of band with information to know that it can use this mechanism with this origin but any mechanism that could configure this client to know that about this origin could have just provided this client with a per origin symmetric secret a password that would allow that the client would send unprompted unprompted authentication yes um to that server but this would not authenticate the client right this would just reveal the client as being among the set of clients that knows this information about the server and then the server can respond with a challenge we can go through standard challenge response authentication so why didn't you do that um so it's the general question about shared cryptography versus or symmetric cryptography with uh versus asymmetric cryptography and yeah pretty much almost everything that's done with asymmetric you could do it with symmetric and N keys but then you kind of have to tie the list of potential Origins with the keys and you get like a bad scaling problem whereas here you can get the keys once and then later over time get the origin simpler so it gives you like more flexibility I mean there's yeah I'm I'm not convinced that it actually uh provides that kind of efficiency Improvement in this case because again you need to be provisioned out of band with this information about each origin that you could potentially contact and so you already have and the clients are already being provided with with order and information here adding passwords on top of that doesn't increase the the order of information that's required to be shared with clients and if you want this kind of"
  },
  {
    "startTime": "01:50:01",
    "text": "shared cross-origin authentication of clients where clients use a single credential across or all of these Origins you can still do that you no longer have to do it within an unprompted context for example you can do it in a hoba context and then you don't have to worry about this thing of like I'm bound to the TLs session I can't Traverse intermediaries you know I'm doing Channel bind foreign yeah that that really depends on your use case it sounds like you don't need you don't need the symmetric part here thank you well so I'm I'm telling you that you don't need it like Guardian Project I'm very familiar with their use case they do not like the system I'm describing is is their system like that's that's how it already works that's how the the bridge distribution system is is already defined so I think look I think if there's an advantage here I could argue that it like it saves a round trip like it avoids the need to sort of pre-authenticate and then you know and then actually authenticate as a as a second step you can do it in one go maybe that's important in some use case but I'm not actually aware of again of a use case where that efficiency gain would matter um and so I think that basically there's a more flexible less complicated solution here um I think we should solve the problem um but I I'd like to see this a little more strongly motivated for this design fair enough yeah I mean complexity is in the eye of the Builder so I think we can agree to disagree on that one well okay yes but like the working group work um you know is has to ultimately proceed by by consensus about this so so that's uh you know it's also for the working group to consider whether this is the right approach all right great thank you so let's hear some other opinions then Kyle Chris um I'm it's not completely clear to me what is being done here that couldn't be done with token binding so can you get a bit closer to the mic please um yeah what has been done here that"
  },
  {
    "startTime": "01:52:00",
    "text": "couldn't be done with token binding so from memory it's been a while since I've done I've looked into that I well I mean one problem is it's it's more complicated machinery and it's at the uh TLS layer I well of course it's at the TLs layer but for I don't know if it has the property of client speaks first or directly uh tied to a request um so the standard way of doing token binding does involve a negotiation at the TLs layer um but I think that could be emitted and get the property that you have here in effectively the same way where the client would derively uh ekm from the TLs connection and then create a signature of it put in the token playing header so I would have to double check from memory there was a lot more involved uh in token binding and the interactions with the TLs layer that made it uh quite a more complicated beast and would be harder to just have like a little token that you send uh I can that's a reasonable question I can give you a let me do some research I can give you a better answer um because it's been a while since I've looked into token by Nick anyone else I'm kind of wondering if we could get a sense of the room of who's interested in continuing the discussion no that would be great yeah so so without making any commitments or saying that yes we'll drop something or that you're going to implement it just a show of hands uh online as well as in the room I don't know how it works online but we'll sort stuff out um uh who's interested in continuing this uh uh this discussion that there might be something here okay so I see a smattering of hands in the room including some implementers online I'm sorry I this big sign here says please do not"
  },
  {
    "startTime": "01:54:00",
    "text": "touch so oh because you're presenting full screen oh that's what's happened okay I guess they don't have a way just to cue if you're interested in your online and then get out of the queue let's do it that way just cue yourself we're getting plus ones in the tit that's good and I see a few people in the queue that's helpful information we're gonna we're gonna adapt the tools we're gonna pay some calories oh it's funny you could see the people in the queue then falling down the infinity well yes don't don't look too hard all right I think that's good information it sounds like there's at least some interesting continuing the discussion uh uh so let's do that cool what would you like from the authors are we at the level of an adoption call are we not there yet I I don't know I'll talk to Tommy I I suspect we're not quite there yet but maybe a little more on list discussion some exploring of the issues like Ben said making sure we understand the use case and why the solution is the right General starting point for that sounds great yeah yeah awesome if I'll see you all on the list on this topic if you're interested one more question for you actually what's your sense of urgency around this uh not really uh I mean it's uh it will be nice because we have a use case I mean you know you can ship thing without having a standard but it will be a nice bow tie to the mask story as well to have all these things like wrapped up so yeah all right thank you and uh we've got five minutes left so unless we have any other business I think we can close for today and we'll see everyone on Friday thank you"
  },
  {
    "startTime": "01:56:00",
    "text": "what do up here great presentations so I feel like there's a lot of iTunes and it is um yeah four years I believe you I like I haven't thought as he was presenting I was what's going to be talked about tomorrow which is the protests public resources available that look like for authentication that would be us anymore it's weird"
  }
]
