[
  {
    "startTime": "00:00:09",
    "text": "we will let people drag 11 because I\u0027m sure the Thursday morning in Scottsdale most lose gates are going around hopefully know what to do by now it\u0027s not ask your neighbor welcome to 84 alright so yeah we are we have magma special and taking notes in the ether pad you feel like going to get the pen and watching what he writes seeing it you know adding any additional tags even worthwhile I\u0027d be appreciated but not strictly necessary you know Brian Rosen in the jabber room you can remote use the Munich of cue with virtual key with your a volatile ultra fancy red button and get you up on the big screen but if you\u0027d rather have Brian talk for you you can do that kids are going around and there\u0027s me to go you know all right no well ask her where so today we are nominally going to 11 but the I think Demark occurs in here supposed to be in here after that is canceled so they\u0027ll be run over it\u0027s not a big deal I hope nobody scheduled something for low that says I\u0027m Jonathan - this is Rachel what are you going to do well it\u0027s Vincent\u0027s fullscreen on its full size of clear okay this is just give you a preview oh my god here\u0027s our sweet new work item markscopy feedback regression control with we what yeah no I wish we adopt with we agreed to adopt last time and I found the active and just a bit of mouse on for on the week before the meeting so marking which hopefully we can finally get done we\u0027ve that\u0027s been lingering rather too long then Ronnie has a proposal for an extension to that then Colin is presenting some stuff on how to could click multiplexer with RTP and then "
  },
  {
    "startTime": "00:03:10",
    "text": "finally because XR block isn\u0027t meeting there\u0027s a proposed XR block a message mostly for socializing the idea and getting feedback on how it is because obviously we can\u0027t I just want to take the opportunity since payload is not meeting there\u0027s the effect the effect the effect draft payload for fact for flexible fakie in and we are going to start we\u0027re hoping to start a white nope last call since it\u0027s does dependency in ordered on RTC web and not like the opportunity that people would pay attention I will also try send to the to the RTC web and the payload that they should review it maybe I should also send it to a VT course or at least people who are not worth following those were those well group they\u0027ll know about it installing right and and for the that is Adam Roach for the people in the room I want to point out this is a dependency for cluster 238 so there\u0027s going to be a lot of heat on getting this completed fairly quickly so I think at least what I knew but yeah so I think but then I guess we\u0027ve had three documents published so yeah us and we still have a number of things as you see deliver q3 which are part of 238 Wiggum bundle and possibly other stuff the bundles need to be the primary thing listed and then we have one document which is waiting on ourselves so let\u0027s do pre marking dog so at least week what have the hanging over us other than that so multipath RTP is Europe here who\u0027s mentioning it last night exhibit on my place he said he come to do some work on it some time which wasn\u0027t terribly so yeah the thing I\u0027m trying to I\u0027m not quite sure what our mouse tone is the motif is already be but I think it\u0027s like 2016 so if we don\u0027t know no idea I\u0027d rather make "
  },
  {
    "startTime": "00:06:11",
    "text": "it obviously rested Aronian its goes a long longer time back I mean we moved it already come apart because we are trying to figure out if they\u0027re going to work on them this yoke says that they tend to so I\u0027m we\u0027re waiting at a certain point in time one has to decide whether Malcolm should die I mean in the abstract I\u0027m not I don\u0027t know if you\u0027re ever here so yeah I don\u0027t know what to do about that that\u0027s true I\u0027ve been on my temptation I mean why am i I will try to see if I can get any more concrete commitment out of the authors I I think I think what Ben said like maybe you can you can take it later and if it is more important because as I say like Lee there have been some work proposed for like RTP work week and stuff like that and that certainly changes some demography when it comes to multi-party PNL stuff like that right so so I actually I don\u0027t feel any interest in it so just just take them off so often if somebody this has been feel free to tell the author that the area director is asking why we shouldn\u0027t kill this because he is that\u0027s part of my job and then multi-factor guidelines we have a slider and there and all the other providers have multiplex guidelines this is also one of the document that was standing there for a while without that milestone not continuing so we took it to took it to finish this document so as you see the zero three version was submitting 2000 dr. BIR 2014 and Marvin and myself did editorial changes on the document because it\u0027s mostly editorial "
  },
  {
    "startTime": "00:09:12",
    "text": "changes to the structure and based on discussion we had with Magnus before about what should be done because Magnus and calling or the previous authors of the document yeah of course there are still authors so therefore the Edit sorry about that sorry sorry about that okay so there\u0027s still the authors of the document sorry the 0 4 \u0026 5 are bigger detour edges in the document structure it\u0027s updated to reflect the current state of multiplexing documents and options which would change between 2014 and today yeah we tried also to do that I mean we try to do everything to keep it up to date with the current documentation which which I\u0027d like civil cars things that that were added during the time from them it\u0027s not ready for publication that the 4 \u0026 5 they\u0027re not I mean the reason I we had the 4 \u0026 5 because I\u0027m the force there was some typos that that was that was there and it was just a change of typo but if you want to compare to previous then you have to compare it to 3 and I think Magnus put it on the dis deep in the in the mando mailing list it\u0027s not ready for publication there are some open issues based on the review from all the authors in the in section 7 and the next step is to update the document to reflect the open issues it was reviewed only by Colleen and Magnus the quarter said we need more reviewers probably for the next version everybody stares firmly up their laptops honestly Paul and Magnus morning and probably myself was a pretty good subset of this build anyway it\u0027d be nice if I had somebody outside the usual suspects all right No "
  },
  {
    "startTime": "00:12:30",
    "text": "just like the mic doesn\u0027t go higher this is this is just gonna break so I will just do it do I look like a rock star Phil Collins maybe all right I\u0027m right the band is being recorded for posterity okay so I\u0027m Colin Perkins I\u0027m gonna talk about the feedback message dressed okay so this was something we presented at the last ITF it\u0027s come out of the our MCAT working group we had a design team do devising a a TCP feedback a couple of our TCP feedback formats to carry the information we need to do congestion control and that they will be able to drive the congestion control algorithms that are MCAT is developing we presented the the design team versions are free of that draft at the last meeting that was then revised to take him to account the comments from that meeting shortly before this meeting and then the AVT card f00 draft was submitted about six hours later and is identical apart from the file name okay so the the change we that the primary change we\u0027ve done this time the the the previous versions of the draft had two different feedback formats they had an Excel block for regular reports and they had a transport layer feedback packet for or early feedback reports which which wish could be sent in on compound packets the feedback we got from this group at the last meeting was that this was unnecessary and we should just use a transport their feedback packet everything and just put it into a compound packet if we were using it as our regular reports so the change we made was essentially to take out the exile block format leaving just the the transport layer feedback packet formats in the draft and the transport layer feedback packet format is exactly the same as the one we discussed before we\u0027re just taking out the the alternative so there\u0027s now only one way of doing it as you see it starts with a common header with the usual rtcp things and the SSRC of the sender there\u0027s then a series of blocks which have the SSS ease of the media source they\u0027re reporting on begin and end sequence "
  },
  {
    "startTime": "00:15:30",
    "text": "number ranges and then for each sequence number there\u0027s a 16-bit chunk which has a single bit to indicate if the packet was lost which if it\u0027s a one if the back that if the packet was lost and then the rest of the sixteen bits are then meaningless avoids it set to zero and you\u0027ve got the ECM echo and the arrival time off such relative to the report time stamp at the end of the packet we put the report time stamp which all the offsets are relative to at the end because the transport layer feedback format says that everything has to start with a SS RCS so we just conformed into the usual style of those and yeah and we\u0027ll you just stack a bunch of those and then you have the report time stamp at the end so the Train is for the draft adjust to keep this format take the other format out and fix the ionic considerations so next steps the I think primary open issue we have is just quite how the type of the time stamps work I think the draft is currently specified to use milliseconds for arrival time offset and it\u0027s a little vague about the report time stamp clock rate in the format and we need to align those to the extent possible and pick sensible rates and sensible formats what I think would make for the report time stamp would probably be to use the the middle 32 bits out of the NTP time stamp just like we do in the LS are filled in in the sender it was so we\u0027re using the same clock we already have for a TCP that doesn\u0027t quite line up nicely with the the millisecond which we\u0027ve got in the arrival time offsets we might need to change that if we count thousand 24 Hertz instead of thousand Hertz that that ven lines up nicely it\u0027s a little bit of a nuisance but so it has to think a little bit about that but I think we could do something sensible there we\u0027d give it a little bit more thought we then need to review the candidate condition control algorithms in our MCAT make sure this fits with what they they need gives the right information has acceptable overheads and so on they find some STP signaling for it and go through and do some editorial cleanups other than that I think we\u0027re in reasonably good shape nice to say that the main issue is figuring out the time stamps - Westland so having reviewed the document not something you review I I think the main thing I think needs more work is discussion of how you adapt the transmission of this when you send it and and kind of so so that\u0027s actually a separate draft which we have in our MCATs that\u0027ll be the will that be CC agnostic so some my the way I was in "
  },
  {
    "startTime": "00:18:32",
    "text": "visiting this was that it would just define the format and then the RM CAD draft would say this is how you pick the feedback rates and configure a TCP to be appropriate for your congestion controller yeah I mean considering the goal of having this being kind of agnostic to watch center side congestion control grants it\u0027s needed I think we need to ensure that you have both the kind of type of scaling and the kind of reporting because I think that you design your receiver behavior is well defined and it needs to be if it\u0027s gonna be in the arm ket document that\u0027s probably you need to be normative reference then and so I mean it\u0027s if you pick it depends on which from which part you coming here but it\u0027s it\u0027s I think needs to be clear that this is defining a very important piece in that case for this format yes I mean I\u0027m not sure it\u0027s normative in quite that way I mean I think all it will specify is you configure a TCP bandwidth fraction and you using the existing parameters as appropriate for your congestion control and it will give some guidance for how you do that I think what what will actually happen is the the candidate congestion control algorithms will say use this feedback format and configure your a TCP bandwidth appropriately you know according to the media rate you have and there are some guidelines for how you do that and singing it over there okay yeah I need to think a little bit more about that but I think how you configure the rates is independent of the format\u0027s so yeah we should configure the rates appropriately but yeah so I mean the I think part of my think it was maybe a bit more not only to the your cases I guess where you have okay when are you actually sending this you\u0027re including it even if you seen zero new packets during the reporting interval so things like that there so I think a few questions around this saying when you\u0027re having sparse or or maybe over full mode that\u0027s true yeah that\u0027s a good point what I think like and this draft just only says like this is the format and this is the this is the information you need from receiver to sender and this the format and and the real implementation of like how and how like when and how frequent they are sending and they Canada algorithm need to decide on that one so my expectation is like they take this and implement this and tell this tell us like whether a what kind of contribution is working for them because the current draft currently says like you can negotiate the rate sending rate and stuff like that so that is my "
  },
  {
    "startTime": "00:21:34",
    "text": "expectation and I\u0027m not quite sure like specific yeah this condition control specific so I don\u0027t know like how we can in this job actually say we can you can you can you can perhaps write something about recommendations like okay this is what we think what they really need to say it in there and how they\u0027re interesting so as I say I think the this draft shouldn\u0027t say much if anything about yes exactly it should say it needs to be configured yes that\u0027s what he says not now yeah Aaron cat draft that says you know this is how you go about configuring it\u0027s based on your requirements and what makes sense and I think the candidate should say for this candidate and configure it in this way and then here\u0027s some guidance yes and that I think I agree with yes sure yeah it would mean these two those two drafts than going lock steps there were referenced each other but that\u0027s that\u0027s okay Mohsen Attia Ladd can you clarify is that the configuration protocol based configuration or figuration is that is the at CCP benefit fraction and not something yeah so I think I kind of agree with Magnus this point that think of the you you\u0027re just a dumb endpoint that knows nothing about congestion control but you want to participate well with anything that is doing sender side condition control I think you want to be able to have already the enough smarts without looking at any arm count work to be able to send the right feedback at the right times without having a congestion control implementation inside of yourself as a receiver yeah that\u0027d be a good goal by that yeah yeah I totally agree and I think the only configuration you need to do that is existing a TCP configuration you know the bandwidth fraction the AV PF parameter that sort of thing should this document say you know must actually put my RS nrr hey maybe I don\u0027t know I mean I think they\u0027re separate I think the format\u0027s is a separable issue to how you can figure it the other thing and I\u0027m not sure the format wants to say you have to configure it this way although we could probably say these are appropriate ways you could configure the bandwidth fraction for it so not too tight documents that closely okay - I think I\u0027m fine we\u0027re not tying them too closely I think this document I would you need to specify when to send a feedback message based on packet arrival if it\u0027s received packet or not etc or in cases when the packet starts to go to go towards overflow I really don\u0027t think this document should do that but I mean if you receive zero packets are you sending a feedback packet yeah I mean it "
  },
  {
    "startTime": "00:24:37",
    "text": "would be so I mean this you just say you configure yes we will send feedback and you send feedback and you just put it in all packets yes but I mean the feedback here is that the feedback is about received packets if you receive no packets or you\u0027re sending a feedback message to indicate that you didn\u0027t you see a packet and then you need to have discussion at least that\u0027s happening and that\u0027s I think go to another part which I was a little bit thinking about what happens when you have losses of these feedback messages and and if you have any overlap or anything like that that\u0027s but it\u0027s a separate question but it\u0027s this these kind of issues becomes evident if you really think about in from from Adama receiver point is that I think you need to specify at least what are the criteria for sending this if it\u0027s configured I think I kind of agree with like we need to write all this thing I mean the the SIS interaction that draft perhaps a better place to describe in these details but maybe we need to say write something about like okay go and look at that if you would like to have like implementation guidelines and I was not really convinced like this document need to have information guidelines and this is just an format up to me but anyway maybe it didn\u0027t make sense doesn\u0027t need congestion control implementation guidance I mean I I think I I think I agree that it needs something that says you if you get a hundred percent packet loss or something send it\u0027s yours what to do in when the sender stops sending you packets that sort of thing well most MERS and I think maybe a practical example it would helpful I shot the issue it suppose that we say it\u0027s only configured through you know our TCP fractions but those are maximums what are so much there\u0027s a hundred percent you know III will allow you to do you know whatever whatever you want the the draft if it\u0027s expected we can figure it only through that still leaves a lot of leeway to say should you always fully saturate your rtcp bandwidth or you choose to be very conservative and and only use you know what you think is reasonable as a receiver so I think that that leeway sort of depends on what the congestion can the sender\u0027s congestion control algorithm expects so I think that\u0027s the mismatch that just using the artistry bandwidth fractions to configure this misses that okay if somebody says you know fifteen percent or TCP bandwidth does that me should always saturate your a TCP bandwidth the fifteen percent and send as fast as possible and with fractions means it\u0027s a maximum it doesn\u0027t mean you must send our maximum it\u0027s an allocation a BPF under under rules will usually not saturate about this but it can a PPS has configuration parameters and you would specify those yeah so yes but even even if you specify no in there are cases where you\u0027re not actually saturating the Bandit "
  },
  {
    "startTime": "00:27:37",
    "text": "right the goal is not change anything is to say you use the existing signaling and do it in exactly the same way you don\u0027t do it a million but I think the practical thing is the implementers should have been a pretty clear guidance of what to do and I think it\u0027s it\u0027s uh if I was gonna implement this as a receiver I don\u0027t think I would I would I\u0027d have to have extreme knowledge of all the algae specs and then still have enough wiggle room to maybe throw up some receive some sender\u0027s algorithms and you know work well with some other senators algorithms so I think a little bit of practical guidance for an implementer of a receiver stack what would help you know always send you know within at least this time frame or reference this document so show that there\u0027s a deterministic algorithm for telling you when how many packets do you have to accumulate before you send out a feedback packet so I don\u0027t think that makes sense I really think what this is doing is saying configure the rtcp bandwidth fraction which will tell you how you would normally send your feedback and when you send feedback reports on all the package you got during that interval yeah and I think it\u0027s that straightforward ahead III I kind of agree with Colin here I mean you don\u0027t want to say because as you said like you mentioned Moe like they send our algorithms it could be different and different demanding so I don\u0027t think like this document have to do with that what what it can definitely do is like okay pointing to saturation kind of thing like well you have other feedbacks to also send like you have feed and packet loss rate paper and all this tips ended so when your cooze saturating your artistic bandwidth you need to think about those things like shall we be saturating all the artistic bandwidth I have located for this one only for congestion control then and to send field and that need to wait or what so that kind of I think like we can we can say something in the document like you you need to before you saturate the artistic allocation with feedback in it if you are using some other feedback message you need to also calculate that one just a hint let people don\u0027t make mistakes so this I think I agree but I don\u0027t agree like you really need to specify within this this amount you need to send a feedback and because that\u0027s condition control candidate specific and this should not go here I mean this might be something for the the RM cat draft that talks about how you configure our CCP fractions I really think you swing for this first so - best alone I agree that we can\u0027t specify the impact we need to kind of follow the rtcp timing rules what they give it cetera I my comment was really about there are some cases is like are you sending or not sending it even if you didn\u0027t receive packets I think that\u0027s one one thing I think we should definitely yes and and and think about this are they similar very basic things like that that has to do with and and maybe think through what happens if what will happen "
  },
  {
    "startTime": "00:30:37",
    "text": "if you actually lose this feedback message etc what how does it look 40 you see the one that receives two reports when they gets parsed you de packet loss yes yes but you know I really think we should not be trying to respec safai timing rules here so I feel like I feel like you know yes so si si may note that they are mcat draft and you know the various algorithms are what somebody was implementing you know who a media center ignition control implementer should need this draft should be everything a media receiver and feedback centers with me plus the Arctic respects in South obviously but I mean they they should I mean somebody was just you know providing feedback and not implementing conditioning for all food we need to read it sure yeah sure I mean that that they they should be expected to do the thing that s that\u0027s configure the time erm it\u0027s a necessity guidance on how to set those people yeah I mean that this should probably you know this should probably say you will likely get these types of configuration premise you have an abstraction possibly even you know these are things which you know you you know you may have yes yes yeah I mean what what what I think what we\u0027ve never done in this group is said you must do this sort of thing we said this is an example of the type of signaling which would work for it but there may be other ways of doing it you know so are you expected to send feedback on every early feedback option because I\u0027m sending you early feedback this optional day to be up if you feel like this is appropriate time said that you sent so this is now in case where you\u0027re expecting to send it always that\u0027s I think especially because I\u0027m fairly certain if I remember the details needed record that for clues you send it immediately so I think you end up alternating use every valid early feedback slot with you know if you receive the packet in the house come just a reminder this document will be used by people who do not use as the be signaling so defining STP signaling is fine requiring as the peas in the leaves no I think that was my point yes you know pay attention to I "
  },
  {
    "startTime": "00:33:47",
    "text": "know you know I was not following much the arm cut with without work but I\u0027m wondering if the receiver doesn\u0027t support these messages but he sends ECM for example the ecn marking the Czar\u0027s arm cut address this case where when we\u0027re negotiating you don\u0027t support that you support the other one so so you can get the information what I mean you can get the information from other rtcp feedback if the if they are supported I mean I I think that depends on the our MCAT candidate congestion controller and some of them might some might not but you don\u0027t you don\u0027t address this in any of the arm cut the Pickens was you can work around even if they receive a dozen support as I say I think that depends on the implementation and the erm candidates and some of them support also a massive types of feedback some might not enjoy her there obviously if the congestion control doesn\u0027t do easy and obviously it\u0027s not going to work with that feedback right serious we can give general guidance so so the idea here is like this CC feedback here we agree to an arm caddy this is necessary information and to do the condition control one of the signal was like Sen but it\u0027s not only the only this and so some of the algorithms like you scream or nada they can they can react on its end but how efficient would be that only to react resent and that has not been discussed it was like as you if you read the draft in the draft and the analysis part we did like these are the information it\u0027s like packet I need to fire then offset delay things and easy and so you see n is part of it yes we discussed this in arm cat and some of the algorithm actually has implemented like it\u0027s pretty scream as implementation of EC and reaction and I think nada also has that but whether only CN signaling will do the trick that is not part of the evolution at least in our evolution so I think an RM candidates I think the goal is that the candidate should be able to work using this if if the candidate is also written in a way that it can fall back to using some other type of feedback if that\u0027s all that\u0027s provided I think that would be a good thing yeah it\u0027s not I think it is like that it is likely if you get in additional signaling you want to use fine but like like yeah yeah I mean but then then Aaron cat I think I don\u0027t get proponent cannot really we have not evaluated just only for like how much efficient we are to only take easy and as a signaling that we haven\u0027t evaluated we don\u0027t have result on arm cap just for your information allows Chan know there will be a little more brutal and our MCAT is about the latest congestion control if you don\u0027t have information about delay you come to the lab ace congressional control you might have fall backs but in order to have the latest conjugation which all you need "
  },
  {
    "startTime": "00:36:48",
    "text": "information about delay you need this this this thing anything else is fullbacks yes yeah absolutely there was discussion about whether you know since you getting essentially a full you know app Mac report failure or do these dreams would it be interesting to you know people accessible all I want to use us instead of you know Mac people probably worth noting that it would be redundant sentient neck feedback but I suppose if you want to configure it then why not if you want to waste capacity that\u0027s your problem I\u0027m jihad again I mean we have a section called design rationale where we actually talked about like tell like people already have some of the excel block and some of their signaling that they can do but yeah we have not talked about like well by the dest is good enough I mean the rationale was like there is no no way to sell like arrival time is time there is no signal right now yeah but I mean I think you should do what signals and if that is stupid then well or case someone\u0027s I used to do something stupid but go ahead yeah yeah I mean eighty of noting that some things are redundant with this I think make sense but I think we can say that but didn\u0027t get it do I care so maybe warnings that no it\u0027s about the Sabres back yeah I mean we if there are overlaps or concerns like that we should obviously note them but you know again if someone wants the signal that you should do something stupid then you should do what the signaling says yeah I think I agree Essaouira start this discussion but what you are telling us go read the ironclad documents and see if they are correct that\u0027s what you\u0027re telling us I\u0027m not sure that was what I was telling you at all but but please do read the MCAD documents and give feedback more is something where I would like to see some implication experience before we "
  },
  {
    "startTime": "00:39:49",
    "text": "finalized this because there are a lot of these details and also with you know how does it behave in practice in real networks I know that\u0027s some of the are mcat candidate Albertus looking at social real systems hopefully income with my are MCAT chair hat on I think we would need to see that it works with some definition of reasonably yeah I mean I suspect it\u0027s not that big a change to the implementations to switch the packet format to the feedback for at least some of the implementations what do you but I mean that they have to deal with that anyway because that can happen whatever the format is so okay thank you all right so you\u0027re kind of behind schedule but at least I\u0027ll be other morning Thomas next yes we\u0027re here so we\u0027re over we\u0027re running around that took them bet that was a lot longer than 10 minutes this might not take the full 20 minutes Somoza natty on behalf of a esperance new house and found the the RTP header extension for frame markings next slide please so version o6 a quick review of what this work is for mm the main motivation is to be able to support RTP switching topologies where we have a middle box that does not transcode the media it just us which is the media and and often the payloads of the of that meeting will be encrypted so one of the motivations is to be able to save rien Krypton costs at the middle box so you can have better scale and latency and there\u0027s also cases such as perc where the middle box will have in the end encryption that it cannot read so it doesn\u0027t have the keys for being able to read the payload headers of the packets so in that case "
  },
  {
    "startTime": "00:42:49",
    "text": "would be impossible to do any kind of media specific processing and the goal of this work is to help surface some of the important bits about the media up to RTP headers in order to be in order to be able to do intelligent switching and then a very more forward-looking aspect of this is that you could potentially support arbitrary payload formats even new ones even undefined ones that uh that the middle box if it has support for this header extension it could understand these other formats understand how to switch them intelligently without necessarily having to implement anything specific to that payload format next slide please and then some of the other benefits is that you can have a better experience because the video can be switched cleanly at intra-frame boundaries by the middle box even if it\u0027s totally unaware of what\u0027s inside the packets and during packet loss there\u0027s more defined semantics about when the packet loss would affect a certain frame or a certain proportion of the frames so what could be renderable and what could be not and then of in case of congestion the middle box can make better decisions about which packets are better to drop towards downstream receivers that have congested links and it could drop entire layers if if codecs are scalable and then endpoints can also take advantage of this the same way as middle boxes when there\u0027s packet loss I can understand better what the implications of that packet loss are for frame rendering next slide so this is that our extension there\u0027s a two variants of it you see the length field I can be either l equals 2 which actually means 3 bytes of payload 3 bytes of a header extension or l equals 0 which is only one byte of header section the one by version is for non scalable streams it only has some flags start an end to frame flags independent frame flags and discardable frame flags and then the longer extension adds layer IDs temporal layer IDs and and spatial and quality layer IDs and picture indices temporal layer 0 picture indices so that for scaleable codecs you can do more intelligent layer drops next slide please so the main change in this version of the draft was motivated by some discussion on the list about implementing this for vp9 SVC applications but I think it\u0027s really Jarek it doesn\u0027t really it\u0027s not really limited to vp9 any scaleable codec would have the same kind of implications not necessarily the exact bits that were discussed from the vp9 payload draft but very similar things also exist for 2 6 4 to 6 5 and basically there was a confusion about how to map some of the vp9 bits the P and the u bits to the frame marking definitions of the I and the B bits so we made some changes to clarify "
  },
  {
    "startTime": "00:45:50",
    "text": "how this mapping can be done in section 3.1 and to the definition of the extensions for the scalable non-scalable streams we show how to encode the independent bit god Bernard yeah so I just had a question for I think Jonathan that there was an issue when we had like more than two spatial layers that the PNA you bit didn\u0027t map it wasn\u0027t because it wasn\u0027t the neither the beam or the eye seemed to really be sufficient to determine what P and you would be let me go through how we changed the definition of the eye and then we and we\u0027ll see if that works for the P that okay yeah all right so the the eye bit was basically changed in definition the only signal temporal independence and so in that case it\u0027s basically the inverse of the of the vb9 p vb9 p bit is predicted I think predicted frame which means the opposite of independent frame means that this frame depends a P the P that means this frame depends on prior bits it\u0027s predicted from I think it\u0027s from prior frames and in the frame marking header extension the eye bit means this is in an independent frame or like an intra frame it does not depend on prior frames and so the the they\u0027re inverses but but now with only with only specifying the temporal aspect in this version of frame working then you can have dependence on lower spatial layers and still mark the eye bit if you\u0027re not doing temporal prediction to previous frames and there was for the for the you bit there was discussion about when when you could do up switching to higher temporal layers and I think the rough consensus on that was that the scalability structures that are recommended for this draft would be restricted to simpler structures that can only support temporally nested hierarchies so we changed that in three for two it\u0027s recommended for a temporally nested hierarchies and it\u0027s not recommended for other scalability structures so basically in that case the you--but is always set the vp9 you--but would always be one for all the frames because you could always up switch to a higher temporally at any time next slide please give a little more detail about the I bit here so this will I think Bernard was asking about what does the I bit mean so we changed it to mean only temporal independence for non-scalable strings it\u0027s very straightforward just it\u0027s basically still iframe or P frame kind of semantics we just modified it to say it\u0027s only for temporally Prior frames next slide this is the more "
  },
  {
    "startTime": "00:48:52",
    "text": "important case for scaleable streams ibid is again still just temporal independence so if you set this bit then you can set it to one even if there are spatial or quality enhancement layers that this frame does depend on so previously you couldn\u0027t set this bit unless this was truly independent that it had no other dependencies but now you can set it even if it has dependencies on lower spatial or quality layers so that\u0027s the that\u0027s the main change that aligns it with with the vp9 pbut would you expect that this would be required to be the same across all social layers of a of a picture or could it be set in separately for different spatial layers because that\u0027s depends whether it\u0027s satisfied as an FYI I don\u0027t see a need to restrict it to have all layers have the same bit value I can easily see a case where you have the maybe the the higher layers are are not intra because they\u0027re very expensive to code intra but the base layer is intra figuring out if you what you got as a poll entry means you have to look at every layer yeah I think that\u0027s right okay next slide okay for for scale buddy structures again this is related to the vp9 new bit which allows up switching to a higher temporal we clarified that basically align it with LR our draft in in its in its nomenclature we use the same definition for temporal nesting that lrr uses so here it\u0027s only recommended for the case of temporally nested scalability structures and it\u0027s not recommended for any other cases of scalability so that means that the vp9 you but is basically always inferred to be one so now Bernard do you think you seen him remaining issues and I don\u0027t know Sergey I was yeah yeah if I\u0027m trying to remember the case you had in your draft Jonathan it was a case where we were needed to up switch in scalability and basically it had been there had been a temporal dependence and then finally there isn\u0027t one and you needed a way to signal that this is the place you could up switch particularly I think if you have like "
  },
  {
    "startTime": "00:51:52",
    "text": "more than two spatial layers and I think what we\u0027re saying here is that the I bit would that the at the up switching point the I bit would become one right and that and that would be true for spatial for that spacial case right but I think that case was largely okay so I guess I guess the only thing I would ask Jonathan is are any of the structures you described the all the structures cases you described in your document will work for this right they were all temporarily nested I mean I showed an example of okay yeah and I think Sergio also replied that he was weary of requiring temporal nesting because he wouldn\u0027t to have to change vp9 implementation and I think all of the implementations that I\u0027ve seen do only implement temporal nesting so you I have not seen a vp9 encoder yet certainly not live VPX that will do a non temporally nested scalability structure someone has one yeah I\u0027d like to see it yeah I would certainly help for example the a v1 code doesn\u0027t that it does is focused on temporal nesting let me put it that way doesn\u0027t doesn\u0027t just generate something else by default yeah so I think we\u0027re okay I think there\u0027s no practical restriction yeah for usable streams yeah next slide so this is not an update in the draft this is a an explicit non update so there was a discussion about whether the discardable bit should be expanded to have different different levels of discard priority that was not put into the draft so there\u0027s no changes for it I mean Ronnie has a more granular definition for priority markings of non-scalable streams and his draft that\u0027s it next slide so I think we\u0027re ready for worker bus call we don\u0027t know of anything that\u0027s open a little more review would be good but it\u0027s good to see people actually implementing it and doing feedback about the implementation that\u0027s cool I mean I think I think we want to look at Ronnie\u0027s proposal and decide if the worth wants to add that or not but other than that part so but Bernard I see you\u0027re still in the queue yeah I think I think all the issues I recall are now resolved so all right "
  },
  {
    "startTime": "00:54:59",
    "text": "okay I think yeah we\u0027ll probably unless something comes up we\u0027ll probably do our last call on this okay so just that on the comment on the question about I mean there\u0027s no reason to delay for that I mean just go ahead I mean that\u0027s why we the reason I wrote a separate document is that what discussed it in Prague and we\u0027ll have it we can you can continue with the frame marking and then we can decide afterwards what we want to do is that if we want to to do that so no dependencies at all so this why it\u0027s written is an update to the other one never okay so what what we propose here is to do some priority flags for free marking for the non-scalable stream we did some tester by quarter does all the tests on that and we find out that there are good results that you can have more option if those are available so the cases say so we suggest read priority values for the ROM scalable stream are droppable frames like it was disgusting in in Prague and that\u0027s why we submitted the draft so it will allow the middle box to discard part of or all the discardable frame is marked by the encoder its provide more option for changing the bitrate and congestion so if for example if I have contiguous a number of frames that are droppable I can mark the ones that are better to be dropped off so if I don\u0027t need to drop all of them then what is the preference which one too broad to drop it provides more flexibility in adapting different bit rates accordingly basically you can try to do some heuristic without that but it\u0027s if the if they are are to reorder the the packet so that that provides better granularity for that so that\u0027s the first usage the other one is to allow differentiation between reference and non-reference be frame so if I drop first the non reference frame then I can drop the reference one two words again it\u0027s more granularity in what I what I\u0027m dropping and the last one is we can also have key frames can also be dropped because the closer they are to the next to the end of the GOP they can there are less important than the one in the beginning because it assumed you\u0027ll have a full frame that you can resynchronize so in the worst case I mean if you you want to go this way you can have this is the priority that\u0027s "
  },
  {
    "startTime": "00:58:00",
    "text": "the last to drop okay so so these are the cases that we we analyze and try and try to bring forward next slide so what we suggesting is to add two beats from the four must be zero beats when zero zero is the highest drop priority and one one is the lowest drop priority between highest authorities the ones that you you you can draw and that\u0027s that means that if you don\u0027t support this extension then that\u0027s what will happen basically okay so we talked about non-scalable once and there is the reason for that I mean it\u0027s mostly we figure out and the the use case that we had was mostly when you\u0027re coming to the to Wi-Fi where you have I mean the situation there is that you have to drop because you know at the home when you\u0027re trying to watch a lot of videos at the same time you have to drop and and we see I mean that\u0027s not and that\u0027s maybe not be scalable videos okay so in this case that\u0027s where the use case what we had on that yeah it\u0027s not encoded the scalable one it\u0027s an unscalable okay at least for the at least for the ppb it\u0027s not really scalable in the case for the baby but also it\u0027s also for the case of I think the only case that can say it scalable is the reference and non reference be frame also if you have a contiguous be frames and you want to mark which one you can drop then again it\u0027s not really scalability it\u0027s mostly it can be any other decision that you can make yes it\u0027s a Content one mercenary I think when we discussed this before you know frame markings goal was to make sure that something is decodable so if your middle box you know that you\u0027re forwarding a decodable stream without error whereas this is more useful for even something which may not be decodable artifact free even you\u0027re trying to minimize the artifact you could use this to minimize the amount of artifact but you you don\u0027t you don\u0027t guarantee that there\u0027s no artifacts you you\u0027re allowing some level of artifact but you\u0027re trying to minimize them by having more granular priority something whereas the other frame working draft is talking about artifact free video what can you do to guarantee that you have a full decodable fully renderable artifact free experience to all the receivers and that\u0027s when I read your presentation now it\u0027s a bit different than what they and they stood what you want because the presentation was talking and you\u0027re right the presentation that you presented was disgusting mostly the case "
  },
  {
    "startTime": "01:01:01",
    "text": "for how to which one to pass not wha to discard okay but my understanding of the document and from the document it\u0027s not only because the also the item says it\u0027s also what you can discard and this carding doesn\u0027t necessarily means that it would be a without any effects just murder if to clarify the document that the other frame working draft does say the discard with the definition of the describe it is is it is discardable and still allows a fully decodable media experience that\u0027s the definition the discard bit you can only set it if something is truly discardable and not impacting decoding of other frames so you could not set that for something that would degrade the you know cause artifacts in the stream so maybe let me know if there\u0027s something in there that says that suggests otherwise because we need to clean that up the intent is that you can only set that bit if you know that this will not impact the rest of the stream of course there is because for the non-scalable case I mean if you have discardable beats I mean it\u0027s always things that will disrupt some out there no so even in a non scalable stream you can just you know every now and then just as have something as non-reference right you have a flat tempo hierarchy no special skill but it just every job if you\u0027ve got the frame in an unscalable stream then you affect the decodability no I\u0027m saying doesn\u0027t matter I\u0027m saying at the encoding I\u0027m saying that the encoding of the frame you actually made this a discardable frame and odor you coded it as a non reference frame so it\u0027s not the middle box dropping it in this card late it\u0027s the encoder choosing to encode a discardable frame okay so we I think what dimension it says okay you can drop more than that if you must even if you have a bit couldn\u0027t just a big congestion inside and that\u0027s why I said it\u0027s typically in a Wi-Fi at the home network basically that you run into this case okay as I said I mean you could go to the next slide I mean the only thing is that we don\u0027t bind it to if we can finish first use the document and then go and work on that but we really would like to have these these options yes I mean that\u0027s that\u0027s what we are doing because we are trying to use it inside in in the solution for our Wi-Fi Wi-Fi residential gateways and stuff like that way we have a problem with with the is going that\u0027s mostly for for of course for the for streaming video not for most have this negotiated it\u0027s a different different parameter than the regular frame marking how\u0027s it negotiated is a different header extension in the regular frame marking no it\u0027s the same it\u0027s just I think it\u0027s it\u0027s adding to its using two of the four bits but if you don\u0027t support it there will be 0 0 which is the ones that are really you can you can drop is it parameters on the current header extension yeah how do you have seen STP is it\u0027s this current I "
  },
  {
    "startTime": "01:04:02",
    "text": "mean I don\u0027t got any negotiation it\u0027s like it\u0027s a no I don\u0027t need if it\u0027s supported MLC priorities if I don\u0027t see priority it would be zero zero because otherwise if you\u0027re southern no no no zero zero is the one to to drop the tides priority okay so that\u0027s why I said it\u0027s the same thing as before I don\u0027t change it this way that\u0027s what I meant by that so I\u0027ve said there\u0027s no problem with with support or not because if you don\u0027t support it you don\u0027t you ignore these bits okay if you\u0027ve supp if I\u0027m if there are if you support it and so in if you if you support it and you don\u0027t see them then you see zero zero only zero zeros and that\u0027s what what what means it\u0027s the highest priority for dropping this I said there\u0027s no problem with backpack Roberto iterability with the current definition except that Milligan except that II somebody that didn\u0027t implement this may think that it\u0027s a violation of the frame marking must be zero and I would want to drop the big and oh yeah let me go check it actually does say that okay so they be in inferring by that this big non zero then you support it yeah I don\u0027t let me go says about they see the problems into a problem okay so depending our first I don\u0027t think you need a parameter but independently of that there\u0027s an old idea this is stuff that actually when when we did the h.264 now reference IDC thing those two bits in the in the nail unit header for h.264 which also mirrored in the payload format those were initially in the initial proposals were meant as encoders selectable and not and not specifically nailed to the nail unit I base it was later done in that committee the reason why they did that was because people argued whether that\u0027s a good argument or a bad argument I don\u0027t know but people argued that it is very hard to put a concrete definition on those on those relative priorities so for example an encoder from one manufacturer may decide to mark everything as as high priority "
  },
  {
    "startTime": "01:07:04",
    "text": "or it\u0027s essential for decoding which would lead to appears in our decrease of 0.01 DB or greater whereas another encoder manufacturer may decide well you know we want to be able to discard 50% of the packets at least so we are assigning those values such that at least half of the packets have values like you know in in the the two and three range of those two bits so that was an interoperability in in this scenario would be a pain in the neck unless you come up with the definition which was even doing it for h.264 was deemed impossible so have you thought about that yes and I think I think it\u0027s not it\u0027s not that relevant because from the strain itself I mean it\u0027s just that if I want to be able to decide from the stream which one to drop its dah which one to drop in which not to draw then I go accordingly okay I don\u0027t care I don\u0027t care how it\u0027s related to others if I seen in this stream these are these are the first I should drop because if I want and mostly because if I provide and mostly because I a provide more options to not to drop to have all of them to be dropped if I if I descend to make decision if I want to drop just but because I need to reduce the bandwidth less than what is the number of frames that need to be dropped so so the algorithm is essentially you decide or your congestion control decides no not your congestion control your this is a receiver thing yeah so it\u0027s not congestion control something else it\u0027s like you don\u0027t have the city\u0027s node or something like that your receiver it\u0027s it\u0027s a it\u0027s basically the middle box that passes our little you know so the middle parks has decided at this point I need to drop something then it looks through its queue which is hopefully mercifully short otherwise we have too much delay right and if it finds something that\u0027s droppable then it picks one of those with the lowers of these indices that\u0027s the idea right yeah yeah okay I\u0027m not particularly interested in not particularly uninterested the the the cost of this is taking two bits away "
  },
  {
    "startTime": "01:10:04",
    "text": "there\u0027s this there\u0027s no harm in this proposal except that it takes two bits or four reserved bits away is there anything on the horizon where we need two other bits understand yeah but yeah because you need to bite that\u0027s all right honestly I think the primary cost of this is it\u0027s the iris that doing this in the context the frame marking because I thought it would be difficult to actually specify what what cinders should populate this with and so I didn\u0027t want to hold up frame marking for a potentially open-ended discussion about how to how to actually signal these bits properly in the absence of specifying how to signal them I feel it\u0027s a little impotent so if the document doesn\u0027t say anything about what you actually do with these with these bits then it\u0027s a little you know so just to clarify you want to get more information about how this how how does bits are marked in in which codec that we tested in right because like for example the frame marking bits are very deterministic so it\u0027s clear how a sender must send them there\u0027s no ambiguity so we don\u0027t need a lot of rules and and and in discussion about how they should be marked this is something where it\u0027s more subjective that there are you know different ways that you know senders may choose to mark them so you need to have some guidance about what you should do and that\u0027s what I wanted to avoid in frame marking and if they didn\u0027t have that information in this document I\u0027m not sure if if an implementer could actually make good use of it so the information that we have about the B frame and the P frame there\u0027s it\u0027s them in which one a to mark I and which one to mark lower priority for B Prime and B frames which drop I mean need to drop but it\u0027s for this specific stream I mean that\u0027s all I mean it\u0027s not for it doesn\u0027t affect any other streams there\u0027s no it\u0027s just for this stream I mean how you decide which one to mark and which one discarded but that\u0027s what you say you\u0027re telling the middle box that these are for you are less important and this one are more important so you could first drop the the one that\u0027s are less important that\u0027s all so again so my net feedback was that I don\u0027t have any objection to taking your honor so as a workgroup item but I think it would need more work to get clarity about what how a sender would actually or he thinks probably I will put go ahead some more text on that and again I mean we can start working on it after we finished with frame work I don\u0027t want to hold free much it was not they was not our intention at all okay come on back and so again I have no "
  },
  {
    "startTime": "01:13:06",
    "text": "objections this work carrying on but I do agree with with MU that we need to specify how the marking is done in order for metal boxes to do anything meaningful with it okay but but it you know if it\u0027s one percent of packets marks or if it\u0027s 75 percent packets marked the middle box treats them very differently in writing this very poor visibility into the streaming community so I think sounds like at this point you know we\u0027re going to probably delay taking an article framework the proffer is done but if Ronnie wants to keep updating it that\u0027s great okay all right I\u0027m pretty sure we have the latest version of your slides so if you\u0027ve downloaded the slides Colin uploaded a new version of the slides during the meeting so big because I\u0027m really organized and had these done in plenty of time okay I kept improving them that\u0027s right all right so I\u0027m still calling Perkins I want to talk about quick and how we multiplex quick are we finish we\u0027re going to run over into the council okay good all right so quick if you haven\u0027t been paying attention is a new transport protocol it layers above UDP and is initially intended to replace TCP in the HTTP TCP stack so there are there browsers and servers out there which are running HTTP over quick over a UDP and quick may or may not be a good thing lots of people have opinions on that but it is certainly something which is happening and becoming popular should we see the initial focus of quick is on plant server HTTP right they say it\u0027s defined as a client-server protocol in the long run it should become a general-purpose protocol right a general-purpose transfer protocol and will be useful for the same sort of things which TCP is useful for but hopefully offering some improved performance in a bunch of cases it would that there are two things which I think it would be useful to do with quick it will be useful to run quick in a peer-to-peer manner in the long term so it\u0027s not just for interacting with web servers and we can use it for other things that need peer-to-peer transport and I think it would also be useful to "
  },
  {
    "startTime": "01:16:07",
    "text": "be able to coexist with quick and WebRTC traffic on the same UDP pods so thinking through those both with a little more I mean the first goal I mean initially quick is being specified as a client-server protocol your HTTP over quick if it\u0027s going to be general-purpose it\u0027s going to end up being used in a peer-to-peer way if it\u0027s a being used in a peer-to-peer way it will need to work through nets which means that we need a net reversal scheme the way we do not traversal in the ITF is using ice which means you have some sort of signaling channel and you have stun running on the same port as as the the data to to open them at net bindings and keep the bindings alive and all this sort of thing now signaling we can do later right we\u0027re clearly given need to define some signaling but that\u0027s not something we need to worry about right now but in order to do this we need to be able to run stun on the same port as quick right and they must run on the same the same UDP port I\u0027ve always stun doesn\u0027t work it has to go on the same part of the data in order to do that we must be able to demultiplex ton packets and quick packets running on the same port or we must reinvent stun as part of quick and stun has been painful enough as it is and redoing all that work in the context of quic is not my idea of fun maybe other people like the job security but I think we want to you know we don\u0027t we need to find a way of multiplexing stun and quick packets in addition WebRTC starting to get widely deployed it\u0027s likely that we will have web servers running HTTP over quick and rather than HTTP over TCP and we might want to run WebRTC from those service to the browser so you can make calls to a a server cooler co-located so it\u0027s a WebRTC endpoint co-located with the server and you know yes in principle we could run that media over quick you know RTP inside quick and so on in principle we could do the key exchange using quick and then just use that to key the SRTP because there\u0027s a D TLS handshake runs and so quick but in the short term that\u0027s a lot of specification work so if we want that use case we\u0027d want to be able to demultiplex the the DTLS and the SRTP packets from the quick packets on the same port in addition there are people talking about using quick as a replacement for the WebRTC data channel in peer-to-peer use cases which would use the stun stuff and also we need to do all the rest of the D multiplexing and demultiplexing with the media and so on and both of these cases it would be useful to be able to do multiplex quick packets and the packets being sent by WebRTC so stun and turn and DTLS and SRTP and so on so of those two I mean to "
  },
  {
    "startTime": "01:19:10",
    "text": "my mind I think the essential one is that we did be able to do multiplex stun and quick so we can run quick in the peer-to-peer way while we\u0027re doing that it would seem useful to be able to if if we can to be able to also support the maxing all all the other protocols who use for WebRTC so how does WebRTC currently do the d-max well currently if you have a WebRTC endpoint when the packet arrives you look at the first byte of the packet and if the first byte isn\u0027t in the range zero to free you forward it to your stun implementation if it\u0027s sixteen to nineteen and you\u0027re running ZRTP you run it to your Zed ITP implementation if it\u0027s 2263 it goes to your DTLS 64 to 79 it\u0027s turn 128 to 191 it\u0027s a TP or a TCP you forward it to the appropriate bit of your stack based on the first bytes of the packets and yes this is a clutch it\u0027s a horrible clutch it happens to work by luck we\u0027ve kind of semi formalized it in RFC 79-83 but clearly it\u0027s a clutch there\u0027s not really if I remember right a good extensibility strategy for this in 79-83 I don\u0027t believe there\u0027s an eye on ax registration policy for how we we add new things in here it\u0027s a mess which happens to work because we got lucky if I am remembering right and Magnus will probably clarify a lot of this was done because things happen to work out I think if you\u0027re running a stun server then you\u0027ll see stun and turn packets on that port but probably not the others if you\u0027re running a web RTC endpoint you see stun and DTLS and a DHCP but probably not the others and so on so we didn\u0027t necessarily need all of these combinations for every endpoint but things happen to work out that way and it\u0027s all been defined such that and documented so it\u0027s clear how it all works so how does quick what fits with all this well there are two types of packets in quick long header packets and short header packets a quick long header packet is used for the initial or negotiation the the initial handshake version negotiation that sort of thing and then it switches to short head of packets once the connections going long had a packets the first bit of the packet is set to one that\u0027s then followed by a 7-bit type field a connection ID packet numbers versions and the payload and so currently packet types one through six are defined right and was there a connection idea but ID gives you a sets of values for the first bytes of the packet which ranged between 129 and 134 for long header packets and that conflicts with the range of RTP and rtcp are using if you look at the first "
  },
  {
    "startTime": "01:22:12",
    "text": "bite of an RTP are a TCP packet quick short header packets the first bit is 0 was then a bit to indicate whether there\u0027s a connection ID present a bit called key phase which is to do if that the keying and the security Stefan I don\u0027t quite understand and a packet type field and currently packet types 1 through 3 are defined it\u0027s followed by an optional connection I\u0027d be a packet number on the payload but again we only really care about the first byte give them those values when you look at the you know whether the connection idea is there or not with the key phases there or not this gives short header packets with where the initial bite will fits in the range of either 1 through 3 33 35 65 367 or 97 399 and those conflict with stun and DTLS and tug if you try to multiplex them all so yeah as it is these just do not go together with a TP and stun turn so what do we want to do if we want to run these together how can we we address this problem well in that the quick working group on Tuesday Martin Thompson talked about this he walked through these four options option 1 just rely on the crypto all of these packets are authenticated in some way so you can just run you know you can check the signature of it all the packets you can try and authenticate them and you do whichever works and it\u0027s horrible it\u0027s probably not the most efficient way of doing this but it would work as a fallback that no one likes it and I can see most shaking his head but it would work option 2 yes yeah I think that\u0027s the important thing if we have something which is probabilistic you can fall back to checking with signatures in the worst case and we don\u0027t want to do it but we could option 2 was rearrange the quick packet formats make it so that all of the quick packets though if the top two bits set to one and that avoids the collisions entirely puts them into a space that\u0027s not used by anything else but the quick folks don\u0027t like that they want to be able to use all of those bits potentially but it\u0027s the possibility option free it was to add a single locked octet shim to the start of quick packets when used peer-to-peer you put a single byte at the front which with a non conflicting value and say this is you know this byte will always be present when quic is running theater pair which in practice would probably turn into this byte is always present if you\u0027re using quick otherwise you asked if I and it stops working in some cases but okay so we we had to add one extra bytes and demultiplex an option for was just try and avoid the conflicts you "
  },
  {
    "startTime": "01:25:12",
    "text": "we don\u0027t really care about the multiplexing with turn because that\u0027s only you\u0027re only gonna see that if you\u0027re talking to a stun server any obstinate answer anyway and you\u0027re not gonna be running quick to a turn server because why would you we could replace the D to the D TLS with the quick King we do the security handshaking quick and then just export the key so we don\u0027t need to run DTLS we only use long packets during the handshake so the fact that they can flick with our TP doesn\u0027t matter because by the time you\u0027ve done the handshake you can do that and then you can switch to ICP you never send both at the same time and yeah okay mostly Fitz if you squint a bit and pay attention to the sequencing and clearly none of these are ideal and I don\u0027t think anyone was desperately happy with any of these solutions in quick there\u0027s also been a bit of an offline discussion since then and Martin\u0027s of hinted at this in in the quick group and we\u0027ve been flushing it out a bit by by email which is it it seems to be possible to do some renumber the the quick packets and avoid a lot of these collisions so if we take a quick packet and we look at the long head of packets and currently the packet types which it defined range from one through six and I think it\u0027s like one is the version negotiation and the rest various other features in the thing and an packet at one is special at that so sort of mandated everything must understand this and the rest is specific specific to particular quick versions so the suggestion here is that we\u0027ve renumber these packet types so version negotiation changes from being packet side 1/2 packet type 7f and all the rest just drop down following that so it so we number from the top down reveling we\u0027ve been going bottom up and that doesn\u0027t do anything too quick right it\u0027s a trivial renumber of the packet types isn\u0027t changing if the semantics doesn\u0027t change anything else than that but it changes where they fit into that space in the first objects similarly further connection ID field in the short packets rather than having a one to indicate connection ID present we can flip it around so zero means the connection ID as present and one means it\u0027s absent which is perhaps the opposite of what you\u0027d expect but there\u0027s no reason why we couldn\u0027t define it that way and that flips those into packet ranges that also don\u0027t conflict and again it\u0027s a trivial change to quick it doesn\u0027t change any of the semantics it\u0027s just a slightly different encoding of the bits so the suggestion as we do that we give some guidance about greasing and debugging and so on which I\u0027ll talk a little bit about in a second but that should avoid a lot of these conflicts so if we do this the quick long header packets then fit in the range starting it by values 255 down to 250 for the currently specified quick "
  },
  {
    "startTime": "01:28:13",
    "text": "packet types so they avoid conflicts with everything else that we might want to multiplex quick short head of packets depending exactly which bits are set to fit somewhere in the range of 64 to 127 mostly only a small portion of that range that conflicts with turn but it seems to me that this doesn\u0027t seem too problematic - just so you have an assumption that it wasn\u0027t it not need the connection ID for peer to peer yes you didn\u0027t state that but I think it\u0027s a very important I don\u0027t think it actually it doesn\u0027t affect the ring yes I picked the full range yeah well I mean if you actually need the connection ID you would fold it into the lower 64 bits again for your short packet cell yes yes sure we\u0027re assuming we don\u0027t need the connection ID here new tamiya I think there\u0027s actually no collision with the turn channel because in case you run a turn channel you know that everything is going to come through the channel first you have to give it to your turn client first and it will unpack it and then you will give it to then you do max it further yes I mean the conflict would be if you wanted to run for example server running quick on the same port as the turn server and there\u0027s another line perspective yeah and I don\u0027t see why anyone would want to do that anyway but yeah not from the client perspective so assuming that we don\u0027t use channels for the quick short header packets and I don\u0027t think we need to keep the no connection IDs for the quick short had a packet so in the peer-to-peer case and it got the impression that we didn\u0027t need to the quick people didn\u0027t think they needed to assuming we don\u0027t worry too much about turn then we seem to be ok said that the quick people might want to use more of this space in the future so we might need to give some guidance about what happens if that\u0027s the case and the quick people might just decide they want to expand the range of packet types they might want to redefine the quick header in some future version of quick to use more packet types or they might just want to grease the space and you send other values of the type field just to make sure it\u0027s still possible to send them mostly Mosin area so that looks through like you\u0027re basically defining quick as RTP version 3 in this format that precludes apt from defining RVT I mean one way of looking at this is that we\u0027re updating RFC 79-83 to say ok quick is fitting in these values and those are the values quick we\u0027ll use the multi multiplex and ok that I suspect probably works reasonably well from our "
  },
  {
    "startTime": "01:31:14",
    "text": "point of view but I think the quick people would would dislike it I think the other way of looking at it is saying this is some guidance for quick if you\u0027re using quick version 1 and you wish to D multiplex with these other protocols then when you\u0027re doing the greasing or whatever else you\u0027re doing avoid these values and if you\u0027re not wanting to do multiplex just go ahead and do whatever you like and it\u0027s a quick specific thing and we just give some guidance for the quick people or as you say yeah we\u0027re defining it as IP version free but I think that\u0027s not going to go down popularly yeah and then the other the other question was I this is trying to multiplex Native RTP with quick but I thought there was also work on a RTP encapsulation using quick so we want to allow both options and you can multiplex both on the same port so from my point of view the essential thing here is multiplexing stun and quick yes I mean that there is work on RTP in quick there\u0027s also work there\u0027s also been talk of doing of getting rid of the DTLS because you can do the handshake in and just specify how to extract the keys from the quick handshake and use that for keying stuff those are long-term things I mean you\u0027re specifying RTP ever quick is not gonna be something that happens you know next week it\u0027s going to take a couple years I suspect is quite a big change it\u0027s quite different transports so I think in in the short term it would be useful to be able to do multiplex it in the long in the long run I expect RTP will end up running over quick and it would just be the stun that we care about my concern is that if we had so many different competing options not necessarily conflicting but the the suppose you support supported them all suppose the quick folks actually work on on better you know NAT traversal then then you know then what we do in AR T so then quick has native native naturale traversal native TLS and and native you know media carriage bindings maybe a quick RTP encapsulation or something like that then we also have this totally parallel universe of of AVT transport of of that and we support both and you can multiplex both on the same port seems a little weak we should know more force prescriptive I think then allowing all those options so we are going to have a parallel universe of RTP over UDP and potentially RTP ever quick whatever we do and they are going to be do multiplex or whatever we do and we can specify how that happens to make it easy or we can just assume that it might happen by accident and this I don\u0027t think this is saying you have to support both it\u0027s saying if you wish to support them if you wish to be able the multiplex um if you arrange the if step back if we make this change too quick then it becomes possible to D multiplex them if you care to do it not that you have to do both and you have to be able to be multiplex them hello Alice "
  },
  {
    "startTime": "01:34:16",
    "text": "John strictly speaking - where - looking at the world and when the quick people are happy the quick people will have the ranges and stick to them then the important thing about seven nine a tree is that it documents in one place all the different happy people who happen to be non-conflicting at this at this time and so I think we need to update 7-9 83 not because of quick but because of the next guy who comes along and wants to multiplex something yeah I mean I do so the question is for whether we update seven nine eight three I think is a difficult one I mean from the point of view of this group I think it clearly would make sense to be able to say quick is using these ranges from that first bite and if we you if you wish to be happy and do multiplex then that\u0027s great I think the problem is the quick folks actually want to claim all of that first bite and they happen to only be using a subset of those values now but they want the option of using the rest of them and they want the option of greasing that bite so I think from a quick point of view what we all have is we happen not to conflict with the packet types defined now but a quick implementation will probably grease it and use the whole of that the rest of that bite but could be could be instructed not to do so if it wishes to run with these other protocols on the same pot because that particular implementation wishes to coexist so I suspect the question of whether we we update seven nine eight three is is actually a much more complicated one than the question of whether we rearrange the bits so the current version of quick happens to coexist if you sooo coming back to the use cases and mainly especially peer-to-peer is quick I understand I think the technical use case which is to have the quick server behind its own mat but could use the use cases the quick doesn\u0027t is that you can run quick in PHP why rather than clients other way yes but do you have more details about the use cases enterprise or residential because I mean so the idea is that quick becomes a general-purpose transport so anything you might want to run peer-to-peer you could run over quick okay understood thank you and you may or may not choose to do so but we want to give the option of doing that and TCP currently doesn\u0027t work well in that case for example and it might be useful to have a reliable transport that does Adam wrote as an individual I\u0027m glad that you concluded by saying you can run anything you want over quick because I think it\u0027s kind of key to why this seems like it\u0027s doing a whole lot of work that isn\u0027t really necessary Minh if we can put these protocols on "
  },
  {
    "startTime": "01:37:17",
    "text": "top of quick then it seems like the problem is reduced to how do we do stun and quick at the same time we\u0027re not to worry about the rest of this and that\u0027s a problem I think that the quick working group can probably solve in consultation with people who know stun as opposed to this which is like terrifyingly complex and as you point out you\u0027re going to end up with issues of you know constricting the space or having features that suddenly become unavailable here in a peer-to-peer mode this just is giving me a whole lot of heartburn I think they actually end up being the same solution which is why I\u0027m talking about it because I think the quick I think in order to make quick multi-play nicely with the rest you end up doing something that looks a lot like this anyway but you do it inside quick and I mean they\u0027re going to have an extension point for this right there is as my understanding as a way to indicate that what I\u0027m doing right now is HTTP and you can have a pack of the RTP you know pack they\u0027re gonna be you know whatever it is you\u0027re trying to slam inside here and that\u0027s that\u0027s architectural II designed as opposed to something we kind of noticed happened and then tried to sort of squeeze in around the edges when we realized that well really want to do doesn\u0027t actually fit but maybe it with Amer enough movies bits around it will I mean I don\u0027t think that works I think that means we end up with quick only working client-server because it are ossified around a quick header scheme that doesn\u0027t then work with things like stun and we end up having to reinvent the whole stunting as a quick extension now I think doing figuring out how to make stun work for quick is reasonable yes right doing it so that we fit in with all of these other things I think is crazy pants I think the amount of changes to make stun and quick coexist and the amount of changes to make stun quick and everything else coexist it\u0027s it\u0027s one trivial change difference between them now because stun takes like three bites out of this space I mean what we\u0027re doing to quick then we also get coexistence with everything else right but again what you\u0027re doing is you\u0027re giving up features inside quick and you\u0027re you\u0027re saying we can\u0027t do channels right and you\u0027re saying that we can\u0027t do whatever types happen there is "
  },
  {
    "startTime": "01:40:17",
    "text": "no semantic change this means zero means it\u0027s exist in one doesn\u0027t so try to flip it at the value that\u0027s all that\u0027s the only thing because there are some things you don\u0027t need sorry so for the first case does not change there\u0027s no change in quickly just saying instead of using for the packet you have to start from one to go from 7f down okay of course but and they ran out only if they they\u0027ll need six to one that the second be 364 will be one will go from 1 to 0 that\u0027s it so drop so yes that the quick people will define new packet types if they define new packet types and start using them then they will not be able to demultiplex that along with stun and turn with turn and ITP and all these other things okay sure but but we don\u0027t regard I don\u0027t believe that\u0027s a problem right for quick version 1 they\u0027re not going to define new packet types and it\u0027s quick version 1 we care about for multiplexing with RTP because by the time there\u0027s more versions of quick RTP I expect we\u0027ll be running with inside quick and they\u0027re never going to get down low enough they\u0027re never can define enough packet types that it\u0027s starts conflicting with stun I think first of all Thursday in variant first of all they\u0027ll have the invariant part which says you cannot change a lot of the information because in future version because you have to have the the the version at the same place in future versions ok the version which is under the 32 just be before the payload in the header the header structure will not change below the version numbers so this start will always be the same so as for the top part you see we have we have the top by starting with 1 always a zero ok and all the rest are you can do whatever you want now for the first bite the only limitation that\u0027s now being added is that what we\u0027re definitely saying that for the long header we\u0027ll start with 1 1 and not with 1 okay that\u0027s the limitation ok that\u0027s so reduce the number of types that you can add message type for the Indy head for the long header to 64 in 64 in 63 basically because that\u0027s zero instead of 127 you\u0027re right having running for quick long header packets they are always the most flexible web stuff because they always start with a one bit and stun uses packets to zero yes just and is not possible no you let me finish running so that the long header packets stun we have no problem with that\u0027s always going to be the most flexible by renumber fields we happen to gain coexistence with RTP and all the "
  },
  {
    "startTime": "01:43:17",
    "text": "other things for quick version one and you may or may not think that\u0027s important but for stun there\u0027s no problem for the short header packets if we flip the connection ID bits then we also get coexistence with stun and that\u0027s important okay and if we don\u0027t then it duck then they conflict with stun packets sure and like I said for stun I can sort of see this like but when we start trying to go further and like we want to have quick an RTP as peers on the same port without any anything other than you know this scheme is where it starts getting really dicey and from my point of view the stun bit is the essential one the if we happen to flip the rest and get the rest okay I regard that as a win but I don\u0027t care that much okay other people may have different opinions yeah I cared about I mean because I don\u0027t see I mean we are working on RTP in quick but we know it will take a long time because we have the log a lot of things that we need quick to change in order it for it to work okay so we may still see RTP and quick running in the same channel in the cases that you described so but at least for for the way that it\u0027s currently described then if we have starting with one one in the in the quick long header then we don\u0027t have the problem of course you don\u0027t have the problem for the short header for that Newtonian yeah I think this comes down to the question of do we do we need to support a transitional period I guess of like where you can do for example for WebRTC like click for the data channel but still use RTP at the same time right like or if we go like later on if everything goes over quick then we don\u0027t no longer need to to worry about that but the other question is like is quick now only the first one of more protocols it comes out this path so do we need like do we need to weigh like I don\u0027t know registry or signaling like some kind of solution to like basically tell me like oh this is this is where look up look up basically how to do max things coming on in on that beauty pport yeah I mean ideally there be some sort of pause identifier and a registry and this sort of thing ideally this would be running over IP and this wouldn\u0027t be an issue right so all this from and using the calculator that I used to estimate that WebRTC would take two years I estimate that we will have HTTP one one done by the end of 2018 we might have quick key "
  },
  {
    "startTime": "01:46:24",
    "text": "version 2 with support for RTP rolled out or specified at the end of 2019 absolutely and so on and so forth so it will be a while well for the case of quick instead of a CTP for the data channel we have running code today we\u0027d like to have a spec out for it and we\u0027d like to deploy it in production to see whether it works well and in order to do that and not wait for quick version - we need to do exactly this demultiplexing so the whole the whole DMX thing is hack it\u0027s somewhere between a horrible hacking and disgusting hack but it\u0027s our hack so can I just I think the nice thing about this is that semantically it doesn\u0027t change anything in quick yeah if you want to do marks then things get interesting but but if you don\u0027t then it\u0027s just a regular quick we just remembered some of the fields MN Campbell is an individual and a couple things that went by in the line before I got up here that I\u0027m not sure I interpreted quickly so my point might be moot but when we start talking about the do much thing of things other than stun RTP or whatever and it might be nice and we do it if we\u0027re doing it cuz it might be nice we might use it someday I would rather give people guidance to not do it if we unless we need it right that\u0027s not what ports are for that\u0027s not what DMX is for right we do but the d-max we have now because we have to but if there\u0027s not a good reason to encourage people to try to share these - all these things in the same port let\u0027s not encourage it so my name is Westland um I think T we do need the RTP avoidance what to say because as I\u0027ve been I fully expected we\u0027ll see people in WebRTC space deploying as Harold says they were already running code they will be board and Google doing that so in short term we\u0027re short is probably the next five to ten years yeah yes exactly yeah I actually been thinking about this connection assumption it\u0027s probably fine assuming that you actually have all the bits so you can lock on UDP IP addresses UDP ports and not run multiple "
  },
  {
    "startTime": "01:49:25",
    "text": "simultaneous connections to the same pier which I guess is actually what the limitation comes down to yes it means you\u0027re going to only run one quick connection onto the same yeah on the same UDP ports yeah but I mean it\u0027s it\u0027s I think that\u0027s not an issue yeah yeah I mean I was thinking about some of these middle box etc is probably has one starts finding port and then you need to kind of bind up these so you use the filter after you down the ice handshakes et cetera you need to move on so I don\u0027t know how much how clutch the implementation stage of actually going from fully open exceptional some and then binding it down to I put a call about remote address so but I think from the quick point of view I think it\u0027s not an issue yeah you\u0027re running one but anyway are you considering that we should run the short type field from high levels to lower also I wasn\u0027t considering that but I would ensure that\u0027s in the case you actually need a connection ID you would still get to those packet types that collides with stun would be coming last in the assignment order or even the short header is much different from the long had the whole feel different the type in the law shorter they\u0027re just just to mark out what is the if the packet number is eight forty it still define them going downwards though but you have also the K bit there and we\u0027re also considering adding more flex there it\u0027s a consideration for when doing that so you ensure that in those cases you those bits are zero the packet type would be distinguished the factor that would keep it out of range of the 0 to 3 valued at stun uses that\u0027s one point just that the this 4 but you have to define what is the type length currently and I think that\u0027s what we will have a problem with because because currently the type is 5 beats but I think that the next steps I think for the quick side what I proposed to do is submit a pull request to quick spec that makes those two changes and I think that will then be discussed in the quick group and they will see whether to take it up or not and talking with Martin Thompson who is when the editors the quick spec he seems amenable to that but obviously they\u0027re the group would need consensus that this was the right thing to do from the AVT point of view or "
  },
  {
    "startTime": "01:52:27",
    "text": "possibly the transport area point of view I don\u0027t know where what the right home for that is we should consider whether we need to update 79-83 or whether this is something quick specific or who knows what we do yes and the there are bigger transport issues here so it might make sense to do that in transport working group is vo who knows I don\u0027t know but in the short term does the area director think we should just would that be this groups today we need a 17 I need to treat this it needs its own area I think know the IAB does the night Alan Campbell I don\u0027t have an answer for that day I would lean towards if all we\u0027re doing is simply changing 79-83 that\u0027s probably here but there are implications as I said it pretty far wide so I think some conversations need to happen behind the scenes to give a thorough guidance on that I think we can assume for now that if the work is done this is probably the place it would be done but that if is still a pretty big if I would suggest we probably need some IETF white guidance on whether we are encouraging multiplexing of things onto the same portal yes that\u0027s kind of what how we do it if we are encouraging that but I think that\u0027s a separable issue then do we just you know ask the quick group to renumber their bits for now this word actually belongs to X our blocks and we can\u0027t make any consensus here but we wanted to discuss and socialize this to get some feedback on whether people will be interested in pursuing it when it affects our blocking for means together okay good morning I\u0027m Marvin Scott eager for people who don\u0027t me actually my name is Ching Wu and I represent these topics and I\u0027ll share introduce that it is exile rock Walker so next so in this "
  },
  {
    "startTime": "01:55:27",
    "text": "chapter we introduced a new metric we call the effective loss index and we also define the except block report for meit and to cover this new magic so this new metal will be used to Mayor the effective the packet loss actually we compare with two existing of see why is obviously 75099 is 5725 and we compare the difference is different from the 5725 actually this chapter that doesn\u0027t need to report a packet by packet actually so we can save this packet by packet the report block overhead and given from the obviously seventy seventy five zero nine actually we\u0027re more focused on to provide static resolves the total package loss change so we can actually predict the the the polka dots change over the time next so what what is the effective loss in taxes this is a new into metric we introduced here we actually we see see this is actually a simple metric to measure the effectiveness of packet loss actually in some other case that we can actually measure the the the the first degree or the packet loss when we apply the packet loss recovery mechanism and we give examples of suppose we receive freedom attend at he 1010 effective loss index used through the rtcp XR block and we can actually sort up the the fitted 5% RDB receiver who on the Performa so we can actually to make a further action to improve these to provide some treatment to impose a corollary experience next so how do we calculate these kind of effective loss index so we make a some machine so we have RTP receiver RTP and opponent they can receive stream the RTP data packets and we can for the RTP and receiver they can actually place the in the middle box or place in an host and we can send a time window they can actually to apply the packet of a colossus repair max chunk by chunk Oh actually the channel size can be the time window size and so you so for each chunks if there\u0027s some unrecovered packet loss anyway we are in actually this kind of packet loss bootcamp repair Maxim is infective so we introduced a formula equation actually "
  },
  {
    "startTime": "01:58:28",
    "text": "for example we actually receive we can can measure the total package with packet loss repair maximum applied and we can compare these total packet loss actually this is more like the pre repair packet loss this is something actually has already be defining of say 3611 but it\u0027s actually is the follow wrong lansing encoding for mater actually so we can use these prepare the packet loss that we compare with ease the loss a effective loss suresh ago that we said actually and we can actually gain as a effect will also factors so we so it\u0027s about the ways received can channel so we can actually average it is effective loss factor and and also multiplied ten thousand so we can translate as a percentage into the integrity okay gave the more more either way to see see the it\u0027s kind of effective loss next so this is simply was almost suppose we should receive nine packet actually we can actually program them into straight chunks each chunks we have three pack a day with different a second\u0027s number one two three and four five six seven so in each chunks are supposed we we lost two pack ADA but I would settle stretch coded for example one so it actually is the greater than the threshold we actually said the effectual loss factor as as one if actually less than the threshold where said the factor in to zero so we can actually Kaku this kind effective loss index yeah next so this is a new block accept lockup for Maeda we proposed actually we the for the example header we actually use the same hideaway define in obviously as 3611 and in addition we introduce the new metrics and it is 68 new metrics the parameter and we plus we have six bit padding yeah next so to calculate these effect loss index we need to calculate it to to to Pamina we need to actually need to configure with number threshold and the the chunk size or patch aside we use a different different term may be a bit confusing but we think maybe channel is more better so we can use SBP to signal these two parameter and and actually this is the the the only this is one way we may use some as a out of mana maximum or with just a manual configure to do to configure these two parameters next so "
  },
  {
    "startTime": "02:01:31",
    "text": "there\u0027s some discussion in a bt call many missin I didn\u0027t follow that and my colleague actually follows so we have to consideration for these two parameter wines effect loss ratio the other is the chump numbers for for this threshold we think as we already discussed in the previous types we can use STV to signal these kind of parameter and but the force ratio how do studies for this threshold this based on the RDP allocation for example FEC application you may consider the FPS a the coding mechanism or coding rate and and here we gave it a simple example use threshold it can be said that a number of the package in the FEC stream so for the chunk of the number which anchors actually this is we we believe actually there\u0027s a the more a number of the channel do you receive them the more a curator you can get these report of a do so we such as that you set as a greater value for these infective lossy index so these are summarized the detector caching on the list about these two two parameter next so that\u0027s all yeah we like to sort of you some feedback and comments on these how well-established is this metrics is it the new metric or is it an existing actually used in the measurement community general actually that\u0027s a good question actually we thought about these we discussed with our colleague are actually this a lot more look-alike is a new metric actually they can based on the existing metric defined in obviously 3611 and also the other two poster repair pakka doors metrics you can derive this measure it\u0027s more like a prepare loss uses pre repair loss counter to compare with threshold we said so these are pre repair pre repair packet also you can get calculated based on the the los lunas encoding that define FC 611 in addition there\u0027s another job that actually actually actually is from ratio and some other core do is they define the pose repair lost Congress they define to pay me the wines poster poster repair lost count also repair Lots counter so you can some of these two parameter together you can get these pre repair pack loss so this is a new magic we introduced here yeah the one thing I would say is it\u0027s a "
  },
  {
    "startTime": "02:04:32",
    "text": "16-bit vo they would have your multiplier yeah yeah yeah and saw that yeah yeah maybe yeah way worse yeah figure yeah so any other comments on this no I was just commenting on this I mean it I mean I\u0027m not a measurement guy but so so I can\u0027t come in somewhere it\u0027s useful but it it clearly fits the architecture it doesn\u0027t cause any harm we have plenty of space you know that there seems no reason not to do it although you know whether whether it\u0027s useful I cannot comment thank you I personally will see you the rest of the week but as a working group we will see I mean email me remind me Bert Juanita what\u0027s email to your mind for a portal comments all right I had one sort of an answer about the exit format of it particular so it occurred to me not informative though cause the packets yeah yeah with something actually time "
  },
  {
    "startTime": "02:07:33",
    "text": "so it occurred to me that the way you\u0027re doing you know all timestamps relative to the same time step "
  }
]