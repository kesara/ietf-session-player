[
  {
    "startTime": "00:00:19",
    "text": "All right, it's 1 o'clock I think we can get started Chris, are you, I'm not able to share this slide I select the slides. It says select your slide And I did but nothing shows up, right? You don't see anything? It just says... I see a new deck is being shared. Right, and it just stops there could this be because it's a the first slide deck is a powerpoint file and not a pdf new deck is being shared. Right, and it just stops there. Could this be because the first slide deck is a PowerPoint file and not a PDF? I saw it from the downloadable meeting materials that the chair's slide deck is a P-PtX file. Yeah, I'm pretty sure we have to upload PDFs I believe there's also a share screen option so that might be an option option Let's see here I think that's not an issue you can share PDF because I can click on any of the files and it's not showing up Um bring up the slides? Yes, one moment Because it just tells me to select but nothing happens after that"
  },
  {
    "startTime": "00:02:03",
    "text": "We will start here momentarily, folks There you go. Thank you Thank you. All right All right, very good. So welcome everyone to IETF 120 here in Vancouver My name is sanjay mishra and my co-chair, Chris is remote. And kevin ma, for unfortunately could not be here today due to personal reasons So that said, let's get started. Next slide go through a couple of administrative parts here of the slides so note well some of you are probably familiar with it as you have seen this before Just reminding of the code of conduct and other things that are listed here. So feel free to have a look at it Next slide. Note very well Just talks about these meetings are intended to be professional collaboration and networking so let's keep it at that There's other details here that you can skim through Next slide These are some other meeting tips If you're already here, then I think you're good Tells you about keep your audio and video off if you're not speaking Otherwise, all good Next slide Resource agenda, and other things that also we can skip over Next slide, please. Okay You can skip over this one also Covered that. All right, so here's where the agenda starts. So we've got two drafts that are under the IESG review"
  },
  {
    "startTime": "00:04:02",
    "text": "So we'll go through those two drafts first Next slide, please And then we have a number of working group drafts. There are at least six thousand these. So we're going to spend bulk of time reviewing these documents, status and where things are. And then we will also go through private features There are some open questions in the mailing list and Arnon will talk through that. I'm not sure if we're going to be able to reach any decision, but we'll definitely talk through that And then we want to save some time at the end for some topics that we want to cover today, particularly with the some of the documents that we have might impact the scope of the charter. So we want to talk to some of those items that are listed here so we'll definitely save some time at the end to cover those. So that's the agenda that we have today. Anyone has any comments for any on anything on the agenda? All right If none, then let's go back to the first draft which is the let's see if you can share that Okay, Christop I see you there. So let's get started with your document Okay, so hello, everyone. Yeah, so that's matthew quick update on the integrated credentials subsets draft Next slide. So it's that the current status okay there has been a small update this morning one additional IESG review which is also"
  },
  {
    "startTime": "00:06:01",
    "text": "good I mean no no major objections. So there's are still five five reviews missing with the yes or no objections in order to pass And so far all the comments were no major objections or comments So mostly precision and reform yes or no objections in order to pass and so far all the comments where no major objections are or concerns so mostly precisions and reformulation and it's so that's the status I have on the following the next slide. I have a recap a bit on the different chain since the 05 version so that's the version from two meetings ago um as i said so there were many nits and reformulations One of the reviewers are not really don't agree on how to put the references of those two RFCs RFC, it's 736 and 736 One wanted to have it in normative The other said it should be informative So I think that at the end I will put it into informational because those are informational that RFCs I think it makes more sense There was some updates in the delegated credentials object So the first one, was before the IESG review. We update the structure bits in order to encapsulate the delegated credential structure in this certificate entry, as it is defined by TLS And this allows also to encapsulate the whole certificate chain, which is quite useful. The reviewer also asked to put references to base 64 encoding, so that's not 4654 it's 464 in the RFC"
  },
  {
    "startTime": "00:08:01",
    "text": "Next slide And then there was some, or the reviewers asked for precision for this should so the should is the UCDM should time you read downstream CDN credentials via the MI And so when there's a should, we should add reasons when we don't respect this should and also talk about the concept And so when there's a should, we should add reasons when we don't respect this should and also talk about the consequences. So what I added is so typically, if you have just short term, one shot deployments or when you are just want to deprovision the downstream CDN where then you don't need to refresh those credentials in anymore, and the consequences are well that the downstream CDN refuses to TTIS connection when you doesn't have a fresh delegation credential. And the last time changes were between fresh delegated credential. And the last changes were a bit more text in the security and privacy consideration discussion, mostly recall about things that were already in the text somewhat else So recalling that the default maximum value period is seven days according to the delegated credential RFC. Recall that the encryption is mandatory for the private key in the mic delegated credential object. So this is all already said in the text before, but just recall it here. And also one warning regarding privacy if someone is able to retreat the delegated credential, this may allow to by the attacker that is getting the dedicated credential to decrypt data sent by end users and that this data may include personal information. So that's"
  },
  {
    "startTime": "00:10:01",
    "text": "that's all So, a quick administrative thing, so I think this is good I just see that Francesca has posted on the chat that make sure to respond to the AD reviews individually, those that have commented on the draft whether or not you have accepted their comments and if you have then just you know reply back to each of those individually Do a reply all to each of those emails that have sent comments and and I also see last bit of comments have come in this morning so you may not have seen those. Fairly straightforward just some suggestions on modifying the text to make it easy to read and i i think i it sounded like the suggestions made in the last review are our it easy to read. And I, I think I, it sounded like the suggestions made in the last review are, are good to follow and makes the document easier to read Okay um and uh one more thing I actually at the onset of the meeting, I forgot to ask if anyone would be taking the meeting minutes since we've already started so I'll take the responsibility now and I'm going to be recording the meeting minutes And Chris, since you're doing the the, sharing the slides, so I'll take over that part and I'll do the meeting minutes here Okay, very good Any questions for Christop? All right, let's move on to the next draft Do we have slides for the next one? Which one? is next? Capacity insights Yes, there are slides for that"
  },
  {
    "startTime": "00:12:02",
    "text": "It's a combined deck with capacity and protected secrets I labeled capability Confounded my search Oh, yeah, sorry about that Well, since they're both one down I figure I'll just talk about both of them and go through the whole deck here Shouldn't take very long So we can just go to the first slide So for those of you who are not familiar with capacity, I assume that you are new to this group So I encourage you to read the draft because it's in its final stages now. We're passing working group last call, and it's going to IESG review and the latest draft, I believe should address all comments that were outstanding from the mailing list with the exception of the telemetry source types registry comments from i with the exception of the telemetry source types registry comment from, I believe, and excuse me, if I mispronounce the name from carsten bormann um who pointed out that we discuss a registry of to limit source types, but do not include it in the IANA section So then that brought to my but do not include it in the IANA section. So then that brought to mind the question of whether we should really be registered this at all, given the thank you, whether we should be registering at all given the, the, the, type and the you know, the unlikelyhood of future extension outside the scope of this draft so it is telemetry so perhaps it will be extended. I don't know but it maybe seems a little premature to create a registry for the single generic"
  },
  {
    "startTime": "00:14:02",
    "text": "type. But I don't know. I'm curious to hear thoughts from other people other than the reviewer But with the exception of that one, issue, all comments should be addressed. And if you can go to the next slide, please. I will be sending out replies to each of those individual emails to address all the comments in line so that we can make sure we captured everything So either way we go on the register thing though obviously will be a revision eight with some minor modic modification one way or the other So I'll pause there because that's before we're moving on to get capacity Francesca. Hi Ben. So I don't have a very strong opinion about it but I think that IANA registries are not expensive to set up them maintain. So if there is the option to more fields to be defined in the future, then just defining a registry would fix that It's a cleaner solution So I will go for that. It does require a little addition to the text with defining the registry and deciding what policy the red registry should have in terms of expert review, first come, first serve specification required, etc. So a little bit of thinking there well so i guess i must i might be interested in in learning some more about that because we already do have one registry defined in the document for uh um interested in learning some more about that, because we already do have one registry defined in the document for, or I guess there are additions to the existing registry Yeah, because there are other additions to the CDI payline so yeah so what i'm going to be adding will be slightly different from the existing IANA section because it's creating a new registry from scratch So I assume there's some RFC that defines how to do that"
  },
  {
    "startTime": "00:16:02",
    "text": "Yes, I can point you to some examples of how it's done What you do in the Ianna section right now, you're actually registering values When you define a registry, it's a little bit more complex because you have to decide what are like the rows of these, the columns of this registry and what do they mean and how, like, what's the, yeah, how do people register do we know where the where the CDNI FCI type registry? is defined, which RFC that's in? Yeah, I can point you to it okay i can post it in the chat Okay, because I imagine with the exception of who the X expert reviewers would be, I think that would be largely similar in definition Yeah. Okay, great Well, I think we have our answer then Next draft i'm sorry what was that You're ready to move to the next draft, you said? Oh, yes Okay. Yep I believe Chris, I think you're the only one to do it real review of this document so far So I addressed a lot of your comments but not all of them We definitely need more review of this document for protected secrets. So I have this question on this side, is anyone implementing it? As far as I'm aware, nobody has implemented it yet. So I imagine once that happens, there's going to be a lot more questions So I would encourage anyone who's considering implementing it to maybe start thinking about this and read through the draft ahead of when you do that because we don't want to get this locked in and then find out as we're on our way to publication that it has you know, major issues with it So, so I don't, I'm not asking for last call or anything on this, because I think it"
  },
  {
    "startTime": "00:18:02",
    "text": "needs more feedback is, is, would be my major point regarding this document The biggest issue right now is one I think Sanjay raised which was related to the trademark for Hashi Corp fault so that is one of the in fact the only support external secret store reference that's currently in the document. Though, though know, we do want to include potentially support for others But if we're going to use Hashy Corp Vault, we need to get permission to use their trademark. So I think that kind of on my list to go obtain permission for that, but I haven't done that yet. I haven't talked to the right people So that's also an opportunity thing that's kind of a that's a blocker before proceeding with this document On the next slide, there is a change log which I didn't put in this deck for the capacity draft just because it's too long to fit on slides This one was relatively compact. But if you're interested in the change, log for capacity, I'll refer you to the mailing list where I have a full change log posted And that's it for this deck so I'll just, I guess, pause for questions before dismissing myself Oh, and Chris, I had your hand. Yeah I'm in the queue with no hats on. I can commit to reviewing this in light of all the changes. And I appreciate all the update And we have a, we're going to have a conversation on the hashicorp situation a little bit later on so we can discuss that then. Okay, all right great. But if anybody else has anything else to bring to the mic all right thank you. Hearing none Thank you, Ben I believe next up is a Alfonso"
  },
  {
    "startTime": "00:20:25",
    "text": "Cannot hear you, Alponzo? Alfonso? You may have to unmute Nothing yet. No we don't hear you Don't hear you, Alfonso. Should we come back? to you? Sorry, it's working now? Yes, it is now, yes. Okay, I'm sorry All good. Sorry for this. Okay, so thank you Chris for sharing the slide, so please go to the next slide. Just a quick next one, sorry. Yeah, yeah Just a quick review of the abstract of this draft this related to a genetic metadata, or just definition related to controlling edge access to resources in the content delivery network, specifically to the Thompson CDNs in the end, and specifically talking about cross-origin resource sharing course protocol configurations, possibility to"
  },
  {
    "startTime": "00:22:01",
    "text": "define the compression rules to the responses from the data to define the compression rules to the responses from the Damsin CDN to the user agents, and defining client connections timeouts also between the Damsin CDN and the user agents. Go next please So changes, this is currently version two and the changes came mainly because Kevin ma made a review and sent a few of several comments that we try to address. So basically this are the changes the main changes were the we have a reference to the latest update of the YWG fetch specification that defined the course protocol that wasn't in the previous version with you also the other structural things and separate requirements and not just definition for the course a micro origin policy object we have rewritten several parts of the requirements sections to try to be to have a more clear understanding of what course is and with reference to the fetch specification and how this is related to the relationship between an abstin and adamsins in the end and what is the the from the upstream to the downstream to configure the using this generic metadata objects and defining by the values of the course response headers in the in the object definition that wasn't in the previous version then with the other different changes but in the next few slides I want to address several questions that i think were relevant from relevant from kevin ma and that could be clarified all others that read this draft. So please we can go to the next one, Chris Yeah, so one of the comments from kevin ma the was not clear the concept of the origin in the document in the draft. And I understand that his is"
  },
  {
    "startTime": "00:24:02",
    "text": "concerns on this because when we are talking about CDNs, Downstein and Amstead, CDS on the terms of the origin we use usually think about the system where the CDNs are going to acquire the content that is going to be catch and search But in course, the origin the concept of origin is a request header that comes from the user agent to the element that is going to serve the content, in this case, ADN times in CDN. When we are talking of origins, it's that value of that request header that we are talking about so it's a different, completely different concept of in terms of course protocol the usage of the origin name regarding what in CDN would be typically i understand as an origin so we try to do regret this section to have more clarifications on this difference of concepts because it's important to understand the rest of the why the object is defined as it is, how we are using in the object definition the term or begin So I hope that now in this version is more clear Please next another thing and this is a question that i think Kevin is not here, but I put this response in the in the mailing list and what we want open to hear your opinions or now or in the mailing list is that there is a definition of a pattern and property in the object definition that is exactly the same that it was defined for the rfc eight of the MI pattern match So here maybe the question is, well, sorry, I see that is all the thing there the question here is that should we reference directly this? property to the RFC-8-0-6 definition? of MI-Patter match? Maybe that is the appropriate way. Well, I related this as a question because I was not pretty sure and I needed to send the update of the draft but but maybe in the questions we can discuss this"
  },
  {
    "startTime": "00:26:02",
    "text": "if there's any a strong opinion on this please go next other thing is that this was a question regarding specific to how to use this generic metadata object when defining from the apps into the downstream the course configuration And it's regarding the two main properties of the document that is of the object that are the I am a low origin list and the while current network so coming from the from the text, it seems like he understood that it was maybe some kind of duplication or or that it was redundant to have both configuration, both properties We have tried to explain in the new version that a lower in list is a pattern match, how we have described before, and only if the this origin request header that comes in the request from the user agent matches any of them patterns that are included in the allow only list then the property while can return is taking in consideration because if that happens, if there is a match, then the time in the end is going to return a response head based on the cost protocol and the value of this response header is conditioned on this problem So we need both properties One is the match validation of the request header The other is how the Dampson CDN is going to generate the response header. So I hope that now is more clear also. Please next Yeah quick question. Yes, sure. Can you go back to the previous two slides? One more Um, yeah, on just so that I understand your question here on the first bullet Yeah, the other sort of sorry they know that the first one. Yeah"
  },
  {
    "startTime": "00:28:02",
    "text": "So you're asking should we reference it directly? Can you clarify what exactly did you mean? Yeah, so this is an, this allow origin, list property in the micro's origin policy object included a pattern that is the definition in the draft is exactly the same definition that is in the MI pattern match in the I NFC 8006. So I understand that is really the comment from kevin ma was that we need to try to know to do definition of different patterns, structures yeah and I agree the thing is that it's exactly the same structure on the RFC 8026, then my question is that then in this object that we need to have this pattern, should we reference to the MI pattern match? definition in RFC 8026? as it's exactly the same definition? I guess that probably the most common response will be yes, but this is why I wanted to do rise for this. Yeah, yeah probably the most common response will be yes, but this is why I wanted to rise for this. Yeah, so I did see your document there. So yeah, I think I agree that you should reference the document, RFC806 and then the MI pattern match as defined in the section 415 as you said. So we can, you know, so do that and kevin ma confirm but I think that you seem to be on the right track there. Okay. Thanks, Sanya Okay, so I would try to finish quick about the client connection control, where there were some questions Those questions were not responded in the mainly list I think we are going to send it probably tomorrow but just to let it questions were not responded in the mainly list. I think we are going to send it probably tomorrow. But just to let the responses here about the was a question in the definition of the client connection control"
  },
  {
    "startTime": "00:30:02",
    "text": "object that is talking about optimising performance well this kind of object tries to set different configurations in the downstream CDN that can be used as part of maybe MI pattern match, sorry, path pattern configurations in the Downstein CDN that can be used as part of maybe MI pattern match, sorry, path match in a definition for a specific paths when you want to maybe have a different paths for different devices and then you can set different client connections configuration. So you are ready to define this property more specifically for different devices and that is very convenient several times because the content provider usually have different client applications that could have different restrictions So it's very convenient that the abstin is able to configure the downstream CDN in a way that it will fulfill these restrictions of the different devices Also, in the future, when we have the MI process, stages, it is something that we have finally in the CDN you could define configurations based on user agent or other values of request headers or any other element to define this also different configurations in the dump agent or other values of request headers or any other element to define different configurations in the Dampson CDN. So also the although the object doesn't seem to be very dynamic, the thing is it combining this with other techniques that we have and we will have in the CDN specifications, you could be able from the Aftin CDM perspective or the content provider to have this dynamic of flexibility in the configurations of the client connections. So please go next This is this provider to have this dynamic of flexibility in the configurations of the client connections. So please go next. This goes in the same in the same line. Please next Yeah, well, just some general questions. I'm finishing kevin ma asking to separate examples in some of the object definition we did in one section because there were two examples, but"
  },
  {
    "startTime": "00:32:02",
    "text": "in the other sections, there was only one example. So I'm questioning this because I saw in other in many others, CDNI drafts, and specifications that when there is one example i don't see there are separate sections. So I would like to to understand if there is something specific for the draft that they he wants to have different sections or I don't know if it is so i would like to to understand if there is something specific for this draft that he wants to have different sections or i don't know if there is a common way to do this that maybe I'm missing so well I don't know maybe we can just discuss this on the melee list so yeah it's just trying to address that comment, but to let that question here. And that's it So I'm open for any question So on the last one, you're saying that you want to take that to the mailing list to just confirm if you want to use separate examples or just keep it in the same section? Exactly, yeah, I will be well, because this was a comment from Kemima, unless there is some other policy that may be missing that needs this examples to be in a separate section but i'm not sure if if have all the documents that include the examples in the section if what is the, why? it's needed to have this in a separate section for just one example I just wanted to be sure that I understand the question from Kevin okay um There are some hands, I think For now, you can leave it as it is in your document so i think it was more of a question of ease of visibility at you can leave it as it is in your document. So I think it was more of a question of ease of visibility. I think readability, but for now, just leave it as it is. Okay And we also see Glenn and Pankar in the curious of Glenn. Yeah, I have a comment right on that exact topic because when we show the cash control metadata doc coming up next uh"
  },
  {
    "startTime": "00:34:02",
    "text": "Pankaj in the curious of Glenn. Yeah, I have a comment right on that exact topic because when we show the cache control metadata doc coming up next, the way we've handled examples there are right in the section of the documentation for new MI object. There's a very brief example that doesn't do a hell of a lot more than just show the use of that object. But then at the very end of the document, there's a section called informative examples that show the use of that object for context along with other objects to solve some problem So that seems like a good way to do it, I think, when you, when they're is a need to not only show the most basic sense use of the thing, but to show it in some sort of more complex context And I called that informative examples Okay, Bancaj Thanks for calling on me Just wanted to make a quick comment about the kevin ma comment that this particular object should be just made mandatory versus being optional. And I think the long-term intent for client connection control was not just to be provide that one property that exists today, which is the keep alive, but also a couple of other properties as an example packet pacing and we chose initially to just kind of keep this object simple enough with just one property and as implementation and as adoption kind of increases, we plan to actually add more properties to better manage the client connection aspect of it So that's the reason why it is kind of like optional And also that not every CDN and kind of provider of which is a client, ask for these changes. And so when you have this super option, and then many other multiple properties within that being able to have that as optional actually kind of helps out in the long term okay"
  },
  {
    "startTime": "00:36:04",
    "text": "Okay, so suggestion is to just keep that as optional and that's the reason you're saying Yes, that is correct Okay Thank you, Alfonso So we have the CDNI cache control metadata Glenn Yep, here I am. I'll share my screen here Do I get to choose which screen? to share? Hold on. Did it just, I'm requesting the share You don't see my screen yet, do you? Not yet. No I'm attempting to locate the button that allows me to let you Fair Okay, now I get to choose the window I want so hold on just a second Okay, I think that did it. Hold on just one second Thank you my screen there. Yes Maybe I'll zoom it up a little bit Okay, so yeah, so on CDNI cache control metadata version two, we'll just kind of quickly go through some of the key comments that came in from Sanjay and how we addressed them in the updated draft. I'll kind of pong back and forth here"
  },
  {
    "startTime": "00:38:02",
    "text": "General comment about, you know, open caching, the term being used. So in the introduction here, we went ahead and I went ahead and added a little bit description about open caching system service the role of DCDNs and they require cash control instructions from upstream and that here open caching systems are essentially DCDNs that use CDNI standards for configuration and traffic delegate such as gives a little bit of context about what we're talking about for people who would just come out from the CDNI point of view Where are we? gives a little bit of context about what we're talking about for people who would just come at it from the CDNI point of view Oh, yeah, so all of the examples didn't have titles below them. This is sort of a bit of a fallout and we just sort of scroll down to one or two right this figure one figure two this is just a fallout of how we generate these IETF drafts from our current google doc format for the sbta sources We'll fix that up in a future version of that so that we can have a little title under each one where instead of just figure one, figure two, it would have a bit of a description. What I did in the meantime, though, is right next above each example, it says in the fall following example and sort of summarizes what's going on So hopefully that should be sufficient, at least for now That covers that one. All right, the use of the terms origin and client, this sort of touches on a little bit what Alfonso ran into Here we really do mean the use of the word origin as it's used in the CDN world. And what I did is, you'll see, I changed wherever we used origin I kind of I replace it with the phrase upstream source. Because in C CDNI terminology, we really are taught about the source, you know, the RFC"
  },
  {
    "startTime": "00:40:02",
    "text": "806 uses. So is that an exception? term here upstream source source? I see chris box join the queue here. Yeah no hats the uh the uh uh suspect that all of the terms that we want to use here are defined in the HTTP semantics document um and i would suggest that we align with the HTTP semantics doc Do you want to send me a little? document. And I would suggest that we align with the HTTP semantics doc. Do you want to send me a link to that? I'll probably find it somewhere. Yep I'm pulling it up Okay, and I'll make a note of that And we may wordsmith that a little bit more, but that's the idea. I think it seemed to flow pretty well doing it like that. Moving ahead oh, there was a comment with the apps abstract will be adding to RFC80 um I did correct the language here i believe what i have is more clear sun Sanjay. This special fiction adds new objects to complement the basic object that's already in RFC RFC-806. So I think that covers what we were trying to express there moving on We already talked about some of this adding section number. These are just little knit things Yeah, I made it clear whether the capability in the intro, if you're really close each of these I just updated the language a little bit to make it a little bit clearer, whether we're referring to UCDN or DCN capabilities. So I think that should address the comments comments"
  },
  {
    "startTime": "00:42:02",
    "text": "There were some ambiguous sentences here that were just cleaned up language thinned out and cleaned up a little bit dynamically constructed cash keys How did I resolve? Hold on one second Oh, yeah. Let me go right to that section here Yeah, so right now references to things like the metadata expression, language, I give a link here to an SVTA doc, that SVTA doc that describes a meditational language is currently an individual draft in the CD&I working group We can do in a future version of our little script again that converts to the IETFR RFC, XML format. We could change this SBD link to an IETF link and would it be appropriate to be a referring, there's a question for Chris and Sanjay, to docs that are currently IETF individual drafts? whereas this SVTA doc is actually pushed. Yeah, so if the document is, if the document is published at the SVTIA, we'll have to ask, there is a process by which we can issue a normative dependency on a document there Some of that process is going to depend on whether the SETA is considered a standard, an SDO standards definition organization It is. Um, and it, it, it I would not necessarily assume that it is yeah And so the process of having a normative dependency in"
  },
  {
    "startTime": "00:44:01",
    "text": "a uh protocol definition in a proposed standard to a non- non-standard document is not typically considered acceptable And you can see here I did have that one in the normative list and the other SVTA once is informative right um And processing stages can't be in the informative list You have to read the or in the and the mel um you have to actually know both of those in order to implement it And so in this case, the Flash Control Mel was normative because it needs to be there. It's a, it's a, you can't do computed cash key without it. Correct processing stages is here in cache control just because I use them in the informative examples, but it's not key to cash control Yep, and we're gonna have this exact same problem with HashiCorp later when we discuss it. But yes proposed standards, standards track documents cannot generally speaking reference non-standards documents in a normative way which is required here. So this normative reference this one right here, I could certainly put an a reference to the IETF draft Would that be appropriate or can that not be? that? That is appropriate, but it does name now here, I could certainly put in a reference to the IETF draft. Would that be appropriate or can that not be up? That is appropriate, but it doesn't mean now. For now, yes However, that would make this a dependency of that other uh that other draft and we could not progress this document until that other until and unless that other draft were adopted by the working group determined to be in scope of the charter of the working group and determined to and this couldn't be published until that came out. Okay, fair enough. So"
  },
  {
    "startTime": "00:46:02",
    "text": "so it's a real dependency yeah so Alfonso, I'm glad you're here listening. I put a get issue in there for us for our little document converter for the next round of things for the next IETF. We can take a certain set of these SVTA docs and take them into the IETF trap room. That should take care of that for next time. Very good good Okay, moving ahead here. There were many cases where we used the term client and we did go ahead and change that to user age so you'll see here. And I think that's generally what we meant here when we use the term client. So that should be appropriate and in line with IETF lang language I would double check that against the 91 that should be appropriate and in line with IETF language. I would double check that against the 9110. Yeah, I think user agent UA, I think that was what Sanjay had already mentioned that for us. We'll double check These were just little The HTTP group spent a long time getting agreement on those words. And there's a lot of value in what they selected. Yeah, all right Then the other little things here were NITS and then finally, there was Aeana consideration so right now is in most of this set of documents on our from our configuration interface we just have done this. So we've listed out the these are the new objects They will be specified here The comment from sanjay mishra you got to do more than that right you've got to um have a subsection for each payload type and so we'll deal with that next time around The other thing I wanted to mention since we were talking just a about examples, excuse me, for scrolling quickly"
  },
  {
    "startTime": "00:48:02",
    "text": "in line with the definition of any object of the these very brief examples that don't do a hell of a lot except to show the syntax of using it, and then there isn't an info informative example section here that shows a couple of more complex use cases of the cash policy object in the context of some more complex stuff in this case with processes stages That's all I got. So I think that kind of gets us through the whole thing And did we want to, I think we had originally talked about moving for a working group last call or do we want to wait until the next round of work? that we do to take care of some of these things that we still are dangling I don't think this document can necessarily go to working group last call with the down reference as it stands Okay, that one this uh this one right here that's no good yes and so Jason the queue. Well, I think, Chris, you already addressed So I'm going to take myself out of the queue Okay, that's it for me Thank you And I believe we have Banca just two drafts Let's see, in which order, I think the client and then the client access and then the source access Yeah, that's the two documents All right I don't really have a presentation that i had shared earlier yeah yeah so Pankaj, what I did was, I, presentation that I had shared earlier. Yeah, yeah. So, Pankaj, what I did was, for the client access control, I thought it would be easier to just go through the comments that Chris had So I posted them here on the, as a PDF Oh, excellent. Yeah, I basically kind of did"
  },
  {
    "startTime": "00:50:02",
    "text": "the same thing and inserted my answer So I can just kind of read the answers I have and for different ones, yeah So let's see, making sure I look at the screen share and also So, okay, yeah, so because thanks for the review of this document Your first comment here as I go through this screen share, the document seems to me in three semi-related, seems to have three semi-related purposes I think and you're kind of referring to the TLS, the location or the IP and I forget the third one client access control, which is the odds side of things, sorry, yeah, where I guess, like our thinking here was that these are all different kind of like I guess like avenues that control how a user agent can actually connect to a service or a CDN and so yes, sure, they are different with respect to an authenticity kind of a setup versus a time versus an IP, but they were all kind of like defined the restrictions or the avenues in which a user can or cannot connect. And that's why they were all kind of good into a single document. There wasn't any other document that actually allowed for that kind of a structure So access control is about the origins set of things and different other documents exist. But this was the only place right now that allowed to collect them all together into a single place and talk about them as different ways in which we can get access to access of a user agent to a server. So that was kind of like the rational or the thinking behind that Open to your feedback comments Yeah, no, I think that's mostly okay um as long as they're all appropriately in scope um"
  },
  {
    "startTime": "00:52:01",
    "text": "think that's mostly okay um as long as they're all appropriately in scope the the last one however is the first, the first describe gating access. The last one just describes the details of the TLS connection And I have to wonder if maybe that last one might actually fit better in the edge control Yeah, that's a fair comment I think maybe the edge control is probably the better one and I hadn't really kind of brought up these comments internally with SPTA group. And so, for the answers I thought appropriate for this particular conversation I kind of brought this up but I think I tend to agree that edge control metadata might be the right place for that Yeah Yeah. Okay, move on to the next one which is para two the delivery time um place definition seems mostly fine You are actually asking for the domain to be used here And yeah, definitely agree, and I'll rectify that that Alphonse is in the queue oh yeah thank you Chris what I was related to the previous comment on if uh having this object in the edge control? draft it's more a protocol question is how will be the way to do that as this is a draft and the other is a working group draft is just to add it to the working group draft or is any other the good news is that we just adopt client access control i'm sorry okay yeah so yeah sorry other the good news is that we just adopted client access control i'm sorry okay yeah so yeah they're definitely both working group docs Okay, perfect. And that's those things Okay I'll continue. Paragraph number three. Let's starts with in the time window, I'll extend the definition"
  },
  {
    "startTime": "00:54:01",
    "text": "definition there is a reference to SVTA 2032, which is an SVTA document for the problem stages metadata. Yes, if we do adopt that particular draft, then yes, the reference needs to be updated. I think it goes in line with the previous session with Glenn. And using SVTA document as a normative reference. So yes, accurate that. I think we'll look to use IETF reference here instead of the SVTA one. And yes, it seems like it's a normative reference, which is the next one And I'm jumping the next sentence, block of sentence in that same third paragraph starts with likewise this is an informative reference. And it should really be a normative because terminating objects is a concept that needs to be understood yes it's a great catch and I believe that this should be a normative reference we'll update that And then because it's a normative reference, we'll link it to an idea of draft rather than S-video name Moving on to the fourth paragraph in this section that defines the TRS parameters the product are enumerated TLS1, TLS2 so on and so forth I believe yeah it kind of makes sense that it should be referencing a registry rather than just actually illuminating those values there so that from a forward compatibility point of view as new versions come in, they can just be referenced through the register rather than updating these documents documents Moving on to the next paragraph, one, two, three, four, fifth paragraph then it starts with likewise the TLS Cyper suite. It's basically the same comment about using a registry rather than listing those individual string or enumeration enumerate those values. So we'll kind of update that and make sense as well the next paragraph after that which is and lastly the client automated data seems to be a bit of a stub"
  },
  {
    "startTime": "00:56:02",
    "text": "seems to have a paraphrasing because it's a larger paragraph here the client auth metadata seems to be very similar to MI-Oth, and right now it seems like it's just a bit of a stuff. So what gives? So where we were headed with that, the intent was that for better or worse if you look at the MI source control or MI source, it has a property called Acquisition Odd. So basically, MI Source is an object that defines all the properties on how to connect to it upstream or a origin server or a server. And one of those properties also includes acquisition odd. And so inspired by that it seemed to make sense to define one single instance of an art or Z kind of an approach for allowing a client to connect to the server or a user agent to a server and that's where defining, and the auth-and-odz-Z is basically encapsulated via MI.com but to kind of follow the approach of mi.source dot acquisition odd it felt that we could follow a similar approach of defining MI dot something something representing a client dot delivery art and delivery art is a property right now within client auth metadata. So that was kind of the intent behind that. And also so that we can have just one authenticity object rather than align for many such objects to be defined. So I think the flow just seemed to fit well and be analogous to how source that I could acquisition art is defined. Similar was intent to define client client-delivery art. So that was kind of the thing to me behind that. Now, of course, right, it's just a stop The intent was to actually define cat common access token auth m i.cati auth. But this spec wasn't done on the CAT side of things. So those object model that was flushed out in MI"
  },
  {
    "startTime": "00:58:02",
    "text": "Clientorpeed out was pulled out So that's why it's just up at the moment. I think once we kind of get the cat object defined, we will all give examples such that header auth and aWS v4 odd, these are two existing objects and I forget which let me see where are the defined just one moment please. Yeah, these are defined under source access control metadata So source access control metadata allows for two different automot modes today which is header and a w s4 off And I believe that these are just odd that do not need to be relegated just to CDN to origin. They can be just new universally used between an actual user agent to us not need to be relegated just to CDN to origin. They can be just universally used between actual user agent to CDN service world too. So together these three kinds of auth objects can be pulled out separately into a different document as well too So that's kind of like the plan there That sounds like the difference action item here Okay, cool The last line, the introduction might also might call on that we are defining new HDP protocols as well I wasn't quite sure what this meant, so if you can actually elaborate, and I think, Chris, this was your email email Yes, we're the document has an I am we're the document has an I have an IAN a consideration section that defines the list of H2T protocols, which you need to do The registry is the correct way of doing that But the only place that that is referenced is in the IANA considerations And I know that everybody always very carefully reads the entire RFC"
  },
  {
    "startTime": "01:00:02",
    "text": "including the Iiana considerations But in the event that somebody didn't, it's hand- to call out that part of the purpose of the document is to register that for the within these specs Okay, I understand and i should have been more careful with my language. We are not actually defining new HTTP protocols here. We are simply ready registering a list of existing HTTP protocols for use in our system defining new HTTP protocols here. We're simply registering a list of existing HTTP protocols for use in our in our systems. Yeah, yeah, I agree. And which is accurate. Yeah, we're not defining new ones Heavens, no. Yes not at least in open caching or CDNI, yeah That actually kind of wraps up what i had to share and that were as a replies to the feedback received so far. So thank you for the feedback. And if there are any open questions, I'll take those not a question, but just to confirm basically you'll respond back to the mailing list or you're going to just update that draft yeah no i think that's accurate that uh i'm sorry that's fair that we should have that exchange on the mailing list so that there is agreement on that mailing list as well and that will reflect those changes in the drafts and publish any one Okay, great. Yeah, that sounds like a good plan then Should we move on to the next one, which is your access control metadata? Yes, yes I know there are no comments on it yet but it's a good idea to walk through what you have in mind in that document Yeah"
  },
  {
    "startTime": "01:02:01",
    "text": "So can I screen share or would you like to? one? well, yeah, I can screen share Yeah, hit the share request button. Yeah, okay Okay now the application will record Oh Lord, okay Sorry, one second I need to click through a few buttons on my system Okay, I think that could work work Pretty damn no, actually, can I do entire screen? Might be better Let me give it a try. Okay I'm sharing my entire screen Oh no, I don't think that worked Let me try one more time Except I want to give to okay oh Jesus is there a link I could bring up unfortunately not how about this maybe i can just talk through the email comments. I don't really have a whole"
  },
  {
    "startTime": "01:04:01",
    "text": "lot of replies for that similar to the previous one I'll just talk to that. I apologize. I'm unable to do screen share for the document I want to screen share. So there was an email from June 12th from Chris for the source access control benefit and then there was a second email same June 12 from kevin ma so I'm going to just address those two two Chris Chris's comment was that feels that the draft document is is a part, two parts of two separate parts of documents that have been glued together And these are section number three and section number four Section three talks about everything as it pertains to connecting and working with a source of the origin side And section four talks about the authorization aspects, authenticity aspects that the source, sorry, that the CDN will use to talk to a source on an upstream origin. So again section three talks about how a CDN talks about an origin. Section 4 talks about the auth and odd-y aspects of that Yes, and that's how the document is constructed And as I mentioned in the previous one, there is header auth and a AWS v4 auth as two different authentication mechanisms defined that allows the CDN to talk to an origin And there's no reason why we cannot use CATCOM common access token or something else as well too And no reason why all three or any number of these cannot be used between a user agent and a CDN. So I think it kind of makes sense that we will move all these art mechanisms under a separate part of these cannot be used between a user agent and a CDN. So I think it kind of makes sense that we will move all these art mechanisms under a separate bucket and then hence potentially pull these out which is section number four out of the source access control metadata so it will end up with just section number three"
  },
  {
    "startTime": "01:06:01",
    "text": "and section three will just be talking about how a CDN talks on origin the fail-over handlings, and those kind of scenario So that's basically the answer for that. And then the second feedback was section four, looks like it should probably be defining a registry of authorization schemes. This would allow third parties in including SVTA to publish specifications It also, that feedback also continues into approach normative reference for ADWSV-4 I don't really have a comment on this per se but I'm open to a little bit more detailed feedback from the chairs here So basically this is the same problem that we have with HashiCorp and the same problem that we have with SDTA references Basically we have a normative reference to a document that is not the result of the consensus of the IETF And there are a couple of solutions here, one of them, one of which may be simply defining a registry and allowing any third party that needs to to use a specification requirement of them, one of which may be simply defining a registry and allowing any third party that needs to to use a specification required in order to publish the doc but I don't see don't see an excellent route forward on a normative reference to AWS in this talk Yeah, I agree well too, but we'll kind of connect offline on this"
  },
  {
    "startTime": "01:08:04",
    "text": "Yeah, should I move on to the event from Kevin? Briefly, we're running out of time Oh, sure. I think this was a comment about MIOTH choose Twitter, to use payload types rather than a separate registry for odd types I think it's kind of similar in line too the AWSV for odd comment as well too, how to register this or not. And then finally, Kevin's one comment for which I have a reply for is to have, am I then finally, Kevin's one comment for which I have a reply for is to have a my dot prefix for all these different objects. And so we are which I have a reply for is to have a my dot prefix for all these different objects. And so we already have one for Header Auth and CatRoth as well too So that kind of makes sense Thank you, thank you The only comment I have, Pankaj, is if you can also respond back in the meeting list to comments from both Chris and Kevin and then, you know, then based on that, hopefully we'll get some more responses back and then just decide the next steps yes sounds good yes we'll do thank you Okay, I think this should be the triggers document All right Jay, you're up next Okay, thank you. So, uh, we're covering the update for the control interface and triggers second edition, otherwise known as RFC, 8,07 this update for the Control Interface and Triggers, second edition, otherwise known as RFC-807 disks. So there's been a lot that is by the way, how do I control the slides on? this one?"
  },
  {
    "startTime": "01:10:02",
    "text": "You tell me to press the button. Ah, okay. Well, pre-species please press the button then Ah, okay, gotcha. I think I gave you control Okay, excellent. Thank you So there's definitely been a lot going on with this particular document when we met in Brisbane, we were talking about draft number 11, and we are on draft number 14 at this point. The slide gets a very brief summary of some of the changes that have happened we published a version 12 draft on June 7th that was mostly just a cleanup draft before we moved on to a much larger set of changes under version 13 This also included the clean for time policy. Version 13, incorporated the changes requested from SBTA streaming streaming technology alliance specifically for the cash management interface in aligning it with that particular document that they were working on and then on two days later on July 7th and just before the deadline for IETF, we did a cleanup of version 13 and a version 14 draft that largely addressed a set of changes that I posted to the CDN meeting list prior to that point So if you access the materials, for the presentation, you'll see that there's a link that gives you the complete set of changes between 11 and 14 So just looking at each one of these individually the first of these, the version 12 change. As mentioned, this was mostly a cleanup, but it also addressed a major topic from the Brisbane"
  },
  {
    "startTime": "01:12:02",
    "text": "meeting with regard to date local time and local time window from time policy As some of you may recall, we discussed this on the mailing list and we had made a decision to remove this feature because of the fact that we didn't see any really strong use cases for it and we didn't get any feedback against it. So we moved forward with that change and that was committed in V-12 Otherwise, we address some major, some minor spelling errors that we had found in the document There was some formatting cleanup, mostly with regard to non-nasky characters and lines that were greater than 72 characters with regard to the diagram and the JSON examples and we had updated the schema and some of the obsolete RFC references. There were some since this came from RFC, 2007, and a lot has changed since that point There were some RFC changes from 7230 and Friends over to 9110 in France So nevertheless, that game us a clean copy, what we consider to be a clean copy going into the version 13 changes. And again, there's a link here that will just give you the changes for version 12 at the bottom of this slide So the version 13 changes are probably the most consequential We, so this one introduced eight major improvements and features. Allen is going to be helping to discuss many of these changes over here, but all of these were with regard to alignment with the SVT cash management interface 1.0 So along the way, we ended up identity yet more grammatical spelling and format issues. So we corrected this as we made the changes and the diff for the version 13"
  },
  {
    "startTime": "01:14:02",
    "text": "from version 12 is at the bottom of this slide here And then finally, two days later, we published the VP draft on July 7th this addressed a list of issues that I posted to the CDNI mailing list. Probably one of the more consequent changes that we made was actually with regard to some of the language around down downstream CDN and transit CDN and the way that these were phrased in the document So we made some changes to make sure that the way that we referred to this was consistent through the document and it resulted in the number of changes in this particular version here The other thing that we had realized that we had omitted from the version 30, commit was the language around CI trigger command. So there were some changes here in order to improve the restfulness of the API, which we in order to improve the restfulness of the of the API in which we which we made these changes but for some reason they got lost in the commits that we made in version 13 so we applied that along with some corresponding payload language with regard to CI Tricker Command, create, and modify So the diff of these changes from 13 are available from the link at the bottom of the slide here So that brings us to the version 13 changes So as mentioned, there are eight new improvements to the spec with regard to this. We move from a HLS, dash, and Microsoft smooth stream playlist format to a more flexible object list concept that not only included these, but allowed us to"
  },
  {
    "startTime": "01:16:01",
    "text": "specify lists of objects in text and JSON form. We have an X new execution policy extension that allows for specification of dependency, priority, and urgency in terms of triggers. Triggers used to be able to act upon just the public URL and now we have amended it to optionally also act upon private URLs if specified and supported by the downstream CDN We've made changes to the restful interface So this represents the first AP changes that we have made in this whole overall effort here We have separate CIT in points for metadata versus content. So this gives us the ability to use this in the future for being able to preposition and purge metadata configuration So giving us a little bit more flexibility and having separate endpoints for that. We have made the CDN identifier optional This was an identifier based off of AS number that we determined was kind of not necessary in all use cases. We now have label-based trigger collections to allow from greater flexibility for reporting collections of triggers and we now have some extended trigger status reporting, both for reporting the air reporting the air objects that might have an error and also what a particular trigger actually matched an active bond here so a lot of different changes that went into this. So I'm going to pass this over to Alan, who will go through each one of these in detail detail Hello, how do I move slides here? Jake, could you do this for me or you kind of?"
  },
  {
    "startTime": "01:18:01",
    "text": "definitely do it for you if you want. Just say next slide and I'll advance it. Okay, I appreciate it Yeah, so I think just before I delve into the details of the features, I think what we really see this important draft because sort of we see triggers kind of as foundational framework for some other work that already has been either presented in CDNI or future work around cash management and also in the future orchestration. So it's really important to make this sort of good solid framework that we can build upon. It's what we plan to do that. So these features kind of step from that, from desire to build solid framework that is operational and functional for for kind of that mess of mess of use in the future so i'll talk to object list right So again, we're moving from abilities to just address playlists, which was in the previous draft, we kind of up to the 12th to ability also build first I'll use text format for simplicity, but also add Jay structured payloads so we can provide structured information and include video not just video payload but also kind of genetic combination of media non non-video objects or just even prepositioning and purge of validation of object with a non-video at all And this can be used in the trigger embedded with the trigger so part of the JSON kind of trigger payload you can embed object list either play, either JSON or playlist or you can actually point to external URL of where such object list or object lists would be stored and even kind of kind of"
  },
  {
    "startTime": "01:20:01",
    "text": "where such object list or object lists would be stored and even kind of multiple layers. So let's say a playlist of playlist and things of this nature. Out of the game five types three types we had before on HLS and Pagdash and HSS and adding JSON and tech And I think JJ is particularly interesting because we have in the future ability to enrich it with additional information for for provide more information about the option in a structured way also we added the ability to use object list not just as input into operation which was intentional initial intention is to provide an option to compare for hey, preposition this but also use objectless in response So, for example, when I'm referring to playlist and DCD as a UCD and DCD, I may come back and say, okay, you gave me this playlist that's what i derived out of it So, or these are the errors encountered in this list So it's a kind of really generic vehicle for described you know, long lists of objects in conversation between UCD and DCD and bi-directional Next slide Execution policy, right? So also core features prior to that kind of triggers really waived, hand-waved a bit around high you know, triggers can be executed what are the constraints? GCD had a lot of liberty in the how to batch process that do that immediately do it, get up two days later So certainly a need for UCDN to ask for stricter constraints on execution, but a lot of discussion analysis, we came up with three attributes. If you can be added as part of the execution policy, first is dependency So only do this after you complete with that, right? So the kind of trigger being dependent on another. For example, only do preposition after you complete the purge so you don't do things concurrently. Priority"
  },
  {
    "startTime": "01:22:01",
    "text": "also you know when you hey you DCDN, when you pick up triggers from the queue, which should come first so just a priority to pick up. And separately, it's urgency, okay, kind of do this immediately. So not just dictating the order, but also that it could be immediate and if it's not possible for whatever reason to do so immediately DCN would inform your CDN accordingly. Hey, you're asking for something but I'm unable to because of the business logic or I'm unable to do that because it's dependent on a trigger that I can complete, just enough but at least things that are urgent there are certain things that are can be origin in CDS like purge now. This is really bad that that version of the file I published so we have a way to communicate urgency and kind of also communicate rejection if urgency is not feasible And that's kind of core extension using same policy extent mechanism that exists and triggers the c i tv too and we find very useful. Next slide Published in private URLs, right? So this is also Jane mentioned that. So not just also I think it not just spells out two options, but also the new draft kind of spells in more detail what does it mean? So when you say URL, what a spells out two options, but also the new draft kind of spells in more detail, what does it mean? So when you say URL, what are the implications of processing particular triggers? Even if it's the existing published URL? What we're saying now is that, well, if you are referring, you at DCD and if you're asking DCD and prepare, proposition the URL, what is required process? there, right? And we really handle and published you requests for prepositioning, for example, as a user-directed request, so as if a user requested that. So all the metrics,"
  },
  {
    "startTime": "01:24:01",
    "text": "objects that may exist within the prepositioning, for example, as a user-directed request, so as if a user requested that. So all the metadata objects that may exist within DCDN and control behavior here, starting from plan access control, catch control metadata, source access control with data, crossing stage things of nature they have to be processed before so for example, but way of example, importantly, so let's say you have to transport URL to generate cash control key, and that's something that cash control metadata dictates or to access origin when you're doing preposition, you have to use this authentication information provided or get removed and things of this nature so even if you're not doing private URL, you're doing, which probably default, kind of we are spelling out what the support needs and uh private URL implies that basically DCDN would have to bypass all of that and use URLs as provided without any processing Apologies, Sanjay did you have a question comment here Yeah, a quick clarification question um Alan the the middle box that you show there the DCDN with the four boxes there, are they just an example or you are drawing dependency? on all of the four? boxes that you're showing because they are all right now drafts in different stages within the working group and some of them are not yet adopted also absolutely no so we're not dictating that we're saying whatever metadata is in place that has to be invoked. And I think in the future, some of that metadata kind of will define it better or define additional metadata objects. So what we're saying is if you are asking for published URL whatever is there that would be invoked for user requests would have to be invoked for publish URL Well, I guess what I'm asking is that"
  },
  {
    "startTime": "01:26:01",
    "text": "is this a dependency or this is an example? specifically it's an illustration It doesn't dictate how exactly that's done It's illustration only for this back. We're not, we're not describing how the metadata should be processed Certainly not our place to do that What we're saying is, for example, if you have metadata like this that would be would be user requests. And you see on the diagram, the users, user request on the bottom so saying same processing would imply and we're saying well whatever it is that is defined would have to be would have to apply. Okay um yeah And I'm quickly to be we would have to apply okay um yeah um and um and um capability that has to be advert and that's something that can be only requested in the trigger subject to capability advertised by DCDM Next slide Restful API, right? This is important kind of trigger triggers sort of its old API. So some of the semantics was not Restful initially or not its old API. So some of the semantics was not restful initially or kind of so there are some areas where we look for kind of align it better for restful semantics and also um importantly allow this to be encoded as on open API because ultimately what we want to use this spec is to build open APIs that you know to be encoded as on open API because ultimately what we want to use this spec is to build open APIs that can be kind of just used, right? for for integration and to do that the several changes have to be done so now I think the language also is better aligned, maybe not fully yet, because that's quite a massive text and some of that is maybe left over, but we did make an effort to align it end to end with rest semantics. And the restful semantics basically says that"
  },
  {
    "startTime": "01:28:01",
    "text": "Trigger is a resource that DCDN creates based on UCDN requests. And that's such resource can be created updated and deleted using rest Commet. And things that we allowed and was not feasible before a change, so instead of encoding this in some sort of custom jason payload using just straight HTTP verb to be posed and then kind of with this URL spec And cancellation is not also with some sort of custom JSON object instead of that we say we are changing to cancel a trigger, now you have to modify trigger spec and indicate what is it desired state so if that's you now desire the state to be canceled, you would indicate that and that will be processed as a if that's, uh, if you're not desiring the state to be, uh, canceled, you would indicate that and that will be processed as, as a kind of as a modification request as opposed to custom non-rest command. So that's that's one thing. So cancellation is done by changing the trigger state and the other thing we also allowing now which was not allowed before that as long as trigger's trigger was not accepted for execution, you can also modify trigger spec. So you can actually change errors in the specification And that is accepted and as long as DCN didn't accept it for execution once this is already being executed then that that request would be denied So those are those are the rest changes and I think as a result we will be able to build kind of full restful open API out of this next slide Just a quick comment here that given you have six more slides to go and we've got a couple of other"
  },
  {
    "startTime": "01:30:01",
    "text": "presenters plus the chair discussion so maybe if you can speed up a little bit um yeah i'm good working the time yes absolutely so i think we're 10 minutes so far so we'll be so um So maybe if you can speed up a little bit. Yeah, I'm working the time. Yes, absolutely. So I think we're 10 minutes so far. So one of the goals is alignment was open good uh so um uh one of the goals is alignment with was was open caching in open caching uh we actually have two separate interfaces for managing metadata and content. So to make this possible, we made some changes. So FCI advertising includes endpoints for both, so can I have indicating hey if you want to change metadata, using triggers use this endpoint, and this is a version attached to that And if you want to manage content, there is that endpoint And then accordingly, UCDN would speak to two separate endpoints and potentially even with different versions You can actually use Triggers v1 for configuration and Triggers V2 for content. And this is all done through FCI. Next slide There was a discussion on the mailing list about Sudden identifiers triggers originally had the document had invested quite a bit into CDN chaining use case and support of that and kind of propagation of extensions back and forth and so on. Not a lot of, not every use case requires that, certainly a lot of use cases are there when there's no TCDN, just use CDN and DCDN talk to one another, and also practical deployments do not really use BGP ASN in all cases. So, uh, allow for that, we just made adoption So if you still do using Chaining, you need that, you can have it But generally, I think there is an ask for broad and that's not in the scope of this draft, but I think we do need to work on better CDN identity so to actually replace it with something that would be worked for and then comply with current, you know, implementation realities next slide"
  },
  {
    "startTime": "01:32:01",
    "text": "Trigo labels. Again, making this manageable. So imagine you're doing a lot of ways again, making this manageable. So I imagine you're doing a lot of labels, you don't have a lot of triggers, sorry, so you often operating a lot of operations. So that's a mechanism for really fashioned off the kubernetes labels here is that you'll be able to more labels with custom mark triggers with custom labels and then monitor jell ones you need if this is a public CDN that is acting as new CDN, it may be supported by content, their content provider customers, maybe some semantics of different content groups or sub sub sub of content, just focus on some and especially if you are planning to have a lot of kick customers and operations, certainly very useful feature too kind of create and track triggers using labels. Next And I think that was the last one So kind of the API was electing in terms of manageability is that again, if you are doing quite a lot of operations and now also now we allowing quite kind of advanced configuration around execution what gets executed when, what are dependencies you need an easy way to capture all of that in one a API call and kind of again prior drafts didn't allow for that to look at at all triggers you have to basically get, first of all a collection and then kind of get every trigger one by one This is far from efficient so so we all optionally allowing kind of first of all one feature that you can get all trigger all labels, all triggers in particular state or in particular label and get all of their information altogether and then you can sort of the way you want, as opposed to iterating one by one not efficient and also optionally we can request for trigger statues and ask for object list to be"
  },
  {
    "startTime": "01:34:00",
    "text": "embedded in there and both of them are subject to FCI capabilities, so if DCDN, support this extended capability, then kind of two parties can enjoy efficient messaging exchange here. Again, both FCI, subject to FCI That's what I have. So back to you, Jay Okay. Thank you, Alan So I'll conclude this by covering what's outstanding and what is next here So in terms of what is outstanding, really, I think we're in a pretty good state with the draft here. We noticed that uh there are some minor issues with regard to the cleanup of some older language with regard to CIT trigger command and how it is currently in some cases, confused with trigger object. We would like to make a modification here to make it more consistent so that the trigger command is actually act upon the trigger object, but mostly as language-based issue more than anything Likewise, there's some older language around CIT delete trigger that also needs to be revised as well. But the main thing that I think we need is more reviews. I have a hunch that pretty much the only ones who really looked at this are likely the RFC authors. And we really could use some additional people reviewing this and posting their comments over to the mailing list, as this would be very, very helpful. So nevertheless, that brings us to next steps. I think we can very easily address these remaining outside issues Indeed, we need more reviews And I think we're sitting in a pretty good place to hopefully ask for working group last call fairly soon here So I guess that's all that I've got"
  },
  {
    "startTime": "01:36:01",
    "text": "for the update. Any questions or comments? from anyone? Okay, thank you, everyone Yeah, thank you. I think this is really good, a lot of progress and I agree with all the three things that you have on the next steps here Okay, excellent All right I think next of the list is Citi and I named Footprints, Alan Yeah, thanks. Do you want to request to share? slides? How do I do that? Here There you go Got it, you can go Okay, I'll ask you to change it. So this is a so this is of the there were two iterations and the kind of in the private draft and I think it was it finally accepted the a group draft Next slide So there's not a lot of, I think they finally accepted as a group draft. Next slide. So there's not a lot of, I didn't think there any changes in that should certainly work to certainly work to do here. Just a bit of background and something I guess didn't come before and then discussions that kind of had on the mailing list So kind of the FSA today is defined in 80 before and then discussions that kind of had on the mailing list. So kind of the FSA today is defined in 8008, which treats footprints as attributes of capabilities really even though its name footprints and capabilities footprints are not independent objects, but it also this RFC describes pushing both methods for fci exchange there is no definition of"
  },
  {
    "startTime": "01:38:01",
    "text": "a real protocol in transporting these objects today kind of rfc nine to four two four nine two four one CDIFCI as based on the alpha is actually extension of alpha protocol that separately defined an RFC-7-2-8 As part of that, it's interesting, is that kind of similar person, what will draft proposes, is that it uses kind of addressable footprint and in the part of that, it's interesting, is that kind of similar person, what this draft proposes, is that it uses kind of addressable footprint and it uses alto PID concept to refer to footprint that have become addressable that that kind of eight thousand provide but it requires use of sorry, of Alto framework Separately, what's being developed in development requires use of sort of out of the framework separately what was being developed in the SVTA open captioning architecture work there is a separate implementation of FCS and that's its SVTA spec SVT-8-405. My knowledge has not been actually submitted to CD&I as a working draft but is kind of foundational protocol in the opening cashmere architecture that kind of implements the semantics of 8008 and also follow the same approach of kind of footprints as attributes to capabilities right so we kind of have a fork here of approaches and we have Alto, which kind of takes the right approach of provided naming, but fails, I think, to, to, and actually brings quite a lot of dependencies so next slide So, we do need kind of name footprint. There's multiple use cases that emerge that require footprints to be used within FCI in a named way but also kind of within another interfaces. So it's kind of, you know, longer overdue to have that. And I think I've presented the use case before, we can skip that, but there is a new"
  },
  {
    "startTime": "01:40:01",
    "text": "to have them in a more robust name and consistent way. So when you use using footprints in different parts of the interface, you actually know that you talk talking to the same thing. Next slide right? So, what the draft provides is provides the framework for footprints advertising that is compatible with non-alto implemented, non-alto, provided SVTA. So we don't talk about capabilities, but talk about footprints that would be possible without ALTA. And several features of important hierarchical structure main space support, catching support kind of complex footprint expression so that's kind of nice feature that I think important and useful so I think what's important is next. The next slide is that so okay so that that's draft has been there. I received comments even on the personal draft first and from slide is that so well okay so that's draft has been there I received comments even on the first on the personal draft first and going from near that that kind of embedded in the current version I think Jay provided some comments, so they still need to be work I think the important part of this draft is sort of we need to first of all, in the document, addressing the need for non-alto footprint advertising So this is real need that to do this kind of without bringing the whole ALTO framework kind of so you can actually have that without ALTO Incorporate the common comments So there's a question specific or specific features like, hey, how do we support very long footprint advertising and so on? So either features or maybe just more language to address those comments, sort of the work to do Most important, I think, decision is sort of a so on. So either features or maybe just more language to address those comments, sort of the work to do. Most important decision is sort of is make a call on how that's stands together with broader FCI definition So there is a SVTI document that address capabilities advertising in non-"
  },
  {
    "startTime": "01:42:01",
    "text": "way using rest. So do we pursue this as two separate drafts, one for a footprint? another for capabilities, or we actually look to merge? those two in one scene? two in one cd and i draft because again i think the big missing hole here is that we don't have the non-alpa FCI expressed an SVTA document, we don't have it at CD&I and i and that kind of in the cdi document so that a decision to make kind of I think it's still we can pursue refining the footprints in the meantime certainly work to do there but I think that for the question for the chairs is that do we see this being concluded and published a separate footprint of advertising or it's rather be done together with capability That's all I have Thanks, Alan. Just a quick comment I think probably more eyes need to review the dog document, I feel. Yes, naturally I would say that this is early as well So, so kind of, yeah, so I would appreciate kind of leave and comments Okay, thank you A quick time check we've got about 17 minutes so this topic and this includes three topics and then are none at the end Yes, and I We're going to try to blast through this. All right So this is some work, some discussion topics for some things that have come up in a number of different places The first question is we have some third party references to either products or documents The Hashy Corp, the SBT,"
  },
  {
    "startTime": "01:44:01",
    "text": "and the AWS, these are all basically the same situation. We did, I did a ah, yes, I'm going to pause and let Francesca speak Hi I could have waited for you to finish these slides before before talking, but since we're running short on time, I just want to say that I did bring this to the ASG and we will be discussing it with the legal council tomorrow morning. So I should have an answer for the working group after that And I believe that that counsel is also available like, office hour sort of in person there if Sentry wants to talk to them but I think that I should have a response for you. So it shouldn't be necessary But yeah, I didn't have an answer and now, yeah, I brought this up Excellent We're going to skip to the downrepresent problem then and skip the trademark questions So yeah, Glenn. Yeah, I said one on the trade situation, I just realized the in one of the specs we reviewed today there was that AWS v4 off. Does that fall into this category? as well? I guess we had already flagged that Yep. Okay, thanks So all of these also have a separate problem separate from the trademark question The trademark question is an absolute bar to releasing, so we have to solve that one This one theoretically can be discussed but gown references are highly frowned upon rfc so we have to solve that one. This one, theoretically, can be discussed, but gown references are highly frowned upon. RFC 2026 says standard specifications normally must not depend on other standards track specifications which are at a lower maturity level and"
  },
  {
    "startTime": "01:46:01",
    "text": "then it defines other proprietary standards that have come to be widely used maybe treated like standards but it is proprietary and it doesn't qualify as a standard track document. So that means that we should generally where we can we should avoid normative references to non-standardist track documents. In the event that we need to, we do have an option There is a mechanism by which to perform that It does require AD and IE approval, just like everything else we produce Ben Yeah, so I didn't mean to interrupt you there I just had a, like, once you're finished come back to me. Yeah, all good And so we have, and again, I'm going really quick, sorry, we have uh kind of three options we can remove them from, we can remove all of our third party downright from the document and either standard them using another forum with a registry. Other people can do that Or we can do nothing We could report them with a suitable open standard where one exists Some of the things that we might be have down reference on may have open standards that we can look at using instead. Or we can note the down reference in the document and work with the IESG on approval Very brief thoughts. I see you then Yeah, so I see kind of a difference between reference an external standard and simply mentioning the existence of something So as an example, I'll use the protected secrets that document where we reference HashiCorp Vault, which I think started this whole snowball. There's one of them, yeah And we don't actually use"
  },
  {
    "startTime": "01:48:01",
    "text": "anything from the vault specification as it, where we don't use anything about the vault API the presence in the document is merely an object that says, here we're giving you a URL that's pointing to towards this thing that happens to be vault we just want to identify the type of what this URL is. We're not saying anything about how Vault works or how you interact with that API. It's merely a reference to its existence. And to me, that seems a little bit different than, you know, referencing you know, like a protocol or something that's actually used by the specification. So that, that that my brief thought on it. And I don't, and I don't, and I guess I would say that if, if, you agree with that additional category I don't think that that really falls under any of the proposed solutions Right. I think you're describing a normative versus a non-normative reference, but Francesca? Yeah. Yes, I was going to say that that exists two there exists two type of references, there is normative references and informative references normative references norm make it seem two type of references there is normative references and informative references um normative references uh to make it simple i think about the documents that you have to read to understand the current documents And informative references are more like, examples and things that could be good to read if you want to, but you can definitely skip them I haven't read this document in in detail to tell you like if this needs to be normative or informative If there is terms, what I understood was that there are terms used in this document that come from that, then it needs to be normative because you need to understand the terms if, you know, the terms that you're using. It's not about like, a protocol being defined or anything like that. It can be, like,"
  },
  {
    "startTime": "01:50:01",
    "text": "terminologies definitely should be normative reference um and and something to answer or point out, Chris, that the down-ref process, it's quite simple and we do it all the time So it's not a big deal sort of to specify this down-ref Of course, we should be careful because we don't want to if we can avoid down ref, it will be better, but we have down references in RFCs all the time. And the process is the follow Basically, the down reference are noted during the ATF last call So the ATF plus call will have text that says, um, uh, following might be downward references And then that allows the community that they can object to this unrest Usually there is no objections. And then this this goes through the ASG and the ASG like doesn't have to explicitly approve once these down references are last called but yeah but anyway, normative references should be stable specific that that is important it should be not the equivalent of work in progress or early in standards when possible So that's something to think about. It needs to be something stable and equivalent to an RFC for other standard organization usually is considered fine Documentation for a product product? How stable is it and how open is it the IESG has also had problems. Not open, medium stable Sounds like something to discuss on the list. Exactly, yeah"
  },
  {
    "startTime": "01:52:01",
    "text": "it's it could bring objection yes yeah okay um discuss on the list. Exactly, yeah. All right. It could bring objections, yes. Yeah. Ben? Yeah, I would just say that uh you know along those lines i'm against the removed them option because I believe that having these references to these widely used services vastly increases the utility of these configuration objects and removing them just means that people are going to do it anyway but without doing it the same way, right? right? So that's more discussion that we will have to take to the list for time. Thank you Oh, Francesca. Last thing, one thing to consider is if having it as informed reference would be fine. And then maybe like pull in to the documented parts that that are necessary to read like the parts that may it a normative reference right we might be able to just define what a namespace is in this document so yeah okay briefly um wen lin the cdina um to just define what a namespace is in this document so yeah okay um briefly um wen lin the cd in the uh in the uh melda document, in the processing stages document it introduces the concept of synthetic responses and our charter said that we will not define new protocols for delivering content from an in cd and end user user agent and it says that in the section of the charter that authorizes the creation of our metadata we're allowed to define metadata for the distribution of content, but it does not appear to authorize the metadata for the creation of content And so I believe this puts the processing metadata draft out of the charter scope Glenn"
  },
  {
    "startTime": "01:54:01",
    "text": "I understand what you're saying but I think it's a little much. I mean, so since synthetic response could be a response code. That would be okay, right, for you to configure this configuration metadata to return a 403 But you can't synthesize a response body that has some text in it describing this is a access action or something that i believe to be the correct reading. Yes I would like to respect for disagree with the application of that rule, which I understand to this use case. But Nevertheless, I did not the only one who thinks this And moving this document forward, may be considerably smoother if we consider a minute our charter. And so either we have to remove all the synthetic responses or we amend our charter or we continue discussing this on the list and I'm pretty sure we're going to discuss it on the list Right, or we would dumb down synthetic response to just be a status code but not a body, I guess Pause, yes. That I would categorize that is removing yeah yeah Let's just get to this on the list. Just a quick interjection. If it makes sense to do maybe an interim call that would give us time to kind of discuss this further i'm open to that if that would make sense Absolutely possible To you, Saja for shepherds oh oh okay the so this is the last slide of here's a quick call out for folks that as we are progressing documents"
  },
  {
    "startTime": "01:56:01",
    "text": "and they get ready to be submitted to the IES typically a shepherd write-up is done, which basically describes what the document is what it is solving and who is implemented it's a simple document and um that typically accompanies the draft when it is sent up to IESG and the IESG can read that document as a way to sort of quickly familiarize themselves as to what it is that this draft is doing so the question really here is that for the CDNI working group in the past we have, the chairs have taken that job out writing up a shepherd's document, but typically it is not necessarily that the chairs only do this. So the question here is that if folks are willing to write up a shepherd document, then we please volunteer. And I know we're kind of out of time, so I'm not gonna to take up more time. I can put that up on the mailing list, but essentially that's what I'm asking for Please We've got three minutes Can we have a I don't know that we're going to have a whole lot of time for the conversation but if we can at least present the problem before we go. Yes Iron on? Is Arnott here? This is Arnon's baby? Is he with us? I do not see him on the participant list. Well"
  },
  {
    "startTime": "01:58:01",
    "text": "then we will discuss this entire on the list. This is really some questions of exactly how and and what the purpose and and scope of the private features are and why this group should consider adopting this doctrine There's been a Kevin put a some thought into what and there's already been some discussion on the list So we should continue that discussion if we want to progress this document Yeah, yeah, I think since it might be laid for Arnone to stay on. So why don't we take this back in the mailing list and get it? him the opportunity to respond That sounds like a good plan And with that, does anyone have anything to anything? else in the last two minutes? I'll put out a thank you to our chairs Thanks, guys. Thank you Thank you very much and appreciate everybody sticking in for two hours. So I think we have some items that we need to follow up on the mailing list And if need be, I can think about setting up an interim if we needed to get more face-to-face time. We can set that up like a conference call to discuss that. But let's can talk that in the mailing list as well to see what's the most effective way for us to come to closure on the issues that Chris that you brought up And also we'll wait to hear from franchise on her conversations with the legal team Indeed. All right a lot of this conversation soon Yes. All right. With that uh, well, thanks everybody and we'll talk to you over the"
  },
  {
    "startTime": "02:00:01",
    "text": "meeting list thank you thank you bye Thanks. Bye-bye And Sanjay, I have captured as much as I could in the dock while we were going, but I spent a lot of the time talking and was unable to capture a lot of my notes I put them in the standard notes doc for for here. So I created the heads doc. Were you able to see that at all? or no, or is it just me that's seeing it? I see one It's this one dropping it in chat And that's where I put the notes that I was able to snag What did you send them? I dropped it into the chat here Oh, let me go back to the chat. Looks like I closed it I can send it to you separately. Okay, I see okay. Oh, good. Yeah Oh, okay So this is, so it looks like there are two versions one I created, when you created, huh? Neat. Well, I'll let you write them Was that? I'll let you reconcile them All right, so I'll cut and paste my comments here and then I think we should be good So we'll take your document as the document Okay, that's the one that popped up when I clicked the note-taking tool. Okay no, that's good. I don't know why mine showed up here all right let me let me let me fix that I'll do that right now Very good"
  },
  {
    "startTime": "02:02:01",
    "text": "All right. Thank you and I'll see you on the list. Yes, thank you so much Bye. Thank you"
  }
]
