[
  {
    "startTime": "00:06:54",
    "text": "check-check there we go all right well welcome to see Bohr um anybody who is going to participate you might want to come a little bit closer to the front so you don\u0027t have to trot up to the microphone can you hear me through the mic alright um so I\u0027m Joe Hildebrand and this is Francesca Palin beany and so here\u0027s the coordinates to participate do we have any remote participants on jabber Christian okay all right um if your remote and you can hear me and you need something related to the microphone we\u0027ve got somebody who will do that for you prefix your your jabber with em IC : and he will relay it for you that\u0027ll be Dave Dale are doing that the etherpad is on here I think that now this URL should work great all right please note well hopefully you have seen this more than once already this week but they\u0027re participating here you have certain IPR and other requirements too so bye-bye please read this and understand it and make sure that you\u0027re following agenda so this introduction bit we\u0027ll talk about cuddle for a while for about a half an hour we\u0027ll talk about the status of the Seaboard draft and then we\u0027ve got the oid draft and a techhdarre draft to talk through and then there\u0027s one that I haven\u0027t read and should called time tags and then we\u0027ll wrap up anything else that people want to put on this list anything that people think we ought not talk about great I\u0027m gonna take that as good then all right so do you want to talk about status jam you keep talking just a quick status update since Prague so CDL was updated after Prague and Caston and Hank are gonna present some issues that they would like the working group to decide on then about the Seaboard it was recently updated and to check that you can also check the github because that\u0027s where the latest version is there is still the implementation matrix to fill I I have pink the main "
  },
  {
    "startTime": "00:09:57",
    "text": "list the only one feeling in was Jo so I think Karsten is gonna is gonna talk about that a little bit but please come forward if you have implementations and please go to the to the wiki and and filled it in so it\u0027s pretty bad if I\u0027m the only one who\u0027s actually done that work because I haven\u0027t done a whole lot else so there is JavaScript in my notes Ybor that will generate the HTML output if you want to use that as a starting point so it didn\u0027t take me that long I think it took me maybe an hour and a half including getting all the formatting so there are some tests in there that you can use as you know here are some inputs and if you can process those inputs then you\u0027re probably in good shape now I don\u0027t implement all the entire set of extensions and tags so hopefully you know somebody else will have implemented things that I haven\u0027t okay about the tax documents so this is so there are two two drafts and about tags that are in the Charter and now so the CDL and see bore our working group documents right now and the tags are not yet working group documents so we need to talk about that and we need to see what is what\u0027s the status for those and here I just reported what you can see the data tracker about when where these documents last update and then we would like to hear from the authors about what they think they need it\u0027s still needed to go for adoption and and/or then working group last call so for the OID tags there has been no update since March so this document probably needs feedback we have asked for it and we even yeah the past couple of meetings so talk about that and about the array tags it was updated after Prague still needs still need reviews I was going through the minutes for the past meetings and noticed noticed that some people promised reviews last meeting did not provide maybe forgot so I\u0027m just gonna remind it here Jim and Paul promised reviews on this document it\u0027s it\u0027s short it shouldn\u0027t you shouldn\u0027t take you long but yeah so we\u0027ll talk about this one too I think that\u0027s it from us and I\u0027m going to start with CTL "
  },
  {
    "startTime": "00:13:01",
    "text": "[Music] if I tip over you have to catch me okay so um what\u0027s this no no it actually works does anybody know how to run this on you has something to do with it not being switched on okay so if you can try switching it out it worked after switching it on in the car meeting so I think it really just needs to research on okay so just reminder of what this group is about we are supposed to take our c7 349 to standards level we are supposed to standardize the standardized CDL and do a few tag structure nuts so that\u0027s what\u0027s currently the Charter and I run through this in three parts the first one is about CD DL so I\u0027m not sure Hank is here because he has a conflict with net conf so I\u0027m not sure you can make this meeting and and christophe is in raven unfortunately so just to remind people what CDL is about and give a little bit of a tutorial that is probably needed to talk about the actual issue that we should discuss today we have been using BNF since RFC 40 so that comes quite well together with being at ITF 100 this has a tradition and for about forty years we have been using a BNF the Augmented BNF that can hair enstein developed for the mail every day I think so this is something we have some experience with and there are 750 to overseas that reference the the a B and F standards RFC so one could say this is a successful our see it\u0027s even more successful than yang which is currently referenced by 160 ourseives there is some tool support it hit the a "
  },
  {
    "startTime": "00:16:02",
    "text": "B and F form it hasn\u0027t taken the world by storm but there is support we have our own tools like Bill feni\u0027s a bap and a B and F Gen but also will establish pathogen rater towards like endler as supported and it\u0027s just normal in the IDF if you do a text-based protocol you write in a BNF spec so this is our role model here we want to be like a BNF and actually that not only works on on a high level but also on a technical level a B\u0026F is composed of productions so you have something like an address specification and that is a local part followed by an ad side @ sign followed by a domain so what these a B and F routes do they give names for sublanguage \u0027as and then you have two kinds of composition you can compose by concatenation like like this does here from catenate in a local party net sign in a domain all you can compose by choice and this nesting structure then at some point terminates at literals like the add sign here or we add a B and F notations for literal so this just means all ASCII characters between 33 decimal and 90 Jason okay so this production based way of constructing languages of course has been with us in computer science since the late 50s when John Becker\u0027s invented it for for Fortran and what we need to do to use the same technology for Jason and see where our data structures is to apply it to trees - trees of data and not to text strings so given that the data that we are using are integers text strings binary strings floating-point and so on we have to add literals for those primitive types we not only have text strings we have these other things as well and we have conveyed constructors for the to container types we have in JSON and C were the V arrays and maps and the whole thing is inspired by relax ng which was the the schema language for exam is done right you probably know another one and yeah I\u0027m not going to comment on that one but relax and G has done some some interesting work here too so in CDL rural names are types you can write something like boolean is either a false "
  },
  {
    "startTime": "00:19:02",
    "text": "or true and then you have a boolean type followed by the way is also a type which has just one number the value falls you could have something like label which is either a text or an integer this would be an application specific type or an integer is actually either an unsigned integer or a negative integer in C bar so types are just sets of potential values and literal is just a very small type so this little one here is a type with the one member in it which is the number one and then there are there are other ways of writing these types for instance one two actually means a type that contains the numbers one two and three so that\u0027s one part the other part that feels a bit more like an ABN F grammar is the groups the groups allow you to write down sequences of items and these sequences of items can then be used within arrays or within maps so the interesting thing about the group construct is that there is a single construct for both defining maps and arrays and of course maps and arrays are very different maps have a label the label is ignored when you use the group within an array and on the other hand arrays have a sequence which is ignored within maps so groups are grammars for key value pairs and keys and values are types so this is where the circle closes you compose groups of types and you compose types if they contain arrays or maps out of groups so that\u0027s essentially the whole technology behind CD DL and the result is that you can write something like this this was one of the first examples when we read RFC 1771 we were annoyed that they had to define a special stylized form of English to define their JSON data type which takes I don\u0027t know four or five pages and so this is the technical content of RFC 7:07 one on one slide so what we have here is a name for a type the type is reputation object we have the map or JSON object braces and then what\u0027s in here is a group which says you can have the label application with a value of text and I\u0027ll show you you must have because "
  },
  {
    "startTime": "00:22:02",
    "text": "there\u0027s no question marks there and you must have labeled reputations which has an array of zero or more refuge ins in it and the refuge one is this thing with some mandatory parts and some optional parts and a wild-card at the end that is there to express the extensibility and that\u0027s really the heart is the one thing we have to talk about so yeah these groups get names like types get names so when you look at it CDA documents superficially you may not always be aware which name is a group and which name is a type but generally that that becomes clear from the context so just to give an example of why we want to finish this now there is this draft in the RFC editor queue which is called draft IETF enema grasped 15 dot text and that draft is done and it\u0027s just waiting for for CDH to get published so we we already have specs out there that have references to CDL some informative because they just repeat the specification and some normative like the grasp specification and we want to make sure that we don\u0027t destroy this specification by a changing CDL in in a major way and there are a few more the FC SDI was outside the IGF which cannot be named in this room but you can guess three letter and longer acronym who that might be so yeah we don\u0027t want to break it and we don\u0027t want to put in the kitchen thing but currently is one of the two focuses is getting the definition of the semantics of the language unambiguous so tool vendors come in and say yes we can implement that and one new thing which isn\u0027t in the internet draft yet it\u0027s in the topic branch in the github is appendix B that is called matching and it summarizes the matching words that are used by CD types and groups in a short way it essentially just goes through the ABN F of course CD DL as if it\u0027s a texture language as defined in a B and F and it goes through that a B and F and for every CD I construct that exists it concisely summarizes the CDR it semantics and what we need to find out is whether that new appendix is useful whether it is correct "
  },
  {
    "startTime": "00:25:03",
    "text": "and whether it is complete so that\u0027s something where where it would be really useful to get reuse on so if people think it\u0027s useful and I think the mailing list has had pretty much a consensus that it is useful we would put this into the next version of the draft so that\u0027s one area of work the other area of work is actually making technical changes and so far the appetite for that has been limited so they have been few people who said I have said we would like to change this and Dad except for one area and the problem comes in when you add a wildcard to some existing map definition that\u0027s why it was discussed under the heading map validation but it\u0027s actually a more general issue so since this is a productive language based on the same concepts as a B and F these two parts of the group are taken separately they are not interpreted together they are just interpreted as they are and the language is then constructed by taking these two two parts together like like in a because now nonfarm you you know so this has we might have an entry in the map with a key of four and a value of type text and we might have any kind of entry that has an unsigned integer as the key and any data type because we don\u0027t know yet how we will extend things as a value so that\u0027s generally fine however really what what like one what one would like to explain here to express here is that the fall is taken so we don\u0027t really want that other guy here to say oh by the way you also can have a key of four and any value because the the falls already taken with us now a grammar mathematician will tell you oh you are making the grammar context-sensitive and that\u0027s exactly the reason why we haven\u0027t done this yet context-free grammars have advantages of a context-sensitive grammars but the discussion on the mailing list was this is really a feature we would like to have it would really be useful if we get an instance that has a key of four and a value of floating point would really be good to have a validator throw an error for that instead of just accepting it because it\u0027s captured by the wild card now how do we fix this there is one possible "
  },
  {
    "startTime": "00:28:04",
    "text": "answer and this is a slide I have used last time in the list of kitchen things saying things we might want to add which is cuts cuts is something that is it was initially defined by the Prolog programming language and recently has become an item of interest for people who do pause expression grammar pauses so BNF started out just as a language for defining things then the theory was built around that and two theories emerged one was way too complicated way too expensive to implement the past expression grammars so the theory veered off into LR and pauses and so on but in the meantime people have started to do a pause expression grammars again and the example here is we have a data type a which is either an ant or a cat or an egg and the ant is an array with the first element being ant and the second being an unsigned integer cat text egg float no the yes yes oh yeah this should said okay that were true then this would be right so sorry about that so the reason why we started talking about cuts in the office team was that we wanted to have better error messages because right now when you put this into the CDL tree it doesn\u0027t really have a good way to tell you what went wrong it just says this is not an a it is not going to tell you oh you said and and after an end you really should have put an unsigned integer and this is what these cuts are doing they essentially committing to a choice that has been made they are cutting down the rest of the search tree by saying oh if you actually saw the word and then really all the other rules that are in this choice don\u0027t matter because this is the one you should be choosing so that means if you get anything but a you ain\u0027t after the end you know this is wrong and you can say there should be a you end there so that was the the reason we wanted to do cuts and that was a good reason but maybe not good enough for for putting it in now the interesting thing is we can use the same construct to handle the met validation issue by essentially inserting cuts between the keys and the values of an item in a group so this would mean if you match "
  },
  {
    "startTime": "00:31:06",
    "text": "the number four and you can ignore all the other alternatives for matching this particular video pier in the map you are done and the only value that is allowed here is X so that\u0027s the this button okay thank you so this is of course a little bit noisy so this would come with a proposal to make the existing : shortcut include that cut so when you say for : text this means you really mean the for is taken by this particular production about this particular part of it so that\u0027s the proposal now this needs to be fully defined those people who know about the theory know that when you do a cut to reach up the tree and you actually find how far you reach up it may seem obvious here but in more complicated examples it has to be fully defined that\u0027s one thing the second thing we want to do is checking for breakage that this change makes and the third thing of course you want to do is implement it to make sure it works so this is probably month of work that is needed to make this happen can L demand from the floor uh do you have other proposals or is this the is this the only one you\u0027ve got I don\u0027t want to start I da ting if you\u0027ve got other things you want to also suggest instead no this is really the main part of this segment so I mean if what you\u0027re really trying to do is get the extensibility bit and you\u0027re having a sort of retrofit this in just for extensibility like I get the the the aunt example you\u0027ve got there but like do you want the aunt example enough to make extensibility it seems relatively complicated from a theoretical perspective compared to like the cognitive load associated with this is relatively high compared to the rest of the document yeah because we\u0027re leaving the context-free part and entries I mean but there are other things you could do to get extensibility if you just wanted extensibility so for example at the end of the the end curly bracket you could put something else at the end that says by the way this is extensible in some way like in for example you could you could have in parens after it some sort of type statement that says what you how you\u0027re allowed to extend okay hi Sean Leonard so uh a couple of proposal I want to "
  },
  {
    "startTime": "00:34:07",
    "text": "bring but I want to first address this pretty clearly so I think it\u0027s valuable as discussed on the mailing list to have some way to either cut or constrain the type Carson and I actually worked on a related problem with this in the context of a B and F and I would like to propose that we consider an alternative way to get the same results namely allowing the broader definition right the mapping from the broad type to to anything but then also have this subtype that\u0027s more constrained right so one way to do it is cuts and that\u0027s already been presented another way to do it would be to have a constraint notation so that you have you int maps any write in the map but then as a subclass or as a constraint of that it\u0027s possible to define specific instances of the U nth such as for and then the matching type on essentially the right hand side and the difference is that with a cut as I understand it it\u0027s it\u0027s a way to essentially to produce better error messages right because you you take that point of the parser of the tree you output the error message and then you backup right essentially so then it doesn\u0027t match however another way to look at it is that the data production still does match the broader type you went to any okay but it just doesn\u0027t match the subtype so then a parser on the fly or during production will know that it matched the broader type but not the subtype and then the application can treat that as either an error or as something that\u0027s potentially recoverable where the consumer can then just realize okay we have the broad match but not the subtype that we were looking for therefore the data item is in is deficient basically and get the same result so do you know that would be there is another control operator that is in CD DL now called within or and so it would behave in a similar way I guess I can propose another way to look at this I have a draft in the a B and F context which is a draft chantek constrained a B and F which ironically uses the Hat so it\u0027s very similar notation but the notation would be something akin to you int map to any and then hat and then your list of specific matches such as for : text 3 : whatever and so forth that could be one we do and while still keeping it a context-free grammar that\u0027s that\u0027s also that you would wrote the the controller first yeah you you would write the catch-all first and then you write the specific instances that also match the catch-all "
  },
  {
    "startTime": "00:37:08",
    "text": "so you\u0027re constraining the generic production to these specific instances of interest and if it doesn\u0027t match the specific instances of interest then that\u0027s a condition that then of course a program can can process or deal with that it match the general thing but not the specific thing so it\u0027s in the catch-all it would be interesting to see a proposal right now my cognitive load gets up because I suddenly have something in CBD area where the thing that comes later has a higher priority than the thing that comes earlier everything else in CBL is the other way round but yeah that could be done okay good so maybe we should work on that then as we look at alternatives to this because I do see that there is a use you know that\u0027s broadly applicable to a variety of users the problem is that that this type here without the Hat is not matching so if you subtract this type from that type then then four column float is still in my the parameters right to process this type and remove the video information and just keep the key information before you can construct the the remainder type that you are subtracting from from the katralla type right I don\u0027t know how to do that right that makes sense although if the remainder type also matches all of the other specific types you can first match the remainder type which presumably would also be relatively cheap relative relative to going through the list of specific matches and then going to the specific match the cup is essentially a way to construct that remainder type right so we would need it in that case as well so we can be willing to write this in a pool request or something in the github I can yeah I can try at least that yeah and actually I want to take this to remind people to participate in the mailing list because we\u0027ve seen very little participation and the working group seems interested and active but in the face-to-face but then I would like to see more discussion in the main unless then I cannot keep like for like trying to get people to talk you need to him so I have I have other proposals but before I get to those proposals I\u0027ll step to the back Jim shot the first problem I have with this is you all sudden became extremely order dependent which means no bill radula hi we already are this is a puzzle expression Grima it does not matter in the current grammar if I do "
  },
  {
    "startTime": "00:40:08",
    "text": "the star first or the four first that that there those would be equivalent in the grammar this is not true anymore and even worse than this is you now have the question of if you have group one which ends in the star int you int points to any and then you say and now append group two to it all of the cuts in group two won\u0027t ever be seen because you\u0027ll hit the star you end yes we cut bit and that\u0027s because of the order dependence a look so that\u0027s the first problem I have with with all of this the second problem I have is I don\u0027t understand why this needs to be expressed in the grammar and cannot be expressed in semantics this is commonly done today for example if you have an email headers I can\u0027t remember for sure but I believe that they leave part of the grammar says you can\u0027t have two of these that\u0027s not in the grammar that\u0027s in the semantics so I don\u0027t see why this can\u0027t just be expressed in semantics rather than the grammar but actually the the you can\u0027t have two of these semantics of maps also is expressed in English and not in the Rima but I\u0027m not and don\u0027t know how to do this I mean if somebody would come up with a reasonable proposal that actually works that would be great I think an edit of this document um first of all if there are good proposals and it\u0027s basically what you just said so busy took some of the words my mouth that can express this as a control to this type definition very interested to see your proposals for that and then coming back to Joe\u0027s comment this is why it looks like this is about extensibility it isn\u0027t it is about the fact that sometimes we have the problem that there are more very defined keys and less defined keys and maps if it would be about extensibility we would use the extension points there are extension points to our choices there we could use extension points here we could use as we could you\u0027ll end with an extension point just as you proposed it is already in CDL but that is not what this is about this is about effect that we have sometimes layers that are less specified than others and those would be basically gobble up all the voyage identified Labor\u0027s so if this can be soft Bob via a control and we were already considering that actually we\u0027re really happy to have a proposal for that and compare it but after a really long "
  },
  {
    "startTime": "00:43:08",
    "text": "time of discussions we basically ended up with making the : they explode something to you if yeah it sure can you solve through the control yeah that\u0027s easy yeah hard part is solving it with the control in such a way that you don\u0027t have to write everything twice yes yes exactly so that is that is why we did this redundant one of the design principle is less noisy and this is way less noisy because it\u0027s basically looking like before it just has some added semantics Jim - okay great sean leonard all right um I did want to draw the working groups attention to a couple of other proposals that have come up with regard to see DDL and and the grammar specifically the proposal that I wanted to make or discuss had to do with regular expressions so I did bring up on the list a few months ago the issue that regular currently are defined as pcre which is great because I think pcre is a great regular expression implementation and everything else but there isn\u0027t a normative reference in CDL or in seaboard to that and I think that that is something that should be addressed in both documents because both of them do in fact reference regular expressions then because of the power that regular expressions have to identify and constrain the different data productions I feel strongly that regular expression should be first-class syntactic elements inside of CDL so for example just as you can do in Perl or in JavaScript the way you write a regular expression is you do slash and then the regular session content and then slash and then usually if you have a editor that its language aware it\u0027ll color the regular expression and show you interesting stuff about it and and so forth so technology is all there right now though it\u0027s defined in a string and the problem is that when it\u0027s in a string there\u0027s a ton of escaping right of back slashing that you have to do to make that work so I wanted to bring that up to make regular expressions a first-class syntactic element another advantage of doing it that way is that then you can add the flags or the modifiers such as I and X and so forth on the end of it yeah because otherwise you essentially have to construct two strings and then put them together and then it\u0027s it just doesn\u0027t look it it doesn\u0027t look good and that that alone the conciseness will will help I think a lot with readability and it\u0027ll help identify and catch errors and such so yeah so that\u0027s sort of on the table Joe Hildebrand from the floor I like the idea of slashes as a syntactic element and promoting regular expressions first class if we think "
  },
  {
    "startTime": "00:46:09",
    "text": "they\u0027re going to be used enough to warrant that it\u0027s a it\u0027s a nice affordance carpenter user of cedar Dale I think these are all great ideas Percy DDL version 2 I would like see detail version 1 as a normative reference next week please so I wonder if you could think about taking that approach yes I did and then I found this I sympathize with you wanting to do this but I also then but you\u0027re a co-author on the draft that\u0027s waiting for it right so you see the point I mean if you can if you can think about doing this as a version 2 effort that I think that would actually be probably better for seeded Yale because it gives it a place in the world and you can then work on improvements so the question first it was this point to the this the carsten were custom presented proposal and what then was this a comment to Sean well both of them really I mean I don\u0027t see any of these of not being backwards compatible with existing CDLs so it wouldn\u0027t invalidate existing CDL files it would be additions so as long as it\u0027s strictly backwards compatible I you know I think you conversion it any day you want you can say today is the day we version it and and then put the next lot round of things in version 2 so it\u0027s really a choice when you do that ok Sean Leonard related to the - all the things that were just mentioned is a concern I have with the control syntax or control operators and how I think they could be made better both by the regular expression syntax and address I think some of these kind of CD DL v-0 v1 issues so I clearly see the value of having the control operators that are currently defined in the draft right for example the bits the bits is it it is control operators write bits regular expression and then size and a few other things but in some ways they\u0027re too extensive and they\u0027re not powerful enough at base however I\u0027ve read a number of CDL specs in drafts and RFC\u0027s or whatever that have floated around I\u0027m not aware of standards or specifications out there yet that are relying on them normatively we\u0027re removing them or taking them out and tweaking them is going to cause real interoperability problems one point about the control operators I want to point out is the size control operator so right now with size you can define it "
  },
  {
    "startTime": "00:49:10",
    "text": "as a single size or you can define a range I believe right so it can be like three to 63 bytes in length or whatever it is so that\u0027s fine but I have use cases where I want to be able to constrain the size of a string or a byte string to basically mod to like only even numbers or only powers of two or whatever okay just because that\u0027s those are the increments of the data items I can do well interestingly if I use a regular expression constraint I can actually do that very powerfully by just saying regular expression has multiples of two right a group of two characters or bytes and then plus essentially or multiples of two I can\u0027t do that with size and I think as a result if we adopt regular expressions in their more powerful form right with the slash notation and whatnot we can actually find that there will be control operators that may be superfluous so we don\u0027t need them at all and we might want to you know make all these control operators simplified and just say just use regular expressions and here\u0027s like a handful of very powerful ones that you\u0027re going to commonly use for these sorts of patterns um so with that said that\u0027s kind of another proposal on the table not to remove the control operators but to recognize that there are perhaps more powerful simpler ways of annotating the same thing and if people really really want a v-0 or a v1 of CD DL we can consider you know dealing with the control operator issue after the publication of that so let me answer that because it\u0027s really confusing right now ring exposed rings okay so yeah so I wanted to point out as well reg axes are for sequences of code units so you can just have a binary regular expression that operates on a tetes from 0 to 255 as opposed to regular expressions that operate on Unicode code points from 0 to 10 ffff yes right no ringer for Strings right my view actually is that reg X\u0027s could be applied to both byte strings and text strings and that and that they you know they just have a different domain in the case of oxides it\u0027s zero to achieve this and what we have tried to do is not turn CDL Interpol so reg X is are there for the few cases where they actually add something but they are traditionally not a way in which we specify the strings in the IDF now one way to solve this problem would have been to add a B and F to a CDL and "
  },
  {
    "startTime": "00:52:12",
    "text": "maybe in C Drive version 2 we will do that but I think reg X therefore for a narrow domain and they should stay that way and I don\u0027t know how to do a grandma that does this such thing so I have to pass on that okay I guess I would just say that regular expressions are a part of C DDL and they\u0027re a part of C bore too because they\u0027re in you know RC 70 49 so and a lot of people do in fact use them so although it\u0027s true the ietf has not defined them that way I\u0027d first question do you really need I maybe I should ask the group or you know whatever have people been using the control operators to constrain their specifications important critical way where it\u0027s like actually normative and have they used regular expressions in that way as well because regular sessions do in fact appear with some frequency in other specifications users Jim or no too hard he says um this is Hank as a user and yes I have used controls from the working group so I think Shawn had raised this before in the mailing list but please take it up again and we will and users please respond to this email okay then why why I stepped up to the mic the first place was that I had a difficult time to parse the statement powerful and simple so my question really is you don\u0027t want to do this now take take this leg out of vacation and they fix it to the head even is this useful do people think this is useful then the next question is the proposal that Shawn just made about record then and then we can talk about is this something to do right now how long would this take and if this should be something for next version or not right so in response to simple and powerful how can that work right well there\u0027s always a holy grail of computer science you say something simple and powerful and then it turns out to be one or the other or whatever and the answer is regular expressions are simple when they\u0027re simple and they\u0027re powerful when they\u0027re powerful right but they are a part up to now of CDL and C bore right the existence of C DDL in its current draft form assumes that AC DDL generator or a "
  },
  {
    "startTime": "00:55:15",
    "text": "parser or validator of some kind that can form suspect will do something with the regular expression right so that basically assumes that pcre is lying around does that make sense so assuming that you have this piece of machinery that\u0027s part of C bore because it\u0027s in the the specs right then that\u0027s what you got so you may as well make the most use of it does that make does that make sense yeah and one question that I don\u0027t have on the slides that maybe Aleksic and can answer so PCR II is not defined in a normative document that we can use it also is the right spec to reference here as shown probably correctly as identified so I\u0027m not sure whether I want to be a guinea pig for the new let\u0027s reference over source projects policy of the is G but this is where it actually would should I need to check I vaguely remember there was one of the save documents that has regex extension so I can find out what it used there so if you were willing to take a slightly less powerful version you could reference one of the ACMA Docs and use Java the JavaScript version they are adding look behind and so you could for example take that that there\u0027s some rather weird Unicode stuff going on with those so if we can avoid reference that I\u0027m just saying that they are a there\u0027s there\u0027s there are standards Docs to point you there which is better then not having something to reference let me try to find the document and and then we can have a look whether it\u0027s a good example or you know at least it\u0027s an example yeah and finally my concern with having accepted the let\u0027s assume we exchange controls in general the powerful and simple reg X we are talking about a domain where if we are ever going to do message validation actually that\u0027s that\u0027s kind of kind of true a bunch of an overhead maybe and that domain so um I would be very careful about the pole for stuff and that domain yeah so the way forward if Alexei finds out we cannot do this records currently linked into the document using an extension point and we can just throw out vague excerpts out of this current document finish it and write a second document that has the regs reference in it and let that sit in the internet drafts "
  },
  {
    "startTime": "00:58:15",
    "text": "directory until we find out how to do it all right we should move on other things okay yeah i okay that that sounds good I would just say as I pointed out not just reg X but all of control operators if not because they\u0027re not useful but because maybe we don\u0027t need them right now there is no control operator that it\u0027s not used by at least one it\u0027s you know I know you want to stop this but I\u0027m confused by something it ultimately the validator I want to be in my embedded device oh sorry Dave Robin maker of embedded devices I want to get a c-more message in I want to be able to validate it based on some compiler that looked at the CDL and told my device how to validate it now if you can say everything can be replaced by one gigantic reg X expression then I\u0027m going to give it to a human to figure out how to actually write the code to do that validation because I don\u0027t have a reg X interpreter in the embedded environment so let\u0027s not go overboard and say we don\u0027t need CDD Allah just one big reg X expression so the the the opt the constraints are easily turned into embedded rules don\u0027t go crazy with things that can per set those constraints those constraints can be easily turned into embedded rules next so the CBO specification itself as you know our job is to take this to standards level and there are several things we need to do and there is a process you find in RFC 64 10 for doing that so those are you who are not familiar with that process please have a look yeah we have some 45 implementations so it should not be too hard to point out to independent implementations whether they are interoperable that that\u0027s what we need to find out is as Joyce said we have fixed the errata while looking at interval T we can look at whether we have unused features and as far as I know we don\u0027t have any patent claims that are known so far so the status of the document is that they\u0027re zero zero had already fixed the errata and - l1 has reacted to a few comments that have been made by implementers one is that the the way the simple types like false true null and so on I encoded is said again in another place so it\u0027s harder to miss the way they are defined we added a changes section maybe in the next version we will separate editorial changes fixes and a new information from each other and the only "
  },
  {
    "startTime": "01:01:15",
    "text": "real new material is the new section about SIBO data months and there we shall quickly talk about that so those people who have worked with Jason and we like it however it\u0027s not always clear what the data model actually is that is being derived from a JSON instance and if you really paid attention you could infer the SIBO data model from our c7 t49 but maybe it\u0027s better to actually make this very explicit so there is a proposal for a new section 2.5 which is called generic data model generic because it\u0027s not about a specific data model a specific application might be using but it\u0027s about the complete set of instances that can be realized in recibo and that generic data model comes in two parts one is the unexpended basic data model and the other half is the extension points of course given that the extension points are therefore extending zero that data model is not closed people can come in and define new parts of that data model but this simple document already comes with 18 predefined tags and for simple items falls through now undefined and of course there are now a couple of dozen tags defined in an Ayanna registry so this is probably a useful thing because the generic data model makes it more explicit what we actually expect from an implementer of generic encoders and decoders because an encoder decoder translates between the data model and the serialization and it\u0027s not enough to just specify the serialization if you expect generic encoders and decoders to interoperate and an ecosystem of such generic and coastal decoders makes interrogatory so much more likely and also guides the definition of specific data models because you won\u0027t define data models in such a way that generic encoders and decoders have problems with that so this is one edition which could be called editorial except there there\u0027s also a little bit of text in there that clarifies some expectations and the batteries included aspect of our FC 1749 is not not appropriate if you need to ship C bar by ma so sometimes you have to leave out the batteries and the question is which batteries do we really want to have "
  },
  {
    "startTime": "01:04:15",
    "text": "India which of the pre extensions by the document are really basic and section two five now clarifies that the three simple data items false true null do come in through an extension point but they are really not an extension they are part of what is expected to be provided in a generic encoder and decoder that still doesn\u0027t mean that a data model that you define using SIBO has to use them but it means if you write a generic encoder decoder please include false true or not and everything else is truly optional and a matter of implementation quality so that\u0027s a statement and that\u0027s probably a state where we want to be very clear about in this working or whether that\u0027s what we expect from generically coders so again this is a relevant vent for interoperability because this ecosystem of generic encoders and decoders helps gain gaining interoperability but it\u0027s not a 2119 type of must or must not it\u0027s just an expectation and we historically have had a little bit of a problem in in the IDF managing these expectations so it\u0027s a little bit of an unusual way of specifying yes okay so if you have any comment on that that would be something that that would be really useful on the mailing list or on the microphone but I don\u0027t get maybe it\u0027s just a type of Sean Leonard in your slide it says anything else including undefined is truly optional but in draft oh one which is posted undefined is actually in the third category of it has to be supported yeah at least that\u0027s what I just chant fix that but so which one are you proposing because it seems that posing false true and no just these three as core elements and everything including undefined as option okay I think I think undefined is is useful to in the prior category that\u0027s just my two cents for I guess there\u0027s a difference between null and undefined especially when undefined is used for items that didn\u0027t decode properly or whatever you know it is where as null is like explicit no I probably have a recommended set I would give to an implementer that includes a couple of those tags and and undefined and a few more things that they should be doing but this is trying to say we really expect people to do the jason-3 false true and so if people don\u0027t other people in the room have comments right now otherwise we can move this to the main list and hopefully get feedback there "
  },
  {
    "startTime": "01:07:20",
    "text": "okay the the other thing that came up as you know we have a few implementations out there last time I looked at it was 45 it\u0027s changing every week now and we haven\u0027t got a lot of feedback about interoperability problems but we do have one and that is really not a problem in SIBO it\u0027s a problem in the world we are bridging two which is the base64 world that has had a little bit of an evolution since base64 was first defined for mine and we probably haven\u0027t been tracking that evolution very well so we have four tags defined that have something to do with basics default two of them alpha basically for us which is what you would use today and two of them are for base64 classic and there is no known problem with the basics before URL once but with basic C for classic it\u0027s a little bit more fuzzy and right now we are very clear in the definition of K 21 that basically for URL is being used without padding we are not saying that explicitly for tag 33 so that may be a problem but then RFC 4646 about that the basic C for classic tags 22 and 34 they reference 46 48 but 46 48 only has essentially decision criteria if you are using base 64 those are the reasons why you would might want to use heading and those are the reasons why you might not want to use it yeah so what we have to decide first do we really mean tag 33 to also be limited to basics before you are without padding and I\u0027m pretty sure that we do want to do that but we merge short make a conscious decision and on the the base 64 classic side we have to do a few no-brainers like saying we don\u0027t really expect whitespace in there or we don\u0027t expect line length limitations which some basics before implementations have but it\u0027s probably not sufficient to just say anything goes in particular tag 21 and 22 intended to be acted upon by a civil to jason converter which might be generic so it has no idea what the application requirements on that base 64 are so we have to tell this generic converter what "
  },
  {
    "startTime": "01:10:21",
    "text": "kind of basics before it\u0027s supposed to generate so the problem is really urgent for the tag 22 because people cannot implement this right now without the knowledge they have to pick a choice and you shouldn\u0027t they implemented big something and the second thing is yeah tag 33 and 34 just say Jesus here is a text string and by the way the semantics of the text string is a 64 a 64 URL or basics before classic now this could be interpreted in a more permissive way because the tank just provides information and we could be happy with that information being it\u0027s some kind of basics to follow we are not going to tell you which one but then it also is a little bit harder to do a conversion conversion through JSON where the JSON data model on the other side might have more strict requirements on the base64 so these are two different but interrelated sets of problems and this of course should be guided by how a 64 classic and URL are being used in practice now basics before URL is almost always used without heading and remember having seen once a version with padding but I\u0027m not even sure that that was standards compliant so into ability might benefit from really nailing this one down and on the basics default side it\u0027s pretty much a bike shed so it\u0027s not really possible to decide this well yeah so we could be more explicit about tag 33 we could be fine tag 22 and 34 as with or without we could also go ahead and define additional tags base64 classic with Betty without padding with up to 70 characters per line probably not and oh by the way there\u0027s also a question that that occasionally comes out about base-16 so you can write hex strings in uppercase and lowercase but that\u0027s the side track right now so my proposal would be to actually read 46 48 which tells us heading was designed to help with situations in which the decoder isn\u0027t quite sure about what the length is in C bar we always know the length so it\u0027s really the no padding case from 46 48 that we have here now again the J\u0027s inside of a potential automatic conversion might have other constraints so maybe the JSON side then next converts into a mind message or something like that so this is not not a perfect argument but it\u0027s an argument that might be used "
  },
  {
    "startTime": "01:13:23",
    "text": "to sort of that bike shed so my proposal would be to go for no padding with basic C for classic - but add some language documentation note that this was only edit this clarification was only added now and asking implementers to be particularly liberal about what they accept with this room cares about may 64 Sean Leonard so I think the core issue here is that you want different implementations to emit the same basic the same sequence of characters right for base64 whether its upper case lower case padding or whatever right so first of all our question is why I mean is there at light and when I say why I mean is there like a canonicalization issue where you really need it that way because otherwise some digital signature or hash is not going to compute a or something like that or what is it and then the second is there is I\u0027m not saying we should do this but another possibility is that you consider all the different permutations and you just register lots of hi tag numbers for all them so I think that that\u0027s not a good idea but that is a way to like deal with it and we just pick something arbitrarily for the current ones that we believe is gonna be the most common take Taylor so I\u0027m partly appeared to respond to Joe\u0027s question does anybody care about base64 in the so ocf is one of the organizations that has dependencies on Seaborg right and I just wanted to report that that ocf you to express schemas right they use both rommel and json schema and now moving towards swagger and both json schema and swagger have the property of defining a type for base64 and not defining a type 4 base64 URL and so that means that they use base64 URL not because they want to even though they\u0027re using super on the wire but because of other external dependencies they\u0027re using base64 so yeah and so the implementation they\u0027re using is tiny sea bore and I don\u0027t know what that does but offhand I\u0027m guessing your proposal would be fine I have to check with the tiny sea bore author but yep ocf would care and offhand I\u0027m guessing your proposal would be fine but I will have to check that\u0027s a very sad thing that you just reported but the tiny sea bore offer really laments the fact that he can\u0027t use the base64 URL buts in the tiny zebra implementation for ocf because there\u0027s no reason other than the specification language having to use previously json schema and now swagger and if we could get both of those or should say either of those fix "
  },
  {
    "startTime": "01:16:24",
    "text": "the tiny co-author would be very elated so Matthew Miller um so for me the time it\u0027s it\u0027s base64 URL and not base64 where it is basics t4 it\u0027s because of trying to interoperate with existing tools which will spit out whatever they spit out but the parsing of that usually they\u0027re accepting of things is usually pretty permissive in the first place so I think I don\u0027t so I think it\u0027s worth moving in that direction for the the 30x set of tags just let it let it be pretty flexible there we\u0027re but on the other side just remove all the white space and the safest I\u0027ve seen for that is also make sure to keep the padding for base64 versus base64 URL it\u0027s almost never padding but what\u0027s it\u0027s okay to be permissive on what what we take but on what you\u0027re going to generate just set some really strong limits this is one vote for permissive on the the 34 and defining the 22 Joe Hildebrand so I\u0027m at all I\u0027m gonna argue for the complete other side which is to remove all four of these tags from sea bore because I\u0027d find them useless you should just use byte strings so that ship having sailed I frankly don\u0027t care what goes into these because I think they\u0027re useless yeah sounds good to me they are register take so they are not going away but we could take them away from the standard okay so that\u0027s Kirsten can you start to thread on this one remaining list and people also those who have talked here please respond to the thread and we\u0027ll take a quick decision because it seems like this is just something that needs to be decided on and it\u0027s not really controversial so Joe already mentioned that we have to do work on the implementation matrix exactly to put a link on your code on the slide so maybe you can send it again to the mailing list so right now again Joe has done his homework and yeah is anyone in this room who can do their homework on this Jim can do that Carsten no sir a season so which implementation would you do that homework for okay Peter\u0027s Peter however you yes okay so that that said please do so I poked myself and let\u0027s do we then "
  },
  {
    "startTime": "01:19:30",
    "text": "we have four so that that\u0027s already a good thing but if we have more that so just for the record they said that you could do for tiny people thank you okay that\u0027s all I had on the syllabus document now the the last set of items on the agenda is C bar tags very civil tag documents and again our c70 49 pretty finds 18 tags maybe it\u0027s 14 when we\u0027re done today there\u0027s stuff in there but the point is it\u0027s it\u0027s easy to register your own sea boat eggs that may even be too easy at the moment and there are more than twenty more tags some of them defined by the IGF for instance they\u0027re cozy and CWT tags but people have come in and done tags for Perl support for Haskell support I\u0027m going to talk about that in a minute tagged language tag string which is really an important addition compression and so on so just as one example what\u0027s going to be completed very soon is the see what we\u0027re talking which is essentially the the JSON web token translated to see ball that packages a claim set into JSON and then you can apply a Cosi security to that in various forms so here we have tag 61 assigned already we didn\u0027t even have to do an earlier location for that because the the registration policy right now is very liberal and the working last call for the CEO we\u0027re talking completed in the IGF iceburg group and we\u0027ll go into ITF last card so that\u0027s an example for a tag document that we are doing because we have a standard that that actually uses that we also have some other tags draft that are not necessarily being motivated by specific standards but are being motivated by wanting to do a specification work that references certain types of data structures so one of this is the OID draft and at some point shown it I have to sit down and see what we actually want to push through here at the moment and what maybe should go into a separate a document but if you have feedback on that document that would be useful but I\u0027m not going to talk about it today the second one is the array tags draft which has been out for a while and has been pretty stable for a while that is still waiting for a working group adoption I will talk about that in a minute the third one is the time tag which is off "
  },
  {
    "startTime": "01:22:30",
    "text": "charter and essentially is is completed process wise because the IANA has registered in an FCFS tag for it the 1001 but maybe we actually want to turn this into an RFC and I\u0027d like to understand what this working group when it has completed its current charter wants to do with us that\u0027s the care or not then we have the the template tag but that\u0027s really something that that is over in LP when and not year so maybe this should be any other group of tanks motivated by standardization activities and then maybe at some point we may want to do a useful tags document because some of those registered eggs are actually very useful and it would be good to collect their specifications into an RFC so people have an easier way of referencing those and we don\u0027t have down refs for document that use that and that useful check document actually could swallow the time tag as well if we consider that useful so that\u0027s one way of handling this is about that okay then let\u0027s go into the array tag that is currently in version o six but they haven\u0027t been many technical changes there have been small editorial adjustments in the last draft and this is inspired by JavaScript it defines 24 contiguous tags in the two byte space and also defines two more tags for other homogeneous arrays which is useful in a decoder if you know ahead of time this array of 4,000 elements you are finding is actually homogeneous so you can map it to a whatever genius you have in your language and a tag for multi-dimensional array so when you get the the elements enumerated you know how many columns and how many rows there are so I think these are pretty non-controversial but for those of course eating up 24 tags is is maybe a lot and eating them out of the two white space is maybe even more a lot we have 232 there are about 20 taken at this point in time but I mean this is about the size of the IP protocol number space so we want to be a little bit careful about that and we have have had arguments on both sides one is it would be a waste of space because arrays can be large and large arrays obviously are fine with a three by check and the other argument is no arrays can also be small "
  },
  {
    "startTime": "01:25:30",
    "text": "and one of the more likely usages of this tank is for an RGB value which is three bytes and yeah then you\u0027ll need attending a three by tagged to a three byte value that that\u0027s maybe not so bright what we could do is partition those 24 tags into those that are somehow big and those that somehow not so big that\u0027s ugly I\u0027d rather spend those 24 tags at once but even more importantly I would like to get this out of the way for some reason they said this has kept us from adopting this draft which is weird because we usually end up droughts before we have solved all tanking issues with them so let\u0027s get this all over the way Joe Hildebrand from the floor we this pattern comes up relatively frequently where somebody has like one general concept that they want to put into a tag and then a bunch of different potential ways it might be used and one of the ways of dealing with that is you assign a large number of these sorts of tags in order to make that happen it is possible that we could come up with a pattern for parameterize tags effectively where you say here is a tag for a to a to place array where the first thing in the array is the parameter and the second thing in the array is the actual model that the actual thing that the tag this human for instance this is exactly that better yeah exactly and so having that pattern more so sort of in our pocket and with a name that we call whatever this you know parameterised tag for instance would allow us to shorthand the discussion and then so my next question here was well could we do a parameterised tag for this where we have one tag specified in which case having one in the one bite range even might be fine and then you\u0027d have another bite for the array so total of two bytes to describe the whole thing three and then three one for the yes so a total of three bytes for this I don\u0027t know if that\u0027s too many bytes if that\u0027s or is it too complicated etc I do agree that having these set of JavaScript types expressible easily in C world would be nice so okay Sean Leonard so to continue off of Joe\u0027s point "
  },
  {
    "startTime": "01:28:30",
    "text": "actually the Seaboard tags OID draft actually discusses that premise of having stacked or parameterised tags where you have a tag which is small and then another identifier next to it which could be another tag because you can\u0027t in fact stack tags you know on top of tag or an integer it\u0027s worth pointing out that in C bore a tag is really just an unsigned integer with major type six I believe instead of major type zero otherwise they\u0027re like literally the same and the semantics of course are that you can put one thing after it which is the thing that\u0027s being also has a correct correct yeah that\u0027s right that\u0027s correct yeah that\u0027s the difference with regard to this particular thing I think the draft should be adopted and I think all the tag draft should be adopted we just get it over with I have I think in Prior meetings Joe expressed let\u0027s put it in the three byte space I basically think for this block we should just put in three bytes space and not use the two byte space but the premise of allocating blocks of tags to take it or exploit mathematical properties like the fact that you know these are interleaved is a good thing especially because we are trying to optimize for IOT you know types of constrained devices where then this can be part of a jump table effectively right with one subtract and then to wherever you need to go with regard to the bike shed issue of you know three buy tags to buy tonight if we have if we literally have an RGB value that\u0027s three bytes we just give it another tag for heaven\u0027s sakes you know like if it\u0027s gonna be an array of lots and lots of RGB values because it is the contents of a graphic buffer or whatever from one computing device to another that\u0027s gonna be a large array so the tags not gonna contribute to it and if it\u0027s just one just invent some RGB tag you can put into one byte space so two bytes space or just just call it a day you know or or I will point out this is a good point to point out you don\u0027t actually have to tag anything at all if you\u0027re really super space constrained on the wire or whatever just don\u0027t tag it just have some huge huge array of integers or whatever that gets me to the issue of when should we tag and some of the oid draft which is admittedly a bit of a kitchen sink does go into those philosophical issues right when should we tag it all the problem with things prior to C bore like asn.1 which i\u0027m unfortunately intimately familiar with is that there are all these options for tagging you can make tagging explicit you can make it implicit you can make it automatic which nobody knows what does just the parser does whatever right and you can reassign tags from one universal class to another so something that\u0027s labeled and a universal integer maybe "
  },
  {
    "startTime": "01:31:31",
    "text": "it\u0027s not an integer maybe it\u0027s who knows whatever the heck it is I think a real advantage to see bore which is not mandated by RFC 70 49 but comes out of it is that we\u0027ve got this really awesome large tag space and one registry where once you register it that\u0027s it for all applications and so I\u0027d like to propose and volunteer to take some of the work I\u0027ve done on this and kind of develop a philosophy of Seaboard tagging internet draft that the working group look at and adopt so we can all say yeah you know this is how you should use tags which mostly is use them explicitly but if your application doesn\u0027t need them just don\u0027t use tags at all and be okay with that and with respect to that\u0027s good because if we agree as a whole if we\u0027re gonna use tags in a specification it\u0027s always everything\u0027s gonna be explicitly tagged necessary it is it\u0027s gonna be great for debugging right cuz you get a Wireshark trace or whatever everything is tagged right and they\u0027re not that big just couple of bytes but you know exactly what it is it\u0027s that weird RGB thing for Commodore 64 or whatever back in the 80s that\u0027s what it is you know exactly what it is no big deal it\u0027s a four byte tag out and there\u0027s a billion other different tags all right different numbers we\u0027re not running out so that\u0027s my proposal Joe Hildebrand from the floor again I think that that would be a useful discussion for us to have and having a draft to start from i/o wherever Shawn went there you are he\u0027s standing my blind spot now I\u0027m sitting my blind spot having a draft to start that discussion I think would be used so coming back to this like if so again this is just me speaking as an individual if you moved all this stuff into the three bytes space just to get us to the point where it\u0027s adopted and then we could have a further discussion that might be the most expedient way okay to get past this so I don\u0027t know if your from last meeting the point was many people seven people around seven people had read the draft and the thing that was missing was reviews and we had people volunteer but then no reviews so we need to get these reviews so on the philosophical question of whether you want to have a cake with a parameter space or use tags with the mathematical property as an integer I agree was shown that that\u0027s a good pattern to have we have 18 trillion tags so we can do this a lot before we run out in the particular RGB example the tag is actually useful because you would use "
  },
  {
    "startTime": "01:34:32",
    "text": "you and eight if you are in the classical RGB space and you would use binary sixteen if you\u0027re using high dynamic range so you actually need the tank to decide which of the two cases you have good point or at that point yeah you just you could have two tags at that point yeah yes yes but why don\u0027t we just provide those 24 for the applications that beat this kind of thing and be done with Mike oh he said heap like one tag you can do mathematical operations on like jump tables computation yeah yeah this computes on tanks but to be able to compute on text you need several of them so I like Joe\u0027s suggestion for to turn it into three by tags for a week have it adopted and then do the the actual discussion I mean that at least gets us past this sort of like philosophical question and like advances us from a process perspective and allows this this document that Shawn was talking about to get written as a way for us to explore our feelings a little bit so just is just as another data point there are a number of ini registration requests lined up right now that want to go into this space so the space wouldn\u0027t be available if we go for those registrations just as a data by Alexandra here so I really like the idea about the document that says you know this is the way we should be you know creating tags this is in the way we should be using them so if you go with this I\u0027ll be willing to to review it Orion objects express some opinion so thanks if thanks for starting this and yeah about these tags like I mean for me a tag is something that like its attack you don\u0027t attach like semantics on it it\u0027s it\u0027s something that says well the thing that follows is this right so I really like the idea of being able to do some mathematical miracles with it and do some jump tables or something but I\u0027m not sure if this attaching semantics to the things it\u0027s not violating the idea about the tag itself like for me a tag is like it the fact that it\u0027s a number it it\u0027s just like an implementational detail it could have been like a big string so having these things it could could work right but you know I I\u0027m not sure it\u0027s it\u0027s something we would like to start doing at some point because "
  },
  {
    "startTime": "01:37:33",
    "text": "here now we have some you find some neat thing to do with it and then maybe tomorrow we find some other new neat things to do with some new tags so we say okay we have some other jump so we have starting code to the tags and and you know we example with the lgb so what happens if okay you have you need to make the distinction between you int and binary 16 to make sure that your RGB is in one case or the other case like dynamic range or non dynamic range so what happens if your application doesn\u0027t use use tax anymore at some point you say okay well in some other case you want to be super efficient so you don\u0027t or we have some parser that says okay I\u0027m just going to strip tags because you know it\u0027s not this is all you can do and if we define it this way then a specific data model can just say an RGB value as three numbers and and use one of the tags that is being defined here I mean they are still in a table right so you don\u0027t have to do the arithmetic with the tag if you only care for a few of them it\u0027s just expedient for a generic encoder and decoder implementation to be able to use the table so you would say an RGB value is either a triple of you and eight-hour trouble of binary 16 and then your okay I mean that\u0027s a support point from the one that wasn\u0027t but what I say is that in this case if you remove the tag then you cannot purse anymore the you cannot make this distinction between is it dynamic range or is it something fixed so just just saying that that but that that was like a minor point that the other point was might be more important that do we want to make this explicit like mathematical thing on top of the text Sean Leonard I think the general design pattern is not specific to seaboard to tags it\u0027s just when you have when you\u0027re computing right you can have a huge if else sequence of statements which is not necessarily it may or may not be parallelizable but if you can have a large range of contiguous choices and then perform a single mathematical operation and jump to the right place or or you know compute that then things go a lot faster and can be done in much less code so it\u0027s just like a general pattern of allocating the same numbers in the same block that do similar things for the same reason that ASCII 0 to 9 just happened to be in the hex pattern 30 to 39 because if you\u0027d subtract 48 from them then you actually have the number in binary it\u0027s the same exact premise okay but we seem to have consensus on going for 3 by tags for the next version during the eruption call and then we complaining loudly to the mailing list that that should be two by text not quickly about the time tag just "
  },
  {
    "startTime": "01:40:38",
    "text": "note now we have finished with the chartered items and the time tag is unchartered thank you yeah I already said that but it\u0027s good to say that again so the the time tag came up because the the Haskell program programming language has pretty much adopted SIBO as their preferred binary serialization technique and in Haskell times are based on microseconds so he needed a way to represent the time based on time a seconds and the Afghan people wanted to have tags so they really can see in the serialized data this is a time and not just in any array of data or something like that so they wrote up a document and I helped them a little bit with with completing that and they got FCSS registration now we could document this tag if we think it is useful we it\u0027s not only useful for microseconds also be used for nanoseconds microseconds or milliseconds so all the cases when you don\u0027t want to do the computation of converting one of these pairs of seconds and a subunit of seconds into a single number it\u0027s useful to to have this kind of a check so it\u0027s pretty general in its usage and we could also go ahead and add more of what what was in the original proposal for the time check to it so there\u0027s there were things were things like time zones and other information that could draw in there could not so these are all other ways of taking it forward and I would just like to know should I talk to the independent submissions editor tomorrow and say this becomes an RFC on its own if yes he will come through the work group and ask assist the run around through working group and so the work will have to have an opinion on that or should I wait for the work group to complete its current charter and then work on making this workgroup document or including it in a set of useful tags or but but have the working work on it I would like the opinion of our ad on this I think I mostly have an opinion whether you should complete other work items before this one but I have I have an opinion upon whether you should complete other work items first before accepting this but other than that you know I think it\u0027s very fair question if you want to pole hold the room to see how many people are interested in working on this which can inform Karstens decision "
  },
  {
    "startTime": "01:43:46",
    "text": "you know which way to take it okay Sean Leonard so I think this is fine as a working group item with Alexie\u0027s caveat that we should work on the first things first that we are chartered for an interesting bookkeeping question which I believe is completely bike shedding is do you want to allocate a block for bookkeeping purposes of seaboard tags just a time stuff so we just say one thousand one to one eleven hundred or whatever is all the time tags will ever need and then somebody we have a block of free tags for times periods and intervals of three tags or of like three okay okay but I\u0027m saying like we know we just just reserved 300 tags or just say Oh somebody\u0027s coming up with some weird time format or do we have a block of tags for Haskell things right so it\u0027s like programming language specific like all the pearl stuff is in 3000 to 4000 and the Haskell so I\u0027ll support that but I don\u0027t know I don\u0027t know I can include something along that in the dock in the document philosophy of tagging if that\u0027s important to people I just see this as there\u0027s an opportunity to look at what are the underlying things that motivate sea bores you know advantages over other serialization formats and one of those is efficiency of the encoders and decoders I believe that\u0027s explicitly mentioned in 1749 as the motivating case so to the extent that we are trying to support IOT devices resource constrained devices you know devices that want to just work very fast on data hopefully that will inform whether we have a large number of time tags or whatever to make the encoding and decoding of these things faster for devices and easier for devices than and protocols that actually need to do them so yeah with that said if we delve any more into time tags I really want some subject matter expert on this thing because I\u0027m not an expert in time we got an NTP working group there\u0027s gotta be some people in there who know all about this time stuff much better than me yeah it helped that Joe touch was writing a document about times at the time that they dressed this was discussed so this document contains a reference to it or touches okay so maybe we can can take the power of who\u0027s actually interested in working on using this who will be interested in this topic here to be clear who wants us to do after we\u0027re done with our chartered items who wants us to do more work on time formats including this one perhaps just time formats in general let\u0027s start "
  },
  {
    "startTime": "01:46:46",
    "text": "with that hands who think we want to work on that ear Hank you have to raise a nom if you have one to spare one all right so that\u0027s two people including one of Hanks eyebrows all right three all right that\u0027s I think useful but not I mean this is not a this is more of a strawpoll kind of question not a don\u0027t work on this but I didn\u0027t see a large thundering herd of folk who were interested in doing more there yes yeah I think it\u0027s sort of an indicative but it doesn\u0027t have to be binding you can ask the question once you actually do those other things right but okay do anything else there all right all right so let\u0027s talk just a little bit more about CD DL while we\u0027ve got everybody here does anybody think that we ought to do a ton more work on CD DL before we publish rev 0 any any hands of people who think that we ought to do add a bunch more stuff before we publish there\u0027s a quizzical look I see do people think we ought I\u0027m going to ask the opposite question do people think that we\u0027re quite pretty close we should go into polish mode and just get the thing out the door like raise your hands if you think we\u0027re there alright so I see a good number of hands for that I see some people raising two hands Alexia is going to clarify I\u0027m going to start applying slight pressure as Area Director I\u0027m any document that normatively reference EDD L is not going to you know it either has to have a normative reference or it will have a discussing it so okay that\u0027s so I think we should I do want to point out one of the other ADEs asked me about using CD DL for JSON and he hadn\u0027t seen appendix e out of the the current CD DL spec so alexei if you could just keep your eyes open for people questioning if they\u0027re allowed to use CD DL for JSON whatever allowed means there is that appendix in the current CD DL draft well he does now because I sent him the link so if there\u0027s anybody else that wants us to do more work there before we\u0027re done enough and I used air quotes there before we\u0027re done enough for people to use this in their JSON specs then the iesg should let us know because if we\u0027re going to move into quick polish and get it out mode we\u0027re not going to add anything "
  },
  {
    "startTime": "01:49:48",
    "text": "else other than what\u0027s in that in that appendix talking about JSON so this is a hey if you would mind mentioning this the rest of the iesg you see if anybody else has an issue otherwise we\u0027re just gonna plow ahead so you know no no what I\u0027m saying is that I think we believe and I\u0027m that Appendix II is enough to motivate using CD DL for describing JSON protocols if the iesg wants something more than that appendix say something that feels a little bit more normative or a separate doc that describes how to do it or anything like that we would like them to speak up immediately and give us a little bit more direction other than without hearing anything like that we\u0027re going to move ahead assuming that appendix B is roughly exactly what\u0027s needed okay sorry because I haven\u0027t actually looked at Appendix C I cannot provide a useful personal comment and I\u0027m not asking for you to tell me the answer to this right now I\u0027m asking if over the course of maybe tomorrow and yes or at least point people to it and tell them that that\u0027s what it\u0027s going to be unless they tell us something different okay did there\u0027s already one I receive public that reference is City dairy for Jason informatively - be careful when you give me action items I give them back alright anybody have any other concerns like if we\u0027re gonna put CD DL on this short timeframe which sounds like we really ought to at this point does anybody else have any other concerns or potential roadblocks things that we ought to aggressively pull out in order to fix things so they\u0027re like the regular expression thing like I would maybe put that on the bubble if we don\u0027t have a normative reference to point to for regular expressions are you are you okay with that Sean Sean Leonard so yeah so my whole thing is I don\u0027t want us to be committed to all these bucketload of features that we may want to change you know or improve or whatever later on so I so you know I am resigned to the fact that we got to publish something right and we got to keep people\u0027s work going there\u0027s no not really question that but we need also be clear it\u0027s version zero and we\u0027re trying to you know add these useful things I mean all that I dunno I\u0027m gonna have to basically start that as soon as we get the first one in the can yeah and so like the the mode here should be if we can\u0027t come to consensus quickly on exactly what it ought to look like if we don\u0027t have a reference for "
  },
  {
    "startTime": "01:52:49",
    "text": "the thing for whatever reason will rip the feature out and we\u0027ll put it back in and this right right and yeah like I said my I have concerns about like I said the control operators in general not because they\u0027re not useful but because like is somebody really using these now and well I know like give us a few weeks or the virgin ones like give it all out you know Hank can you quickly comment with a certain three little is a ssin would have a problem with ray X being taking out do that later yeah so do that on the so all I\u0027m saying is that if we can\u0027t come to consensus on these things quickly now I\u0027m also now that we understand sort of what polish mode would mean I\u0027m also okay with somebody going up to Mike and saying you know we\u0027re not quite ready for that I\u0027m not seeing anybody running to the mic all right so this is just hey we need to be able to finish okay chabi relay from kuru Maeda or some variation of that pronunciation reg X is good at finding something matches however bad at detecting something does not match bad Greg X patterns might lead to a dos relying on reg x4 validator could be risky please send that to the list that is an entire separate discussion one of the things Shawn that we probably ought to put in the dock that you proposed is a talk about how much these sorts of things should be used for generating validators at runtime versus being used as a mechanism of documenting what the validators ought to do and I know that that is a place where timbre and particulars had very strong opinions in the past and the way that we got to being able to do some of the CDL workers was talking about it in terms of describing what the interoperability properties should be and not about generating values right so Joe this is Sean Leonard so just a question are you referring to the philosophy of tagging document that was oh oh okay yeah because that your comment was addressed more to CD DL right okay in my mind it was one big philosophy document okay no problem yeah cuz I\u0027m I am of the view opinion that it\u0027s more descriptive than about validation I\u0027m also I recognized people will wanna validate things but the point is to describe and we want to emphasize that and one way to do that is to kind of put some focus on the fact that if stuff doesn\u0027t if you have data that doesn\u0027t conform to the CD DL it\u0027s not necessarily a "
  },
  {
    "startTime": "01:55:51",
    "text": "fatal error okay this is not XML land it\u0027s more like markdown land if it doesn\u0027t quite fit that\u0027s okay still work with it that\u0027s not the way we use this use this for defining protocols and if the protocol is not being followed then you have an error all right so let\u0027s not bogged down in that particular philosophical whole there are different ways of using app so the sean\u0027s way is also another way of using it all right let me go back to what I was talking about with CD DL so let\u0027s make sure that anything that we don\u0027t have pretty good consensus on or anything that we don\u0027t have good references or or anything that\u0027s not done we can start ripping that stuff out get a version zero out the door so that other people can refer to it that should be a pretty high priority for us over the next several weeks and I don\u0027t see me but this I see some nodding heads I don\u0027t see anybody shaking their head I don\u0027t see anybody jumping up to the mic all right go ahead jump up to the right as Dave Robin I was just gonna say with the exception of reg X which gets into the whole philosophical about it what\u0027s it used for it can it be used for generating validators I think if you take that out and you look at the rest of it I can easily make a validator code out of it it\u0027s it\u0027s it\u0027s fairly strict I mean we had some matching questions J year that we talked about but for the most part I can automate about a validator from that so I\u0027m just saying that\u0027s that\u0027s okay with the Reg X is more of a explaining to a human to give to my coder to write some rules and that that breaks everything all right so let\u0027s have let\u0027s finish off that discussion on the mailing list thanks about to jump up because he sees the way the winds blowing in regard to the three-letter a true man suo reg X is not by to within as what is within control within all right well maybe that\u0027s that\u0027s a quick way out of this for the short term is would be to remove that regex control does anybody else gonna have heartburn from that did you say that all right so we\u0027re gonna Val we\u0027re going to talk about that a list see if anybody has an issue with it that would be a way for us to move forward get the thing out the door and we can add regex back in in version 1 or version 2 or whatever going to call it all right two minutes just remind again please participate in no meaningless SUBSCRIBE and I would be personally interested to hear about people that are using CD dl4 CDL and implementers of C bore so I see a lot of people here that I I have not seen in the mailing list talked a lot so please make sure you\u0027re in the main list all "
  },
  {
    "startTime": "01:58:55",
    "text": "right any last comments is there anybody that didn\u0027t get the blue sheets do we have the other blue sheet handy can somebody raise it up for me somewhere where I can see it thank you all right thanks everybody that\u0027s all yes so all they have done great it to a comment hi there was a bit of misunderstanding I thought you guys did wasn\u0027t quite right a strategic yes because you are updated the definition and sort of war spirit I initially thought it was wrong as in Euro defined linked relations instead of defining you once but mark explained that actuates now your but but because Europe instead of just doing by reference you if it is a text "
  }
]