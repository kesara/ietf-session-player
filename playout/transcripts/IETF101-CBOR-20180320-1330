[
  {
    "startTime": "00:00:35",
    "text": "yes I have yeah you probably have to plug in both friends of the HDMI camera you know the question is which one is the right it came like here we are looking for the projector there are lots of cables but where\u0027s the great projector maybe "
  },
  {
    "startTime": "00:03:44",
    "text": "because broken alright let\u0027s let\u0027s do all the normal things that we would tell people to do I\u0027m going to disentangle it from the other I frequency source here let\u0027s see if that helps look for the commuting buzzer no no it\u0027s so we use this for the alternating - well it was a different room my USC yeah oh yeah I think we can start yeah it slightly late but thank you right so welcome everybody you\u0027re in see Bohr right now so if that\u0027s not where you want to be please you\u0027re welcome to leave now we\u0027re looking for a minute takers and scribe jabber scribe can anybody volunteer minute taken consume at least relay from jabber no we\u0027re so sorry I\u0027ll use the mic can can somebody at least relay from jabbers so if somebody yeah okay thank you Jim and so if somebody could capture action items thank you Paul so first of all the note the note well and reminder minutes are taken meeting "
  },
  {
    "startTime": "00:06:46",
    "text": "is recorded and your presence is logged into sheets this is the agenda for today so we have the introduction I was going to be short the main item is going to be CD DL led by Kirsten I believe and then C Boer status and the RA tags draft yeah times are indicative so we\u0027ll see yes if anybody has anything that I want to add or any modifications to the agenda okay move on so a quick status update of the working group documents right now before custon takes it so the four CD out there was a working group last colder than Ted the 13th of March and this this created some review comments that are going to be discussed today and for the Seaboard 70 49 this so it\u0027s working progress we are version zero to the implementation matrix was updated so thank you for thank you to those who provided input to that so now we have three implementations in the wiki and yes then the Ouray tags got two reviews thank you Jim and Paul for those and it seems like it\u0027s ready for adoption after the authorship right these reviews so we will have a call for this document so Carson can take it very constrained pink box yeah I don\u0027t have to say this because the Francesca already said it so let\u0027s go right into Syria wondering right now okay so we had a pretty good discussion at 8100 and what we did after ATF 100 was to introduce cuts in maps for one specific application so we are not introducing the general concept of cuts but just for that one application so we still have some time to tweak this for CDA 1.1 or something we had a problem in Singapore about regular expressions and the solution that came up after the meeting was using x SD regular expressions they "
  },
  {
    "startTime": "00:09:51",
    "text": "are a little bit weird but which your expression variant isn\u0027t and there is a little bit of text in the document that explains what what kinds of pitfalls come with that the main problem is that vectors D and and vector W actually are unicode references so you might get Indian numbers or Japanese numbers in your wonderful identifiers if you don\u0027t pay attention and the third thing is that we defined matching rules in Appendix C so this is a summary of what\u0027s going on in that and yeah and there were a few editorial things we were trying to fix the terminology little bitch and later that we probably have to take another round at the terminology some fixes around the examples and there are some cobwebs in the engine reminded me this morning there are stayed some cobwebs in there so of work to do there as well I also generated a freezer document I think we should do this for every single IT aircraft that we ever work on this contains the things that will not go into a CD DL 1.0 the nice thing is that we don\u0027t have correct consensus on what exactly goes does not go in there but of course we have to have consensus on what that\u0027s gone into there so the big cut thing lots of proposal it\u0027s fun little literal location improvements there add back PCIe there is a proposal that maybe we should allow a PMF for specifying tech springs in our documents and there is ideas of adding a module superstructure all of these can be done later so that\u0027s why they are in the freezer adoption now on the current document we have lots of good editorial comments which is code for saying the text isn\u0027t that great editorial yet even after humans of improvement and yeah I\u0027m wondering when are we reaching the point of diminishing returns sometimes comments tell us that what we did in the last role of editorial comments was the wrong thing and we should revert that so we will have to find some some penance on some of these issues "
  },
  {
    "startTime": "00:12:52",
    "text": "okay so there\u0027s lots of work to do again to minimize this but they also want to want people that this will not be Shakespeare at the end of the process so to the technical issues the the main people the main thing that gives people some powers is the map matching that\u0027s not on the map matching issue so the the idea behind that we have a single concept called groups that we use for describing both maps and arrays and groups are runners of type so they have all the properties that you know from from other girls they are sequential in nature they describe Alinea languages however the linearity is something we only use for array matching where we process the elements of the array just as we would process the characters in a language that we match with a grandma while math so that nurturing from the grandma defined by a group actually always picks any member any member of the map and that is maybe slightly unfamiliar but it seems to work quite well implementation wise this means you actually drive the pawza from the grandma not from the text as you would in a normal path that\u0027s where most of the bugs in the current of mutation comes from because the current of communication started out with a normal father and then morphed in into a real manager completely so this requires a little more work on the implementation it also means that we do have some non determinism yeah and that may hurt in certain boundary cases I haven\u0027t actually found a specification where did that but it\u0027s probably possible I haven\u0027t done it\u0027s probably possible to come up with an edge case wherever it does touch okay so that\u0027s the map matching issue and one specific thing that we had on the mailing list under the charm at validation validation is not a term I normally use in the context of City idea is that if we have a match and a white car match the semantics of the match which in this "
  },
  {
    "startTime": "00:15:55",
    "text": "case before we should have a text is kind of counteracted by the wild card match so we put an old proposal out of the driver adding cuts to the language again we\u0027re not doing another thing but we are just doing a subset for the maps the idea about the cup is that once something has mesh you are not going back to matching other things you are kind of committed to that match and exactly that works for this case as well so once we have matched this for yeah we are committed to finding a text value and if we don\u0027t find a text value then the whole thing doesn\u0027t match some of the important prerequisite to a cut of doing anything is that we have to have a mesh doesn\u0027t do anything if there is no match and some of the confusion was about the current indicators that can happy around something that uses the cut so how often does this pay you that far really maps to a text well the example is not so good because there\u0027s only one for but if this were a more general type here so let\u0027s say the numbers from four to seven all have to be text but we only want to have one of them that\u0027s currently no way to write that down so the current indicator would say we have only one match and all the other numbers between four and seven would go into this white card so that that\u0027s a limitation of this approach not one that has perhaps even but maybe something that that needs to be documented documented better than it is now so what do we need to do again this is being discussed there github issues and so on are the remaining comments on the editorial side or do we actually need additional technical changes this is really one thing that we have to clarify before publishing has to arrest you I\u0027m Jeffrey askin I sent you an email about this like five minutes ago so you didn\u0027t have time to read it I believe that the semantics of group matching and "
  },
  {
    "startTime": "00:18:56",
    "text": "occurrence matching are not specified well nearly at all they\u0027re kind of waved at but not specified and kind of the one one way to specify them means that the cut indicator on the last slide has no effect and I\u0027m not sure what specification you intend to to cause it to have an effect and I think I think that\u0027s a technical problem not an editorial problem that that we need we need a description of what what causes a map to match basically with with this mapping if if occurrence indicators apply by saying you get a non-deterministic expansion of the of the occurrence indicator then the occurrence indicator could easily appear zero times here causing the cut to be ignored and we need we need a precise specification of that matching algorithm in order to have a reasonable RFC I can give you the precise specification this is the positive expression runner but you probably won\u0027t be happy with that greater than the truth concise so the fashion grammar is that it\u0027s greedy so it\u0027s trying to match as much as possible so T 4 would indeed match if you won of this as a non-deterministic final then indeed you have the problem I am sure um I\u0027d actually like to change to modify the the ordering of of this thing so you basically if you have multiple things in a row you start by saying you\u0027re gonna match the things which are most specific in terms of keys first so you would all match to know everything that\u0027s a string everything this number and then you\u0027d mesh everything there\u0027s any number and then you everything that\u0027s in it because that would give you a better set of understanding of that doesn\u0027t make all of your cuts actually apply as opposed to if you have another cut after the the the star you ant right now that Kyle would never get applied well whose I um the specification writer can do that or just in my tool which says is this valid to the grammar can\u0027t your tool cannot reorder what the specification writer wrote I agree with that so you want a tool that actually tries to apply some ordering yeah and I\u0027m trying to understand what that ordering would be yeah this is Jeffrey Gaskin um I don\u0027t think it\u0027s possible in general to say this type is more specific than this other type you can say it for a for "
  },
  {
    "startTime": "00:21:57",
    "text": "and you int of course but you can have since since there are choice types they can just overlap and not not be more specific than each other I\u0027ll answer that one first um I would basically say anything that\u0027s a value it\u0027s a type which would it be constructor types anything that\u0027s any in the order in the part okay Sean Leonard I want to express that I am opposed to introducing cuts in the CDD alfie 1.0 cuts can can can transform a context-free grammar into a context-sensitive what an alternative subsets or constraints was sketched out in Singapore from an editorial point this is introducing new matter at the last minute when it needs to be fleshed out more over the coming months ie after we get this version of CD VL out so basically this is similar to Jeffrey\u0027s point not well specified and trying to do too much okay let me reply to that executive by the words that are used in Singapore if we want : to be a shortcut or equal it\u0027s greater and we have to do this now there\u0027s no way to add this shortcut later and the this interpretation of : is probably what most specification writers expect so I think we should do that now the the alternative is essentially taking this information the number four is smoking four and smearing it out to the other places that might possibly also match that so for a specification writer this means a lot of tedious work copying all the things making sure all the cases I actually hit and so on and I don\u0027t think that\u0027s a good thing for a specification language should be possible to write concise specifications Jeffrey askin um I think it\u0027s useful to have the colon syntax act as a cut I\u0027m not sure that we also need to cut syntax that that seems to have some more general problems if we can do just : maybe that\u0027s easier to specify so this is hanger speaking as a contributor we had a long discussion about introducing cuts at the last moment and effectively how CBD edits are used and this is I think the point class Nene tries to bring across here the exception "
  },
  {
    "startTime": "00:24:57",
    "text": "is the behavior of cuts there\u0027s a syntactic connotation that is in the second example yeah and that is what we experienced so if that is not the case this is very important to know because it would be contradicting what we got as feedback in the last months so if you look at the last example I think to most of you in the room it seems to be clear that you want four to be text and that is the only point here so if we do not want a simplistic sentence in Turkish notation like in the last example because it is intuitive how cats work we really have to decide this very very soon and again I think if you look at the last example it is very obvious what the designer of the city at once so my bedazzler yeah the microphone I think I said it maybe we just should try to agree or not agree on the last example and its meaning as being depicted a constant and that\u0027s the important thing yeah and if someone else thinks it does unintuitive to have another example for being expected to be text then we should make that very very openly clear yeah so I think this and that\u0027s certainly possible I think it\u0027s a little bit weird to have a shortcut for something you can avoid in them form you have a shortcut for something you can avoid in long form but yes that that would be a way to further reduce its change youit\u0027s enough ok so Sean Leonard so the point is what you want to say is or is text only all the other answers something else right so this ice the slide says you end and that means all you wants except for right what happens when you later want to say five is only a byte string you have to put it all right at the top but you can\u0027t put it at the top if you\u0027re supposed to be putting at the bottom yes so then don\u0027t room that I\u0027m not sure I know what okay unfortunately I wish you had the slide that I thought I was seeing this morning which was my example of if you build a group with cuts that you can end up appending things on the bottom below the start you amped which are never enforced "
  },
  {
    "startTime": "00:28:00",
    "text": "yep we\u0027d look if somebody does an additional spec they\u0027re going to expect it to be enforced but it\u0027s never going to be checked by anything that uses the grammar to check and that\u0027s one of the reasons I came I was proposing the other the other set of rules because as a writer I\u0027m an expected to be enforced and it\u0027s never going to be important that\u0027s non-intuitive okay so quite by creating a sorting mechanism for the elements in a group this consideration could be late right okay now there are two reasons why I don\u0027t like the sorting mechanism well first of all I think the spec writer can be to put things in this sequence in which the think writer wants to then consider but the main thing is I really don\u0027t know how to do this honoring it since videos are types I can even pass the proposal that you age um you say the spec writer can get it in the correct order yes yes the first spec writer can get the guy who writes an extension to that\u0027s been can\u0027t why because his stuff is going to potentially be a pin at the bottom hole copy and paste um they say you include this fact from this document and append this because I want the the I am put it in the front because I want the rule to be the same I can\u0027t put it at the bottom because I\u0027m going to have the wrong word or cots so it\u0027s like I now have to reproduce the module over there in my document well there\u0027s a way around that particular consideration by by giving everything but the word colony but we don\u0027t have a way for our fans to combine magically the only thing we can do with files right now is forgetting it then and you couldn\u0027t concatenate something to this which extends it so I don\u0027t know that ever could happen but more importantly if you want to make sure that there is a clear separation between the ones that are bound to specific tags types and the right route you can can just give the first thing a name and then have a second rule that says Empire gets the white hat for it and I wish I had a computer to type this "
  },
  {
    "startTime": "00:31:07",
    "text": "Sean Leonard again the way that constraints work is is that you say with appropriate syntax star unit goes to any first but then the subsequent parts of this spec you can identify specific instances of star and the star you ain\u0027t goes to any for example when you ant for Tet is text and when u and v is district and then he refers to a document he\u0027s produced the precise nature of the syntax requires a bit more fleshing out though yes all hoffman has minute taker can we take this to the list I\u0027m like I haven\u0027t been able to do the last view yeah so let me try to summarize so there are some proposals that the grammar should are metal and the approach would reorder things before matching on your fucking maps and that\u0027s always there are some proposals to have the shortcut but not the L\u0027Enfant and did there are some proposal but introduce something like constraints which we probably would have to start developing at this point which would still have the problem that you have to repeat the same information in multiple places to make it so maybe you can take this to the list just a precision so when you say short cut and long from you your for to point to and one way to the slide and this is essentially just the long form why does it make sense to have the long form because this may not be something that is allowed here so technical so it\u0027s pretty weird to to limit the reach of this feature here by what happens to be synthetically allowed in front of the court let\u0027s take it to the list and move on for now okay next item operator precedence now I\u0027m not aware of any non-trivial computer language where people don\u0027t which operational precedence so yes we have our share of this year as well the operator precedence that we have until it\u0027s quite logical when you are always thinking in terms of groups and types but if you don\u0027t it may be surprising for instance this thing here plus ARB "
  },
  {
    "startTime": "00:34:11",
    "text": "means you can have multiple a zombie\u0027s it does not mean you can have multiple A\u0027s and single V if all a single V and that may be surprising to people who think about this as a goof but in really it\u0027s not a group the thing after the plus is a tight trust that\u0027s why we have slash and double slash as two different choice operators so why this is maybe surprising in this case the same thing in nap context suddenly is very familiar and we say we have an optional integer or a text it all makes a lot of sense and I think most of us who have written specifications actually have like this in their specifications so this is really a very normal thing to do but it\u0027s essentially the same operator precedence here it just says time spec can occur within a group without parentheses so I\u0027m not sure that this isn\u0027t just yeah getting used to the language and the fact that that groups and types are two different things in the language I have thought about ways to modify the operator person and I feel of like where I am grateful to oppose that but only on a very very small scale so general changes here are probably not good here and they are too easily through situations like this so if you do a + H - B that\u0027s a syntax error and if we change the operator precedence to this over this we would just make it easier to write so in Excel but sometimes it\u0027s a good thing because it reminds the implementer of to put in the parentheses yeah but in this case it\u0027s just an annoyance so I think what we should do is add some more text to section 3.11 which is the one that he finds the operator precedence and maybe also include a little bit of text about asking the the specification of I try to use a style that doesn\u0027t actually evolve visa processing so just like in a B and F where people are continuously confused when people mix concatenation and choice we should ask people to use parentheses "
  },
  {
    "startTime": "00:37:12",
    "text": "when they want to mix groups and types in ways that may not be obvious that\u0027s obvious year so my recommendation would be to place parentheses around a star P that\u0027s one proposal wizard comments one I see nothing yeah this is Hank again why I understand the problem the necessity the spire that\u0027s the world of being not noisy because I think this will happen all over the place so it will be very more apparent thesis Leni after that and I\u0027m just thinking of a readability here and our promise that it would be easy to heat and bright and I think we\u0027re moving away from the ever understand point that it might be a necessity of just political it is Paul Hoffman who\u0027s lazy it\u0027s never hard to read too many parentheses it is harder to write no no I I have and it\u0027s never too hard to read parentheses unless you are like more than six or seven levels in and I don\u0027t think we\u0027re going to be worried about that here yeah I fully agree it\u0027s hard to write but let\u0027s not say it\u0027s gonna be hard to read it need not be parentheses by the way so the reason why we are seeing this year so rarely occasions is that people actually mostly define a type the name for father is that we before putting it into a group so that they are not actually writing for enter this they\u0027re they\u0027re actually providing additional documentation by giving the choice and lien before using it so I think in in practice we can still make the recommendation without littering up the specification is too much we should check okay so let\u0027s move on to general you I think we kind of have our item form which was essentially about dead count with the example that unfortunately so generally I don\u0027t think dead should eat too hard errors because dead code may just be the result of applying abstractions in the right way and if you create traps in in applying extractions you are not better off then creating traps through dead code however a tool might still provide a way to give you a "
  },
  {
    "startTime": "00:40:14",
    "text": "warning when that helps yet is undecidable like mostly support trellis but I think woods can can still capture most of the realistic cases and give some warning signs so I think yeah with the discussion where we are kind of comment on this comment fix is maybe an editorial comment but just to make sure that the people are real this there is this mechanism called generics and it can be used for both groups and types and the grammar actually says that but the text so we shouldn\u0027t say that table and actually looking more closely so the unary operators ampersand \u0026 interior probably should get their own precedents and then we can so if there\u0027s a problem as well and finally a gent found problem in the grammar for the unread statement and essentially was a copy and paste error here if they were murders in the document this says root day but that is of course nonsense because other words I\u0027ll apply two types that didn\u0027t cause any problems during testing because group name attack training are identical identical right hand side so yeah so this this was a genuine this mistake well the other thing is that the result syntactically lands in the type branch of the Rena which is only true in 1 out of 3 cases but that\u0027s not a problem because types can be used in places where groups can be used so yeah if you have it all it turns out but ok so the only thing that I propose changing is using the proper technique yeah finally maybe it in the notorious a little bit more than in the Victoria comment they have been several editorial comments that essentially pointed out we are using terms confusingly inconsistently so for instance there is the well entry which is defined in a way that makes you think this is about a member and not an entry and I think we should actually "
  },
  {
    "startTime": "00:43:14",
    "text": "make very visible in the document that we have challenged for the see both side and terms for the ciggy a side and these terms never mix so the city gate side tells you what data items mesh in different language okay that\u0027s all I have on City deal so you\u0027re almost telling with that there might be other comments yes Jeffrey askin um I wanted to make the a very general comment that the CDL spec is mostly written as a tutorial for how to use CTD L rather than as a specification for when C bar items match CD do rules and I think before it goes Darcy it should be written as that specification appendix e starts down that route but is not complete doesn\u0027t define all of the elements of C video and and is also written fairly more concisely than it should be because it\u0027s I think trying to be a summary of the rest of the spec rather than being the specification itself so I would like to expand Appendix C and make that be kind of the main body of the spec and the current main body should be a tutorial on how to do it I think that that\u0027s a very sensible proposition it also means we will take a year to are you willing to help if we can get to a like a pull request style you know where we\u0027ve got most of it sort of fleshed out and maybe we\u0027re arguing over knits and grammar and whatnot in the short term like should we set a date for that do you have an opinion does the working group have an opinion about how long we would we would wait for that Jeffrey maybe you have a more clear opinion of how how much work that would take so ad asks if it\u0027s just we were doing more more and answer is more in in some cases like for a group matching I don\u0027t even know the algorithm that Carsten has in mind so that that definitely has to be parsed in for for some of the other things like what dot dot bits and unwrapping it\u0027s it\u0027s clear enough I think that that I at least am capable of of writing the specification but it takes a fair amount of time so "
  },
  {
    "startTime": "00:46:16",
    "text": "for instance I might be able to sketch sketch something in I don\u0027t know a month even even other constraints um but actually getting exactly what words would take Walker I don\u0027t know if that helps and that was over asking yeah so we we did have a call last couple of ideas meetings and and the result from the working group was we want this out as quickly as possible but and yeah I want to hear what the working group thinks so my son Leonard is basically he why he appreciates the v1 affinity versus rest document these basically says let\u0027s get the version one point out now and then we can run a more formal spec on the next version if we feel is necessary and plus one me this is this is Joe Hildebrand from the floor I stood up to say roughly that which was I do see a ton of value in specification being written away you just said one of the things we\u0027re trying to do is get a stake in the ground so that this conversation that\u0027s going on about JCR etc there\u0027s a an actual sort of RFC number that\u0027s the start of that conversation from our point of view here at least that was one of the things that I thought we had sort of talked about so that\u0027s just me as individual I have no particular that\u0027s just mine and and if we don\u0027t have this straight straight constraint in time that would be great to start working on that without you know rushing into so the one thing I would like from Jeffrey is those items where you don\u0027t even know what the spec says and I sure can fight your friend Jose that would be much faster than Jeffrey asking again having having CDL spec the way it is out of limits where we can use it I think in that for instance I get objections when using it in web specs because it\u0027s not as it\u0027s not precise as as web sessions need to be but clearly there is value in getting kind of the sketch nailed down and it\u0027s fairly clear what you mean when you write CDL given the current draft so it\u0027s definitely not like over my dead body we must not publish this that that\u0027s actually super helpful to hear so does anybody does anybody feel more strongly that we should stop and do this work now "
  },
  {
    "startTime": "00:49:17",
    "text": "before we publish a 1.0 just looking to see if anybody\u0027s raising their hand or going to Mike all right that\u0027s so it seems like a reasonable path that we can sort of agree to that we know that there is still work to do that this is a first grab we already knew that we were going to do abyss on this anyway because there are a couple of features we wanted to add and at that point the working group could decide to take on or you know more structural rewrite at the same time Aleksey are you comfortable with that approach yes for the record yes yes and so another point that was just discussing with Kirsten is that we need to update the milestone date so we\u0027ll do that and yeah but just in accord with what we just discussed so I Alexey when can I expect you to be done think that GDP I was not going to effect before this is time May 21st I would like to get input from Jeffrey but for me personally it\u0027s a really high priority item to get this done it\u0027s nice to have an environment and so this will be the most important thing for me so to the working group keep reviewing this and keep checking the github and see if if you have any comments so I guess we\u0027ll have discussion in the mainly list for these points that were left and then an update and we\u0027ll see if we need another working group last call and sound sweet good okay so we came over so the other document that this document that this works on is the SIBO spec and just to remind people this is about taking this tenets level it\u0027s not about futzing around but it is about learning from the first five years of using SIBO okay so yeah improvements in "
  },
  {
    "startTime": "00:52:21",
    "text": "specification quality by now go way beyond fixing via rattles this is an old idea so I think we are doing some some good chance and if you want to know what taking something to standard means look into our of c64 ten which documents this and we are really lucky you don\u0027t have to go to this one um yeah just quick update there are more than 45 representations ok so last time we looked at 70 49 this of one and there were a few changes you want plus a significant new section the data models a section and why did we do this because experience is not documenting your data model but having readers inferred from the text creates a lot of pain now we invented a few terms and one is the term generic data model which is essentially the set of data items that can be represented in C ball and we split this into a basic infinite generator and the extension points and I think one of the successes of C was so far there\u0027s been that we do have those extension parts and the whole point of being very specific about this is we want to enable the implementation of generic serialization implementations so getting this ecosystem out there getting this 105 plus helps and if they are interoperable write down what you\u0027re thinking about the data model yeah one thing for instance we decided I expected undefined is a nice to have but it\u0027s not actually expected not to be there so when you write your CDA spec for something and you may want to use limit use the use of undefined two cases when you actually need so what did we do in ditional - well first of all we accidentally duplicated the data model cakes and worse we didn\u0027t apply changes to have a little bit of editorial work to do we\u0027re going to come home but I think more importantly we can now make use of the economic terminology so that there are a few places that actually are already improved with it and I would expect the next version to "
  },
  {
    "startTime": "00:55:23",
    "text": "have more of these places so this is probably mostly editorial let\u0027s see if we find anything my typical observation is that we have learned that people who are using a SIBO want to separate the world of integers from the world of floating project players so there is one paragraph in 1749 which essentially declares the equivalents of integers and floating point values and that paragraph is gone so that is a technical change it\u0027s not really a thing you change to the way C was being used because people have been doing this all the time they\u0027re just simply ignored what what was in the error but we now take heed of that and yeah so this means for instance places like equivalence separate integers and floating points and there are a few more places where we probably have to make sure that we maintain that separation now it\u0027s very clear that there are environments that cannot do this separation very easily and the fact that environments are different we are not going to fix that so there there needs to be some attention to the fact when you actually define an application of this specific data model and we may want to expand that we already have text in the JSON appendix about this but we probably want to do this well general Oh what so jungle to run from the floor so the in the JSON working group we had all those notes about if you go down this path you might end up with something that\u0027s on interoperable like depend upon the difference between these things or whatever I\u0027m wondering if we\u0027re going to need some of those notes so in in the JSON RFC it says like if you use something looks like an integer but it\u0027s more than to the 53rd then you\u0027re gonna have that day because there are a lot of implementations that don\u0027t process enters larger is this are we going to need some of those kinds of instructions here\u0027s my question the kind of instruction would be slightly different because we already separate those on the serialization yeah so it\u0027s not the situation like in JSON where you have the number you need to find out how am I going to process this number in my implementation so is this is 10 e1 is that an integer instead of floating on that that\u0027s a typical problem that you have when when interpreting JSON and keeping integers and floating points separate we don\u0027t have "
  },
  {
    "startTime": "00:58:37",
    "text": "good so that is that and now for my favorite subject I write it on the slide can non Equalization when we wrote the original CBO proposal there was a little bit of internal fight in the office should we actually but there are some applications that actually came can make use of a unique representation for each potential data what I don\u0027t so let\u0027s help these people so again the question of course is can there be generic serialization for economical SIBO and generally canonicalization has certain application dependent effect to it there are things like key equivalence that we only have a meaning in at the application level so one has to be careful about that and there are other places like floating point representation where really it depends on the shape of your application what you actually want there so we do want to encourage generic encoder writers to not ignore it when they ask for canonicalization and so how can we help them with that and the idea is that we as this says provide some recommendations that an application can use to choose their canonicalization what and that\u0027s all that is in 1749 if you read it close now those rules that we originally picked both were kind of leaky there were quite a few places where we didn\u0027t really say anything at all and also there\u0027s one thing that implementers have told us in pretty subtle charms was not so great which is the key operand so the recommendation for Hyorin will change to buy twice lexicographic ordering which is right now everything it says I think we have to define what that means but we also keep the old recommendation in there for people who want to reference that because they already had an application standard that is based on the old recommendation so follow will stay in "
  },
  {
    "startTime": "01:01:38",
    "text": "that the recommendation will be four by twice lexicographic other and this is about the thing I\u0027m most rented when we started talking about canonicalization you remember ace and one which had CER and we are doing the same thing so yeah true good sorry about that but maybe that\u0027s to be expected so the other thing is that we probably want to be more specific in our recommendations for floating-point canalization currently that X simply has three variants you can and the question is should we express preference this year an application is free to do something different but should we express preferences and my proposal is to have a general rule that in an organization we prefer the shortest encoding in all cases for integer or length information for Strings for tag numbers but also for floating-point for big numbers for big floats and so on so that would be a recommendation that would cover all places that would kind of a unser cause I\u0027m for people but again they can go ahead and do the application if anything if they need you to um I don\u0027t have a preference on on the float I don\u0027t really care one way or the other I worry about doing things like big numbs simply because you\u0027re removing a keg which may have been explicitly put in the tree so you\u0027re actually changing something very significant yes so there is a there is a an assumption here that big noms and the rod integers are coming from the same space that you don\u0027t want to have a map that has a big number one and and fix another one as two different keys and I think I\u0027m behind that assumption yeah about it that would not be true in the world I\u0027m thinking of in terms of some stuff okay well I might play more in the cryptographic world so big numbers and integers are completely different things Oh Madison what do you usually num1 for that could be Paul Hoffman can answer that the first thing in a in a counter "
  },
  {
    "startTime": "01:04:38",
    "text": "that has to have 128 bits yes why can\u0027t you represent this in 64 bits or 32 words on because the counter is supposed to be a hundred twenty-eight bit yeah but that\u0027s true of all integers integers and see what are 64 bits but we represent them in 32 bits and magic thing that\u0027s in it fits if we can so how is that different from bigger we did that the question is is there ever a situation in which technology makes you take a different application path then the same number if you look at for example a DSA signature it consists of two integers yes which I would probably represent as big nuts one of those integers could be one yes but how would it help if you can analyze this only one I mean yes I see can try you know this is the DSA signature so you know that this is yes I mean it so you know what these are so by canonicalizing them down clear out the representation you don\u0027t use any information this is Geoffrey Gaskin I\u0027m two examples from the webathon Fido security key space Adam Langley tested a bunch of security keys for their ask them wonder output and discovered that many of them had bugs in which links they gave to the to the numbers if a number was was a byte shorter many of them forgot to shorten the the dur representation and so in our canonical in our preference for the canonical encoding are we going to introduce those bugs into implementations of seaboard based protocols the second example was there\u0027s a geolocation extension to to live authentic like shortest encoding for the floats they yelled at me they said make it make it the 64-bit floats because that\u0027s simpler to implement now I don\u0027t I don\u0027t feel that strongly because this is just a preference individual applications can make the other decision when it\u0027s right for them but but in both both cases the kind of fixed length encoding seemed to be easier to intuit matthew miller so kind of going back a little bit to the correct cryptographic context so especially if it\u0027s used as a counter the semantics what it\u0027s really meaning is the semantics are treated as a counter but it\u0027s syntax is expected to be a set of bits this many this many "
  },
  {
    "startTime": "01:07:40",
    "text": "long and losing the information can be death can be catastrophic to decrypting for instance now i kind of have the same feeling it\u0027s like jeffrey pointed out that you know it\u0027s often easier to just have an encoding and we\u0027re have a have a size and just everything works against that when you\u0027re work dealing with canonicalization issues it i I would almost propose that if this is going if we\u0027re going to go down this road that if we proposed shortest encoding or really if we need short proposed anything that we need to make it clear to people reading this that you will need to make some very very careful considerations of your own application to see if that still applies correctly so there is one case where we actually are using a SIBO encoding of of an integer where we always wanted that will be five bytes and we just represented as a bad string so on a civil level it\u0027s about string that the application then turns this into an integer is not visible on the serialization that so that that would be my way to handle these things would really need to be constant size for some reason children from the floor I just wanted to remind us that we have another option here which is the relatively nuclear one of saying canonicalization considered harmful please do not do this ever this is why we have bytes in this protocol and didn\u0027t want but this is an alternative we can do both we could but if it gets the point where we can\u0027t make these kinds of decisions we always have me week we could decide that it is a in our architectural opinion it is a bad pattern to do canonicalization of any wire protocol and it\u0027s always wrong I\u0027m not saying that I almost believe this I don\u0027t quite well yeah but I almost believe that it is impossible to do a good enough canonicalization that interoperates well into the future on all the edge cases that we haven\u0027t thought about for all protocols and so you should just avoid doing canonicalization in your protocols we have someone into q also if you want to answer custom the website applications of collectivization beyond crypt so in the crypto case we have learned that this is a bad idea in the case of hashing some data structures by a vir representation that can be a very reasonable thing to do in particular if this representation is not a once the thing is but it\u0027s just three "
  },
  {
    "startTime": "01:10:40",
    "text": "individuals or something like that and using that as a unique hash key is something that that we probably want to support ago I was going to bring up the fact that what do you expect to happen if you decode andrian code with a canonical compliant encoder would you expect it to take for example that big nom and convert it to an integer you hear the question yes I\u0027m trying to understand because the consequence of this is that you changed the stream if it actually changes from a big Nam - - and to an integer which means that the other side the one that actually created that byte array might no longer be able to interpret it if it did not understand big numbs in the first place so to canonicalize big numbs you actually make big numbs mandatory feature for all implementations would you agree with that do you think that that should be the case well I believe any decoder that finds a big nam with a value one is free to turn this into a one so that may be an somewhat more expansive answer event and the question you know one other thing that the decoder may want to do is check canonicalization so look at the stream and see whether it\u0027s actually genetically encoded which trivially may be done by Rhian coding it and you may want to put this into your decoder so that that\u0027s another function that a Dakota four canonical encoding a one-time CR go to did that answer your question it did it did not satisfy me but did answer yeah go ahead matthew Miller again so kind of going back to Joe Hildebrand site suggestion which I contemplated coming up here much earlier to suggest maybe as a as a an alternative nuclear option punting on this completely and letting it be in a separate document that we can hatch over is Jeffrey Gaskin again in response to Joe\u0027s comment I got advice from Adam Langley that all of the specs that I do should specify canonical output in order to facilitate testing because then you you only have to assert that your bytes "
  },
  {
    "startTime": "01:13:40",
    "text": "are this not in this set and then that that decoder should enforce canonicalization so that again the the encoders are constrained to produce that canonical output I I think it it is totally plausible for this document to not say what the canonical encoding should be be a change that I that I wrote gives kind of the base a base canonicalization for for the basic generic data model but not the extended generic data model and and gives that a name so that other specifications can refer to it when they\u0027re defining their own canonicalization and I think that\u0027s sufficient we we don\u0027t have to express preferences about how to canonicalize big numbers or floats we just say other specifications must must specify it this is a comment from Shawn I guess the point is to what extent is C board type and tag information supposed to be preserved when serializing between different implementations i guess i\u0027ll this is gem now I tend to agree with that question because are you trying to see are you trying to canonicalize the data model or are you trying to canonicalize the seahorse structure yes you keep the two of them are they\u0027re gonna be different are going to give you different answers yeah so indeed in the data model an integer is an integer and did it the data model doesn\u0027t tell you whether you need to encode this with a particular wave field or therapy immediately in the first byte so the the encoder actually has a choice they and there\u0027s also an assumption that a decoder discards the information which length was actually used because it\u0027s none of the business of the application to look at that length so that\u0027s a pretty strong statement but I think that something that\u0027s really important to enable generic decoders because if a weird application for some reason starts to keep on serialization details then you need a completely different decoder which by the way will be a by factor of three slower then then the one that just discard this information so I think it\u0027s important to be able to discard irrelevant information in a decoder now whether that applies to interval this big none we certainly can discuss I personally believe it does but the specification currently takes no position Sean Leonard I this is "
  },
  {
    "startTime": "01:16:43",
    "text": "responding to Matt\u0027s comment I think it\u0027s worse a separate document which also made to find authorization but I agree with Joe that an option is just to say don\u0027t do it this is Joe Hill friend from the floor going back to the question that was asked from the jabber room I do think it is a property that if something is in canonical form as bytes in the wire and I get those bytes and I parse them and I regenerate canonical form 100% of the time those bytes have to match exactly no matter what the canonical I mean that\u0027s what canonical means right without that property we have nothing so that\u0027s not exactly the question was asked I think that\u0027s the like if I take random stuff in and have the canonical stuff it\u0027s always going to different slightly and in all the different ways if I take canonical stuff in you should come back out analyze exactly or or we shouldn\u0027t do for me this is almost the definition of rapid yeah uh-huh given that and I\u0027ve just been thinking about you even saying person about that it decoders should throw away unimportant information with her examples and I\u0027ve certainly seen them and you and I talked about this when we were doing is the first time where decoders throw things away and then make an assumption about what they\u0027re looking at I think it\u0027s important for us to keep this what you were considering irrelevant information so that a big numbing in as a one still is a big number one once you\u0027ve taken it in and therefore I think that we have exactly the two choices of pretty much keep everything or don\u0027t do canonicalization and I you know you and you and I went through this a whole bunch because I by the way for those of you in the room I was the one who said canonicalization and and Carson was just screaming madly from Germany like for a week about no no no and this was mostly due to crap Jim and I have dealt with an ASN one you know from earlier I think that we\u0027re now in the same rabbit hole again and I think what we should do for this document is to say canonicalization is hard or oMG as you can on previous slide we are not going to recommend things we are going to give some observations about canonicalization but you make up "
  },
  {
    "startTime": "01:19:44",
    "text": "your own rules and you\u0027re gonna cry this is Jeffrey yes Caen um I think I would heartily endorse a statement that generic conical is a ssin is a bad idea because the generic thing cannot tell whether you\u0027re big no mattered whether it mattered that it was a big numb but I think protocol-specific canonicalization is important whether in this document or another one thanks matthew miller um look i mean ultimately this this you know this data format has some pretty strong ideas of what types are as opposed to json where we absolutely needed to do these do these things or you\u0027re gonna run into big problems and these big problems weren\u0027t so much that you know two different things might have the same core meaning but my serialize method differently they would blow up and that that from everything i was served that\u0027s not the case here so i don\u0027t you know i i would be cautious on trying to go too far down any road around the canonicalization or dangers other than things that are super obvious which right now there\u0027s not really any bit so but you know i guess this just what yet one more vote to just not does not deal with canonicalization in this document this is Joe Hildebrand from the floor again I believe that a world that had 20 different sea bore anomalous canonicalization mechanisms each of which a generic library probably had to implement separately from one another with all their minor twiddles would be a world that is strictly worse than where we are today it would be worse in enough ways that I think I like a sand one starts to look good again and I think that and that\u0027s those of you that\u0027s why Matt made that noise those of you who have heard my various rants on hiss and one know that that\u0027s a relatively strong statement if we look at Durham vs / vs / vs XC are horses what have you oh yeah and asn.1 like that is an anti-pattern and I get that those are encoding rules and not canonicalization rules but they\u0027re related the failure the ways that that fails are related here in the the myriad number of little bits that I need to write in this and one system in order to parse their entire world and generate their entire world and I really really don\u0027t want that so I would be okay with saying one of three things I\u0027d "
  },
  {
    "startTime": "01:22:49",
    "text": "be fine with number one never canonicalize it\u0027s evil number two here is a canonicalization mechanism either in the stock or a different dock though those are the three things either in this doctrine i would not be fine with number four which is hey canonicalization might be interesting here some stuff you might want to consider and go write your own and let a you know but there\u0027d be many of these I think would be a fit so echoing a channeling Sean Leonard my first impression is that there\u0027s a big distinction between equivalents of major data types ie 0 X 0 1 versus interact users are 1 when they\u0027re both ends and the equivalence of tag data types so that\u0027d be you know big numb of one versus an engine 1 because of the big numpad okay so I think we still have to decide whether this becomes a separate document or is done in in the main document I think all the other questions remain on the table by the way so I think we can discuss the technical issues independent of the procedural issue how Xavier know this so I you know I\u0027m a fan of batteries included so you know where we are my preference would be but if it\u0027s too hard to fix this in a reasonable timeframe my I have a patch to improve some other bits of Seaboard definition but I think that the rest of the spec is fairly close to ready and from the discussion here it sounds like canonicalization is not so just to make to make progress easier I think I suggest that we pull out canonicalization now into his own document and proceed on them in parallel so Alexi is nodding his head and thumb shopping that I did just want to point out that what we\u0027re doing here is moving to the impression I got from their own is it in between strongly saying that it\u0027s a bad idea which is a one or two sentences saying very little or doing it in a separate document if people can agree on saying very little or strongly saying against it hopefully you can do "
  },
  {
    "startTime": "01:25:50",
    "text": "it quickly if you want to do anything more you should do a separate dot that\u0027s I mean so and and keeping in mind that what we\u0027re doing here is moving the full standard that\u0027s definitely looks like it\u0027s not baked so we could also spin again before going to full standard we could do another Hoffman um thinking a process here I think that the vast majority if not everything else in this document has strong consensus in this doesn\u0027t to me that calls for a separate document and in moving to full standard one of the things as acceptable is to split out stuff from the early one that in fact didn\u0027t work and in this case didn\u0027t work yeah or move but in this case didn\u0027t work means didn\u0027t have a strong consensus as everything else and poll before I before you go and before we get to Thiago I have a clarifying question would you see the thing that does not include canonicalization the thing that is going to full standard taking a strong ref on that document or not yes I think it\u0027s fine to say the previous document started down the rat hole we are now simply removing the rat hole maybe a different document will happen you know having the forward ref and a full standard is like a bad idea well I mean it was blowing us and it was getting a number but yeah it might be procedurally the right thing it might be but I think a better thing is to say is we might have there might be a standard track docket or there might be a document in the future for this and leaving it at that because in fact we might not have consensus on the separate document either I don\u0027t want a bet that we will I mean that separate docket document could also say updates the full standard although dates a full standard is odd isn\u0027t it yes and I think wrong I think I don\u0027t think you can update a full standard unless you are at full state so that doesn\u0027t mean yeah I think for this document we can say we took it out for a reason yeah and it might get pulled back into the universe in a different doctor yes so since we already have the text for the 74 separate document review an internet draft for that tomorrow morning so we can start working on it but I think I\u0027m taking home that this is the best way splitting orders the best way and I think Jeffrey gave an example of why even including strong language about the benefits of deterministic encoding which is a chump I prefer what canonicalization is a useful thing in cases that we don\u0027t have better scars for okay iago hand I think you just wanted to point out that the equivalents "
  },
  {
    "startTime": "01:28:51",
    "text": "for keys that you had only the external data model might need to be yanked out as well because that ties very closely with canonicalization and making sure that no keys are repeated sorry I\u0027ll say let me say that in a microphone what I said what I mumble to myself was that\u0027s a good point it\u0027s not obvious to me what the answer to that is we should probably do a little bit analysis before snapping the judgment my view was would be that if we cannot do increments for his then we should stick with 70 49 that\u0027s what\u0027s the problem and taking that out would be a major mistake I also don\u0027t think that it actually raises exactly the same of it it\u0027s not the same problems but it is to be looked at so I agree with whoever just said there just need to take a look do you agree yes thank you I think we can move on okay so that that\u0027s all ahead on the document did I miss any ones yeah so this was just a reminder no this is just a reminder that we have this implementation metrics Franchesca already mentioned it and we will all have an implementation we\u0027ll want to look at this again and see what we can fill in yeah it\u0027s not a formal requirement but I think it\u0027s just prudent it\u0027s just sanity checking to do this at this point in time this is jeffrey askin not directly related to any of the slides in making changes to see Horvath\u0027s over the last period I think several people sent pull requests and discussed it a little bit on the list and then kind of all at the end all merged them all and it was it was hard to tell whether consensus had been reached whether they could have been merged earlier and of course earlier merging makes it easier to write later ones without conflicts and it\u0027s a conflict which caused the duplication of the data model section so I want to see if there\u0027s a better way to get to determine consensus on the list to accept a whole request there are several small leads in what\u0027s "
  },
  {
    "startTime": "01:31:54",
    "text": "in the master right now that we probably have to raise in general we said that pull requests for big parts of the document should go to the mainland list I think that\u0027s what you have done for most of them and I understand that they were like old pull requests that they were in consider when merged like that new pull request that they did the same parts etc yeah so I don\u0027t know what\u0027s the best way to solve this but yeah working with the editors and working group that\u0027s yeah and you know just just trying to get a little bit more aggressive about merging when we think the consensus has been reached and I think you know if you\u0027ve got a pending request and it feels like the discussion might be over and if you ask the chairs to you know move the ball also in general I noticed that people come up and scream when they really don\u0027t agree with something so when the list is fairly silent or you have had some consensus that means that also for the for the auditors that dateable requests could be merged in there we can define a cadence for when we do that so I mean if nobody is screaming for 0.5 micro seconds that doesn\u0027t tell us very much no of course so we need to have a little bit it\u0027s not a last call a kind of situation but a little bit of no idea how long can we take to respond to something before it\u0027s not a response at all - I I think three weeks for just you know for a dead discussion if it\u0027s been dead for three weeks because it\u0027s going to turn into a draft and if we get it wrong people miss a pull it out yeah okay so the answer to the how do we fix this is move faster anything about this implementation matrix I think we we got the implementations that were decided during last ITF meetings so thank you Thiago and Jim and Joe for filling this in so custom new input is we need to fill in more columns do you so do you have ideas names implementers or does anybody in the working group s get someone or I "
  },
  {
    "startTime": "01:34:56",
    "text": "will go in something great thank you thank you and as we discussed sort of off mic before the meaning what we\u0027re not looking for is for people to do a bunch of work in order to fill out the rows here and to make sure that they\u0027ve got the most complete implementation possible what we\u0027re looking for is what did you implement so that we know what was interesting for you to implement for your use cases and just a quick comment right now not everybody has writing rights on this wiki page so just send me an email and I will update this so just for information I could have a wiki is the repository so you actually can check that out make changes you just cannot do a pull request in the general way but you can can operate already next technicians yeah that release included there are some some tags in the document there are a few tags out there and we don\u0027t need a working group to do tags everybody can but there are maybe a few things that where we actually want working group attention and just just as a reminder that this is going on SIBO we\u0027re talking just about approved as being in the RFC editor - for four days so that is a Sybil tank that we can be pretty proud of that\u0027s good work and there are a few drafts out there two of them are on charter but by selection of the people who wrote the Charter the OID one needs work we have told it for a while we just have to find the array one is on charter and it\u0027s one of the things that\u0027s very far option just to remind you what it is it mainly provides tags for homogeneous arrays represented in byte strings so JavaScript has typed arrays there is a criminal standard for type arrays and so on that\u0027s pretty much an industry consensus for what these typed arrays are and we are just providing tanks for them so we can use them seamlessly in civil documents so this document takes the position that tags are reasonably cheap so we can put the type information of what exactly is in the hajime\u0027s array into a tag which together with the various data types and the various "
  },
  {
    "startTime": "01:37:57",
    "text": "organizations leads to a total of 24 tags where two of them are actually equivalent because endianness of videos and such particularly interesting but apart from that it\u0027s pretty much a chilled matrix so this is the main thrust of this it turned out that in some implementations it\u0027s actually useful to have warning or check that pays you a raise that are represented in the traditional style in the classical style are homogeneous so SIBO doesn\u0027t tell you that you have to have all the same types in one array but to say it will be because you can find that on your own but it may be good for a decoder to promote that upfront and finally we got requests for multi-dimensional arrays and since it\u0027s easy to turn the one-dimensional array into a multi-dimensional array there is a check for that so this is thanks oh seven and that document has been out for a while and it kind of got stuck on the question should these tanks come out of a two-part space or a three much space I showed this slide the last time I don\u0027t really want to do this again but too much we have to decide and we have some reviews on their documents of all unnoticed we probably have to be a bit more explicit on the endianness issues German doesn\u0027t like that we are putting the time information in the tag but I\u0027m sure this is what most people would want at this time so I did try to defend the other position we probably need an example for multi-touch during my question that came up do we need color major Fortran style do you fill the array yeah so I didn\u0027t say didn\u0027t like yeah so what I said was this is the way that for trans toward arrays an additional no it would it\u0027s toward them column-major calm water instead of yes the opposite direction in the way you usually do this in C which is the way everybody\u0027s done it since yes I "
  },
  {
    "startTime": "01:41:00",
    "text": "don\u0027t remember more examples the document KSU homogeneity is in but it doesn\u0027t give enough examples they offer 24 tanks of the array of 24 tanks that we reserved one is actually unused and the current document proposes to retailers have reserved and yes this is intentional but of course we could use it for something to have something this D Sarge thank you he\u0027s even reserved so this is just the hole that is created by the fact that big endian Ewing age is the same thing as a little engine unit and so we only reserved we only use one of the two tanks and reserve the other one ah Jim Joe my comment was actually about the other aid which I wasn\u0027t too sure if you intended to leave them open or if you wanted to reserve the issue did something else funky to end up using them well I think these typed arrays have been around for more than five years and I haven\u0027t exactly had an idea of what to put in the first column here you should never say never but I would say just leave them unattended and you can allocate them father Kim nuts and finally just about anything that might be with large items probably needs a little bit of security reservations yeah so one reason I wanted to have this on the agenda today is there is actually a registration request fishing at Ayana in the first come first serve space for doing pretty much the same thing in a slightly less ordered way and i inau will have to take that registration so that would be a nice run around the "
  },
  {
    "startTime": "01:44:01",
    "text": "world I have tried to contact the author of that registration I haven\u0027t succeeded yet but I will continue trying so that kind of creates a little bit of an urgency that we finally come to grips with what to do about was the regex so yeah the remaining question is this Hofmann it\u0027s fine to take it from the tea light range I\u0027m one Jim you can get up and say that just don\u0027t point fingers at us I that that this is an obvious I believe there is more obvious use that we would necessarily need to keep these out and I think this is just fine um Jim shot I think it\u0027s fine i I would rather take them from the free bike range there\u0027s no need to try to conserve space for this and that makes sure that you don\u0027t end up later regretting the decision channeling Sean Leonard what is the pin denied and a registration and unfortunate I don\u0027t know what he\u0027s referring to but a little bit of the process question I don\u0027t know click on the play so I\u0027m not sure since I\u0027m the designated expert who got this on this I\u0027m not sure what I can actually say about it so we can Alexei can find somebody to to do it for this one to be the reviewer separately like what happens when a when the person is the reviewer wants something in the registry for themselves so we okay so do we need another expert for this could you talk to Mike so I probably know is that I yes oh that\u0027s within a Mexican you can talk to me because I\u0027m the chain of Appeal I think okay but essentially what they did and there is a github repository with with requests in it so it\u0027s not totally it\u0027s secret what they did is they just defined a bunch of tags for a few items out of the whole array that they needed and these come from first campus their "
  },
  {
    "startTime": "01:47:01",
    "text": "self space so they they are three by tags so they would kind of pre answer this question but they are also not in this nice arrangement that allows interpreting the tech number right III think contacting them and recommending that look this is the work which is very similar it\u0027s very sensible thing how do you do this if it\u0027s right if it\u0027s first-come first-serve then I suppose you cannot stop them okay so I should go ahead and fight in my own registration we cannot stop them we can convince them so that\u0027s 11 new that we still have they really want this yes I really pissed off we have to change there I am the registration procedure and which to do it quickly I suppose I see can override it yes I guess so I mean alright so if anybody wanted to stand up and say hey let\u0027s change the registry rules like I\u0027m standing up oh you do want to change it I just use to expert review for everything no first-come first-serve for everything that should so we get more control over the one plus one blank space and I think but it\u0027s not going to affect this is West anyway so right and I wouldn\u0027t assume that these people want to do something either I just have managed to talk to them that\u0027s coming from shine a week plus one two three range for the three by range he\u0027s worried that we may want to come along and do some additional links out of it that are even longer later date is actually on the liquid Michael Musto we did something similar in core we call happen and that does the expert a bad one but still and I thought that was quite useful to protect your your you know everybody wants their thing their shiny object the the most efficient Dom registration class and not all things are created equal for much just how widely they\u0027re going to be used in deploy point of view which i think is something that doesn\u0027t it extra than the working group can make a better call so I would agree you need some separation "
  },
  {
    "startTime": "01:50:03",
    "text": "of rules they\u0027re just what we saw in core is just everybody went for the smallest one all the time yeah this is the one data point either UT got tagged 61 and content format 61 but you see there it is maybe even more important than right here okay so here\u0027s a few people saying one plus one byte space whitespace is fine and a few more people saying 1 plus 2 byte space is where we should be going because we want to finish this discussion at some point in time it seems like getting ourselves into 101 plus too much space so that would be my summary of the discussion I\u0027m not happy because this encoding okay so the plan is to take these review comments here do a next version of the document and we should have adopted it a long time ago because we are we are not changing the fundamentally tweaking on the details but I\u0027d 1 there show age based on this um just well we\u0027ve got everybody here uh does anybody object to us taking this up as a working group draft cuz if I just I\u0027m just looking to see if anybody did we could have that discussion now since we\u0027re all here I don\u0027t see anybody jumping up to object and are there at least a couple people who think this is interesting work for us to do I don\u0027t want to do a homage cuz there\u0027s I don\u0027t think there\u0027s all there\u0027s only only one or two people go ahead all right so why I asked for objections didn\u0027t see any okay Oh Sean has some thought you got it Sean about the RGB it\u0027s interesting but I was really thinking about high dynamic range I think RGB is a bit more complicated in this day of 4k HDR 10 Dolby vision and all that it probably means some specialized data types of its own which is to say outside the purview of this Jayraj typed they arrays and then he says one more thing I agree the typed array should be worked on by the working group which is relevant okay so yeah "
  },
  {
    "startTime": "01:53:03",
    "text": "submit next version entering these comments and then we can adopt this document and then you could you could just publish it as the 0-0 I can do this right well that\u0027s validator on the list yeah I like publishing personal one yes we have seven minutes incredible so we have open mic if anybody wants to so I\u0027m gonna be stepping down as working group chair for C board here I won\u0027t be coming to ITF meetings as regularly going forward for variety reasons and if you are interested in sharing talk to Alexi and do it quickly because he\u0027s already got some interest in variety folks but if you think you\u0027re the right person this would be a fantastic time to pull Alexei aside anything else no all right great thanks everybody wasn\u0027t she "
  }
]