[
  {
    "startTime": "00:03:37",
    "text": "the ones that were Jenna trip uploaded at the very last moment but not the ones were written at the very last moment so go figure so anyway back to and the Chromebook may be godlie so hopefully we\u0027ll get something something just swell so Ronnie is taking notes in the ether pad if you have a second person to watch that say neither pad and fix anything he overlooks with nothing you a bad thing if anybody wants to volunteer Bo okay and since I have far too many laptops on the table I can\u0027t actually pay attention to the jabber so if anybody we do have we do have remote participants so if anybody wants to be anybody in that you want to be in the jabber room on the client what still works what I can keep an eye on it and you know and Bernard will be providing about Lee so we need to actually so blue sheets should be going around we\u0027ve already gone around you don\u0027t if you don\u0027t see them figure out where they are at the end and we have medical recording Nowell Nowell word wrapping here is fascinating but the content should be correct it\u0027s the old version oh dear well look up the know yeah I think this this this one doesn\u0027t have the the ombudsmen stuff so so find another slide deck and note that well agenda yes right so sorry gender which is been had a few several things attitude at the very last moment because we discovered Marco people you\u0027re talking about the people didn\u0027t tell us about until they left but you know hopefully we\u0027ll actually get through it all and if no new published documents since last time we still have three things that are sitting in cluster 238 which hopefully should clear real soon now and one thing that\u0027s blocking in another document of ours which we\u0027ll be talking about we have removed multipath RTP because they\u0027ll be interested in working on it yeah we can if somebody does come back and is interested we can "
  },
  {
    "startTime": "00:06:38",
    "text": "resurrect it we had the next slide and multiplex guidelines does anybody want to say what the status of what he puts guidelines this was virtually writing that it\u0027s that - yeah Ronnie you\u0027re the editor now aren\u0027t you so I think it sounds like both Magnus and Ronnie thought the other one should have done something on it this has been I\u0027m hearing that I Roni and Magne 3 1 2 get together talk about it and report back frame marking yeah because if you authors are multiplexed and I will talk this week to figure out what to say faint marking is multi-organ no mo is not here yet so mo push an update I think at the very you know the day after the draft deadline because of github was down even though he\u0027s thought in getting up because I begged him this is following the working new blast call so people who had comments and working class call which is I think mostly me at Magnus should read over the changes and see if his art hours were reflected and follow up on the list oh I think I see my outside that\u0027s looks like an almost silhouette there I think he\u0027s going to the other door okay somebody make sure the door isn\u0027t it is mo excellent so we had a feedback from Magnus Jonathan Ronnie and I think he wants to other folks and so we updated all that feedback and oh wait hmm and that should be the end of all the feedback the the authors are aware of so I think we\u0027re ready to progress this most of the changes were editorial the the one I should probably call out is there was a tl0 pic index there was a note that it was valid to have zero as a valid running index and so there\u0027s a question about whether or not if it\u0027s unknown is it valid to still mark it as zero so we updated text to say if it\u0027s unknown you actually must submit it so that that a receiver can be aware whether it\u0027s truly unknown or what does it mean but make me so I should clarify the text to say omit means a reduced length so it means truly remove it and "
  },
  {
    "startTime": "00:09:40",
    "text": "reduce the length field so it\u0027s not in the payload at all and there was also a point about lrrr since we updated the the restriction frame marking that you can only use it for temporally nested streams so LR temporal air refresh is really never needed because the the streams are always self refreshing because they\u0027re nested but that that raises an issue that is this restriction okay for for future needs and I\u0027m aware of a few I\u0027m aware of some work that that is not planning to do nested streams and in the restrictive way that frame working currently says so that\u0027s to me that\u0027s the only open issue whether or not people have an opinion of is that too restrictive or not so I feel like sort of what the question is is a little bit vague so would you be able to send you all the lists or describing what the that open issue is so we can make sure that you know we have because unfortunately I\u0027m there it\u0027s it\u0027s I feel like there\u0027s some concern that this doesn\u0027t solve all the problems people have and the question is does this solve some of the problems that some people have and is still useful or does it not solve enough problems for anybody and it\u0027s thus a waste of time or needs to be enhanced so I think that\u0027s the big exactly yeah we want to progress this if then we have a Biss you know you know six weeks six months later because a new payload format wants to do or even existing payload formats want to do you know more elaborate markings more elaborate structures scalability structures so I\u0027ll send a email to the list about what the issues are but all the other points are mostly editorial so I don\u0027t think discussion comments please look at this to make sure your comments were addressed successfully I think that\u0027s the end of it and share slides and what\u0027s enough next is a CC feedback what\u0027s it some time yeah no "
  },
  {
    "startTime": "00:12:44",
    "text": "it\u0027s more that we thought we\u0027d actually talk about actual working group documents before we talk about you know future of architectures the ping book seems to turned into a pink cross which I\u0027m not sure is an improvement all right so hi I\u0027m Colin Perkins I\u0027m gonna talk about the congestion control feedback so this is a joint draft with ahead Varun and Michael but none of the co-authors have seen these slides and commented so this is entirely my fault and blame me for anything possibly yes so we have the pink boxes you can\u0027t see the slides so we have the congestion control feedback draft which we\u0027ve discussed a bunch of times this is the the outline of the format I think the only change which is going to happen is that the insect post one is going to turn into a lambda field at some point I think we discuss that at the last meeting Jonathan and/or take Neal and I think we had someone remotes socio remotely we\u0027re trying to implement this at the hackathon over the weekend and Jonathan sent some feedback based on his experiences oh I guess they\u0027re expert their experience was so what I\u0027ve got in the rest of these slides it\u0027s basically Jonathan\u0027s email copy pasted it into a bunch of slides with some discussion points so we can try and figure out what to do about those comments since we\u0027re all in the room so the the first issue jump from raised was that the passing of the feedback packets is a little odd in that the only way you can tell if you\u0027ve got to the end of the packet is that you only have four bytes left and there\u0027s no actual count of the number of feedback reports in these packets reports then you just realize you\u0027ve just got the time step left and that means you\u0027ve got to the end and this is passed it\u0027s unambiguous to pass but it\u0027s a bit weird and it\u0027s perhaps a little bit of a nuisance the problem is there\u0027s not actually a lot of space for a report count right we we could stick one at the beginning of the packets that a misaligns everything and exactly I think also conflicts with the standard for congestion control feedback packets which ones the SSR season everything lined up so that would be gross but we could do it if we needed to we could maybe put a report count in the very "
  },
  {
    "startTime": "00:15:44",
    "text": "last offset very last architects which would also be ugly but perhaps in a different way or we could just don\u0027t worry about it and say that passing is gonna be a little bit or could but who cares monix as an individual I would be inclined to say the latter but point out in the draft that parsing is little off words all you have to do yes yes the advantage of putting it in the last octet is that one of the comments later is that the report types done field is not that\u0027s too much precision anyway so we probably can spare the bits just to save a byte about that but it maybe isn\u0027t worth the trouble I don\u0027t know anyone else has opinions you told my as the other one who tried to implement that at the hackathon I agree it\u0027s like a little bit awkward but I bother too much about it I mean like you your while loop is like instead of saying like while I great a zero is like while greater however you come to this visit yeah well then remaining is different for over there yes great sort of for yeah okay so I guess the outcome for this is that we believe it as it is yeah okay all right timing so the current version the draft says that the time stamps used for the report type that the clock used for the reports time stamp is derived from the same clock used to generate the MTP time stamp in SR packets and it seems Jonathan is not desperately thrilled by that choice so this was a change made fairly recently in that previous version so the draft didn\u0027t specify what clock was used and we obviously need to specify something and I thought the NTP time stamp format was a good format and that since we had a clock specified for Center reports it was easier to reuse that I certainly think the time stamp format is a good one whether we need to specify that it\u0027s the same clock or just a stable plot running at the requisite rates people if people think a different clock or any clock if the rate is used I don\u0027t know I thought it was useful that we have an unambiguous reference to which clock to use but maybe that doesn\u0027t actually matter so everything in practice I don\u0027t think it makes sense to use the media time stamp here since there are a bunch of different clock rates I think we want something more consistent than that especially cuz you have to be consistent across sources yeah yeah yes so it needs to be some sort of wall clock if we want to decouple it from the clock we use for sender reports they don\u0027t subjects but we need to specify what clock we do use so again as an individual I don\u0027t I\u0027m "
  },
  {
    "startTime": "00:18:48",
    "text": "not going to be standing up because yeah yeah there\u0027s a lot of stuff on the people\u0027s yeah so yeah my main concern is that you know typically your auntie be time stamp will come from something like the POSIX clock real time if people are familiar with that which is basically good time of day whereas for send time stamp which is thus you know subject to adjustments as you know MTP kicks in or you know somebody discovers their clock is off if they\u0027re not NDP sync they\u0027re things like that whereas typically for for feedback you want something much more like clock monotonic which is not have any sort of just sync to anything in specific but will you know be much more stable it so in most platforms it\u0027s just usually just up time since was in spoon - done yeah it seems reasonable to specify that this is stable and maybe we could even reference some of the clock performance that actually would work in for example the clock source document cetera or we\u0027ve I mean yeah I mean we wouldn\u0027t stable clock for NT for the sender reports as well otherwise lip sync goes off maybe this is a bigger problem with the hair for toasters yeah okay but yeah maybe I mean III think it\u0027s it would be sufficient here just main point out that for using a clock that has any kind of clock adjustment if he has this downside it made results in discontinuities in in the intimate time measurements in herself and maybe recommend just recommend saying choose a clock that doesn\u0027t have this property and that should be sufficient for this document but maybe we can even reference some of the reasonable clock formats if they are available based on the box or draft so if you have any suggestions for text that would be appreciated and if not I can just say well it should be a stable warlock NTP format well something counting you know this is current UTC time yes it does not what you what you don\u0027t it doesn\u0027t have to say this this clock doesn\u0027t have to say that it\u0027s currently November 28th well if it does if we using the NTP format it doesn\u0027t necessarily have to be accurate if I say that it\u0027s you know January 1st 1970 instead because I\u0027m coming from yes but I mean this this is why I lined it to the SL time step because it\u0027s an ambiguous what it should be yeah I guess "
  },
  {
    "startTime": "00:21:48",
    "text": "the main thing is there is there ever any interesting reason to correlate these timestamps to anything other than each other I mean is there a reason why you want to be able to say when this feedback message was generated versus assess our time step or is our duties only need to be relative to other CC feedback messages I don\u0027t know my guess would be that people are going to at some point and for some random reason dislike to compare them with the timing of all the other things which are timed even if we don\u0027t think we can\u0027t think of a reason to do that now but I yeah I don\u0027t have a reason why you would care about that currently so I guess for now okay all right similarly the since we\u0027re measuring the report timestamp in NTP timestamp format this gives 65,536 of a second as the clock unit whereas the arrival time offset is in person than 24 second and clearly one is more precise than the other we could save some bits we could adjust the timestamp former I didn\u0027t think it was worth the effort coming up with a different time stamp format but if people really care about the difference in precision then we could change that yeah I mean I basically just thought this is ugly and we\u0027re waste basically these 6 bits it\u0027s 2 to the minus 16 pursuit of the minus 10 that thing is them basically there\u0027s six ways that\u0027s data which I\u0027ll give them to the actual and useful information for the and this is sunny truth yes so it feels like we could do something better but I don\u0027t have a specific suggestion I mean if I believe if the previous versions of the draft basically had everything measured in milliseconds yes right both the absolute both both are report time at the absolute yeah I mean we could come no a second since the starts of the session or something not there that\u0027s perhaps a little ambiguous what starts at the session is milliseconds so I mean those I can sense some arbitrary time so this is arbitrary time that system I\u0027m a given standard rather than that nobody killed care yeah we I mean yeah we could certainly do that I don\u0027t with I\u0027m not sure it matters if we pick an aviary trip arbitrary time we should be clear though it\u0027s it\u0027s a betrayal all this stone is it point to stop messing with us I mean if we I\u0027d like to see changes "
  },
  {
    "startTime": "00:24:54",
    "text": "stopped at some point yes equally if people implementing itself having trouble implementing it then we want to make make it easier to implement that\u0027s I know is this issue worth for everybody in the format or should we just not care about those those bits nobody cares all right okay yes I mean I could specify the last six bits of zero if you don\u0027t care but doing it matters okay so what values should be used arrival time offset the packets that arrived after the reports times so I think this is the case where we have so many packets that we want we need to split the reports into two rather so I mean I think for this to happen you have basically you\u0027re reporting interval a forgotten so long you\u0027re overflowing the arrival time offset yes so there are some packets which you know have been received but they don\u0027t fit in this particular report awesome no they had theythey they did something they don\u0027t fit in the report it\u0027s that they is that their arrival time doesn\u0027t fit they can\u0027t be represented at the arrival time offset I\u0027ve given that the arrival time offset is epsilon under eight seconds this basically requires your reporting interval to have gone above eight seconds yeah so basically so this would but that\u0027s a vain is that you know you can see and and also things are in turrets reordered by more than eight seconds essentially this is packets which are in the future for a particular report right so you have to use at the time you get around generating the report you discover some of the packets their arrival time stamps are more than eight seconds ago so you need to generate two reports but I think the conclusion is right anyway okay so yeah we need to clarify exactly what\u0027s here so we can write the guidance but I think it\u0027s yeah we might not have not received okay so the second point is what what actually is the time stamp in the what actually is the report type step and currently it says the time instant when the packet was the report packet was generated yeah yeah I\u0027m confused yeah this is the same issue as previously that the time the report was so if you discover that you can\u0027t represent well you know you\u0027ve got more "
  },
  {
    "startTime": "00:27:54",
    "text": "than eight seconds of evidence to report yes so you have so one of them you have to pretend that you generated this report eight seconds ago so that you can represent the arrival time offsets of the oldest packets yes then the report types have will not be when the packet when this report was generated because that\u0027s now you know you\u0027re faking it uh speaking eight seconds ago yes so it\u0027s it\u0027s so it\u0027s as yes and then you work generated as if it was generated eight seconds ago but then it\u0027s I think it\u0027s mostly just semantics of what thought yes but the point is you can\u0027t rely on this for things like are geeky value no argue T estimates or anything cuz it\u0027s not it\u0027s you know this it\u0027s the time at which this report is true or this report was true not the time of which no necessarily of time in which it was generating exact so it\u0027s per what it probably wants to be as the time at which the last packet in the thing was received such as the arrival time offset for last packet is zero but that would be a clear and unambiguous definition yeah but the tricky thing there is that because you\u0027re reporting over multiple sources that we do have to scan all your sources before you can figure out while you\u0027re it that there is a time which indicates that the point at which you are reporting on that doesn\u0027t necessarily represent the time at which the packet was generated and that\u0027s the thing we need to be clear because it could be a time in the past so there is a report time something the packets it currently says it is the time the packet was generated I think we decouple it from that we say that it\u0027s it\u0027s the the report time there may be in the past this is thus this was the state of the world as of this time yes yes it would typically be the time at which the packet is generated but it may be a time in the past you know Mia but the whole problem only arises for the scenario where you generate a report for the past if otherwise the assumption is always that this is like no yes but there\u0027s there\u0027s quarter cases where you have to generate something for the past or to correctly represent when very old packets are up so sorry I guess actually what it may be is if you have more than one if you have so many reports that you need to have more than one report packet then it may be a time in yeah some of them may have times in the past yep which which is rare and should only happen if things get really ordered in weird ways like or either things get reordered in weird ways or if your session your group size is huge and your rtcp balance is small such that you\u0027re reporting interval gets really really long yeah and in that case you might not "
  },
  {
    "startTime": "00:30:56",
    "text": "even set the reporting time stamp to like in the eight seconds in the wall but you boys it probably for like the the one where you\u0027re generated form or the eight seconds you probably set the reporting times them right at the at the earliest possible time of the the extra packets you need to report okay yeah yes so I think we need to explain that there are odd corner cases where the you have many packets to report and then the intervals don\u0027t work where this may not give the extra generations okay overlapping reports yes yes so we need to just do the right thing with very old packets and not report them as lost but report them as being out of range if we can but yeah so that\u0027s that\u0027s just a strike for clarification okay so we currently say that the consecutive report should just be consecutive sequence number ranges should not overlap obviously if you have a big outage then you don\u0027t want to send a report on the last ten billion packet or ten thousand packets which which were in the outage so we need some words to say do something sensible as an outage and that\u0027s just a bit there\u0027s all this because my email will sort of incoherent there\u0027s also the converse case here that if you had package sometimes you\u0027ll actually get a slight overlapping reports if you have to say pact and reordering right at the plate you set a feedback you want to actually go back and say hey yeah so yeah I previously reported through packet seven saying back at six was lost now a reporting saying that get six arrived and yeah packet seven still arrived and yes so there\u0027s some overlap yeah okay so again that\u0027s just a clarification of exactly what to do in the budget corner cases report on duplicates if you get a packet and if you have multiple copies of a packet which one should you report on I suspect it doesn\u0027t matter my my gut feeling would be to say we report on the last copy of the packet received but if you want to make it first they don\u0027t care I think probably most recently received yeah killer if you happen to get a duplicate packet after you know you report on a packet then you get a duplicate of it again after you set the report you should have probably had an updated report with the new arrival time in the next Republican tax report yeah which will again have it overlapped okay [Music] ya know with the new type step well "
  },
  {
    "startTime": "00:33:57",
    "text": "Mohsen Attia from from the implementers point of view yes some of these things are confusing weird and it seems like we\u0027re just coming on you know making up answers that sort of makes sense for an implementer but I mean the point of all this is for a congestion control implementer and so I\u0027m wondering if any of these decisions are actually impacting how the congestion control algorithm actually works like the congestion controls expect feedback on duplicates and if they expect accurate feedback on the duplicates and if we make a decision about it\u0027s gonna be the first to the last wouldn\u0027t that impact their algorithms because they\u0027re using these these numbers to actually calculate the available bandwidth some of these more concrete issues my guess would be the duplicates so very enough that it doesn\u0027t make any real difference in practice I suppose you might hit Kona cases where that\u0027s not true although there\u0027s there\u0027s two reasons for duplicates one is that you know you really do have the number replicating packets which is pretty rare the other is people who don\u0027t let RDX properly and just respond that they reset it\u0027s a packet but hopefully we can stop doing that dose yeah this is the the firt this is the one that actually made me think about we really need to bring this up to the congestion control pointers the other ones may also be relevant but this one immediately struck me is that if I was implementing the congestion control I would want to know the first packet received because the deltas that I\u0027m calculating and and the the the delivery offsets that I\u0027m calculating the duplicates are irrelevant to me it\u0027s really the first limit because if you start giving me reports on the duplicates those are going to probably skew my my calculations so I think the earliest one is is the one that probably makes the most sense for a congestion control implementer no I mean you\u0027re right that we should probably bring it up for the congestion control people yeah certainly thought about that okay okay which SSRC ste reports button sir currently says reports on every SS SE that\u0027s being congestion controls the issue is of course to receive a counter which sources are being congestion controlled so you should probably just say report on every active SSRC signaling a TCP feedback STP negotiation allows you to limit feedback to a subset of payload types should that be allowed for congestion control feedback what I hadn\u0027t realized it did that I only realize this because when I went to try to interoperate with Nils he set the signaling that way I can imagine weird corner cases like for example if you\u0027re sending variable bitrate video along with low rate constant bitrate audio you possibly don\u0027t care about reporting on the audio for congestion control because you can\u0027t congestion control is anything "
  },
  {
    "startTime": "00:36:57",
    "text": "in the congestion control is just to stop sending it and you know if you have 10 kilobits of audio and 5 megabits of video who cares about the audio so maybe you might want to do that yeah I mean in case you told me I think in this case it\u0027s this should apply to your RTP transport not to the actual coded correct this is agnostic of the codec but yes the rtcp feedback specification is I mean yeah you showed me like the implementation worst are I guess I mean the question is if that needs to be written down here in the draft to say like it always needs to be happen with for all the codecs you\u0027re offering having that I can certainly imagine cases where you have codecs which you can\u0027t congestion control it\u0027s no point to any congestion control feedback for no because you can still those but you know you\u0027d still you still know how much conditioner is on this whole session and you take away the bad you take away there that\u0027s from the yeah but you know I mean if you\u0027re sending video and you have a very low rate text channel awesome then why bother sending conditions subtitles gasping any difference how do lava strum and the we recently started out on this stuff was because we need a transport right congestion control implementing the mechanism in such a way that you can usefully use feedback on only a few packet types in this session is going to be severely complicating implementations and make it less useful for what we set out to do so I\u0027d strongly strongly strongly at least strongly suggest so that we just say report for everything all the time don\u0027t and implementers should not have to care about the case where you the implementers of the fee of the sending feedback should not have to care what what the other side does with it that\u0027s the whole point and the sender has to sort out yes I\u0027m getting packet loss and now I have to allocate bandwidth between the text channel and audio channel and the video channel that\u0027s the sender\u0027s problem sure but it\u0027s the sender\u0027s problem in this case as well yes you know if the the sender if the sender is only able to say to say I won\u0027t feedback on everything and then the receiver only has to implement support for sending feedback on everything yes what we\u0027re not saying is the feet that the receiver has to care what the sender\u0027s doing at which source is being conditioned controls well know what is saying is you use some some streams you just to make the reports I mean I mean if you if you "
  },
  {
    "startTime": "00:40:04",
    "text": "specify for some media sections and not others well that\u0027s the thing something you can do with it we will STP that\u0027s sad but I think you should I think that the the use case we definitely want to support if congestion control for a whole transport and anything that makes that life more complicated for implementers should go away until unless it has a compelling use case okay so we just specify that if you have to specify all types yeah and if you need somewhere and if you if we agree on doing that and I would suggest that you to make it life easier for implementers to mandate that you basically use this in STP with Artie see if he picks star to avoid the situation that what I basically sent Jonathan was the list of like here are all the payload types and I\u0027m listing it on all on one because if we allow that then you actually need to require from the implementers to go through all the pale up types and ensure that it\u0027s actually turned on for all of them and handle the corner cases of like what happens if it\u0027s not implement not offered on one of them so I think the easiest solution then is to just say like it has to be done both star okay the end of story okay sure that makes sense Mohsen Attia so there\u0027s a consequence of this this means that all retransmission formats and effect formats would also be mandated to give feedback receivers would have to feedback for every r-tx or unless you did them in a separate section so that separate section is a whole other thing but but I think you would want that because you want to get feedback because again it\u0027s you\u0027re kidding you want to figure out how much total so I was getting through on the session and obviously what\u0027s what\u0027s experiencing congestion which particular SRC has experienced the congestion does not have to be which just as our C\u0027s you\u0027ll adjust you know to produce your grease your bandwidth it\u0027s entirely up to the sender others associated but I think yeah I think actually sending the feedback for the all the repair flows also is absolutely want worth explicitly calling that up because there may not be obvious to an implementer okay yeah makes sense okay yes we should fix the editorial notes [Music] which will be up next burner happen not your guard okay so Bernard if you wanna get in the queue [Music] already be over guards Butte Burke multiplexing right so can you hear me yes okay cool "
  },
  {
    "startTime": "00:43:04",
    "text": "all right this is a presentation about quick multiplexing it\u0027s a follow-on to a presentation that Cullen made at IETF 100 so we\u0027re gonna give an update on where we are and what I\u0027d like to recommend the group do from here next slide okay so just recapping the problem Creek is potentially attractive as a peer data exchange mechanism for WebRTC applications primarily that is reliable transport which is defined in the current transport document but they\u0027ve been some interest in unreliable transport for things like games or potentially media and people are proposing unreliable datagram and extensions to brick rubber to see applications almost always multiplex today and that\u0027s our TBR case you eat them and you kill us all on the same soccer very very popular that\u0027s currently documented in their RFC 79 80 so in terms of solutions multiplexing of stun is absolutely required because otherwise you\u0027d have to reinvent some equivalent mechanism to do pewter peer make multiplexing with DTLS SRTP and sr TCP is required if you\u0027re gonna do use our TPS RTP and rtcp alongside quickly and if you can do that you get also the ability to mix quick and the SDGs data channel as well next slide so some non requirements are support for turn channel multiplexing that\u0027s an optimization which I believe is not supported in any web urges the implementation where you have a core architect prefix excited the standard 36 like text on overhead also ZRTP is used in wherever to see as far as I know and that\u0027s an alternate key exchange mechanism so we don\u0027t require that these actually work although okay they don\u0027t break anything Thanks so a little bit of a recap on past events March 2017 Colin Perkins and large either first noted compatibility of quick with RFC 1793 and of an issue I in November of 2017 in ITF 100 Colin presented type tf2 ABG core potential solution on the weber 29 that solution was proposed as a PR emerged into quick transport Oh 8 and subsequently in December PR to undo the changes was rejected and as I\u0027ll describe quick has evolved since then and so the solution proposed by Colin has changed a bit and "
  },
  {
    "startTime": "00:46:05",
    "text": "we\u0027ll talk about some of the implications of that next thing so this was the t multiplex for clothes that I kept running underneath it the main differences here are that there\u0027s potentially some overlap between quick and the turn channel but as I mentioned that isn\u0027t really consequential cause where\u0027d you see em invincibility valve support the turn child and then quick is also in the range 252 to 5 which is the long hitter so basically this this meets all the requirements and some things that were non requirements like not conflicting the vo to be next okay now a few words about the DTLS allocation here it\u0027s important to understand that currently DTLS does not use anywhere near the full allocation as you can see this is the Ayane table and for DTLS the requires coordination which means a potential conflict with 79-83 is in the 0 to 19 and the 60 40 to 55 range but 25 to 63 are currently unassigned 25 will be assigned by DTLS 1.3 but basically a large portion of the DTLS space from like 26 to 63 is currently unassigned so that\u0027s something to keep in mind in the slides that follow Thanks so since the presentation I tip 100 the idea of using quick and web urgency has gained some traction we have a JavaScript API spec on their active development in w3c its protrude a lot from annotation experience and has been following the quick transport dock adding support for unidirectional streams as an example and lots of lots of interest in it and some implementations are coming there\u0027s been an attempt to implement filed there are people experimenting potentially with additional scenarios like carriage of media so so quite a bit of interest here next so why can\u0027t we declare victory at ITF 100 basically said we would document this purely in the quick spec what\u0027s wrong with that well history shows that if you have an undocumented algorithm or agreement something is likely to go wrong over time one of the things that can go wrong is if you don\u0027t document 8 document requirements in the IANA registries like what we have for DTLS someone could assign a code point and step on something without realizing another problem is that I think more relevant here is that if you have an undocumented algorithm it\u0027s likely particularly one that changes with different drafts of quick it\u0027s likely to exhibit interoperability problems and as I\u0027ll describe the original proposal from IGF 100 needs to change a bit and if we don\u0027t write this down eventually some developer is "
  },
  {
    "startTime": "00:49:06",
    "text": "going to find some old set of slides go implement it in something bad will happen and that\u0027s particularly true since we have trials of approaching with this and once those are out people will start to depend on multiplexing you\u0027ve got whereby GC which is being deployed all over the place some 100 applications 1.5 billion users so it\u0027s very easy for something to get out in the wild and be very difficult to recall if it\u0027s broken and so at this point if there are problems with multi node some support that would have consequences and I believe I\u0027ll try to make the argument that are we needed to document this in an RFC 79-83 this just so developers know how it all works we also go over it very carefully and understand exactly what we\u0027re telling them to do go through the normal process next so this was particularly brought home to me and going over the transport draft version 16 and comparing it to the o8 and trying to figure out what changes were needed in the d multiplex algorithm the long header didn\u0027t change and the type values field values are pretty much the same so that was more or less as it was in Colin\u0027s presentation so at least that part is good expired but I noticed a few things that I had to scratch my head about one is that there\u0027s a stateless reset packet with a key phase bit so the the actual short header has changed there was a C bit in it that we talked about it I tip 100 it\u0027s now a K bit for key phase and this brings up the possibility of potential overlap for DTLS namely code point 48 as I described earlier it\u0027s not actually 48 adnan actually an allocated VPLS code point so even with DTLS 1.3 nothing bad would happen there but it but it does in Japan ridiculous pace as allocated in our C 17 I need 3 thanks so the short packet header header has also changed and there there\u0027s now and some orbits which you said randomly that generates for point value is 48 to 55 for the potential overlap with each LS for a k value of 1 that\u0027s in the range 112 to 119 which was taken into account in the previous I chip 100 proposal so that\u0027s not an issue but again we this potential overlap with GG LS which is not documented in are currently in RFC 1793 Thanks and finally there was a version negotiation packet that\u0027s in Section 17 point 4 which has a high order bit set to one and then a bunch of unused bits which are set randomly in the server and that generates value is 128 - 2 - 3 - 55 which can overlap with RTP and rtcp that\u0027s not a big problem because if the version field here the next 32 bits will be 0 for quick so you can check that and "
  },
  {
    "startTime": "00:52:09",
    "text": "realize that it is not in fact RTP and rtcp it\u0027s a quick packet but that fact was also it\u0027s not something that\u0027s in 1793 or in the IGF 100 proposal okay so based on what I\u0027ve just shown you here\u0027s what I think the revised e multiplex proposal looks like and again this is something I think you has to be double a triple check but here\u0027s where I think it ends up which is pretty similar what came before except that code points 48 to 55 would be forwarded to quick that would be from the short header you\u0027d get one swell to 119 also from a short header potentially for 4 different values of the Cape it you would forward 128 - 1 1901 - RTP and rtcp but only if the version field the next 32 bits was not 0 and then I think - 52 to 55 would still go to a quick and that\u0027s the long header so a little bit different from what we had an idea 100 I think still workable but a little a little bit different and also some additional checks that have to be done from what we had there you can\u0027t just look at the first octet uberx yeah well one question on the version check so would not overlap with the time stamp and RTP and what was it was timestamp 0 invalid or somewhere coming about so how\u0027s the house that it\u0027s a pretty poor heuristic I think if I rely on good point mode this is why I think we\u0027d have to discuss this good - double double check this I think that yeah there would be if you potentially had a time stamp of 0 you could make mistake there might be something else we would have to look at in that case I guess the point I\u0027m trying to make your mo is that this is worth documenting and reviewing in the ITF rather than leaving this - and one other questions so sorry I forgot where things landed on the multiplexing draft I thought those discussion of squeezing the turn range to something much narrower that didn\u0027t happen it\u0027s still the full range in the in the multiplexing draft the RTP multiplexing draft of squeezing the turn range into something very narrow even narrower than this in this 64-bit 79 well I don\u0027t recall it that\u0027s certainly something that again if we had a draft to actually talk about we could we could do and might well be worthwhile so I guess that would be another reason to actually have a document and put it through the process so that we look at it and understand exactly where where we stand I thought that simply we said that the turn needs to be D munched from just "
  },
  {
    "startTime": "00:55:11",
    "text": "turn trails even be too much for stun but other than that you always know is this a packet coming from your turn server or not okay no yes if the IP and port is coming from your turn server between it his turn or stun otherwise you don\u0027t it\u0027s can\u0027t be at your general so I think I think that\u0027s a separate separable problem so the con I was going to make sort of the general come up Bernard is that well so I think the problem here is that we\u0027re thinking about it only from one entity\u0027s viewpoint and there\u0027s maybe multiple entities that are concerned about this and want to do it may not actually be the receiver that that cares about this there may be you know stateful boxes on the path that you know that also want to understand what this is and so if they you know now they have to know what the turn server you know IP import is to you know in order to know that it\u0027s turned so I think it adds a layer of complexity for for democracy daren\u0027t necessarily the final receiver better if we had a turn range that\u0027s well defined that fits narrowly within you know the quick and RT PRT speed DTLS de-mux strategy yeah I think your point is a nothing I\u0027ve shown here would make that impossible I was actually surprised that turn was still allowed 64 to 79 I thought I thought it got I thought was already squeezed down to some time yeah I probably have to triple check for the quick document but my understanding is if there the overlap there has been reduced but again it\u0027s requires triple and quadruple checking to make sure you understand all the ranges that can be done here I think the most important thing is we need to update the multiplexing - I\u0027ll just say that quick is RTP v3 and that\u0027s a whole nother thing which we\u0027ll talk about in the next next presentation but next yeah I would I was going to say is I feel like quick sort of had this there\u0027s what the current quick to be doing s they\u0027re calling it now is doing and then there\u0027s what quick is guaranteeing for the future which is the wire image and I feel like this needs to be more what is the wire image guaranteeing which might be need to talk to I guess it\u0027s Martin Thompson about just sort of say what is he willing to say that click is going to guarantee not just in this version but in all future versions of hotel the agreement was that we were only talking about quick version one because by definition the quick version numbers if you go to a different version negotiated a different version you can change almost anything so and I think the thinking was basically the inversion to you know who knows what it could do so you can\u0027t really you know make absolute promises about it but so that so my recommendation would be to just try to document what goes on and quick v1 maybe not call it quick but just quick version one and make that clear so "
  },
  {
    "startTime": "00:58:13",
    "text": "that we would understand exactly what you know what the promise was but I think that\u0027s also one of the arguments for documenting something if you write something down then everyone knows exactly what you\u0027re agreeing to do or not agreeing to do and what exactly the advice is like my overall impression from reviewing transport 16 was that just leaving this as folklore would be potentially very dangerous like leaving a gun around with someone who shoot themselves and also in particular there might be changes to the TLS content type registry for example to cite values 48 to 55 which have overlap as requiring coordination in RFC 79 80 through this not that they\u0027re likely to get allocated anytime soon but just to make it clear what the statuses all right so do people agree this is worth doing and I guess since 79 - III was able to chorus we should take it on as well even though obviously the coordination across a wide variety of the a ITF and are the people who gave this presentation willing to be to submit a draft due or the author\u0027s offending 83 or whatever submitted draft updating this I I\u0027m willing to do it I know Collins here\u0027s a confidence I don\u0027t have time to lead it but I will certainly help if someone else is leading the effort so my advice would be submitted draft for I guess progress the next meeting and then or even even sooner we don\u0027t have to do everything at meetings but submit a draft and we will take a look at the side at that months we have a draft look at whatever you want I\u0027ve got it as a go through this any pupils thank you are we out of time yeah we\u0027re out of time so I guess you\u0027re you don\u0027t get to talk after all but okay so hi I\u0027m York and this is a very quick heads up there of a about a piece of work that : I put together and responds to all the artifact engineering work that has been going around and around RTP and quick "
  },
  {
    "startTime": "01:01:13",
    "text": "and running real time streams over over quake so this came from a paper we submitted to a workshop that\u0027s going to be published in December there\u0027s and we submit we sent this with Yui to the mailing list and suddenly people came to us and said oh don\u0027t you want to say something in abt core AK so here we are this is why we don\u0027t have a draft yet there\u0027s going to be one at some point hopefully not not-too-distant point in the future the the main observation is that many people have been looking at different flavors of running RTP over a quick we are guilty of of a draft of outlining some of the ideas ourselves um but quite a bit of these have been done more or less in an internet hoc fashion streaming media probably works reasonably well but interactive media we had all kinds of different suggestions or in the past this is surely not an exhaustive list from ranging from mapping each video frame in a conversation to an individual quick stream so opening 30 frames per second or something like that 30 30 spins per second to avoid persistent retransmissions because the video data might get stale at some point limiting retransmissions at some point then we have most recently a Datagram proposed that doesn\u0027t do anything but just emulates UDP over quake with a little bit of a framing or the quick stream and what we did is we wanted to take a step back and actually look back at what else what our CP has been doing and so we came up with this paper which has a good reason because doing oh it doesn\u0027t advance anymore just just just scroll to the next one so one of the one of the reasons that we didn\u0027t start off with an ID is because you can\u0027t really do some really sophisticated tables in an ASCII art so easily okay so in the slides that will be there there is a table with 21 features that describe what RTP has been doing how this is crimp how this could be addressed on top of quake and how that could in the end be all this but the fourth slide is here - the fourth one here but not the third that the last mode not the one before anyway so we have a big tape yeah oh it\u0027s PDF and PowerPoint whoo times Roman isn\u0027t a funny phone tell me so you get the idea we we went through a bunch of different properties that are you free pictures that RTP provides looked at how this could be mapped into quick and how one could put this into any and it\u0027s too "
  },
  {
    "startTime": "01:04:22",
    "text": "long to go through this anyway so take a look at it at the paper at that table out of this analysis we try to come up with a minimum feature set that one could use as a strawman proposal on how to co-evolved RTP and quick advance and we call these arty streams that have minimal edu sequence numbering rather rather than fight offsets we have media specific timestamps as we know from RTP ways to control we transmissions on a per channel fine-grained basis and then we have more detailed reception reporting which is what we figured would be the use for common transport layer features that are worthwhile adding to quick we also have a wall top wall clock time synchronization for interest into the stream what our TCP usually does by by means of a separate method a packet type and any push of all the rest to the application layer the nice thing about this that most of these things are optional so if you leave out everything yet this reduces nicely to the Datagram style service that we have right now except that it doesn\u0027t use this Ness the strange framing so this is a heads up because we feel that probably quite a few endpoints will be implementing quick and we will also want to do real-time at some point and so we want to come up with something that makes sense in the long run we\u0027re gonna have some discussion around this topic at some point Thanks questions thank you well thank you all and see you at the meeting anybody didn\u0027t get a [Music] "
  }
]