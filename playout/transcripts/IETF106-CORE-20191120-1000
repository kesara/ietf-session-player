[
  {
    "startTime": "00:01:47",
    "text": "[Music] so slowly arriving either because they have to sleep after the social or because they have been due to side meetings already this morning as most people have been this is the common group three minutes and as you can see we have streamlined this a little bit so you know only can be a chair of this working group if you have a 12 character email address so Jaime has to it had to change this yeah it turns out that Ericsson has standardized an odd lookit I\u0027m not going to explain further from this point yeah this is an ITF meeting and there is a note right slide which you can look at and we have blue sheets who are the note takers today Sneaky\u0027s so you\u0027re using visa pad great let\u0027s hope that actually works there was some interesting messages from the Secretariat about the internet yesterday who can help because if I don\u0027t okay great so the the agenda has a lot of items and some pretty random assumption how long we will take for these items so we will see where we maybe can can gain some time and and where we will lose time so this is the agenda for today which is essentially based around three subjects the conf work where we essentially need to issue working with blast codes at the moment and Android just asked whether there\u0027s anything in the way the the various ideas on how to use the group communication and properties that we now can achieve with Oscar so we have four segments here and finally we will talk about sin ml and because there is one document in India is reprocessing right now all that we want to get unstuck something might fall off here at the end let\u0027s see how we managed to do this because on Friday we actually have some some buffer space that we can fall into also things we don\u0027t get to today "
  },
  {
    "startTime": "00:04:48",
    "text": "we\u0027ll move to Friday and the main subject of Friday we\u0027ll be discussing the outcome of yesterday\u0027s core application side meeting and the the related draft but of course we will need that that buffer to handle everything that falls off today so two things are missing here one is the resource directory draft which is also in history processing right now actually a devaluation right now so that might also come up on Friday and there\u0027s also a draft that expired and we want to resurrect and why we were trying to resurrect it we found a minor problem with the a B and F that that actually is not that easy to fix so maybe we can bring this up on Friday as well so that that\u0027s potential changes to the agenda that will hit Friday any other things that need to be changed on the edit agenda okay so we we had our hallway discussion already that was yesterday in in-room butterworth in in the afternoon and I understand that some people couldn\u0027t go there because SEC dispatch was conflicting with it yeah it\u0027s hard to organize site meetings here but we had some good discussions and I think laws were a report on those on Friday we have a number of documents in the pipeline the the multi-part content format is in the RFC editors queue and because cluster 328 has been released it will take a while until it emerges again so I don\u0027t have a prediction for that but it will take a while several documents are in is G processing and I\u0027m a bit confused about the status of hop limit the test this wonderful text approved announcement to resend point raised right up needed yeah sorry I should have I need to follow up on this can you have a read of Adam\u0027s comment section asking why this cannot be mapped to HTTP header field seems quite straightforward I would like people to have a look at this and quickly tell me why it\u0027s not possible right so just just "
  },
  {
    "startTime": "00:07:52",
    "text": "to decode what you just said yeah we have a new hop limit yes I can mitigate cycles on the core web site and the question is why why are we unable to do the same thing on the HTTP there is some text about mapping to http and then saying but this still cannot be preserved end to end so why don\u0027t you define a new HTTP header I think that\u0027s the gist of Adams comment right okay I think we can answer that so this is the point raised yes okay sorry for not being clear yes that that\u0027s the only thing that as far as I\u0027m concerned that sort of made me pause to push the approve button okay so I think we had this discussion already a couple of months ago and the result of that discussion and I\u0027m not sure if Adam is part of the consensus of that was that we had a solution now for the the co-op side and we\u0027re happy with that because that\u0027s solving the problem there\u0027s that dots has and doing something that actually spans both sides is more complex okay I think his comment is along the lines that it\u0027s not hard to define HTTP header field for this right - just preserver yeah so we already had a proposal at one point to define a generic HTTP header here is a co-op option please transport that for me we almost had had that in our score it turned out we didn\u0027t need it in Oscar right in the end but we could resurrect that so we don\u0027t have to go through this for every new think that\u0027s certainly a generic way of abusing this comment yes that would be okay good so I know what what to do the arm but yeah one that shouldn\u0027t be difficult to get closure on I would think Thanks so the resource directory work is just in the phase where we\u0027re Alexei is making number of comments and and the authors are working on those comments so that is all mirrored to the core mailing list so you should be able to follow that discussion and if you think that that discussion is going in the wrong direction then it would be really useful if you speak up but it\u0027s not clear right now that we actually need to talk here about that and if we do we will draw it on Friday then we have two drafts that are in in the cinema cluster so we will talk about those today "
  },
  {
    "startTime": "00:10:54",
    "text": "one is the fetch patch draft how do you use any media types together with fetch and patch methods one is about the more units proposer for cinema I think we have some progress there and we\u0027ll talk about that later we have a couple of drafts that are still in the workgroup last call still in the working group they have passed last call one is the stateless draft where we\u0027re close we\u0027re close by the way and someone break him up where Klaus hasn\u0027t provided the update to the draft after the last call input so yeah he missed the deadline and we are waiting for their show for and request tag actually made the deadline and we now just need the Shepherd right up and push us put it push it through so these are the advanced for advanced elements the the one draft I talked about that it has an ABN F problem will be resurrected and when we are done with the ABN F problem we are probably ready for working up last call there\u0027s the draft missing there sorry making the same mistake again in newburgh new production call is the phaser draft sorry for not putting it on this slide we put that out yesterday belatedly and I have to apologize for that and we also have the corrections clarifications draft that went through adoption call but didn\u0027t get much feedback even though people in the room said this might be a good idea so maybe we have to reconsider that how we go forward with this do you have any other document you are worried about at the moment and that is not already on the agenda okay then we can go into the main part of the general okay hello everyone my name is Eva Petrov and I will be presenting the advancements in quorum so basically not much has changed since the "
  },
  {
    "startTime": "00:13:56",
    "text": "last IDF the documents are pretty stable for the C draft there are no updates what we did was as it was requested that the last IDF we merged the seed generation 2 with the young - otherwise we didn\u0027t receive any new comments and I think it\u0027s good for a working group to ask oh I guess at the end we\u0027ll discuss all of them ok so yes that\u0027s the status of this document for the young sea board document we updated it I think in September there are few changes that are worth mentioning like there was a conflict with this massive attack that we made we were made aware of after some discussion we agreed to change the support act that we were using and we went ahead and made this modification in version 11 the other more significant changes that shoot was changed to a must in section 5 related to young data template encoding it was clear that the intent was to be a must for us but we just it made this mistake otherwise number of editorial changes we clarified route deltas are used exactly we refer to our cat6 10-4 seaboard diagnostic notation and we have dated the terminology section we removed the plus sign from the examples added some previously missing examples for example related to live encoding with names or any xml and we updated the examples not to point to obsolete RFC\u0027s but doors are very minor editorial changes nothing significant was changed here we believed to that the document is much easier to i\u0027m it\u0027s more consistent now so we also believe that it\u0027s ready for working group last call "
  },
  {
    "startTime": "00:16:58",
    "text": "the next document it was just very at core rank library which was adopted during the last IDF so it was resubmitted us draft IDF korean Kleiber e there 0 0 the lasts we didn\u0027t receive any new comments from the last version so there are no changes to this document or the comments that were submitted before were already applied 2-0 5 and yes if there are no concerns about this document we feel that we can go to a working little group Lascaux and finally for the community document what changed from version 7 to version 0 it is that we now also reference Oscar as a possible security mechanism we also changed a shoot to a must when talking about user ordered lists in the net confirm document it\u0027s very clear that those lists must be order as they are provided and we had put a shoot before which I realized that we fixed it so those are the more important changes that we did other than that we clarified in section for the treated to how and that we should add the keys when we add a new element to a list we updated the reference to Corian library as it has a new draft name we had it idea of copyright to a young description so very minor changes already and but a few places we had forgotten to change the name cometo core conf and we fix that another minor change was that some places we were giving the recommended values /c instead of saying that it\u0027s a generic thing that users can change with we believe was clear but it could have been a little bit confusing for some people so now we use the more generic form and we removed the plus signs from examples as it was discussed during the "
  },
  {
    "startTime": "00:20:01",
    "text": "last idea so there are no other changes that we were that we are aware as needed and we think we are all ready for working group Lascaux are there any comments or any concerns so far Robertson Cisco so a question actually back on the seats draft and I\u0027ve made a comment I think from the alias before I don\u0027t I can\u0027t seriously the lease document that drafts defining the SIDS as 60 unsigned 64-bit integers mm-hmm but if they have been put in as Delta\u0027s in the files that are still being done in the actual mysteries I think you want us to be unsigned 63 bit integers I\u0027m sorry that when you subtract them you still end up with in a assigned 64-bit integer value okay so you want to in terms of what you allocate or not allocate only 63 bits rather than 64 hmm okay so I think that\u0027s been discussed on the alias so hopefully that sorry about this emission we will take it okay thank you Robertson any other comments ok so I think this was the the state that we were trying to achieve here we have you didn\u0027t say much about it but you mentioned P yang if there are implementations out a number of people have looked at this so generally looks ok so this is called material and I think the important thing about networking last call is that it actually will include the net mod and net conf work group so we will send out to working with us called to the three groups with a request to actually have the discussion on the core mailing list but I think it\u0027s important that these other groups actually part of this work new brass core ok so everybody agrees about that a quick poll who cares about yang for people for people in this room I know that there are other people who are not in this room maybe he\u0027ll we have a conflict with some some management group I don\u0027t know didn\u0027t check ok so I think we will go ahead thank you Oscar "
  },
  {
    "startTime": "00:23:01",
    "text": "will come hi hi this is marco de la confirm rise for the next four presentations first one group of score yet another advanced update this was mostly related to addressing the comments we got from a not weeks review thanks a lot for that and a quick overview of those we clarified the group medina must be unique for a set of groups under the same group manager which is also directly and clearly responsible for validating the public keys used in the group since from the joining as to their format relay parameters and coney and so on there is also a part of the secure co-op message processing that was moved away from this document to the update of 7390 that we are doing with s co and this is about ensuring that a client receives up to one response per server per request with the exception of observe it used to be the fun here according to previous discussion moved away to that other document also we improved the encoding of the two external a ids define here according to previous discussion and results from interrupts and we decided to totally the couple and make related to application specific policies the way a recipient node handles with the derivation of the recipient context in case it is still missing or the retrieval of the necessary public is the process that message so that doesn\u0027t have to happen necessarily the first time a message is received from a yet unknown sender it could happen before and it\u0027s totally up to application policies also we made a number of qualifications on group working in cases where a recipient node may be interested at its own risk to some extent to keep for a short while and recipient context so to give some time to have the the key rollover completed and the group stable in this respect so what\u0027s ongoing a few things we still would appreciate to get feedback on what we should actually Monday to implement as a preferred count the signature algorithm right now it\u0027s EDD say with a 25 509 Jeff this is just about feedback from vendors and use case deployers and "
  },
  {
    "startTime": "00:26:03",
    "text": "so on in still an open question then one particular point from Jim very latest comments that we discussed last week thanks for that there is a corner case related to the case where recipient node can keep for while the the old previous recipient context and key material where a request is essentially protected with the old key material and when the recipient receive it well it\u0027s still in a position to decrypt it but it also has the new context ready to go and it should use the latest context to protect the response but just to give a confirmation to the client that then they are aligned again we are going to include the group ID as ID context at the response in this first response to the client and at the very least in this first following notification in case observers use so we plan to include this node also in the next update also right now we are still defining two new Ayana registers in this document for indicating the structure to follow when indicating parameters for the use conditioner algorithm in keys we are going to remove these registries from here because we are instead going to point that extended Ayana registers that Jim has defined in the update to cozy as useful for grupos core and for other words for instance to a doc so as immediate next steps we plan to integrate the totally non critical comments we got from Jim we can discuss with him already and it\u0027s relatively easy to incorporate them and removals the IANA registers I\u0027ve just mentioned but considering the very advanced status of the document that got many reviews so far and and this relatively easy in comments from Jeanette we know already how to address and the many interrupts have gone through we think this can actually be considered to move on to work in Reverse call now so of course the usual questions so who has read this version of the document well maybe a little bit too little time since the deadline who has read a version of this document you Trish great thank you yeah I agree with that and two two hands and job oh okay so it would be nice if the people who previously supplied reuse would send a quick notice to the mailing list yes this is where Alaska already I mean "
  },
  {
    "startTime": "00:29:04",
    "text": "we\u0027re still going to have a working class called there but it would be nice to hear from the reviewers that they are they think their comments have been addressed so that that would be my proposal for proceeding yes so which normative references do you have which of the other things need to be done before this can become our see from the jabber Jim do you want this now or after the next version I guess like the this is email saying yes I think this is ready for working with law school for both of you so thank you I can think of 7390 bees there\u0027s no motive reference here that is not adopted yet more on this later nothing else that I can remember actually I\u0027ll double-check but that\u0027s probably the elephant in the room okay so I think we need to discuss how these these drugs can move without ending up in a giant cluster strike on something right thank you okay next then this is another supportive document in a sense of non normative as we presented before of course and just to recap this is about assisting just deployed device that need to find out how to join groups they\u0027re interested in they have essentially no idea what the group manager responsible for a group is how to approach it and the address the join resource to talk to in order to join the group and so on and as even the corner case where the device is deployed even before the group manager or before the group manager is at the group and the devices they\u0027re in a position where it needs to find out how to join a group and information to join for this we are proposing to use the chorizos directory in a sense that the group manager essentially registers addresses directory the links to its own drawing resources that the device has to talk to in order to join the group and properties of the group configuration aspect of the group\u0027s can be also included in the link description as target attributes essentially then devices perform resource lookups on the resource directory essentially to retrieve that link a pointer to the group manager in the join resource "
  },
  {
    "startTime": "00:32:05",
    "text": "this was also recently disgusting one of the latest core inter him and a few people were asking for having widely shared a diagram along these lines where the whole lifecycle flow was shown and this document is in fact on on the very first step where the client discovers essentially a link to the join resource at the group manager and then things move on on the ACE domain when you get authorized to in fact join the group through the general resource now group membership resource at the group manager and then back to core when after having joined the group you can use grupos core to communicate inside the group so suggestions are welcome on the best way to make this diagram circulating where to include a wiki a separate document whatever well of course this document is covering step one but except for the color we can now put it in an RFC as well not yet I know things are changing but right except for the colors okay this one through in a sense a kind of review of scrutiny again during a design workshop we had in Stockholm in October and then we discussed the very same day a few hours later at the core interim we had and we clarified already in the abstract and most extensively in the introduction that the rationale we have been building this approach on the problem for the device is discovering the groups to join and properties of the groups and how to join them and we are mapping this to the problem of discovering links that grant access to the group so the problem becomes discovering the links in their description and it happens that there is an approach for doing that in core which is the resource directory so let\u0027s just use it in order to find out the links to join the group innocence editorially if we rename general resource to be called group membership resource consistently with the works in a scuzz this is not about joining anymore it also has meaning for the the notes that are already members in the group later on and can interact with the group manager as current members like that in the ACE document we redefined this sec GP parameter to be a simply an invariant plane name of the oscar group that is not related anymore at all with the actual oscar group ID or as we were doing before a zero epoch oscar group ID so it\u0027s just much easier to handle and it\u0027s just a plain identifier of the oscar group we made also a minor change in in how values are defined for the target attributes ascribing properties of the group and in particular the signature algorithms and related "
  },
  {
    "startTime": "00:35:06",
    "text": "parameters we were before considering taking value from the name column of the corresponding cause we registries we switch to the value column cuz the definition of those registers say that value in the value column must be unique rather than shit so it just seemed to be a better choice consistently with all these updates we also update in the examples that I remember include also a real-world step-by-step life installation provided in supported by bug net to open points that I can mention the first one is actually moving forward that was discussed before we have a number of target attributes here you\u0027ll be good to register them through there\u0027s currently no registry for target attributes as I said this is moving forward and apparently there is going to be at some point working progress document not published yet called core attributes tentatively which is also going to cover the creation of such registry so when that happens there will be opportunity also to register their this target attributes and maybe you should add that this hasn\u0027t happened already in 2012 because at the time the document we were depending on there is no such residency and now the update RFC 82-88 actually says if a serialization of weblinks wants to define such a registry it can go ahead and do so and so we can go ahead and do so and probably should and it\u0027s just that somebody has to do the work and that somebody has to hatch that egg right and has started in fact and speaking of target attributes we have postponed this for a while but I\u0027ve been thinking of in fact adding one more target attribute in the link description specifying the URI of the authorization server that is supposed later on in the ACE phase of the full lifecycle of the device to provide an access token to grant access to the joint resource at the group manager to proceed with the joining this of course is for the client to continue anyway experiencing an unauthorized access out of wish you\u0027d get that URI anyway eventually from the group manager so it\u0027s a matter of optimization and we don\u0027t see any particular problem in including also this link as for the target attribute so unless there are strong objections against that we plan to do that in the next update and it seems there are not "
  },
  {
    "startTime": "00:38:06",
    "text": "right if I may play close for a second he might tell you that you are eyes the things that links point to and necessarily target attributes but I can\u0027t emulate close beyond that so I can say oh my T\u0027s proposal designed for that I will check also with Klaus Thanks okay yeah to summarize most of the updates were clarifying the rationale of this approach in introduction mostly and encoding of target attributes and new additional why we can include updating example accordingly we think the document is already in pretty good shape actually to move forward and it went through I would say a review process during that design workshop we had in Stockholm and and again during the following interim still we would also like to get review of the actual documents as promised two meetings ago with a few volunteers so yeah we we solicit again reviews on the actual document in order to process them ok so that the way forward is that you will make the people who promised reviews and I didn\u0027t know this list again just as a reminder with minutes link yeah thank you okay next then this work was also presented for the first time at the last meeting in montréal Montreal we are in for defining multicast responses as observed notifications and just as a recap this is in general useful the moment you have multiple clients of all observing a same resource on the server that rather than replying with many individual responses to each of those clients would instead said send a single multicast notification and the very practical use case we consider is reffering use case from the beginning is pub/sub where then you have a number of subscribers all interested in observing same request on the broker server and other than the performance benefit of multicast here you\u0027ll be able then to keep those subscribers as pure clients only so of course multicast responses are not defined now you can imagine why it\u0027s mostly because of problems related to the binding of talking values between requests and responses not to mention security and this document is exactly about filling this gap and described how this multicast responses can work the approach we had "
  },
  {
    "startTime": "00:41:08",
    "text": "in the previous version was pretty much resigned more on that later but 21 of the most critical question from the previous meeting on the handling on the token space we ended to something like this the token space formally belongs to the group of observers but then practically the group is entrusting the protocol management of that space to the server bottom line the result is that all clients will be aligned to a very same token value that will appear over and over in all notifications for the same group of serration and like before it is possible to have security using group of score to protect all those multicast notifications and when that\u0027s the case the clients will be synchronized in using all the same externally ad for well protecting a very fine those multicast responses this is at the high level a number of assumptions the clients have already discovered the exact resource they want to observe on the server and the server knows already the multicast IP address and port where to send all teca\u0027s notifications to if group of score is used to protect the notifications at least the server must be already in the right Oscar group not necessarily the client from the beginning but there\u0027s a way I can show you so that the server can help the clients to understand on the run was the right Oscar group to consider so this new design came up out of the many feedback we got in Montreal and then was extensively discussed during a meeting we had a design workshop actually we had in Stockholm in October and then summarized also a decor interim we concluded that it\u0027s the server that can practically start the group of servation on behalf on the group at any point in time but practically in case one of these two things happen first there is no observers yet on that resource a first client comes and the server decides right away then to start the group observation or there are already a number of clients observing that resource in a traditional way and the server decides no it is just better that they all switch as observers participating in a group observation but how does the server predict we start this group observation it has to do that like on behalf of the group and to that end the server generates what we call a phantom observation request so it\u0027s an observation request for registration that the server generates itself and sends to yourself without hitting the wire of course it\u0027s like if it is sent "
  },
  {
    "startTime": "00:44:08",
    "text": "by the group so like from the multicast IP address that of course cannot really happen on the network but that\u0027s just to give you the intuition and all the following multicast responses as notifications will be in fact sent to that Nauticus DP address and they will be in fact a response to that phantom request not really to any individual registration requests sent by the client so practically the server decides to start the group observation it was this phantom request sends it to itself and when building it it has to choose a token value well it chooses it from the token space that practically the server manages and this token space is related to messages that are like coming from the multicast IP address of the group and address to the target resource so the server has all the ability to to keep the uniqueness of the all-news token values from that space the server process is this phantom request like if coming from the group from the multicast IP address I\u0027m from then on that token value T the server chose is the one used Observation practically in responses the phantom request is stole and that doesn\u0027t have to be a response right away a notification right away that can just happen when the resource value in fact changes but what about the clients the server has to tell the client that this is happening as a new client comes or in case clients already observing in a traditional way are switched to the group observation in either case the server sends to the clients an error response that includes some information and in particular the IP multicast address and port where the notifications will be sent a serialization of the phantom request from which the client can take all the little information they need and a current representation of the target resource cause clients were interested in knowing that value already in the first place and it\u0027s a bit unfair to push them to send yet another request we can include the current value right there already then later on of course when the value of the resource changes the server can send multicast notifications to that IP multicast address with the token value it\u0027s selected for the final request and in fact the phantom the multicast notifications will be a response to the phantom request but when getting an error response of this kind the client will essentially start or configure on inside an observation for that resource on its own client end point associated to that multicast IP address and we\u0027ll accept notification address the debt multicast address with that token value T that the client retrieved from the serialized phantom request delivered in the error response as an example here we "
  },
  {
    "startTime": "00:47:10",
    "text": "have a server that has no observers at all at the beginning on this resource as lee-char and first client one sends the traditional observation request and the server decides right away no we\u0027ll go for a group of servation here with this first client participate in it so the server decides to allocate the token value FF creates a phantom request essentially the message in the green box says that talking value is selected send it to himself in a way like if coming from the multicast address now replies to the client with an error message we went for the error code 5:03 does seem the most appropriate to consider here and the payload of these error messages I said includes remove the cast address to be considered for notifications the serialization of the whole phantom request and the current resource value and well something identical happens when a next client CTO comes other than well there\u0027s no need anymore for yet another fan to request the observation is ongoing already but the response to the client is exactly the same as for the other one but eventually the value of the resource changes and then it\u0027s when the server can finally send the multicast notification to the group address to that multicast address and with the token value chosen for this group observation so the binding here at the co-op level is between the multi class notifications and the phantom request with that token value if you want to add security on this well it\u0027s essentially about protecting the phantom request with grupo score in the first place and the server this has to be from the very beginning a member of the Oscar group so it\u0027s in a position to do that this one to request will then have an oscar option of course which will include the sender ID of the server and the consumed sequence number value of that sender let\u0027s say as x and y the point here is that then every single following multicast if occation will be protecting using as external a ad structure including X\u0026Y as Raggedy Ann Wragby heavy which is consistent they are the ones from the phantom requests in fact and since this phantom requests protecting the group of score will be still included in the error response to the clients they will be able to retrieve this information to and to build correctly that externally ad for every single multicast notification coming later on so here you have a secure tie between again the notifications and the phantom request based also on grupo score optionally there is the possibility for the server to give some more information in that error response if you do so some of that information must be included then and we are thinking of the URI of the join resource at the group manager to join the group and the name as plain "
  },
  {
    "startTime": "00:50:13",
    "text": "identifier of the total score group you can possibly add more information on the way the group works essentially algorithms parameters and and so on so that puts immediately the client in a position to know what to do where to go in order to join the group but this is optional and the client can rely instead on other means like the draft I\u0027ve just presented before based on the resource directory discovery well in case you can see a group of score is just the same it\u0027s just that the final request is also a group of score protected message notice corruption with kd5 and partially 5:01 so after that the sequence number of the server is stepped forward of course the 5-0 - the error response includes also the funder request as a group of core message serialized and more information on this error response how to join the group essentially the the link to the join resource and the name of the group same thing for the second client of course with no need for yet another phantom request finally when it\u0027s about sending the multicast notification this is of course also protected with group of score deals corruption as this time I partially 5:02 the latest Sigma\u0027s number to be consumed but the point is this notification is protecting using as external ad rec ID 5 but rec IV 5:01 so to ensure the secure binding with the original phantom request so to conclude this is the result of I was a major revision from version 0 based on the feedback the discussion on the redesign workshop the server is entrusted by the group to manage the token space consistently we can enforce also secure binding between the notifications and the phantom request and only know this is about performance is particularly useful in the pub/sub case also to keep subscribers as client only and now I think having reviews of the document as such and this approach will be very useful to us unless there are comments already you had many questions yourself Carsten at the previous meeting I I hope we are on a better track now I think this is pretty clever stuff of course immediately questions like how do you do congestion control come to mind whenever you are using and so on so I think just this has still some some way to go before we can say ok this this is acceptable but at least to me it seems to be the best propose that we have had in this space so far don\u0027t know if other "
  },
  {
    "startTime": "00:53:18",
    "text": "people have an opinion on this Christian from the jabber not on castings point but more general comment one more new feature of the current revision is that the new error response unlike the previous options can be cached and distributed possibly by a pub sub server and a detail I forgot compared to the original approach this is much simpler because we don\u0027t need new co-op options anymore we don\u0027t need to reserve any talking range anymore right so I think the next step again is finding reviewers so who is interested in in reviewing this document hmm doesn\u0027t look good now we cannot make any progress without reviewers obviously okay oh one hand from the German plan to do a read on it yeah Jim Jim yes thank you thank you okay but that\u0027s not not enough to really make progress on this group so yeah we will have to find people who actually want to work on this someone from the pub subspace would be useful yes okay so I think that will happen on the mailing list yes so I think up next yes last right was for me today at least this is a work led by s code and me the presentation today and it\u0027s an update or actually an attempt to obsolete if approved 7390 that was the fun in group communication for coop in fact over IP multicast and this is going to be yeah a normative reference to group of score speaking of which we have improved the nature of update or absolution of all 7390 we clarified in the document in this version that we are essentially replacing everything of Sarina and 7390 other then the experimental restful protocol that was define there as an API for configuring groups and that part remains their experimental essentially and it happens it hasn\u0027t being used that much so that\u0027s not covered by this document "
  },
  {
    "startTime": "00:56:18",
    "text": "itself other than that in this update we clarified what since covered is document and especially the security part and the definitional group of score is the the masked way to secure group communication for co-op and we clarified also that all the main body of the document has to be considered normative while everything in appendix meaning use cases are purely informational yeah I\u0027m just wondering about this absolute success except for the experimental protocol so experiments of course can can run forever but then you never get a conclusion so normally we try to have a point somewhere we say okay this experiment was successful this experiment was not so successful and to me it seems this experiment was not so successful that particular part that interface is apparently not used or we couldn\u0027t find any anyways but anything else group co-op was implemented oh yes yeah I\u0027m just talking what the part that you you have in your except for and I would imagine that at this point we would say this this experiment has concluded and and nothing came out of it I mean we\u0027re not going to do a replacement for this protocol and some farm or anything it\u0027s just an experiment that is concluded so to me it seems we actually can obsolete seven 390 and all together all together I mean if you ever want to read up on the experiment the ROC idea sure but I think we are not continuing this particular experiment at least I haven\u0027t heard from from anyone who would want to so I think we can simplify this a little bit and then just say the new thing would be just be a replacement for 73 just removing the statements on the exception okay yeah so what happen from last time well we mostly process the many comments from the reviews from Jim and Thomas for Satya thanks a lot for that we reconsider all the content from 73 90 in this new light we had a number of TBD items left especially in the final person the document describing how moon seekers can practically work in different multicast transport or internet working among different protocols and so on we had a huge number of issues and on the way they were all closed up a few two or three ones you find now came up actually after the resignation but it\u0027s minor things so we substantially concluded the document and this will be readable on the new content we provide we clarified "
  },
  {
    "startTime": "00:59:18",
    "text": "a bit better how coop works in detail with such model with respect to request response interaction we gave indication on meaningful good where is the server can consider for possible response suppression and then it is recommended in fact supports the no response option just as long as this improved the the the suppression policies in the interest of the client we discuss what happens the pros and cons of a client repeating multicast requests with the same token either changing or not changing the value of the message instead so that that can be useful for being sure that all the servers that are reachable are on the same page with the client of course it has some impact on performance or it can really do nothing much or responses are lost altogether and as I mentioned in the group post representation we moved in this document handling on the client side on responses from the server so that with the exception of observe the cry is expected to have at most one response per server for a given forgiving request we expanded on the security considerations and made a number of editorial improvements as well we focused a bit more on observe clarifying in what sense this draft is updating 76 41 that doesn\u0027t really say anything on observation requests end of a multicast we describe more in detail what happens when the kind of transmits an observation request with the same token and again same or different a message ID and we gave some indications on what a server is supposed to do to check the liveliness of serving clients and practically we expect application policies along the lines every now and then the server should send confirmable observe identification they should be non confirmable like the request but it\u0027s in particular impact is possible to have the confirmable and that should happen here and there for the sake of liveliness check on possibly updating block-wise instead we took a step back and we are not really updating it anymore we are expanding a bit more especially on the block to usage but all in all along the line all of 79 59 but we are just adding considerations on the fact that block 1 would be really problematic in the multicast contest so we are highlighting the problems but we are not really proposing how to solve them seems like a bit exaggerated an otoscope for this draft possibly if there is enough interest that can be a "
  },
  {
    "startTime": "01:02:18",
    "text": "topic for a totally separate document so because of this essentially we are not really updating 79 59 anymore as it was intended originally but this can be discussed possibly if more important so what we expect next I mentioned a few minor issues we finally tracked on detail but by their minors we had after a submission more comments from June shall stating this is all not a good document but proposing a number of minor fixes and additions here and there and Thomas already promised another review on this latest version of reason then of course you\u0027d be interesting to start considering one of those implementations supporting coop / multicast I can immediately think of californium of course and well Coco\u0027s the multicast itself just worked we used it for a group Mouskouri Interop would be interesting to test over it is also additional coop services and especially observe all-in-all considering the current status this minor next steps we already see in front of us and many reviews we got we think this is for sure eligible to consider for working group adoption ok so the usual question who has read a version of this document two hands any hands from java no and so when we did one hand from java so when we did 7390 we knew that this was an interim placeholder and we were two hands from java this was going to be a placeholder for a while until we understood the the issues better so this to a certain extent always has been on the agenda to revisit at some point and and i\u0027m happy that this is actually happening now it\u0027s the the only experimental protocol that the experimental ever see that that we have produced here if I remember correctly and it would be nice to get this weeks but repaired but of course you can only do this if we get the reviews forces already not that bad so that makes me is partially happy Francesca beanie yeah I just want to say I support adoption of this as quickly as possible "
  },
  {
    "startTime": "01:05:20",
    "text": "and move it forward also considering like the normative reference from grupo score what she said out of the document is moving forward assuming adoption of this of course I\u0027m pretty confident the next version at least we will do our best maybe even considerable for for a big shift to work in robust cold if that can help so you talked about implementation in California how far away is that group co-op is already there and working will take the whole draft how much of that is actually implemented according to what Kim Krauss I can get back to an old Mary posted took or actually he was saying there was a line to 7390 okay in fact I think we have to have a little bit confidence from implementation so I think that that would be something where I think we would want to wait for before going for with Nebraska so June from the Jabbar says he has a full multicast implementation for our score so I guess yeah that that\u0027s the group co-op part this is their run Cooper Square okay the question is does this cover all of what\u0027s in the draft right now and that\u0027s maybe something we should ascertain before we actually go for it nope a score so that that would be one of the reviews looking at implementation status and and see how confident we are yeah but apart from that I think this this is a good work so anybody else who would argue for adoption of this document who thinks we should not adopt it so in in soccer one zero is enough from Jabbar plus one adopt from Jim and Christian okay okay this is not quite in room consensus yet but we can take the adoption call to the list and this time we are not going to forget doing that for for another four months and go ahead with that thank you [Music] so next is sin well as I said we have have two documents in the is G right now and we have two documents that are in various stages in the working group and what we will do is we will look at all "
  },
  {
    "startTime": "01:08:23",
    "text": "four but maybe we are going to look at units in the end because the inventor of sin ml and founding chair of this working group isn\u0027t here yet Helen Jennings and he has some some interest in getting this fixed so we start with the other things okay so let\u0027s start with its impacts with 10 ml arm so this draft is all in iese review it\u0027s currently state that it needs a revised draft there was no updated person for this idea because um I wanted to have all the updates in the front is reviews in the same person but you can\u0027t find the Inga Topsail requests those latest changes so that\u0027s very good the directory review from Mathias Kovich thanks a lot for that a bunch of small things here and there and watch IAC comments from Warren Barry and Elissa also is a discuss from Roman that have been addressed already in the versioning it one of the recurring comment we got from my ESC was this fragment ID section was a bit confusing so I did a rewrite for that and also I did some examples and at least I haven\u0027t got any complaints on the new version so far also added but expansive clarifications that what are they really the mandatory parts you need in every fetch and patch there needs to be at least one record at each record needs to have at least a name it etc also that co-op is used for securing these operations cause this format itself doesn\u0027t provide any security but it\u0027s really the work of the underlying protocol and also clarified that I patch and patch are equivalent when it comes to sin ml patch because that cinema patch records are or idempotent there are still one discussed from Adam and one comment from Ben that this still needs to be addressed and in particle or the review from Adam raised a few other issues and so I\u0027d like to get your crude feedback and confirmation for so one issue that we notice is that we actually didn\u0027t have a selector for with units so how currently both veteran patch work that you always include a name of the record and you may include a time to select the records either for fetching or for patching and the reason for doing a design like that only including a few fields there is that then you can use these few fields or find the record and every other field for patching them like 90% of cases you actually want to patch only the value but there is you know usefulness for appeals also add new fields to the records what we didn\u0027t actually pay attention to that is already in the RFC examples quite often unit is used to also disambiguate on records so you may have same name for a source of data but read for example say this is latitude this is longitude and only unit tells you apart which record is the relevant part for which part so obviously we do need to also add unit to the list of selectors so the proposal here is to update that "
  },
  {
    "startTime": "01:11:25",
    "text": "and say yes you always have name and you may have time and/or unit so basic addition of unit is to change and it would be like so far you would be an exact match so whatever you have of this combination of the three needs to be present in the record you want to find for fetching or patching so if you don\u0027t have any concerns of this weight going forward that\u0027s gonna be part of also the next version of the draft custom woman from the floor this means you never can update the unit in the record correct so it\u0027s reasonable yes yes so the way we chose to form whole Pat\u0027s FX record has this downside that what is wherever\u0027s use a selector cannot be used as patcher so you have to choose one way or the other that\u0027s all so we got the question so where do you draw the line well this is what we want to draw the line get the very minimal set that you really need that name time and unit to select uniquely records if you do need something more elaborate there you still have the Chasen packs format which has there a lot of power but also a lot of complexity so you can still patch stuff but then you have to pay the price then another thing that Adam pointed out that we should probably clarify that the record order matters in the patching so what what may happen that you have multiple records that are operating on fields with similarities so for example if you have two records that both end up removing the same record in the target pack that\u0027s that should be an error but you don\u0027t really know until you actually handle the fact you are actually handing handling them both so what Adam was suggesting as a solution that first of all clarifying that if Pat\u0027s record matches more than one cinema record that\u0027s immediately an error that\u0027s something we may want to consider but that\u0027s more on the next slide and if this one of the signature if any of the patch records fails then you don\u0027t change anything so the whole patch needs to be atomic and then you would apply all the records sequentially I mean this seems to me a very reasonable thing to clarify on the graph that it need to be addressed sequentially only question there is do we want to allow applying patch to more than one record and that brings the last point so currently the dead texts kind of implied that yeah it\u0027s an error if you much more than one that needs to be clarified anyway alternative design here would be that you can match multiple records with a single patch record and you for example be able to delete multiple records when this was first suggested to me I think was close okay that\u0027s it that\u0027s a good idea I did a bit more thinking I found a "
  },
  {
    "startTime": "01:14:26",
    "text": "whole bunch of complexities there corner cases so it might be just simple to go for okay you don\u0027t want to do this you if you need to modify something put a separate hats record for every single modification you want to do and and be done with it so this is basically a request for you guys if you have a use case in mind that you would think of matching multiple records for patching is a must please let me know as soon as possible otherwise I\u0027m leaning towards it\u0027s an error if attach record happens too much multiple such a simple thing to handle and then II you really did that by being more specific which record you need to apply to any immediate reactions on that customer from the floor again so [Music] are we sure that this is all unimportant the deletion should be I think we did the exercise once which is probably double check especially if you much more than let\u0027s double check okay oh yeah that was the intention it\u0027s very easy to mess up and do something where this important property yeah gets lost oh you wanna yes so which one\u0027s next we have Colin now yes that\u0027s why I\u0027m reloading the slides okay so you have the next one yes and the Chromebook is establishing a secure connection okay well wait their slides to reload I guess there was no violent agreement on the way forward I proposed so I\u0027ll go along those lines make a new version submit that and then if I ESG is happy and we check the item potency issue once more I think that\u0027s gonna be on its way for an RFC I just wrote the words okay so presenting on behalf of Carsten he straps I may have been also active contributor for this draft um so quick reminder about the Sentinel unis registry it\u0027s basically it\u0027s a "
  },
  {
    "startTime": "01:17:27",
    "text": "sorts ring source strings to represent units of measurements so we\u0027re not defining units I mean there\u0027s other organization who actually do that work what we are defining here is that how do you express those in cen ml so M stands for meters etc and s for seconds in the original cinema RFC we had a rather restrictive registration policy that was a long debate on that and we wanted to lean towards facilitating interoperability that we don\u0027t need to be doing a lot of conversions so we wouldn\u0027t have kilometres for miles we\u0027ll just have meters in the registry however what we did more and more notice after getting more deployment experience on on send email that they are one of the right units in practical use today and sometimes can be tricky to actually use only their unscaled SI units for example in Ole Miss back works there\u0027s a millisecond kilowatt-hours DBMS etc so if in order for those models to use only the units we had originally in the central registry they would have to change a large amount of existing models which can be very impractical and also in many uses there is a natural scale offset or a unit that is used for example millisecond in some use of time micro micrometers for particle size even though ad meters for it usually always missing micro micrometers or Gore kilowatt hours if you\u0027re doing our power stuff so a proposal that we had at last IETF is to have this secondary registry of Sentinel units so it would be another Ruby C with slightly different kind of rules that would be accepting also the scaled units but they would be mapping rules always to the original cm central units and there\u0027s a few example from kilometer and and DBM on how that works in practice so based on discussion before the last IETF with all my spec where that seems to be a very good way forward would be addressing those use cases and also of course it\u0027s converging thing being able to do it automatically is seem to be a very useful feature and it seems Italian is actually planning to have a JSON based registry too sometime next year so you could actually more more facilitate of getting that information automatically and processing it as part of your application there\u0027s also a long discussion on the email list that I think Colin initiated on that and really like is this right right right way to do things and how do you work still one actually maintain the interoperability but still accommodate on some of the need needs on the industry so what the draft that Carson wrote currently says is that we\u0027re not "
  },
  {
    "startTime": "01:20:27",
    "text": "commanding the use the secondary units it\u0027s really that the case you really have to do it and and then basically used use you use the first table if you at all can if you cannot then here\u0027s a way you can still deal with its nml but of course there were some concerns are we actually now creating two different kind of sentinels and how do how do we deal with interoperability when there\u0027s gonna be much more units than maybe a lot of implementations were expecting for anything else you don\u0027t say on this one yeah I think there are several facets to this one is the editorial one to say may but should not this sounds almost like an RFC sixty nine one nine keywords but it\u0027s really not meant that way and the other one is is the way we we are updating eight four to eight the right way by simply saying we are putting in that secondary registry and of course a few implements anywhere you implement that secondary registry but still its use it\u0027s not it\u0027s not recommended so these are two different levels we could make more clear so before we go into the the full discussion now he has two more slides I think but if you have direct comment on this please challenge eggs I mean this is all this won\u0027t change anything in what happens in the real world right like whether we\u0027d maze made me out you should but we know you will whatever right like I\u0027m not really that I think that we need to hit the core problem and then may will come back in tune these words a little bit but I just wanna know one thing on the framing of this this is not something new we discovered we knew all of this information about units long before we set up the current registry in the current RFC we discussed all of this extensively so this and I\u0027m not saying we shouldn\u0027t really and change and and which i think is the proposal already has here or both of you have but I don\u0027t think it\u0027s like we suddenly discovered that people used milliseconds yeah I also don\u0027t think it\u0027s and we have a trade-off between what will help us achieve interoperability of this data in where it\u0027s used not just the focus of what would be convenient to generate and we need to think about though both of those we go forward on this that make sense yes so indeed we have no new information on this side and this wouldn\u0027t make us change anything then your information we have is that other issues might be using this innovation and that was a well known in the previous version of this argument and "
  },
  {
    "startTime": "01:23:28",
    "text": "discussed we made the previous discus decisions that is not new information either and so and so anyway my recommendation on this slide is this isn\u0027t the right time to worry about the details of that we should go figure out what our real solution looks like on the stuff and then come back to what advice I mean clearly if we\u0027re making a table it\u0027s because we intend people to use it that\u0027s why we\u0027re making this whole thing so let\u0027s not just be like you know I mean this will be about as useful as saying we recommend you use v6 and you shouldn\u0027t use v4 I mean people are going to do what they\u0027re going to do so I\u0027m not really worried about these words very much yeah yeah and one one thing I think would make a lot of sense to do is I mean instead of just saying may but should not like write down that rationale that I mean lot of that was documented in the email discussion that we had on the mailing list like why using table 1 actually makes makes a lot of sense and there are a lot of non-obvious aspects there putting those in the draft so whenever an engineer comes across and okay which one should I use at least you have some guidance of these non-obvious aspects and then may you know doing an informed decision based on that but then yet that we had a good discussion this morning with Colin and Carsten starting at 7:00 a.m. that\u0027s how committed we are so based on that I guess we kind of yeah we do want to do this accommodating for their more units that\u0027s kind of where we agreed on what we have in the end quite a bit of discussion okay so how do we how do we handle this registry of within new units so we did discuss some some proposed expert review guidance for now what we call table to more relaxed units so probably it should be something okay we need the units to be a subset of 7-bit ascii basically the only only having F at each so we\u0027re looking forward them same style that we have for the current units and probably use the same character set as as the names be more explicit on that but then what kind of units should be except in the original race is pretty much like on scale si which is a rather strict there\u0027s a few exceptions there already but that was kind of a general guideline so for this would be kind of towards the other end of the spectrum being much more liberal but we do want to have still something there is not like in any random proposal would be accepted so one way to phrase is what thinking would be that units are founding existing scientific literature or specification and that you can point to a a specification that uses this unit you know whether is some industry consortium or or my a suspect then pretty much would be accepted of course if there\u0027s "
  },
  {
    "startTime": "01:26:30",
    "text": "the already same unit for that thing so we shouldn\u0027t have two strings meaning the exact same thing that would make much sense but sometimes there are cases where actually it really deep down it is the same thing but they\u0027re two different industries that are using different quote-unquote unit describe that then maybe that actually make sense to have have the same same unit so a different unit identifier for the same underlying SI unit and also checking when there is a new registration I mean it would be kind of towards first on first-served you would check that okay if if that someone wants to register cm for meaning something else in centimeter probably should advise them to go you know find another identifier for it and also what we actually have right now is we have these two things were same a scientific reactive apparent power we may want to move some of these things to the table to that when people originally proposed for for a table one though and we should think about the naming syntax one thing that was recently proposed was this evens per hour per square meter in the original guidance we had like okay you shouldn\u0027t have more than 1/4 watchlist in the units but for that kind of unit two forward classes may make sense produces an initial draft unlike the guidance on the table to cause them current guidance in in the grass was rather maybe what wasn\u0027t wasn\u0027t quite adequate and maybe even conflicting so : James could you say a little bit more on this I mean you know I this makes a very open register and just to provide some examples intent this makes very open registry if somebody is asking for micro fortnight\u0027s as a unit of time we probably give it to them right and definitely miles per hour and everything else for sure and it\u0027s you know it\u0027s to try and give people what they want and we I mean we have examples that are already in the draft like the heart beats per minute unit that you know it\u0027s hard to justify some of these things right and this that would be fine in this table would allow exactly those types of things one other thing that I really want to highlight for people is this reactive apparent power we have lots of things where people really want to use units for something that is not units at all but tags additional semantic meaning to them and I think this you know the different types of power measurements are excellent examples of a good use of that and we should allow that but that opens the slippery slope I think this will totally open also you know in in minion Street parts-per-billion of carbon dioxide and parts-per-billion of oxygen they consider those two different units and that\u0027s no different than the power one so I think we\u0027ve got "
  },
  {
    "startTime": "01:29:30",
    "text": "to be okay with that and III think this would I can see many advantages of having the second type of registry that had that very open type of idea particularly with the machine readable way of mapping it back to Table one so I just want people good with that type of openness to this table I mean I think that\u0027s one of the things that re aren\u0027t trying to get feedback on here hi I\u0027m I\u0027m Matt Gilmore I work with Itron to your point though quite frankly we do not we my company makes electric meters we\u0027ve shipped probably 200 million smart meters across the world we all right so I get it that you can represent kWh and it\u0027s just a scalar unit of joules but we\u0027ll never ship joules over the air its kWh so I mean there\u0027s got to be some means where an industry has a standard and we\u0027re just trying to bring it out to the IOT and that\u0027s why we went to secondary registry I mean I\u0027d say heard loud and clear and you\u0027re not the first people to say exactly that right it\u0027s not the only example we\u0027ve had other people you know have said when they sit when they set a house temperature in Fahrenheit or Celsius they\u0027re not converting it they\u0027re setting it to what it\u0027s either 21.5 or 79 degrees but it\u0027s it\u0027s not something else so I think we have a pretty good agreement that okay we will have more units and it\u0027s more on the details like how do we organize the whole thing and then the expert review guidance is kind of one key part there so all the feedback here would be very much appreciated and if and of course anyone volunteering to be the expert I mean those are also highly appreciated someone you know background on these kind of things I think would be it would be very good okay there one more slide or you want to comment right on this one oh okay then one issue we couldn\u0027t quite get agreement on or we could we still need to do some more analysis on is should be used the same you field or should we have a new field for the units in the second table and now that\u0027s called the YouTube field so in the first process over you\u0027re using the same unit for both I mean they both go in same X new field there are some downsides to it for example that if you wrote software that is kind of expecting things in table one you may have assumed that this is rather stable registry of course there will be new units but not like in masses so those assumptions may might be broken once you get like you know 100 new units in in the table to also in some cases it might be used with a clear indication on the wire is the stuff from the table one or table to the top would actually then "
  },
  {
    "startTime": "01:32:32",
    "text": "make a youtube proposal potential on the other hand having a separate field for this units from table to it does create in importance nm a lot of complexities different feel for similar things and that\u0027s what we hit when we were discussing the content type string and a numeric value we okay it\u0027s a simple thing let\u0027s let\u0027s make them separate fields cause they\u0027re different values no it\u0027s you need a lot of complex is a lot of a lot of corner cases how base values overwrite each other and you just bunch of complex logic which you can easily avoid if you stick into the single field and also I mean these are are still units units in the same sense so that kind of semantics of that field are or are the same what we did conclude in our morning works of that yeah we need to do more analyze something to think of the corner cases anyone interested in this and willing to chat a bit more feedback could be highly welcome we\u0027re planning to talk about bit more during the week and maybe we can a quick one on the coarsest on Friday two on our conclusions where we may land during this week and actually have a proposal for wayforward right now we don\u0027t have clear one yeah having another side meeting on this is probably good idea do you just proposed adding unit as a selector criteria yes adding you to as well that will be part of those complexities we will hit if we have another field yes yeah I just so I\u0027m not sure that the you or you I\u0027m not sure that you two is the only way to skin this cat but the the thing that I feel very strongly about is we have these two options of spectrums they have pros and cons and the spectrum what we chose in cinnamon al was very much in favor of what made it easy to do analytics and combine this data and use it in our operable way and I don\u0027t think that we can just I think we need to find a backwards compatible way if we\u0027re going to change this we can\u0027t just we\u0027re too late to just change it there\u0027s too much software written that assumes that if it\u0027s dealing with the units it will understand them and be able to process it so I\u0027d like us to find some way that it\u0027s very clear whether we\u0027re using the new units or the old units I don\u0027t I don\u0027t believe that any amount of you should or should not use this or that I mean we just heard the answer to how that conversations gonna go right it doesn\u0027t so I think that we need to to think about all the things that went with the assumption of our current RFC we have to not break why they did that and what what they\u0027re doing it and this would do it there might be other ways to do it but I think we need to find some way of not breaking that type of interoperability yep yeah or at least "
  },
  {
    "startTime": "01:35:33",
    "text": "minimize the damage I guess that\u0027s what I\u0027m fair enough yes yeah because I mean oh of course already today technically any implement they should expect there are gonna be new units also in the first registry but yes the assumption on the amount of new units cut if the assumption is if there that there won\u0027t be new units which their inherently understands but they can\u0027t read right Zack like yeah sure somebody might add radiation and they only do temperature but they\u0027re gonna be surprised to get fahrenheits that their application should be able to process which they can Alexia\u0027s you\u0027re poor ad for this document it looks like this one is not ready for hg basically yeah we need we do need to figure out this you you two think hopefully we\u0027ll get some clarity this week so yes as we discussed the last time on there is some urgency on getting a registry and getting your values there that you you two part may not be that urgent because I mean for that it\u0027s more we could figure it out later I don\u0027t know if there\u0027s a sensible way to do it\u0027s a pre-registration of the units and then we\u0027ll figure out this detail later later on I mean during the process but having those units usable it\u0027s kind of the urgent things and I think we\u0027re just not really disagreement on that but we need those identifiers and the identifiers themselves are rather straightforward so then we wouldn\u0027t have to then rush getting this into RF see if we could have the registry ready okay second question is have you talked to Pete Resnick it was the one who\u0027s continued discussion when Colin races yeah not after his emails no should yes maybe you should talk to him I think I might be incorrectly proxying his comments but he thinks that one registry with an extra column saying whether it\u0027s recommended or not would be better was confusing to people but again you know I personally sort of don\u0027t care but some people feel strong is another I suggest you talk to him and see if it\u0027s fab boxing of his comments or whether very smart read the main problem with that is that there are other columns almost all columns are different between to everyone and every true I think it\u0027s really administrative thing and I I agree with Carsten that like the separate tables make mix makes a sense from administrative point of view but "
  },
  {
    "startTime": "01:38:33",
    "text": "yeah it\u0027s good point let\u0027s let\u0027s check with Peter explicitly on that at least he didn\u0027t react on the later comments where we where we were converging on this way of doing things like a calling was in the in the end favor of the two tables and as everyone else yeah so I think suggests that he\u0027s not trying to derail our emerging consensus and there\u0027s other things we found like things that definitely need to be updated in the current draft with with like the expert rule like whatever rule 5 was whatever yeah yeah so I mean it\u0027s definitely a very minimum a Rev of the draft is definitely needed that\u0027s for sure on the on the splitting and moving things forward I am NOT I\u0027m not really very ok with that because if we are going to use I would rather not have these new units than have them in the you field with no solution to the problem posed here so if we\u0027re going to add these new tables there has to be some way of dealing with this problem I\u0027m not so be very clear on that I\u0027m not okay with if we know how we\u0027re going to do it but it\u0027s not finished yet that\u0027s fine I don\u0027t care but we\u0027re not going to agree on the units before we agree whether we are breaking the whole design of the currents in ml on a non backwards compatible way right so how about allowing table 2 and you field if it\u0027s prefixed by an asterisk its prefixed by an answer okay sure III mean like look that like as I said there may be many ways to skin the cat but some that we agree on some way to see in this cat yeah yeah yeah okay so I hadn\u0027t thought of that Carson nice suggestion yeah we\u0027re going to at least those different options on up you know he\u0027s a paper or a screen and think about that once I think we have many ways to solve this and I\u0027m sure we will find a way but I think like in order to make things move us as fast as possible I think if we could like prepare for the pre-registration of these units that it doesn\u0027t have to wait until you know there\u0027s an RFC mark on it I think that would be very good for for everyone depending on these new units just basically right now since I oh oh ma we kind of chose to use these units we are working new registrations of objects before we get these units ready so there is some some urgency in that sense otherwise we\u0027ll need to find a way around it and that could just get messy in the end so it would be much more clear to have the units in a registry and then we\u0027ll figure out how we have to deal with that good I think that was my last slide on that topic and the next "
  },
  {
    "startTime": "01:41:33",
    "text": "one okay cool okay data value content format indication just a quick reminder what this draft is about it\u0027s about giving content format information about the things that you wouldn\u0027t send ml include in your VD this data value field so for example the example on the top that\u0027s on putting C bore array in a senemo data and the second one would be putting basically comma separated values run through Z gzip for compression in the data value the change is what we had done since the last IETF what we agreed over there is that we are now used in the same field and string values for both the content format and cone type encoding so we used to have different field for this shrink type and the integer type that resulted in all the complications that I refer to earlier so now we\u0027re just using string even though there\u0027s a numeric numeric value you put it in a string because it\u0027s a simpler and there\u0027s a white or two of overhead but that seems to be well worth it also we added this mandatory to understand version of the CT supposed to see the underscore or base city underscore and we also had a bunch of examples about alexei was was asking for to actually validate does this way that we form the string versions made make sense so there you can now see a few examples that are listed in the current Kraft I think in particular out the last one and the second to last one Burgess also the content coding included are the interesting ones so using now this new format of having the cone encoding separated by at sign as part of the string that allows us to use a single field for all of these piece of information and avoiding some of the complexities with multiple fields however they\u0027re still the same complication that we briefly discussed last time how do you handle mixing base fields and mandatory to understand fields what is the really the field that ends up being used after you have resolved the records and it\u0027s important to go take case number one that is a tricky that you have a base value for foo that you say it\u0027s mandatory to implement implement and I understand and later on you would have a food that is not mandatory what actually ends up being applied and how so currently so this is nothing specific to this graph it\u0027s a cinema feature at large but this is the first graph where we actually hit this issue so current text is that okay they\u0027re mandatory to understand field "
  },
  {
    "startTime": "01:44:33",
    "text": "overrides the regular field and you shouldn\u0027t be mixing them and shouldn\u0027t be mixing the max it\u0027s a very sensible thing overall and but you may not be able to avoid that if you\u0027re combining send email from multiple sources so one source used to monitor do you understand the other one used regular fields you want to put them in the same pack how do you deal with we thought we had a resolution on it then we realize it\u0027s actually more complicated than you think so Arsene 1925 rule 8 applies also here so we\u0027re planning to have a one more closer look on these rules how does it actually should be resolved again feedback would be very welcome we\u0027re probably need to write a maybe a piece of cinema someday include some instructions there or put it somewhere in in a generic fashion some guidance how to do this but this is the first draft we actually have to solve that issue specifically okay any questions comments on that one okay and I like say if you can impart a call have a look at the format and see if that\u0027s sensible kind of from media type expert eighty point of view you can even look at the examples in the draft and see if tax le works for you okay then we\u0027re actually on time the final sentiment draft the base prefix so this is a draft I wrote together with Christy announces the idea there is that since a memo we have this requirement for COBOL unique names for example in the RFC week I\u0027m only use ipv6 prefix in the previous of the name in order to get Discovery unique names and the whole idea there is that it puts global unique names they facilitate information exchange across multiple systems because you have a global unique identifier you can always point to regardless of the source where you actually got the information from the downside of this choice is that you sometimes have a long and this is long in quotes cuz I mean depends how are you mister to long names can end up some tens of bytes of overhead for a pack its and so if you are in a very constrained Network something like Laura one for perhaps it accident may make a big difference for you and you want to release squeezed out there the remaining bytes the thing is like usually the base name prefix has some information that it\u0027s also available out of band out of band of The Sentinel FAQ for example an IP address requests you arrived Els identity etc so the proposal in this draft is that you would be able to indicate how should you construct the "
  },
  {
    "startTime": "01:47:33",
    "text": "base name based on the information that is available out-of-band and then when this information is no longer available for example after the first hop you then put replace this this pointer with the information that you are using and therefore be able to use again like standard RFC SN ml there is an IP r declaration on this draft there number 360 - you can go and check it out that for more details how it looks and like in practice here you have the ipv6 address as the base name you basically replace that with a new field called BPI and say their number one number one referring to ipv6 address as a pointer and then send it forward and then when you would actually send it then for further on you wouldn\u0027t be using the one format the upper format which is send again standard send ml then of course a question is like what kind of values can you use for BPI here\u0027s our current proposal so it would could be used I P address as in the previous example potentially with the port also what seems to be rather common thing is used a request base URI so depending where you did the request on that could be used to form the global unique base name also if you have security association on your connection are you using TLS or something similar you could use for example your public key or the fingerprint of the public key there\u0027s a nicely defined format in RFC 69 20 or how you could do that or you could use for example tsk-tsk identity or if you\u0027re using a core resource director your endpoint identifier or often already usable for this purpose so you just say okay you use my endpoint I need fire as the base name prefix and you\u0027re done the current status of this work Hannes ja panic actually presented at the last IETF another draft was addressing the same problem this problem was originally discovered in the OMA or we may work or related to light with NPM because they were actually using using something like this but not being explicit about it so basically in in love the case you only sent the path component and not actually the prefix component as we generally having an insane ml so what this method would be doing is making that information explicit so then you can use things from the omiai within the metro system and things from outside in an intrical fashion the key difference compared to the harnesses proposal was that there was a new field instead of base name of these relaxed rules are based on or local based name that relaxes the rules for uniqueness different approaches are for the same case however as Hannes pointed out on the mailing list I\u0027ll seems that at least within the OMA sphere the stuff "
  },
  {
    "startTime": "01:50:33",
    "text": "seems to be interoperable even without this addition so we should have a closer look like in what kind of cases would we actually need this I think it\u0027s gonna be mostly valuable when you do go outside of a let\u0027s say for example like within the ecosystem and you actually need to exchange information in sending a format outside of ecosystems but you still want to have this good compression inside techo system but we\u0027ll be looking into more details on that and and reporting in the upcoming IETF meetings yeah so what do we do with this trash so I said I will have a closer look and I think we\u0027ll know at the next idea unfortunately a bit along your vacation before this I didn\u0027t have time to do that analysis so we\u0027ll have a closer look and see what direction makes sense I mean should we potentially combine the mechanics Newton is proposed or is this one way or better or the other I think like from author\u0027s point of view closer look is needed so consider this as more as a heads up and intro to the problem and and potential solutions okay I think in that case we are done for today you all on Friday yes well this is my 29 inch Cobra group meeting and I think we did once before so just for information this room will be used for a lunch meeting where\u0027s the receipts there\u0027s still one blue sheet floating so this room will be used for a lunch meeting so please do leave it edge 12 "
  },
  {
    "startTime": "01:54:10",
    "text": "that\u0027s true yes "
  }
]