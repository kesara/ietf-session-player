[
  {
    "startTime": "00:00:04",
    "text": "dude are you gonna how\u0027d it work I don\u0027t even what do you do oh you don\u0027t use Chrome yeah so right yeah if you if you use Safari you can open up preview without click if you use Chrome then great so actually I have the I have the initial chair slide right here do you want me to project the chair slides real quick and then we can I can close that out don\u0027t need social media all right good morning everyone welcome to IPP MIP performance metrics I\u0027m Brian Trammell this is poster vanie we are your humble co-chairs this is an IETF working group meeting the note well applies anything said here as a contribution to the IETF all IETF sub contributions are sub the rules of 53 78 and 81 79 usually at this point I say probably by Wednesday you should have seen this at least once if you haven\u0027t seen this and actually read it and to understand what\u0027s going on I\u0027m going to draw attention to the fact that the RFC number for IPR disclosures has changed that\u0027s because the policy has actually changed someone so please do make sure you have a look at 81 79 and understand what it says here is what we think the status of our working group drafts is I would be happy to be corrected by any of the authors if we have this wrong I\u0027m pretty sure that RFC idea 186 was in fact published because I know what the RFC number is so yay another IP PMRF see we have a 11 Rev of model-based metrics that was updated um just before the meeting I believe this is ready for ballot L okay so that is it scheduled on the telecheck yet okay cool so if that\u0027s just happening so that draft came in on our original recharter in Orlando IETF 86 in March of 2013 so we were it turned out to have been somewhat more complicated journey than we thought it was going to be although in hindsight we probably should have seen it coming because it\u0027s it actually turns out that the transfer "
  },
  {
    "startTime": "00:03:05",
    "text": "capacity measurement on a real network is hard we have 6 million PDM often 13 which is completing on ESG evaluation or is it through at this point it\u0027s through okay so hey we have two that are basically on your way out 23 30 ipv6 0 1 we\u0027re gonna have a talk about my understandings we\u0027re still waiting on 6 min so we\u0027re not waiting as much on 6 men because I because the the internet standard has been published there are continuing discussions about addressing architectures that will terminate at some point before the heat death of the universe we\u0027ve got Altmark 0-5 working group last call is complete and we\u0027re waiting for a right up from the Shepherd Thank You Carlos thank you very much we are going to start the working group last call on twin peeing during this meeting basically this and that email out to the list as soon as I\u0027m not projecting these slides any volunteers for shepherds people who have been following the egg model 41 who would like to help us out in writing the Shepherd statement so the Shepherd statement is essentially a statement that goes up to the iesg it says you know here\u0027s how the working process worked out here\u0027s I\u0027ve actually checked their all the IPR disclosures have been made have been made this is a report of how things were at the ie at the if they\u0027re working group level and it helps the isg do their evaluation so it\u0027s not an enormous amount of work and it is sort of a good way to get some experience with you know the depth of the process that we use here at the IETF so any volunteers to shepherd that document through we\u0027ll take that call in the list so metric registry and initial registry twelve and four um this is another one that we actually probably are we knew that this was going to take as long as it was going to take one of the things that we chased down in discussions about this draft I believe in Chicago but it might have been Seoul was we really need to have some metrics and measurement measurement and representation methodologies for information about a path that is discovered through active measurement and I think owl is gonna present that draft or is is Ignacio Ignacio is presenting the draft okay excellent so that\u0027s where we are with the drafts here\u0027s our agenda we\u0027re gonna start with initial metric registry from from owl and then we\u0027re going to have twenty three thirty ipv6 from Joaquin "
  },
  {
    "startTime": "00:06:06",
    "text": "then we have basically two larger discussions on the agenda one is our reach are during discussion which you know will come back to we have some some slides introducing that and going into the details of the charters there will be a bit of a shorter bashing session um the thing that raised this issue was the discussion in Chicago about bringing the in-situ OEM work into AI ppm but it turns out that actually most of the changes that we want to make of the Charter are about reflecting work that we\u0027re already doing or that we\u0027ve realized in the course the past four years that we need to do so there are a couple of presentations that are related to this so all of the IOM stuff so the updates in the IOM stuff will have as part of that discussion and then also the route metrics draft that Ignacio will bring in after that we\u0027re going to talk about um taewin plight presentation from al two presentations from Greg and a discussion afterward about so what this is is basically about is the pregnant for would like to be able to use the T map test protocol on its own and needs a registered port for it so that seems like a good time to basically clear up remaining ambiguity about the status of that as a protocol um and I think we can come to I\u0027m being I might be optimistic here but I think we can come to some sort of consensus in about twenty minutes on that after that we have six lightning talks we have probably if we do the agenda in the order that we have it I think we have you might actually have time for six now because we took 15 minutes back out of the agenda so these are work that has not been discussed on list but may be of interest to the IPP M community these are ordered basically in order of first things that are directly applicable to continuing working group work there\u0027s a couple on alternate marking then new work that we have not yet seen in order of request timestamp and then a returning work that is not directly related to two other work in the working group so this is the queue and we\u0027ll go through those five minutes at a time I\u0027d like to try something I not sure we\u0027ve done this in AI ppm before so there\u0027s a five minute limit when we hit the five minute limit we were all going to clap and thank the author until they sit down so with that we will go to Al on the registry and "
  },
  {
    "startTime": "00:09:19",
    "text": "okay registry for performance metrics good morning everybody nice full room today so I\u0027m al Morton and and doing this with Marcelo been one fill and um er next slide so we we a long time ago decided that we needed to specify metrics with more precision than we did with the flexible versions that we put in the RFC s and you know you can read this quickly while I\u0027m talking here but we we really need to narrow these things down because we want to make clear comparisons between the systems that we measure and that\u0027s only possible if a lot of things are documented and everybody refers to the detailed implementations and discussion that we\u0027ve that we\u0027ve got here so obviously with the registry you provide a unique ID and detailed exposition and and all sorts of things so we\u0027re trying to raise the bar on what what it means to measure delay when it means to measure of loss and in very specific circumstances makes like Oh is there a clicker there\u0027s a quicker Oh what\u0027s this let\u0027s just fight yeah that\u0027s good okay so we\u0027ve got a registry concept and we\u0027ve been working on this for a long time and we think now that with the Buenos Aires naming scheme and and all sorts of things that we\u0027ve done we\u0027re actually getting pretty close to what we need so also had lots of good meetings with the IANA folks because if you\u0027ve ever looked at the I ended directories and registries they they typically display things about a screen wide and if it goes beyond it\u0027s sort of a screen width it\u0027s a very becomes a very complicated thing and if you ask them to do the review and not help them out with experts that can be difficult too so we\u0027re actually kind of minimized what we asked of Vienna in this and we\u0027re going to support that with the additional detailed information so as you can see this is organized in categories and columns we\u0027ve got summary columns metric metric definition actually the categories are here on the left and lots of detail has to be added here so that we really nail down what the implementations have to do in order to make these measurements okay so it may come back to that so we added a lot of new loss metrics this time around in the initial contents and that yielded feedback on the names so down here in the bottom the Ayana section talks about three things that we\u0027re asking them to do we\u0027re asking them to give us URI namespace as as indicated there and to help us with a sub registry of the "
  },
  {
    "startTime": "00:12:20",
    "text": "name types and the elements of each name that feed into the names so what did we do with that let\u0027s see here\u0027s this a good place to go through that no actually so on on the on the one of the next drafts I\u0027ll talk about that some more but we\u0027ve got the name elements divided up into these categories the metric type the method the subtype method and you\u0027ll see how that works and and the subtypes can be expanded so that you can be as expository as possible the reference specification for this metric row the measurement units and the output formats so the the third item in the I Anna section is is all about the instructions for adding the new registry entries and to recognise the extension of the metric registry and in at least one category and each each entry will be mocked up and I\u0027ve been working on the mock-ups so that I enna essentially knows as much as possible what to do and I don\u0027t expect you to read all the the little text here but I did try to make the names as big as possible so you can see that the very first metric is a round-trip delay RT delay metric it\u0027s active method the subtype methods are IP UDP Plus on the RC number will be filled out the units of measure of seconds and the actual metric is 95th percentile so pretty easy to figure out from the name but we\u0027ve got a description there too and one key point is that under the URI column and you can\u0027t see all the columns here that I Anna will produce but one key thing there is is that there will be a URL to the complete registry description which wouldn\u0027t work in a you know a screen kind of thing like this you basically want to be able to see all the information read it like a document and that\u0027s what the you are URL will point to okay so here are the new name elements that we that we came up with as a result of this adding loss and so we\u0027ve got facto effectively a new category here the response loss for domain name service queries we revised the units so that we have ratio which is unitless then and then % which can be used for many different things but now that can be added to a ratio of necessary and we also have logical which is 1 0 I think that could also be true false in fact and that\u0027s one of the things in my mind to to change here if we get a chance and on on the outputs we have a singleton which is just a single sort of single number output and that\u0027s now distinguished from raw which is multiple Singleton\u0027s that was that\u0027s the way these things were always mentioned so we\u0027re gonna have both singleton and raw and we\u0027ve now explicitly got this lost ratio in there which is lost to total packets usually less than or equal to 1 all right so here\u0027s the mock-up of the element named element sub registry this year these are all for metric type and these "
  },
  {
    "startTime": "00:15:23",
    "text": "are the ones this is a subset of the ones that we have there now for a round-trip delay for round trip response time for the DNS response loss for DNS one way delay you round trip loss there\u0027s a whole bunch more in this first category of metric type and you\u0027ll actually see more caught more columns off to the right there as well when you see the final version ok so look the question we\u0027ve been asking and for anybody who does true passive measurement to the name element sets cover passive well enough and I think if someone actually doing passive measurement was to take a look at this they might have some ideas for us but that doesn\u0027t seem to be kind of feedback forthcoming and every time we look at this and add a few metrics or whatever it\u0027s been a chance to adds new name elements and we\u0027ve done that and so it\u0027s fairly easy to do this in the future and I think that\u0027s our protection if we don\u0027t get this feedback we\u0027ll be okay so how am i doing on time alright so here\u0027s the the initial performance metric registry entries these are the actual detailed entries that we\u0027re going to propose right away to put in and you can see there\u0027s a long history of drafts here for our co-authors Marcelo Phil and Keven D\u0027Souza my colleague at 18 T ha so the feedback on the registry contents we\u0027re actually you know still seeking what folks would like to see if they go ahead and look at this stuff hard these detailed registry contents and and appreciate what it takes to implement these metrics we\u0027ve had regulator guests in the past that\u0027s what reg you guests stands for and and actually over the last three or four meetings in a row probably not this time but you know we\u0027d like like people to feed into this so now sections four through eight in this draft introduce all the the new detailed of registry contents and what we found this time around was that it was fairly easy to add a loss metric kind of like as an overlay or a subsection in each one of the ones were for example if we had round trip delay before with UDP the first metric I mentioned it was fairly easy to add loss and that\u0027s because the methodologies are so closely related with loss and delay you use a timeout to determine whether the packets lost or delayed and or just not going to wait for it anymore and because of that commonality of the methodologies fairly easy to to put in loss so now in the in the draft we have many questions that were sort of answered and and decided with short discussions and and based on the I Anna work to clarify the protocols we\u0027ve got the ability to four editors like me to to expand our list of metrics and to do that economically by having an "
  },
  {
    "startTime": "00:18:24",
    "text": "approach where one section can actually create the registry entries for let\u0027s say four or five all delay related metrics and loss as I said because they\u0027re very closely related so we\u0027ve applied that approach now to almost all the sections so the early sections and the later sections seven and eight so here are the new metrics and now you can look at some more names and a little bit larger font size as I mentioned these are all going to be loss related obviously so we\u0027ve got round trip loss active IP UDP the response loss for DNS one way loss for active IP UDP Poisson and one way loss for IP UDP periodic and the rest of the information there anybody need the blue sheets actually I do Spencer well I guess I stood up at the wrong time thank you okay so um so I said loss has been added in the absolute simplest way we\u0027ve got this traceroute metric proposed we\u0027ll be discussing that at the at the meeting here and and I think this is I think this is worthwhile adding you know maybe we don\u0027t need to do it as part of the initial contents maybe we can do it as an adder or something like that but let the working group decide that there\u0027s many methods of measurement though that\u0027s the interesting part and and that\u0027s what we there\u0027s some new work going on in that area and there\u0027s always research in the area of traceroute both the active and the hybrid methods of measurement so here\u0027s a question to the group in the past folks have said yeah we\u0027d like to have a registered metric for ICMP echo request echo reply but and I and it\u0027s a big but here is anybody gonna really use this as a basis for comparison between systems and is anybody gonna use a ping measurement for regulatory compliance and I\u0027m kind of thinking maybe not but Brian\u0027s gonna say something Brian Trammell you would be surprised and horrified every day ya know I mean so in a lot of measurement situations especially in in so like there\u0027s this there\u0027s a broadband measurement project I guess so it\u0027s broadband mapping project that the Commission is running the European Commission is running for regulatory use cases primarily and their um their latency metrics I think they haven\u0027t really decided what they\u0027re gonna use but it\u0027s gonna be whatever they have in the dataset from the act of measurement provider and in a whole lot of cases that\u0027s ping so I think we need this well and because I mean if you\u0027re actually looking for again it sits back down to the do you want to look at the "
  },
  {
    "startTime": "00:21:25",
    "text": "difference between 53 and 55 milliseconds um which actually you can if it\u0027s stable paying well you know you can do a bunch of math and you get or do you want to look at the difference between ten and a thousand milliseconds and things okay for between ten and a thousand milliseconds yeah so it\u0027s really down to that yeah so I think we really actually do need this but but but I guess the point people are gonna use it yeah all right well if I mean if people are really gonna use it and regulators are gonna ask for it then then we\u0027re stuck great I think I think we\u0027d like to nudge them in the direction of not of using measurement methodologies that are slightly more comparable but I wanted to do that is to not include it I don\u0027t think that\u0027s gonna be a nudge that works out because there because that if that\u0027s all they have right there\u0027s two things that you can do you can either pretend that you used to you amp you use ping and you say oh we use to you went for this yeah which is terrible or you don\u0027t use the system which doesn\u0027t actually give us the comparability that we want so I think that I think that we kind of need to so um there was a second question that you asked earlier in the previous you don\u0027t have to go back to it is that is this okay actually no no show me that show me the just show me the names yeah for passive measurement there\u0027s basically two that you can easily use I mean there\u0027s a whole bunch of various bits of TCP passive measurement looking at transport level performance characteristics right which is latency lost jitter yeah um that jitter definite the jitter definitions you can get out of that are going to be subtly incompetent incompatible with the jitter definition that we have in our metrics right simply because of the way the TCP works there\u0027s also some discussion in the quick working group about what should the measurability aspects of quick be right and most of the work there is focusing on RT t + RT t okay and a lot of the work sort of there\u0027s been sort of informal surveys of who ships boxes that do what and a lot of the work that i\u0027ve seen as part of that effort for figuring out what quick should do based on what people are already doing with passive measurement and operations is that RT t is king loss is taken to be interesting but is much less interesting than RT t latency is because you you can you can guess I mean you can do active measurements if you\u0027re in a troubleshooting situation with loss but doing accurate measurements on the same path with the same traffic with the same headers to get exactly the same network treatment passive is the only way to do it yeah so I think the the exercises you take the oh actually no these are the these are all of the oh yeah no so this would be our LD n no "
  },
  {
    "startTime": "00:24:26",
    "text": "these are the loss metrics right so basically you don\u0027t have delay there\u0027s a delay comparable versioning to this right well because so so rttt cpr TT there\u0027s not a delay comperable loss metric for TCP RT t the very nature of it right but I think they beat the exercise basically taking the the just the delay yeah at Rex for UDP and then reframing them as TCP RTT passive passive yeah so I mean I can see this happening in the names pretty easily great and everything was on and then writing the definition to be you know do the stupid thing right which is watch the packet match with another packet yeah you know it\u0027s not I have I have tax that I\u0027ve written like six times explaining that that we could you know must be goodbye now lunch yeah that you could lunch together and um so I can actually ping me on that like all right we can all right cool well but it looks to me I mean you know do I do a lot of passing measurement in operations right now no um do I think a lot about it yes and this looks to me to be fine right so all right thanks sure thing thank you Mike Mike Ackerman good stuff as usual thank you my comment is on your ICMP question yeah and in enterprises we use that a lot for both latency and loss and so I\u0027d like to see it included or retained or well we\u0027re not precluding people from doing it it\u0027s it\u0027s for the registry really for me it\u0027s really about these comparisons we\u0027re gonna do it anyway if it\u0027s in the registry then that gives us all right all right and I have one other dumb question while I\u0027m up here ah yeah yeah response time loss for the response loss for DNS yeah what is that actually telling me is that a there was a reply there was a request to which there was no reply man you have set me up perfect okay look at this on my job so no no stand right there I mean in in DNS response time measurement if you get the response you wanted or the query answer then you\u0027re good but we have these two possible methodologies for measuring loss it would we could require support of an ID generation and population in the message so that when you get another message back from a second query you know which one it was it resolves ambiguity an alternative would be to use a random source port what the hell just happened you closed the presentation mode yeah yeah all right so but what what we would choose one method his version of clapping yeah I think so it wasn\u0027t he wasn\u0027t willing to own up to it I think that\u0027s right so so this is a major question we need to answer here in this in the context of DNS loss do we want to use this random source port methodology "
  },
  {
    "startTime": "00:27:26",
    "text": "or do we want to impose on people to insert a sequence number somehow and that\u0027s I hope I didn\u0027t stay here to give you that answer my no no I\u0027m all right well let\u0027s let\u0027s talk about getting towards the first I think we\u0027re actually running out of time but this was the major this was the major question I wanted to ask here and also I think we\u0027re gonna convert a couple of the metrics in section 4 and section 5 to periodic instead that seems to be the actual implementation so that\u0027s what I think we\u0027ll go for make it really quick Nalini I\u0027m overtime here sorry yeah there\u0027s actually already is an ID in the in the transaction ID Lillian Elkins in the in the DNS but it but dannis is gonna be encrypted so we\u0027re gonna lose it oh yeah great well but the problem is it may not be populated I think that\u0027s the problem but let\u0027s talk let\u0027s talk that\u0027s why I raised the question let\u0027s let\u0027s nail that down all right so thanks very much everybody jeez read the draft if you\u0027re gonna have to implement metrics read the draft who who has read one of the last three revisions of the of the registry draft for the last two years of the initial registry draft okay [Laughter] ghost on Thursday we encourage eyeballs on this thank you especially if you\u0027re gonna build stuff here\u0027s the tools [Music] so hello my name is your confer beanie I\u0027m covering this with L Malini Mike and VIN this is about nap date of the IP performance metrics framework for IP version 6 so a background most of you probably know it already so we have that B performance metrics framework summarizes the basics on which we build metrics so we have the basic trades there we have some some definitions we have some some assumptions about packets there and so the result of measurements might depend in this case on packet types in this and unfortunately the IP performance metrics framework was written back in 1998 if I remember correctly so by this time we didn\u0027t have IP version 6 or it was in the course of being standardized so we have there a statement that says a packet must include the valid header and the version field is for meaning IP version 6 is out of scope we have defined our metrics with IP version 6 in mind but according to that performance metrics framework it\u0027s out of scope any IP version 6 met measurement good we had some input of Brian carpenter during a review and we "
  },
  {
    "startTime": "00:30:27",
    "text": "said we will fix it in update good it was adopted as a working group item back a year ago and yes that\u0027s some work done on this we had some inputs status at last ITF was that there is discussion needed and we need to wait finally we had some some working items and we tried now to find solutions to no longer wait to in reply to your question so and Institute to have or us to find our assumptions to find our way and to propose solutions and these are the solutions so first question was what fragmentation IP version 6 fragmentation which is commonly encountered we have this quite distinct method of fragmentation just at the sending cost and so on and so on everybody knows and and we thought about how to include IP version 6 fragments and it turned out to be impossible because if we all all metrics are built on the assumption that we have we do not have fragmentation meaning if we introduced now allow fragmentation for IP version 6 it means we need to review and revisit all metric definitions and we also with respect to IP version 4 and that\u0027s not feasible so this is we adopt exactly the same approach that we have for IP version 4 and this is what we propose and say IP version 6 fragments are out of scope so fragment so so if if if fragments are used everyone\u0027s on his own in defining and and and finding right scope for these measurements Brian so hyper in trammel arm I only see one problem with this and this is all kind of your say so is anybody working on 6lowpan in the room 6lowpan is something slight but none of my laptop days yeah yeah so ok 6lowpan and IP version 6 header compression so we did some maths and it turns out and also it\u0027s it\u0027s originals in the 6lowpan I spent some time on reading these 6lowpan RFC\u0027s it turns out that we have about 31 bytes of user data per packet and in addition we do not have any IP addresses neither IP version 4 nor IP version more IP version 6 addresses in IP except if you\u0027re tunneling so this is if our packet fits into these 31 bytes then we can use a kind of tunneling mo just "
  },
  {
    "startTime": "00:33:27",
    "text": "transfer plain IP version 6 packets over IP over six low and so on and so on so our impression was that doing six low and including six low here and allowing six low means that we have to revisit anything that is even the concepts of standard form packets do not fit we need to review all of them and this is definitely out of scope so it is clear that we do not include include this explicitly the six lowest out of scope but we feel that it is better to have this to have IP version 6 going on the right track so to have IP version 6 standardized and if someone feels that is the need of a 6 low then to do it in a separate document so high for internal this actually this is the answer that I was hoping you get to so the only place that makes sense to have explicit support in the framework for 6 low in my in my opinion is if there is an interesting measurement application where you\u0027re comparing ipv6 to 6 low packets or you\u0027re doing path composition metrics where you have a gateway that\u0027s actually doing some sort of algorithmic transform on the packets and making them turn into 6 low packets which doesn\u0027t seem like that seems like such a little corner case that I think that we can safely carve it often say if 6 low people want to use the want to use the framework then please come and do the work to update it hi al Morden I I sort of assumed that there would be a gateway you\u0027re imagining that 6 low packets get generated as 6 low packets and only oh right right then then it\u0027s all 6 low yeah but but but I I guess I was looking at the end-to-end piece no no I don\u0027t change the answer the question no so thanks Spencer Spencer Dawkins is a curious area director I think that I have pretty good visibility of kind of where we are with 600 in fragments here but I\u0027m I\u0027m not sure how where the rock committee community is about about this situation do you think they know that that\u0027s going on or and I know it\u0027s harder because there\u0027s not a working group right we need some way to contact them but in fact so the problem that I see is really with this definition of a standard form packet that we try to fit to IP version 6 now to find solution to this and having 16-bit or 16-bit addressing that is proprietary to to 28.2 dot 15.4 is it creates some kind of "
  },
  {
    "startTime": "00:36:28",
    "text": "difficulty because we have the RFC we try to stick as much as possible the existing RFC with us with the framework sure and and introduce you know a distinct kind of addressing where we do not have all of these fields paid of land and and whatsoever and so on complicates matters cool I I will I will take the action to go back and send an email to the relevant area directors now so thank you thank you for thank you for giving us clues robust Heather compression is like so so we have stayed in the network that\u0027s one more one more problem we have we create stayed in the network in network nodes that that also impaired on the type of P that change the type e of packets so it\u0027s somehow difficult and and will try to promote this fast to have IP version 6 included into our measurements good we have this context is this concept of a minimal standard form packet and it\u0027s it said the RFC says that it is often useful I don\u0027t know of one singer single reference to this concept of a minimal standard form packet and I don\u0027t know how it could be treated in practice because this means that we basically do not have any payload any transport layer paid and the transport layer headers in a in a packet perhaps an IP version 6 we could do it with a no next header field directly in the IP header but I don\u0027t know to which extent this much this makes any sense and it for IP version 4 I don\u0027t know of any way how to specify that we do not have any transport header because we did and the protocols the field must be left unspecified so we opt for dropping this support that\u0027s for discussion unless anybody is using it right Thank You al so is anybody using the minimal standard formed Heather ok thank you good and last thing was the IP version 6 extension header treatment and this might be a controversial discussion we wanted to wait for six men to find the conclusion they haven\u0027t found it and now with in situ om and and all other aspects we just said we increasingly see an encryption of higher layers if we refer to quick we see that transport layers are encrypted we have no way of conveying OAM information timestamp and so over the network so from the perspective of IP performance metrics it does make sense to allow addition of trend of extension headers on the path and removal of extension patters extension headers along the path this is our position we would like to have it we do not know and perhaps before the end of the universe we will know if it will be allowed or not allowed but from an OEM perspective and IP pmbus if we "
  },
  {
    "startTime": "00:39:30",
    "text": "believe it should be allowed we need it we have some challenges we need to define and this is what we will do so define also changes adding an extension header we seen on Saturday in the a nrw workshop there was a discussion on on segment routing obviously adding a segment routing header somewhere along the path changes the route and therefore the type II of the packet so there will be some some needful discussion but we feel that adding the extension headers removing them and even modifying them along the path could be helpful for our perp so the proposal is allowed to allow this and stators and next steps thanks for updating the slide good we have proposals for basically all of our open items we want to int we want to have a discussion around list or off list and finally to reach a conclusion we will update a draft and then we want to go working group last call and we want to do it soon so integrating all of these items into the draft should take a matter of weeks and perhaps we can be we can do the working group last call even before next IETF meeting all right so this is a so this is a call for pre working group last call comments yes who\u0027s read the draft okay I can\u0027t see a whole lotta I mean like punch down over here okay Mike that doesn\u0027t count okay cool um again encouraging eyeballs on this because we will let\u0027s see working backward from November will want to yeah will want to do this sort of like early October at the latest so um actually as soon as you guys get the next Rev up I\u0027ll will start W DLC please not just on that before that will also need a document shepherd anybody in the room with ipv6 expertise IC Jin link OVA hiding I see Stephen Stroh is not looking at me huh you did someone just nómine dómini awesome oh wait yeah I know he\u0027s gone through yeah we can\u0027t do that okay yeah nice try Michael\u0027s also a co-author right and it\u0027s unfortunate alright so we we will we will we will leave that as an open question for the work of your class call the please consider whether or not you can help out a shepherd on this it\u0027s thank you the problem is that existing "
  },
  {
    "startTime": "00:42:31",
    "text": "RFC\u0027s depend on this job being becoming an RFC so Mike Ackerman a quick question on the previous slide about extension header processing what can we you you articulated it perfectly my question is what\u0027s the next step relative that do we want to carry this opinion well first off is it the opinion of IP p.m. secondly do we carry that forward to six-man is my question or is this a premature question on my part well I don\u0027t actually there\u0027s not any impact on v6 so this is not a 6-minute thing right this is an impact on our framework it basically is an impact of the handling on the under handling of extension headers and if we really religious about this as far as gray hood from from different meetings we cross put al Morton\u0027s suggests we cross post the letter yeah yeah yeah great we cross oppose the last call but but this is not a thing that there\u0027s there\u0027s not six men work that depends on this correct this is the issue that six man is debating or the rate okay right and we should absolute would they like the benefit of our input so to speak certainly yeah no so okay yeah so we\u0027ll cross post though actually when you like pre wgl see do cross post the announcement of the post and the next thing hope thank you thank you all right yeah I\u0027ll do them yeah everybody awake yeah feel like recharter in working group yeah alright so we\u0027ve had a our current charters for um a little more than four years now I I wasn\u0027t actually expecting this charter to last this long yeah model-based metrics there were questions in Chicago and post Chicago about bringing IOM into IP p.m. there seem to be rough working group consensus that that work fits here um there seem to be working group disagreement that that work fits here under the current Charter so we decided that we\u0027d have a discussion about the Charter so I\u0027m bill and I actually sat down and opened this up um and when we open it up we actually found that it doesn\u0027t really optimally cover what we\u0027re doing now it was worded in such a way that everything we\u0027re doing not technically kind of fits and that was on purpose because we wanted to have a relatively wide Charter to you "
  },
  {
    "startTime": "00:45:33",
    "text": "know be able to chase down sort of things that raised came out of the metric stuff things that came out of the 2330 stuff that um you know we had a line in there we have a line in charge of it says we\u0027re gonna update our framework but not necessarily reacting to external things but hey it does really matter any ideas let\u0027s make some small edits to catch up to the present so we\u0027re gonna go through these paragraph by paragraph we only touched four paragraphs at the end and it turns out that that touching those paragraphs doesn\u0027t really change much normative language with respect to whether IOM comes in so the first thing we want to do is rename the working group we\u0027ve been called IP performance metrics since 1980 mumble if you look at the work on our agenda we have um we\u0027re spending a little bit less than that for time on metrics and a little bit more than half our time on methodologies and those methodologies are on charter for our working group in that they allow us to measure metrics but it might actually be more useful to be explicit about the fact that we do measurement there\u0027s uh yeah so yeah this is I\u0027m I\u0027m sorry for the red-green color blind people um I do if it\u0027s bold then it\u0027s new if it\u0027s crossed out then it goes away I tried to have it so that would actually work but I\u0027m seeing but the bold might not actually be bold enough to point out that it\u0027s new so strike metrics replaced with measurement then we take the census specifying network and our lower layer OEM mechanisms out of scope the I ppm charter now when I look at what I OEM is it\u0027s not a lower layer OEM mechanism it\u0027s a mechanism for um carrying certain information on path which can be bound to lower layer headers but it doesn\u0027t like the naming is unfortunate but I think the naming is unfortunate as a collision between sort of ops area terminology and transport area terminology anything that looks kind of like measurement in ops in my understanding gets called OEM because that\u0027s it\u0027s it\u0027s a management function in order to remove confusion here we would suggest that we just strike this line I don\u0027t think that striking this line is necessary to bring IO am in but on the other hand we have a line that says we don\u0027t do OEM and then we have a draft called IOM that\u0027s I can see how that can be confusing right and it\u0027s splitting it\u0027s splitting hairs to say well so it this is something that I think makes it clear and I don\u0027t actually know what having this in solves I don\u0027t know the problem that this line solves women basically the rest of the edits are we add protocols and methodologies to the things that we do it was a metrics heavy introductory "
  },
  {
    "startTime": "00:48:34",
    "text": "paragraph now it\u0027s and metrics protocols and methodologies having intro paragraph again this just reflects you could say that this is Evan toriel this reflects sort of we\u0027ve been doing owl had a suggestion that we strike and not a value judgment because it could be somewhat confusing that the way that mbm works is you do an acceptance test which looks kind of like a value judgment because yes and newer values but it still does provide an unbiased quantitative performance measurement and that was what we were really trying to get out with that text and I think that this end not a value judgment is is this is some of the oldest text in the Charter right but are there any comments on paragraph one Spencer mr. Dawkins responsible area director I don\u0027t mind getting Appeals I mind getting appeals that include the the words can\u0027t you read so thank you for striking that so that\u0027s I thought tommy\u0027s rocky Marvel I apologize for this comment but can we get rid of IP because some of the methodologies were discussing are for example applicable to MPLS and IP is not necessarily there so I mean if we\u0027re talking only about IP we\u0027re limiting our scope and okay so I\u0027m gonna make an individual comment I should probably run up to the mic but I\u0027m lazy um now I think I know why we have that line in there about putting that out of scope because so on the one hand yes maybe on the other hand we\u0027ve always been focused here on the types of measurements that you can do from IP endpoints and it\u0027s very difficult to measure in pls from an IP endpoint you can measure from an MPLS endpoint but you can also measure in pls if you\u0027re an MPLS endpoint you can put IP packets down the MPLS endpoint and you\u0027re measuring the same thing greg i greg murska ZT okay i really like to comment because i was to comment about this sentence that was crossed yes the network layer and wor layer is confusing because now we have many overlays that go above at E and what about them because they do put packets of om packets on the wire and they do have their own performance measurement on their layers on sub layers if we want to so I think that "
  },
  {
    "startTime": "00:51:37",
    "text": "trying to generalize and look at performance measurement methodologies applicable to networking technologies being worked at ITF that might be a worthy goal and then try to scope out specific encapsulation because specific encapsulation should be decided in appropriate working groups so if we can combine let\u0027s emphasize IP performance measurements because we need technologies for for example SFC and vo3 beer and they not necessarily run on IP data plane they run on MPLS data plane but they can benefit from their common technology methodology at the same time we want these groups to decide applicability of this methodologies and this particular encapsulation so if we can achieve this separation of authority domains I think that will benefit everybody actually I am just to make it very clear that I\u0027m not speaking from a chair I Brian Trammell as an individual I really like where you\u0027re going with that I think the key is so it\u0027s it\u0027s so there\u0027s commonality and methodology that\u0027s very interesting one of its it it\u0027s not interesting because it saves code although it also saves code it\u0027s really interesting because you start to get comparability across these different layers and that\u0027s not a thing that we\u0027ve ever really had and I think part of the reason that we haven\u0027t had that is that there\u0027s a little bit of a firewall between TSV and ops on this that shouldn\u0027t be there right I mean like I mean the way that we don\u0027t have that firewall or there are people who participate on both sides like yourself I am chair head on I am not sure how to write charter text for that it\u0027s hard right so so there\u0027s a I think we\u0027re opening up a bigger question that we it\u0027s good that we have the time an agenda to discuss is is this a thing that other people in the room are interested in opening up and basically saying okay we we we have these methodologies and things like Altmark work very very well at both sides things like IOM work very very well both on IP pads and on non-ivy pads do we want to bring essentially convergence in metrics methodologies not protocols not encapsulations but in metrics methodologies and have comparable "
  },
  {
    "startTime": "00:54:37",
    "text": "metrics across that boundary um discuss I I think we do I\u0027m not sure how to scope it so the problem is is that is that my Eve scoping that I would write for that puts a whole bunch of stuff in scope that really shouldn\u0027t be in this room great I don\u0027t know I think that by saying that we\u0027re going to we\u0027re going to measure take these metrics that we have experience with and take these methodologies we have experience with it IP and look at their applicability in non IP networks is very interesting but but I\u0027m not sure how to how to scope that so we can get the right people in the room so that\u0027s that be a question that I would yeah okay one way of at least separating ourselves from specifics of networking technologies and encapsulation of methodology on the wire would be to say protocol encapsulation on the wire is outside the scope again it\u0027s not exact wording it\u0027s not recording but along this line so basically we don\u0027t want to tell other working groups how that looks on the wire well I mean we we do want to we do want to continue maintaining our own act of measurement protocols on top of IP where we do have our wire format straight so I mean we need to do it in such a way that a rampant he went for me in in scope but and anything else we come up with on the IP side remains in store but encapsulations in non IP networks are right okay okay in my other experience so we do have bi-directional forwarding detection for kind of continuity verification between systems leave denotes that is applicable to IP it was that technology was developed and defined in VD working group but applicability to MPLS is an MPLS working group as long as doesn\u0027t change the BFD based protocol and so in all other groups so applicability of BFD as a protocol to different layers as long as doesn\u0027t affect the FD based is done on this working groups and then for be of these FYI so it\u0027s a cross presented just to tell that we\u0027re doing that seems like a again it seems like a very good arrangement I think we need I think we\u0027re now I think actually what we should do is we take to the list a new paragraph that essentially talks about the scoping then we refer to at Ford from the from this paragraph and then we make any changes that need to happen in this paragraph that contradict it right so I\u0027d like to "
  },
  {
    "startTime": "00:57:37",
    "text": "keep I\u0027d like to keep um IP in the name of the working group because it\u0027s been AI ppm forever yeah yeah yes IP plus performance metrics and it\u0027s still IP PM because if we put a plus in a working group name the two those people hate us yeah I pppp pppp pppp M I tell Mizrahi again so I think the work we\u0027re doing today already goes beyond the scope of IP in some cases so I think as an exercise one thing we can try to do is remove IP from the Charter and see what what\u0027s the result and think consider whether that\u0027s valid or not another thing we can do is just add a paragraph that says in some cases the methodologies will go beyond IP and that\u0027s still part of the scope of the working I think those are two options we can think about so L Morton has another idea not necessarily conflicting with these others but I\u0027ll go back to the measurement thing later perhaps what we need most is our stated goal which you just came to the microphone and I think we all agreed with Brian and and that is that we\u0027d our goal is to encourage or foster a better measurement commonality across the different layers and the only way we\u0027re going to get there is to have recommendations that are broadly applicable and we can always evaluate whether proposals are consistent with this goal and don\u0027t tread on and so maybe there\u0027s another phrase there without without without creating overlapping work something like that and and that might be the way to phrase the we\u0027re trying to do something good here we\u0027re trying not to piss you off as well right yeah so and then back on the other page consider consider IP performance methodologies measurement is what we do with all this stuff but in the working group we create methods and the rate so and the surrounding IP performance methodologies to me sounds like making IP go faster which is not what we do so what we need is I feel the weight ie p and p performance metrics and methodologies so now the working group is IP p p mmm okay I think measurement yeah Oh Cisco I also like the spirit of "
  },
  {
    "startTime": "01:00:43",
    "text": "what Tali saying I I think there\u0027s great value in that how that translate to the Charter however I could be I would really try not to innovate too much on the wording on this part and Libby disease I would actually much rather have a targeted paragraph stating what you\u0027re talking on the other slide leave IP leave everything as is in addition the working group will blah blah blah I think that\u0027s a much safer way of not attacking the government thank you if I may make a comment again all right I\u0027m gonna make a I\u0027m gonna make a non chair comment cuz I\u0027m getting I\u0027m tired um so is it safe to say that we are not interested in methods or metrics that are not measurable at IP at all right so it\u0027s like the the way that we decide things are in scope or out of scope are if it\u0027s not applicable at IP then it\u0027s out of scope here if it\u0027s applicable at IP and applicable at other layers then it\u0027s in scope here and we should make sure that we explore the applicability those other layers Notaro cisco i I think that\u0027s the same thing that I was saying look at it from the other way yeah and I think that perfect way of reading it right it\u0027s because you know within the Charter you\u0027re trying to get clarity both what\u0027s in and what\u0027s out yep and you know if it is for AP it\u0027s in but it\u0027s also within Charter to go and explore and you know the other thing that I the other word key word that I think needs to be on the Charter as a goal is collaboration collaboration with other working groups yeah and that means hey we need this encapsulation as FC which ever grow right that doesn\u0027t get defined here I would say that that\u0027s not actually so it\u0027s not a goal that it\u0027s a major method of how we meet the first goal right it\u0027s like we\u0027d like to foster measurement commonality is opportunity yes across different layers we could do that by being by by being the working group where all the measurement in the entire IETF happens but that\u0027s not going to happen so thank you thanks Dave Allen Erickson actually your last comment pretty much I code where I was going to go because when you start talking non IP you make me a bit nervous and the reality what you\u0027re talking about is a ETF technology yes and if that was if that was simply made clear because just about everything that\u0027s not I P in the IETF is some form of IP helper oration yeah right like yeah like beer or yes so what we what we mean in the IDF when we say non it non IP is things like MPLS and what you mean "
  },
  {
    "startTime": "01:03:44",
    "text": "in PDF when you say non IP is the entire management layer that\u0027s down below that and there\u0027s no reason so I mean wait yeah you know there\u0027s a bunch of satellite protocols yeah exactly yeah yeah so I think I think a good way so so that this makes me a lot more comfortable with this than when Tom first got up I think by basically saying that the scope is you know is applicable on an IP network than yes and let\u0027s look in the other the other layers that it might be applicable at in foster cross layer collaboration we don\u0027t wanna say crops layer in the IDF but you know there\u0027s sports nothing to be done yes absolutely wait you\u0027re not doing that yeah right um good thank you Dave I actually chair had on I\u0027d actually like to ask for any comments from people in the room who thinks that this is a terrible idea get up yell at us alright that\u0027s pretty good okay cool that sounds like an answer let\u0027s actually get through the really easy editorial stuff now so I think I think we\u0027re gonna have to do a little bit more wordsmithing here and we\u0027re gonna have to take this discussion to the list I think we\u0027ve got good input from the from the in-person discussion here I think that this is we can get to something that we can iterate on relatively quickly I think I understand where the scope is though are you happy with you think we can bang this out okay all right let\u0027s do some easy ones we\u0027re reach are during the working group so we can take out the line that says we might reach our to the working group there was a comment that we might want to remove the dependency on 63 90s since EMDR doesn\u0027t really seem too much of a going concern anymore but I think that the the framework in 63 90 we\u0027ve actually figured out how to work with it so I don\u0027t see any reason to actually pull this out like it\u0027s as a as a base performance metrics template it\u0027s actually pretty good as a performance metrics template that defines how you measure things we\u0027ve kind of augmented it with the registry so I\u0027m warden so 63 90 I was never intended to apply to the working groups that already had good templates and that this got jammed in at iesg time I I I think you know we we leave it but we respect it yeah yep enough yep paragraph six this is a tense change we said that we were gonna define a registry now we\u0027re defining a registry so we can make this present paragraph "
  },
  {
    "startTime": "01:06:47",
    "text": "seven we\u0027ve got two so there\u0027s two can you even see the different shades of green here there\u0027s two things that we\u0027re adding here and I wanted to talk about them separately one is we we talked about context so anything that we can get like just a metric in isolation doesn\u0027t give you anything really optional right a metric and isolation with a couple of endpoints and some type P gives you a little bit more a metric along with all of the metadata about how it was created you know which tools how was the measurement set up references to other things is much more useful and comparable right so our goal and I like the where we got sort of in the the more points I\u0027m charter on what our goal is is we\u0027re really at a point now where we\u0027ve got the metrics we have some experience with them now we want to foster comparability and one of the big ways to foster comparability is to make sure that when you\u0027re looking at measurements you know as much about the environment in which the measurement was taken as you can this was this text was written to be extremely general and we thought it might be useful to add some examples here in order to make it clear what kinds of of context information we think is interesting so measurement implementation information not just with which methodology were using but which revision of which tool was being used because there are always bugs in inactive measurement methods there are always bugs in passive measurement methods you\u0027d like to be able to know whether you\u0027ve got invalid rows because you found a bug later and it\u0027s like okay well I can\u0027t rely on it any more conditions on the networks in which measurements are taken so you know if you\u0027re in especially this is especially important for passive right so if you\u0027re doing or even active right if you\u0027re doing um a study that\u0027s using a lot of ripe Atlas notes knowing about the the load condition on those ripe Atlas nodes it turns out um gives you information about the fidelity of the measurements that you\u0027re running and or information about the data plane topology of these networks we have a whole bunch of work on spatial composition of metrics across paths and no way to measure what those paths are um so this is this is let\u0027s think about trace route and other and let\u0027s think about in Vandal Yemen let\u0027s think about other ways that we can get path information into our metrics huh lots of methods the second one is something that actually came up after our discussion alright let\u0027s let\u0027s talk about the first one is so this is not it says for example but not limited to and this is really clarifying clarifying text so we can probably do without it but um it says that right now we\u0027re pointed in the direction of looking at these sorts of information because we also don\u0027t want to say hey we\u0027re gonna collect a lot of metadata including the user identifiers are the people who are involved because that would not work so we want to we want to be clear about the type of contextual information that we\u0027re interested in are there any comments on the dark green part of this "
  },
  {
    "startTime": "01:09:47",
    "text": "text before you go to the light green front parse more of a question than a comment given that you\u0027re considering multiple implementations and we have multiple methods and tools would it make sense to also have a some qualification of confidence of what you can get from a particular implementation or tool I\u0027m just thinking of situations like if you\u0027re using ICMP and ping not every router renderer handles ICMP packets in the very same way which impacts what you\u0027re getting it as an outcome of that particular measurement especially thinking of the earlier conversation that we were having around using ICMP as part of the registry for metrics that other people will well use for decision-making or qualification of a network so is that something that we could go and add here is that in the sea yeah yes and no so yes in that it\u0027s contextual information that that that gives you a better idea about comparability no in that we actually these are so the contextual information is on a collection of measurements in the error bar should be on each measurement right if I have a long series of pings over a peep over a period of time that are between 52 and 53 and 1/2 milliseconds I have a pretty good idea that that 52 is I mean it\u0027s it\u0027s within you know I have high confidence in that because I have a thousand of them and they\u0027re all about the same if I have a lot of those and then I have a ping that\u0027s two seconds and there\u0027s only one of them but I\u0027m not sure I believe that what\u0027s your level of confidence and ping in that case right the level of confidence and thing is not great so there\u0027s a base level of confidence but there\u0027s also a sort of statistical analysis that you can do so confidence is so I think I think what I\u0027m it\u0027s the confidence in the measurement itself yes and the confidence in the tool Wayne used to get to the measuring rate so it\u0027s I think the methodology and measurement so so I think that methods for measuring the confidence in for the types of measurements that we\u0027ve done so far measurement methods for quantitate Kwan quantifying the confidence that we have in measurements are still seems to me to be on a single measurement is a is an open area of research right like being able oh it\u0027s hard right having the ability to I mean there are other there are other methods where you can like there are other methods where you can do cryptographic things for example where you have more confidence because you can actually quantify the number of bits that you need to that need to be wrong for this measurement to be wrong but in ping it\u0027s like it\u0027s really really hard to quantify the things that can go wrong "
  },
  {
    "startTime": "01:12:47",
    "text": "with ping there\u0027s like a whole subfield of Internet research about unbreaking ping the so yes this is absolutely in scope here I\u0027m not sure how to capture it because it\u0027s because because that one term captors two different things great and we need to make we need to make clear so I have a note here that we should figure out how to get that in but we need to make clear that we\u0027re not confusing the two kinds of confidence other comments on this list of examples I mean so with with the note please don\u0027t you know put you know every single example in here because we it\u0027s a list of examples it\u0027s got like five examples in it then it\u0027s good it\u0027s goal is two examples is 20 examples in it then people are gonna treat it as if it\u0027s complete and if it\u0027s not in the list of 20 things then it\u0027s not on charter I think we\u0027re good here are there other comments on this point moving on to the light green section um this is actually some oh that\u0027s a terrible highlight we\u0027re gonna leave that one highlighted um this is something it actually came out of the applied networking research workshop that was held in this very room on Saturday wow it\u0027s been a long week it may foster this work by defining information and data models for the storage and dissemination of measurement data and what this is is that we have a few measurement platforms and a lot of sort of research grade measurement studies all of which define at least one of their own and often more than one of their own data formats for data storage and exchange and if you\u0027re trying to do calm lake actual comparability across different tool sets or different metric sets you spend about 80% of your time writing parsers and about 10% of your time assigning confidence and the other 10% of your time doing work um it seems like there could be a better wave in this I had personally I had an offline conversation with some of the right that was people and they would be a minimal to print to to take their experience with data formats on their platform which is relatively large it does it does trace routing and some response time stuff rate it\u0027s not it\u0027s not a large distributed Oh amp infrastructure it seems like we do know some people who run large distributive infrastructures and we could possibly talk to them about their data models but um they seem to be slightly heavier weight than what right has done um and it seems like this would be a way to have a conversation about how can we how can you learn from the experience of some of these measurement platforms in order to define ways it\u0027s like okay well if you\u0027re gonna publish a thing like so you say to this this broadband mapping thing if you publish it and if there\u0027s a standard that comes out of here if it says you\u0027ve referenced this and this is how we represent this and you know that "
  },
  {
    "startTime": "01:15:47",
    "text": "when you\u0027re parsing it that you can use the same person it means the same thing that seems like it might be very useful so comments on this part I support what you\u0027re saying as a concept I think is great I don\u0027t think that takes the CDs reflects what you said okay because I think is fairly generic and you know in particular the one specific concern that I have is to is to mark a you know finer demarcation between working line because you know part of the work there is about data models on some OAM things which may include some you know way in which we export measurement data so you know if we can if we come disambiguate with lime that would be great and I think the way to do that is to be more to add more precision to the text he may end up being longer yep but you know that\u0027s the reason it seems like that might be another paragraph because paragraph seven is already getting pretty long we can put a paragraph break here on I think you can get doesn\u0027t follow yeah right yep yeah so this is we\u0027re actually kind of talking about a separate thing great yes I think this ended up in paragraph seven because I was editing paragraph seven while Ian or W thing came up um can you help and suggest text here more than happy to okay excellent thank you Frank but my point was very much along the same lines kind of understanding what the relationship to the work in line would be are we gonna go and define yang models for that or no yes so something else and also that the other thing is like but I\u0027m not a native speaker very obviously and I\u0027ve really difficulty decoding it may foster this actually means there\u0027s a sigh well as fluffy as he can go right so saying what we are gonna go do and what we\u0027re not gonna go do this probably helping them great yep excellent so um crow as Wilson text yeah so one thing that I think is the problem here is that in the internet measurement research community data model means something very different than it does in the operations community so in that it\u0027s basically the information model is the set of classes and sort of what attributes they have in the data model is how you bang that into a JSON object right so it\u0027s much it\u0027s a much lesser um or or into a sieve or object or into CSV or you know how you how you represent it down it\u0027s it\u0027s a much less precise term of art in that area than it is in so terminology in in that was an unfortunate and unintentional terminology collision so I don\u0027t want to open mic the Charter at "
  },
  {
    "startTime": "01:18:48",
    "text": "this point because like it\u0027s like oh we chartering let\u0027s put let\u0027s put in some ponies and Spencer\u0027s Spencer chuckle means that he would also like us not to do that I\u0027m Spencer could I ask you to come up and take the temperature VAD on this one or can you just you can you can you can you give a Roman gladiator if you don\u0027t have to walk all the way up okay cool yeah let the record show thumbs up from Spencer alright so with that let\u0027s talk about stuff related to what we\u0027re okay so that yeah the outcome the action item is bill and I are gonna take text from Carlos and the comments that we had here we\u0027re gonna propose probably we\u0027re gonna stop talking about just diffs at that point we\u0027re gonna propose a full Charter divorced and then we\u0027ll iterate on that on the list and then we\u0027ll hand that up to a dispenser and he pushes all the magic data tracker buttons and then there\u0027s a discussion in the ie B and then there\u0027s discussion in the is G and then we get a shiny new charter settle with that Frank thank you all very much okay so a brief update on NC to OEM and the data draft just go to the next slide I have a single slide on that update okay you just don\u0027t go to presentation mode maybe that\u0027s the solution I have very low confidence in this measurement method yeah I think even harder would be to give me a number on how well it does its 27 or so we received a ton of good comments post Chicago meeting and one particular area that we put a load of additional text in EXO and that an ad hominem section is that in situ OEM is really bound to a particular deployment domain and that we want to go and from an implementation perspective make sure that we\u0027re doing everything that we can in order to keep the IOM data fields to that particular domain so that they\u0027re not leaking and in addition to that also put some emphasis on the operator to make sure that these data records don\u0027t leak so that was a major concern so we edit that section with kind of scope specific information for NC to OEM "
  },
  {
    "startTime": "01:21:49",
    "text": "and the deployment domain I think is specifically spelled out and we\u0027ve done a load of widsom I think even over the list to go and get there the other thing that we specified as part of the scope section is in situ OEM control points which is encapsulating ecaps elating and transit nodes encapsulating puts on the header be capsule aiding and removes the header and transit notes either update or add to the header then we also had a clarification that NC to OEM not know something doesn\u0027t necessarily apply to all the traffic but can apply to subsets off the traffic and again you can use some classifier to decide on what that subset of the traffic would be that goes well hand in hand with other drafts like we\u0027ve seen the UDP ping or draft from predator LaPook often team so that well the UDP pinger can be used with in situ OEM which is why patter is of co-author of the draft we clearly stated that encapsulations for inbound for in-situ OEM will be done in a variety of different working groups ie it\u0027s out of scope for what we\u0027re doing here but it would need to go into the various various transports so exactly what the new charter should go and try to achieve so the earlier discussion that well tell and Greg drove will have multiple layers eventually these layers can all use in situ OEM data formats hopefully they all use the same formats so that\u0027s what we want to go and and achieve here so that also talks about the layering aspects it\u0027s absolutely possible that you have a tunneling protocol like genève using in-situ OEM and underneath you have a transport protocol like ipv6 using another for for itself flavor or instance I have to say often see to OEM and well obviously you will also want to go on specify things that they combine well with other REM mechanism so I already mentioned the UDP finger from patter that comes along quite nicely in addition to that hmm there is one change that we\u0027ve also done for t1 and doe amp as well as for ntp that we have a field to make the overall insertion of information that we are adding checksum neutral so that\u0027s an option so that you don\u0027t have to recompute the checksum if your protocol uses UDP but you\u0027re you\u0027re staying where you are and that\u0027s exactly the same reference mechanism and that\u0027s taken reference to RFC seventy eighty seventy seventy eight twenty and seventy eight twenty one and so that\u0027s another "
  },
  {
    "startTime": "01:24:51",
    "text": "addition and another change given that we\u0027ve seen quite a few silicon vendors even putting the thing into silicon as we speak I don\u0027t want to go and iterate through the names again but we\u0027ve seen at least three public announcements plus we have the open source implementation so things are moving and things are moving quickly so let\u0027s make this a Sanders track document that was a comment on the list rather than the originally originally proposed experimental version and in addition to that a big thank you to Joe Clark and L Morton who\u0027ve done a thorough read through and we were able to are now the load of editorial knits one thing if you read through the list with added a scope section we\u0027ve done one update to the the data fields and a lot of editorial knits so you see that the document is stabilizing mine are quite nicely so I think we\u0027re achieving what we wanted to achieve which is also probably wider the working group at auction : well and that\u0027s what I had thank you very much so actually as a procedural um note I think we\u0027re going to just so everything is nice and clean um continue doing any further edits on this as draft Bruckner\u0027s until the recharter goes through and then as soon as that\u0027s happened the adoption call that we already did will take effect right so I think we need to do another adoption call we already have a pretty good runner frost consensus on that point okay so yeah please ask a question so oh yeah well let me finish we have a pretty good indication of rough consensus that this is this should be an IP p.m. now we have a charter that should fit well I mean we have almost the only cell charter we needed to go through the reach or during um once that\u0027s happened we can bring those on this draft IETF I ppm IO am all right good yeah thank you yes shat on the very Broadcom so we have a bunch of customers that only want the end-to-end in situ om so for that reason I noticed in your draft you only have a sequence number for the end-to-end but we also need timestamp for example to measure the you know in replacement of t1 problem you can have time stamps right absolutely there is data fields for timestamps not for n2 it only for well Popeye so the question is so there is the restriction for end-to-end where only the inserting and the removing will ever touch that particular data but what I want you can have also if you\u0027re using the kind of hop-by-hop one it\u0027s still "
  },
  {
    "startTime": "01:27:51",
    "text": "that allah dhu is over in the video no but individual notes in between can miss out right so you can still use notes but starting at the endpoint so the other ones don\u0027t touch it okay and I think that that specific case is covered we want to make it more clear we can absolutely do that so we have subtype you need to eat maybe become a little closer to the mic uh there is a sub type in the e to e option type which can be used today it\u0027s defined there\u0027s only sequence commodifying we can refine a number of other of other data type i think somebody in 6lowpan has done timestamp i can send you the reference to that draft because they also wanted end-to-end a second thing is that the timestamp formats you have right now it\u0027s only PTP do you want to add ntp to ethos or not well take that to listen I think that as well as the first comment you can get out onto the list and the tariff plan is not exactly clear how to identify there is in-situ opium in the packet or not how do we know it is there or not ipv6 here we have options but how about the other one well I think that\u0027s a transport related question I know is very difficult to be resolved here yes so nothing from a procedural perspective what I would expect happening is once this is a working group document so that we can officially refer to that in other working groups we will see there\u0027s been this kind of scratchpad document that we call the transport draft that has yeah it\u0027s just a capsulation for us that we\u0027re starting to have individual drafts on these and video iconic encapsulations and then we can Corrine do the OL encapsulation address that specific question thank you one comment on this side with my i\u0027ma trains poor guy TSV guy had on on don\u0027t call it transport draft transport no yeah you you will get lots of concern for the yeah right you will get well no I understand marinade encapsulation you\u0027re gonna get a lot of you\u0027re gonna get a lot of confused comments that we\u0027re gonna be helpful all right so next up and we\u0027re running a little behind on schedule I think nowhere we have we have ten minutes for the next two presentations so we\u0027re running a little behind so speeding up would be good we have we have ten minutes for the next two presentations right so I mean yeah you can I mean like we\u0027re probably going to end up going over on this anyway but you know please try to be "
  },
  {
    "startTime": "01:30:51",
    "text": "brief Knology but when we actually increments that we need to consider what\u0027s impact to the actuary data plane performance also when you consider in the future how you mix the solution really scale so you this proposal we have a address several issues or based on some real use cases so I consume them fast the first one is about how to scale the to support more data types currently there are only 16 beats are used to for data types and support at most 16 different types but currently for here we have been defined only two V\u0027s to be Celeste so we proposed to use a preserver last beat so which means another man will follow the feather so 31 approves it one more new data types so to support AB 3 number of UD the types so that yeah we can imagine there are many different various cases to support new data types so exactly wise to do is a some potential limitation on the past lands and I\u0027m too because also we may have a just limited budget to hold the IOM data if the past is very long and you know the overhead may be too large so to solve resolve this issue will be proposed to use van David beats to indicate the segment IOM so the contents then given the IOM is that we give a fixed size of the segment and we only hold the IOM data up to that segment in image and answer sending in the head will remove the header and just send the data to some mental insanity and we started working and we addition this Lancefield into two parts the first part is for pete\u0027s you to indicate second in size which means that you segment can be up to sixteen sixteen Hawks and the sectional cards are useless you still to indicates the remaining hops in the segment so there are some also some use cases for example if you have you have we have fixed budget to hold the IOM "
  },
  {
    "startTime": "01:33:52",
    "text": "data we can calculate how many hops weakness support each segment then we can see the segment that Courtney okay I was keep some other your species I\u0027m like at the last why is it there are some possibilities for virus reason some notes as cannot provide the IOM data or cannot provide part of the data so how to handle that we proposed user data know the bitmap to indicate which node is a is valid to provide the IOM data so if some note can pass a header but they prefer to note added is own dated to the to the to the full an old bank and just research is respond engage in a bitmap so that which means the following data list that\u0027s no parity there\u0027s no similarly for each for each node I have another we have another relative bitmap so in the case of which data is that this is actual valid or not which means that it and you use kisses is that you know sometimes maybe the traffic is very heavy and the no just cannot keep publish if want to add data to the note maybe is in danger of drops the package so in this case is rather to note add new data to that after that to the node I can simply set the amenities so there are some other issues minor issues or try to address performance even implementation or equation so any question thank you very much next is yep did we so he\u0027s basically just gonna do this he\u0027ll put himself in queue and then I\u0027ll be min Ignacio can you put yourself in queue Wacka Wacka Wacka Wacka and will be even in hello Ignacio hello hi hi everybody it\u0027s too early here I what i will start with with advanced ed unidirectional good assessment it\u0027s a draft proposal with jean war with al martin and "
  },
  {
    "startTime": "01:36:52",
    "text": "European Viviani and I am Ignacio Alvarez amylum well let\u0027s start with the objectives here we will propose three objetives a new metric which updates the section 5 of earlier RFC 2330 a framework for active and productive passing methods and also on round trip delay measurement statistics next slide please well this is just a tour network to make our examples we have a source and destination nodes and some routers in the middle next slide please here we want to identify a particular flow from source choose a destination and in particular the flow is identified for IP source address IP destination address the port source number and the port source destination and also the protocol next slide please we we can see that normally there are different flows from source to destination because the different routing policies or balancing something like that and we want to measure the different flows the idea is to measure round-trip delay from source to every intermediate hope and we want to call this T I is the intermediate hope and the cost identification is the IP ingress interface for active measurements or alternative alternative identifiers in the case of in situ or all a.m. we also call this cover our cost according to our FEC eleven twenty five twenty two in this case the host she do not decrement TTL therefore is not discoverable next slide please we identify two different things route member which is for a particular flow in this case the green one which is the set of round two times TI t BG e TK TM and destination and also route and sandal which is the every possible flaws in in order in in the thus except hops "
  },
  {
    "startTime": "01:39:57",
    "text": "distance from the destination next slide please and finally this is the formal description where we we can see that every cop has a hot number and also the number of lower the number of alternative route okay next slide please well we are interesting to define two groups of Route assignment methodologies active methodologies mainly based on trace route here we we propose to use polystrate route which is a tool developed in 2006 and you embarrass ons because this is a floor Y stool which means that can identify in 99% of cases every hope for every flaw that you that that Tron\u0027s a source and destination we we have different tools like scampers companies this base is a very includes many other features but also implements this idea a proposed for Paris trail route we also want to highlight everything methodologies like in situ or OAM where nodes cannot timestamp and route information in in every in every step in every hop next slide please well the rupee the type P route in southern method variant should verify different things for different kind of protocols this is some kind of structure of the ideas around Palace traceroute for instance if the proofs are TCP we want to maintain constant the the source and destination address the port and source destination also the the field dscp in order to to be the to be observer as the same flow for UDP is a little more complicated because we want to ensure the backward part I mean we are measuring round-trip time we can measure just we can no chance the IP of the hope the ingress IP number but the backward packet which is a CMP can follow different paths the IDH to maintain the idea to follow exactly the "
  },
  {
    "startTime": "01:43:00",
    "text": "same part for this cop this particular hawk for that we need to observe the UDP checksum and well this is a little more tricky because we want we need to manipulate something so maybe something that time into the packet in order to assure that and for ICMP proofs we use normally the data field to compensate teacher than IP checksum please next slide well what what are the goals to measure this round-trip time here we have like four but perhaps there are more in particular we want to identify Intercontinental summary links satellite communications congestion entitlement cuts I added some articles related with this for problems in particular congestion is a little tricky the definition but the paper that I highlighted for this item is related to compare the minimum RTT versus the actual RTT and when you see some some variation you can see okay you you are facing some kind of congestion and we can add more eventually but this is that the four first type that problem that we want to to to find using this tool next slide please well this is just to illustrate one of the the picture that we can get when we are doing some statistics here we are we perform some round-trip delay doing several for instance one hour one packet per second from the from the one particular hope this is for case in different cases and we can see here that the queue are really really heavy really long this is the the reason because we want to to find some kind of indicator some kind of measurement that can get some idea well what is happened please next line then our idea of statistics is based mainly "
  },
  {
    "startTime": "01:46:02",
    "text": "on well on traceroute oh I forgot to put a debris it\u0027s the rich method but in this case if we use trade route we should use something like a straight route with asurs the the road and the idea is to use quantities for represent each cob the quantities are I our typify but the minimum and maximum time and the quantiles the first the second and the third which is the 25% as 50% and 75% and we propose to use Picchu a greens that can be able to compute quantities online which means that you can do this in in inside the router or inside in computer what you want because you just to put the every every measurement and he can update they take the quantiles and even if you want another kind of quantities like person deals you can do that for for the quantity that you are really interested in next I please well this is the the algorithms that show an example what we are having in our mind we we are sampling during some time window we use some time between two measurements we say if you want to be exhaustive which means explore every every possible path every possible route for every flow of just a single flow and we got destination and the output is the de Qantas and this is very simple just to you got a loop during the time window WB you just perform you advance choose it advanced race route for instance Paris trail routes camper or you want and you collect every measurement and you compute the quartile the quantal for every missions this is all net slide please well we we got some feedback of IPP mailing list we have to incorporate some standard turn for FEC 21 and 19 we have to define discover cost in terms of the "
  },
  {
    "startTime": "01:49:04",
    "text": "RF EC 1122 perhaps an idea more more more complete than that we we need to make a clear parallel lines about what can be can be detected the parallel means for instance for hops which means perhaps the same distance three hops away you get three different eyepiece but then problem with that it\u0027s um some roads can have more links than another okay we have to define this clearly and what parallel means cannot for instance parallel links we can distinguish also about the coverage methods the active and a rhythm what what another method that you want we want to use we want to explicit more how the method can be combined it and also to to highlight the security considerations for instant change changing fields to keep checksum constants normally I\u0027m not to introduce any security problem but we we have to to write down that also in in situ OAM there are several are just to disk to discuss between crude metric and in situ oh I am for instance how what happened with the checksum is happy remove and okay how to deal with that and also more feedback are will come next slide please well with this slide I\u0027m finish if you have some questions will be happy thank you greg Mirsky city first question is have you considered alternate marking method as one of the hybrid methods to instrument the measurements well we probably we can introduce that but my problem with that is that we are interesting to measure every hope of flow normally this this method needs to be assisted with with something in the in the note because with your on your methodology you need to to to have something in in "
  },
  {
    "startTime": "01:52:05",
    "text": "the hop in order to establish this this time this this result is related with run trick time using your your methodology perhap is more oriented to one wave measurements yes but probably we have to to think about how to introduce some kind of 1:1 wave measurements thank you well if you mic on this seems like a really good bilateral conversation to have okay so the two of you should talk to each other and back on it okay and Singapore cuz so I don\u0027t actually see how it works but I\u0027d actually like the two of you to talk about it and then propose something and question is so you pointed out to the challenge of ensuring of correctness of the rowing trip that sorry like you you pointed out to the challenge of ensuring that you\u0027re rounding round-trip path is corroded what\u0027s the last word and go out it basically that you\u0027re crossing the saying they routed yes crossing the same interfaces links who knows okay the similar problem being identified for example in the lag because there are different hashing mechanisms so what they came up is that realized and protocol that pins flows to the particular constituent link so do you see that there is a need to do that to ensure carotid nurse or you think that because there are different policies of doing hashing in a CMP and you may need to play a different game to do that in your measurement well a CMP it\u0027s it\u0027s for the normally for the returning path okay you can use anything before for the forwarding one but normally the the problem arises in the return path yes I know there are different hashes methodologies but normally the poly straight route normally works for the return path true because they try to maintain several fields constant sure "
  },
  {
    "startTime": "01:55:07",
    "text": "sometimes not possible to maintain our tuning but constant and you can get some some problem yes sure it\u0027s not not perfect but we let the idea to to use it the best way to do that okay it depends from on on routers not not on us and that leads to my next question this might be it\u0027s better to look at rounding round trip delay as two one-way delays do measurements as one-way measurements well it depends because I already said to do one-way image measurements you need to give to to get some support in the intermediate hops which is normally it doesn\u0027t exist I perform a lot of trash route around the internet and even if you want if you need to to use IP timestamp option normally is not supported for intermediate routes it\u0027s really hard to get information what you are not you\u0027re not controlling the the intermediate routes the idea of this graph is that you can use this methodology at large in Internet not inside a single domain domain where you you are controlling that and also for one-way measurements you need to synchronize clock which is really hard to do if you don\u0027t have some special [Music] special hardware assisting you I think it\u0027s very interesting to get one way time when way measurements but you need a lot of support for the intermediate hops thank you all right thank you very much and Greg don\u0027t go away so that concludes sort of three chartering and work covered under the reach or during the intention for actually for the previous one is to ask for adoption at some point after the Charter is in because we can do that either on the list before Singapore or in Singapore I presume is that or do you want to do something entirely different with it okay um okay so we\u0027ll do that between now and Singapore if it\u0027s if it\u0027s ready if you guys want to rev one or two more before then just let\u0027s take that to the list all right now we\u0027re going to talk about "
  },
  {
    "startTime": "01:58:09",
    "text": "TM TM plight TM test and you know how we\u0027re going to fix the the ambiguity about these that we\u0027ve had this is actually kind of an externally clocked things I brought this work even though there hadn\u0027t been a whole lot of discussion about this on the list this actually came in from BBF requesting a way to get a port assign\u0027d 40 mm test traffic where the control I understand the BBF application the control is actually happening over to your 69 or something comparable right so it\u0027s like there\u0027s a BB F control plane and then t1 test on the data plane so you need a port for this so you can actually do control with it and this seems like a good opportunity to have the what is T lamp what is T went up test what is - um control it are these separate protocols is T went up light a thing we\u0027re not conversation and figure out how the best way is to get a UDP port assigned to this so Greg I think you have two presentations on this and then al has one and we\u0027re gonna have a bit of discussion yeah okay okay so so you then Al than you alright okay let\u0027s do it that way this is just a very quick update what this drug is about as grind pointed out there is interest on have allocated port that can be used as a reflector port in t1 test or at least in the version of t1 test that is not controlled by not instantiated by t1 control protocol we had a discussion in the round in Chicago and there was a great discovery made in Chicago that when T womp-womp and t1 protocols went through Ayana processing both received not only tcp ports for their control protocols but were allocated the same number from the UDP port range and they were accordingly assigned to all WAMP control and t1 control so we changed request for allocation to port reallocation to take these ports that being allocated for control protocols and allocate them to test protocols respectively or one test protocol and t1 test protocol so in our draft we\u0027ll only "
  },
  {
    "startTime": "02:01:11",
    "text": "talk about t1 control so this is a capture what we\u0027re proposing the port 862 tcp is used for t1 control protocol and it was allocated a UDP 862 and assigned to t1 protocol so the recommendation is to reassign to t1 test protocol as T WAMP receiver reflector port and use it as default port in t1 test so effectively this is all what this proposal does Arielle may you have a similar proposal it\u0027s actually my proposal ok that\u0027s not my slides though that isn\u0027t either that looks good let\u0027s go ok so controlling T web test based measurements using alternative means is an idea and it\u0027s a good idea I think t lamplight also suggested this idea but we\u0027ll talk about that more in a minute allocating a port for tia when test would help obviously and that\u0027s this precise request from BBF so I proposed this reallocation solution in Chicago in discussion at least with three or four different folks and then we also had this question about what is T Wham that came up in the meeting so I decided let\u0027s write a draft or I\u0027ll write a draft that solves all the questions that emerged in Chicago and answers the questions I think in the in the best way so we don\u0027t have an ability to negotiate the use of a template without the control protocol and that was a key consideration and whitie went late got moved to an appendix it was actually Lars Gertz ad comments that caused that to happen and further we we actually had to reinforce that because t want light which only mentions the test protocol and has proprietary means for other communication it basically has no way to communicate the required keys in order to operate in a secure mode and so it had to be sort of relegated to this appendix and as we know it\u0027s mandatory for all the protocols in ITF to have sort of mandatory to implement security features so that\u0027s kind of the background and I\u0027ve got more detail on "
  },
  {
    "startTime": "02:04:12",
    "text": "the draft and especially links to the messages that that discusses and ad comments and so forth that resulted in this lineage but that\u0027s why it\u0027s a very simplistic requirement for the both the control protocol and the test protocol in O amp and T lamp to be together so let\u0027s talk about that but first of all we\u0027re going to recall RFC 77 99 we had to go back beginning in Hawaii and define what active and passive and the new form of measurements which were very glad we define now the hybrid type 1 type 2 and spatial it was very good and very important to have an RFC that defined things clearly for our work and why do we need to do that because we\u0027re a standards group we have to have definitions of terms that we can refer to unambiguously and when we don\u0027t have those we can use the dictionary the dictionary is usually pretty good too we can\u0027t define every word in the English dictionary here so let\u0027s let\u0027s not waste our time with that so for have in order to have unambiguous terms in om panty WAMP we have to consider the text that\u0027s there so L WAMP actually that\u0027s an important word here it actually consists of two interrelated protocols om control and om tests and when you look at the dictionary definition of consists it\u0027s very explicit it\u0027s made up of composed of and there\u0027s no ambiguity here it\u0027s to two protocols so the oh way up control and when tests are defined in sections three and four and we\u0027ve got a very similar section sentence in T wimp it consists of two interrelated protocols again and it refers back to the Oh wimp definition and remember neither of these documents standards track Oh amp and standards track TM they would not have gone through the iesg successfully but they didn\u0027t have both the control and the test protocol as mandatory points so what is TM polite it\u0027s basically an idea it\u0027s not this light bulb necessarily but of that sort it could be the point is that T WAMP light is really just an idea it\u0027s an informative appendix it gave the possibility for other forms of control but it\u0027s just some information there\u0027s not enough information they\u0027re done of detail for anyone to claim compatibility with t way of life there\u0027s too many details left wide open and so a rigorously specified set of protocols that reuse T web test truly need a new name BBF has our own spec number so there\u0027s no ambiguity there I think that will work fine but if we work on things here we need a different name other than T went light as well so in my proposal "
  },
  {
    "startTime": "02:07:17",
    "text": "we do what I said in Chicago and we do it for both o WAMP and T when we basically take this is the UDP assignment and it used to be control now it\u0027s test and I\u0027ve been thinking about this for a long time in fact when I when I wrote the I Anna section 40 Wham I really just followed what they had done in Owens and it wasn\u0027t the right thing to do because the control protocol is TCP only and the test protocol is UDP only so if we were gonna sign a port it should have been 40 wins 14 want test to know when test so I\u0027m fixing my own mistake how about letting me do that so here\u0027s the proposal we clarify the names of our protocols for the industry standards Traco WAMP is a two protocol suite standards track t win is a two protocol suite we reallocate the well-known ports that\u0027s the simplest solution here shouldn\u0027t gonna any worry about that and also let\u0027s take a let\u0027s take a why worried approach to what we do with the what we what we let the implementations do with these ports it would be pretty easy to try to specify something but you know although all the standards track tyo implementations are out there doing what they wanted to do without this help it\u0027s the new protocols that take the benefit so let\u0027s let\u0027s let those guys specify the specifications to keep themselves from shooting themselves in the foot by having this one well no port maybe multiple tests trying to contact that loan then port that\u0027s that\u0027s a potential problem so that\u0027s it that\u0027s why I proposed do we want to discuss those two are gonna have like yes like char \u0027m as a shadow room do I brought huh I think what you\u0027re saying is that the light version does not have the control protocol that\u0027s what it is that\u0027s right and you\u0027re saying that won\u0027t be the t vamp that\u0027s what it\u0027s definitely not t1 so it\u0027s like Oh MPLS also they used to say you must have a leafy or RSVP and then eventually so you can configure it you can you can what you can\u0027t configure it you know like oh so so things things things change but we should we should if the if the implementation changes yeah yeah that\u0027s right that\u0027s right so they changed the name that\u0027s the that\u0027s what I\u0027m that\u0027s what I\u0027m suggesting we need to do here well I can point that basically we do have yang model for static MPLS and it still would not be LSD because and there was the fears a little bit different yes so it\u0027s yeah you basically have Sdn environment and you don\u0027t have a dynamic distributed protocol so it\u0027s a little bit different paradigm so if we can agree that tea "
  },
  {
    "startTime": "02:10:18",
    "text": "womp uses distributed control plane protocol and uses t1 test protocol and then we can discuss whether we work on something which is using Sdn control environment and then we talk about test plane separately so I\u0027m not sure I understood what you said Gregg with respect to the standardized terminology when you said a distributed control plane protocol what are you referring to in my view what t1 control is so the t1 control is is distributed control plane similar to LDP you RSVP which is does label signaling okay to instantiate MPLS LSP but at the same time now we are developing data models that allow that to do without LDP RSVP from the same Sdn controller so I think you\u0027re agreeing with my definitions that yeah I\u0027m perfectly fine that basically we can say that T WAMP consists of distributed control plane which instantiates test instances but at the same time we can start a discussion on Sdn environment how it works there and and something and and and let\u0027s start that discussion with a new name yeah a new categorization of this work I think that\u0027s fine I think that\u0027s that\u0027s the distinction I\u0027m really looking for simple two-way active measurement protocol stamp yes then yeah and if we\u0027re done it we\u0027re done if we adopt my draft so can you can you briefly summarize the differences between your two drafts ami I think okay in my understanding of our draft is the difference is that it addresses or womp right which is good proactive measure I agree with it and then it clarifies the terminology which is fine too so we can I think that will be easy to merge the two drafts and because I don\u0027t see anything that you know questionable in Al\u0027s work and we have some security considerations section I think that might be useful too so can we merge the two drafts appoint the two of you editors on a working group rather this dry and just call for adoption yeah up and I\u0027ll be glad to take the first steps to do that okay I think well your new section three and the security considerations don\u0027t jump the gun yet I\u0027ll throw those in the gun yeah we actually have to call for adoption oh yeah yeah we\u0027re anything wrong well I I\u0027m sure Greg and I knew what we were getting about so yeah okay cool so you guys are clear on what the thing is if the hum goes through right yeah so just "
  },
  {
    "startTime": "02:13:18",
    "text": "just say it\u0027s section three and security come come in - yep so the home is on to adopt these two drafts as the basis mainly using the approach in this draft merged with the two of you as editors right on a working group draft to do definition of stamp or whatever we don\u0027t have to hum about the name no that\u0027s not a matter of this and allocation of ports for it all in favor of that adoption please hum now all opposed that adoption please hum now that seems pretty clear to me let the record show um crickets okay that\u0027s done we\u0027ll take that to the list please begin work and now Greg is going to present the stamp yang data model okay so let\u0027s keep in mind we\u0027re talking about stamp again so this is what we\u0027re talking about it what I think that we kind of converging agreeing we have configuration client as the environment that talks to session sender and session reflector of the same tira of the same stamp test session correct that okay so what were the changes we we have two coffers joined us and we modified some of extended some of their metrics calculation back into a statistic percentile percentiles the three percentiles that can be programmed by default they\u0027re ninety five ninety nine and ninety nine point nine they defined as a floaties with the two decimals so basically it could be not ninety nine point nine but it could be ninety nine point ninety eight for example but the same person tile applicable to all measurements to one-way near and far delay in the round trip and to one-way near and far and round trip delay variation we had some discussions whether it\u0027s flexible enough and that we appreciate the consideration and the feedback whether the same person tiles "
  },
  {
    "startTime": "02:16:20",
    "text": "to be reported for all these metrics or there\u0027s some use case where you have you want to have a different person to house reported for different performance metrics and DCP handling mode so this is these are some examples of the changes being applied I just don\u0027t want to read them out loud you can look at the materials and being uploaded or just run diff between version seven and nine you can skip version eight so periodic testing mode for session Center as we I think they discussed in back in Chicago we differentiate two test modes continuous and periodic in continuous the test packets being generated continuously and then operator can define the peer of calculating metrics in theoretic testing mode each text test session has certain time it runs and then it seeds and after certain time out period all their packets all information being collected and the metrics calculated but in periodic mode this can go in infinite indefinitely so basically you can repeat the same test in its duration indefinitely in our view an hour and saying that it might produce a little bit different metrics because for example in continuous mode we stop at a certain time and we don\u0027t wait for the packets that might be severely delayed or it\u0027s like out of order delivery in periodic testing modes this packets more likely to be accounted for because you have a timeout period for your test session associated so that\u0027s the difference so the packet was statistics we added was ratio and burst and maximum and burst minimum metrics percentile I already mentioned that we have three levels that can be configured and that these three levels who will be reported if they\u0027re configured if they\u0027re non zero they will be reported for one-way near-far and delay in deliberation so DCP handling mode being defined because there are some implementations that just merely take a DCP value of received test packet and put it in the reflected packet or there are some implementations that allow you to configure explicit value for the "
  },
  {
    "startTime": "02:19:22",
    "text": "reflector to use for the test session so now steps now we\u0027ll work on updating the document with a new terminology and refer to the stamp as a stamp data model and we are looking to start work on supporting our FC 7750 which is DCP monitoring that\u0027s a functionality that reflector copies received DCP value and reports it back in a payload in our discussion that been kind of very interesting especially for mobile backhaul because there\u0027s in the multi service environment many cases when the ECP mapping was confused and that caused severe problems and that gets dropped on the wrong service because it\u0027s being mapped to the or DHCP and after we do that or somewhere in between after we please change the new terminology stamp world like working group to consider adoption any comments in this draft I am the vibrato I\u0027m not related to your draft in general we have a problem measuring the average no so I was I wanted to see if the has anybody worked or has anybody proposed doing a running average or weighted average in certain normal average good to do the average you have to you know have all the numbers and then add them up and then divide by the number of packets you have received to get the average which is difficult to do or you need a lot of memory for that so far actually yeah on a matter of average I can say for example for alternate marking method is good measuring average actually because it does very easily so has anybody proposed any metrics like a rough what I call it running average weighted average it\u0027s like double you read in you know queueing given you do the queue seems like a comment on the on the registry draft here comes el there\u0027s a there\u0027s a kind of a running average in the RTP jitter evaluation that\u0027s um I mean if you have you looked at that show alright so difficult is because if you have too many flows let\u0027s say I have I don\u0027t know 10k flows I have to first of all a big in the chip I should have a big memory for so I had to count those number of "
  },
  {
    "startTime": "02:22:24",
    "text": "you know you need a counter for add and you also need the accumulator for all the add them up all of them together which is a big number so instead of all of that I can just have it I don\u0027t know like 16-bit or 32-bit so running average this much cheaper no no yeah we\u0027re running out of time yeah we\u0027re running out of time and this is yeah this do you take this offline this is an interesting conversation yeah I think you have as a leading offer on alternate marking method what to say but it I I don\u0027t think that it has a very scale threatening problem I think that there might be some thick done to do a good metric but still maintain some reasonable resources cool thank you very much all right welcome to the lightning talk around go fast this phone will beep and then we will all clap go marking me toward the draft concept a new way of thinking about alternate marking meter next the marking metered seems to be applicable just to point point flows because you need the one marking point and you have on to individuate your flows you can you can have your counting points but now the idea is to generalize this methodology to measure any kind of unicast flows so if you think that there are also some application when you have a lot of flows and a lot of monitoring points the order of magnitude of the mocking meter counters could increase is NaN multiplies by hand for example so we think about methodology in particular for an SDN environment so and to make the performance monitoring more flexible so next the flow classification as a also tile mentioned in a previous presentation we see that we can identify the flow we want to monitor with some identification fields for example for an AP flow we need the IP source at the destination transport products whose port destination port and COSO service if you want to make a class of servic based the performance monitor and to create the flow without a net marking meter you have to identify your flow that will be that have to be a point-to-point flow because you have to recognize your flow along your path and your counter has to be coherent currents "
  },
  {
    "startTime": "02:25:26",
    "text": "on along your path with multi-point alternate marking you can enable the performance monitoring without any constraint about the identification field so the type of the kind of flow that you can monitor in next slide are very general so point to multi-point to multi-point to point flow and also in general multi-point to multi-point flow next how multi-point marking the first thing is we have to build a graph so we have our production network we haven\u0027t identified our nodes of the graph that are the monitoring points the measurement points the link between these measurement points that could be real or also withdrawal and then we build our monitor ad network graph that was composed by into ingress measurement point the egress measurement points and intermediate measurement points next for this monitor ad network we can define the network packet rows so this is always true the packet rows property that packet toss of this monitor and network is the sum of the input packets means the sum of all the output pockets for all output measurement points so this is a very simple rule and we have the formula but these are this rule is just general for all the all these multi-point network next slide we can see how we can recognize the cluster within our monitor ad network and we can defy the concept that is the small s sub Network maintaining the packet rows property for each sub Network so for every we can say that for every complex network for every multi-point to multi-point flow we can always recognize this smaller sub networks that I have this pocket rows product this is also under the study of a collaboration with the university that if we have this complex network we can always recognize this cluster with the graph theory some graph theory consideration some algorithm that we can demonstrate and will be detailed in the next version of the draft so next as well of the packet trust this method can be applied also to the delay okay I can skip also this design but the methodology can be applied on this channel so just just last words nice so the idea is that for example you can see the potentiality of these methodology because if you if you think about a nice the oriented and Sdn oriented Network a "
  },
  {
    "startTime": "02:28:28",
    "text": "controller for example can calibrate performance measurement for all the network then can in case of problem in case of packet loss in case of height delay can recognize the cluster and cane detail with the by changing the the filter criteria or our flow can recognize Makassar and make a per cluster or in case of needed more detail at a flow performance monitoring so I suggest to also read the draft of tal and in the next version our idea is to detail more about the cluster algorithm calculation and more detail about the also delay measurement real quick Thank You Giuseppe al Merton suggests to take a look at RFC 56:44 which has some of the metrics I think you\u0027re trying now to define this for spatial and multi-party metrics okay thank you so I\u0027m going to take the challenge and do this really quickly my name is Tomas rahi and this is joint work with karma Josette the morrow Mack Bureau and Greg okay so this draft has been around for a while but it has a new title and a new scope and basically the new scope of this draft is it does two things one is to define new alternate marking methods which are compact that is they require either one bit per packet or 0 bits per packet the other thing we do is we summarize all the existing and new methods for alternate marking we compare the pros and cons and the trade-offs between them and the idea is that if you\u0027re designing a network protocol and you\u0027re going to use alternate marking for example an MPLS nsh beer you\u0027ll be able to use this comparison and trade off to choose which alternate marking method is best for you so I\u0027m going to skip ahead now because of the short time I\u0027m skip to the summary so this draft basically summarizes all the alternate marking methods including the two new marking methods which are described here that use only a single bit and some of the methods that use zero bits per packet Marvel is going to demo this week actually tomorrow in the bits and bytes a demo of alternate marking using multiplex marking one bits per packet and actually a very cool method is used there called time flip so please come to our booth and see how it works now basically if you\u0027ve read the alternate marking draft which has past working group last fall recently you should probably read this draft as well and you "
  },
  {
    "startTime": "02:31:28",
    "text": "should probably have an opinion about it if it even if you haven\u0027t read actually if you haven\u0027t read the alternate marking draft you should definitely read this draft and we do expect to get comments and feedback about this even comments like this is not useful or this is not interesting can also help us so any feedback would be welcome here thank you thank you very much arm that concludes the IP p.m. meeting at IETF 99 we will see you in Singapore apologies to those on the lightning talk Heuer that we did not get to bring into cue so thanks very much and we\u0027ll see you on the list [Music] you "
  }
]