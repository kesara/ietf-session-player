[
  {
    "startTime": "00:01:34",
    "text": "oh good morning people there maybe it\u0027s good there\u0027s a little bit later in the week but it\u0027s a little sparse and there\u0027s a couple of speakers not here so maybe we\u0027ll wait another a couple minutes there he uploaded his wattage at 2:54 am so let me see must have been on some level "
  },
  {
    "startTime": "00:05:02",
    "text": "okay okay so we\u0027ll go ahead and get started here this is the table or Babel working group depending on what you feel like I\u0027m not Elise lake with whoa a co-chair either co-chair of Russ white he\u0027s not here he we originally an English scheduled yesterday when they so he was planning to be here but he made arrangements to leave either this morning or last night I\u0027m not sure so when we got rescheduled for today he was not here so well what is that note well probably you\u0027ve seen this before or would you read it we\u0027re operating under the IETF IPR rules if you make any contributions including saying anything during a meeting you need to declare any IPR you know about that hasn\u0027t already been declared and there\u0027s a bunch of other stuff here too you should look at so why wasn\u0027t this surely there\u0027s a mode of this where it will age I thought that mode we should be correct yeah oh okay okay thank you doctor people should review documents if they want their talk in to be reviewed and that\u0027s what improves the quality of documents is the reviews and hopefully the resolution of the comments made during the reviews so it still isn\u0027t in a mode where it automatically goes from one screen to the next okay I am not sure what do you mean if you mean the little the four up right down left and right arrows that\u0027s the only thing I\u0027ve used I haven\u0027t scrolled at all during this I\u0027m hitting the down arrow right left and right oh right somehow that doesn\u0027t seem logical to me but anyway moving right "
  },
  {
    "startTime": "00:08:03",
    "text": "along agenda we have an agenda so we should bash on it if anybody wants to make any change the plan is talked a bit about our status of milestones and Jerez which is I think there\u0027s good news there and then presentations on changes to available bubble h mac r TT based routing information model and the yang model and we\u0027ll wrap it all up anybody wish to make any changes so it\u0027s just one note the model is at the yang model this is now I have a group document published yes it\u0027s Charlie\u0027s just me it is I have tricked it everywhere else I\u0027m pretty sure he died not too surprisingly I do the slides for each meeting by editing the slides for the previous meeting and I failed to change it here it\u0027s draft IETF novel yang model it is a working group draft okay no requests for changes so we\u0027re now that\u0027s right there document status so we actually have a nifty kind of like sort of cohesive set of four documents with publication requested the applicability the two security crafts DTLS and HVAC and RFC 6120 six bits so it seems hopefully that package will advance we do have three working groups including wrapped IETF babble yang model which it\u0027s correct here the and the source specific end information model drafts which are in working group last call are there related drafts there\u0027s the home net babble profile which is in the RFC editor\u0027s q in miss ref state means it\u0027s waiting on normative references and the to normative references it\u0027s waiting on our RFC 6120 six bits and the source specific draft and then there\u0027s the doughlas fable RTT extension graft and this slide also shows the previous set of three experimental grafts so we just moved the milestone of submission of RFC 6120 six bits to the IES g RT to our ad to be more specific from the to be done to the current ones were you know kind of behind relative to the actual dates on the current milestones but that\u0027s we are making progress I believe on all fronts here the management draft the last one is is intended to me refer to the yang draft in my opinion so that\u0027s kind of the status of things I think I\u0027ll wait till "
  },
  {
    "startTime": "00:11:06",
    "text": "after the presentations or there were a couple of working group actions concerning adoption and last call that are I said would go through this meeting without I think I\u0027ll do things related to those at the end of the meetings or so any questions or comments on that I guess not then we will proceed with the agenda and with Julia\u0027s presentations let\u0027s see oh boy how do I get to the next thing here that\u0027s not what I want a break love I can\u0027t align all I say if it\u0027s taking a while okay okay okay uh and you would you like a control device I can do it for you so hello I\u0027m Julia scrub Oh check and this thing over there is my name and if you\u0027re ever wondering why I have so many strange consonants that\u0027s because it\u0027s written in the Polish spelling system which dates from the Middle Ages now the checks over here used to have a very similar writing system but then in the early 17th century there was a great reformer Covey on who\u0027s who redesigned the writing system to make it sensible so if you ever look at my name please use it as a cautionary tale about what happens when you come to ITF with an already deployed protocol and are too concerned that ever backwards-compatibility next please okay so last summer together with things online and the Veronica kodiak we set about to design a authentication method in for Babel that "
  },
  {
    "startTime": "00:14:07",
    "text": "would be as simple and as comprehensible as possible so I know nothing about cryptography and the design criterion was something that I could understand okay that means no DTLS no complicated libraries whose security properties our difficult understanding requires some knowledge and so it ended up by being a and it ended up being based on the work on a number of people so it was based on some work that had been done by Denis of Shenko in RFC seven two nine eight and we had a lot of in good and in particular so I\u0027ve tried to be exhaustive in the acknowledgements but so here I will only mention Marcus Stenberg who gave us some very important ideas because some properties and we ended up you know we did the opposite of what happens usually usually you have ambitious plans and you end up realizing it\u0027s difficult and so you scale them down and in this case actually we were expecting to do and that turned out pretty well we got a protocol that protects both unicast and multicast so remember that in Babel you have both unicast and multicast packets depending on the pendulum well various details of the protocol it\u0027s not vulnerable to replay it\u0027s reasonably easy to implement it been actually reimplemented by Toki and the properties that make it easy to implement are that we don\u0027t require the global clock there is no global counter in the network and there is no persistent storage so barbara was telling me at the time well why are you trying to avoid persistent storage there\u0027s no such thing as a Rooter with no persistent storage well the problem is that persistent storage is very difficult to do right okay depending on the hardware you\u0027re on you might have a hard disk you might have an SSD you might have some proprietary NVRAM and trying to access it transactionally is going to be very difficult so i\u0027ve preferred to sweep the problem out under the rug by not assuming any persistent storage it says algorithm agility there are a few parameters you can change depending on what your needs are next please and what we did was that we did everything on the mailing list because I didn\u0027t see a competent so the two ladies our cryptography student they understand cryptography they don\u0027t under they didn\u0027t necessarily understand route routing protocols at the time as to myself I know apps and you absolutely nothing about cryptography and so we did everything in the open on the mailing list except for two things that were done more recently and that I\u0027m going to tell me about which were mentioned on the mailing list but didn\u0027t really have a lot of discussion I hope they will be non-controversial we changed the mandatory to implement nack algorithms so now what it says is that you must implement sha-256 and you should implement lake 2s and that there is an "
  },
  {
    "startTime": "00:17:10",
    "text": "additional requirement you must discard your neighbour cryptographic state after a bounded amount of time so the original RFC seven to nine by that done by then had to mandatory to implement algorithms they were Shaolin and ripe in the 160 now I think that\u0027s fine but I was told that Shaolin is not recommended in new protocols and one person who does understand cryptography told me that try candy 160 is somewhat niche so in the latest version of the draft we say that you must implement sha-256 you should implement like 2s and the intent is that those are most must accept that you\u0027ve written should in the draft in case you have some very good reason not to implement like 2\u0027s if you have no good reason to implement like 2\u0027s please implement both and we implement both in both babble D and Bert next please look I\u0027ll tell you the whole truth the hash function just doesn\u0027t matter so first of all we\u0027re only using the hash function for authentication so if there is a first preimage attack that\u0027s something difficult I\u0027m not sure what it is that I\u0027m told it\u0027s something difficult but then we are threatened but we are not threatened by collision attacks if somebody manages to do a collision attack then we are not threatened by that so any hash function you may conceive for its strong enough according to my computations and I\u0027m not a cryptographer but according to my back of the envelope computations md5 would be strong enough MD 4 is too weak ok so anything you use reasonably if you have a reasonable reaching interval will be strong enough and you\u0027re only hashing the control packets so unless you run in Babel on an abacus then any hash function will be fast enough so really it doesn\u0027t matter sha 256 is clearly overkill for what we are doing but even that will be fast enough so it\u0027s fine next please however some people are concerned about slow software routers like the things you get in your home with no hardware assists for sure 200 56 and token they suggested Blake to s I\u0027ve done my homework I\u0027ve tried to find out what is uh what is the world like to us actually I asked Paulo Xavier to come I\u0027m grateful to do my homework for me and what Paul have been telling me is that it\u0027s blazingly fast and software it has 128 bit lengths it integrates keying so you don\u0027t need to hash over the result of hashing because the King is integrating the protocol you don\u0027t need the H Mack construction and the issue is it which is the reason why it was rejected as shastri is that it\u0027s based "
  },
  {
    "startTime": "00:20:12",
    "text": "on very similar principles as char 256 and so if sha 256 is broke and most probably like 2\u0027s will be broken too which should not be a problem for us because even if it\u0027s broken it will still be strong enough for our needs next please ok so that\u0027s the first thing the change in the mandatory to implement hash algorithm the other change is that we\u0027ve added some protection against delayed packets so babel h mac is invulnerable to replay if a packet has been used once you will not manage to use the same packet again it\u0027s also involved to reordering but it is not what it is vulnerable to is packets being delayed so if a packet is in the right order it can be delayed by arbitrary amounts of time now if the attacker is at a network switch it might be able to block packets and then send them later we don\u0027t know any attack that could be against Babel that could be using delayed packets but the notion that there are packets that have been sent identified and they\u0027re replayed and they are intercepted and then sent say 2 hours later is something that makes us nervous so we\u0027ve added next please so one property of the protocol is that a node may at any time discard its perkier cryptographic State ok so you can say ok forget anything about the exchange I\u0027ve made with a given fear and then there is a mechanoid called the challenge mechanism that will create a new cryptographic state at the cost of one RTT of lost packets and the node can do that at any time and what we added is that now a node must we discard its cryptographic state after a bound at time with no correctly authenticated packet okay so we don\u0027t give any figures for the bound we say you must ensure that there is a bound and the time on which you keep cryptographic state for somebody who\u0027s not speaking to you okay and we are not specifying the mechanism but we do give implementation advice next please so we\u0027ve made it to non-controversial changes to the protocol and like this random in this talk thank you for attention Michael Abram just a clarification so you\u0027re doing this as an offset in time from now and they don\u0027t have to have synchronized clocks at all there is no requirement for the different devices to agree on what I meant okay so we have we have surprisingly weak requirements I\u0027m still surprised we managed to do that and if you\u0027re wondering where the catch is "
  },
  {
    "startTime": "00:23:12",
    "text": "there\u0027s overhead in the packet there is basically that costs us eight bytes per packet have overhead yeah just that\u0027s a typical thing that cryptography people don\u0027t might realize that a lot of these things don\u0027t have an real-time clock that is battery backed up and they might come up with any time whatsoever and I see this all the time I mention there this ability to discard the cryptographic state scheme is really good because that might happen like because you crashed or something so so you know any other questions or comments on this presentation see so if I go okay the next one is Glade based grouting okay hello I\u0027m Julia scrub attract did they mention the spelling of my name next so I\u0027d like to tell you you know can you grow really old you start taking the things you did when you were younger and trying to recycle them and so today I\u0027m going to tell you about something we did four years ago and that I\u0027ve just asked a for adoption by this working group now and that\u0027s joint work with Betty Jean glaze so there is a company in Paris they\u0027re called Nick CD and next idea running a distributed cloud system so they have data centers all over the place and what they are trying to do is to build a distributed cloud out of all of those data centers and their original plan was to run over the public ipv6 infrastructure and that failed horribly the problem is that the public ipv6 infrastructure is not reliable enough and if you have enough nodes then the probability that anyone can speak to anyone else is basically zero and so they came up to me and I said well why didn\u0027t you put a bunch of tunnels and run some dynamic routing protocol over the tunnels okay so we designed over a restaurant napkin an algorithm that would allow us to have enough tunnels so that the network remains connected and then they told me okay that\u0027s what routing protocol shall we use I said it doesn\u0027t matter it doesn\u0027t matter because since you\u0027ve separated the tunneling bits from the routing bit you\u0027ll be able to change in the future so why don\u0027t you try that oh they said cool and for eight "
  },
  {
    "startTime": "00:26:13",
    "text": "years now they have been running Babel and they\u0027ve had very good experiences with them and wished they\u0027d started with normal an extended Babel and they were very happy as long as all of their data centers were in France and one day they opened they set up a new data center in Tokyo so here\u0027s an example topology and that\u0027s an actual problem that they saw so that\u0027s a little bit an opposite of H Mak H Mac is something that we did because we wanted to do something clean here we were trying to solve an actual problem that real people have and in this topology what happens when the leading marks a link breaks the tunnel has broken for some reason because some ISP have decided that it\u0027s cheaper to break connectivity and violate their SLA rather than pay for transit and you have no connectivity between liliane masse well babbles is two hops between through Paris and two hops through Tokyo and so non-deterministically one half of the time it will decide to route the package from limb to Marseilles through Tokyo we have nothing against Tokyo but clearly routing packets from Linton are safe through Tokyo is a bad idea next please so my first suggestion the world\u0027s why don\u0027t you put a GPS in every router and then we can use the geographical distance for breaking ties in our routing and they said that\u0027s out of the question that\u0027s out of the question and what they told me was that the problem was not the price of the GPS the problem is the human being who is going to make sure that all of those GTS are running at any given time so you\u0027re introducing too much failure modes you\u0027re introducing unusual things in the data center they said that\u0027s out of the question so we decided to measure the two-way delay the rtt and derive a metric from that so before somebody comes up and tells me about TCP Vegas or led that or bbr or is it B RR v BR okay all of those things that measure one-way delay I know it\u0027s possible to measure one-way delay but it\u0027s more fragile than RT t and it\u0027s more difficult to implement and remember that here we are not doing a congestion control algorithm what we\u0027re doing here is a routing protocol the goal of the routing protocol is to select the best routes so you are not to accurately model reality as long as you have managed to find the best route you\u0027ve won even if your modeling of reality is somewhat coarse and RTT appears to be good enough at least for this application and the problem is that the natural way to measure RTT basically pink requires asymmetric there\u0027s a client and a server and synchronous interaction you have to answer the ping as fast as possible now babble is a symmetric protocol "
  },
  {
    "startTime": "00:29:13",
    "text": "incident a synchronous protocol nowhere in Bayville does it say you have to reply straight away there are times where it says you must send a packet in a timely manner but at no point do you have to react in an immediate and the other problem is that using RTT as input the routing metric causes a negative feedback loop which I\u0027m going to describe which might lead to persistent oscillations next please so RT t RT T is on the diagram the distance between T 0 and T and the natural way of measuring it is to send a packet from a client or server and have the server reply as quickly as possible so first that\u0027s that\u0027s asymmetric that\u0027s something we could work around actually there\u0027s no big deal with doing symmetric asymmetric stuff within babble but the other problem is that when the server replies the thing it must answer Punk as quickly as possible and the delay you have between the ping and the pound is what is going to kill your accuracy and now because in babble you are allowed to reply later you might have buffered some stuff to be sent later and here you have tricky issues of do I flash everything right now and cause congestion do i rear their packets and cause pathology due to packet reordering ok it look like a little bit tricky to implement next please and so what we decided to do was to use Mills algorithm so Mills algorithm was done by Mills and it was originally implemented in hello which was the routing protocol used by the SAS for people who still remember the fast also either people who are old enough to remember fuzzball or people who like me enjoy doing protocol archaeology and so there\u0027s actually a TLV in babel that is named in the honor of the hello routing protocol and the same algorithm has been used later still by Mills in something that all of you are using which is NTP so the idea of Mills algorithm is that you do a symmetric asynchronous paper you send your packets at any time you want and here I\u0027m concentrating on the second packet the one that goes at time T T from the right to the left and this packet is not just a silly pink packet with no data it contains three time stamps which are teo which is copied from the previous packet in the other direction which is called the origin timestamp TR which is the time at which we received the previous packet which is there called the reference timestamp and it also contains the transmit timestamp which is the time we\u0027re sending this "
  },
  {
    "startTime": "00:32:14",
    "text": "packet okay I\u0027m now be careful tio and T are according to the left peers clock and TTT r TT are according to the right Pierce clock and we don\u0027t assume that the clocks are synchronized they might have an arbitrary offset between them and then once the guy on the Left receives the packet it confused at a time stamp set with T the time at which has received it and computes t minus T Oh 12 times on the Left T t minus TR both times on the right makes the difference between the two and that gives you an estimate of the RTT and that\u0027s symmetric that\u0027s asynchronous that doesn\u0027t require clocks to be synchronized and the reasons on the other hand are something you must do you must compute the timestamp at which you send the packet the TT as late as possible just before you send the packet not on your buffer and same thing as soon as you receive a packet before you even parse it you timestamp it and that\u0027s what your accuracy is going to depend on next please so we wanted to do Mills algorithm Babel and what we\u0027ve done was to encode the timestamps and sub GL DS and the transmission timestamp so the time at which the packet is sent that\u0027s a property of the packet so we\u0027ve put it in the hello and that may have been a mistake perhaps it should have been simply a TLV rather than a sub TLD of hello and the other property and the other other to timestamp the origin and reference those are copied from the latest packet you received from the peer so they are specific to a given peer and they are sold as sub charities of the ihe govt and originally we started with a 10 millisecond granularity and then dave told us what he thought about it you know Dave you know how he tells you that he disagrees like seven times in a row okay until you get it and I wasn\u0027t sure but my co-author batiste said Luke is absolutely right it costs us four extra bytes and we never know when the extra precision might come up to become out to be useful and so the granularity is one microsecond next leaf okay no secrets here are 32 bits rolls around every 36 years or is it 72 I\u0027m not sure about the sign but okay no particular issues here next please okay so Mills algorithm is going to give you some RTT samples and that\u0027s a noisy signal and the signal that is not immediately useful for a routine metric remember we are doing a routing protocol here anything that\u0027s not about selecting the right route is just noise we\u0027re not "
  },
  {
    "startTime": "00:35:16",
    "text": "in I\u0027m a bit slow here Michael Abraham\u0027s again you said microseconds so you\u0027re counting microseconds so you\u0027re 32 bits 32 bit counter in your counting microseconds nope yeah okay so what was the 32 I said something stupid about the year about rolling over yes I did I did I will right so so it rolls over much you have to to raise to the 32 microseconds that\u0027s right yes and that would be thirty-two thousand seconds it\u0027s four billion in / Our Lady\u0027s four thousand seconds yeah it\u0027s a bone it\u0027s an hour and course unless you\u0027re going in an interplanetary well I suggest I\u0027d suggest we tackle this problem when we have it yeah sure yeah sure I was completely off so we are assuming here that you send at least a hello every hour okay so you get a bunch some noisy signal but your goal is to select the routes okay and you need to do quite a bit of processing so the RTT sample that you get or a noisy signal you do some basic smoothing over there then that gives you the smoothed RTT and the RTT is a time in milliseconds that\u0027s not a metric in order to get a metric you have to map it to the abstract units that we use for our metrics so you take your link cost the one the normal link cost which mode is the 96 that you have with normal battle and you compute a penalty from the smooth RTG and this penalty is not a linear map from the RTT of how you add the penalty to the link cost from that you derive a metric and here that\u0027s important there is a third mechanism which is hysteresis that\u0027s applied to the metric I\u0027m going to discard all of that next please so the RTT samples we get or a noisy signal so that\u0027s actual data from an actual tunnel between France and Japan and that\u0027s the bad case the good case is actually worse in some ways that\u0027s the good that\u0027s the bad case at the time when the ton the RTT was very not so that\u0027s during the day and what you see is that it oscillates widely between 280 and 320 milliseconds and that you have a lot of outliers and the blue line is the smoothed data and the smooth data is a signal that you can actually use so note the horizontal scale that\u0027s 10 hours of sampling and so what we do is so I think that the actual algorithm you use for smoothing should not matter much you just want a smooth signal but we did "
  },
  {
    "startTime": "00:38:17",
    "text": "not do any real evaluation of what happens when you change your smoothing algorithm so we\u0027ve just stolen the algorithm from TCP the one that\u0027s used for computing the RTT in TCP and the constant alpha where TCP says should be between zero point eight and zero point nine we chose a zero point eight three six and first person who works at Y I\u0027ll be very impressed if you work out why you won\u0027t work at F now you will need at least an envelope next thesis you want the answer it\u0027s easy to compute with integer arithmetic where in doing Taylor\u0027s is some stuff that\u0027s the whole reef okay now so now we have a smooth RTT signal but using RTT for computing geometric colors a feedback loop you know when you were a kid on the highway and it was really hot in the back of the car and the highway was really congested and then the radio would say well there\u0027s nobody on the other Highway and then everyone would move to the other congested so the radio will say hey there\u0027s nothing nobody on the first Highway and everyone would move back was going back on here is that there is a negative feedback loop the more you push traffic over a route the more its RTT increases and therefore the less desirable it becomes and therefore the less traffic you push over it now usually an egg Luke a negative feedback loop is what you like but converges because the more you do something the less you do it but here when we\u0027re in a discrete space either we go to the left or we go to the right the fixed point doesn\u0027t actually exist so you end up oscillating now Babel doesn\u0027t care even in the presence of oscillations Babel will push packets towards the destination according to Luke free pass there\u0027s not much that can be wrong but if you also like between routes you might reorder packets and higher layer protocols do actually care so you need to limit the frequency of oscillations and the insight came from some old paper from the 1980s which was trying to use RTT and link-state protocols and the answer is you want to saturate your metric so instead of mapping RTT to a metric linearly as you would expect what you\u0027re doing is that you have a range below min RTT at which you consider look this route is good this link is good it doesn\u0027t matter how good it is and above and that\u0027s not important the important bit is that above max RTT you consider this link is bad it\u0027s really bad I don\u0027t want to use it if I have any choice and at that "
  },
  {
    "startTime": "00:41:18",
    "text": "point the penalty remains constant and the fact that at some point you stop penalizing high RTT links that this world is going to limit your oscillations and what you want is that this Max Artie T value is well chosen and this that part of the protocol requires manual tuning next please now the saturation bit avoids oscillating between congested links but you might still if you\u0027re in the intermediate range have two routes that have very similar RTT and they are oscillating around a value and you will end up switching turn to apply hysteresis and there are many hysteresis algorithm so I worked out this one so in this one you have in a which is the metric that\u0027s actually announced and there is a second metric which I called the smoothed metric which is basically an exponential average a smooth version of the announced metric so think of MA as being the short-term metric it tells you how good the route is right now and m/s being a history sensitive metric it tells you how lot good this route has been recently and when you switch routes you only switch routes if the new route is better than the old route both short-term and long-term and this and there\u0027s a symmetry between better and worse is what is going to give you hysteresis and hence more stability next please that\u0027s with hysteresis and no smoothing this datum line the pity so this is worst case we constructed a diamond topology in simulation with huge amounts of buffer bloat so buffer bloat is really bad for us because it means that the RTT is very very widely with nothing to break the feedback loop so though those are four bloated routers in a diamond topology measured over 4,500 seconds Michael helped me because I\u0027ll say something stupid again that will be about an hour and a half yes and what you can see is that you have oscillations between the red route and the green route so you\u0027d have to look carefully at the frequency next leaf and now you add the you tune the metric to have a max RTT value that as well chosen is the dashed blue line around hundred and something so what you\u0027re doing is that the links are spending most of the time and they are saturated State and at this point you pick a link the RTT of the link increases because you have buffer bloat so you switch to the other "
  },
  {
    "startTime": "00:44:18",
    "text": "link but the RTT of the rig will only decrease once the buffers have drained and then you have the hysteresis that takes some time to take it into account and supplied after saturation and together between the fact that you\u0027re waiting for the buffers to drain without measuring the RTT because you\u0027re in the saturated range plus the hysteresis bit you end up having oscillations that are order on the order of a minute but the TAS depend on bubble being scheduled along with the data right the firm if you have like type of service prioritization of the routing protocol traffic then this will go then you have no problem then you\u0027re measuring the link RTT without measuring the RTT due to queuing and all of those mechanisms are useless because you\u0027re not going to have the feedback loop so what he\u0027s also talking about running over tunnels and you might not have the fur to say sure for the routing protocol when you\u0027re running over and it\u0027s all over the internet I think you\u0027re looking for deity they really really worst scenario here that\u0027s already drank more so I\u0027ll put it differently perhaps I wasn\u0027t sufficiently clear we don\u0027t want this to happen the feedback loop is a bad thing and it doesn\u0027t happen in practice in practice you\u0027re going to have plenty of throughput okay you\u0027re running over gigabit links okay nobody has ever managed to use a whole gigabit except perhaps David I\u0027m not sure ok Michael - yes so I just want to say about buffer bloat I had to deep load our Giggy you\u0027ve bi-directional offering because when I ran I for single TCP session 100 milliseconds of buffer bloat if I did not deep load it the standard configures ask the router to shape at one gig gigabit per second then the TCP guys have done a wonderful job and TCP will take all the bandwidth and I\u0027ll use a hundred milliseconds of buffering it\u0027s great so the one that came default in the Linux distributions that I was using did this so this is not as silly as it might seem no it\u0027s not silly so basically we are assuming that you run this right okay pathological was it was probably the name that did what I was using for not silly but yeah this is this can actually be a real problem you know what we want is a protocol that those mechanism are not used when your network is working fine what we don\u0027t want is a catastrophic mode of failure when your network happens to trigger this thing okay ideally of course you don\u0027t get the feedback loop in the first place and you have no problem okay is that yeah next please okay I\u0027ll tell you the whole truth we\u0027ve done some really bad science we wanted to have a solution that worked we ended up we had only a few months because that was effects your internship "
  },
  {
    "startTime": "00:47:19",
    "text": "and we did not at the time work out a complete understanding of what\u0027s going on we did an engine engineering job instead of doing a scientific job that is we did manage to get something that works beautiful and that has been working in production for eight years now but we did not actually study all the trade-offs and we don\u0027t fully understand what\u0027s going on so there is one minor issue in the packet format which is that the IH u sub TLD can only be interpreted if the packet contains a hello so remember there are three timestamps and two are carried by the HU because they are per peer and one is carried by the hello so that means that in order to interpret the data in the HU you need to put a hello in every packet so that requires some inter TLV scheduling in Babel and that\u0027s something I really dislike so I wrote it and written an alternative here which is to include the transmit timestamp in each HU but that causes a different problem so remember that you are time stamping the packet as late as possible so what we do is that when we buffer there hu the hello we put a and sub TLV in it at the very last moment we patch the hello with the timestamp and that\u0027s fine because there is only one hello in the packets but there are multiple ih use and if you need to patch it multiple time the implementation will become more complex the other alternative that I didn\u0027t write here ins which I actually like more is to use the timestamp on the hello to you the timestamp in a dedicated timestamp TLV rather than attaching it to the hello that\u0027s something we will need to discuss and we did some Mike Robinson again often or the hellos typical sentences every every four seconds for second by default okay and the minimum value is supported by the protocol is 10 milliseconds and what we did is that we did do evaluating of the interesting bits like why saturating is important but there are some things that were we did not do our job at the end we didn\u0027t evaluate what happens when you change smoothing functions that\u0027s something that doesn\u0027t bother me much because the answer is pretty clear nothing much will happen because this new thing is not important bad things happen in this protocol if max RTT is too large if max RTT is too large you get oscillations in the bad cases and we didn\u0027t do any work on auto-tuning max RTT which should be doable and I think that\u0027s our greatest "
  },
  {
    "startTime": "00:50:21",
    "text": "sin we didn\u0027t fully evaluate the effect of hysteresis and how the hysteresis should be tuned so it\u0027s obvious you need some form of hysteresis but whether we\u0027ve done the right thing that\u0027s not clear at all next please and that is the reason why so what we have here is something that will be beautiful in production we\u0027d like to get it standardized and the packet format I think is something that we understand we understand the trade-offs but in order to make use of it you have to use a bunch of algorithms and those alder is are not fully understood so what I would like to see would be a situation which we managed to standardize the package for and an enormous part of the document just say hey folks that\u0027s how you measure RTT and babble if you need RTT and what you use this RTT for I\u0027d like to avoid standardizing because I don\u0027t think we\u0027re ready to standardize that and just have an informative appendix saying look that\u0027s what we\u0027ve used it for it works pretty well okay you might take inspiration and we would like to do more research about the algorithm that of course no eta for that because if there is always other stuff coming out thank you for attention david\u0027s Knaus e google thanks joyous first point I really supportive of this work and I do think it should happen here I\u0027m really glad that we have one like actually deployed extension like this which really reassures us that the extension mechanism in Babel all works so that\u0027s a great use case that we don\u0027t were shipping something that we know is solid and now a question have you just out of curiosity have you tried running this in babel d running both the one RT the rtt extension and h mac and how does that impact timing it doesn\u0027t work it doesn\u0027t work due to a limitation of the implementation so remember that in order to make this work you need to have a hello together with every i hu so the timestamp will be ignored if an i achieve is spent in a packet that doesn\u0027t have a hello now remember that will DTLS the H Mac now is H Mac we haven\u0027t with DTLS it doesn\u0027t work with H Mac we have it we haven\u0027t done any testing there is no reason it shouldn\u0027t work no incompatibility with H Mac and all right impact the timing because might impact the timing but that\u0027s just one passive hash and over the packet but that\u0027s a cool a good experiment to do yeah and so it might be worth just adding somewhere in the document that it doesn\u0027t work with GG awesome say why because I think that\u0027s that\u0027s the implementation does the implementation "
  },
  {
    "startTime": "00:53:21",
    "text": "that\u0027s not the protocol because nothing pretends it prevents you oh yeah unicast oh because they think you have unicast hellos and you have unscheduled hellos so you don\u0027t even need to do anything complicated you have the unscheduled hellos so now it can work with DTLS over unicast oh cool what maybe explaining how to do that could be a nice of that Dex or something um I\u0027d rather we didn\u0027t explain it until we did it are there any other comments questions so there\u0027s a call for working group adoption that was it I was posted which ends at this meeting and there\u0027s been strong support on the mailing list and no opposition there are anybody in the room that\u0027s supposed to adopting this as a working group draft hearing nobody it is so adopted and all set ask the authors to post the zero-zero version as a working group draft thank you very much by the way if there\u0027s is there anybody who hasn\u0027t signed the blue sheets and maybe I can put their hand up or we could get the blue sheets to them but maybe there everybody has signed the blue sheets okay they don\u0027t have boxes they have X\u0027s that okay so the information model it is in W GLC which means Donald you\u0027re as bad as Aaron oh my god in the Pecha Kucha Aaron was like forwarding my slides before I was done with my twenty seconds and it was so wrong okay where I had to advance the slide right you know get twenty seconds per slide okay so um anyway we have been Mahesh and I have had a great discussion at least I think so um I don\u0027t know how much and we\u0027ve been doing it over on github in my github site where I\u0027ve been trying to keep editors drafts and things like that I have not but I know I promised I would I have not put the updated broadband form data model there I just sort of ran out of time with everything else I was "
  },
  {
    "startTime": "00:56:22",
    "text": "doing this week but um it\u0027s in good shape I had great comments out of broadband form as well so major changes clearly we did some stuff on hmm some stuff on DTLS I put in the statistics and message that we agreed to coming out of Bangkok and there was also some additional discussion on the list that helped me clarify some stuff I thought that was great and the other stuff out of Bangkok I did okay so I\u0027ve got the rest of the slides are about some issues I would really like to get some input on number one do we have the link types registry do we have the right names currently in the registry and is it meaningful to describe what sorts of links it is used for and is there any idea on how extensive the list should be now Julius has previously said this is I think you really only want the main four and then we can leave some room for experimental stuff at this time if they want it Mahesh and I have discussed that in fact now that we understand better that Ethernet isn\u0027t really just Ethernet but it supposedly incorporates everything that\u0027s wired including all of the no new wire protocols like powerline and mocha and things like that we\u0027re really confused and wondering if we should change it back to Wired or Julius so if you look at the Babel the implementation you\u0027re going to have a lot of per length tweaks are you going to use packet loss for computing the metric are you going to use RTT for computing the metric are you going to use split horizon and so on that\u0027s impossible for a normal human being to chip and because of that we have bundled sets of parameters into names that you can give to the actual users who don\u0027t want to understand all of the details so for example wired means no link quality estimation no RTT and you split horizon okay I\u0027m not very keen on inserting things that don\u0027t have clean mappings or clear mappings on to the algorithmic level so my cobraman so instead of inferring these properties don\u0027t you want to model them for those properties instead instead of trying to create it is this going to be used for that don\u0027t you want it there isn\u0027t an eye on a link type list of FDI in a Volvo but if we\u0027re modeling properties here shouldn\u0027t we put the properties in here instead of having you "
  },
  {
    "startTime": "00:59:22",
    "text": "know Ethernet to mean something so in other words maybe under the used for links defined by describe the properties of the links that you use these names for okay I mean if this is the reason why worse the ethernet is because there are table properties then put the properties in there instead oh by making up something in inferring from it okay the question is do we want to be exporting something that makes sense or do we want to be exporting something that the users have a chance of understanding and that\u0027s a difficult call no I think we can meet both actually what I\u0027m hearing is we should not use the term Ethernet that\u0027s really confusing the description should be really about the properties of the types of links and this should be I don\u0027t know maybe the names can be more esoteric to meet the description or to characterize that the grouping of link characteristics Benedict Wong I would agree with that in that for wireless maybe I\u0027m not sure whether Babel is considered over some of the networks but the RSSI kind of thing for why for the standard Wi-Fi and over a cellular network will be very very different okay I think I\u0027ve got a way forward on this and I understand better and we may actually change this from a link type 2a link properties type just so that we get it completely out of the people who are thinking of the Ayana if\u0027 list yeah cool I hope you\u0027ve got that on the the notes I read oh my god well hopefully you know the Medeco recording will work okay hmm DTLS interfaces modeling um had some discussion of additive interfaces oh good Michael\u0027s leaving us nobody said one hour go away okay um now Mahesh and I were discussing and actually I got some input in broadband form that we should actually change the direction of the reference right now I was trying to reference two interfaces from H Mac and DTLS but it\u0027s been suggested that it might really solve a whole lot of issues if we change the direction and from interfaces reference to H Mac and DTLS objects and that would actually match more closely with what Julius was "
  },
  {
    "startTime": "01:02:22",
    "text": "describing on the list as to what you were doing if we do this I still need to consider where to put the global DTLS and H Mac parameters in this decision because I\u0027m pretty sure that like the use of the cached info extension we don\u0027t want that to be kind of a per interface decision it but maybe I don\u0027t know and that would be a useful thing to get feedback on similar to this server certificate type extension and those are the DTLS things and then on the H max side we\u0027ve got whether the verification of received packets is enabled and the question is you know if we move the direction of linkage should these things be considered interface specific or should they be global and nobody\u0027s going to help me answer that are you okay with changing the direction of the reference because it matches more closely with what you described Julius okay so the other question that you noted that Julius nodded yes thank you Julius nodded okay it was not nodding off that was an actual responsive nod yes okay dubious crap attract the question here is whether an security credential refers to an interface or an interface refers to a credential we\u0027re a group of Prudential there is a disagreement between my implementation and information model and they\u0027re trying to work out whether I\u0027m wrong and Barbara\u0027s rights or whether Barbara\u0027s I got confused no we\u0027re not the only one we should agree on the direction of the reference in one way or the other and everybody is saying that we should reference from the interface to this set of potentials and that\u0027s what good that\u0027s what you nodded about and I agree with you completely and that\u0027s what my colleagues at broadband forum said too so it\u0027s like everyone agrees that Barbara is wrong okay okay but now the the other question I really have is about are these other parameters global or can they be associated with the set of credentials okay verification of receive packets that\u0027s clearly you want that to be per link you have a secure router you\u0027re adding a new link there are unsecure Reuters and this link you want to transition the new link you don\u0027t want to disable security and all the other links just because you\u0027ve added a new insecure link okay so on the H Mac it can be associated with a set of credentials that the link points to or I would say "
  },
  {
    "startTime": "01:05:27",
    "text": "it should be associated with the link it\u0027s the interface itself okay so you have a set of credentials it\u0027s on all of your interfaces you\u0027re having a new interface and you\u0027re adding this new interface incrementally so basically these parameters get added up under the interface so just go to the interface for H Mac okay this specific one you\u0027ve quoted which is weather verification of receive a the packets is a name right those get added that goes to the interface okay Mahesh aeternam Donnie um I think we should try to answer the question of which end phase refers to Detailers H Mike object or the other way around is by asking the question do you have one interface that they\u0027re first the multiple VPLS /a track objects or that you can have a given DTLS /eric object being used by multiple interfaces what is the case I think I think a single DTLS can be used by multiple interfaces and that\u0027s highly desirable because we want there to be kind of a default or to be able to use a single for everything yeah the but the other one that Toki did bring up was it would also be desirable to have a single interface be able to point to multiple objects and I think we can have both its and and for H Mac it\u0027s once we pull this global parameter out I think we\u0027re fine I now need to though understand the DTLS whether they the detail s things are global or are they linked specific or your your walk you don\u0027t look convinced I\u0027m sorry so we\u0027ll talk yeah I think it\u0027s hard to do that here but typically you want to have a many-to-many so an interface can have many something and this this thing should have like a name that you reference it by they\u0027ve this credential like an SSH key if you\u0027re doing that or so on you should be the have that flexibility because that always comes up sometimes later I would say that you wouldn\u0027t want to do something like that we\u0027ll get to names later okay so if the DTLS people could kind of think about are these DTLS parameters global or would they be kind of link specific that would be really helpful yeah they\u0027re not gonna answer me today but I want an answer and if you don\u0027t give me an answer I\u0027m going to make a decision okay name for DTLS cert and H Mac key and this is more informative because Mahesh and I have already agreed on this we\u0027re "
  },
  {
    "startTime": "01:08:30",
    "text": "going to be naming these things so that they have a unique key that you can refer to them by because there\u0027s really nothing else to refer to them by you\u0027re not going to refer to a key by its value okay um let\u0027s see so we\u0027ve also taking one step up that was the that was the the this was about the actual certificate and key but one level down we had these objects and some of this yeah where we\u0027re trying to figure out how to refer to these H Mac and DTLS objects that contain keys multiple one or more keys and Mahesh and I had disagree and on where to specify the unique key because in some of my modeling that I do on the broadband form side we have auto-generated things if you don\u0027t specify a unique key so I don\u0027t know need the information model to do something for me necessarily and so I think Mahesh we kind of agreed that you can just specify something in yang if we don\u0027t do anything here does anyone else Oh Julius does have something too so not the hash of the content same white oh my god or even simpler why not use the key as their identifier itself a fingerprint so okay so that goes back to this one this is a specific certificate or a specific key and that\u0027s a human readable name it can be it\u0027s it\u0027s the information model at this level it doesn\u0027t care once you get into a yang data model or broadband form data model they do different things or even if you\u0027re doing some other way of data modeling it those things are going to care but it\u0027s left up to the data modeling mechanism and not dictated by the information model in this case we\u0027re saying that we do need some sort of name we\u0027re not specifying the syntax of the name but it cannot be the exact value of the certificate or of the HMS think I understand three you don\u0027t understand four okay four we\u0027re going to need there is inherent in the information model as currently specified there is nothing you can point to that is a unique key and so what I\u0027m saying is we\u0027re going to leave it up to the data model to figure out what\u0027s the right mechanism within the context of that data model as to how to uniquely identify these entries okay "
  },
  {
    "startTime": "01:11:30",
    "text": "you\u0027ll have to explain that to me offline or over beer it might make more sense of Revere beer is the fine okay I think Mahesh and I are fine and I\u0027m really more concerned with Mahesh than I am with you Julius okay so if you go back just what does unique mean huh because there is this unique is that this thing can only occur at one point in anywhere or was it mean what unique piece so when you\u0027re looking at a set of objects you need to be able to address the object that you want right you know like if you\u0027ve got yeah and so that\u0027s simply what we\u0027re saying is how do you address the object that you want and in all of our other things you know like when we\u0027ve got their interface lifts we have a unique way of identifying the interface we have a unique way of identifying the route according you know to the IP prefix and stuff but when we got to these tables there was nothing and so we\u0027re leaving it up to the data model okay metric parameters oh yeah okay so this is this is how Oh Christian you have something to say is it on the last one oh I\u0027m sorry Ronald I\u0027m sorry yeah I just have to say that I\u0027m failing miserably to capture this discussion because I\u0027m not at all familiar with the information model don\u0027t worry about it yeah I appreciate it and you don\u0027t have to record that either we\u0027re not too short on time yet but we are - is gonna get some fun I\u0027ve only got two more issues and then we\u0027re done um in this one it should be a quick one and this is something that kind of came out just in Mahesh in my recent discussion and so we figured we just toss it out here we have this the the route the calculated metric and the received metric and we previously had input that we have to have one of these but the question that wasn\u0027t clear in my mind is are they mutually exclusive or is it possible to have both of them you really want to have both you want to have both you really want you you must have one but it\u0027s okay to have both for debugging for debugging problems you do want to have those you so you must have one having both as desirable perfect that was quick okay okay so in this this is this is a personal problem this actually didn\u0027t come up with Mahesh and I just wanted "
  },
  {
    "startTime": "01:14:33",
    "text": "well actually it sort of did I just wanted to be absolutely sure that when we reference an interface that it can from our interface list when we reference some other interface where this interface lies it can be at any layer physical layer Mac layer IP layer tunnel IP we don\u0027t care what layer that interface references the lack of people coming to the mic means we don\u0027t care thank you I have my answer so we have right now when I look at the implementations you know they\u0027re referencing something like eath you know Linux ETH one which generally in ETH one has the full IP stack on it it\u0027s really not the specific ethernet layer it\u0027s this thing with all of these IP address stacks on it if we had say in Linux the ability to reference the 100 base T interface would that make sense or are there layers that don\u0027t make sense of interfaces no because babel runs over ipv6 okay which means that you want to be referencing the layer 3 objects exactly my question however and the fact that babble is using lower layer information it\u0027s very carefully designed so it\u0027s only an optimization in that we reference the layer 3 object and if we have access to the layer 1 and 2 thingies we can use it that\u0027s what is fundamental is the layer 3 object ok and I think that answers my question because both yang in broadband form we basically stack our interfaces and so you\u0027ve got you know here\u0027s an ipv6 interface in this ipv6 interface by the way happens to ride on this Mac interface and this Mac interface happens to ride on this physical interface and so you know your interface stack but the question is at what entry point we\u0027re we\u0027re in the stack should you be pointing and you\u0027re saying I need to be pointing for the ipv6 answer I need to know the link local ipv6 SS so I\u0027ve got we\u0027re good we\u0027re good I\u0027ve got my answer thank you and it was not the answer I was going to go for if you hadn\u0027t stood at the mic so it\u0027s a really good thing you got up there so we\u0027re in wgl see additional review would be really great in the meantime we just here just result just about every single one of our issues I think so I\u0027m going to be revving the information model "
  },
  {
    "startTime": "01:17:34",
    "text": "based on this and we\u0027ll do the Yang and the tier 181 and I think we\u0027re in pretty good shape thank you yeah that\u0027s fine No thank you very much so there there is a working group last call but as you there hasn\u0027t actually been much response on the mailing list and there are these issues though that since the documents gonna be read well let\u0027s continue the working group last call next is how do I get out of this name and then the magic one so Julius if you were concerned about the number of Z\u0027s in your name we couldn\u0027t exchange some agencies together all right the status of the document it is of a group document as Donna has already verified we did manage to augment the routing management interface as re RFC which brought us support for addition of Europe the vrf instance is something that is now available for us to also add I haven\u0027t quite done that as yet so in the next Rev I\u0027ll take care of that so with the changes the the model now looks something like this as we say I\u0027m augmenting routing 83 RFC 83 49 in as per percent we have now H back and DTLS port which we have added to the yang on at the bottom is the addition for web and rip support under that so issues so much like Barbara I also have my own github which is tracking all the issues related to the data model this discussion I think we have had so I\u0027m going to can skip over this because I think we\u0027re going to come back with a proposal on how to really model the link type so Barbara and I had to go back quite a bit on this discussion of mandatory values and I finally after several attend and a good breakfast we find Barbara explained to me that the two attributes that she\u0027s trying to address one is mandatory to implement which is not what this is about slide is about and there\u0027s mandatory from a model perspective as "
  },
  {
    "startTime": "01:20:34",
    "text": "far as values that need to be provided for the protocol to work correctly so I don\u0027t have a slide on mandatory to implement but just I\u0027ll just say I\u0027ll wave my hands and I\u0027ll explain this maybe in in the model is that we need some capability of a feature statement which allows and implemented to declare what features they supported and I and an example of that feature would be I support DTLS capability or I support H Mac and once you declare that feature then the model it\u0027s expected to have all the capabilities defined if you don\u0027t declare the feature that part of the model pretty much vanishes and you don\u0027t have to worry about trying to implement that so that\u0027s mandatory to implement so now mandatory as far as values that need to be provided um so I think in this particular case what I\u0027ve highlighted in red are two parameters which I believe are mandatory parameters in what happens is that when when you do specify that something is mandatory when the client tries to configure the Rueter or out of with that information if those valadon exists the client won\u0027t even be able to send that config request to the server if so it\u0027s the client is not good enough it\u0027s not doing a good enough job the server will definitely check and return an error saying you have not specified the mandatory values it also means that this the scope of mandatory nests is limited to the parent so in this particular case the two parameters that are highlighted in red are mandatory only if an h mac is being specified because if it\u0027s mac is not even being specified then it doesn\u0027t matter whether there other parameters within which within that that are mandatory the other clarification was around read-only attributes in the information model in yang typically it doesn\u0027t really make much sense to declare something that\u0027s read-only mandatory so something like Rooter or outer ID that Bible uses is read-only attribute means it\u0027s set by the system so it doesn\u0027t make sense from I\u0027m a config perspective to say well brother ID is mandatory if it is not said "
  },
  {
    "startTime": "01:23:35",
    "text": "there\u0027s nothing that I can do and if I read the Rooter ID can the answer be the earth known a proper implementation will make sure that it is always said but yes to answer your question it is possible that if you read and the implementation hasn\u0027t done it right you might actually get nothing back for it right I think what Joyce is trying to say give its Knaus e I think what Joyce is trying to say is that you can actually have an implementation of Babel that does not have a router ID that is just a like simple client node on the edge that doesn\u0027t offer any routes and so there it so that it\u0027s valid for that to be non-mandatory okay then actually I don\u0027t know maybe the information model then what I\u0027m gathering is that it\u0027s not mandatory right which also means you can\u0027t use it as a key that is true it\u0027s not quite clear so does it make sense to put restrictions on the implementation does the management model put restrictions on is it legitimate for the management model to put restrictions on the implementation so it is technically possible not to have a Rooter ID but it doesn\u0027t cost much to say we always have a Rooter ID okay so so let me back up the the reason why Barbara mentioned Belleview it can be a key is because currently we reference an instance of Babel by the rotor ID and if the Rooter ID is not there then we have no way to reference not shocking but so but my question was actually more general because that\u0027s a detail we can bring to the mailing list does our Oh so our o implies that there is no way of saying it must be presence is that it I sorry there are other ways we\u0027re saying it yeah but in yang ro does not imply that there are other ways yeah what I what I mean to say is that it\u0027s not enforceable I mean you can have it in the description and you say must you must provide but alright so we have had discussion of keys on the mailing list and I don\u0027t know where this discussion sorry just a quick last point on the router ID I just checked the 6126 base "
  },
  {
    "startTime": "01:26:36",
    "text": "and the spec explicitly says that the router ID must not be either all zeros or all ones so if this makes your life easier you could if it\u0027s not there have it return all zeroes for example well then the question is if can multiple instances of the routing return zeroes all zeroes in which case then it\u0027s not unique again true yeah and then but like those instances that don\u0027t have a router ID are just gonna be kind of observers they\u0027re not they\u0027re gonna be like almost invisible to the rest of the network so now being able to refer them is kind of okay oh no it\u0027s not okay no it\u0027s not okay and Julius is shaking his head so forget what I just said they don\u0027t appear as originators of roots but they might that feareth neighbors so still see them so y\u0027all are thinking of this from the network perspective we\u0027re thinking of this from your inside this box and you need to reference the information if you need to reference the information is there can the router ID be a key into your object model or not and what we\u0027re hearing is not I\u0027m glad you\u0027re forcing the decision no what we\u0027re hearing here is that the natural data structure that is used by babo says that you only need to have a ruler ID if you\u0027re originating groups if the data model needs to say that implementations that implement the data model must generate ruther ID even they don\u0027t need us just for the routing part I\u0027m fine with that it\u0027ll cost much to generate 64 bits of randomness sure okay so that then answers our question of how we need to update the information model and I\u0027ll reflect that in the young one yep thanks for the clarification okay so I\u0027m not a security expert and I just go based on what is there and some of the be remodeled so my effort is to try to just bring attention to the fact that there are other data models that we have to deal with as far as he setting up keys key exchanges and everything related to that so there is already an RFC for symmetric keys and how to store them and how to use them there is a draft on the asymmetric key and certificate support that is in the works in the net count working group but none of these of course have any thing that supports key rotation I don\u0027t know if that\u0027s important if that\u0027s important that I we need to figure out how we will support that and then I think this is the question I think Julius brought up on mailing list is how do you share keys "
  },
  {
    "startTime": "01:29:37",
    "text": "across domains as H Mac uses symmetric keys so I don\u0027t know if these are issues but I\u0027m just keeping it there so that we don\u0027t forget it as we try to progress the draft either we decide it\u0027s not an issue and closed them or we try to come up with answers no update on the routing policy and augmenting the routing policy model I\u0027ll do that in the next version and my final issue is with example configurations I really could use some help here I would appreciate trying to get some configuration examples that I can use not only to validate the model but also showcase to people who want to use them on how it we configure so if there are different implementations of the model that have different ways to configure I would be I would imagine that would be very not very kosher but if it is the case let me know but basically I would appreciate some examples that I can use for validating the data model what you\u0027re asking for are examples of real configurations in the current ad hoc configuration language of our different implementations is that correct that\u0027s fine you give it to me I\u0027ll do the translation of that into what would be accepted by the data model and then we can validate to make sure that the example makes sense right so it\u0027s mainly wanting real data but it doesn\u0027t have to already be in the yang syntax it\u0027s that\u0027s good I can do the translation to the yang syntax including H my H my keys of course yes that\u0027s what is far afield configured alright that\u0027s it okay thank you very much these are actually out of time so people should help Mahesh we\u0027re getting things he\u0027s asking for I\u0027ll you can post something to the list to asking for that also or if you don\u0027t I\u0027ll I will maybe when the minutes are done and stuff so thanks everybody for here I think we\u0027re making great progress we have a big package of documents already in publication requested State and more documents coming along so see you all on the mailing list and this Montreal with the next IETF meeting I think anybody have anything else they want to bring up I guess not if you did not sign the blue sheets they\u0027re up in frontier please come and sign them thanks again "
  },
  {
    "startTime": "01:32:40",
    "text": "okay so this is the one that hooked to the projector okay I reloaded this okay I can just download my flashlights yeah and project it\u0027s yours oh yes "
  }
]