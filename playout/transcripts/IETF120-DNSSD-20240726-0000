[
  {
    "startTime": "00:00:14",
    "text": "I was going to say, you know, wait until three or five know, ain't dot for you, if I now. What about the audio? show? That is true say, what about the audio issue? That is true. Eric said he was texting No, no. Is he open your mind. Oh I don't want to call them out by name He might be logged in, but you know, not at his computer I do that out a bunch, you know, you log into it not at his computer. I do that out a bunch, you know, you log into the call, you go make yourself coffee, and then someone calls your name, you have to sprint back So just we'd like to test the audio in the room So if you're remote and you're willing to say something so that we can test it please join the queue Yeah, we're just like essentially working for a remote volunteer who's willing to say something so just we can test we can hear you Thanks, can you say something like test? test Question one, two, three, can you hear you? Oh, okay. All right, so it sounds like if Question one, two, can you hear you? All right, so it sounds like it's coming from here. I'll contact me to echo okay So we do. So we Are you texting them? Yes I don't know if this is going to work"
  },
  {
    "startTime": "00:02:02",
    "text": "What is this positive B? C It won't work because it's I haven't gotten the room working properly. Oh, all right, I'll do it So yeah, the echo says they're looking into it Okay, fine I mean, I've already, I've also contacted this Secretary of the ECHO Maybe I'll do this one too Okay, they're notifying the ABT. Yes, it's cool recall. All right, the, uh team has been notified, hopefully anyway, we'll be the ones talking at first, so that'll be probably okay by the time we need to have remote participants speaking Arch, we get started? Yep. All right. All right All right Chair of Science. Okay, welcome to DNSSD, IETF 120 So this has per all IETF sessions, is covered by the note well. So by party"
  },
  {
    "startTime": "00:04:02",
    "text": "participating in the IETF you agree to follow the requirements set out in there, so if you haven't read them please please do read them in particular this tells you about requirements for disclosing patent information of the intellectual property and also tells you the guidelines for how to treat people to respect people so please do that that This being sorry, this is the usual arrangement for the meeting, so we have a volunteer for note-taking, so thank you for Francois. Hopefully you found that link. Let me know. Yeah, okay okay You can find the Metachead chat either in METECA or Zulip and that is the link for the session, but hopefully you have joined that or you're in the room and if you're in the room please use the on-site tool here are some useful links for our working group, so the charter is defined there and all of the documents that are working. We're working group so the Charter is defined there and all of the documents we're working on and we'll be covering those in the agenda that's how you join the main list, which is slightly updated from how you used to be this we also have a gethub so in that organization, we maintain the live versions of the work group documents If you have a proposal for a new document that you would like to be set up in there, please contact the chairs so this is the agenda that we're proposing to go through today so we're going to cover those working group documents first then"
  },
  {
    "startTime": "00:06:02",
    "text": "those individual drafts, and finally discuss issues with SLP transport and the size of those updates Are there any requests? for changes to this agenda? If not, let's proceed So Ray, do you want to come up and discuss multi-Q types? Do you want to control the slides on your phone or should we write them? Yeah so I've not done any slides for this one as the updates have been relatively straight, because the updates are relatively straightforward so the biggest change is the incorporation of the text albeit somewhat edited, that Peter Svedshek dropped on me a couple of days before the draft cutoff deadline. Those have been put into the GitHub. I unfortunately didn't have time to try to incorporate them before the documentation deadline. Sorry, the cutoff submission deadline, because they were really quite substantial But the main thrust of those changes is that it simply makes the construction of response much more generic and, in fact, doesn't even need to mention negative responses or DNS seconds changes is that it simply makes the construction of responses much more generic and in fact doesn't even need to mention negative responses or DNS at all by saying you basically you fill your putative response with the in primary query were specified in the DNS report and then you simply attempt to put in whatever records the standard DNS protocol says you supposed to put in for the remaining Q types so for as long as they fit I've also incorporated the change from Remy and VG, whoever that is, to update the applicability to say this is not relevant to the Multicast JNS protocol Thanks for Stuart and Ted for actually confirming that was the case, which is why"
  },
  {
    "startTime": "00:08:02",
    "text": "I didn't drop that in immediately and the other change is that there's now a normative reference to RSC 9619, which was published yesterday that Joe Abling and I worked on, which is the QD Count's use usually one document so it's actually clarifying the near specification that you can't you really can't put two questions in the same quick at least not in any useful form, unless using it So essentially clarifying the near specification that you can't, you really can't put two questions in the same query, at least not in any useful form, unless you use an extension like this I do still have some further updates from Peta SpaceShack to try to incorporate on the client handling of this option Pater, unfortunately, been unwell nursing sick children this week. So I'm still waiting for some clarification on him on exactly how those are going to what those needs to be incorporated that's it from me any questions So there was some discussion on the list regarding this draft, so please join the queue if you want to discuss any aspect of it Yeah, currently the text is just in GitHub. I haven't pushed a new up update yet. So yeah, we've been looking for further confirmation that what a page is proposed is actually acceptable as working group consensus and ultimately as soon as he clarifies the client handling side of things, that's when I propose to actually incorporate that and push the dash 03 I think is the next version Okay getting some thumbs up for the room, so sounds like carry on Yeah, so affirmative confirmation that actually agree with the updated section 3.2 in particular would be very useful to confirm that it really does reflect one group and consensus could we have a short of hands for folks who have read what Ray is talking about? and just to make sure that we have at least enough eyeballs on it"
  },
  {
    "startTime": "00:10:02",
    "text": "Oh, sure. Yeah, right. Let's do it in the tool. So the question being, tool So the question being, have you read, well, the latest. The latest, get on commits Ted, if you're, no not the optimal sitting place Yeah, maybe I should go around the other way, I don't know, ted lemon So I haven't actually read the latest GitHub commits. Thank you for doing them Petters' comment was long It was very long, yes. And so I didn't realize that you'd done those commits, or I would have read them, but thanks for doing that and I will go read them as soon as I have a chance. Yeah, so the language is not sure identical. I haven't dropped it in verbatim in part because Peter being checked doesn't do things like the definite article Yeah, so his English is good, but it's not perfect He's a colleague of mine so I can say that And there was actually an ultimate little bit of duplication in there which I've cleaned up All right, so I think if we have had two folks reading it, we're going to want a few more reviews So thanks, Ted, for committing to doing that. And yeah, we have some folks who have read it in one, no opinion I just, I just want to confirm I we understand what's being asked so the text we're talking about is no submitted as an internet draft yet, but it's in GitHub correct okay do you want to people to review on GitHub or do you want to submit one? and have them review the diff? And I Ted says that that's easier I don't mind. I mean, personally, I prefer to try and follow the email or emails on the list rather than get issues or all right it was but he's asked can you submit a dash o3 with the"
  },
  {
    "startTime": "00:12:02",
    "text": "commits, that way they can review it on the list? Yeah, that way they get the uh the automated email to the list has the def yeah i did i had hoped to wait until i had confirmation from Petroback, the client handling text changes he proposed Not before putting out the dash 03, but if you as chair would prefer, I just do that anyway and then do a dash 04 maybe in a week or so this time and then I can do that too yeah but that sounds good we uh unless we hit 99 we'll be fine okay i'll do that We don't know. It's, it's the RFC tech problem. The world will end Well, fortunately, the draft got reset when it actually became a working group document. It's been around since then 2012 And they go through quite a few rows about that time so we digger at least get back to zero zero again Oh, that's true. Okay, thank you. Thanks, Ray few rows about that time so we dig at least get back to zero zero again oh that's true okay thank you all right thanks Ray and thanks again for all your work on this document glad to see you making progress and by the way just in case folks don't know, if you open the GitHub, repository for it, you can see a rendered view of it so in HTML and text, you can also see the diff with the latest submission, the Datatracker. There's a link directly there there Okay, Ted Do we have the clicker? Yes, we do Yes, but it's not plugged in time That's it Where is the jungle? No no, but it's easier because that way, otherwise it just hits us hour. Just say next slide so um no, but it's easier because that way, otherwise it just hits an hour, just see next slide. Next slide. So, wait, what we're? it just hits an hour, just see next slide. Next slide. So, wait, this is the advertising, yeah, so I did a pretty substantial update to the advertising proxy document for I IETF 119"
  },
  {
    "startTime": "00:14:05",
    "text": "Okay, yeah, so this is better. So I did that, the update for IETF119, but I haven't had time to do an implementation yet because of things you will find about, find out about later And so that's, the document is basically hanging fire, waiting for some sort of work that needs to get done in order to enable the work in the document There are some issues that we discuss in the process of deploying our original implement of it that suggests that the what was what was written in the original document is not good enough, and so that's why I kind of backburnered that and started working on the problems that were in the way of making forward progress And so I'll be talking about some of those later Next slide They're on there with those slides. Sweet okay yeah so unless anybody I mean I really have anything terribly new to say about this other than that we have some sort of you know, foundational work we didn't do that we now need to do before we can proceed with the next step on that And actually, that's a perfect segue adding as chair, to explain, like, Ted and I had some emails on the list about prioritizing work in this group and the advertising proxy, and I was under the incorrect impression that some of these other items that Ted wanted to discuss were unrelated to our adopted drafts and so that's why I was suggesting we focus on you drop the draft but Ted helpedfully clarified that those topics are actually blogging for us to actually finish in public the adopted drafts, why it makes the perfect sense to discuss them right now, because it's part of the resolution we need on our adopted documents so thanks for glad clarifying that, Ted Okay, let's move on to the next one Okay, this is"
  },
  {
    "startTime": "00:16:02",
    "text": "going to be another exciting presentation. Next slide So, um, with the other stuff, so both so advertising proxy and SRP replication are actually kind of type together because the use case for both of the that at least I'm working on is thread border routers and thread border routers is use case for both of these that, at least, I'm working on, is thread border routers. And thread border routers are these little permissionless devices. Some of you might have been here in the meeting a couple an hour ago about this is there these little permissionless devices you plug into your network that have to kind of try to connect two networks together in a way that works and isn't broken. And they do a fair amount of sort of cooperative database sharing in order to make that work, both on the MDNS side and on the on the on the SRP side and so SRP replication is the is the is the SRP side it's basic a kind of a peer-to-pe zone transfer and in order for this to work, it needs to be the case that when SRP replication happens, the advertising proxies that are advertising the data that was replicated using SRP replication are able to do so effectively And so the problems that I was talking about in the previous presentation also affect SRP replication The good news is we at this point have a fair amount of experience with the actual basic protocol and sort of the things is we at this point have a fair amount of experience with the actual basic protocol and sort of the the things that it does and the the sort of I don't want to get all highfalutin but the computer science assumptions that we made that allowed us to make this replication protocol happen And it seems like our basic assumptions are good. The main challenges are more just with the advertising proxy and getting that to work So basically, I've been consumed with that and not with proceeding on SRP replication It would be really nice to do another inter-op with Google"
  },
  {
    "startTime": "00:18:00",
    "text": "at some point. We did one about a year and a half ago, but we haven't had time to do one since then, so hopefully sometime soon. Next slide if there is one. I don't think there isn't, yeah. These were just quick updates Unfortunately, the sort of the adopted work is all hanging fire on some unadopted work which I will talk about next And anyone, if you wanted to comment on either of those adopted documents, then please join the queue, otherwise we will move on to the individual drafts Okay, so time since received TSR, next slide So, um, proposed this quite a while ago based on operational experience and we came up with what we thought was a fix to the problem but we hadn't really understood the problem very well I had a bit of an epiphany about this, I think, we were having a conversation either in IETF 119 or 118 about this problem and I think Stuart and I sort of both realized that we were actually trying to solve the wrong problem. We were trying to solve the name conflict problem and what we actually had was an authority problem and so so a lot has happened since then, including several passes at trying to describe how this would work and an actual implementation that is done now and that clarify a bunch of stuff that we were thinking about. So we now have an implementation of the new improved TSR and and that it addresses, so the old TSR was causing a lot of name conflicts and we were also you know we had suppose you had like up to five advertising proxies on your net network, well, every one of those advertising proxies would probe and depend"
  },
  {
    "startTime": "00:20:02",
    "text": "every record that was being replicated using SRP replication. That went up being a ton of MDNS traffic. So, um basically the clarity that we came to was that TSR is about asserting authority and freshness, meaning who owns this record, who is responsive for publishing it and is the thing that we're looking at more recent than the thing that we saw? That is, is the new thing that we're seeing, more recent or less recent? than the thing that we currently have? in order for this to work one of the things one of the simplifying is assumptions we made with the old TSR was we'll just do TSR and probes because TSR is just for conflict resolution and that happened in probes. That turned out to be a very bad idea and caused a lot of a lot of sort of MDNS packets storms. So we now include the TSA information every packet, every MDN packet and that means that it has to be an EDNS option because we don't want it to accidentally show up in somebody's cash that doesn't understand TNS So we don't want some client that's just doing like looking up records to find a TSR record in the cache. So it's got to be eating a zero Next slide slide So previously, we already had this idea that the TSR record represented a timestamp, which is one the information that the tsr record correspond to was received from the source of authority So the SRP requester is the source of authority here The SRP requester sends an update and we remember when we got it So with SRP replication, when we're doing replication, we actually replicate the time that we received the message from the SRP client, not the time that we did the replication So the idea is that we're maintaining this"
  },
  {
    "startTime": "00:22:02",
    "text": "original receipt time from the source of authority We represent it in flight as as a relative time because we don't have a we can't assume that we have solid time synchronization And then at rest, we just store it as you know, an absolute time and it doesn't matter what the absolute time is because you only it's only ever on the system that it's being stored on and so that system can decide But the big difference now is that we include a key hash, which represents the authority source. So now, instead of, so when you do an SRP update, the SRP update has a public key that it's and so the requester signs the update with a private key and includes the public key in the request And so we now use, the key hash to represent the authority so if two different SRP requesters happen to claim the same name, they're going to have necessarily they're going to have different keyhashes. These keyhashes are validated by the SRA server. And so, I mean, it's course, it's vaguely possible there could be a collision, but I think you know, that's hopefully that's down in the noise. I mean, I'll get back to you in a couple of years So, next slide slide So the new conflict resolution process is slightly more complicated than the old one, but it's actually, well, in some ways it's more complicated, in some ways it's quite a bit simpler because we no longer actually do conflict resolution with TN is slightly more complicated than the old one, but it's actually, well, in some ways it's more complicated, in some ways it's quite a bit simpler, because we no longer actually do conflict resolution with TSR. Basically, one of two things is going to be true either we have actually conflicting data, and we can tell that it's conflicting or we have stale data and we just need to figure out which data to throw away. So that's a lot simpler than what we were doing before So if we have data cache or in authority and we get a MDNS message, if we have data that has to, we get an MDNS message that doesn't have TSR that's just a con conflict. If we have data that doesn't have TSR and we get an end"
  },
  {
    "startTime": "00:24:02",
    "text": "we have data that has TSR and we get an MDNS message that doesn't have TSR, that's just a conflict. If we have data that doesn't have TSR and we get an MDNS message that does, that's just a conflict. All of these are just hands the same way that conflicts are always handled in MDNS So it's very simple. I mean, the way they're handled isn't simple but we don't have to do anything new that's complicated So if we have data, uh, has TSR and we get data with TSR with the same key hash, now that is not a conflict ever this is really important. With the previous approach, we were actually treating stale data as confirmed data. And that was actually causing some serious problems. So, in this, the way this works is if we have new data that we get and the old data is actually older, we just flush the old data And if we get new data that's actually stale, we just ignore it. So it's, it makes life very simple. Next slide so um have to treat cash and authority data differently So if we have data in cash obviously if we have data in cash and we receive an update that's newer, then we just chuck whatever was in cash and replace it. If we receive data that's older, we ignore the old data If we have a local registration that conflicts with the cache, we flush the cache, but we do a probe. And doing the probe tells us, like, basically, there could be data in the cache that's no longer being defended. And we don't want to just fail the registration based on that. So instead, we do a probe and the probe should tell us whether there's conflicting data and because of the way that MDNS, you know, in the standard, the way that MDNN handles probes, we can be sure that we'll either detect that there's conflicting data or there won't be any conflicting data and life will be good So if we do a probe and we get back a response, with a conflict that's just handled as a conflict We don't need to think about that here because all we care about it stale data now. So if we get back a probe that has stale data, if we send out a probe when we get back"
  },
  {
    "startTime": "00:26:03",
    "text": "data that is more recent, which could happen for example, if we're doing SRP replication and things get jammed up or something like that we could wind up having one MDNS responder registering stale data while another one is registering new data And so we register the stale data after the new data was registered We send out our probe. We get back an answer The answer is that the data that was just registered as stale we return an error to the, client that's registering this service on the MDNS responder. And we just tell it it's stale. So it's not a conflict it's stale If we have published data and then and this this is this is actually kind of the the core use case for this functionality is SRP replication so that's SRP replication, the first thing that happens is we have, you know, the SRP requester succeeds in registering the SRP service with the SRP responder and are registrar and the SRP registrar then replicates that to everybody else so the SRP registrar has advertised with MDNS has advertised this new information with the new TSR so all of the MDNS all the MDNS responders that have seen that new data are gonna flush their stale data but it's not guaranteed that that data will be delivered So we could wind up in a situation where we've got an MDNS, an average, proxy, that still has the old stale data And then when we do SRP replication, it's going to get the new data, and that's going to cause a flush. Sorry In the replication case, actually, we don't have an issue because it removes its old data. The issue is when we do"
  },
  {
    "startTime": "00:28:02",
    "text": "the first, the initial registration, this is hard to explain, when we do the initial registration, on, you know, having just received the SRP update on the registrar that's actually talking to the SRP requester. That, update is publishing data which is theoretically in the old style TSR, is in conflict with what was being published by all of the other advertising proxies and so we sometimes would get conflicts during that process And those would then be resolved later through SRP replication, but by then it was too late and a lot of damage had been done. So now when this happened, one or two things are going to be true. Either we're going to publish all this stuff in MDNS and the advertising proxies that have been publishing the stale data will get a stale data response to their old published data or if they don't get that stale data response the next thing they're going to hear is an SRP update that fixes it and so basically we never get into a situation where we have stale data that doesn't get removed And we never get into a situation where stale data turns into a conflict Next slide, is there one? Yeah, so uh this has some really nice side effects. One is when we're doing SRP reports conflict. Next slide, is there one? Yeah. So this has some really nice side effects. One is when we're doing SRP replication, we don't need to always probe and so we, we general, it should be the case when we're doing replication that the original registration does a probe or an announcer for both and that clears the cash on all of the other advertising proxies. So all of the other advertising proxies are no longer advertising there stale data and so now when we do replication let's say I'm a peer that's got a result that going to be published, replication results not a direct registration that's going to be published"
  },
  {
    "startTime": "00:30:02",
    "text": "in the advertising proxy We already know that the source of that data has probed it, and so we can skip the probe. What that means is a practical matter is that we source of that data has probed it. And so we can skip the probe. What that means is a practical matter is that we're skipping a ton of multicast traffic. And so now our effect on the network, the amount of multi- traffic that we're producing is drastically reduced As a practical matter, in our testing of this code, we're just not seeing Spurrius' conflicts anymore It's just like, you know, every so often I see something in the log and I think, oh no, is this a bug? And I go and I actually look through it and I look at how it went and actually went exactly the way it was designed. So it's very exciting so that said of course this is a very new code. We don't have a lot of miles on it. We'll talk about it again in November we'll know a lot more in November let's put it that way next slide that might be the end. Okay, so that's it. Any questions about TSM? TSR? So I guess no question, so yeah, let's move on But of course, yeah, if anyone's got any thoughts on this design, feel free to share them. If anybody wants to implement it, that would be cool Because right now, the only implementation is in Apple code. So, like, for example, I know that Google has a fancy new mdns thing and it would be nice if, I don't know if the Google guys are listening, but if you guys want to implement this, talk to me okay additional records for DNS push. So this is something that I actually present last time. DMA had actually reached out to me well before IETF 119 and was interested in doing something related to this, which I when he sent me the email about it, I thought"
  },
  {
    "startTime": "00:32:02",
    "text": "he was proposing to do this. So I was like, yeah, let's work on it together And then it turned out actually we were talking about two different things but he still wanted to work on this, so we're both working on it So next slide. Unfortunately, this is going to be very exciting and new for DEMO because I did not have time to talk to him about it before I did the slide deck. So I apologize if Dima is listening So we published a dash zero zero individual draft which is pretty thin right now. Oh, by the way the TSR draft, I have not actually published an update to it because I need to talk to the lawyers first, but I'm allowed to publish it, I'm allowed to publish changes on GitHub just not on the IETF website, so not as an IT draft. So if you want to see the new version of this, you can't actually see it in GitHub already Sorry, I know, it's depressing So anyway, back to this So we haven't done any implementation work and you know we had this idea that basically we're trying to achieve was parity with MDNS. So MDNS has this ability when you do, like, let's say you're doing a browse You're going to do a query for a PTR record with a service name and it's going to return a list of PTR records with service instance names and then you're going to do, you know, SRV and TXT record on whichever service instance names are chosen and then having gotten an SRV record, you're going to look up the addresses on it That's just kind of the standard flow for DNSD And so N DNS responder will very happily stuff the MDNS response with as much data as it has in its authority table. And this really makes sense with MDNSD Responder, because MDNS Responder is typically, the MDNS responder being Apple's MDNS implementation Any MDNS implementation would do the same thing. I just tend to short, I tend to use MDNS responder because, that's what I hack on. So, so MDNS responder will happily send you back"
  },
  {
    "startTime": "00:34:02",
    "text": "the PTR record and the text records and the A and Quad A records because typically there's only one service on that device and so it totally makes sense, right? It's not even a very big packet DNS push is normally being done to something that has a lot of information in the case and so now if we were to do essentially the same thing that MDNS responder is doing in response to an MDNS packet, we would be sending you a giant pile of data, much of which you probably don't need So, the original idea wasn't quite right Next slide So yeah, so this is actually just explaining what I what I just explained So we were just, basically we're going to send this giant potentially giant response. Like if you, if you did this query, to an advertising proxy, you would get back an MDN message with a lot of information in it, which is pretty okay for an MDNS message on Wi-Fi because a lot really isn't that much, but actually one of the use cases for this is IoT scenarios on constrained networks and on constrained networks, sending like a bunch of data you don't need is really not a good idea. Next slide So, um things are a little different. We do care about the round trip problem, like one of the benefits of stuffing all the data into one packet is you don't need to do multiple queries, you send one out and you get all the responses back. And remember, MDNS is multicast. So on Wi-Fi, that means that you're always going to pay a 300 millisecond penalty whenever you do a query so if you have to do like three queries or four queries, that's going to take more than a second And as we all know, a second is a very long time So DNS push is a little bit different the round trip problem is still there but we don't need tons of extra data. We just like, we need"
  },
  {
    "startTime": "00:36:02",
    "text": "some data, but we do want to avoid the round trips So there are a couple things we do. One is, right now my DNS push implementation does not do name compression and I'm a little embarrassed to see I was actually telling Stewart to this and reported as a fact that the DNS, the DNS, sorry stateful operations document which DNS pushes based on forbids name compression and therefore we can't use it, and Stewart was like what are you talking about? It says that right in the document that you're supposed to do name compression so anyway, so it would be nice to do name compression, which would be a nice little enhancement But also avoid resending stuff we've already sent. So if we do a DNS push of scribe, we did that to a domain name and we're only supposed to be getting responses back on that domain name. So it doesn't even make sense to send that domain name back once and compress it Or really, if you think about it, like every time you send every time you construct a DNS push response, which might happen multiple times over the lifetime of the subscription, you're going to see that name. We don't need to send that name. We already know it So it would be nice to do that. But that's that's small improvement Next slide. And slightly off topic, but I just mentioned it here because I'm thinking about improving DNS push So, yes so I have some theories about how to do that. But the other thing is we could provide a hint like which do we already know about a service that we're trying to find So, maybe we could provide a hint about that. That was one thing that I considered in the, and it's actually in the current document When we do a push query for an SRV record, we definitely want the address records, because at that point, we've chosen the service So we know we want to talk to it, so let's include that. And to signal all of this, we probably need to add a TLV Now, I haven't done any of this stuff yet. I'm just spitballing at this point"
  },
  {
    "startTime": "00:38:03",
    "text": "So if anybody's interested in doing this work and writing it down and what I'm saying makes sense, you could actually just take this and go in write some code and a draft or like do some work on the draft and that could be demire or could be some other people in this room. And this room and you know get a jump on me and and and I could just like benefit from your work. I'm just suggesting that. Next slide so the other thing that's interesting is that historically DNSD was about discovery like individual devices like printers and things like that So it wasn't really a, first of all, there's this interesting, like there might be 15 print on your network and you would like a list of all those printers the you can display in a user interface and the user will then pick one and then, they will print to it. So that's kind of the historical model of the NSSD. Ironically, so that the idea is basically the printers of these like giant thumbs that are sticking up in your network, and they're just a few of them. But now we're doing IOT stuff, which is like every light in this room, maybe So what is that? That's like I want to say, 30 devices anyway. Each one of them has an IP address. Each one of them has a service advertisement maybe I want to switch for of them on or off or change their settings So I already know about those devices. I already have a relation with them. I don't actually need to do a browse. I don't need to look up PTR records. Maybe it's interesting to look at it those devices. I already have a relationship with them. I don't actually need to do a browse. I don't need to look up PTR records. Maybe it's interesting to look up PTR records just to see if they're there, but I don't need to do the whole DNSD process to talk to them. What I really need is just to see if the device that I remember talking to is still there under the same name And so this is something that I run into a lot in the work that I'm doing with Matter, which is an IOT control protocol"
  },
  {
    "startTime": "00:40:02",
    "text": "Matter just has a key which is, you know, we, when we onboard, the device, we give it a name that is very unlikely to ever be claimed by some other device it's just like hex garbage And so we really it is really quite safe to just assume that that name is still going to be present a day later or a week later or a month later. And so we can just do a resolve on that name We don't actually have to even do the browse and what that means is that really when we start off the DNS push, subscription, what we're subscribing to is the service instance, not the service and so the question that we want answered is, tell me everything about this service that you know right now. So give me its text record, give me its SRV record, give me its address records We don't really need to specify me, obviously we need somehow to say to to to to to to question, but that's the task Next slide slide so just talking about existing the current matter implement which is open source, you can download it from GitHub. It doesn't you can download it from GitHub. It does a continuous browse so that it can notice when things come and go from the network This doesn't work at all, unfortunately But when actuating a specific device, it does what I just described. It just doesn't resolve. It doesn't actually care about the browser And so it's basically doing an SRV and a text record query, and then after that's done, it does the address record query. So practically speaking, what we want is to just send a single DNS push subscribe that says here's the name. I want the text records and the SRB records on this name and by the way whenever you get an SRV record, could you please do Quad A and A lookup? on the target for the SRV record? Next slide So what we would need to change? So yeah"
  },
  {
    "startTime": "00:42:02",
    "text": "so there, if we want this to be like a single round trick, then obviously we could just do multiple subs subscribes and just make sure they wind up in the same TCP segment, which is totally fine, and I'm not actually proposing we do anything more than that except we do need an additional record an additional TLV that says whether we want a the same TCP segment, which is totally fine, and I'm not actually proposing we do anything more than that, except we do need an additional record, an additional TLV that says whether we want A, quad A, or both for the SRV record so that's the only change we need here And then the responder can I either try to collect all this data and send back a single segment to single TCP segment or it can just send the data back as it arrives, depending on the application for something like a threadboard or router I would be tempted to coalesce up to a certain size just because it's only one packet So next slide So coming next is writing some code and seeing how it works. By the way, this is slightly, we were talking about things that are like required for the advertising proxy versus not. This is sort of not as required as TAA but it's also something that, like, we do have on the construction constraint network we do have an issue with um with the size of the communication that we're doing and it is it is actually becoming somewhat urgent for us to solve so that's why I have been thinking about this problem recently But this is not the top of my priority list. It's just a thing on my list. So that's, I think that's the end of this. Probably one more so 9 out of 10. Oh, yeah, that's just, that's just the slide slide So, any thoughts on this one? Thank you. I'm going to grab my water"
  },
  {
    "startTime": "00:44:02",
    "text": "I like this idea a lot I'm stuart cheshire from Apple I like this idea a lot, and I hadn't thought of doing this and while you were talking, I was just quickly looking through this push notifications draft There is one unfortunate little detail, which is you can have multiple push notification subscriptions on the same TCP connection yeah and the event messages that come don't have any identifier that says which subscription they belong to. You're expected to use the name to match that but that's a solvable problem if we if we configure out a way you know maybe the 16-bit message ID that was used for the original service subscription I don't know I can't think on the spot right now but I think if we if we fix that we could save quite a few bytes, which matters on a slow network like thread Yeah, that was kind of what I had in mind too. We already have this identity that we just aren't using. Why not use it? Okay, let's move on to the final topic I don't think this is going to take too long. Yeah, but there's a lot. Okay, so I was talking about constrained networks earlier This is the one, this is the killer constrained network problem i'm about to tell you about this this we this really not fun. Next slide So we have SRP when I originally started working on SRP with Stewart like I think it might have been I don't even know when it was, but it might have been like Buenos Aires or something we just, like, thought it was a good idea to, like, try to come up with a way to do DNSSD automatically without requiring all the multicasts that MDNS requires So we hadn't even had a specific target use case"
  },
  {
    "startTime": "00:46:02",
    "text": "at that point. And then as time went by, thread came along and that became our first target use case, and we managed to convince the thread guys that SRP was a great idea, and we should all do it And I don't feel at all guilty about that, because I think that if we'd picked something else it would also have had these same issues, because we just didn't think about them Oops. So the issues we have are first of all, SRP is at least for constrained networks as a UDP-based protocol, which means that when we're setting, for example, the SRP message contains a public key and it contains a signature, which is actually bigger than the key And that's a lot of data that actually doesn't have anything to do with the SRP update other than that we need to authenticate it which we do. Thank you result is that SRP updates tend to be pretty sizable and you can of course split them up into multiple updates if you have a bunch of stuff to do. But if you do that, you wind up resending the same data over and over again Like you resend the key over and over again, for example And we're not using TCP, so we can't split these up, so that really sucks. So that's one issue and that is a real issue. That's the least bad issue though. The other issue is our goal here is, like I was saying earlier, like imagine all these lights in the room have an IP address, and they're all on the thread network. And so my SR, sorry, my thread border router crashes and I have to replace it with another thread border router or, you know, I don't have a border router, but I have a mobile device that's connected to the thread network control these things. And it published the SRP service and right now what happens is all of the SRP devices register within, I think, 500 milliseconds This is on a network with a"
  },
  {
    "startTime": "00:48:02",
    "text": "roughly a carrying capacity of 25 kilobits per second That doesn't work. So we wind up with congestion collapse This was an unpleasant surprise We hadn't really been seeing this problem with the threadboard routers because normally you just turn them on and there isn't a synchronous event that happens at the same time that you're trying to control and accept The bad news is one of our use cases is you have a phone that you want to use to control all the devices on your thread network. So it connects to the thread network and there's no SRP service on the thread network because your phone is the only like you know full functioning device so it publishes an SRP service And it's, by the way, it's a phone, so it's a sleet device because it can't be doing thread at full throttle. And so now we have congestion collapse happening right when the end user was to control their accessories, which really really sucks so you can see response time is on the order of multiple tens of seconds with this scenario and I've done a whole bunch of work to finesse this problem. So hopefully if you actually have one of these devices you won't see this, but the problem still exists. And it really sucks. So next slide slide So it would be nice to improve some of this stuff and you know we've actually had, so Abton and I have been discussing this problem and we both have different ideas for how to solve it, but our ideas are totally compatible. We can do all of them One of them is to try and do six low pan compression to get rid of spurious or extra redundant information in the packet that we don't need and that can save a fair amount of space although not a huge amount. Another is to assume that the key that we're using to register with is already known and then we don't include it And then can we"
  },
  {
    "startTime": "00:50:02",
    "text": "do something to make the to make the HMAX small without creating a security issue Eric Yeah, Eric, just a quick hint, rather than doing six rules pen style, if you look as chic which is basically using no dictionaries because there's a very, you can compress any protocol by making up the dictionaries before just a hint you may want to look there send text or or pointers because yeah we're definitely interested in that and i know abton has some ideas And he may already have thought about that, but he may also not have So the six-low-pan style compression is mostly Abton's ideas, so I'm not going to be able to talk too intelligently about them But I know so Abton, if you want to say something about it, you're welcome to So sending partial HMAC hats is something it would definitely save a lot of space the question is what are the security properties of that? I don't know So it would be nice if there's somebody here who does know that can help us with that. And if there isn't, then we'll need to talk to other people in the IETF who actually have a clue about this. So that's the package size problem, and those are just some ideas about how to deal with it and then there's the transport problem So congestion collapse is a problem that we're all probably somewhat familiar with and we normally think of congestion collapses as something that happened when you've got a lot of high bandwidth TCP streams going together. And so you can deal with that by doing ECN and L4S and fun stuff like that Unfortunately, that approach doesn't work very well here because the thing that's in control of sending isn't sending very much. And so the problem is you've got lots and lots of things that all want to send And there isn't an easy way to coordinate that So one of the things that"
  },
  {
    "startTime": "00:52:02",
    "text": "I'm thinking might help would be to have the initial message just be a very small one and so the small message would just include information that's just like hashing stuff that we hope the SRP server already knows And so we're essentially sending a very small packet, and so now if like 50 devices on the network try to send this packet within a certain period of time the likelihood of congestion collapse happening is a lot less because we're sending less data and on a network like an 802.15.4 network, that really makes a difference So I'm hoping that this will help Also, of course, I mean, I'm not even, I didn't even mention this, but one of the problems here is that sort of the default jitter time for startup when there's a synchronization event was 500 milliseconds and that's just too fast So that's been increased to something like 10 seconds, and I'm sure that will make a big difference but of course now that means that can take 10 seconds for the network to recover after a synchronization event so But 10 seconds is better than 30 minutes I don't think it was actually 30 minutes but it was like kind of painful So the idea here is that these probe packets are, first of all, they include enough information that we might even be able to avoid even doing a full packet exchange But secondly, if we do have to do a full packet exchange we can schedule it So the SRP register, which is a single thing, hopefully, or at least it's a small number of things, like maybe there's several registrars, but even so, the SRP register can make a more reasonable schedule and then we can avoid having multiple devices competing for the same bandwidth at the same time to do their SRP registrar and failing and retrying and failing and trying and failing congestion collapse And also, when the"
  },
  {
    "startTime": "00:54:02",
    "text": "SRP registrar sends its schedule it can say you know, I already have this information, so you don't need to send it against So the most obvious one of those would be the key, right? But also things like, you know, service instance names don't typically change, post names don't typically change, and what else, I mean, I addresses are the thing that's most variable, really So in principle, we could really really really cut down the amount of data that we're sent now all of these things are very IOT specific Like if you're doing this on, Wi-Fi it's hard to imagine this ever really being an issue. I mean, you know it's not ideal if 50 devices suddenly trying on Wi-Fi, it's hard to imagine this ever really being an issue. I mean, you know, it's not ideal if 50 devices suddenly try to do a two-packet exchange of you know, an 800-byte packet and a, you know 100-by response, but it's probably not going to cause congestion collapse But we do care about this for the for the 802.50.4 case so this is something that I'm this, again, this presentation is not. I have a draft. Please read it. It's this is some stuff that I'm going to put in a draft. Please get excited about reading it and soon you'll see a draft, hopefully And I think that's it Oh, yeah, lots of hot air, no implementations Do anyone have any thoughts on how to solve this? problem? Is anyone awake? Dueller? Does anyone apart from steward and Ted care? They all just came here because the Wi-Fi is so great and they love the sound of the jackhammers"
  },
  {
    "startTime": "00:56:02",
    "text": "I don't have expertise in this area, but I'm happy to get input. I'm sure we can explore options I like the suggestion of static context header compression. We're not the first people to want to compress packets on low speed links so I'm confident we can do this. I think it's a useful thing to do And this is not why I stood up, but the question does any We're not the first people to want to compress packets on low-speed links, so I'm confident we can do this. I think it's a useful thing to do. And this is not why I stood up, but the question, does anybody care? We need to figure out how to get more people working on this because the matter organization has hundreds of companies and thousands of engineers working on matter and those products depend on thread, about half of them half a Wi-Fi half a thread And I feel like we and Ted in particular are doing a lot of heavy lifting here to enable hundreds of other companies to ship products If only we knew people and matter leaders leadership you mean us oh wait well i will continue to work on what i can do at apple And I think that you make a good suggestion. I should maybe rattle the cages a bit in the broader CSA organization. Maybe for the next CSA meeting, I will actually point this out. And in the thread group too Another option that we have as chairs is to do interms instead of meetings at the IETF which i know some other groups do and in particular if most of the folks that you would want in the room are not regular IETF attendees, or like, for example, I see upton in the queue, who can't make all the meetings in person an interim when like, you know, for a bunch of folks are like local or even we can do it virtual might be more focused, so that's an option Yeah. It's also worth noting that the matter member meetings"
  },
  {
    "startTime": "00:58:02",
    "text": "are always at the same time as IETF in November and that may be one thing that's getting in our way oh yeah that's in inconvenient that's super inconvenient um yeah it almost seems like they're deliberately. They always schedule the meeting the same week as I IETF. It's like they don't want networking experts to bother that meetings. Stuart, you can you can talk to some people about that. We've tried Abton's in the queue. Why don't you? Go ahead, Abton Can you hear you? No we still have that problem. Very barely. Speak is loud as you can i'm tempted to go tweak the panel. Yeah, you want to give it a try? All right and everyone else be very quiet so we can hear Apten Go ahead, Aptain. One week, I think, I think there lowest hanging food, which I think might be the best day forward if I can say all the invention. The key as much passes and the key, like the the fact that, like, is 140 bytes for the key and the hatch of the theater signature is a big overhead in all the buses. So that's a response to the height of the space would be due to Luke. One of the two thoughts that came to me as said the present thing on the transport whether the idea of using PCP, that's a lot of these initial probes are very much aligned with 2050, whether the idea of using PCP for that is a bit of unfortunately absolutely sorry, it's not your fault, but the audio is really not working in the room Any chance I can, well, I was going to say to type it in the chat, but we're about at the end. Can you maybe put it in an email on the list? Yeah, sorry about that We did ask for help and they weren't able to fix the audio in this room room Thank you I think it might be the source because if you're hearing me pretty well oh yeah we are So I think it's on his end. Okay thanks so it might be on your end upton for next time. All right suggestion, upton, sometimes people are not using the microphone, they think"
  },
  {
    "startTime": "01:00:02",
    "text": "they are, and I mention this because we have this wonderful feature where MacOS will now use your iPhone microphone which is great unless your microphones unless your iPhone in your back pocket when that's really not the microphone you want to be using I've seen that happen before so that brings us to the end of the session so thank you everyone and please share your thoughts on the list And we look forward to hearing your inputs thank you you And thank you, Frossov, for taking the minutes. Much appreciate it Click the buttons to upload the minutes to upload it. I don't do it now"
  }
]
