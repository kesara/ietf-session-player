[
  {
    "startTime": "00:00:07",
    "text": "I\u0027m just trying to get the downloads [Music] remember what that was how we got that you know I think when you down to get one maybe gear files so it\u0027s this is it oh I see I use the default so we could just go through them yeah and then once we\u0027re through we\u0027ll probably have to go okay so I\u0027m just gonna go through these in the order that they happen to get downloaded here so the first one is the floor is DNS so will somebody come up from the floors DNS and give your presentation excuse me okay we\u0027ll do you later that\u0027s not a problem not a problem we\u0027ll do you later okay so let\u0027s go with the next one spin dump yeah it\u0027s quite the maze to get up here at after after he\u0027s done I\u0027ll try to give the next person a cue to move your way to the front of the room before you you know so we don\u0027t take as much time all right so just use the left and right keys too okay so here\u0027s the presentation of the quick measurements table and our project we call spin dump so we\u0027ve been working for a couple of IDF\u0027s on this spindle tool it\u0027s a network latency measurement tool basically that looks at quick in other protocols today we had some ideas of implementing some experimental proposals for measuring packet loss so there are a few different proposals out on using some of the reserved bits in the short header of the quick packets so "
  },
  {
    "startTime": "00:03:11",
    "text": "we needed also to create some sort of unified handling of quick versions because we now start see a lot of different versions and different uses of these experimental bits and yeah that\u0027s basically what we try to do and what cut down was that we made a table driven version of experimental and non-experimental quick versions we implemented two drafts of these lost measurement bits and we are currently developing sort of reporting of loss measurement events in our tool we\u0027re also integrating this into some testing environments using it for instance mignonette test vm that we can use to test a lot of different networks yeah scenarios basically we also did a bunch of bug fixes this is a list of how we are handling different quick versions so previously we had kind of nasty structures where different behaviors based on different quick versions basically we had go into every function and check which person list now we have generalized this quite nicely so so that we can add new experimental versions with new support for different header formats etc and and yeah make it much more dynamic you know and yep that\u0027s right so some of the lost detection proposals that got implemented was one that is based on these cue and orbits that will be presented at map RG so we have that implemented and we also have this round-trip loss measurements so we have a bunch of process in there what did we learn was that supporting all quick versions is quite demanding it\u0027s quite demanding - especially when we have a protocol that\u0027s evolving and we have a lot of experimental proposals to have a nice structure of handling you know all of these different cases we see that both these loss detection proposals have measurements in real networks and we hope to be able to to facilitate more measurements of this but yeah problem is that we only have two reserved bits and to reserved bits for two proposals is quite not that much so this was done with the me mark sealer yuriko\u0027s investor Fabio morrow in Alexandria you can find our tool it\u0027s been dumped at at github and the new measurements proposals you can find at these links so yeah that\u0027s it okay thanks let\u0027s I want to be "
  },
  {
    "startTime": "00:06:12",
    "text": "okay PTP notifications is next and kickoff nope sorry io am make your way to the front so we don\u0027t waste time can\u0027t use the right and left hi my name is Sachin vishwaroopa I\u0027m from Cisco system and myself and of us we worked on the PTP notification I am for the first time for ITF as you can see as you can see I will not use the format and maybe next time we\u0027ll follow the same thing so essentially in Cisco I work on IP fabric as some of you may or may not be aware but these days the paradigm on the media also is changing it\u0027s moving away from the standard SDI to IP based fabrics and that\u0027s what we were called one of the key things there is the PTP there is the synchronization between the your media gateways endpoints as well as the video audio sync is very critical and the accuracy needs to be less than 400 nano second and that\u0027s the reason we use PDP with the PDP today we actually have as I notice you have the standard for the young already defined like RFC 85-75 but what is more critical for us too is to get the notification and that\u0027s because of the number of sinks which are involved in the PTP in the PTB like in the precision time protocol in a second we typically think eight times so we cannot expect network management system to sync and find out the deviation from those samples because if you think about one day for a single switch we generate around 700,000 the sample points and so we want to do it in a distributed fashion so what we are thinking is to extend what we have with today with the PTP yang to introduce like a new notification there okay this slide again talks about the synchronization I mean earlier when we started on the audio video right if you are using a lower signal or maybe think about like ultra HD HD 4k 8 K now the buffer cannot be that big right so that\u0027s reason synchronization is critical I put some more things but more importantly you can think like audio and video Nate green thing and that\u0027s what we have been working on so these are the use cases what we wanted to address it in the hackathon so essentially for the live event we wanted to monitor and monitor our notification again depending upon the media profile the the duration and the stake all those parameters need to vary and that second we wanted to do "
  },
  {
    "startTime": "00:09:13",
    "text": "the configuration as well as generate the notification sure so in the hackathon we have the deliverables we defined today make a PDP an notification model again we need to review with the team we develop a third party application on Cisco switch so the real deliverable here was a Python script which will consume on the switch and push it away our notification to the existing product we have like an environment solution and we extended that to introduce a new REST API to consume that notification and overlay the PTP information on top so it\u0027s kind of pie chart but I am sharing the slide so you can see the example I will pay load as well as notification and this is how the user interface looks like here what you are seeing is fine leaf topology with Cisco switches and based upon the PTP offset threshold those witches at the runtime are color coded so based on the notification which WebSocket it dynamically updates the screen so based on the number of sample which has deviated we actually color code those and this was just idea just to demo that part and this is the back end where we introduced like a new application on the back end with the Python trip which completely integrates with the Cisco CLI so it\u0027s as if like a original part of the Cisco it\u0027s coming from Cisco and you can monitor and control the notification part of it so that was the idea the whole idea is to take the notification and integrate into the PTP thank you okay I is up and il NP is on deck so this was a project to do IO am which is in situ om operations and management basic idea if you\u0027re not familiar is to have an ipv6 extension header hop-by-hop option that contains an IO am option which is information that the router fills in as the packet goes along its path so the ideas were taken metrics and performance measurements from routers in a path so the goal we had today in yesterday was to implement something and show some interoperability there was a couple of drafts on the IO am one is on the specific option when is on the data format and what we did we brought up UDP paying that\u0027s a little program to you to a UDP ping that sets the extension header and the IOM option and we had a client-server one router and we were able to follow the path and have the "
  },
  {
    "startTime": "00:12:13",
    "text": "information filled in the kernel implementation or the router was provided by Justin that\u0027s at this github and separately the client in the server code was a different implementation all of these were on linux hopefully next IETF hackathon will have some more router or host implementations join in so the way this works for what we do we ping a remote host add a few options and as you can see we got some response back and we parse the IO am message that we got back and sure enough the router filled it in so more interestingly is the note information this is directly from the IOM draft various pieces of information so I have the egress interface and Gress interface timestamps transit delay things like that so there\u0027s quite a bit of information that we could potentially gather from the network in this fashion we did learn a few things particularly trying to to get things dinner operate getting the lengths right we\u0027re parsing fields particularly fields that hold lengths that correlate to other lengths that was kind of interesting bit fields don\u0027t make things easier in this regard especially when they\u0027re split across byte boundaries and we also have a few suggestions to I ppm particularly in some of the data formatting cake data format for instance it\u0027s a lot easier to deal with fixed fields than variable length data in this regard so we probably have some good feedback on that wrapping it up so we had a good number of team members and a couple of first timers at IETF hackathon thank you okay Olympia\u0027s up and taps is on deck okay so just some background information on island P we had the first demo of what will eventually be a public release of the code at the last ITF and we\u0027ve just been developing that especially trying to fix some bugs that we found in a tie T of 1:04 which was very useful to to know about so the plan here was really to make sure that Island P could work over a real network that\u0027s the idea eventually and so what we had was a network that consisted of some low-end rooters but they are just commercial rooters they run ipv6 only the idea is that Island P works completely end to end so the core rooters just think you\u0027re running ipv6 whereas actually you\u0027re running Island P and the other "
  },
  {
    "startTime": "00:15:14",
    "text": "thing that came through a fortuitous conversation with Stefan BOTS mayor was some DNS improvements help with DNS in general and I\u0027ll say a little bit more about those in a slide coming up so these the key things that we managed to work out today we did some test runs with TCP / Island P running over these commercial rooters between two boxes that were running an island P modified Linux kernel and but running over these commercial rooters and we had some discussions on fixing a possible issue with DNS additional information processing and that was actually fixed so that was a good outcome I spoke to Stephan BOTS man after I uploaded these slides I should also thank so I didn\u0027t put his name in but Peters bachik actually did the coding to put this fix into one of the the DNS service so thank you for that as well this is the demo that we had running we had the it\u0027s not really easy to see but you\u0027ve got two boxes at the what is your right hand edge running the island P code and in the middle we\u0027ve got four little edge rooted boxes those are r1 r2 r3 marked in the logical diagram and we emulated a mobile node moving across them so no mobile IP they\u0027re just unicast routing and what happened is that as the mobile node moves across this running a TCP flow from the blue node the correspondent node while it moves and we just wanted to see can Island P do what\u0027s meant to do which is to change its location seamlessly as it moves across those different networks and the results we had showed here on this graph the individual throughput on the network shown on the top three facets of the graph and on the bottom graph is just the aggregate throughput you see of a correspondent node so that was pretty good we got a consistent TCP flow running across those commercial routers running Island P and to end they were just running unicast routing but we had a mobile node this was work that was done mainly by my PhD student who\u0027s working with me at the that\u0027s saying my time is up at the university of san andrews and we had some former students who also contributed some code and just some thanks to some people who have made it possible for me to be here today thank you very much [Applause] okay I - inner-self is next and tap is now taps is now hi hi I\u0027m Theresa I\u0027m presenting for the new taps table which is for transport services just a quick recap what taps is so we are developing a sort of an abstract API for different "
  },
  {
    "startTime": "00:18:15",
    "text": "transport protocols and those are just the Transfer Protocol it\u0027s our current PI tabs implementation supports of course it would be nice to have Quicken there as well so the idea is the application specifies some extract requirements and then it gets a generic connection and the application doesn\u0027t have to care whether it\u0027s like a new transport protocol and this is being worked on by the tabs working group right now in those three drafts now in our PI tabs implementation we added a few things here at the hackathon so we have tests now and we worked on racing between different transport protocols so of course those are not really equivalent but if we have transport protocols that are sort of provide the same features and we can try them at the same time and sort of go have the eyeballs on them and we are working on that right now also we are working on getting multicast to work which is kind of work in progress also we have a nice interesting concept called framers so the idea is you get a byte stream from key city but then you have a sort of a delimiter that limits your byte stream into messages and this is a concept that has been added to or that has been expanded in the recent draft and so we\u0027ve been discussing framers a lot and there\u0027s also going to be a more discussion on this concept in the working group so we have some feedback because in our implementation we have implemented it and some parts were unclear also we\u0027re going to discuss how much we of this we have to specify from the tests we could fix some box in our implementation obviously but also we are sort of modeling the input that we get from the application and maybe also we\u0027re going to model the output sort of the resulting connection so let\u0027s see where this leads in terms of comparing different implementations and don\u0027t also we have some other minor additions to the draft so the people who were there the entire week and are mostly Jake Max and me also we had more discussions with people from the working group Phillip and told me for example and so thank you for thank you to everybody who contributed to that and this is the link to our repo okay I to NSF now and SR v6 VPN yawning next hello hello this is a person from sko in Korea let me introduce I to NSF of primal walk hack hackathon project this time so this "
  },
  {
    "startTime": "00:21:21",
    "text": "time I - and I said hackathon project we want to pro concept the person over I - and I said framework can work on top of a commercial probably cloud platform it is called SOA you can see security on air so we approved our three interfaces on top of this commercial platform and also we demonstrate the security policy and translator is works well so this is a building block and so this shows that our internet draft on at I - and as a working guru and this is a poster so this is our during the weekend we work together Tim Porter so this figure shows I - and SF so this is a nice I to another frame work or project so so you may be a panel reader this one so this time we embarked with commercial fiber NSF so here we is fire and also we used previously we used the Rakata open source the red bitter so this time we combined the commercial our power and open source should be cut up for web filter together on top of commercial public cloud system developed by the ATR in Korea and so to slide a demonstrate mmm a copper over here you can see demonstration here so the register to NSF for features and also consumer I to pay she used it to deliver the security policy in the high labor point of view and then security controller translate halide policy into local policy so this is a see you can see a one you see is the one you get so we provide the user interface to easily configure that 12 script functions using that is test boat yeah okay so we provide the two or scenarios filtering and we return so this time we prove our concept I told except interfaces are watching on top of a commercial platform also we show that the translator is a working well so well tomorrow hack demo our where we can attempt to rate will be happy with the European thank you for your listening thank you [Applause] "
  },
  {
    "startTime": "00:24:24",
    "text": "OKs rv6 VPN yang and coming up is LP when this is Michael and about introduce hack projects of SRO six within configuration journey the module yes this is our hacked in and we know we are a deployment server sixty weakened and the configure sr60 I\u0027ll meet him sorry six unit module and the sender as our v6 model is under development by IDF so we\u0027re looking forward a pass to support its operators to controller use a TF Yamato to interact with the vendors native young to and that to debridement and lacks a device and so the project here is we using the an support a book and I guess the only the modules to configuration to config as re 16 and implement it\u0027s a key features in I have as a risk model also we want to development also we want to development and plug in to support standard Yamato to translate to native module okay say said what we can we can\u0027t work on what we got known and then we implement a three unsupervised one for us our basic global and as our sorry six and that\u0027s our with six within mode and we also develop them and app to allow it remains ITF model to the Wonder native your motive you can improve our tab I\u0027d have a service exposure and output is a native as our basics Madhu and here is a function and flow for the new device you can direct the implementer I have module and for the laxity was you can use a plug-in to transfer to the standard model choose a native model and what we learned is that as our basic model can be proud to support as our sixth service delivery and we use an spa playbook to extrait multiple tests and the here\u0027s problem is that the window deluxe device maybe only support until model and this operator of controller may want to depart ICF\u0027s and emolia\u0027s common interface to interact a base multiple vendors so we grab to our addresses issue and it will both feel if I know okay if you like to if you are interested in the topic you can join tomorrow\u0027s happy hours and where we all shows a demo and discusses a detail okay "
  },
  {
    "startTime": "00:27:27",
    "text": "this is our team member since everyone\u0027s contribution okay okay obi-wan is now and PBT is coming up next good afternoon this is a report from the from the NP one open cheeky table down in the back so this a hackathon similar to the previous few hackathons our goal was to improve the open-source implementation of shake shake is a protocol defined at the LP one working group it\u0027s about compressing headers and providing fragmentation so that IP protocols can be transported over LG ones and everyone\u0027s our loop our wide area networks such as Laura when sig Fox n BR UT l TM or I Triple E 15.4 W which are characterized by very small payloads and very reduced bandwidth and energy resources the major draft is the first one shown here and we have a few continuation drafts so what we got done this weekend was merge several feature branches in our project we had had separate developments over the last few months and which resulted in basically the compression being in one branch and fragmentation in another branch and so we merged that so that fully integrated and we got the basic tests running again and she needs to be ironed out yet and one of the branch provides in the new fragmentation mode that was introduced last fall including the extensive tensile testing of that we I did a few other functionalities simple OAM stuff like ping responses and all that stuff so that one major achievement and the other one is making the the project easier to use for newcomers so we created a user guide how you we run the code simply when you get started we added that into the Sphinx documentation of the project and we also would test plan for to the random testing of the fragmentation machine oops so yeah what we learned is that it\u0027s easy to diverge on such projects when you have contributors overseas that you quite don\u0027t know beforehand we also when we really want to lower the adaption barrier to this project so that newcomers can get used to it without draining too much of the resources of "
  },
  {
    "startTime": "00:30:29",
    "text": "the old timers and also yeah we want to provide complete examples and we want to become the reference implementation for shakey and that\u0027s our team ten members when new hackathon member free people remote from Japan Spain and Chile which allowed us to run 24/7 over this weekend by having the Japanese working while we were sleeping that\u0027s it thank you okay [Applause] PBT is coming up and the next one after that is IP wave okay we have a PPT let\u0027s see how well that works hmm click on present yes of course okay yeah I can I\u0027m not I\u0027m not able to advance it okay so we\u0027ve asked PBT to upload a PDF and we\u0027ll come back to it so for now I P wave and our arts to you is after that so this is a poor Joe so I want to share all the experience i py per project basic product a protocol project so to go is a to want to approve the IP about the six over l2 that Alabang possibly wave will I Triple E label a logical inkelaar the second one is a bit cooler neighbor discovery with the address laceration and multi-hop D ad and also we take advantage of intermediate of acres in banette radius D ad time also we can short the English initialization of TCP a little patrons and so we proved the to attract or she be and also each one able discover attract so this is a poster this is the total 13 so this is a figure is at the picture and at all architecture so you can see liquor can communicate each other using b2b also communicate the p2i so our idea "
  },
  {
    "startTime": "00:33:29",
    "text": "is you can see the beaker even though it is not communication range or lotus-eyed unit this is a providing Internet connectivity to beaker so it can initiate the ad using intermediate beaker and register using multi activity and also it once it configure with the or global IP other otherwise it can start the TCP UDP connection so we are probably using simulation this figure so the zoom up for a loader simulator and also we use the oil net for the truck simulator so you can see we using a 3 hub multi happy ad to reduce the tid delay and also we can start typically a TCP connection so this is a portable stack the left-hand side is that you can see variable protocol stack this is IP this is a website necessarily protocol for safety so we implemented before a logical link on layer and IP version 6 over go to the 11 or so neighbor discovery so the simulation result is our double discovery can lead use the legacy our neighbor discovery so yeah okay so we during the weekend wheel along the probe concert IP rightful OCB and we call neighbor discovery I can work for the note here are the queuing Network so you can take a look at other material for Peter cleave and also get help olenka thank you for your listening thank you [Applause] okay arts to you now and TLS one three SSH come on up for next okay okay I\u0027ll choose a feed of arts and cultural listings we\u0027re looking to save the producers of arts events time and and help them bypass the intermediaries who have kind of taken over the their data so we want improve the discovery and circulation of the arts events when we\u0027re here at ITF and we want to make the arts more machine readable so the problem is that the arts sector publishes its information in very fragmented ways and regrettably intermedia is into "
  },
  {
    "startTime": "00:36:30",
    "text": "intermediaries have become the authorities of our compiled arts data so what we did here step one was a lot of preliminary data organization and step two was we constructed widgets for the users for public users to indicate their interest and once they once the games were made that helped us love the results and feed different information to the users so so the before picture of this as it is on the website you see all the arts events that are listed there where the user has not made any preferences and then the user will plays one of two two of the games we created and then in the end we have recommended events for for the user and then the user can play the game again and we can learn more about the user so for the outcomes we have begun organizing our system to take into account these user preferences and there\u0027s a lot more discussion a lot more data needs to be generated before we can implement any of this and we have some questions going forward and I\u0027m happy to speak with anyone who wants to know about this project okay thank you very much all right 1.3 and mud onboarding is after the app and this looks like TOS 1.3 is another PowerPoint don\u0027t let me give that another drone they wanted to go at the end all right oh yeah I\u0027ve also update uploaded the PDF okay so we\u0027ll catch you at the end when we do when we catch up on the uploads so my rudder on boarding is now and then dhcpv6 after that okay hi everybody well it wasn\u0027t just mud on boarding we muddled in anima ACP work on that as well a couple of different drafts that are going on here so we have the RFC 8520 and we had a lot of projects running around at that center table there we had work on a mud mud reporter this is a mechanism by which manufacturers and network administrators can learn whether or not their devices are actually putting out policy recommendations that are useful to those devices or if there\u0027s miss configuration some work on mud maker which generates the Jason the the guys from Syria labs completely redid the code which was nice because it was in PHP and my PHP which is really bad and now it\u0027s all in Python thank you guys there was DPP mud integration that was going on there was a verification "
  },
  {
    "startTime": "00:39:31",
    "text": "mechanism that was being developed by the folks at NCC OE and then we had some grass work and does the discovery work going on and let\u0027s see here what did we plan to solve actually we just plan to all get together and figure out what to solve and that\u0027s what we did so as I mentioned a lot of I think it covered a lot of this ground already on mud run mud reporting we got a guy back there Rangga who who sat there and basically coded the entire time got an 80% implementation in terms of what he can report out and we had a lot of bug fixes going on to to a bunch of this stuff the mud manager that Cisco did how to loop in it on it still has a loop in it but at least we know where it is and know how to avoid it and I\u0027ll be putting in a patch for that in fact I have a patch already just needs to get committed so we had a lot of some interoperability testing going on we had a couple of guys here from c-calm who went and actually implemented mud right on the spot in their devices and test against a number of mud managers generating themselves a mud file that was appropriate and tested their acts we can now test their access and then we had some additional integration going on in terms of filters for east-west or north-south in terms of the verification code and yeah we got a lot of work going on so we know also we need to fail fast we have on some of our code and we have a lot of work to do on the mud reporter just a couple of screenshots of some of the stuff that went on here this is the the thing that will generate mud files in terms of the verification and here you got here you have dark and our gentleman from c-calm and in terms of them bringing their hardware that implemented mud either in DPP or directly using things and here\u0027s the long list of people who actually did a lot of work and thanks to a bunch of organizations who are supporting them thank you and it looks like a lot of first-timers on this one so that\u0027s great yeah okay dhcpv6 PD and then coin RG after that okay so hi this was a spontaneous project as you may have known there\u0027s HP v6 PD on the heck of the network and we were chatting with people and I put together code for fo outing to capture those packets pick up the appropriate routes and install them that wasn\u0027t previously possible now it is and that\u0027s it and we have a new record for shortest presentation Thanks okay so coin RG and map RG after that hi "
  },
  {
    "startTime": "00:42:38",
    "text": "everybody I\u0027m sorry didn\u0027t use the the format in Quebec we call that being a distinct society this is the coin RG p for hackathon and this was our first one as you can see because we didn\u0027t know about the format who are we we are actually a proposed research group we\u0027re still waiting to be a real one but we want to look at everything that works that deals with computing and the network and investigating this whole continuum of putting computation from the data center all the way to the edge we want to look at architectures we want to look at protocols and want to look at real world use cases and this is the reason that we\u0027re having this hackathon because there\u0027s a bunch of people invented a language is called p4 which is currently being used to do some specific programming in switches and we wanted to look at this idea of this cloud to edge computing continuum and p4 we didn\u0027t have a specific project except or remote participant most of us were pretty much new users and because of that we have to really give a shout to the company Montreal company who sent us two engineers for two days to help us setting up our environments and developing the code that is actually at the end we ended up doing real work which is like yay so what we did and yes we me and pl we are gone but hey thank you guys we did the basic examples we had actually one very very proficient sadly a remote participant who actually implemented and started implementing an ipv6 v6 switch machine learning in NP 4 he checked his code in the in the github and it\u0027s related to a work that was done before in ipv4 we had actually we actually poached people from other tables that you joined us we had 12 participants at the end so that was actually pretty surprising for us and the people we poached included people who started looking at p4 to golang and this morning we did packet filtering and we gathered a ton of information and I\u0027m always done and so our next steps we want to continue gathering projects we think that you know we have a good chance to become a real research group so we would like to have a coin interim and we want to have another a Katan and Singapore has really got the heck of this and we would like to really really thank the hackathon organizers and our helpers and or participants thank you very much ok map RG now and hackathon measurements is next good afternoon "
  },
  {
    "startTime": "00:45:39",
    "text": "everyone so the measurement analysis for protocols research group participate in our third hackathon this time and I\u0027ll tell you what we were up to the problem that we were attacking on at this meeting during this hackathon rather was to produce a reference implementation for doing IP address aggregation two applications of this are doing address space anonymization where we where you a granade say you\u0027re at before address 2/24 what do you do with ipv6 another application of it is for instance to find homogenous populations for instance for content delivery networks to do matchmaking between the users and the content the specific problem solve was how do we take something like a Patricia tree if you use Python or Pro you know this as net Patricia or in Python PI radix or PI Trisha how do you use a data structure like that to represent all the activity in the entire internet it\u0027s too big when you have tens of billions or hundreds of billions of v6 addresses so so the the to solve it we decided to take an existing code see the agree tree which is an implementation of patricia tree and make portions of the tree immutable and I\u0027ll show you why that self the problem but basically it allows you to solve the problem by partitioning it you can partition the set of addresses arbitrarily into small sets you can put them on a cluster and you produce an intermediate result where you can capture the state of the tree as you\u0027re performing some operation on it and then do it iteratively so so what were the new ideas and what did the team agree on well the team it turns out today was just me so we agreed on everything and we agreed to use the agree tree and really agreed that this this partition this partitioning problem could be solved by making portions the tree immutable so that\u0027s the new the novel design idea in a patricia tree the github upload is pending and I\u0027ll just show you exactly what it was because we managed to get it we managed to get it done in just a day so what we got done so he\u0027s imagine you have a set of active addresses here\u0027s ten I give you six / 64 s and you can punch them up into one of these trees that are commonly used it\u0027s kind of like a routing table so we put the tree we put them in the tree the relief nodes are all those active addresses and then we run some operation which I call Agora five which aggregates them in some useful way based on your selection criteria like let\u0027s say I only want aggregates that represent at least 32 of the of those active users well the problem is if you ran it the own way it\u0027ll aggregate up the whole tree because there\u0027s nothing there so that the simple idea is I just bound the tree or I put in immutable entries and basically make a horizon or a border on the tree here here measured in red and so when I run an operation like a like a an aggregation it\u0027s bounded by that red portion and we get a result an intermediate result that I can then do it early like say on a MapReduce cluster with hundreds of machines and then so to give you an example why this is important you probably think in 94 you know what a slash 24 is and I pre 6 even with this small data set of 180,000 active slash 64 is this shows that about "
  },
  {
    "startTime": "00:48:39",
    "text": "half of them reach this sufficient aggregation at slash 56 but another half of them needed to be aggregated slash 40 and today in the v6 internet a lot of people use slash 48 which is right in the middle and a horrible compromise because you could have a better answer or you\u0027re not not aggregating enough so what we learned is is that this is a candid best practice and we\u0027ll carry it to the working group and I made a couple design other design decisions again that were you know man unanimous so with just me I\u0027ve based on a publicly available open source code from some colleagues including candor ocho and we\u0027re gonna meet on Friday and I\u0027ll go over some more the results so join us on Friday at mapper G if you can in the morning thanks ok measurements just the one okay and use the left and right buttons left and right okay so hi I\u0027m I\u0027m al Morton and I let a champion to project today on measurement using UDP to measure IP link capacity and we had Lynch Avot own remote and for first-timers who all joined the project because we put the asterisk next to the name yes you\u0027re welcome alright so here\u0027s the plan we have this metric and method of measurement we have the draft up ready for a five-minute talk in IP p.m. Wednesday I think it is our goal here was to gain UDP based measurement experience with a get busy one gigabit access at ietf everybody knows how busy that can be and an additional access types were made possible by our volunteers that joint and I just want to mention that you know all the names here Ryan Hoffman from Telus and Ryan\u0027s gonna speak a little bit about his results and Timothy Karlin Marian Dillon and Kyle Kyle it all from UNH at the interoperability lab thanks so much for joining this ok so here we go so we ran the tests we iterated some measurement parameters we\u0027re going to revise the tool based on what we learned and compared with the commercial tool everybody knows what that commercial tool is it\u0027s us so we we ran from here side by side for the tests that I ran to the UDP server in Middletown New Jersey both servers and clients on the same machines and here\u0027s a quick representatives set of results with the UDP speed test of you know we\u0027re seeing the effects of the traffic here we\u0027re only getting into the 800 I mean it\u0027s a it\u0027s a gigabit per second access right we\u0027re getting an 800 "
  },
  {
    "startTime": "00:51:39",
    "text": "650 Luke of a measuring a lot lower we go back and measure with UDP St you now we got a lot closer to the limit of one gigabit per second and then in the afternoon on Saturday everybody was pounding away here and we really need to learn the signature of what that that is and my time went away what the hell oh there it is oh my gosh it\u0027s only 46 seconds left go go so I wanted to include non congested links so set up a connection between our Telus lab and Emmet in Alberta with alles New Jersey lab to perform the same kind of test but in bulk so using two servers here in New Jersey just to be able to get the bulk of tests that we needed unfortunately the server in New Jersey only had a GUI so this shows the comparative results a consistent near gig speed result with the UDP speed test as opposed to the TCP test which was highly variable really important information for us because it\u0027s difficult for a technician that\u0027s going into a home selling a service and using that test to reveal though the customer what they\u0027re achievable speed is and it being subpar the UNH folks walked in this morning got this test running and and and resolved a problem with their router screening in the firewall on UDP traffic and made it work properly right after that it was a great effort in just a few hours here this morning and we learned a lot of stuff for potential development and and and you know you can learn a lot from testing different access types that\u0027s for sure thanks very much [Applause] okay so I think that\u0027s all we have downloaded let me go grab the new ones yeah okay which yeah let me see 29 did we do DNS SD Discovery proxy what yeah so DNS st discovery proxy oh I\u0027ll make this really fast so we\u0027re here working on making discovery work with less use of multicast because multicast when you\u0027re making discovery work with less reliance on multicast because multicast is slow its unreliable it\u0027s wasteful of shared wireless spectrum there\u0027s a list here of the "
  },
  {
    "startTime": "00:54:40",
    "text": "drafts the discovery proxy is based on the hybrid draft which uses DNS push notifications which in turn builds on DNS stateful operations we\u0027ve been building a code for open wrt running on these little GLI net AR 750s little pocket gigabit router i was here working with ted and barbara joined us thank you barbara we did a bunch of work with integration open wrt package management dealing with asynchronous change notifications with you bus to really polish this code this is all available on the ITF hackathorn github and we now have pre-built packages you can download it yourself and run this and in about five minutes have your own discovery proxy running at home thank you [Applause] okay web RTC and then it looks like PBT is after that alright hey my name is Alex Anwar and it\u0027s a very difficult name to say so people call me dr. Alex I will represent the team here about web out is Hugh about this is a technology to bring real-time communication audio video and data to the web and it has an IETF pendant which is RTC web for all the protocols the encryption the security the codecs and so on the last missing piece is called simulcast which is the capacity to send a different resolution of audio and video simultaneously over the wire to finish this back at the belief receipt so some of us came around here today to try to push that so that we can finally have a finalized spec and people can implement product on top of them we had two browsers represented today Firefox and Chrome the two others were excused for visa reason and other things we had free media server represented to give feedback on implementation which is also very important and finally free application vendors that were using both browsers and media servers to help communicate about the needed and missing functionalities and different bugs we "
  },
  {
    "startTime": "00:57:40",
    "text": "had different people going at it at a different angle some of us just took some bugs and went through it but globally it was a very efficient session we went through ten different bugs in different browsers and we also helped different vendors implement similar cast in their media server or at least made progress there and provide feedback to to the missing pieces so all in all very efficient sation and we\u0027re very happy and we made a lot of progress in two days that would otherwise not have been possible without the opportunity to have a face-to-face the agathon gave us so thanks to the sponsor and things to charge [Applause] [Music] okay the PBT my name is Lucy yeah today I will introduce to my project poster card base with telemetry for eSATA flow information elementary at first I will introduce what is the post card base at elementary as we know there are already had there have already been defined for data types in ITF draft IOM data including to type Tracy - Tracy type 1 beauty and the luster is a H 2 H type now we will define another new one treating type called we call it puts the card base at elementary so what\u0027s the different between the post card baster elementary and our am tracing type at first we separates the elementary instruct instruction header and the metadata so like the like this picture show the red one is the e structure and the yellow one is a metadata a postcard will ship the metadata will she out hope I hope at each node so the host as we\u0027ll get the postcard metadata why then "
  },
  {
    "startTime": "01:00:42",
    "text": "I will try why we introduced this new type because we list three reasons the first is detect use this type tracing type we can detect the location of the packet loss and and then we can solve the encapsulator encapsulation list with the fixed packet header sorry little nervous and and the last one is a different the queues priority from for the metadata from user traffic and then and then the I feet header definition at show is this diagram aligned for octet rule and there are a little different from the IOM type I am header there is no lens bit and there is no metadata okay this page show this project in hexa at first there are network domain include for Reuters and a tester will send to test the flows and and also receive this to test of flaws in ipv6 transport as the transport protocol the Rooter for as the inquest node to encapsulate the I feed header and the Reuters 3 as as eQuest Note 2 Inc they capture leads to the I feet header and Rooter 6 and the Reuter file as the transit knows the yellow yellow one is a matter data is collected to the collector the collector framework is circled by the - lon [Music] we built the collector framework based on the open source open source project for example the Kafka as messy distributes a message queues and the readers as the memory DB and then the "
  },
  {
    "startTime": "01:03:46",
    "text": "coroner as the GUI so we collect all the metadata and and program to show the following three case at first is a delay delay monitor for each node and link and end to end we can see from this black panel yeah on the right of the black panel and his his true is a show us the packet loss monitor just the file pack his loss and the last case is a past recent insert is the left side yeah that\u0027s all thank you [Applause] so there\u0027s we do that we have the floors the floors DNS we\u0027re ready for that one and then it looks like l4s will be after that stand like this keep it tight the floor here so the floor is Dina steams so the the Dina\u0027s table was quite eclectic group of people it\u0027s like the the DNS protocol probably so we did something about Dina\u0027s privacy dinner support for specific networks provisioning and miscellaneous stuff the catch-all so the Dina\u0027s privacy work we worked on was zone transfers of TLS shot and cert so you want to protect your zone it\u0027s encrypted etc salt is the push model certain kind of subscription model I\u0027m sorry yeah as a subscript support dough proxy plugin for any web server by pitter it\u0027s a far cgi plug-in interface and means of preparations for dots and I\u0027ll invite so there\u0027s a lot been discussions on though in DNS community and about a decided everything that\u0027s choice for end-users and deployment are important so I think there\u0027s a good work that we include this dough support in "
  },
  {
    "startTime": "01:06:48",
    "text": "different pieces of software good the dinner support for specific network so DNS is kind of the Swiss Army of the Internet of course I\u0027m working dinner so I\u0027m I\u0027m have some specific view on this but also for ideal and P presented already there were some collaboration between Stephan and the ILP group to extends part of the implementation of DNS to work with an identify locator split and in some other situations in ipv6 only setting but you had it asked for a quad a and there\u0027s only a a records it has to be some middle box that has to do some translation so does the Dinah\u0027s prefix this coffee by mark implemented in bind again DNS as a provisioning tool here so for if you want to do something with any cost and you don\u0027t want to create an plus my gun for DDoS attacks you want to have an any cost open resolver with something like a DNS server cookie so you protect your open V cursor for DDoS attacks with spoof addresses this is implemented in bind and inbound and is D another provisioning thing is temporary records in the DNS sometimes like the less encrypts ACM of the Acme protocol you want to publish some info base for a short time in your dinner zone so you\u0027re the owner of a domain name for gets your certificate you have the timeout resource records after that the information is removed from your zone another important thing is the HCP s SVC it\u0027s kind of a service records and it has been a long-standing well problem to solve actually so how do you provision your web service and how do you adjust them in your DNS has been the number of solutions over the years by the DES community by the HCP community and this proposal seems to be received this wrist proposals received positive feedback from both working groups so it\u0027s a lot of interest here and there\u0027s envy sorry there\u0027s an implementation in Burma in unbound the miscellaneous gets all we did some work on llamo formats in DNS packets the original RFC is actually about Jason but their origin author of their Seif sighs well Jamal is fine it\u0027s readable and it\u0027s already in use in the proof of concept of root server measurements frame that\u0027s also wrapping up we did a lot of interrupts between ourselves between different groups the ILP group the web community I think we have done some good work that\u0027s all and these are yeah okay "
  },
  {
    "startTime": "01:09:58",
    "text": "out for us and then wishy who\u0027s the left and right thank you and I want to thank every the organizers of the whole thing as well thank you very much but low latency low loss actually it\u0027s low latency low loss scalable throughput got the name wrong this is a l4s going on in the transport area and TPM NTSB WG right a bit of background here but I\u0027m looking to dwell on it there\u0027s the where our code is all linked from and the specs we\u0027re working to had got number people we actually expected to have more nearly all remote and hardly anyone here but it worked out the other way around something like seven newcomers which was pretty good and quite a few projects we didn\u0027t expect I\u0027ll jump to the next time then I\u0027ll come back we did plan something something that didn\u0027t happen with a bunch of people remote that were all new just it became impractical it\u0027s time in India basically and didn\u0027t quite get the finishing but going back quite a few projects to brought a testbed with us God they all set up found there were problems with latest limits Colonel screwing up what we had intended to do etc had to rebuild things blah blah Richard got on well with Michael Tilson implementing accurate Eastern in FreeBSD with Michael dukes and helping there was also I suppose the highlight really was the l4s testbed we had the SC people come over and give us their um-flint where they wanted us to evaluate on it we started working together on that which will probably continue during the week that\u0027s right and I\u0027ll now come on to that we started the first scenario and we\u0027ve got the others to do also the ns3 implementation fast start was added which made good progress on the freebsd implementation which didn\u0027t exist before this got the handshake and the feedback working and the protocol to packet and packet drill and we built a "
  },
  {
    "startTime": "01:12:58",
    "text": "good work relationship with the SCE team that\u0027s we the L first team but now we\u0027re we\u0027re the L frozen SCE teams and what we learned well DC TCP behavior keeps changing in recent Linux kernels so I think we\u0027re gonna have to develop some regression tests for the maintainer because it\u0027s just impossible for us to use it at the moment all you have to keep going right back to an early version of the kernel accuracy n we now question one of the or the most recent change you made to the spec having tried to implement it so we may go back on that but we rethink it and discovered that a counter that crosses a boundary obviously we knew it crossed by boundary that just made it started thinking about cross compiling and stuff made it a bit more challenging to make sure that would compile correctly and also learned that remote attendance of newcomers that our hackathon doesn\u0027t really work yep ok thanks [Applause] okay where\u0027s the wishy here\u0027s the Machine okay thank you so this is a report from the wiki hugging activity here at the IETF hackathon so we see a work on IOT semantics and hyper media interoperability is a long-running activity at the IETF is already our sixth hackathon we are in Tingting research group but of course spanning work across multiple organizations and individuals usually our plan has been finding different ways turn on and off lights does that\u0027s what IOT is of course all about this time we had a slightly different focus here we work on two major topic one is this IOT data model convergence so reducing fragmentation increasing interoperability on the data models and then hypermedia for IOT but this time instead of focusing on lights focusing on making coffee the specifications included in particle working on coral the constraint restful application language that has been in the thinking research group quite some time and now moving to the core working group for Standardization but also specification from other organizations so we\u0027ve been working actively on the one data model simple definition format and then also data models from other organizations in part on omae\u0027s spec works like within to them and keeps our models on the datum or convergence so we use that one data model simple destination format to do data and model interchange so that format is a language that you can use to describe data models from varied of different organisations "
  },
  {
    "startTime": "01:15:58",
    "text": "and based on those descriptions you can do for example translators between those models but also able to exchange model rate model data so bring for example models from different ecosystems to your ecosystem we have been working on some automatic tools for this purpose so we have this automatic conversion of if so I with the models into SDF and we spend some time in the hackathon improving the tooling and in addition to improvements we also discover quite a few potential improvements on the SDF language itself so on the data type schema and constraints in the STF language to be using JSON schema for doing the validation of the models but also after this hackathon now we have a tool for generating CDL schemas for there for the SDF language and we can use to all the CDL tooling for that too and that\u0027s a side result of this activity now we have also a JSON format proposal for coral so you can use the use of JSON tooling with your with a color representations one activity on the data models was this binary data extraction so if you have something that is not easy useable JSON format or such you can now use these tools for extract json-ld from it we have playground deployment available on that that you can post post your data and get json-ld representations back and the other big one was proving coffee with hypermedia so of course from the days of hyper hyper media hypertext coffeepot control protocol x we\u0027d be wanting to do this now we have modern tools and protocols for this purpose so you have a carrier crate coffee machine reference scenario also known as Karstens coffee machine you can discover and describe your coffee machine discover many options make coffee selections and finally get get some coffee brewed we have now two open source implementations that use coop and coral to achieve especially the first three steps the last one we\u0027re still working on and this is the set of people who are working in our team this time we have one new first-time member mike mackool and we had two remote participants if you want to see more information links open source implementations etc you can go to our wiki page and all the information is there thank you [Applause] [Music] sorry okay I see the UM see the quack "
  },
  {
    "startTime": "01:19:19",
    "text": "okay hi and this is the report from the quick table where the big table in the middle somewhere we are also the htv-3 table because that\u0027s kind of the same thing this is our regular interrupts spreadsheet it\u0027s getting pretty crowded on so we had nineteen implementations that we\u0027re tracking most of them are both client and server each letter is a test that\u0027s either passed or not passed we now have three lines the first one is sort of the table stakes basic protocol stuff second row is quote-unquote advanced features that it should really be part of the first row but they\u0027re not sufficiently widely deployed yet that we can do that and the third row is new which is a bunch of new tests that specifically test htv3 compatibility you see bunch of white compared to what I showed in previous hackathons that\u0027s because the - 22 drafts only dropped like maybe 10 days ago so a bunch of implementations basically didn\u0027t have time to update yet so this this should this should change but this is the most remote nation we\u0027ve ever had we keep adding new ones so it\u0027s looking pretty good most of them were here a bunch of people also send engineers specifically only to the hackathon and they\u0027re not going to stay around for the ITF which is kind of an interesting development so it seems our companies find at least more benefit in hackathon and the actual standards meeting we should maybe consider in some form and so shown is a lot so I\u0027m not gonna spend too much more time on this one thing that\u0027s also new is I don\u0027t know what it shows up like this so there\u0027s a general yang guy I might can see man I\u0027ve done a bunch of work so I don\u0027t know about you researchers amongst you probably know NS 3 which is a network simulator and Jonna and Martin have worked on allowing you to define an NS 3 simulation so you can define well-defined TCP cross traffic or topologies and then you can plumb in actual Crick implementation into that topology and you can do congestion testing for example repeatable so it\u0027s kind of nice it\u0027s kind of cool it\u0027s it\u0027s early days is the first time we tried this we plugged in I think two or three different ones this is a sequence number of plus order the transfer people will be very excited because now quick starts to look like TCP you can look at this graph and you see what\u0027s going on which is hide before because it\u0027s all encrypted so this endpoint corporation you can generate plots like this this is from the simulator with one of the stacks we\u0027re using Robin Marx\u0027s tool there\u0027s the logging format it\u0027s being defined called cue log he has tools to visualize cue lock into something like this from the bottom you see like how the RTT changes that quick things that has over the path and then you see that a regular sequence number AK plot so this is exciting because finally it means you don\u0027t have to be like the look at the bits anymore in order to understand what\u0027s going on in terms of congestion control so this is very cool thank you ok if there\u0027s anyone other "
  },
  {
    "startTime": "01:22:26",
    "text": "than TLS 1.3 who has who uploaded a presentation and hasn\u0027t presented yet come up here and see me and let\u0027s go find the TCP 1.3 you saw I\u0027ve got it there TLS 1.3 I said TCP green check okay very good can you help us with the slides please happy to just say next slide okay thank you very much so breathing it\u0027s Logan from Mauritius from the southwest home team so we are based in Mauritius oh we\u0027ve done a bunch of work on TLS 1.3 SSH SC Venu dscp code point and the ITF mobile app next slide please Sotiris 1.3 our aim was to get more applications running on TLS 1.3 dscp ID it\u0027s a new code point but was just I just became an RFC and we\u0027ll be working on into integrating but into open source projects that does the ITF mobile app but we started working on previous ITF when B is the SCE drop but came up recently and when the last thing but we work on was on duplicating or c4 in SSH so next slide please so I\u0027m TLS 1.3 we\u0027ve worked mostly with good on base software packages so matter moves it says like slack alternative so the PIO was said check sm TP is another good on package but still working progress and m AI ni which is for Amazon s3 still written in go lang we added the we\u0027ve added the TLS one police report and lastly we\u0027ve got TLS 1.3 API integrated into the SP 11 port 4 and the last thing is but we are developing a c-sharp library for TLS 1.30 TLS Rock and it got refracted and it has some support for hello retry and things like that 40s 1.3 into shock so the other stuff that we\u0027ve been doing working on is DSC ple when you call point we integrated the patch we integrated it into net birth repeal was sent to open SSL and it was also sent to enough tables "
  },
  {
    "startTime": "01:25:27",
    "text": "the other thing that we worked on was we go back up as I said there are links to a screen shot and it\u0027s it has improved compared to loss ITF resin-based shop implementation of ssh that\u0027s still running with hopeful and we duplicated but lost e we work on an SC implementation for F to curdle in freebsd based on paragraph at Rodney and Jonathan were published it\u0027s still very basic but it\u0027s enough but we can see SC packets on the wire on Wireshark so next slide please so what we learned basically was open source project then to want to wait for new dscp code points to become RFC before accepting patches but spur case for ssh so we wanted to wait our c4 in ssh is mostly fading away it\u0027s mostly going away we\u0027ve not seen that many key cases of open source projects still shipping with SCE is Jeff starting so it\u0027s worth looking more into that was also over work what was going on with over SC developers and lastly go long 1.12 ships with TLS 1.3 api so expect more TLS 1.3 in software packages returning ghulam so lost side so what\u0027s basically yes we are whole team here from Mauritius we are grateful to my sponsor business cos value who hostages and visible links as well to to our ripples where we are some our results over SC as well as we could and for the ITF mobile app we have it via over that link and we also included for ILS shop flourish so thank you for everybody for listening to what we\u0027ve done thank you and it\u0027s it\u0027s interesting to see an entire project remote that\u0027s cool thank you anybody we missed okay thank you everybody for presenting and thank you everybody for coming to the hackathon and Charles\u0027s backup and thank you so much Barry for helping with the presentations it\u0027s a it\u0027s a lot to go through and it\u0027s it\u0027s handy to have have helped have a couple people Rory\u0027s welcome to welcome more help for the hackathon we also huge huge thanks to our sponsors too I can they really stepped up big as I mentioned not only for this hackathon but for the next two "
  },
  {
    "startTime": "01:28:28",
    "text": "we\u0027d really love to line up more sponsors for the hackathon because as you can see it it\u0027s always it\u0027s it\u0027s quite large and it takes all the money to feed us and have a space for us and great to see that everyone gets so much value out of it so if you\u0027re at a company or an organization that has the ability to sponsor we\u0027d appreciate that and thanks to Nova flow for helping out this time around that was great as well and thanks to all you really the champions Ally thank you for having your project welcoming newcomers we want to continue to make this a great experience for newcomers to not just for those of us who have been working on the standards for a long time so appreciate those of you who did have new people in your team and you helped them get started that\u0027s just fantastic so and thanks for you just paying attention to all the presentations they were recorded we\u0027ll have them they were live streamed also so if you missed something you can go and get it afterwards lastly if you have you didn\u0027t present anything but you still have some useful results to share please do upload your presentation to the github org or or if you want you can just send it to me I\u0027ll all upload it for you if you want to put your PowerPoint presentation there or some other format that\u0027s fine now just for up here we wanted the PDFs and I think that\u0027s it Thanks good luck with the rest of the IHF meeting and as always thanks so much to Charles for all the work he does it\u0027s a big job [Applause] "
  }
]