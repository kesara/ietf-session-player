[
  {
    "startTime": "00:00:20",
    "text": "okay uh let's get started this is a auto itfo one one two meeting virtual meeting my name is ching woo the first thing i want to mention is yeah my co-chair he got sick cannot make it but we are fortunate to have muhammad back there to be the acting chair chair so welcome matt to help moderate the discussion and so we we will have a actually code we have a hedge talker actually collaborative meeting taken to us and for a general and slides and you can get access to the link uh notewhere as euler node will tell us how itf uh is operating including idea process policy and rules and ipr and one thing i want to mention is our isg encourages all the working google chair to highlight the code conductor so for the code of conductor means you should be courtesy to the colleaguer focus on technical discussion for example topics we have a bunch of pcp if you are not a familiar please read it uh other minutes trivial so the session will be recorded uh so we'll use the media echo queue"
  },
  {
    "startTime": "00:02:02",
    "text": "control if you uh want to speak please enter in uh into the queue by press the red handed button if you want to leave the queue please have a second click the wrist hand and before you speak please unmute yourself and after speaker please mute yourself uh for audience uh especially you can mute your video stream and we also have a jabber and it will be served as a slider uh comments and we'll keep track of the side comments and if you want to speak before the mic but you cannot make it please put at mica and we will forward the comments to the meeting room and the blue sheet we have electr electric blue sheet so your antennas will automatically record it and notes taking we have a kodi med code called md and the hedgehog talked to us and and i i think we already have agent and daniel have to take a minute if you want to add additional minutes feel free to do so and so this is a channel for today's discussion so the agenda is very tired uh first as a chair we will introduce the working status because we have our new channel get approved so thanks marking and and especially want to you know highlight the two working group uh document styles update because there's some open issues that need to be tracked we want to make sure all the comments are just and for today's discussion we'll focus"
  },
  {
    "startTime": "00:04:00",
    "text": "on charter items we have two charter items the first one is auto om support and json will lead the discussion the second one is auto om over http 2 and richard will lead the discussion and also we have a deployment experience update we receive two different updates one is from g2 the second is from flow director and uh we actually have already have a discussion with team so kait will introduce how g2 is integrated with auto the second is flow director the daniel will give update of flow director and hopefully this will be good input for auto deployment and after that we'll have three long chat items the first one is also as itf network exposure function the leader will be the lewis and the second is compute aware network use cases will invite the leopong to introduce these financial new diploma use cases the last one will invite uh leo zu jung from london university to introduce bandwidth exclamation on opennet lab after that we'll wrap up the discussion and agenda bash okay let's move on uh actually we uh we could work remotely we are already familiar with walker remotely but i want to mention highlighter three since the first we should utilize the meninist so usually the consensus is judged on the menu still we today we have important discussion in this meeting"
  },
  {
    "startTime": "00:06:02",
    "text": "meeting and informal meeting and under early the working decision is made on the menu list so please uh actually start it's important to actually close down the topic and to show the the topic get it done and also it's important to start a new topic so if you have any new idea please publish your document and make an intro and a summary of what you do on the list and begin the discussion on the list and also for the next itv dave meeting probably we have hope can have a mixed meeting both online and in person but it hasn't been announced yet but let's stay tuned and last uh and we have a online meeting and also we have informal meeting uh if working google think we need to uh have these kind of results working with chair can arrange this kind of resource and so this is a auto working charter so we for this channel we actually have two important delivery one is auto om the second is auto new transport in addition we can cover uh the auto deployment update and so we uh we also can explore the use case and protocol uh maintenances so you can see we have three deliverable and so for the auto deployment challenge we have documented in the wikipedia or internet draft"
  },
  {
    "startTime": "00:08:01",
    "text": "and we actually break down the chat item into several categories and you can see the first two actually we already have a relevant individual chapter so this will be our uh focus of this uh agenda discussion and we also have a a long channel item actually has a bunch of draft hopefully it will serve i could improve to the order different update and we also have information uh development tracking so you can see actually for clan we have two implementation server we have four implementation if you have been aware any new implementation please let us know and we'll update this week page and this document update we already have four working with draft uh actually ready for ietf isg telechat arrange it at the december 2. and so today we will discuss the two documents who which actually has some urban issue so that's it let's uh move to the first topic uh i think it is a gokai hello everyone uh this is guy uh so ching can you share my slide okay go ahead okay so uh this is a presentation about the open issues raised in the last core reviews for auto pass factory extension so next slide please"
  },
  {
    "startTime": "00:10:02",
    "text": "and for uh jane art and art art uh let's go reviews we have uh both gives the uh some minor issues and for the reviews from ops dir we actually uh had not ready so uh so the main content of this prediction will be on the uh reviews for the obs dr so next time please and for uh art art and junior arts we actually uh most of the issues matter or need issues so from the other we have one issue is the use of current id uh does not conform to a previous rfcs and also the second issue is uh we need ipv examples for ipv6 so next slide please and we have a major revision for the first issue basically the use of kind of ids in the last revision and we defined the format to be compatible with rc uh 2003 87 and 532 and we also had revised the protocol specifications and examples to accommodate the changes for the use of content id so next time please and actually we most of the open issues comes from the review from ops there and we have classified them into four major issues the first is uh the reviewer asks for more use real use cases and examples to better clarify the extensions in a document and also there are some concerns about the clarity about the concept of extra natural element and then there are some terms that may not be very uh cleared then may uh trigger some like"
  },
  {
    "startTime": "00:12:00",
    "text": "ambiguous meanings and the last is uh the reviewer asks for some examples that uh the past vector can be used in practice so let's please so this gives the uh review for the first issue so basically the reviewer is asked for uh argues that in the uh 17 version of pass vector and the use case section does not reflect real traffic steering objectives of existing systems such as the lhc project and also some specific examples of are needed to show real use cases and also some discussion and examples for identifying bottlenecks are needed so next time please and in the in our latest revision we actually uh have uh introduced more detailed uh examples about uh how this extension can be used in practice and the examples are extracted from uh existing systems that uh where we saw that where we believe that this extension can be used uh or be integrated into such these systems and uh for details about these examples uh please refer to the latest document so next slide piece and the the second issue oh implement and we also uh oh sorry i i don't see screen so well which side is this a page eight right yeah page oh okay uh and uh the second issue that some specific examples of anees are needed to show real use cases so we actually"
  },
  {
    "startTime": "00:14:00",
    "text": "give the example for example how for the example for the use cases that we presented in the last slide we actually also list how the different network components will be considered as anes in a specific use case and we also refer to these use cases to their like research papers or other materials so next time please and to address the issue of uh identifying bottlenecks uh we actually uh first we point the array studies so the people so readers of the document can refer to these uh research papers to understand how uh the bottlenecks can be identified and we also uh put some use uh put some use uh actual concrete examples in the document to show how pass vector can help expose bottom information so next time please and for the second open issue basically uh the reviewer asks for clarification examples for abstract editor element so first we give you some examples in the use case section and also when we specify the meaning of action network element we put another example there to show that uh different uh objects if they have the same property then they will be triggered as like equivalent uh actual error elements to basically to give a better sense of how different neural components can be uh can be considered as those basically why we use the meaning of actual network element to basically show some uh common properties of different physical entities in the network so next slide please"
  },
  {
    "startTime": "00:16:07",
    "text": "and for uh like some terminologies that uh the reviewers might uh might find ambiguous we actually revise these terms to avoid ambiguity for meaning so next slide please and for the last issue basically we need to give some pointers for how the clients can use this extension to orchestrate their traffic first we also give some examples and pointers when we demonstrate the use case and it is emphasized in the documents that auto is only used for information exposure and traffic steering is done by the application okay can you wrap up in one minute yeah sure basically i think the next page is basically a summary of uh well what we have done in the last revision so issues from the last call reviews are addressed as uh from my understanding and we are actually waiting for the reviewers feedback and uh it will be so we have one question for the working group is uh how do you suggest that we proceed with this document so actually marking up thanks um so to be clear all those diffs that you showed are present in the latest version of the draft yes yes uh i think these changes are already in the 19 version uh okay excellent version 19. this is the latest one okay good i just wanted to make sure that the iesg um has it um it would be it would certainly be nice if the last call reviewers responded to your changes but um i don't view that as"
  },
  {
    "startTime": "00:18:01",
    "text": "necessary um the ads can the other ads can do what those can you know judge whether or not you've addressed this so i i think we're fine to proceed to the ballot which will happen yeah i see i mean by all means if you i believe you have already but email the reviewers and say hey we made these changes please look at them um but yeah i already send them the emails yeah but i didn't get it fair enough right but we're not going to block on last call reviewers being responsive thanks okay all right thank you okay yeah i think that's all for the talk thanks jim okay thank you let's move to the second topic richard so let me share your slides yeah thank you here you go okay can i start yes go ahead great yeah and uh for the performance metric uh uh document we received the uh gen art review from alvin davies very very nice review and then we also got the art out review from christian amstels and they are also very nice review the main changes was to uh address the uh reviews and there's one remaining thing which we have not really confirmed yet but i'll go over what it really is okay so next slides please so here the main thing we changed and to address the gen art and art art reviews basically we made the changes from version 17 to version 19 and would be number one is mostly clarify the definition of cosmetic string mostly came from the review from christian and also of course clarify the ina considerations from from ad from other reviewers as well and then the last one"
  },
  {
    "startTime": "00:20:02",
    "text": "in terms high level structure is ongoing discussion with the uh the general review albing and mostly about is cos context parameters if you want to get a little remainder and the cost context parameter is on the lower right corner so that's one uh which we're still trying to really really reach the final the final decision with with uh alvin uh i'll go over a little details but that's those are high level changes we made so now let me first uh went over the first first change which is triggered by the review by christian and main issue here is he wanted to clarify the grammar so if you look at it and in the early in an earlier version we give a formal grammar which there's all these email changes of course pop pop game exchanges uh we use some kind like a grammar and then the discussion of suggestion eventually from a question is maybe just use some kind of english english description about what a cosmetic reading string really is and we agree with it because we looked at the authors looked at the multiple ways to specify the grammar and everyone looks like slightly more complex than necessary we're not really dealing with a very complex grammar which is dealing with what exactly the format of a cosmetic screen really is so eventually uh we adopted the paragraph which shown over here of course it is in a newest version so the definition basically is uh optional uh base metric identifier of course valuable everything in quotation means they are the real text and would be base a metric identifier followed by an optional statistical operator string that's a new term but of course only editor not content change and then i think uh their discussion about using dot uh call eventually decided to really adapt column because the the review set would be look you already have pr iv column and so why don't we use essentially my"
  },
  {
    "startTime": "00:22:00",
    "text": "understanding our understanding is why didn't just do the same thing so therefore we adopted that small change from uh the previous version now become like a column so therefore if you set examples it becomes delay one way and delay one way column mean mean and delay one way percentile 99 so that's only one change and also the same review comment by a question is a discussion about what exactly how to specify which statistical operators you want to use for example what if it is a maximum reasonable bandwidth you already have a max and which one is a good metric so originally we recommended using pakistan and having these questions oh god too slow you have one minute oh one minute oh okay so basically i think in this one address i don't uh we're pretty happy about it so next next one please this one is the ina consideration and we add all these paragraphs an input we clarified from the review that for any new value or cosmetic and metric proper metrics you must include the three things identifier intended semantics security considerations and that part also address we think we're pretty happy about that please next one please so the only now or the only opening issue is how much information we want to really give to this uh uh the one the parameter field which is the the inlet right uh uh uh like a rectangle and the main issue i think i mean review comments and uh that one from general from from elwyn is how much do we want to make this one to be machine readable so therefore the current version is we're using json value and i think the working group early discussion was let's make it opaque but then the discussion from the reviewer is how much you want to make it to be machine readable i think that's the main issue we did talk about it and to really answer this question uh you we really have to ask ourselves what exactly why machine want to read about it and in"
  },
  {
    "startTime": "00:24:01",
    "text": "which sense machine want to read instead developers would read about it and there's so therefore we talked about there are essentially two cases you might want to machine to be read number one is whenever you have for example look at the estimation the rightmost column and you might want to tell them which estimation also you use to estimate one-way delay and t-space report and so on for example later today you will see kai and and talk about the g2 work which uses maximum fairness which is a sitcom paper and i believe trying to be deployed in uh yes net and so on and of course also can be using for example in the conversion we talk about using profit so therefore one way is maybe really index to talk about uh it is which method you use the second way we identified and how much one making machine readable is maybe one keep some kind of detailed parameters for example when you are marrying for example lawsuit you're marrying every 10 milliseconds instead of every 100 milliseconds or averaging statistically of course i mean you were given long-term value but the measurement itself examples might come from so some parameters so overall thinking about this one we still believe a generic link parameter is probably the best way to go so therefore your application would be even okay and i get like for example what measures you are using and which are the parameters and we can get initial deployment and then if after we have some experiences we will work with eventually i think we can upload some of these work to this uh uh the bits of 79.71 and auto deployment so eventually if like some kind of very public way to specify those parameters can become public and we can we can make them into the deployment considerations instead of right now holding on this particular way because earlier working we did talk about this one for a long time so we're waiting for all of you right right yeah yeah we we were we're we're still waiting for the feedback from erwin and well i think we'll ping him again and we won't discuss hopefully we can reach consensus as soon as we can"
  },
  {
    "startTime": "00:26:00",
    "text": "yeah that's a backup slide you can go back okay any comments from audience yeah mighty machine readable thing um you know we talked about this during the ad review prior to that and um ultimately yeah there's probably some value for debugging and i could imagine a particularly power user like looking at the stuff and deciding if an alto server was like good enough based on what the admins were but ultimately for this to be useful um at all you have to have like you have to write scripts that say ignore the results if like if i'm unsatisfied with the criteria so that implies you know a registry and all that so it doesn't have to happen in this in this document um it's a little late for that but ultimately yeah it doesn't have to be a long document or a bisp but just something saying defining your registry and then i think that's what this has to go for it to be worthwhile in the long run yes exactly so imagine the target gallery all the time i talked about already in my new latest version that's the only one where's your ongoing discussion but we're not making any changes on the target yet great okay okay let's move to the next topic i think it is jason okay do you want to share slide by yourself or okay uh let me slide two minute size you need to use like one okay so this is presentation for the new items about the the young design model for the auto oem"
  },
  {
    "startTime": "00:28:00",
    "text": "and apparently still already work and we try to summarize the uh what the scope and the requirements for this work and we give some initial proposal for the current model and we have many open discussions in the mailing list in our previous meetings and the main goal for this work is we try to define the yandere model for the operation and the management purpose for the autofocus because this is the uh the blank part for the auto working group we already have some extensions for the realtor services but we don't have any uh standard for the operation and management purpose and the main reference we make this work based on the the rfc about the base protocols and the department considerations the latest version we already upload to the drivers but because we still have many discussion uh online so we have some quick iterations on the github so if you want to check the latest version you can go to github to check the latest one and this table will give the base requirements we summarize from the the base program rfc uh so we think uh this this summarize the outer page requirements like uh in this work we're trying to support the configuration for the auto server setup we define the management information base just for the communication for the data cells the [Music] information resource generation algorithm and the access control at the"
  },
  {
    "startTime": "00:30:01",
    "text": "performance monitoring and some conversation for the security policy management but before we go into some details uh i want to make sure uh so i'll make clear what is the scope in uh about this work so i think uh in the scope of this document we should suppose we should define uh audit data model for the the auto server of the client operation and management it depends some data model for the functionality of capability configuration for the different auto services we also need to define the performance monitoring for the operation purpose but but it's not in the scope i also want to make it clear so in this work we're not trying to define any data models related to any specific implementation so for example a try not not trying to give any specific data factor uh about how to store or how to deliver any auto information resources like the network map because micro probably might find some other information resources to find the extensions also we're not trying to give any data model to define a specific algorithm about how to generate the auto information resolution also we are not trying to define any specific data structures about how to store the information class from the different data sources so i'm trying to make it clear this document at the beginning so now so based on the this based requirements"
  },
  {
    "startTime": "00:32:03",
    "text": "uh make the objective in the document earlier uh so in this document we focus on the uh these four main objectives so we support the configuration for the auto server setup and provide the configurable data models for administrators to create update and remove the alt information resources for this part issues both the different types of digital sources it can allow the developers to argument the new apis we will not try to define any specific algorithm but we allow developed argument data model to start their own algorithm interface to generate the auto information cells and we also allow the the future new extensions uh kind extend this data model to support the new information resources in future and so this data model also includes some statistic information for the performance monitoring and the security policy part but uh the current version of this document only we only have the this our current progress we only focus on the the second and the third part of this article list so our current initial proposal focus on this toolbar so this is the current the initial proposal for how how the operator can use this data model to create an"
  },
  {
    "startTime": "00:34:00",
    "text": "information result and the operator can model to [Music] specify a new uh information auto information results like it can define a new auto information results by specifying some common parameters like what's the resource id so let's type out this the ultimate information resource some based exact same code the dependency about this uh information results and some other informa also information results like the cosmetic dependency depend on another network map and also for the specific information source it can specify some resource-specific parameters and the main part is that you should specify some kind of creation algorithm and this creation movement is provided by some other developers it can augment this model like uh let's give an example like we use the [Music] layer 3 unicast class algorithm to generate a network map from some other data sources okay and the operator can import some different kinds of data sources from different particles the pgprs the authorized data the pce data and some other network management data and for the data source import uh the the operator can specify"
  },
  {
    "startTime": "00:36:01",
    "text": "what's more to retrieve the data you can use the reactive approach like you can use some types of mechanism i will just use the proactive pulling mode to press practically to get the data and for the different there is a purpose that could uh if it's a uh date from the enterprise can use it maybe get from the young store and now it is a network management uh information it can data from the some other network management system like the promises and some other devices so for the algorithm uh we have some examples proposed by the different other individual stuff like so this one gives an example how to translate the advice server to the network map and i also have some use cases i could can translate some some data from the experiment to the smp devices to the property map and also we have have an example to translate the pcbrs information to the map and cosmetics create the reality auto information resources and for the statistic"
  },
  {
    "startTime": "00:38:03",
    "text": "in the deployment consideration uh i've said it suggests some it already suggests some memory information should be spoiled by the author cover like a it should support some application performance information and some system and service performance like the request response for each information resources and cpu memory addition they also map update the number of pds and some other like the automatic sizes but we also have some auto extension like the the coscanda the sse the unified properties so they all have the different membrane information also be useful to be collected by the auto server so this data model will cover of this information but uh where we still have some uh as a missing part uh not covered by the current model uh they will be considered in the future versions like the how to configure the the server libraries and how to support small uh the data source recruitment mechanism and some uh partial communication support and more options for the integrated policies also have some discussion on this verb and the data model for lifecycle management and following uh the first steps try to summarize some main uh items uh the generates from the"
  },
  {
    "startTime": "00:40:03",
    "text": "the online automation is discussions like uh the secretary proposed some comments like does this document provide any generic network models like the dysonic ici as well from google papers we're trying to actually the generate network model is not in this gobot document but we did try to uh define some common interfaces to connect the auto information results to other uh ultimate results and the related data source so that we think this can be useful for this document and also to try to try to understand so how to understand the head-based interface for the information resource creation so it's not make the decision uh we use the internet based in the security interface should be intent based but in this document we try to make the [Music] in this creation interface be reactive like if the operator configures connection between the information resource and uh some data sources it's a tesla change that means the the created information results should should be a mathematical aptitude and also because in the early version we separate the data cells import to the internal data cells and eternity cells but in the latest version we remove this part we think we think they we don't need to differentiate the different types of the"
  },
  {
    "startTime": "00:42:01",
    "text": "resources we allow the developers to argument the community model for the testosterone how to connect to the different specific data source also is we think this is the important part so this is still i'm going to work i also sent some many english classes with uh like how to support the server discoveries and uh how to support the livestream management and the performance ring and how to integrate the demon conduct data sources this part well i also have some discussions in the mailing list and finally internally also have some discussions about how to define the gene model for the auto clients on the side because the current the model only focuses on the auto servers but actually in the scope of auto client conversions also in the governance document but [Music] in clarify actually use cases who will use this data model to categorize the auto clients not uh it's not useful for all the auto clients but for some specific use cases like the network application integration cases of the multi-domain case they may be useful and also for the security part and the the performance modern version uh you know and also give some comments about how to refine this currently this model without thankful the feedback from the"
  },
  {
    "startTime": "00:44:00",
    "text": "unlimitings and the mainly list and if you have any other feedback let's welcome to email to the working group and see there are others and also you can you can open the issues in the github lcd time to reply to you so yeah we're looking forward to reaching out your feedback okay thank you jason and so thank you for chemist welcome actually a good summary for the discussion on the list and offline so i think uh so i think this work is very important worker in the charter so which is the missing part in auto deployment rfc so therefore this worker i think should closely align with auto deployment rfc and also other protocol worker so first step for this work i i think we need maker we need to make it clear what is in the scope what is our scope so uh so i think that there's three most important part one is information source management second is data connection data source as served as infrastructure monitoring so you already touch this but i think this need to be further cooked so with this any other comments from audience richard go ahead um martin first i'll hide first i think yeah you can be first okay yeah just let me make sure follow the cue very quick question uh one complexity of uh outer server configuration is the algorithm to compute the network maps because that's oftentimes a foundational service so"
  },
  {
    "startTime": "00:46:02",
    "text": "but oftentimes that will be very algorithmic not like declared using for example like a young model so what's a long-term solution for this one you want to address in this effort om effort some some can be declared for example declare any network node is for example every autonomous system is one or every federation or for example if you model a data center which is one thing i'm considering then that potential can be declarative but overall most will be algorithmic so how how do you plan to address this uh i'm sure i understand question credit so but we're not trying to yeah let me switch to the the page maybe page four uh so i'm i'm not sure if you are talking about uh so how to organize the data to present the auto information results because because uh we only focus on how to uh give the interface to create the transmission but not how to store our delivery data like we mentioned the network map i'm thinking of oh you collect data but you need to specify a way if you're doing a management and probably you want to specify how these multiple types of auto network maps can be constructed so somehow the in some way should be specified in some way to make a good manager at the same time specification can be very common okay yes you may maybe all right uh [Music] this part uh this is the missing part in the current model but uh i'm not sure if"
  },
  {
    "startTime": "00:48:03",
    "text": "because i think it's more like the implantation specific like the yeah the oem system should consider how to implant the the data management if you collect the data from data sources how to store it and how to query and translate to the so i suggest to take it to the list yeah so martin yeah just very briefly on the alto client thing uh look i'm not an alter protection practitioner so i don't have the answers but um uh i i just i just think that certainly that's a good separation point and uh you should really think i don't know whether there's an actual use case uh particularly when you're talking about you know inter-domain stuff that isn't even specked um my my instinct is that that is that is maybe not something worth putting the effort into thanks okay thank you so let's move to the next topic richard so given the time limit actually i want to ask you maybe you can limit your presentation to 10 minutes sure i will so just make sure you have my latest slides right oh wonderful yes just i made some edits i don't want to can i start yes okay so i'll talk about auto transport uh that's a charter item and uh right now there's a small team of people uh roland and danny and the check so we're working together we're discussing about auto transport of course the long-term goal is to provide some kind of one whatever to address the working group uh the charter item which is auto transporting new protocols but overall we actually take a slightly broader uh from a fundamental uh approach to design the auto transport of course this is only one one smaller team right now"
  },
  {
    "startTime": "00:50:00",
    "text": "other people are giving all the feedback but currently that's a really like kind of result from this uh uh for four person team next slides please so the high-level goal of to really address this working group charter item we decided to actually do a slightly more systematic approach we're not designing anything new because before we really design anything new we decided we should have systematic approach of course long-term goal or the the ultimate goal for example by next year is really try to push for the deployment not really design something super fancy so we should address real issues therefore the auto transport uh conflict we focus on lately focus on the following four items number one actually is analyze systematic analyzer of the transport workload if you want to talk about transport you really understand what services and what the requirements of services we're dealing with before we talk about we design a hb2 or h3 and then after we have the workload and then we want to really very quickly start to really set up the environment and to evaluate the performance and effectiveness of current auto transport input on the biggest particle using http 1.1 one point x and then also rfc 8895 and auto sse therefore they want to develop we want to benchmarking understand where exactly the weak points really are and then we also get started to talk about the design and benefits versus no benefits of integrating the new transport for example gb2 off three into the auto transport so therefore we're getting started which will we have some initial efforts but that's actually a part of the effort as well and then finally of course this one is absolutely not in the charter but we also think i thought it'd be quite interesting that when we are designing the new transport using http 203 and also take a look at the transport or genetic transport of network information to application transport so what exactly other transport are doing so therefore make sure our design would fit into the bigger picture or at least be comparable and then we can use other"
  },
  {
    "startTime": "00:52:01",
    "text": "people design as well so therefore those are for for high level goals we're working on and now let me go to the details for every single one of them so this is the first line of work which we did and lately i think after the charter is approved so basically what we did was uh we had this uh of course there's a much longer version but here is we don't want to make the slides to be too busy to read here we have we did a work of listing all the major auto services for example if you look at the live column the app and the most column that's a list of all the major auto services which we think we are dealing with from beginning of course you private information resource directory and you have network map you have a custom app and a future map endpoint a property service and endpoint cost service because calendar unified properties perspective they're ongoing i think they are getting somehow to any point and cdi capabilities and footprints so those are the services the second column gives us the design so what kind of input we do and are they really get service or post service and if it is get a post uh service uh basis design and what kind of input do we have and what kind of output do we have so what encoding it really is and so on so therefore that is a second one we analyze and then we talk about cell phobia okay what exactly is data structure because oftentimes transport depends effectively oftentimes depends heavily on the dependency on the structure on a query and so on so therefore because we classified uh all these kind of different services and what kind of fundamental data structure you're using for example network map well let's take a look at the cost map the third third row it's a basic input information structure and it's key by the store fundamental but in an increasingly that auto was designed and based on the historical design of rc7285 it is a three level of key value store and you index from source network map to the next to the destination and then"
  },
  {
    "startTime": "00:54:02",
    "text": "index into the values and this one will be dependent on network maps so therefore to be dependencies with other information models so therefore how to handle this and then we analyze the scaling of the uh each information resources how much data we're talking about for example here let's look at the even the simple one let's look at the network map for example and we did some analysis we said oh okay the size of this one will be proportional to number of cidr uh because that's where you group a network and therefore we did some initial analysis for example even for a very simple one let's say for example you want to model global internet you want to really agree everything together and if you don't do for example aggregation and you want to transport information then we're talking about 866 that's actually which is already 170 uh uh cidrs we're going to transport for the global bgp prefixes so therefore that's the size we're talking about and about like a 900k or 800k of addresses so it'll be huge if we want to really address it in that way then we analyze the transport and oh for me yeah i i actually i don't have a lot of slides so next one we talk about what okay and what kind of stability expectation oh can you go back okay i'm not done with the previous slides yet because that's important so next one we also start to really analyze the stability expectation of all the transport so for which one will be stable we anticipate of course different deployment can be different some one can be dynamic and then we talk about if you really do you really it's not stable and what kind of incremental changes you have for example red column showed the potential operation when you support because they have different implications on on scheduling and also on the capability of transport as well as on efficiency okay next slides please next please okay so giving us analysis of all the services which is very nice and then"
  },
  {
    "startTime": "00:56:00",
    "text": "this is our current plan effort before we really do the design we won't get initial results so therefore uh uh danny and i and and roland and friendship will start to talk about it so right now our decision is we're going to first step actually is uh evaluate the current transport efficiencies and also provide initial like benchmarking like token services or auto services so therefore this moment uh it's very generous binox is fully open to use its infrastructure as evaluating environment we can evaluate all kinds of transport and the greater big network which is like a quite large network covering uh hong kong shenzhen about 13 cities and also open to use its infrastructure to evaluate all the transport and also as a way to model their networks for example then for the very basic one about transport we right now decided to deploy uh five benchmarking services you can call like some kind like a auto transport spec so for example we filter the cost map and endpoint unified property map and cdn node because there are cd nodes inside the network and we model them as well and then we do flow detection direction based on the flow director and pointing to the cdn nodes and then we also uh deployed the passive vector providing available reservoir bandwidth for for all the networks so therefore actually we're really trying to use them not only to do transport but also model those networks by themselves in particular agreed to be a network it is a relatively larger network and then we're going to evaluate the transport oh i have two minutes so transport one is one point x of course keep alive and two and three initial design and then we call auto sse and then the right hand side the last column is collecting matrix for example what can metric one collect i want see sort of what we can compare with different transport next slides please so here is the initial design and initial of course it's a really benchmarking initial design i don't want to say this is in any way or form uh uh"
  },
  {
    "startTime": "00:58:00",
    "text": "finalized design at all so therefore where that's the initial design about uh design auto transport using hb2 now three and only two so the left-hand side is the auto sse which rfc8895 and initial current design is based on that design but we want to move this one into the right hand design which also auto record right now we call auto h2 and http 2. so therefore basically moving a lot of control channels and so on into the http 2 design next slides piece so here is a list of requirements and so basically we want to use the same uh all the resources possible using this design and you can do addition or deletion and you can signal this start or stop it's you know like what auto ssd can provide already and of course very important part actually challenging part is r4 how to do incremental updates and then we also talk about it yes if we're doing http as the transport we want to make sure we follow all the semantics and so on next slides please so here we main design issue is that okay i'm running i only have 18 seconds left would be how do we really encode incremental updates and because really uh one very nice design for ssc from all the features and so on is we allow you to send all real information and you can do json patch you can do json merge pack it's very flexible but how do we really encode it using uh http 2 next slides please oh so that's the initial design so therefore here is a list of initial design and the initial design one is incremental update stream is equal to single http stream so therefore we do essentially now we have a content indication layer to encode what kind of content type you really use it and so therefore one way is use exactly auto sse sort of reason possible or we can design a very simple uh content layer the second one of course i think that's really one suggested in rfc 8895 section"
  },
  {
    "startTime": "01:00:01",
    "text": "3.3 is for every single update we open a new gp2 stream and which one will be good and so on but the major problem here is we might be violating the approach promise but overall i think that's from hdb2 meaning they are really not designed for portrait notification or increment updates they're mostly essential like prefetch designed for web page prefetching of course we can talk about option of http 2 extension next slides please yeah so this this one basically says that's also the the space we're serving in uh we will take a look at that actually auto is one of the efforts in ietf the sending network information application and also itf has effort of rfc 3168 to send easy end there's also effort for example from 3gpp i want to make sure our design will be compatible or as much as much matching as possible but that's of course the sidewalk we're also focusing on early part i think that's all and then i'm willing to take questions as much as i can okay thanks richard martin sure yeah i i read the draft um i was a little confused on where you were going with it and which maybe is appropriate for an initial shot so thanks for that i i do um uh well i was finally you know as an introductions talk about um multi-streaming headline blocking and stuff like i really we don't need to write a specification for just taking existing like 72-85 requests and responses and putting them on on multi-streaming um i i that's that that should not be a focus of the spec i think we need to look at um things where you'd actually modify the mechanisms and and you know you alluded to that with like the push versus sse um and by the way as a comment like h3 is push twos that that that should be you don't need to treat hd as a separate thing the only mechanism i could think of that isn't there is priorities um i don't know if you would want to leverage priorities but"
  },
  {
    "startTime": "01:02:00",
    "text": "um we do we do for example they have dependencies and we won't even use all the dependencies for example we need to reset allocation exclusive new stream and so on so therefore we want actually we do one because like a class map and network need to depend on so the allocation you want to give resources that dependencies you want send send updates to network map before this map otherwise it's just increasing the property yeah it sounds really going the right direction i just want to steer you away from writing a lot of text about you know just taking 7285 request response and putting it on h2 because that should be seamless um and just focusing on really what the new apis are that h2 and h3 give you uh because that's what needs to be specced out thanks sure definitely great thank you okay thanks to rich richard so let's move on to the next stop yeah i think it is a gokai we talk about g2 so gokai do you want to share slides maybe you can share a slide i'll just say it next oh so does everyone see a slime now okay okay i just seriously oh so hello everyone uh it's me again so uh today i'm going to give some uh update on uh our uh integration with g2 system and i think uh as they have some like uh ip issues so probably we are more focused on what kind of services can be provided with it with this system instead of how they are being realized inside their framework so today uh basically i'm talking about the bottleneck service with auto and so next slide please"
  },
  {
    "startTime": "01:04:00",
    "text": "and in this talk basically we cover like four aspects so first we give some uh basic concept of the bottleneck service and we give some use cases of how this information can be used by applications to better orchestrate the traffic and then we give some basic information about the g2 optimization framework and then we give some immature designs or basically some uh some evidences that we want to make to integrate the spawning service with auto some examples and uh so here we basically give an overview of what the bonding information as a serp basically we try to argue that the bonding information can be provided as an out of service i think here are some uh a few points first is many networks use dynamic resource allocation to improve natural utility for example uh in networks we basically use tcp as congestion control to allocate like bandwidth resources and the tcp congestion control is actually uh you can be modeled as one of the optimization problems that dynamically allocate resources based on uh like different attributes and also we uh now many like cloud platforms or uh orchestration systems they basically uh manage the resources of these infrastructures using dynamic resource allocation for example in a google's uh web optimizer uwe system they actually use uh some some form of maximum fairness to allocate the resources between different flow groups and the uh buffalo information is actually important for applications to predict network performance and also get guidance for the traffic optimization process in such networks basically we need some examples"
  },
  {
    "startTime": "01:06:00",
    "text": "including throughput prediction and also optimization for time boundary flows uh by region limiting the application's own flows and also uh g2 papers also talk about like use cases such as network planning but we do as we want to uh argue uh we want to find that the common service is provided by partnering service and the auto service so we will be mostly focusing on the first two use cases and i think the last inspiring service can be important motivating use case of auto uh we already had the dual system they already get a lot of some initial resources and also software development and even with some simulations on electronic simulators and i think they are actually moving towards some potential deployment in networks for supercomputing or software defined uh web optimization and i think uh so this service can be valuable for a future deployment so next time please and uh here actually are some uh definitions for the bottlenecks so uh the first is basically the the dynamic bandwidth allocation can is usually based on some optimization problems for example for maximum phase we can the the system is trying to maximize the minimal uh flow allocation for the traffic in their network and in the general sense we also have uh many for example tcp can just control the actual adequate resources based on some unconstrained network utility maximization problem and for these problems we can basically have some formal deviations of the bottlenecks and uh if we describe them in english they basically if we it can be implemented as if we increase the capacity of the links then the"
  },
  {
    "startTime": "01:08:00",
    "text": "rate of the flows can be uh increased as well so basically uh that's a uh an informal definition of the bottlenecks so next slide please and here we actually uh have an example of what uh what leg links looks like uh assume in this network we have like two links l1 and l2 and we have three flows f1 f2 and f3 and if we if the network is allocating resources with our maximum fairness then we act we can actually uh using the definition that we just introduced we can see that the bottleneck of f1 is actually l2 and bonnet for l f f2 is l1 and bond x4 f3 is l2 so next cyclist and the way uh waste the the analysis we just made and we can actually draw a graph of the bottom x between the links and the flows and for these for this for this uh but for the for the network we just described it its bottoming structure looks like uh something in this page and uh we can see that uh the directions of the for example we can say uh out if out if an edge is pointing from a link to a flow basically it describes that uh this link is a bottleneck link of the flow and if a flow is pointing to a link basically means uh the link is not a bonnet of the flow but the rate of the flow would have impact on the links failure of the other flows and with this structure it enables a quantitative analysis of bottom techniques or flows over other flows so next slide please for example if you want to"
  },
  {
    "startTime": "01:10:02",
    "text": "answer the question of what happens if the capacity of l1 is increased by a small amount of traffic like delta and exactly so we can propagate this change along this bottom leg structure and we can see that okay if we increase the capacity of l1 then the rate of f2 can be also increased [Music] and exactly and another type of question is what if we increase the uh what if we decrease the rate of for example f3 by delta and first uh with the with the bottom net structure we just described if we decrease the uh rate of f3 the bottom extraction actually changes to the structure in this page and next up is and again we can analyze how the how this uh rate change can be propagated along the spotlight structure and we then we can analyze uh how other flows might be impacted by uh this uh this this change we just made so let's start this and uh with this there's a with this bonnet structure we actually can analyze so the first use case that we can provide is provide a throughput prediction service and in this service basically the application can specify a set of flows and then the server will uh will be able to answer uh what is a predictive throughput for this set of flows in the network so next slide please and basically here is a complete example of the simple prediction service so assuming we have three background flows f1 f2 and f3 and a client wants to query the rate for f4 before even establishing the connection so the"
  },
  {
    "startTime": "01:12:00",
    "text": "server uh will be able to uh the server is to monitor the background flows and then uh so next slide and the network the auto server basically can add the new flows to the network and then analyze its bottleneck structure and with this bonding structure it will be able to predict that the rate of f4 is actually uh is uh 0.67 actually like uh 2 over 3 uh for example megabit per second so then it will be able to answer the uh this uh super prediction service so next time please and another use case is for example uh in the judo paper they should describe the case where you want to uh speed up a certain flow but you can only rename it some flows with no uh with smaller with lower priority and then to enter this uh to uh to be able to solve this kind of problem uh you can also use the bargaining service so next time and for example uh assume that the uh application wants to optimize the the rate of f5 to be 0.8 and it can only written emit flows f2 f3 and f4 and then you can for example query the auto server and get the response as the next page and so for this query it actually uh if we return the if we look at the flow gradient uh epoch structure then we can see that uh uh with this bonding structure they can we can actually derive how different flows would impact the rate of the target flow and basically uh we list the"
  },
  {
    "startTime": "01:14:02",
    "text": "values on the top and from this uh page we can actually see if you if we can if we rate limits the rate of f2 it actually uh does not help us to increase the rate of f5 so in in this pay uh with this information the application can choose to reach name it r uh f3 and f4 so next circuit and again uh when we try to re-limit f3 and f4 then the bonding structure will actually uh will actually uh change and with this chain with in this new bonding structure we can actually uh get a quantity of analysis for example the old rate is 0.5 and we want to increase the rate to 0.8 and then we can actually calculate the data using the information and then we get the data should be 0.3 so we can uh so next time please yep so uh so basically we just give uh these two examples uh to demonstrate how we can use the bionic service to solve like uh flow scheduling problems uh in the application and here is an introduction for the due to work because g2 is the application framework that based on this quantitative theory of bonding structure it develops some efficient algorithms to compute the bonding structure that we introduced and and also they give some examples of how you can conduct application layer optimizations for their own flows with uh in networks with maximum fairness and i think the geo work is getting a lot of attention in both academia and industry and they are actually uh they have some ongoing deployment efforts in both like supercomputing networks and also with uh data center networks so next time please and here is a some examples of the evaluation results that they get from their"
  },
  {
    "startTime": "01:16:00",
    "text": "studies so it has shown some potential in predicting support for tcp traffic and also demonstrate uh many use cases such as optimal rate path network planning and the te for time boundary traffic that we just described that these types of use cases can be effectively solved using the bottleneck structure so next time please and in the next few slides we just discussed uh give some initial idea of how this service can be provided both ways auto as the suspension and also with the northbound and basically in this slide we focus more on the providing the bottleneck service as an auto uh basically using auto as a response so next time please and we uh summarize the requirement that we just get from the use cases for through prediction uh we we need to specify like flows and the status and we also need to get the super prediction results for these both and for the second use case uh we not only need to gather flows uh specific flows and get super prediction we also need to specify like uh some customized linear constraints about flows and also we might need information about the bonus structure including ingredient and flow gradient values so next step is and uh actually the bottleneck service can be provided for some specific use cases even with the current auto uh base protocols and extensions for example if we uh if we are trying if the auto server is providing the supercreation for site-level flows for example the flows uh between different uh uh networks for example building different data centers and there are resources allocated by uh using some kind of like maximum fairness then"
  },
  {
    "startTime": "01:18:03",
    "text": "pid and this information can already uh so this type of information can be uh provided using some existing auto extension for example here we need to specify whether the flows are established on uh unestablished or already established and then we can use the cost matrix from the performance metric extension such as throughput as a cosmetic and then in the response we can actually return the basically the throughput for the predicted support for each flow and next happens sure i think we only have like a few pages uh so and also we can also uh specify the superprediction for like tcp level flows so next slide yeah actually and also we uh to support the use case for uh time-bounded data transfers we also have some initial design so next step please for example uh in this we actually use the multicast extension to specify multiple to get multiple information about the bionic service for example we need the throughput and also free flow gradient information and then uh the the response will contain the both the super and also the flow gradient and the flow gradient information can be used by the application to decide which flow to be rate limited so next type is and the application can add the rate limit as flow uh basically constraints to the flows and then the auto server can pre predict the new throughput based on the constraints and and basically in this example we"
  },
  {
    "startTime": "01:20:00",
    "text": "the application can get the expected flow rate for its own target flows so in two iterations so next time please yeah so here is a summary of this talk so uh the our first argument is that the bionic service can be useful in many networks and uh solidwork has been established by g2 for maximum affairs and moving towards like real deployment so and we also believe that bionic service can potentially integrate as part of the auto framework and uh basically we we are uh interested in if uh the working group is uh basically how how we can proceed with this work is there any interest from the working group to standardize this type of service yep that's all thanks jin okay thanks kai so richard uh i think we don't have time can we move to the next presentation okay yeah i mean just like one very quick so basically uh the g2 team presented to the auto team and meetings and they have tremendous interest i think this actually can be a very good use case for auto deployment we can focus initially not really extending uh auto just use existing auto for deployment but later of course there's some like a fully user feature they might we might need like to do a little bit like a simple addition for example inside the current filter when i like flow level uh filter which is very simple uh essential like a mime type yeah okay thank you richard so thanks okay and then move to the next danny uh do you want to share slides by yourself now could you share this live please okay yesterday"
  },
  {
    "startTime": "01:22:06",
    "text": "slides are coming i think thank you okay this is annie from bennox and today you know i would like to to present a couple of slides with information about the implementation and diploma experiences with flow director and next please oh sorry nx yeah let's start with flow director so in few words basically flow director collects data from the internal state of the isps basically it builds an inventory from the front wire from warden and control plane secondly flow director you know complete computes defects mapping and compiles that into an into an unaccessible database and finally communicates this information to the hyper hyper gangs just to quickly introduce these terms you know hypergames for us at least you know there are multiple definitions you know are large networks that provide services mostly to the end users they are globally distributed and generating you know a large amount of data you know for example like my facebook netflix so far and so on and basically flow director communicates the network information to the hyper giants that that want to collaborate using different protocols including the alto protocol next slide please um yeah just a couple of words of the history on this is it's took more or less 10 years in in research you want to move to pages for"
  },
  {
    "startTime": "01:24:00",
    "text": "i can move or no no yeah you are for for it should be next slide yeah yeah yeah basically like i say this talk more or less 10 years in research and about seven years in for the company to get the point where flow director is is now and between the fierce evaluation and the actually going live is more or less seven years and flow directory you know what's also been horizontally scalable and all the components are at hidden adherent to the air faces and currently basically we run a fairly large environment with over one gigabit per second of net net flow data and we hold about 600 bgp sessions or less okay next slide please and regarding the architecture basically we have three main components these are bound components that are basically for data collection and aggregation the code engine which does all the model building and calculation and we have the northbound component which does all the communication of the trunker to the hyper youngs or ctns we have you know alt or others like enormous interface like csv or out of banks pgp interfaces okay next slide please so now let's go into the operational experience to talk a little bit about this okay next slide please uh first of all we have a collaboration with one hypergiant this hyperjunk had more than the 10 percent of the total traffic inside the isps network basically there were two kpis to"
  },
  {
    "startTime": "01:26:02",
    "text": "consider for the isps we wanted to reduce the loan hold traffic and for the hyper young we wanted to reduce the latency you know this is basically bring the server closer to to the user um flow director basically uses a mapping function that is a combination of the path length and at the distance and just to say that uh flow director basically when it's give a pat ranking it is this part ranking basically is a suggestion that is that it can be by the hyper inaudible okay next slide please so now to talk about the benefits for is for the isps for example what what you can see here is basically the traffic of the hyper junk of the backbone and long haul links and you can see here the traffic on the long haul links are you know in constant decrease basically we deployed a flow directory into five phases and one of the interesting things is in the whole face in the middle and you can see in this point the the traffic especially in the long haul traffic cost goes up this is basically because there was a you know a sort of misconfiguration and the mapping was reset to random and but you know when the system were enabling the traffic went down and at the end you know we have a significant reduction especially in the lot hall long-haul traffic which is the most expensive for the for the for the isps okay this is basically one of the benefits for the isp next slide please and in terms of the benefits for the hyper junks like i said before we use the distance as a proxy for latency so in term of the distance we reduce the gap that is the distance between the server and the"
  },
  {
    "startTime": "01:28:02",
    "text": "clients are reducing by about 40 40 percent which means that flow director localizes the traffic and again you you can see here the in the whole face this goes up really high you know because the mapping got broken but at the end when when the water restarted the the traffic goes wet down again okay next slide please now just to give a little bit more information about or in terms of the health implementation and the plumbing experiences okay next slide please just to to give an overview about what was implemented or deployed currently currently implemented is the the base alto protocol with all the provided features you know information resource directory netmap filter network network map cause map it back on services etc uh uh here are one points that we differ from the rfc in at least one point that is or eight points are not the ip addresses they are the ips nets therefore we don't we don't identify just just one one hot one hose okay and and in case of the incremental updates this was partially implemented because to reason it it was still a draft when we started the implementation implementation and also it requires you know some structural changes because it's you know a little bit quirky and in terms of deploy it in production we basically have the network map and cosma features okay next slide please and the scenario where we we were currently operated or it's you know a cdn that wants to deliver"
  },
  {
    "startTime": "01:30:00",
    "text": "content to the isps customers basically we're considering only paths from the city and caches towards the customer this is because you know the main traffic simply flow from the cdns to the to the end users and you know the cdn caches are not only embedded into the to the aes of the cdn itself but but can also be embedded into foreign ideas and one here one you know interesting question here is how to group the prefixes to form the dpids or and at the end create the alto alto resources next slide please okay just to quickly provide info about the how to delete us accumulated with routing protocol you know we collect information about the links router networks with flow information alternate for example from netflow we can collect english already spoil points and we and we can get you know information from the network monitoring and to try to collect you know information about the utilization ban with that see etc great next slide please and okay just for for uh for the alto uh max calculation we are you know attached to a large european ixps as you can see here there are a lot of routers and i beat prefixes so yes i don't i see you can see all the details i don't need to repeat all the information next slide please okay for the network map we basically uh defined three different pids internal external and oak net of net basically for prefixes from directly red asses this means not third party traffic on on pyramid links"
  },
  {
    "startTime": "01:32:00",
    "text": "and yeah i see next slide please let's let's see the time is going to okay for cause map basically we provide three different course maps and the hop distance that is because in terms of number of aes internal hubs but weights that is basically because according to the routing protocol acoustic cops that is divided from the delay or beating the utilization okay now i think next slide please okay some statistics from our auto running server so all the network maps because map are updated every five minutes we have more or less you know 250 000 prefixes across 1700 pids and the average map size is about 6 megabytes and in case of the custom cos map matrix we have more more than one top 3 million of pid pairs and with the average size of the cost map is more or less 47 megabytes okay okay we can go next okay yeah you know obviously we experimented some some problem because we are working over a large network so we have for example and long running for the maps calculation process in this case a new network map is always available first than the current available cost map and on the other hand there is a limitation to the ip addresses in the 8.con services and you know the rfc states that the source and destination while the young ip addresses however we want to to get the cost for certain region we are connected to to request prefixes for for clients of nebs next please uh yeah for try to we consider a set of"
  },
  {
    "startTime": "01:34:00",
    "text": "modifications to deal with the previous problem for example mechanisms to publish all maps together when the last the last one is ready on the other hand or alto server support prefixes in the 8 point cop services and we also adding metadata fields like dtl timestamps in the alto server response okay next slides please just to quickly summarize that you know for us we consider that there is a opportunity to play networks more efficiently through networking application integration today i wanted to to briefly show how this collaboration works in a system that is currently deployed and you know it's worth it for both isps and hyper junks in terms of net steps the ideas you know is to contribute without the through implementation and deployment experiences to communication and while you know i'll be not the highest priority activity in terms of implementation for us where okay richard said we are fully open to to use our infrastructure as an evaluation or testing environment so i think that that's all okay thank you so much okay danny and i i think glad to see flow director has already been moved to a production stage so thank you for sharing your problem and limitation you found in the auto implementation i actually suggest you can take to the list to have some discussion it will be good input to the auto deployment experience update yeah sure thanks okay rachel we don't have time for comments maybe we can discuss on the channel room and for remaining uh topic actually we have three topics i suggest we actually condense each topic to seven minutes so the first is luis who is you want to share slides by yourself or you want me to share i"
  },
  {
    "startTime": "01:36:00",
    "text": "prefer you share thank you okay and yes i will try to be brief and okay great okay i can see now the the slides thank you chin so the idea here is to present this work which is considering aldo's itf network exposure function and i come with contributions also from san juan so yeah next please yeah the motivation of this work essentially is to to understand that negroes are becoming consumable more and more by application and services we are observing this trend and where there are discussions in other working groups as well in itf about this idea of application network integration or network application integration so different ways of interchanging and exposing information on capabilities in one direction or the other so this is also a trend that is being observed in in other initiatives outside itf so these new forms of exposing capabilities and yeah the final idea at the end is to inform or to allow applications to get informed about the situations of the network and in such a way that these applications can uh take better and and optimal decisions so it has i mean moving from the couple way in which today applications and services are run into something much more uh yeah in for base so yeah uh trying to avoid that inferring or guessing of what network capabilities and status and basically collect information that could be useful for uh for the application services to have a better optimal criteria for the delivery there are a number of examples in in other let's say solutions and other other networks for instance the 3d network special function that somehow is an inspiration for this work where the network functions can be informed application function sorry"
  },
  {
    "startTime": "01:38:00",
    "text": "can be informed about capabilities of the 3gpp overlay network also we have other initiatives like the hcm multi-access computing apis where these apis can provide information about the possibility capabilities of the access network or uh even radio information and so so far same night story some idea for the oran run intelligent controller and so on so far next please so chin okay thank you so um yeah alton in fact was conceived from from its inception as um as a mechanism for providing information to support optimization decisions on on applications so in this sense alto seems to be very well positioned to take this role of regular spatial function for itf capabilities initially the possibilities or the information that can be exposed by alto are the topology information that is now being expanded to a number of other capabilities as chair performance or segment in view according to the path vector etc etc we saw at the beginning some of these possibilities so um taking into account these these capabilities so how we structure in the in the draft different possibilities of information exposure so somehow we are collecting a kind of catalog based on on existing and foreseeing work they have been existing work and assuming the what is documented in nfcs or documents that will become rfc soon we could account on a network topology associated cosmetics for performance metrics this segmented view leveraging on the perfector solution and and also we could even try to cover some other cases that are not actually documented at all but can be straightforward like the dynamic ip addressing that could come for instance for the control and user plane separation"
  },
  {
    "startTime": "01:40:00",
    "text": "trend both in fixed and mobile networks so dynamic upf instantiation or dynamic bng user plane instantiation for instance where you will have a dynamic allocation of ip addresses to those instances also we can account on on information that is exposed by proposed augmentations and here maybe we can talk about the optimal service edge um also the underlying view of for overlays the apn this overlays the cellular network or the cdn and so there are also some individual drafts now in in the group um analyzing those those situations and uh also just to commend other information uh other potential information that could be exposed has been also discussed in the weekly alto meetings with this is not yet documented by the idea according with the progress of the discussion would be to document them and to be included in the draft and here we could mention for instance multipath approach multipa support could be something that could be also part of of these exposure capabilities so next slide please thank you so uh here just a view of what could be our uh graphically or for illustration purposes what could be the the interaction between alto as a network exposure function and potential clients of these capabilities we could have external applications here we can account on external cdn logic so we could consider external cdns like the case that danny presented before or internal cdns that for instance is the the proof of concept that telefonica is integrating with the internal own internal cdn but also we could consider cloud application orchestration or cpp network sponsor function or whatever other a customer external overlay network that could leverage on itf capability all you have network capabilities and also we could have a number of internal customers like sdn controller the cdn logic that also has been"
  },
  {
    "startTime": "01:42:00",
    "text": "mentioned and so on so far maybe some other sources of of uh some other applications sorry the idea would be to collect this information from the itf network to fit the the alto network here we we added bb pls but there could be other sources also as described before by danny maybe as an mp or maybe directly collecting information from the nodes through a net conjunct models next slide please uh chin also a potential way an alternative way of collecting and providing information would be to uh to to position these applications that are internal to the network here we put the three epp has internal to the network in case that this three evp network is also handled by the same administrative domain at the end yeah essentially the message here is to integrate um to collect the information from alto and to expose this information to external or internal customers through the alto protocol with or without the stations depending on the kind of information so next slide next and final slide please so the idea would be to collect feedback from the working group and for sure we are working on preparing an expression with more detail on the usage of alto as itf network exposure function with a final purpose of course positioning alto as this itfnf for for for feeding applications and services thank you good job yeah i just want to give you one very quick comment i think this is super super cool and i really wish i hope that there's some way we can push this one forward either you know we we we we support nef for instance gpp or the other world run but although i think this should be very increasing work i strongly support i'm very interested okay let's move to the next topic loophole do you want to share a question by myself since the time is"
  },
  {
    "startTime": "01:44:00",
    "text": "not so enough and some slides need to be quickly go through yeah so uh my screen available yes go ahead okay um hello everyone this is this is pawnee from channel mobile and it's a computing aware networking use case of auto first is the background um about the ict infrastructure definition um so the service providers offering the integrated community on the networking infrastructure to provide the best use case uh user experience such as low latency and high reliability and optimize utilization of network and competing results but there are also some challenges of edge computing such as geographically scattered large number of styles resource limitation and hedge nearest hardware dynamic load and others so the problem is that all of the challenges are not solvable so um solar in computer domain know the network domain so we need to find a collaborative approach um it's the case that we want to see is that both of the network and computing factors in the same level to influence the user experience so it's better to have the scheduled and among the different sites to find the suitable one to offer the service yeah so do due to the challenges and the use case we put up the computing aware networking here is a definition of it"
  },
  {
    "startTime": "01:46:02",
    "text": "um committee aware networking is proposed based on the ambitious network connection and highly distributed computing results it proposed new mechanisms to be aware of the distribution and status of computer science in network and combined service and framework of team optimal loading and load balance to schedule the computing and network results based on the awareness of service requests so to improve the efficiency of the computing and network results and something need to be clarified is that the relationship between c and the diecast since i had joined the uh meeting um as previous itf meetings and so diecast is a key function of computing where loading layer which has a potential opportunity to do something at itf besides this the cm framework also has a network resource layer computing results layer convenient service layer and the management layer and here is the potential relationship of computer where networking and auto for the framework and the computing aware networking can realize awareness control and scheduling of computing and network results and perform dynamic and on-demand service scheduling the function of computing and the network management layer may be realized by or by opening some interface with other server which includes two aspects so one is deployment of cn with auto more stable static information should be considered in service deployment such as network topology compute convenient technology and so on unlike the request to"
  },
  {
    "startTime": "01:48:01",
    "text": "scheduling service develop deployment should still follow the principle of progressivity if the results are insufficient the ability can be informed to increase the hardware results um so the order can be used to transmit information um it has a similar idea with the draft or the service edge and and another aspect is scheduling of saving waste auto scheduling needs to consider more dynamic information such as mobility status of network and computing and service requirements and also also can help collect real-time network service node information and providing the best service of network and service nodes based on the correct information the service requirement and or providing data analysis and policy distribution the time node selection uh still depends on distributed routing such as diecast and we exactly know that satisfy the same framework or any components of it might not be the substantial workout now but the trend of infrastructure definition may bring the new opportunity of it since it can help give the suggestion to deploy the service node and collect some useful information if the network can get the computing information it can also send to the auto server so here are some questions received from mailing list and question one is uh multiple protocol or um one protocol to use to collect the information uh we think multi-protocol will bring the issue of synchronization which is not easy and cause some additional expense if the network is determined the network may come support the synchronization so"
  },
  {
    "startTime": "01:50:01",
    "text": "one protocol may be a right way maybe extending bgp can be an option but the frequency frequency is a problem and another question is that to decouple also from the specific syn architecture it's a good way to really and to combine them and also find some some way to uh to solve the problems uh now yeah um and the last question is that requirements of real-time information how to shorten the period of information refreshment measurement so real time is good uh is the important factor in the same framework and we can find some informations in the existing rfc um the other service may not have the um so uh real-time uh information for the network of the uh loading um so it's the it's a potential uh challenge or problems to uh realize these functions um so um you need to run wrap up okay yeah um so it's the last two one okay that's all thank you okay thanks so you standing for input to auto worker i think you raised a lot of good questions suggest you take it to the list have some discussion thank you okay let's move to the next stop topic uh loads the chain oh hi i'm going to share my screen okay great [Music] can you send a request okay i think i have sent it okay yeah can you see my screen yes yes go"
  },
  {
    "startTime": "01:52:01",
    "text": "ahead okay let's get started hi i'm jushung from microsoft research asia i'm going to give a talk on bandwidth estimation on openness lab on behalf of openness lab community this talk is mainly focus on it to introduce the final assassination and discuss the possibility to make it as a part of auto as we know rtc is going very fast recently compared to january 2020 the active user increased by three times and the number of costs and the meeting increased by seven to seven 17.4 times in april i think the most important indicator reflecting the user experience is pcr pro call rate in the figure we can know that the number of pool costs and the pro car rate are increasing dramatically when the copy 19 outbreaks in u.s are march so it's a very urgent for rtc to continue improving our call quality to attract more users bandwidth estimation actually is one of the key reasons of the pool call rate in the table we list the top 10 reasons for pro call pro 11 cost you can you can know that uh 20 uh 28.9 percent of programming code is highly related to bandwidth estimation and 40.9 percent is related to bandwidth estimation the problem includes the no sounds discord distort with audio final background noise uh audio delay call dropped video low quality and the video freezing so there's a question come to us can bundles estimation can be a service to make everyone contribute contributed to it let's see the traditional final assassination you can see it has many interfaces with different modules and"
  },
  {
    "startTime": "01:54:00",
    "text": "also for big company the bandwidth estimation are proprietary that means every company uh has its own design and implementation uh is kind of closed so it's usually use single model for all users and it's hard to uh innovate in this area so i think we can use the concept of auto to make a bandwidth estimation as a standard service it can make the architecture simpler and make the service open it can enable more customization and everyone can contribute to this service and share the technology of the service to to boot to boost the innovation actually we have a bandwidth as miss admits challenge on mmc's this year the goal of the challenge is to optimize the qoe for real-time communication for example the video and audio call quality and every participant should design their bandwidth as an estimation model or algorithm to compute our bandwidth to estimate the uh the current bandwidth based on the network status we use network open lab as the taskbar for this challenge uh in the evaluation period actually we use uh more than 40 run run for schema on opennet lab it includes nine videos uh three networks including high medium and low bandwidth and we have five runs per schema in the run in a wrong driving way the final score is the average average rated sum of the video score audio score and the network score finally the nanny university team is the winner and they uh their score is 78.33 which is better than the google congestion control which is 71.47 we can see the innovation is very"
  },
  {
    "startTime": "01:56:02",
    "text": "promising in the bandwidth estimation and we can see we can also see bandwidth estimation can be a part of the auto the figure 1 shows the location of auto service and auto clients the server can be independent or live with the clients the client can request the bandwidth bandwidth through the interface actually they can use the kind of the standard auto interface to communicate the potential application can be uh rtc such as uh teams uh tencent tencent meeting or also some other rtc software the the input could be packaged states and the output can be the estimate of the isomine bandwidth of to the sender of course the input output can be changed adapt to the need of the application uh by the way our all of our research actually are on the top of opennet lab it is a kind of data-centric networking research community the community is founded by tao uh night top university across asia including nanjing university packing university qinghai university and also macro software research asia professor timchen is the chair of the community this year i think uh due to time limitation i think i can give a brief introduction of overnight lab it actually it provides a framework and also heterogeneous nodes to achieve the data-centric networking research and we are building more and more uh nodes across asia and we are expanding the opennet lab to the world worldwide to increase the coverage yeah thank you okay thank you so much so you want to make a comment yes yes hello this is from alibaba and i"
  },
  {
    "startTime": "01:58:00",
    "text": "have a question so you just mentioned that uh for the poor core rate it's forty percent of the procore rate is related to the bandwidth estimations and i want to know how do you calculate how do you compute this this number how how is this number uh computed uh actually uh we just uh we we have our actually we have uh uh when when you're using teams actually you can have some uh you can you can have a score the user can can mark it as some score and we check the the bandwidth bandwidth estimation backlog and and we can compare there are some bandwidth variations and maybe the bandwidth is not adapt to the real real bandwidth okay richard okay uh i think this is a great my question is falling suppose we we want to integrate this one as a service using auto i think the api it's not a media prompt we already have it one concern is the frequency of the data so currently in your current implementation and your vwe server what's the frequency that uh how much data and at which frequency that you your dpwe server is sending information to the client actually uh in in kind of the uh webrtc or or some rtc like this uh we exchanged the bandwidth estimation data uh in i think 200 million seconds so basically we're talking about potentially if we push auto and to the sending information we'll talk about the several hundreds or milliseconds frequency and that'll be good enough yes yes got it cool that's very okay"
  },
  {
    "startTime": "02:00:00",
    "text": "okay thank you thank you richard so we're on time actually quickly right here thanks for uh mohammed actually uh moderate from behind a reminder the time limit uh thank you for uh daniel and and and agent to take a minute and thank all the participants and uh any last words from mad or martin no thank you chen thank you okay that's closely the meeting yes thank you you"
  }
]
