[
  {
    "startTime": "00:00:08",
    "text": "And Yeah. I think I think correct. Leave it. Can you see the queue of your We'll plan my kind of how did you get the room fives up? I, it just a tough dessert and something potential, but it just doesn't so should we Hello, everybody. I was about to say good afternoon, but for people who had dialed in, that makes no logical sense. Welcome to the delay and disruption tolerant networking working group meeting, IETF 118,"
  },
  {
    "startTime": "00:02:01",
    "text": "if you're in the wrong room, there was your chance to quietly creep out can somebody at the door just push the door shut, if that's okay? Just because there's a bit of noise in the corridor sometimes. There's a few more people just sliding in so we'll get my chance. So 1st and foremost, this session is recorded. So, the mic's alive. Please be a little bit wary about what you say, and we'll cover that in the note. Well, next slide please add So, as with all our ETF meetings, this one covered by the note well. I hope you are familiar with this by now, this being the 2nd day of this IETF meeting, If you are unfamiliar, Please make time to read this. There are copies all over the IITF website as well as on the screen now and in the slides and materials for the chair slides. The long and the short of it is Any thing you say at the mic will contribute on the mailing list. Is effectively in the public domain and you, cannot come back later and claim that that was covered by some IPR or you shouldn't said that. If you said it, you've said it, so be careful We also have, anti harassment guidelines, so, please contribute in a constructive and well mannered manner. There are processes if you feel that that is not being, if that if if that is not happening, please bring it to the chairs, and there is also a number team here to support and adjudicate as required. Next slide, please. If the clicker is working. No. The the technology has died already. It's Bye. I should there we go. So the this is a new slide for for this session. The note really well, which, goes over the detail the previous slide in a in or length to to make sure that, people do understand exactly what's going on. I think I've covered most of this already"
  },
  {
    "startTime": "00:04:01",
    "text": "Next slide, please. So, meeting tips, please make sure you are logged in to either the on-site tool, the small middle, middle tool you can use on your phone quite happily or if you're remote, you will already have been logged in because we don't have blue sheets. And it allows us to plan the right sized room for the next event. And also to make sure you've actually paid to be here. If you have any trouble, Meteco are around to support, but, as of recently, the client works well. So, long may that continue. Yes. If you are remote, please try and keep your you're muted when you're not actively speaking headphones strongly recommended. It's always difficult that people dialed in from all over the try and get the audio quality high, but, the best we can do If we can try and achieve some good quality audio, then people can understand what is being said. And, we can make more progress. Next slide, please. So, These are some general resources for the IETF 118 meeting, including the agenda, informational meet echo. So, the irony of this is being presented through BTECO, and here is the information of how to present through BTECO, proving its turtles all the way down. Next slide, please. So this is the agenda for this meeting. There were some last minute updates where we reorganized the open discussion, which we did have 50 minutes because We're gonna include 2 presentations as part of that discussion. So at the bottom two items above the open mic are 2 presentations as part of that wider discussion the, top 5 items are actual presentations on working group documents or drafts in progress."
  },
  {
    "startTime": "00:06:00",
    "text": "So we'll start with those and then we'll get on to to the later discussion And and I was just gonna add to make sure that, please, as we go, particularly for those who are, online, make sure that you are joining the queue and make sure that you join and help us, take notes throughout the session. Online. Thank you. So does anyone wish to bash the agenda at this point, or should we move on? Let's move on. So, Sarah, I hope you're Online and it's gonna get the deck ready and take it away when you're happy. Great. Can you all hear me? Yep. Wonderful. Alright. So hi, everyone. I'm Sarah Heiner. I'm gonna make this a quick update on the DTNMA, the DTN Management Architecture, just to cover some of the changes that have been made since we finished the working group last call. Next slide, please. So to give you at first a quick overview of where we are now, We've published version 7 of the document. That address some of the comments that we receive back from the ops area as well as the comments from the DTN Working Group last call. All of these edits, we would say are Yaron Minor, mostly clarification of techno of terminology And then just making sure that what we are saying is consistent across the DTN network management ecosystem. Next slide. So in particular, we finished the removal of all of the management model. That's the ADM and op operational data model details from the DTNMA. So this is in recognition of the fact that the DTNMA is an architect"
  },
  {
    "startTime": "00:08:01",
    "text": "or document. So we wanted to adhere to that informational document scope. So we removed data type and object type details where they're addressed by the AMM and the ADM documents instead. Next slide. We also made some minor terminology updates to keep the discussion across those DTN Network Management documents. So this required just a couple updates to align the AMM ADM and AMP. So for instance, because the ADM makes a distinction between a control and a macro we updated the reference model that I have pictured here. To identify messages that are originating from the managing device. As containing commanding data rather than control data. Since that was only capturing a subset of that information because of the update to the ADM. Next slide. We also received some really excellent review of the existing management protocol discussion in the document from Brian Cipos. We made his recommended changes, again, around the more careful use of terminology, if you're sensing a theme here. So this clarified that the challenged network usability shoes that were identified in this section. For both SNMP and Netconf like protocols, did not stem from the SMI or yang models themselves. To So we distinguish between data model semantics, model syntax and the actual protocol used to manipulate data on an agent. So, again, more careful use of terminology and making sure that we're calling out the, similarities and differences"
  },
  {
    "startTime": "00:10:01",
    "text": "in these protocols and, getting into some of the nuance between data model model syntax and the actual protocol for data manipulation Next slide. So, finally, we updated the language in the, use case just to be more explicit in identifying the access control lists we identified them as items that are associated with policy expressions, but they aren't, intended to be interpreted as required annotations in those polls expressions themselves. So because ACLs are internal to the DTNMA agents themselves. They're of intent behind those use cases. Not to say that they should be explicitly included in messaging or transmitted over the wire. So that is my last slide. So I'll just end with a thank you for the feedback and the support received during working group last call. And would be glad to hear any additional thoughts that the working group has. And and just a a reminder for that, the the working group last call, I believe today, is the, last day of that 2 or 3 week, last call. So if you have not had a chance to review the document, please do so today. And let us know if you have any questions or concerns or thoughts related to it. Alright. Sarah, thank you so much. Great. Thank you. So next time we got Scott Burley, talking about bundle and bundle encapsulation and cost"
  },
  {
    "startTime": "00:12:01",
    "text": "to the transfer. So there's actually 2 decks here Scott spend as much time on either deck as you want within the 30 minutes slot. Okay. Alec, Can you hear me? I'm, I have little troubles configuration earlier. Yeah. We can hear load and clear, can you hear us? Yes. Everything is fine. Perfect. Perfect. Perfect. Okay. I will go ahead. This first deck is actually, about five years old because it really hasn't been much change in, thinking on bundled, bundle encapsulation since, work that was done back in 2018. And, I'll I'll try to go through it quickly. This is I think, mostly in aid of getting, started on addressing bundle, bundle encapsulation in the context of the revised, updated, charter for the working group. And next slide, from Ah, okay. Quick overview of what I'll be covering. I'll review the history of bunsen, but cancellation very briefly. Talk about aggregate customer signaling because it bears on the the updated, BIV design run through that design look at, some, potential applications for bundling bundle encapsulation. And, and some thoughts about the future. And next slide, next slide. So, Bibe really goes back to 2009. There there was work being done on, bundling bundling encapsulation by, folks at, MITRE Corporation. This is Simon's and volunteers, Keith Scott, and at the time, bundling monocapsulation was conceived of as a as a capability of the application agent of the"
  },
  {
    "startTime": "00:14:03",
    "text": "BP node. And there's a as a BP application, running on top of the the the real, BP. And the the motivations were, to, support, content centric networking at some point to, support efficient custodial retransmission of multicast bundles. And for, tunneling security, in in particular, traffic analysis is something that because BP sec, Kent encrypt the primary block of of a bundle because if it did, it would be unroutable. The only way to, to shield the the the identity of the sender and the receiver of a given bundle, the source and destination of a bundle, is to in encapsulate the entire is to encrypt the entire bundle and make it the payload, encapsulating So, VivE is, ideal for that. Next slide, that original specification, was interesting wasn't really taken up, implementation, and sort of languished for a while and was resurrected in, 2013 as a, a, as a convergence layer rather than as an app on top of PP. That is the the new, BP would be underneath the existing on the protocol rather than above it. The motivation there was, can help in in what we were trying to do at the time, just entangling routing from security. And the the buy and tunnel, took the place of the security source and security destination elements of the original, bump security protocol. Next slide."
  },
  {
    "startTime": "00:16:07",
    "text": "There was a lot of discussion and a custody transfer meanwhile in, 20152016. The resolution of all that was that it was determined that customer transfer with a custodial retransmission, really couldn't be made efficient. And I'll talk about that in in the next presentation a little bit more. In some deployment scenarios though, if if there were inter directional links no way to, achieve a reliable transmission would be to have a an asymmetric, acknowledgement mechanism, coming back, on on a on a sort of, out of band or out of the same band as transmission. Link. And, how would you do that open the protocol was an obvious choice for for making that happen. Saw it. It seemed like a, actually quite a good fit. Next slide. So, the idea here was that we determined that, the custody transfer didn't really belong funnel protocol itself. That instead BP transmission reliability, should be accomplished between neighboring from a protocol notes that is to say if the convergence layer So, the this this custody transfer asymmetric reliability that that we still needed the place to do it would be if the convergence layer that is used BP as a converged layer protocol. And and then, of course, well, Vibe already did just that. It was being conceived as a Convergys layer protocol. So why not just, build this, residually required custody transfer capability the end of bundle bundling bundle encapsulation and use it for"
  },
  {
    "startTime": "00:18:00",
    "text": "both purposes, independently or together that is you could use it for, And in security, just as it was originally intended in 2013, you could also use it for reliable convergence layer transmission over asymmetric paths. And next slide, at the same time, or so sort of at the same time. In in 2012, There were, guys at University of Colorado Boulder had who worked on a more bandwidth efficient definition of custody because customer transfer turned out to be extremely useful for operations, of, DTN over links between Earth and the International Space Station. So, their their aggregation mechanism. I have a customer signaling was documented in a draft that they never posted. We were indebted to Sebastian Kuzinski and Andrew Jenkins for that work. The concept there was to, provide a an alternative administrative record and also an additional extension block on the protocol. And this mechanism was implemented as an option in, all of them implementation of, BP. The idea being to enable custody studio retransmission to be used for reliable DP on the ISS where the, link data rates for so extremely asymmetrical is to be almost be direct, inter directional So, the the the fit was was deemed reasonable in in that case. And in fact, the ISS guys love the way custodial retransmission was handled, in in how it, provided liability and operations. Next slide. So,"
  },
  {
    "startTime": "00:20:02",
    "text": "given that that great success, in 2018, came out with a, new bundle of bundle encapsulation specification. That included custody transfer and specifically this aggregate to transfer an adaptation of the ACS that had been developed for, BPV 6. It, operates as an optionally reliable convergence layer protocol underneath, bump protocol. And the encapsulated protocol may be encrypted may be signed, it neither depends on what you're trying to do with it, and the there there are many possible, you uses for this capability that I'll talk about in a second as I go through, Snap occasions. Next slide. So, in in this sense, Bibe, takes the the form of a reliable convergence layer protocol where the the protocol is on the protocol itself. The payload of the encapsulating bundle would be, the encapsulated bundle together with optionally, transmission ID and an expected time of acknowledgement, both provided if, custody transfer, mechanism is is required on, on this particular, convergence layer link the acknowledgement of the encapsulating bundle is aggregated into a new administrative record that is sent in a responding bundle there are, customer disposition codes in those responding bundles and and the that responding bundle aggregate the transmission IDs of the receive bundles in, a format that's"
  },
  {
    "startTime": "00:22:01",
    "text": "pretty compressed so that it makes the, the acknowledgment, fairly low bandwidth consumption. If the acknowledgement is not received by the expected time, then the transmission of the encapsulated bundles soon to have failed, and the encapsulated bundle is queued to be re forward. Next slide. So here are some possible applications. For, VivE I think are, range from the fairly obvious to the exotic and probably am improbable But I think they're interesting to think about, anyway. Let me slide Here's the the the basic custodial reliability model, where the, little is shown in green here, and it encapsulates the source bundle shown in sort of salmon color. And the what's going on in between the two nodes is that the source note is encapsulated in in a vibe bundle. And, forwarded to, to the bond destination. The the the Bible destination, in this case, node 2 is the final destination of 5 bundle but not the foundation of the source bundle. The, buy bundle received the, the encapsulating bundle and sends back using, an entirely different, transmission path, the acknowledgment that, enables the sending bottle to forget about, resending the the, vibe bundle. At the at the year the buy destination bundle"
  },
  {
    "startTime": "00:24:02",
    "text": "the source bundle is extracted from the encapsulating bundle and forwarded to the destination node in the usual way. Next slide. Oh, I see a slight a hand up. Is that right? Yep. Yeah. It in fact, my hand. So Oh, yeah. Your hand. Yes. So with, with with chair head off, two questions. One is is it always the case in vibe that there is a single encapsulated bundle. Or in these cases, would you assume that a BPA would put multiple bundles, into a vibe. Good question. In what has been written so far? It's all assume that there's just a single bundle inside the encapsulating bundle. We could talk about mechanisms for aggregating multiple bundles into, into the the encapsulating bundle, and that might not be, a very reasonable way to proceed. It hasn't been documented yet, the the the second question, and and that makes perfect sense. The the second question I had was the, is there, in the by, now a relationship between the extension blocks that are in the capsylated bundle, extension blocks that would be placed in the encapsulate ting bundle. There, there is no mandatory, relationship. The intent is that the encapsulating bundle is a brand new bundle that can be configured and directed in whatever way makes sense at the, at the at at its source. That might might turn it well, entail borrowing some of the configuration from the, the encapsulated bundle but it's not required to. And, I think that's actually that distinction is is quite important because some of the things that you can do with by"
  },
  {
    "startTime": "00:26:01",
    "text": "would be, limited and, and, and maybe table, if if you're required to, carry forward all of the holiday service and and so forth that, characterized the encapsulated bundle. Oh, I completely agree. I was thinking more bundle age block or previous node blocks and and whether, they had they explicitly addressed Yeah. I and and, you you an argument could be made for, adopting, and, and carrying forward some of those but I I think it's a more powerful mechanism if that is left up to, implementation and configuration rather than built into the Sure. Thank you. Hi, Scott. Rick. Yeah. Rick joining the queue here. Again, to hat off. So personal opinion. My question really is about do you see the encapsulating and decapsulating pair of of nodes Having the same implementation or do do you foresee bundle and bundle encapsulation being a specification to allow 2 different implementations to interoperate because I think that determines the level of rigor that has to go into the specification. Oh, I I I would fully expect the the, sending and the the the the encapsulating bundles, bundles sourcing destination, to be accomplished by potentially different implementations. I would expect VIVE to be a, a defined particle specification and, and standardized, in the same way as"
  },
  {
    "startTime": "00:28:00",
    "text": "as any other convergence layer protocol. Perfect. Thank you. Yeah. That said, to my knowledge, there are no other implementations or BIV at this time. So, it's it's quite easy to to change the spec now because you'll have to change one implementation to conform next slide, please. And and we just have one more person and Oh, I'm sorry, Eric. Yes. Just to clear up a quick clarification question. The circles, 6219, are they just, representing Depologies of of other nodes that forward the a custody signal. Yes. That's right. Yeah. Okay. Thank you. The idea is that, there, there might be, any number of, of, of on the protocol nodes between, the the source and destination notes, but they're operations are are are at@alevelbelow the operation of the transmission of the encapsulating bundle. Thank you. Cross domain security is another, straightforward, sort of, application of of this mechanism, you, you may have a a couple of safe regions of the network and one that is extremely unsafe. So maybe that for the farmers reasons you, your, your source bundle has very light security or, or, or maybe no security or hardly any security at all. You, you, you, you don't need to protected very strongly, but as it transits, a wild and woolly"
  },
  {
    "startTime": "00:30:02",
    "text": "area of the network. You wanna add much more security much much more strongly computed, encapsulation and encryption, for example. And so you can use a bundle of bundle of encapsulation to do that. The original likely secured, bundle, is encapsulated inside a bundle that is, that is, that is encaps that is encrypted in some, highly, you know, post quantum kind of mechanism to insurance safety as a as it transits the dangerous part of the network. And then once it reaches the safe harbor on the other side that the source bundle acted and and forwarded, in in other, you know, benign Next slide please. Very similar defense against traffic analysis you, if you, as I mentioned earlier, if you have a, a source bundle, and you really want the source bundle not to be, it's it's source and destination not to be advertised to the world, you can at the at the edge of an unsafe region of the network you can simply encrypt the entire and use that encrypted source bundle is the payload of, a vibe bundle, and then decrypted at the biodestination and and forward it in the usual way. Next time. Going a little bit further afield, you can sort of generalize this idea I guess in and and and say that you might change the quality service of the bundle as it"
  },
  {
    "startTime": "00:32:00",
    "text": "as it passes through the network. So when the the bundle is, you know, in its local local region. It's, say, assuming that we have things that are similar to the PPV 6, quality of service. Maybe it's It's expedited in in it's very important once it gets on to the trunk line, it's just like anything else. So so now it's just standard. It has to just like, you know, stand in line with everybody else. And then when it gets to the to the vibe, destination. Well, now it's expedited again. It's it's very important. You can imagine, other, dimensions of quality being adjusted in over the the Biden Commission as well. Next slide. In in particular, there's a, mechanism in ion. I'm not sure if it's in anywhere else. Called critical, forwarding, which is the, determination that are so important that if there are multiple ways for it to get to the destination, you wanna send it on all of them. Well, that that kind of determination might apply only in particularly unstable portion of the network. And so rather than, sending it from its source over every possible destination over every possible path to the final destination. You do it only over the particularly unstable part of the network and the destination of the, the of the critical transmission is another, vibe node which simply extracts the the bundle from whichever on on its, copies it sees first and forwards it to the final destination node. Next slide. Transient multicast. You can, imagine perhaps an extremely unstable part of the network where you, you, you want to,"
  },
  {
    "startTime": "00:34:02",
    "text": "use multicast to make sure that the funnel gets to its final destination but only circling subscribed news are are acceptable egress nodes from that part of the network. And so they they joined the multicast group and the, vibe source multicasts to that group And all the members of that group receiving copies of it of the of the, encapsulating bundle extract the source bundle and forward it to the destination next slide. Source path routing in the event that you wanna use source path routing and his a a way to do it, you just encapsulate and and slate and encapsulate nesting them as easily as you need to to to ensure that the the bundle falls a specific path through the network and, and, and if and doesn't go through any alternative paths even if such paths exist. If you wanna do that, of course, you wanna secure, well, every every forwarding node needs to be secured against, the arrival of the encapsulated bundle, but if this is a useful mechanism, this is a way to achieve it. Ribcast. Just a passing comment. There is a lot of work around performing similar capabilities of the IP layer I think it's probably worth reading as we start to go further into this sort of off protection functions is what they call it within the debt net area deterministic networking So they're doing, packet replication elimination and ordering"
  },
  {
    "startTime": "00:36:02",
    "text": "functions, they've got a very strong framework which covers pretty much, you'll previous four slides. There are there are frameworks well thought out well peer reviewed that I I strongly recommend that that that this working group looks at that work and says, how applicable are some of these techniques? What are what are they worked out what have they found doesn't work well. So It's a bit of cross pollination there. Yeah. Absolutely. I I think what I would suggest here is that that, standardizing BIV itself is is is an activity and standardizing, these applications I think that that marist its own each of these, I suppose, marries its own RFC. And, and I'll be informed in exactly the way you say. I I completely agree because I think that was what the debt networking group have discovered is that this is a very complex and, field and by creating the building blocks and then applying explicit techniques for all of these things has worked well for them. So Yep. Yep. Thank you. I'd I won't, claimed that any of these applications I'm talking about here are are things that nobody's ever thought of before. What what I would claim is that VIVE is is a way to accomplish, these things in a, in a delayed, tolerant manner. I think it's worth exploring so I think I'm almost at the end your next slide. Oh, yeah. Combinations of these things, so certified cast, you and the I think the idea of being here that that, any of the mechanisms, discussed earlier and probably lost more that I haven't thought of yet. Are are enabled by,"
  },
  {
    "startTime": "00:38:01",
    "text": "just this, mechanism that, uses on the protocol, at the convergence layer enabling in a sense, enabling the characteristics of the source bundle to be overwritten in, whatever way seems, useful in the configuration of the network. And that may be my last slide. Oh, yeah. Oh, it's the, I I mentioned here that being considered for adoption by the, detailed working groups in the charter. It's not a complicated specification, And, I think it's quite powerful. And I think that is the last slide. The last one just says questions. I'll I'll just jump in. Well, actually, with chair hat 1, this, spec I believe has been adopted by the DTM Working Group. There there is a, there's a there's a there's a there's a there's a there's a non personal draft, for that BIVCT. And I wanted to remind, the working group at large that One of the reasons, that we are having this presentation in this working group meeting is that getting bundle and bundle encapsulation standardized is one of our charter items. And and now that as we are getting through some of our prior work, on as as Rick's gonna talk about in at after Scott's second presentation around IPN URI schemes and the network management stuff, getting Bibi, finished is is sort of the next thing on deck. So, please pay attention to the slides that are here. But also, there is a adopted draft to look at And, certainly I'm, eager to hear comments on the draft and and come up with revisions to the draft. I think I'm probably running short on time. So, I'm I will try to zip through this deck very quickly"
  },
  {
    "startTime": "00:40:03",
    "text": "and, a lot of it is, is old news anyway, I think. This is sort of general ideas on custody transfer why, we're we're sort of revisiting, why is, removed from it could be 7. And, and and and what to do about it in the future a little bit. It's a fairly short, deck. So next slide, this is actually, I think the maybe the most important thing in this presentation, which is that the concept of custody is, not really a retransmission mechanism it is I think a a way to think about it is that it's an exception or, an adaptation, anyway, of the end to end principle. That is to improve performance, the forwarding nodes along the path in the start of the destination. Are are successively responsible for retransmission. Rather than only the source being responsible for retransmission. Improved performance and in, pads where, one of the, hosped between, adjacent nodes is extremely long summer propagation delay. You don't wanna pay for that a second time if it gets lost on on the next hop over a over a trivial. So the the the responsibility for accomplishing retransmission is handed forward and that's what custody transfer is and and and what customer transfer mechanism that was built into BPD 6 was designed to implement. Next slide. The the problem is using custom transfer to provide reliability. In in and of itself that is to to accomplish reliability rather than just to to drive it."
  },
  {
    "startTime": "00:42:02",
    "text": "Is that there are no negative acknowledgements the the closest thing to an academic acknowledgment is I'm I received this, but if wanted, I'm not gonna forwarded. It's really, a routing signaling mechanism rather than a than a liability mechanism absent negative acknowledgement is the only way to signal retransmission is to have a timer expire And, and and if you do retransmit. You have to retransmit the entire thing because you have no negative acknowledgements. So you don't have any partial negative acknowledgements. Does that make it at all. So anything that is lost has to be retransmitted in its entire 666, next slide. Oh, Eric. Yes. I was just gonna observe that I think it's not the countdown timer isn't the only way to know that you might need to retransmit depending on your convergence layer, might be able to observe a convergence layer failure like a TCP time out or something. Actually, I'm I'm I think I'm getting to that in a second. The, you're you're right. The, you know, absent the signaling from the convergence layer The only thing you've got is is is a time out. The the, custody transfer protocol itself doesn't give you any clues. The convergence layer has to do Yeah. Exactly right. Okay. So next slide. The problem is time out driven retransmission, there's no general algorithm for knowing how to compute the the retransmission, time out interval because it's different different parts of the network. Next slide."
  },
  {
    "startTime": "00:44:00",
    "text": "Even if you had something that worked even if you had ways of of of doing it properly at all points in the network. It doesn't do any good because as written in, BBB 6 and those were never required to accept custody. So It's not between topologically adjacent notes necessarily. The custom acceptance signal might come from a node that's 3 ops away. Or thirteen hops away. And of course, the custodian doesn't know that the Bible's gonna reach that note because there's another path that the bundle is going to take end to end, so it can't know when that's going to happen. So I it can't compute the length of time that it'll take so we wanted to reach that point and come back. And and and if it does retransmit, of course, it's always going to be excessive because there's no parts of the transmission. So the no matter what interval you you pick either the, the timer will expire too early. And in that case, you're wasting bandwidth and retry bidding stuff that's already arrived. Or expires too late. In that case, you're wasting storage and you're returning delivery. Next slide. Worse than that, and this is when it came up in in discussion, like, later on, all this can be fragment well, the if a bundle is, if custody is taken of a of a bundle, and the bundle is then fragmented by a node that does not take custody, then then the original bundle doesn't get received until it, arrives at his final destination. There's and and the and subsequent custodians, subsequent nodes may take custody of the fragments and the custody signals for those fragments will not go back to the original story. Next slide. Multicast, you have multiple copies, the,"
  },
  {
    "startTime": "00:46:02",
    "text": "the custody signals from the different recipients of the bundle, if it's held custodially, can't be mashed up because the custodians that they the, the actual recipients of the bundle may not be neighbors of the source node, so it doesn't know who they are. So it has no idea of knowing whether all the of, members of the of the, most gas group have received copies, and so it has no idea how to retransmit to them, to them, Next slide, This is talking more about the same. The corresponding node doesn't have to be any of the nodes to which the custodian transmitted the copy because nobody's retired and required to accept or refuse custody Next slide, so when the custodial retransmission expires, exterying doesn't know whether it has to transmit or not, because doesn't know which child knows received the bundle. In writing to receive custody signals, from more nodes than it that, nope that it knows about and it doesn't know which ones it did not receive. There's no way to match up the, constantly similar with the actual requirements for custodial retransmission. So next slide, I I think what we arrived at for BPD 7 is that the alternative is just not to do this, but instead to, rely on, reliable, convergence their protocols. Bundles, in in case of multicast almost as sent to each child node in the in the tree using, reliable convergence layer protocols where possible."
  },
  {
    "startTime": "00:48:01",
    "text": "And and whereas possible, this gives you reliable multicast. And the the general principle here is the converter server liability. Is the way to implement the concept of custody transfer. Next slide, this is the last one in this deck. There is, an exception to all this, and and this is this goes to what Erica's saying before. One converges layer transmission simply fails, the bundle either has to be retransmitted on the same convergence layer in in irons called an out duct serve the Crimson convergence layer channel. Or else the but the protocol agent has to determine that it that that route is the wrong way for it to go. And so the bundle needs to be sent back up stream to some other, branch point in the, in the networks are going on an on alternate route. So when it does that, of course, it has to forward the entire bundle for that purpose back to this other node. So it once again, you, you pay the cost of forwarding the entire one will serve on this hourly, and it'd be nice not to have to do that. An alternative would be for the upstream forwarders, 2 or 3 or however many generations back to retain copies of the bundles in case that we forward is necessary. In that case, then when when custody, conversely, transmission fails. You just send up uh-uh a hoops failed kind of, message back to one of these custodians, you don't have to send the entire bundle And that custodian then can re forward possibly in a different route. The it saved copy of that bundle. And, I would just point out that, a mechanism called, a mechanism for for status report aggregation"
  },
  {
    "startTime": "00:50:03",
    "text": "is, being discussed in the CCSTS detect working group that would do this, and that seems to be a a promising development that kind of resembles the original custody transfer idea but, is, more powerful and, I think more useful. And that's the end of my presentation. I can stop now. A I just like to say, Scott, thank you so much for that. We we get frequently questions about the concept of custody transfer and what between bundle protocol version 67. And, I think this deck does a a pretty good idea of explaining some of the thought behind it. Additionally, the, this working group decided not do additional standardization around custody, transfer because, other working groups, like the CCSDS working group, are working on a signaling, that that may do the same thing So it it it it it also is a a good opportunity to show where, we can planned the communities most directly needing this feature pursue it, and then we can understand ourselves whether we wrap it or profile Exactly. I Thank you so much. K. And it is you. Okay. Nope. So this is gonna be very quick. Next slide, please. So the updates on the APN URI schema draft, are very, very small. But quite critical the intention being to make progress on this draft because we have become stuck on issues around governance, around how Ayanna should hand out some of these critical top level items, the allocator identifier in"
  },
  {
    "startTime": "00:52:00",
    "text": "particular, So We have made a Change to the document and the only change that has been made in this document is to Cole, a lot of tech from the advice to designated experts regarding the Ayana Allocated identify registry, We have stripped considerations that designated experts should make So that is in particular some seaborvan, because of the nature of seaborne encoding, smaller integers are more efficient than larger integers. That is a that is a consideration that must be made when allocating these numbers, smaller less on the wire. More attractive. Is a technical consideration. What we have removed is all the language concerning governance policy, fair use access, how Ayanna should behave or hand out numbers because that is a far bigger topic than a technical which fundamentally adds another integer. To a, a a pupil of integers. So that's the summary on this slide. Next slide, please. So the governance policy text about this. So there's general consensus in the working group fair access to deep space for all delivered in a transparent manner is a public good. That I don't believe is a contentious statement, and I believe the the discussion on the text, discussion on the mailing list was very much around these concepts. As an author of this document, My pushback is the IPN update document is a technical document. A very dry technical document about adding another integer. Having a subsection in a technical document which suddenly starts talking about governance policy for deep space is bad editorial practice. If we if the working group or the community at large considers that such a document week. If that's"
  },
  {
    "startTime": "00:54:04",
    "text": "text about governance needs to exist, it should be in its own document. Where it can be properly reviewed and expanded and chewed over and pro treated appropriately rather than hiding it, accidentally hiding it within a very technical specification document. So the suggestion as an author is if working group members wish to write up a governance policy document, the chairs, and that's me with my chair hat on VAD the IESG and the IETF and internet societies as a whole, we'll do our best to find the right place for it, provide it sufficient time to be chewed over to be worked on as appropriate. But documented the right place for it. We've taken it out of here. The text still exists. There's a revision history. Next slide, please. That's it. We want to get the IPN document after working group last call, and published. There are people want to implement this. We can't keep holding it on the policy. Section. Is there anyone in the queue? Have I have I clicked a hornet's nest? No. No. Not at all. And And that was gonna be, my point back, which is with this update, we would like to put this into, what we believe will be the final working group last call So, with that, Given that, optimism, are there any questions or concerns or comments about, what Rick has presented here. Alright? Good. Rodney. Next up, we will hear from, Sarah Hiner again. One 0 config. Edge node. Okay."
  },
  {
    "startTime": "00:56:01",
    "text": "Great. So hi again, presenting this work on behalf of Brian Sivos who's published the personal draft which is the lightweight bundle protocol Edgenode would 0 configuration and 0 state and this is to address the use of existing protocols and mechanisms to stand up lightweight single application BPH nodes. Next line. So first some background, Currently, you have to supply existing BPA and CLA implementations with external configurations so that you can bootstrap into the BP network. And that configuration is a burden to network admins. Since it lacks a standard form has to be maintained and is redistributed when it changes. that configuration is also a burden to the users of the Edge nodes since it requires translation and synchronization when are made again. So that burden translates to a barrier to entry. To both potential users and for developers, a especially around prototyping and interoperability testing. So the goal of this draft is to significantly lower barrier to entry for lightweight, BP edge nodes. Which I'm going to define further on the next slide So if we look at a simple use case from the draft, I have IP Land, connectivity, And now I wanna get on the BP network And I don't care about the other CLAAs that are involved, the routing algorithms, etcetera. Just wanna plug my box in and have it work. That capability exists already in the IP domain. And there are existing mechanisms that we can use to provide that same capability forward BP you. We don't need new protocols or tools for this simple case."
  },
  {
    "startTime": "00:58:04",
    "text": "Don't need mechanisms like router to router discovery. Since this is purely at the edge of the network, We don't need general case CLA discovery. And the Edge node in this case doesn't have to support multiple application. So we're picking a simplifying use case to solve first because it represents a common need. It lets us make use of the existing work in this space. Next slide. So the draft identifies the existing mechanisms that support this proposed configuration and the new behavior that to be defined to allow those existing pieces to interact properly on a BP network. So the first half of the document addresses CLA discovery. It builds from service discovery on IP Network using DNSSD. There are several pieces needed to use DNS SD. That we already have including the TCP IP service parameters a registered service name and a certificate profile for authentication and authorization. The name for a new behavior here is at higher level to allow the router to offer itself and the edge node to enumerate and use that TCPCL service. The second half of the document then covers the 0 state BP agent. Which supports the use of TCPCL already to send in fundals. But if we can simplify its operation, to say that it supports a single application and CLA. Then the BPA no longer has to maintain state, it doesn't need queues. Instead, many of those BPA functions can be handled by a software library or in middleware. Allows us to simplify this configuration."
  },
  {
    "startTime": "01:00:00",
    "text": "Next slide. So it's important to note that the the intent of this draft is to not solve everyone's problem, this very limiting use case of an edge node supporting a single app is very intentional if your goal is to operate in an IP network, over TCP. We can reduce the burden of configuration and turn this into something like a library to import so that someone can then try operating on a BP network just same in terms of what it takes to get up and running. So keep in mind that these mechanisms are not for general purpose neighbor discovery for operation anywhere other than at the edge of the BP network. Or for operation over non IP networks or not over TBCL. The proposed mechanisms can definitely be changed a bit to relax some of the simplifying assumptions that were made. This is discussed a bit in the draft already. Which now has a second version posted to address the first round of feedback that was received. Next slide. And I believe this is my final slide. So for next steps, the, any feedback on the document or, even implementation feedback would be very much appreciated. Potentially, we see this as a good topic for a hackathon if there's any interest since it's an idea that's building off of existing mechanisms and infrastructure. And if you have points that are listed here around proper routing between edge nodes and some thoughts on requirements."
  },
  {
    "startTime": "01:02:04",
    "text": "I will just request that you take that to the mailing list so that Brian can also in those discussions. So with that, that's all I've got. Thank you, Sarah. No one in the queue. Just uh-uh, Rick, personal opinion, think this is really good work. I think it's I think it's really valuable to just chip away at these nice, easy edge cases, get a working solution that builds on existing technology. I think Good stuff. Thank you, Brian as well because I know it's it's primarily your hard work as well as Sarah Right? I mean, It is me. So That's the end of presentations on drafts in progress. And we wanted to use the latter half of this meeting to to raise a couple of discussion points and to discuss topics that are sort of pre draft but we feel as chairs and also personally through discussion with others as well that there are some hot topics that probably need to be addressed, and it helpful to do that with the background of some slides. So it's kicking off first talking about applications and how they live well in a delay tolerant. World. Got it. I've I've Hi. I'm Ed. And I've Exactly right. As as Rick mentioned, I did wanna put together a couple of thoughts on what it means to be delayed tolerant. And we talk certainly in this working group the delay tolerant networking working group. But if you have applications that have to run over a delay tolerant network, the the network can be delay tolerant you know, as much as it can be, if your applications aren't, that doesn't mean things will suddenly work. Right? There are things at the application level that that have to be accommodated. If you're operating in a particular environment. And then I wanted to end with a couple of thoughts on Deep Space as someone that that works"
  },
  {
    "startTime": "01:04:03",
    "text": "on deep space spacecraft and the flight software and the operations they're in, But I will also point out that, they're they're has been a very active, mailing list on Deep Space considerations and and how networking works there. And there are, sidebar meetings the one happening today, and I think one happening tomorrow. If you are also interested, please So find those and and participate. So The the first observation, which again, is probably not an earth shaking observation is pretty intuitive observation. Is that a tolerant network doesn't help an intolerant application. And so when we start talking about what does it mean to be it means all the things we tend to want out of our applications. We wanna to be very quick. We want it to not have to have a lot of delayed back to the user. We wanna be able to send our data very, very quickly. And if something doesn't look right, we wanna throw everything away and start over again. Hoping that by throwing everything away and starting over again, clicking refresh or something else, then we're able to get back to a normal operating condition. And we're willing to try and try and try until the stars align and we can make things go. If you need to be delayed, tolerant, Then there are some things that that probably you should be thinking about at the application layer. And if we need to operate applications in a delayed environment contested challenged and so on, then we should be asking ourselves questions of, are the applications we're trying to run inherently tolerant or inherently into So, again, One of the things that, we talk about for intolerance is when applications will determine when they need a response back. And particularly if those needs for response back are things that the application itself will act upon So if applications use application timers, that say, I I require that I get side of my application within a certain period of time, and that period of time is short enough seconds, minutes, or maybe even hours."
  },
  {
    "startTime": "01:06:03",
    "text": "Then, I always run into the issue of what happens if I'm in a highly delayed or highly challenged network. Another thing that can make applications intolerant is assuming that there are state synchronization mechanisms. And and we'll talk about why that's a state, can be a difficult assumption in just a slide or 2. But state synchronization means 2 things. One is that end to end state can be established And then once so established, it can be meaningfully kept up to date even if endpoints are coming and going, and then the last is the applications do assume that either the, duration of sessions or information exchanges are relatively short enough or the amount of state keeping is relatively small enough. That it can all fit within the compute resources of a particular node. And, you know, if we are on common desktops as we understand having thousands and millions of session, you know, sets of information is really not a problem. But if we're in very resource, constrained environmentally powered devices, then we really do start asking ourselves much information are we storing and why. So and and of course, even even a very resource environments, we know that there are things that we do to help pre placing data is important. And that's why we have content caching and that makes things work. We know that we're trying to go more towards, completely push mechanisms and not pulling data, because even in our very high availability, high rate, networks, we know that it makes things work better. Know that reducing the number of sessions that we have going to things like RESTful interface even if we have sort of, stateful state synchronized transport, not adding extra, state synchronization just because it's something that makes things work better. So we've already thematically look at how to make our applications a little more quote unquote tolerant even even on the internet. So,"
  },
  {
    "startTime": "01:08:01",
    "text": "When we get away from the internet, or when we extend the internet into different nontraditional areas, there are two things that I think we have to take a look at. One is the the tension between latency and intermittency, oftentimes, we'll talk about delay tolerant networks, right, the the DTM working group. And delay, could be interpreted, misinterpreted as the latency due to long signal propagation delays. However, that that doesn't necessarily capture what delay really means. Delay could mean not just long signal propagation delays, but also, I have lost contact with something that I'm trying to communicate with. A spacecraft because it's on the other side, for example, of the sun. Or it turned off. The radio turned off. So if we look at, the problem of delay tolerance as solely one of long latencies. We can fix that. That that's not particularly difficult to fix because, long latencies can be accommodated with longer timers. Or longer time outs for timers. And if we just hold on to state and wait, and don't time something out. That's fine. However, if we're trying to understand extreme intermittency which is Separate. And comes about because I have lost contact with something that I'm trying to communicate with possibly because it's no longer turned on. It has rebooted, or or some were gone into an idle state. Than simply extending timers is not a solution to that. So, again, the observation here is a latency solution is not necessarily an tremendency solution So as we look at what it means to have a tolerant application, We need to understand whether we're tolerating simply latency. Whether we're tolerating intermittency. The other, one that that is important to us here. To everyone is security. And there's a difference, of course, between transport security and communication security."
  },
  {
    "startTime": "01:10:03",
    "text": "And oftentimes if we have a single transport end to end, They look like they're somewhat similar, but but they are quite different. So, transport security is securing, at the transport layer. And it assumes, as we talk about it, that, you know, the endpoints of the secure data exchange are using a transport layer. And if you switch transport layers, then then you've broken that that chain of security. And that so if you're assuming that you have the same one and that you're not switching, That's fine. Communication security is different. That is the secured end to end information change. It's properties and carried with the data itself, and it doesn't necessarily come just from the transport layer, in particular, when we talk about bundle protocol and BP sec and and the fact that we could operate bundles over different transport layers. We we come to, the situation where a store and forward network may get data coming in over one transport and then it will store it. And then when it goes to forward it, It will forward it over perhaps a very different transport, certainly not the same tunnel, certainly not the same session or perhaps not the same tunnel and perhaps not the same session. But it could be a completely different transport as well. So we have to separate the concept of securing our data from securing our transport layer. And so, again, if we are trying to be tolerant of delays, we have to be tolerant of changes to the transport end to end. So in all of that, a couple of assumptions that can come out and and these sort of have a parallel construction, but we should be careful when assuming that systems are very capable and power. We should be careful about making that assumption. Because that is not always the case. And we'll talk a little bit about, one environment where it's not always the case. Which is deep space networks. But telecommunications systems in general could have very, very short duty cycles. I mean, yes, when we put a Nick in our server, that thing's gonna be powered probably all of the time."
  },
  {
    "startTime": "01:12:02",
    "text": "But if you're a small solar powered device with a radio, that radio will probably be powered off most of the time. And we can see realistically duty cycles for radios down 5, 10, 15%. We had to be careful if we assume that long run trip times only affect timers. Because again, if you have duty cycling, in in particular due to cycling, then you may be losing state not just, latency. Full about assuming that local processing is if we wanna maintain state end to end. That is additional memory. It is additional compute. It is additional, work. To store and restore, coming back again from a sleeper in idle state that very embedded in resource constrained systems tend to want to limit. Anyone has ever done boot, or or or state, restoration of a very resource constrained embedded device. People spend an awful lot of time worrying about that. And then again, we do have to be careful about that idea of a single secure transport. Because, with particularly long round trip delays, you may get into store forward situations, you may change topology. Topology changes may, caused you to change your transport decisions that you make. In all of that, if we come back and say, if we have delayed tolerate network, that are bundled based and we want, delay tolerant applications or at least not delay intolerant applications. Then when should we consider BP Inclusive stacks. And so there are a couple of things to think about as to whether bundles our, you know, solutions here again, a little repetitive, but when you have, intermittency and not late and when you need to do that store and forward, that is what bundles are built for in the structures of the PDU and the structures of security therein are meant to carry the annotative information to help with that. If your end to end is gonna be using multiple transports, the bundle is is meant to exist as an overlay over different transports. And generally,"
  },
  {
    "startTime": "01:14:02",
    "text": "when you are in a very resource constrained environment, bundles actually, the the amount of software needed to implement and use a bundle. And we saw just a a hint of that, in the prior presentation, when we were talking about a bundle agent, the the bundle API and satisfying it, can actually be done with a very small amount of code. And run very well on very resource constrained devices and carry, some, some of these sort of Features that we need separate from from building and implementing multiple stacks, which can bring additional code and compute. The reason why some of this is particularly important now is we are going, an awful lot of thought, route space networking, and some of that is is deep space. I I, myself, don't have a fully good grasp of what deep space means. Think it means, within the branch points, within, perhaps up to, you know, including says lunar. And I think people are arm wrestling right now over whether lunar does or does not mean each space. But but there are a couple of things I wanna make, and I just have two slides on this. One is, I I wanna talk about what kind of systems we might be building in the next 5, maybe even 10 years. If anyone has ever been and the reason for that is where the yet, right? And we we do wanna understand how to make engineering recommendations based on what might be proposals right now. If anyone has ever worked on a Deep Space mission proposal, deep space is expensive. You know, the some of the least expensive D space missions I'm aware of are around a $100,000,000, but but typically that's really, really small. And they pretty regularly go over a $1,000,000,000. because of that, you usually propose to a technology baseline technology baseline has to be something that exists, at the time that you propose it. Not I'm sure we will have figured this out over the next 3 to 5 years that it takes to build and launch something."
  },
  {
    "startTime": "01:16:03",
    "text": "And and a couple of examples of that that that I've worked on and I'm familiar with you know, the just for scale, if you will. You know, the new horizons, spacecraft was a was a, cost saving $700,000,000 was originally, I think a one one $1,500,000,000, project, running, you know, a blazing 12 Megahertz Mongouss Processor. Which for those who don't know, was the the same processor that was run on the original PlayStation. Although, significantly down clock, and I think was running about 8 megabytes ramp, we we did better on the Parker Solar Pro was a $1,300,000,000 mission, but we had an 80 Megahertz, Leon 3. Fault tolerant. And I, I, we might have had a little more than 22 megabytes but we we only use 22 megabytes of RAM, but we we only use 22 megabytes of RAM. You know, for the system. And then, folks may have heard about the dark mission, which you know, hit the asteroid, last year. Very successful mission. Particularly because of how inexpensive it was. At $330,000,000. To come in also running an 80 Megahertz Leon 3 700 with, again, a whopping 16 megabytes of RAM. These what what's interesting about that is, of course, is that New Horizons Parker Solar Pro dark The money that's associated with them and the time it takes to build them. These are not small investments. One would think if you're gonna throw a $1,300,000,000 of the spacecraft, wouldn't have a compute problem. You're on an 80 Megahertz Leon 3. Right? The the money is going into your instruments, safety, and just the fact you have to live in and exist in this environment. So we we need to understand when we talk about deep space, what that environment looks like and what people are willing to fly there, what they can fly there. So, my slide on this is, again, can well, and then uh-uh final get off the stage slide. Is there's always more. They The considerations, please, we have to understand what is the impact on RAM. What is the impact on our CPU?"
  },
  {
    "startTime": "01:18:04",
    "text": "What happens when to save power, power constraints dominate everything. Right. New Horizons, was was a nuclear powered. It was a radioisotope thermo generator powered by plutonium, the the irony that the mission to Pluto was powered by plutonium was lost on that one. But but we had about 300 watts of power at launch. Not not even. Maybe 280. And by the time 10 years later, we got to Pluto, it was down to 240 or something like that. Commitment to make for everything, instruments, heaters, computers, everything. So if If you don't need it, it's off. Right. You're not gonna just dump power it to keep your exciters warm. You're not going to have your radio on unless you expect. To be transmitting or expect to be receiving and you plan those. If you look at a 40 minute round trip time at Mars, You're gonna transmit a data volume. And then you're gonna turn your radio off. If you don't think you're gonna need it for 40 more minutes. To come back and receive something back again. And that's part of what we do with, like, Deep Space Network Planning is understanding when will spacecraft turn the radio on so that they can understand we don't see things like we're gonna stay powered all the time just because someone might want to talk to that that's not something you can do in a environment that is dominated by power constraints. So I've I've a couple of questions here and that I we we ask we are asked questions often in the DPN Working Group. About what it means to make tolerant networks. There's a larger question of what kind of app locations run on those networks. What does it mean to have an intolerant application or a tolerant application And what are some of the use cases and environments that drive you one way or another? So I wanna toss out there in the working group and then we can follow-up as well in the mailing list. But is there enough material here. Are there enough intelligent things to say about this problem in these tensions? That we should write an informational document of some kind."
  },
  {
    "startTime": "01:20:02",
    "text": "That says this is what a tolerant application is. And this is what it means to run in an environment, like a DTN environment. Or here are some use cases and problems that sort of evidence, why you need to think about the tolerance or the intolerance of your applications. And then the second is a lot of the D10 work was was, sort of, started, with that foundational document, RFC 4838, which define the delayed tunnel network architecture and some of the use cases there. And that was published 20 years ago, 15 years ago. Have we learned enough in the past 15 years or so, that there is an update to that document that should be if we were to look at that, are there things that that seem less important than they were in that document. Are there things that were missing the needed to be added. Yeah. Are there more important things to add do we feel that that document has held, firm over the past 15 years. So, that's really all I wanted to talk about was to put a couple of observations together, a little bit of considerations, with experience from deep space networking. Then to be able to come back and say, you know, is there is there value in producing these kinds of documents that course, if there is who would would do such a 2nd. Oh, we've got Steven in the queue. I see. But I I don't know. I have I'd have to reread 4838 And so I'd have no opinion on that yet. So I did. Can you go back one onto the the the the kind of Yeah. Actually, another one, but but the moment you're bringing in dollars. I'm not clear what message that's kinda sending to the working group in term in terms of if people are working on specifications that turn into ROCs, are you basically saying, don't expect this to be implemented and deployed in big space for another 5 or 10 years at least"
  },
  {
    "startTime": "01:22:03",
    "text": "So so if if you're well, so I'm I'm not suggesting that's a good or bad thing. I'm just, you know, I think it might help people to because, you know, as in terms of how they think about the process, because it's not the normal thing for IETF for those standards. Well, and and I think that's important because the barrier to entry is different. I I frequently ask lots of people for 1,000,000,000 of dollars. Only a small subset of them have a $1,000,000,000, to give and only a smaller subset of them are you know, to me. But the the, in all cases, for for those organizations that have the responsibility to write those kinds of checks. They want a established technical baseline at the time that something is awarded Sure. So so if we're writing RFCs and we say it's gonna take 2 or 3 years to get through the process and fundamentally change along the that's good except my my experience would say that missions will come back and say, we're going to baseline something else. Because it's not They have to pick during that 2 or 3 years. Sure. Yeah. Yeah. So so that that's that's a message. The other is really thinking through what are the impacts of the things that we are standardizing because the the cost is high, which means that things get locked in pretty early. And the constraints are significant. And and those are also things we don't typically work through because if we have If we're deploying something, have more compute resources, we can throw a little more memory at something, or we can We you don't get locked in very early in a 5 year development cycle for something that then has to largely unmodified for the next 50 years or 20 years or something. Right. Yeah. I mean, I I think the, you know, some so I think the basic message is, you know, for the RFCs produced by this working group. When you're trying to think about those being applied in in deep space missions, it's not even gonna start until, like, 5 years after the RFC's written kind of thing. Because that's when they that's when they would say to say we'll adopt that That that But for other applications, it might all happen much quicker."
  },
  {
    "startTime": "01:24:00",
    "text": "I completely agree. And the only reason I hesitate on that is there's a lot of private interest in space and deep space and and that's, of course, any any private companies can do what they wish. But my experience is that the the agencies that, like, NASA that built these things, they want that. Established at the beginning. And so if your RRCs aren't gonna be done for a few years, it's not gonna be in the technical baseline for anything coming around right now. Yeah. So I don't know. Yeah. I think experience visa is they're they're the same, basically. So Yeah. Derek? At you. I wanted to say that I I think there is, value some of the work on, especially if you go back to the last slide. Particularly if one of the thing, one of the outcomes is we elucidate the requirements for the API. Between on the protocol applications. And an agent running. Like, if you think about the I the IP IP networking, We have taps now, but prior to that, everybody pretty much understood PSD sockets, Hazakh's Libc calls, etcetera, etcetera. I don't know what that is for bundle protocol application, but we should probably it would be good to have that scoped out to understand applications need to get addresses. They need to do this. They need to do that. What are the things they how did they do it? And end up drafted Right. C style API or anything like that, but, a TAPS style API requirements or something. Would be a a useful outcome, I think, to encourage some standardization across, app app writing. Heavy, heavy. I'd like that. I would love to read that Yeah. We have no submission API. We I I don't know how to send a bundle unless I know exactly which BPA implementation I'm using. There's a whole lot of stuff that happens at the control plane sort of magic provisioning layer that's Yeah. Just magic right now. Yeah. Thank you so much. Thank you, Ed. So we'll swap."
  },
  {
    "startTime": "01:26:02",
    "text": "So as should become obvious fairly quickly, Ed and I talked quite a lot, which is we're supposed to do that sort of thing. And, so my slides also it's looking more at The recent discussion we had on the list about quick, quick, quick, quick and the use of IP. In deep space. So thought I'd start with an emoji because I'm far too old and far too British to be using emojis, but I don't k. So next slide, please. Oh, important. This is meant to be gentle, slightly tongue in cheek. I've included some light quotes and jokes because I don't think this is a subject we should fight about and that's actually my underlying message. So as you're all probably aware, there was some really active debate on on 2 mailing lists, but let's not get into that. After Mark and his other authors posted the, draft many deep space IP assessment touchment which was well read and well reviewed, which is fantastic. And Yeah. And he asked some very he and the team asked some very good questions. Which is, you know, whether the requirements of communication and deep space could be addressed by a pure IP solution, particularly you know, by using quick because quick is is good and has some very good features that that didn't exist 20 years ago. And I participated. And I wanted to present my personal opinions, so this is chair hat definitely off. Next slide, please. So As I understood them and Mark is at the back of the room, so he can correct me where I go wrong. The core points of the argument for using quick and deep space Well, IP works. It's it's proven technology. We've we've, you know, the internet's pretty good. Seems to work pretty well."
  },
  {
    "startTime": "01:28:01",
    "text": "IP hardware and software exists, you know, commodity pricing and the the tech stacks out there I can find people who know how to write networking software. I can by networking software, I can bi networking hardware that all runs on IP, and it just works. I mean, That's a no brainer. And, yeah, I can't remember the name of the RFC, but the the the work that went into looking GCP IP over very long RTTs, about 20 odd years ago said, yes. There are problems with time of retransmissions with TCP, and there are problems. But you know, quicks around now. We've learned a lot in the last twenty odd years about dealing with very long latencies and and keeping sessions, alive and and they made some very valid points that quick can handle these these long RTTs. Without much problem. And the whole IP management, you know, you Dan pointed out the whole IP management stack you know, Netcon Freshcom, SNMP if you wanna go back you know, it that's there. It exists. It works. We can We can buy these pieces of kit, and we can manage them, and we know how to do this. You know, there's a whole the whole ops field exists. We can do this. So Next slide, please. And there was there was just one comment in the chat on on this slide deck, which is the the last bullet on management. There there is some That's not necessarily true. Yeah. Yeah. Sorry. I am making gross generalizations. There is a question. Here. I will I will admit I'm I'm I'm shredding softly. I'm just exploring. So next slide, please. All of these points are valid. You know, you're sure they're recorded cases where, particularly, you know, you might why why do we have to use XML? The XML over long distance is bad but the core points are valid. You know, IP works. Quick can probably handle the latency problems. That's fine. That's great. Next slide, please. But"
  },
  {
    "startTime": "01:30:01",
    "text": "And this goes back to what Ed said. What is deep space? Well, I'm I'm gonna use the hitchhiker's guide to the a quote because a, I like Douglas Adams, and b, I think it sums it up. It's really big. You know, we're talking beyond Leo Geo. Stuff here. We're talking out. You know, next the next generations of of human exploration into deep space. When I talk about it, I talk beyond Sicily and beyond La Grange Point of we're at we're talking about the big deep space stuff. Okay? Next slide, please. Does the size matter? I just it makes for great title. The size does matter because it introduces physical problems that the internet doesn't have. And and this is where I'm starting to repeat something some of the topics that Ed covered. And so I I won't go too deep into delay is one aspect. Sure. When we start measuring things in au, you know it's got big, when the speed of light starts to matter significantly in your round trip time calculations, you know things have got big also things move, you know, that's orbital mechanics. But things are moving, which means that link from a to b is going to change over time and So, you know, you're not laying down a really nice fixed apology fiberoptic cables anymore. It's it's things are moving around. I think the the the second part is actually disruption. And this goes back to what Edward was saying as well. Planetary bodies are really good occluders. If you're using radio systems or or opt systems. They're they're getting the way they're a pain like that, pointing beams over long distances gets really hard. Interview. Working over the pencil. It's it becomes quite obvious how hard it gets And This is what Ed putting his slides much better than and I've summarized him one line operating technology in deep space is actually all about power. And assuming that your devices are at all times, is is a false assumption."
  },
  {
    "startTime": "01:32:00",
    "text": "And sure we'll get smarter with power. We'll fusion in another 30 years, I'm sure. But we're still there will be another fuzzy edge where we'll be pushing those boundaries where delay and disruption and power dominate what's happening. And I think, you know, as as we expand out, that Fasierge would always be there. Next slide, please. So DTNs. So this current approach to communication in deep space is to build store and forward. Networks. That can survive that delay in disruption. Which we find in deep space. You know, when with all of those points that that both of us have now brought up, Relaying on an end to end communication link stops being a a viable way forwards and saying, okay. Let's store forwards hop by hop. It's a little bit of a no brainer, but I wanted to reiterate some of these points. And the approach within the IETF Working Group is to standardize what I am paraphrasing has. And information centric. Storing forward, overlay network. Built around the the bundle protocol is the is the implementation detail of that. And I am a rude observer at times, and I often describe Digi and Achi's email done right. You know, male travels you know, hopefully we'll fix the spam and binary in, but Next slide, please. Because I just want to unpack information centric storing forward and overlay network. And why I use those terms. Information centric. Is because the basic unit of communication in a GTN that we discuss is an infogram It is a self contained, self describing package of information. As compared to 1500 Octet datagram. A stream of fights. Datagrams and bytes, I can't remember the name of the the model which has data information, knowledge, wisdom. There's it's a you're quite an old fashioned psychological"
  },
  {
    "startTime": "01:34:01",
    "text": "that the or business thing IP networks move bytes. Bundle protocol moves messages. A message is in has informational value of its own. And it is self contained. If you get to the message, you can do something with it. If you get some bytes out of IP, you probably need some context in order to work out what that is unless you can fit the whole thing into a 1500 into you or or whatever. Point 2. Storm Forward. It's explicitly understood that you will not have an end to end path. A lot of the time, and therefore, you should not expect an end to end path. So assumptions about how addresses are resolved needs to be hot by hot. You need to understand that your security needs to work at rest and and Ed covered this with the difference between transect and commsec. Very important. Fact that you may Scott was talking about some of the custody transfer problems. You may have effectively bundles going backwards up the transmission path in order find a viable way forwards. Changing transport layers It's key expiry and things like that. These are complex topics. And I think the most important part of what we're building is an overlay network. I mean, we don't often address this. The bundle protocol rights on top of other trans sport protocols. It's a bit weird being in transport when we're an overlay. But what we don't actually solve is you know, traditional OC model that the layer 2. We don't give a damn about the layer 2. The layer 2 is actually layer 3. In in IDF terms, we write on top of this stuff. So, yes, we might have convergence layers and define convergence layers, but we have the TCP convergence layer. Which which which which writes on top of IP. We have UDP, LTP, again, is a is a way of"
  },
  {
    "startTime": "01:36:00",
    "text": "of moving freight and getting a bundle from one hop to the next logical hop one of the in the overlay, but what happens underneath is pretty transparent to bundle protocol, and it doesn't should he care. Next slide, please. Okay. So BP does not equal IP. That's starting to to to take off as a catchphrase. Remember. I think it was Jorge who started it first, but it yeah. I I like it, so I'm asserting that. I assert that it makes no sense compared directly IP with BP. Because they are serving different purposes because they address different use cases. However, and I've I kind of mentioned this before, IP is already part of the BP stack. You know, the only standards track convergence layer we have He's built on TCP. And we know TCP doesn't work in deep space. But it doesn't mean it's not a viable convergence layer to have in your toolbox when you want to build repeat networks. Is why we standardized it. Are other things which may work better for particular environments, but going back because bundles run across the bundle overlay network, that choice of link routing other by hop transmission protocol can be made hop by hop or by implementers or with a sufficient flexibility. So And what's what's important there is that but what bundle protocol considers one hop maybe many, many hops in the underlying network. So you could consider a a bundle that comes from some deep space probe hit some ground station and is then delivered to a researcher's PC that from ground station to researchers, PC, may be one logical bundle hop. But it may transit half the internet to get there. So There's a It's overlays. I'm I'm assuming you know about overlays. I I'm happy to take that question from Jen"
  },
  {
    "startTime": "01:38:06",
    "text": "you. It's a very quick question. Just to clarify something for me. I'm muted group. So But that's why I kind of wanted to make go over this new switch from it. I'm not new the problems on my Yeah. I should not talk about this now. My question there, when you say it's, do you only have an implementation on There's no relation to CCSDS protocols right now at all. Let me clarify. Sorry. We the IETF has only standardized 66, as a, a standard track document K. That's awesome. Thank you. A little bit of detail. Yes. There are lots. CCSDS is now, continuing the standardization of LTP because it's very deep space. There's personal drafts on UDP, Eric, to your left, has a early draft on an ethernet there's lots, and that's that's part of the model but we may not we're a little behind on the standardization, but please start typing. Next slide, please. So a little bit of Rapotional and and for those who don't speak French, I'll I'll let you Wiki Wikipedia has a good example of it. Quick has some fantastic properties that would make it, and I deal convergence layer. And when we mean convergence layer, the technology that makes the hot top of work. You know, the deep space IP draft explains how you can run IP you in many non terrestrial use cases. Very successfully. IP networks already exist on the planet. Obviously, I'm using 1. But Leo and Gio, they're on they're already running IP and and more and more of it will happen. I can see IP networks being native on the moon the next 10 years. Correct me those who know more about this than I but my predictions, and I can imagine Miles having a native IP network at some point."
  },
  {
    "startTime": "01:40:00",
    "text": "And that doesn't mean bundle vertical is pointless. But it also means, oh my god, there's some transit networks we can use. When we're trying to move things around on a planet before we try and get it off a planet or get it back a planet from somewhere else, what elsewhere. So so quick would be fantastic. To let us move bundles around. And a quick convergence layer is this appears to be a no brainer. TCPCL describes how to frame things and, a stream orientated reliable transport. Quick, has very much the same. It's multi streaming with our head of line blocking, which is fantastic. Built for for HTTP. So what we do for TCPCL is entirely transferable across the quIC. We just to work out which streams and how to do the multiplexing and demultiplexing, but it doesn't seem hugely complex. And then suddenly, we can build on all the great stuff that's in that deep space IP draft and say, great. Through quick and IP out as far as it'll go. It works. And then we can piggyback bundles onto the back of that, and then bundles can do the bit which where IP starts to, to show some fuzzy edges because of going back towards presentation. That, that, disruption that delay that distance, which really starts to kick in In combination, these things make a lot of sense to me. Lost. Next slide please is my last. I think this is my suggestions of What we should probably do in this case? I think it would be really good to continue the the the work trying to make quick and IP working let's call it near space. Whatever that means. Says find out the limits. Let's let's go find out the limits. Let's find out how far this stuff will go because it's good tech. Let's standardize the BP conversions there on quick. It shouldn't be too hard, but I haven't started typing it. Famous last words. And then let's roll it all out. Let's roll it up, and quick. And bundled protocol as well, everywhere we can."
  },
  {
    "startTime": "01:42:00",
    "text": "Soon as possible and get it all running. Because otherwise, people will keep reinventing in isolation in silos. And The internet has proven that despite all the flaws in IP, having a consistent protocol to allow the transmission of traffic around on on this planet has made a great deal of sense If we can push that out as far as possible, it's probably good for Humanity. And can we have one maiden list, please? Cause I bought a following 2 of them and crossbow And because we're talking about space, I had to put Livelong and Prosper because it's about I'm trying to get a bit of humanity in here as So, Yes. I will take questions. That's my last slide, I hope, or I'll just duck and cover. Oh, we do have. Oh, here we go. Yeah. Yeah. Yeah. Yeah. Yeah. Stone fight tool. So this question here. Kimji, CMCC. Here, you talk about, like, a deep space or kind of, the very big, big picture here, actually, you know, without the, I I try to get some information about, like, computer, like, satellite satellite constellation part. It's also fit into the DPN things. Because, you know, on the other side of the SEO, Derek Cutter, working on some satellite based Mhmm. Based the communication, there are some released 9 team work to give, like, the store and the forwarding. So, basically, the thing you're talking about here, and also, I think it satisfied the first point you mentioned, like, the information transfer the second stop forwarding. The last part, something. Like, I think you mentioned the three points. The last part is, like, decent our latency or intermittent something. Yeah. Yeah. Probably intermittency. Three things. So, all the three things actually on that, the store foreign satellite, fitting into this part. And then, you know, I I come here, try to get the, you know, some"
  },
  {
    "startTime": "01:44:04",
    "text": "some insight or help about here, Costa in strategically side for this type of store forwarding, service. Costs, they are trying to say, okay, for some very some application or services, like, a Mail key or short message that itself is the delay tolerant application. Because that that will make the life easier at this moment. So there are some architecture assumption there. Okay. For the SL in the second link. That is something out of the picture right now from the security side. But here, actually, I come here, monk say, okay, for the actually, I think, for the 6 g on next things, this will, play into the picture not just, MBIoT. I'll, like, a short message. They'll tap delay turn application, but for delay in pattern application, will need to use this VPN network to do the work. So when I look at the things and then listen to the the other of the session here, I have not found that part from, you know, the working group. That is the same. Go ahead. You you look like you've got answers there. Well, never an answer, but a comment. So the for particular for when we talk about 3 g, and 3gpp. 3gpp. There was some work that was done a few years ago. So to look at what it would take to build delay tolerant applications in, I think, at the time, a 4 g LTE scenario. And and I don't know if that work sort of would help with this understanding now the things like the the the email will be out genome at the base station will be unbar stuff Sure. So that will be different from the one you mentioned about that thing. Remember, it's like, when the onboard satellite, the best station, you are going to have the ASR link and also the, the the the feeder link will be delayed in the middle. All kind of things you're talking about here. Yep. That there was, the work that was done was"
  },
  {
    "startTime": "01:46:00",
    "text": "something around, something called a a a def a deferred bearer or a delayed bearer. And, and so it was the idea that local applications could send their data to a a cashing proxy bearer which would then be, attached to a dedicated bear that would be established later. And then the the caching proxy would allow data to flow without the application understanding that it delivered data to a bear that was just holding on to it locally. Waiting for it to be transmitted later. And that was a way of hiding the store and forward. In in a bearer, a store and forward bearer, that the applications don't need to know about it. And that was implemented and tested on the International Space Station. To to show that it would do the work with between the ISS and ground stations. Okay. Oh, but the sync data is not on the the the 5 gs back. Itself. That's that they're using something the different here. Because the stuff faring itself, the store will be on the, you know, some place, not based on the barrier you mentioned, because the barrier there is just used It's the way to transmit, not the way to store. There's no specific, like, a barrier for data starter forward. That's only just a general, the DRBOS R visa. So so so so I have a I have a general comment particularly about Leo. I think Leo is an interesting use case because it's not on the surface of the plan it's really close. I mean, it's it's really close. So some of the assumptions built into a general purpose DTN using big fat bundles, which is what we're talking about. Probably don't apply to Leo, and that's fine. It may be the case that the store, and I don't know a great deal about the 3 g p p work. Going on at the moment. But it When people talk about store and forward, sometimes what they're talking about is big buffers. And delay. And some so that so that they're still trying to maintain that IP"
  },
  {
    "startTime": "01:48:02",
    "text": "I've got UDP Datagrams, or I've got basic Datagrams, or I've got a stream of things with some selective acknowledgement or or whatever. And if I've got some intermittency, I can just put a big buffer in there and try and solve the buffer bloat problem, but that's that's there. That's to do. What we're trying to do with This working group is to say That's fine in Leo. But there are other environments and other use cases where it doesn't work. So can we do 2 things? Can we provide a solution which will work elsewhere. And can we play well with whatever they want to build in or standardizing Leo, I think we can because if they've got an IP layer, or something that will carry bundles. That's great. You know, somewhere with you within your, ENAB, you could have a bundle service. That says, well, I'm doing all this this, store and forward at what loud they wanna do a test. But if I've got a bundle, I can use that and I can move the bundles on, and then suddenly bundles can transit through through LEO Networks. So Agree. That's it for both. One more. And and Steven Jack. I I I hope I'm not asking the implied question. I'm a little confused. So, There's been a whole bunch of discussion about, some of the the proposals, Marcus, do you agree that, you know, exploring that may make some sense. Whether it's one list or 2 lists, I don't particularly care. 2 is confusing. But were you proposing that that that kind of expiration be part of the working group work or no? Sorry. Sorry. I the chair hat definitely off. Not talking about process or where this should happen. Just in in my personal opinion, I don't wanna turn around to Mark and the guys who are looking at how to make quick and IP work out with long latency and"
  },
  {
    "startTime": "01:50:00",
    "text": "and big RTTs. Keep going. That's great stuff. And what I'm trying to do, I suppose with the whole point of this, I'm trying to decouple the how dare you write something that says it's bundled protocol. It's irrelevant to you know, that that slightly naive knee jerk reaction I read between the lines on the list, where it actually we're trying to address 2 different problems, and they are there's a lot of overlap. And they are compatible with each other, and they're actually trying to achieve different things. So I'm kinda saying Okay. So Everybody calm down. I think we're fine here. Yeah. I know. That's kinda fine. So so what you're assuming then is that the 1st Volus, would not be in the charter of the working group So Which that is not I think, but No. No. That what first bullet is I'm pointing to it for those remote. The the the first bullet is out of scope for the current charter of this working group. Exactly. So the second bullet is in scope for this working group. That's clear. But I think then in that case, the first and last bullets do could create a kind of a a bit of a funny situation. Right? Yeah. I I did that have one made in history as a frustration because we were having the same subject duplicate, there's might be a plea to the ISG, and I, you know, to say Yeah. Does this go back to quick? Or do if quick says there's too many of us in quick already, do. Does it spin something else out, but it would keep keep doing So I wanted to make a fine, but I think, you know, if you have one mailing list, then some things that are in charter and some that, that's gonna be tricky. However, so I think the other thing is, of the kind of tension here seems to be assuming that Yeah. We're gonna end up at an hourglass, and there'll only be one waste Yes. And you know, it's either gonna be the multi protocol or quick and can't do any mixture. I think that's gonna not correct. And then it's also, I think, not correct. There's any one kind of measurable thing that tells you when it's right to use the bundle protocol. You could talk about bandwidth delay products and disruptions. In fact, what might make the the difference is whether applications exist, but"
  },
  {
    "startTime": "01:52:04",
    "text": "run-in that stack. And maybe if you're running those applications over quick, it'll run like crap. But it'll work. Yep. And you can't currently run those applications over the phone protocol for whatever In that case, you're probably gonna choose quick. Right? Yeah. Yeah. Absolutely. Right up until the point where you go, this is now so crap, Yeah. We've got to do something else. And and at that point, I don't think you can yeah. So my contact is only this that I don't think you can characterize the crappiness by Annie a metric, Oh, yeah. There's all sorts of other stuff that goes out and loves it. So Yeah. I I I hope the, I hope the first bullet is ends up being true. I don't care if it's one that I missed or not. I agree that there shouldn't be this either or kind of tension. Yeah. Thank you, Steven. Sorry. Perhaps I should have I I in retrospect, that last bullet should be have some organization about the mailing lists and where this discussion happens because tracking two conversations and two lists is just a pain. Anyway, one more? Oh, there's more. Mark. Cool. First off, thank you, Mark. I'm not blessed. I just want to Oh, well, Let's see. Correct. But make sure that with with we've been working on is is not only quick. Yep. So, you know, quick is an important piece of it We're looking at the whole stuck. Right? And it's only when the whole stack you know, all the pieces of the whole stack. Actually works that in a the whole thing word. So It's fine that you say. many times, you know, So it's a short short time. Sure. I've heard know, it it's not only quick, so it's actually an art trigger. Endeavor is 1. No. Which would be fantastic. And as far out as you can push that, going back that to the my first slide is IP works. We've got the kits. The price points are really competitive. If we can keep"
  },
  {
    "startTime": "01:54:00",
    "text": "if we can make it work as a further bubble than the surface of the earth, great. Because bundle protocol can still ride on top of it, so there's no fight. To answer. Such Yeah. Hi there. Your really nice, Eddy. So I I mean, this is fine. I mean, we are understanding ourselves. Like, yeah, there's, like, a different kind of sort of work and this is related, not really the same thing. That's important. And that's where the related part is where I was trying to make sure that the deepest space and DTM expects the talk. And and I agree. Like, having, falling to mailing lists tough thing. So obviously now that you guys are like, this this whole things are, like, con this conversation happened. I don't really care. Which mailing list you more, like, proponents or whoever weeks to take one. We have mailing lists. So that's not a no brainer to me. So So I have the deepest space kind of discussions in the deepest space, mailing list. And DTM to do the DTM things is fine. Now and then cross posting to announcement and all this thing. This is you do use our common sense, basically. I'm happy to see, like, we have kind of an understanding, like I just said, like, related part. But it's a separate thing. As you're saying, like, this is trying to to different things. Whenever I say quick, this is good. I would likely likely do as a responsibility for quick working group as well. I would like quick to be more general purpose than, web thing. So please do experiments and and and as I'm saying, do experiments. So one I would like to know Like, if this thing's more an experimental or this is more like an, ready to standard. I think I have a chat with Mark before. So I think in this they will be talking about it. So this is good. So I I think we're in a good shape. Yeah. I do as well. I really hope we are. So so Yeah."
  },
  {
    "startTime": "01:56:01",
    "text": "Thanks, guys. Yep. One over time. But we still have some. So we left this bit of the agenda for further discussion because we didn't know how long previous how contentious those previous two presentations were gonna be, or if anyone else wants jump to the mic to cover anything else. So yeah, open mic. Join the queue or Yeah. Yeah. Thank you. Sorry. This better. I'll intro I'll introduce myself a bit better. My name is Ensfincoza. The reason I'm here is sort of several different reasons. One is I come from a more internet protocol background. My wife and most of her friends, from space industry. So this overlap interest immensely. And I'm also, for my work, doing effectively. Well, how what did you call it? An information centric, going forward, hopefully in the work. So there's there's a lot of shared interest there. One of the things I've been working on in I've been shopping around for a working group and I send them mail to dispatch think this morning or last night, it's a bit of a bluer. Is actually a a container format. That gives you communications encryption, that gives you some sort of multiplexing of data, that lets you chunk it up, that lets you reassemble it And I was wondering whether this group is sort of, right place to talk about this. But we have one. Have one. Yes. Nice. Have a look at RFC 9171, which describes 920. Bundle protocol. Format, which is Okay. Seaborextensible. Okay. And and with an associated security. So Okay. I I have no problem looking at this. I have no problem making comparisons."
  },
  {
    "startTime": "01:58:01",
    "text": "If I find that there are things that you're not doing that I'm doing and vice versa, is it still place to mention it. Yes. Absolutely. That's all. Thank you. No. We're very open to contribution on on making this better a faster, smarter, Okay? Alright. Last call for comments. Last call for calls. Last call for last calls? Well, we are 2 minutes early. Thank you so much. Will see you in 119. We're in a minute. Thank you very much, guys. Hey, how are you? There's only need to be something question the That's right."
  }
]
