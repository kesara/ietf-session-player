[
  {
    "startTime": "00:00:46",
    "text": "okay who\u0027s ready for dns SD yay yeah there is okay so you know what the first questions are who\u0027s gonna be the note taker in the jammer scribe one don\u0027t be shy you know you\u0027re the ad that\u0027s just people sitting reading their email please want somebody help with a bird or devil taking pretty please I can do jabber we need a note-taker I\u0027ll be on a third pad - but I need you no thank you on etherpad it\u0027s synced up you\u0027ll find it on the agenda there\u0027s a link to it that\u0027s my favorite place or even just if you get to the ITF agenda yes that\u0027s right sorry we\u0027re not speaking in the mic yes right but it does oh wait so like it\u0027s directional yeah these are incredibly directional [Music] all right thanks all right welcome to DNS SD if this is not the working group you\u0027re looking for this is the wrong room so especially since this is Monday this is the note well please note well the note well in particular and seriously do we do it if you haven\u0027t and if you\u0027re a new would ITF attendee or if you\u0027re a longtime ITF attendee who still hasn\u0027t read it just talking at the microphone actually is liability for you in terms of patents and disclosing them so if you know about patents and you go say something you have to say something so before you do make sure you read the note well and know your responsibilities we also have "
  },
  {
    "startTime": "00:03:47",
    "text": "a code of conduct which is discussed there so please read it those things and behave accordingly all right thank you so again some reminders that should be obvious to people but even the people who have been here for the longest are the ones who forget the most often please state your name clearly any time you go up to the microphone and please review documents and send feedback on them even if the feedback is just looks good because when you write documents you also want other people to read them and the blue sheets this is a reminder for me to send out the blue sheets all right coming so that\u0027s the part one the second all right the blue sheets will be coming to use very soon all right we have a minute taker and a jabber relay did the bow for you find the link for the etherpad stir cool thanks so we have a jabber page I\u0027ll be keeping an eye on it if people say something there I\u0027ll relay it at the microphone so these are just lengths for people kind of horror not necessarily in the room or looking at this PDFs later but they\u0027re just the nature tracker for what we\u0027re doing as a quick reminder we have a working group github organization we encourage document authors to move their documents there if they feel like it but it is absolutely not a requirement and we have a new area director so all right we will on Thursday have a new area director so first off I like to take a second to thank Terry for his years as a director so could I have around my pocket it\u0027s been an absolute pleasure this working group has been one of the most collegiate professional active working groups I\u0027ve ever had the pleasure of being engaged with thank you thanks Terry and thanks to the Oracle participants for making that that way and let\u0027s keep it that way because it\u0027s great and let\u0027s have a round of applause in advance for Thursday for tipper Eric who\u0027s gonna be here all right so our goals for today are and they\u0027re not just similar to where we were at three months in Bangkok but we\u0027ve made progress on all these items which is nice so we\u0027re gonna start with the discovery proxy pushing Steve flops which we\u0027ve been talking about for years but we\u0027re very getting very close to done we\u0027re gonna talk about also the update prophesy private subdomains timeout resource records then keep making progress on privacy which is still you know really big what kind of for us and then maybe time "
  },
  {
    "startTime": "00:06:49",
    "text": "permitting spend a little time about reach our during afterwards so kind of similar to what I just said here\u0027s our official agenda would anyone like to bash the agenda is there anything that you would like to add there or things that you think we should not be discussing all right thank you and we\u0027re start off with Stuart yeah hold on all right try again look what button are you using now I did you but you need to go in the other order as well okay try now yes all right thank you David we have three documents we\u0027ve been working on for a while that have been slowly going through the process good news DNS stateful operations published a last Friday RFC so that\u0027s good I\u0027m really happy with that document I think it is my name is on it so I don\u0027t be too self-serving but I\u0027m really happy with it and I think it can be a good foundation for future extensions the first of which is push notifications we\u0027ve been through working group last call with this we got some good feedback and Ted lemon has been implementing this and in a way it\u0027s lucky that while we were putting Deanna stateful operations through the public publication process we we were sitting on this and holding it because Ted discovered a small flaw we had previously before DSO existed made the decision to adopt the DNS update record formats because we\u0027re we can reuse existing technology instead of in venison new that makes sense since that happens DSO came along and to find the TLV syntax that goes after a conventional DNS message and makes the argument that this is a cleaner way of expressing data rather than rather than trying to overload existing fields and give them new meanings and trying to massage things to look like a resource record which i think is good advice we were still using the old DNS update format which does exactly that it tries to overload Sora\u0027s record formats and what Ted noticed is that in a DNS update the first record in the question section "
  },
  {
    "startTime": "00:09:50",
    "text": "which is called the zone section in an update tells you the DNS class of the zone we don\u0027t have that section in a push notification and when Ted was actually trying to implement this he said that there\u0027s all this weird overloading of what type and class mean in the records to mean add a record or delete a record or delete an entire RR set and what we\u0027re left with was that the DNS class was unspecified now DNS classes are not really used so maybe that\u0027s not important and we can just forget it but I kind of feel like it\u0027s not our place to be making that decision if DNS oak decides the classes are deprecated I\u0027m fine with that but this is not the document to make that decision so with that and the realization that we don\u0027t have to be constrained to look like resource records we came up with a simple change semantically it\u0027s no different base just a different syntax and I will send a summary to the mailing list but while I\u0027m here in the room we would like people to have a look at that and see if they agree that this is a trivial change and everybody\u0027s happy with it and along the same lines Ted noticed that the reconfirm operation has a reply but there was nothing a client could ever do with the reply that was useful it was just extra bytes being sent it was extra code being written waiting for a reply just so you could ignore it so while we\u0027re making this change it seemed like a useful simplification to just get rid of the replies so make reconfirm a unidirectional message instead of a request response so I think those are two worthwhile improvements and we have updated the document with that new text I think probably it\u0027s worth spending the two weeks to do a workgroup last call and I fully expect that we\u0027ll have no comments in that two weeks but we should give the working group for a chance to respond and after that we\u0027re clear to go to IETF last call is you review and let\u0027s make it a goal to have this one with an RFC number by the next IETF meeting in Montreal then the other document discovery proxy actually Stewart yep before we move on to that so to give people a little bit of context the DNS Bush document had gone through last call before which had passed and I think Stewart\u0027s approach is really good doing it again if well first off does anyone in the room if you have any objections please come to the microphone now otherwise we understand that maybe not "
  },
  {
    "startTime": "00:12:50",
    "text": "everyone has read the latest document and maybe having stored summary on the list will be helpful so we\u0027ll probably start the last or well start the last call now or whenever I get to the data tracker and it\u0027ll go for two weeks starting after the end of this meeting because everyone\u0027s busy during this week but all things considered I think it all that move very smoothly because we have had a lot of review of this and especially now that we have an implementation which Ted will look into we\u0027re in really good shape so thanks for everyone who put a lot of work into this yeah we we had some debate about this and and part of me just said let\u0027s just let\u0027s just leave you to not worry about it you know add a sentence that describes the problem but after we discussed it a bit more it felt like we want to make a good protocol we don\u0027t a compromise and and at this point a little bit of extra work now to produce something better in the long run I think is the right trade-off teri mandersohn currently still ad I think I concur with the the last call the semantic changes you are made are substantive and I would I would have pushed back anyway had I have still been in the chair when it got to me I would still be advising Eric in such a situation to push back on those sort of changes and hopefully he would also do the same thing for consistency so yes great idea thank you just to clarify when you see pushback you say I mean style last call I\u0027m not don\u0027t just try and throw it up to the the iesg or review absolutely do your own work make sure it\u0027s as clear as possible and there\u0027s consensus in the working group on everything so on the second document discovery proxy this has been through workgroup and ITF last call and this is right now in the state of waiting for push notifications to be done which was waiting for dns stateful operations Ted and I have also been working on implementing this and we in the course of discussions of explaining this it became clear that there were some things in the documents that could be explained better so I have made an attempt to improve the document to explain those things better and I have a summary here none of this is changing the behavior or changing the messages that are sent it is things that we realized were kind of implicit but not stated explicitly one of those things is the unicast subdomain and the dot local collection of information on the local link are more or less a bi-directional mapping one is mapped onto the other and for every "
  },
  {
    "startTime": "00:15:53",
    "text": "query you do with the delegated unicast subdomain that maps to a corresponding multicast query for almost everything but there are some exceptions and I added some text discussing that so if there is not a full bi-directional mapping for example the document recommends that if there are link local addresses in the multicast DNS address records then those link-local addresses are suppressed for queries coming from outside the local link because the link local addresses wouldn\u0027t be useful so that\u0027s an example of where the dot local multicast namespace and the exported namespace don\u0027t match there are names in the local one that aren\u0027t exported and in the other direction there are little differences and I have one on the slide here that there are certain metadata records like the SRV records so how you finally push notification server for a given subdomain is you look up the DNS Porsche underscore TCP SRV record that record does not actually exist in the in the dot local multicast DNS namespace so that was something that the document didn\u0027t discuss and it\u0027s it\u0027s a potential area of confusion so we wanted to clarify that and in particular the Woerner that is described here after Ted had finished his implementation and we\u0027re using it and it all seems to be working fine and we\u0027re very happy it was a bit slow and when we and to start with we didn\u0027t look at that because we were just happy it was working and Ted was working remotely from Vermont and we\u0027re doing service discovery from 3,000 miles away and it\u0027s kind of exciting that it\u0027s working but once we started looking more closely we figured out what the delay was and the answer is when I\u0027m using a shipping version of this code now this in two years time we won\u0027t care but right now I\u0027ve got existing code which is looking for the old udp-based llq protocol which ted has to implemented because that\u0027s obsolete and it\u0027s going away and because all those queries map into the corresponding local query it would try and retry and retry before it gave up and that would add a six second delay before any operation succeeded before it fell back to the old simple queries and polling so once we made that realization it seemed wise to point out in the document that there are some of these names that are special and don\u0027t simply translate back and forth in the obvious way so that that update has also been submitted I will run RFC DIF to make a "
  },
  {
    "startTime": "00:18:55",
    "text": "comparison to help seeing the differences and post that to the list I think what we want here is consensus from the group about whether these are merely helpful editorial changes or whether they change anything about how the protocol works and if we decide they are changing them something substantive then we need to make the decision about what level of last call we need to do to review these but as with the last document we felt that letting this go ahead in its current state was not the best service to the community and benefiting from this implementation experience we had and putting that in the document was serving people coming after us to be implementing this so that\u0027s the update on those two documents Thank You Stuart any questions for Stuart all right okay I have 15 minutes so you guys are gonna have to ask a lot of questions cuz I\u0027m not gonna talk for that long I\u0027m Ted lemon I\u0027ve been working with Stuart as he mentioned on doing an implementation of all this cool stuff that we\u0027ve written documents for so we\u0027ve implemented all of these specifications at this point staple operations hybrid proxy no sorry discovery proxy DNS push Service registration protocol and discovery relay so stateful operations is actually being used both for DNS push and for discovery relay so we have two different things using the same DNS stateful operation code and indeed actually three things if you count the client and server discovery relay is separate and actually four things if you count the discovery proxy and the discovery that and the client has separate things so that stuff is all done with the exception that I haven\u0027t actually done the server-side keep a live code because I was kind of under the gun to get something out the door and that was the lowest priority but that shouldn\u0027t be too hard the client-side keep a live code is done so I will be probably hacking on that and testing it the next couple of weeks meanwhile if anybody wants to actually see the code that URL which I\u0027m sure you can probably I doubt you can read very easily on the screen but I\u0027m sure you can find in the in the meeting minutes or in the in the in the meeting materials that will get you to the actual implementation it\u0027s inside of the the hackathon repository that we were using discovery proxy so that\u0027s what Stuart was just talking about really we\u0027ve we\u0027ve got a standalone discovery proxy it acts as a it acts as a "
  },
  {
    "startTime": "00:21:57",
    "text": "authoritative server for the for the zones that it\u0027s proxying and conveniently it also will do dns lookups for other things so you can use it as a DNS resolver just which which is handy for the home net application that\u0027s that\u0027s part of why I did it that way it relies on em DNS responder to do em DNS resolution and it implements DNS push so that you can get a timely notification of changes and again the code is is at that URL currently there are a couple things missing the code is able to identify what linker requests where it\u0027s it\u0027s able to decide what link to send a request to but I haven\u0027t actually implemented the link naming stuff that\u0027s in the in the discovery proxy documents so that\u0027s that\u0027s still to do and I\u0027d really like to get it packaged up for open wrt because I think that\u0027s one of the really nice use cases for this code that I think a lot of people could try out very easily but that\u0027s relatively little work so mostly done all the protocol work is done dns push so we have as I said we have an implementation of the discovery proxy and then also mdns responder which is a DNS it\u0027s a Bonjour how would you describe it Stuart it\u0027s it\u0027s it\u0027s it\u0027s the thing that does Bonjour discovery for you and also does Bonjour advertising for you it\u0027s it\u0027s if you if you use Bonjour on Mac OS it\u0027s actually going through mdns responder but it\u0027s an open source project and what we have what we used in the hackathon was actually a branch of the Apple Code with some additional stuff all of this new stuff that we\u0027re talking about here in it so so the that that is actually doing DNS push now and so you can actually build it and install it on Mac OS if you turn off some protections and it works nicely source code also available and I need to add the keepalive support so I need to implement the server-side and you test the client-side Service registration protocol so this is where we have a specially constructed DNS update that is checked for consistency self-consistency and then if there if if there isn\u0027t a conflict in the in the zone file for the the for the update then it\u0027s just added and the update includes a key which is to sign it so so the update is validated against the key that was used to sign it and then if another update comes in for the same name that uses a different key that isn\u0027t accepted so you get first-come first-served naming as a result of that I\u0027ve implemented a very simple SRP client that sent that generates an update signs it sends it I used ECDSA because that seems the the "
  },
  {
    "startTime": "00:24:58",
    "text": "target for the simple SRP client is an IOT device that\u0027s that\u0027s you know low power doesn\u0027t want to do a lot of work ECDSA is a good choice for that it\u0027s also very compact so so the update is actually quite small I thought I put the size of the update in there but it\u0027s it\u0027s like 415 bytes for a complete service advertisement using using SRP it\u0027s one packet to the server and one response back and the response would just be a DNS header that says yes thank you so and then I\u0027ve also implemented an SRP proxy that\u0027s a essentially an SRP server it receives SRP updates checks them for consistency checks the signature I haven\u0027t quite gotten it to the point where it\u0027s actually doing a DNS update to a DNS server but that\u0027s the next step so that\u0027s all working I think I mentioned the validation that the the ECDSA validation works with by nine so I assume that by nine is doing it correctly when I first when I first did the code I I read the the 6/0 document implemented it sort of naively and had successful validation between the proxy and the simple client and then I tried to do it against by nine and by nine rejected it out of hand and it took me a couple of I think a day or two to figure out why by nine didn\u0027t like it it\u0027s the way that sig zero works is quite obscure yeah I wouldn\u0027t put it that way so but that\u0027s done so the reigning work is we need to have an SRP client that actually does the full SRP protocol and not the simplified SRP protocol just to make sure that then all that stuff works but I don\u0027t see any reason why I wouldn\u0027t it\u0027s very straightforward be nice if the SRP proxy was actually updating by nine and it would be kind of nice to hack SRP support in two by nine so these are things that are on the agenda but none of these are things that I think are sufficiently I think we I think we\u0027ve we\u0027ve exercised the protocol well enough that I feel like the specification is mature so be nice to do some more work on it but I don\u0027t think we have to before we publish the code for all of this is in that link it\u0027s all open source Apache - you\u0027re welcome to check it out discovery relay so discovery relay the idea is essentially a discovery relay is like a DHCP relay a little bit more complicated than a DHCP relay but has the same essential function which is a really stupid thing that doesn\u0027t have any any features you can add to it it\u0027s only goal is to essentially act as like an extra like Network link for a centralized discovery proxy so you have a centralized discovery proxy it connects to the to the discovery relay using the discovery really protocol and effectively it has a it has access to the link that the discovery relay is on that means you can add all of your "
  },
  {
    "startTime": "00:27:58",
    "text": "features to the discovery proxy you don\u0027t have to add any features to the discovery relay you don\u0027t have to keep the discovery relay particularly up to date and it\u0027ll still work so we have an implementation for that in mdns responder both the client and the server and they were great I\u0027ve used them to do discovery over 3,000 miles of of Internet so remaining work discovery relay requires TLS support and it doesn\u0027t use PK I uses pre-shared keys not PSK in the standard sense but just like you know a self-signed key that you would configure as opposed to using PK i to validate and I haven\u0027t actually tried that bit but I\u0027m pretty sure that we\u0027re that the specification is correct I updated the specification after doing all the TLS work for DNS push and so I think it\u0027s correct at this point so I\u0027m reasonably happy with it and feel like the document ready so lessons learned I mean you heard Stewart talking about stuff that came up we he didn\u0027t mention every single thing that came up this was a very fruitful exercise we found lots of little minor nits in the various documents we updated them and I think at this point we have reason to think that these drafts are mature so action items would be really nice if anybody\u0027s interested in implementing like like doing a real full implementation of some part of this work it would be nice to get another person to do that and you know please talk to me if you want to try to do some Interop testing I would love to do that I\u0027d love to help help you get up to date but don\u0027t ask me any questions about the protocol because I want you to to read the specs I think we\u0027re ready for a working group last call on the real a document passed last call once before but I just wanted to hold off until I\u0027d done the TLS work and I feel like at this point the TLS stuff is good enough SRP I think is ready for last call and Stewart already talked about DNS SD push so that\u0027s my status and I\u0027m done any questions all right [Applause] um so you asked for last call we\u0027re thinking of going ahead and taking that to the list that meets your needs anybody complain good yes Tom you\u0027re up "
  },
  {
    "startTime": "00:30:58",
    "text": "let me make a comment about the last call first um because everyone\u0027s so busy this week I don\u0027t think it would be a good idea to start last calls after this meeting but maybe next Monday we could start them and then we\u0027d have time to yeah what I generally do is start it during the week but make you go for two weeks from the end of the ITF precisely because that way people can review it this week if they want to but no one is pressured to do so okay this draft came out in February it\u0027s the first time I\u0027ve talked about it and the idea you know we we haven\u0027t actually got to the a charter work but one of the things that I hope becomes recharter item is how do we transition to a unicast only discovery model to better serve the Wi-Fi clients that are bigger proportion of our user base and if you\u0027re not aware of the problems there it\u0027s mostly having to do with waking up clients that are on battery and having to use additional power requirements to receive multicast that they end up not needing because they don\u0027t have anyone you know needing that service or don\u0027t provide that service or things like that so the idea is if we can transition to unicast we we better utilization of the access points and better battery performance on the clients so the goal of of the update proxy is to transition it entirely from mdns to a unicast only system this diagram will be referring back to it it doesn\u0027t have anything update proxy specific in it it\u0027s a just kind of so we can reference things to talk about how they work from unicast perspective and to kind of refresh the clients that are both on this net external will make queries for services subnets and we need a way to map those into a unicast DNS namespace and the discovery proxy is one way to do it and it does it dynamically and this update proxy is a alternate way to do it that does it a priori to build the entire list one of the problems with the deployment "
  },
  {
    "startTime": "00:33:58",
    "text": "of wide-area Bonjour was that all of the clients couldn\u0027t get a shared key that they could update send updates to you know a authoritative servers didn\u0027t scale well and you didn\u0027t want to distribute those keys and so by having a few trusted boxes on your in your infrastructure that have those keys act as a proxy you can then scale the updates better and do the service registrations all over unicast okay it uses the same subnet model that the discovery proxy uses that you should already be familiar with one of the nice features is because you now have update access you can create these subdomains for each IP subnet on demand you can create the delegation you can create the SOA records you can then create the IP address enumeration records so that the clients can find the subdomain it\u0027s all can be automatic and you end up with an auto configuration system that only relies on knowing the single shared secret in the update proxy to be able to do an update and then everything there can build on automatically and then the clients it\u0027s transparent to them they as long as the you know the top-level domain is in their search domain the update proxy can insert the browser pointer records at the domain level so that it can add the subdomains as needed and then to the clients this is all becomes transparent and automatic so it\u0027s a it\u0027s quite neat because of how easily the whole thing builds automatically you you can figure the one shared key and as it just as each as the update proxy you have becomes aware of its IP subnets and they can come and go or whatever and they can be reconfigured it can add them it can configure them it can make them browsable and then start sending updates for their services that it discovers and the other nice thing is each client that\u0027s on on these interval individual networks can transition independently so initially it\u0027s gonna proxy the mdns stuff but as the clients learn about an update proxy they search for an update "
  },
  {
    "startTime": "00:36:59",
    "text": "proxy they find it they can unicast their announcements to the update proxy and intranet transition independently from multicast mdns to unicast only Tom you said the clients are sending their announcements do you mean the services state you tell them yeah sorry the services yeah the this the client and some some clients a box acts as a client and a service announcer potentially okay so when a proxy starts up it has to determine the sub domain it has to make sure it can send updates and they\u0027re accepted and after that it can go ahead and create all the infrastructure to make that subnet mapable it can start out by passively listening to mdns announcements it can send a query for the services your services dns s the UDP local to try and find services that are on that network and as it discovers services and service when you first announced a service you\u0027ll send it twice so that people who may have sent a query recently but weren\u0027t online at the time those updates will get out and so you can use those announcements and then once you learn about these things you can send unicast qu you know which are query unicast queries to it to refresh it you listen for the goodbye announcements where the TTL is zero and you can delete it and then you can remove it send the update to remove it from the unicast server and along with the the records that you send in the update you can either include the lease lifetime option or you could actually add a timeout record at the same time which Tim\u0027s going to talk about timeout records later but it\u0027s another way to transfer the life of that lease for the update announcement so as a refresher of the way that the subdomain name can be determined both clients and the update proxy can search for the subnet you know and and what would be like the default registration domain or the registration domain or the and there\u0027s a list of the Browse domain that default "
  },
  {
    "startTime": "00:40:01",
    "text": "browser me and try to determine what the subdomain is if there\u0027s one already allocated for the subnet if not it can create one on demand and register it so that all the clients can find it and other update proxies on the same subnet can know that it\u0027s already assigned and you can have multiple update proxies on the same network and they can work independently but they can work redundantly and you can either just have them both send updates and one of them will fail because it already exists or you could have them try and coordinate by seeing if something there before they try to update I\u0027m not sure if that\u0027s worth the extra effort but so one method of maybe generating the subdomain on demand is to use some algorithmic way to do it so that you create this unique identifier and everybody you don\u0027t have to worry about guessing or what NIT what should I call this does it matter that it\u0027s you know the engineering department versus the marketing department you know or building one floor one and building two floor two it doesn\u0027t really matter you don\u0027t necessarily care about any of that so just these names are not going to be ones that appear in you eyes typically you\u0027re looking for the the actual service the SRV instance name not these names so I\u0027m not sure that it really matters what they look like so I talked before about how clients can individually transition to unicast only serves discovery by looking for the update proxy and they can do a query SRB query for a reserved service name based on the a subnet address enumeration method to find the update proxy for that subnet which it should register that record and then that\u0027s all done via unicast and the client doesn\u0027t have to use any multicast at all so it this is the idea behind this is a way to transition to unicast only but comparing it to the discovery proxy which is another way to map from multicast to unicast is helpful in understanding how it works so I put this summary slide together as far as state goes the discovery proxy tries not to keep State for things that no one is interested in so it minimizes State as "
  },
  {
    "startTime": "00:43:02",
    "text": "much as possible whereas the update proxy tries to learn about everything that\u0027s available because it\u0027s putting the all the services in the unicast authoritative server and when clients create they query the unicast server and get a response immediately back so there\u0027s no go search for the service ok it\u0027s instant it\u0027s either in the in the day the authoritative server or it\u0027s not so we have to get everything in there there\u0027s advantages and disadvantages to this the response time is much quicker or I shouldn\u0027t say much quicker it\u0027s potentially quicker if it\u0027s not already in the cache if they have to go search for it with the discovery proxy then you end up with maybe a slight delay and probably not you know if a that\u0027s not a fatal problem it\u0027s just the response time would be quicker in the case where everything\u0027s already in the unicast server the discovery proxy will increase the amount of unicast re of multicast on the networks based on the number of subnets that are browsable times the number of queries and responses that receives so with without the Discovery proxy those multicast wouldn\u0027t be there but you\u0027re adding external clients over unicast so that generates those queries the the update proxy will only add one multicast query and that\u0027s for all services and and as the unicast as the clients transition to unicast when that becomes not necessary in the long term but the update proxy will make unicast queries to refresh all the services to make sure they\u0027re still out there and that will increase unicast traffic as opposed to multicast traffic now in the end if you look at a switch when you do a query if you do a multicast query on a switch you\u0027ve got all these ports with all these clients on it or all these sorry hosts on it and a single multicast gets replicated on every port and a unicast and if you send multiple unicast that gets replicated on all those same ports on the subnet so as far as the number of packets going out I\u0027m not sure there\u0027s really a difference the replication is done in the hardware of the switch under multicast typically so it might be less load on the switch but it\u0027s the same number of packets going out on the back end with the "
  },
  {
    "startTime": "00:46:06",
    "text": "discovery proxy because it doesn\u0027t know all of the services that are out there you can\u0027t do DNS SEC and SEC records because that tells you what the next record is and you don\u0027t know of what the next record is there that can be holes between your knowledge but because the update proxy knows the services or attempts to know all of the services it knows what the next records are so you can use the in sec as you get updates and send them up to the authoritative server it can rebuild the zone with the correct n SEC records and everything can be signed with the NSX and you can have the NSX signed service discovery as far as the complexity goes there\u0027s you know it I think we need feedback from implementers to validate you know that the discovery proxy has to implement a full authoritative server the if it does the mdns relay so that it can collect have like a single discovery proxy that everything gets collected in that\u0027s additional code to write where as the complexity of the update proxy means it\u0027s mostly just passive mdns listening and doing some unicast queries plus sending updates to an authoritative server so to me it seems less complex to do the update proxy but it I think that has to be implementation-dependent do you wanna me okay yeah I respond yeah I I stood up because I think this is a good chart and this is useful I had a couple of things of feedback yep maybe update this as this presentation is given in other places yeah where you say order n-squared I think you\u0027d be good to clarify what n is whether that\u0027s number of clients number of servers number of links right number of subnets times the number of query plus responses because you when you do a when you do a unicast query it gets and out to every subnet right the the client will query that and then get a list of subdomains back and it\u0027ll send out queries to each one of those which will do an MD NS query on each one of those and gets and so many responses back so it\u0027s number of subdomains times the number of responses basically plus "
  },
  {
    "startTime": "00:49:06",
    "text": "one right those are not necessarily the same number right they\u0027re not both and you know it it might be you know it\u0027s an order them it\u0027s order N squared because it\u0027s you know a times B it\u0027s the order it\u0027s not it\u0027s not N squared it\u0027s the order N squared ok so that\u0027s why I\u0027m saying it yeah it\u0027s it\u0027s a little bit unclear what the scope of this is whether you\u0027re looking at the amount of traffic on a particular link or collectively the amount of traffic in the whole world or yet what it is that we\u0027re measuring electively for the unicast query the single unicast query that comes in I think a single unicast query goes to a single discovery proxy which is connected to one link right no single unicast query before a search domain gets broken up into all the browsable subdomains the the client the client will do that query get back the list of subdomains and then do a bunch of queries for each of those we can maybe talk about it in in more detail offline I just I think I think in the case of some update proxy saying there is only ever one subdomain and for discovery proxy that could be n sub domains is is not an apples to apples comparison no no I\u0027m not saying that so yeah we can talk about it that it\u0027s that it\u0027s there\u0027s one per in the update proxy there\u0027s one percent of me I think you I think and as you implement this and test this yeah we can get real operational data I think you may be being a little bit optimistic with the the order one which is another way of saying there is no change in the multicast traffic at all it\u0027s it\u0027s you know one time it\u0027s what it used to be which is no change at all I think when you do the underscore services matter query what you\u0027re actually going to be doing is you do a multicast query to discover all the service types represented on the network yes for each of those service types you then do another multicast query to say find me every instance of every type on the network and then for each of those instances you do another multicast query saying you can do a unicast query at that point once you have the instance name once you have the instance name you still don\u0027t know who to send the unicast to until you\u0027ve resolved that address yeah okay the the device giving right yeah okay the source of the multicast packet may often be the same device as the thing that offering that service but "
  },
  {
    "startTime": "00:52:07",
    "text": "not always so in general you need to do another query so right I might my intuition here is that the amount of traffic is probably going to be comparable and probably it would be possible to show that in any case the discovery proxy is strictly less traffic on multicast traffic because the update proxy has to exhaustively discover everything that\u0027s on the network that anybody might potentially ask for in the future whereas the discovery proxy because it\u0027s on demand is by definition only discovering the subset of all possible services that clients are actually interested in so I think it has to be strictly less yeah because it\u0027s discovering fewer things and then you talk about DNS SEC I think there you want 10 sec 3 because the idea of ntek 3 is to prevent zone walking which was a attack discovered with classic DNS AK that some people were concerned about where from looking at the an SEC records you could then enumerate all the contents of a zone which had privacy implications in Sec 3 added some cryptographic hashing to make that zone walking infeasible in the case here and I believe that the draft talks about this so if it doesn\u0027t we should fix it discovery proxy allows online DNS SEC signing not offline which is a little subtlety it\u0027s not saying you can\u0027t use DNS SEC but you can the the device has to know the key what you can\u0027t do is the classic keep a PC in a locked room with a floppy disk and sign the zone offline and then walk the floppy disk out to the server if you really really want to have very strict isolation that that device can\u0027t be compromised you can\u0027t do that when you\u0027re building this dynamically so the device needs to own the key and that is an additional vulnerability but that\u0027s not quite the same thing as saying you can\u0027t do dns ech it\u0027s just that you\u0027re only doing online sign ya know I didn\u0027t make the claim you couldn\u0027t do in a sec I said you couldn\u0027t do in SEC records well you can do in circ records and I think it talks about that if somebody does a query for a name that doesn\u0027t exist you generate an N SEC record that says this name doesn\u0027t exist ok and if they do a different query for a different name that doesn\u0027t exist you send them an insect for that what you don\u0027t have is n SEC records that straddle a whole range of names that says none of these exist but that capability was actually a failing event set because it enables own walking so the inability to do range n SEC records "
  },
  {
    "startTime": "00:55:10",
    "text": "is arguably that\u0027s not a deficiency because that was not considered a desirable property of an SEC records ok ok no it\u0027s a good point thank you yeah so I\u0027ll update that ok so there\u0027s some issues that are kind of outstanding in the spec that I need to work on just I need to walk through the implementation and match up to the spec and make sure that everything gets created correctly and it\u0027s listed in the spec of what what to creates to make it the auto-configuration all work transparently to a client in the case where an update proxy fails and it leaves sub domain information behind and another update proxy takes over just want a document to make sure that that transition happens you know cleanly I had some questions and Stuart and I can talk later or we can you know now is appropriate that\u0027s fine but if you want to register a service in multiple domains then you know and the our registration domain query comes back with a list of multiple domains is that okay to just register that service in all those domains or like for when doing address enumeration of the subnet um I will let the chairs guide us in terms of how much time we have left for discussion we are here to have a workgroup meeting so to some extent having this discussion publicly instead of off in a corridor somewhere I think is appropriate as long as the time allows for that they don\u0027t worry we will cut you off mercilessly Thank you very so the domain enumeration records were originally created when we optimistically thought that device vendors would implement DNS update for themselves and for a variety of reasons that turned out not to happen it is it makes me sad even today you can buy a network printer that advertises its service using DNS SD and the service is vendor printer - hexadecimal vomit because they think if you make every name unique out of the box that solves the problem right because you you look at the list of printers available in air print and you see 12 different printers differentiated "
  },
  {
    "startTime": "00:58:10",
    "text": "only by the hexadecimal string on the end and as long as you memorize hexadecimal strings then you know which one you\u0027re using getting people to even put in a meaningful name for the printer by going to the web UI and typing in a name turned out to be in practice apparently too much of a hurdle so if you\u0027re not willing to give the thing a name configuring it with a key is certainly not going to happen so that was overly optimistic it never happened and the point I\u0027m getting to here is don\u0027t be overly constrained by what we were hoping would happen 10-15 years ago if if it\u0027s appropriate to define new mechanisms or new conventions here that is totally on the table the those old records were there with an intention of giving guidance so that when you connect your new device to the network and go to its web UI it says I see on this network the administrators are recommending the following for domains sales marketing engineering or first of all second floor third floor and you pick the one that\u0027s appropriate for your device since that never really materialized with we\u0027re not beholden to that we can define you mechanisms if that\u0027s appropriate for what you want to do ok and then the last point was that it\u0027s possible to do subscriptions through the push notifications to the authoritative server if that\u0027s ever implemented in an authoritative server there is not we just had a discussion at the hackathon about the reconfirmed message and it\u0027s not possible at this point to get a reconfirm back to you know there\u0027s no nowhere to send a reconfirm if you received one at the authoritative server but what the reconfirmed triggers in the discovery proxy I think the client could do manually when it would have wanted to do that when it recognizes that things not responding I think you can just make the queries that it needs to do without using the reconfirm in the subscription so that\u0027s something that we can pursue as well so those are the outstanding issues and I\u0027ll take the draft as I work through these as far as implementation there\u0027s one I\u0027m working on it\u0027s it\u0027s partially working but it\u0027s not actually sending the update out at the moment because of a concern concurrency problem I was having in the code as I learned rust but I think I\u0027ve worked through the issue in my head now and it\u0027s a matter of reor connecting the "
  },
  {
    "startTime": "01:01:11",
    "text": "code no it does listen to them the NS announcements that are out there and builds a cache and then sends updates for new entries into the cache and times out the cache entries listens as it gets the goodbye packets it doesn\u0027t send the updates yet as well for those to delete the entry I\u0027d like to add t6 support to it and do it over TLS as well right now it\u0027s all over UDP dude the subdomain discovery and auto auto configuration stuff at dynamic interface support so as addresses are added on an interface or automatically recognize those and you know start providing update service for that subnet and then work with maybe some either the some foot vendors or some router vendors that I happen to know from previous lifetimes so that\u0027s that\u0027s all I have [Music] we\u0027re gonna ask to keep the questions a little short because I\u0027m apparently back about a math and we are a little bit behind schedule all right well then I\u0027ll make this very short thanks for doing this work Tom I look forward to seeing this progressing we can help you with testing over the internet remotely and in person at the next hackathon a one suggestion I made to you directly but I want to share it with everybody in the room in in your current draft you have a little appendix that\u0027s comparing this with Ted\u0027s discovery relay idea and what I would actually suggest is instead of viewing that as an either/or kind of approach the the the way I think of the discovery relay is it\u0027s analogous to a bootp relay which is used by DHCP and the idea is that routers have the simple pupi relays that have not changed in 20 years and in the data center there\u0027s room for innovation new DHCP servers come out with new capabilities and that innovation can happen without you having to upgrade every router in in the enterprise and that decoupling enables innovation so I would definitely think about having your proxy as well as working with directly attached physical interfaces view the Discovery relay is like a USB Ethernet interface with a really really long USB cable on it that runs over TCP but it is a way for you to have an interface on a network that you\u0027re not physically connected to with hardware but it\u0027s as if you\u0027re "
  },
  {
    "startTime": "01:04:11",
    "text": "connected and then all the stuff you would have done locally you can do remotely and if we\u0027re successful in getting those relays deployed in routers then they provide this capability they\u0027re like your little minions out on the network which the discovery proxy can use your code can use are the future things it creates this ability to innovate because you don\u0027t have to keep changing the routers when a new idea comes out yeah it\u0027s a great point Ted lemon so I don\u0027t want to make you answer this question right now because I think it would be a little bit difficult to answer it while you\u0027re just standing there in front of us knowing like ah but I I don\u0027t understand like so we have we have the the hybrid proxy the discovery proxy we have the we have Service registration protocol which provides a migration path to DNS update so that we\u0027re using unicast only if we can get all the clients to implement it and so it feels like this is actually solving the exact same problem and I get that the characteristics are different but it would be helpful to have a kind of a clear sales pitch for why this is a good thing to do and why it\u0027s different because at this point I actually don\u0027t know I mean when I first started looking at this problem I think Stewart and I I remember we were meeting in in Argentina at the ITF there and talking about this and I actually proposed something really similar to this because like you I wanted to have a complete zone file with everything in it and we had a pretty long conversation about that and I came away with it I came away from the conversation concluding that actually that wasn\u0027t a really good idea doesn\u0027t mean that I was a writer that Stewart was right but it would be good to actually capture that that discussion and be able to express clearly why it is that this is different and good as opposed to the same thing I\u0027m not really different yeah the short answer is that I implemented the discovery proxy and found it to be I think more complex than I would have liked and adding on the DNS relay and discovery relay and all those components you know you guys were able to bootstrap from mdns responder and that got you to where you are today rather quick much quicker right and certainly that\u0027s an option for people some people may not be able to do that some people are going to implement from scratch and I find this solution to be simpler less code I don\u0027t know that it\u0027s better I thought that it was worth writing it down and "
  },
  {
    "startTime": "01:07:11",
    "text": "implementing it to see and I\u0027d love to have more people work with me on it because it\u0027s lonely so I mean tricked thanks Ted could we ask you to like repeat this question on the list because like we don\u0027t have time right now but I would love to see maybe a comparison of the two solutions and like you had one about the discovery proxy and like you know the a nine squares tall complexity and getting to the bottom of this on the list would be really helpful might be worth actually just just doing a document doesn\u0027t have to get published but just doing a document that explains that picks apart the problem because I think having a discussion on the mailing list is we\u0027re probably not going to get to the point very easily so so he\u0027s volunteering oh yeah no but more serious leaking the two of you collaborate on that that would be incredibly helpful for the working group Thanks let the minutes show that Ted made a thumbs-up all right and Tom you can go sit down and Tom you can come back up I\u0027ll try to be quick okay so we we\u0027ve talked about different privacy options and I thought I\u0027d throw another one into the mix here the idea is that we already know how to search for services in a subdomain if we can make that subdomain private then we don\u0027t we just do what we normally do and that\u0027s we make normal queries and get normal responses so the idea is let\u0027s create make it easy to create new sub domains that are both encrypted and authenticated and if that\u0027s not too much complexity we we have a way to do private service discovery and among your devices or among a group that you define and so the idea is that all the queries and responses are encrypted they can be over TLS it\u0027s what the current document says the previous document said well we could do these queries in the clear but that the actual records were encrypted and that got too complex so this one that was the Overson you know one version says let\u0027s just use TLS you create a private subdomain by having that prior relationship with some entity you might have might be your email provider it might be your own domain it might be you know somebody that you buy services from and in my example if I have email costa terry advantage a.com the bang je com domain can create a route for private subdomains at under "
  },
  {
    "startTime": "01:10:13",
    "text": "pvt dot nj.com and then I can owning crew cetera like that email address then they will have some policy to allow me to create that subdomain based on maybe some credentials I already have like my email credentials or or it could be first-come first-served like Ted\u0027s Service registration protocol does and only if there\u0027s a problem or conflict you know what they but when you first create it there\u0027s nothing in there so you\u0027re not exposing anything and the way you create one is you use update to create a key record at the at the apex and that key record is the public key and then from then I\u0027ll from then on all operations that you do in that private subdomain has to be signed with the private key associated with that public key so you do a query you would put the query you would sign the query with a 6-0 signature using that your your private key it would go up to the authoritative server which would then verify using the public key you put in there and make sure that that you really have the private key you\u0027d then distribute those private keys to all of your devices and all your devices add that subdomain name as in your search domain and you\u0027re able to search and update records in the private domain and say if you want to update the key record you can do that as long as you have the old key record if you want to use a client certificate I think it\u0027d be possible as well to put a TLS a record with the public key and then the server could verify your you\u0027re the right client using the TLS a record that\u0027s at the root of the apex might so I\u0027m trying to understand this you get URL so or in this private space and there you put a public key yes and then you put the private key corresponding to this public key in all your devices yes so you sign all of you sign all of you do that like where do i generate the key pair and then how do i export the private key share it across devices and put the public here this URL wow this will take me a while to digest this yeah it\u0027s it\u0027s really I\u0027m not trying to "
  },
  {
    "startTime": "01:13:15",
    "text": "dictate the policy and how that happens but there are a variety of Mac ways that could happen that I don\u0027t they\u0027re not currently enumerated in the draft but that\u0027s something that we could do as possible ways I think that current providers do that for you today now you may not trust a provider to create the public-private key pair and give it to you and not keep it but that happens today and a lot of people have rolled out services doing that and I think I message is an example where that\u0027s done today where the the the the keys are distributed for you by that provider christianima and I\u0027m not sure I understand but do you suggest that all the devices that they\u0027re authorized to interact with a sub-domain have a copy of the public key of the private key yes yes today if you see that with SSH you you might have well well you well you don\u0027t have to know that yes different keys I\u0027m sorry you have the energy persuade device yeah and if you don\u0027t have a different key for advertisement that there is yeah what happens I mean yeah yeah yeah I mean certainly well we can talk about it more on the list I have one question yes my name is Lucia Tosh so the intent here as I understand you can correct me if I\u0027m wrong is to keep these domains private yes but things like certificate transparency log which is very popular so there you can get the the subdomains from there right if so so if a certificate is issued and all the private subdomains are one could go and get the purpose of the mains from from there if assuming that certificate transparency log is also the owner of the website is also populating there their certificates in the certificate transparency log so one could also retrieve it from there so okay yeah well people do it today with PGP there there are probably other ways that they synchronize private keys alrighty can you wrap it up yes thank you okay I think we\u0027ve talked about most of this "
  },
  {
    "startTime": "01:16:15",
    "text": "the we\u0027re getting half a page that\u0027s odd okay so I can put some of these questions out on the list but this is kind of some of the things I wanted to get feedback on the under pvt nomenclature that are not sure if that breaks the attribute leaf rules that were recently published to use it in this way and it wasn\u0027t clear when I read the documents I need to find out more about that if this is the issue that Christian brought up synchronizing the private key and you know if you have a group you might want to have some people a lot of people be able to read it but only a few people be able to update it so we could have like a right key as opposed to rekey as well at the at the apex and then Tim and and well them both brought up the point of maybe you want to separate encryption and and and authentication so that if you wanted to provide you know public records you could do that that\u0027s it any more questions next time will offer you know if there any more questions to the bring them to the list please Tim Europe all right so since tom was talking quite a bit presenting the our time out draft which is just for those of you who haven\u0027t read the draft quick overview what we are trying to do with it so it\u0027s introducing a new time out resource record which is essentially to hold information of how long other resource records can be considered valid and it gives them a lifetime so after this lifetime the authoritative server is supposed to remove them the idea to have this as a resource record is simply to have this information be stored right in the zone where you have all the other information about the records and this way you can transfer it to your secondary servers and even if you have like a multi vendor set up it\u0027s not a "
  },
  {
    "startTime": "01:19:17",
    "text": "problem just have this information in one in one place and can transfer regarding any yeah any band of specific things you might have done in any in other cases also you I mean you could do an implementation which survives restarts or crashes of your server software but yeah if you don\u0027t then this resource record will will save the information when the when the record is supposed to expire in the zone and yeah you also have it if something fails so what could fail to work for example if you have services which are registering wire for examples yeah the SRP or the update proxy or anything else the cleanup might not happen and even though you might have a update lease option so you know how long this record is supposed to be valid you you know the Idina zero option and provide a mechanism to transport this lifetime and to save this date between different different instances of your name servers so that\u0027s kind of the idea I\u0027ve been during the hackathon this weekend working on an implementation of a little demon which provides this functionality by just looking through the zone grabbing the resource records saving a time or for later to remove them when the expiry time has come and once it\u0027s reached it just sends out an update to the authoritative server and the records are removed so simple as that to keep it short just a few next steps which Tom and I were thinking about or which would be interesting to us at first we\u0027d like to have feedback if you have an authoritative server would you implement this or if not why not I mean strictly maybe that\u0027s better question for DNS auth but yeah doesn\u0027t hurt to just as many people as possible another thing which we\u0027re discussing it during the weekend we have like a represented record type in a in each instance of a time on record and it would be or what we were discussing is if it would be okay to let the you represented record type be any and then the instance is valid for all other all types under the owner name yeah maybe if you have some ideas about this or if you "
  },
  {
    "startTime": "01:22:18",
    "text": "think that\u0027s a good idea because if you have like an A and an A and court a record now you would have to have to tomat instances and this way you can just have only one of them Ted lemon you might consider having there be in any record that is superseded by any more specific record alright other words mmm oh yeah the whole thing\u0027s missing hi Pete Alexis power DNS um I had a quick look at the draft just before I went in were not against implementing this however we don\u0027t have plans to to do this anytime soon and there was one little thing I didn\u0027t see in the draft it does not mention at the time what record should or should not be Korea Bowl okay we had it not specifically a not being okay yeah we had the discussion in an earlier version maybe specifically said we don\u0027t want to have this variable and it turns out that brings more problems than anything else so it doesn\u0027t say anything because we thought it\u0027s it\u0027s okay to have it credible yeah so I had a small discussion with whit Holtz earlier today and he mentioned thinking about making a non meta a meta are type like a range like we have no meta types now that are explicitly not queryable so we\u0027ll only be represented within a neck so far so it might be interesting for you to talk to him about this okay so so the initial discussion of this Joe ably said that he wanted it to act like any other resource record and when we had it not queryable he\u0027s like we don\u0027t want special rules so that\u0027s why it\u0027s now queryable and it also allows you to do update to add and remove it and know it\u0027s there so there is advantages to having it Creole alright thanks Stuart Russia a couple of comments on the draft in at the start in the introduction you give some motivation that compared to using the Eden s0 option the benefit of having this be a real DNS record are that it can be saved on disk and it can be transferred to secondary servers I think you can make those justified just for Asians a bit tighter because we do have ways of saving data on disk that\u0027s not DNS records because like my digital camera does that every time I take a picture we do have this technology I think you\u0027ve got a good argument that if you want to save it out as a textual zone file in a way that is portable between different DNS vendors then having this other metadata stored "
  },
  {
    "startTime": "01:25:21",
    "text": "on disk in a proprietary format is not portable so I think that would be a crisper argument for that that it gives you portability it\u0027s not that that\u0027s the only way to save data on disk but it saves it in the portable way the other thing that was a bit anomalous and I\u0027m not sure how you\u0027ll clean it up but you start off by saying the great benefit of this is that it\u0027s transferred to secondary name servers and then later in the documents you say that secondary name servers must not do anything with this data if they\u0027re never going to do anything with it then the benefit of transferring it to them is is less clear so I think that language could be tightened up a bit all right so the idea is that the only the primary server removes the records so if you have a failure of the primary then the secondary takes over the role as a primary and then it has the information on moving the records when the expiry time has come question yeah I\u0027m gonna cut off the line to save time question asked chair does this is this specific to DNS SD or does this sound like maybe something that should be presented in DNS op know if you have a look at the name it\u0027s or it\u0027s kind of intended to be in DNS op also as a discussion but because well for example the service registration would be one primary use case of this we thought we we would let the networking group know absolutely and thank you for presenting this it\u0027s very common that like with the RCS euro-style that just got published you know stay for operations for us to have documents in DNS ops that are discussed here and our documents rely on ya and just just as an information with plenty of discussion of the DNS op mailing list already because we posted the draft over there perfect thank you that\u0027s just what I wanted to check alright thank you and Christian Europe and we\u0027ve successfully made sure that you have less time than was originally allocated on the agenda so just letting you know well the original a lot of time was 40 minutes so you still have plenty of time yes so if you have followed the various episodes of the evolution of private DNS discovery we have been through multiple IDs and we managed to converge on a set of requirements that narrow the problem we have a requirement drug that shows the scenarios that we want to serve which are effectively people that know "
  },
  {
    "startTime": "01:28:24",
    "text": "each other or device that know each other arriving on the same network and performing a multicast discovery locally without giving away the identity or the presence of seasoned and we don\u0027t want to give away the identity of either the client or the server and among beer discussion we are we are the also clarification that we don\u0027t necessarily want to maintain binary compatibility with the a necessity so I look at that and says aha if that\u0027s the case I cannot binary capacity with something else which is TRS and so yes so a little first set of assumptions there about what okay about what what we assume in the industries and Asia when I speak of TRS I speak of TRS 1.3 and the reason for speaking of ts 1.3 is that TS one country is the first version that has any hope of providing several privacy because in the version prior to that the response from the server carried a clear text version of the server certificate and so much for Survivor see now that is fixing TS 1.3 so that\u0027s that\u0027s a good thing we can say hey we can update here s response and it doesn\u0027t disclose the identity of the server to people on the link it does however disclose it to whoever set up the connection the next thing that we have in these toolbox which is a actual work in progress is encoded s Aniyah now the TRS require initial request carries service a service name indication which is effectively the domain name of the server then to simplify now of course if you\u0027re undecided in clear-text so of course if your initial curvature is whenever the cell in clear-text again the hope of fiber C are very limited but we have recent development on how to encrypt that same and it\u0027s encrypted by effectively having a public key of the server accessible to clients so they can use it to encode it and that way only the intended server can decrypt the SNA and that\u0027s meant in particular for big salvadore server a lot of different domains so you can connect the seller but you don\u0027t know "
  },
  {
    "startTime": "01:31:24",
    "text": "- which particular domain you connected and the further assumption in the design is that we are going to use UDP burst transports they of course familiar with TCP with TLS about TCP but there are variations that do not use TCP under the two interesting variations there are details which is basically straight TLS or UDP and quick which also use a TLS exchange during its initial handshake to set up the encryption key and then is encrypted and carries a lot of our UDP so these are the assumption in the design so then basic idea the basic idea is that if we have here as protocols that are carried over UDP then I can send the first packet in the exchange of a multicast and that first packet about the exchange carried the encrypted sni of the target server so if I do that it\u0027s received by every server of what in fact everybody will kill us on the local network but they try to decrypt it and only one of them will succeed the guy that as the corresponding private key and so that gives you a way to do a discovery request followed by trial description and if that match well you have a 101 TLS best connection and the what attracted me to the design is that it has the Year the poverty of doing minimal innovation in terms of encryption and processes etcetera are you you get terrace you get TLS and you don\u0027t have to innovate discuss which key you use or whatever it\u0027s all specified you you benefit from a lot of investment 80s walking you benefit from a lot of investment in the ESN I design because there are pitfalls there to verify that this thing works so that that was that\u0027s the general idea now there\u0027s one difference with the ESN I design hydro the classic oil classic it\u0027s a work in progress so calling it classic is kind of weird but the ESN idea the design relies on DNS and basically what you do is that when you go to the DNS you\u0027re a property of the server tells you which encryption key you shall use for the four years and I it gives you the public key that you shall use now it turns out that if you "
  },
  {
    "startTime": "01:34:25",
    "text": "broadcast a public key then anybody can use it and anybody can do a request on the local network says hey Christian are you here and I will be able to decrypt it because it\u0027s my key and they will know I\u0027m here so what we don\u0027t own that so instead of putting these es NIT in a public space for every to read we say no we are going to use that as a control point so that this public key is only delivered to the clients that are authorized to discover me and so in as much as I keep that public key secret and here we stop having a problem of vocabulary but in as much as I keep that public key only disclose to authorized client I have in fact a private discovery system now you want in the document we had discussion on that on on the email list we want to not call that a public key because if we call it a public key it\u0027s a busy people power so we\u0027re quite the discovery key so the server each service as a discovery key which is only available to authorized clients so that gives you a property that only authorized client can issue a discovery request and then when they get the response they know that we certainty that the response come from the otherwise Selva because the sni design as a proof in it as I am in the response to prove that the server is who they claim they are value is Alliant because the fallback mode is that yes there is an our mode that you have you have given that pub that discovery key to all your bodies and one of them is a traitor or one of them is careless and and leaks the key well that design is very busy and because in that case you go back to yes and I that means that yes it would be possible for someone to discover me because hey Mike he has leaked but at the same time it won\u0027t be possible to tell which clients are trying to discover me so we have this fallback mode that if the key leaks the server can become discoverable but the clients identity is not discovered so that\u0027s nice yes it so kind of like the idea at least from what I have heard so far "
  },
  {
    "startTime": "01:37:27",
    "text": "my question is TLS by its design is a little bit asymmetric you have a client and a server and in DNS SD maybe devices are more like peers that discover each other so it\u0027s like if my printer is discovering my lightbulb I I don\u0027t know why it would who would be the client and who would be the server and how would they decide on the on the roles to use in in the scenario that we are looking at I mean we have looked at the Stewart for example so key scenario in which the diabetes up on his cellphone is discovering the insulin pump in your body these things are really peers and the the high level response is that any one of them can act as either sell or cry out it\u0027s a matter in application design because the server\u0027s public discovery key as you call it must be somehow out-of-band communicated to the client that is true so but if you if you have the insulin pump property you can very easily say that basically doing the synchronization the the pump gets the applications key and the application gets the forms key so that either can discover the other okay Chris what I was just gonna comment isn\u0027t that the same scenario with the existing proposals that we\u0027ve been discussing so far yeah that\u0027s not a new problem I don\u0027t think okay so let\u0027s let\u0027s go to the where we have small issues first I mean it\u0027s not clear that all applications that need private discovery will run about quick they will eventually because quick is going to take over everything but I mean take some time so in that case what we can do is have a two-phase scenario in which in the application that has to be discovered you also have a small implementation of a discovery protocol that runs over these theorists yes a9 discovery and provide something like DNS Avadi hereis or DNS of a quick so that\u0027s what you do is that you discover that DNS service co-located with your target application and once you have discovered that you ask them a bunch of DNS query to understand exactly how to actually get to the application and then you get there so from a a diploma on point of view of them we have two application ones you can ship that together with your application and and get to discover "
  },
  {
    "startTime": "01:40:28",
    "text": "remaining up with the discussion on the email list and the target of the design is really the private more or less peer to peer application to device scenario in which device is paired with pretty few applications a pretty few clients Vanessa if you take the insulin pump for example you are not going to pier the insulin pump application with very many pumps with just a few so in those peer-to-peer scenario we don\u0027t have a really big scaling issue because what the normal set is very small but it is true that if you want to discover something the client that comes on a network is going to send a bunch of multicast requests for every server that they want to connect to every private server and it is true that they may well be deployment cases in which that number is large so that\u0027s that\u0027s the downside of that proposal the other downside which is related is that if the client arrives first and only the clan can do the discovery then the client would have to repeat the account and that\u0027s a downside I think that it\u0027s not a practical downside because I believe that if you look at the scenarios we have in the requirements doston I use tend to be very much peer-to-peer and so it\u0027s effectively Weaver our lives last twice to discover the other one and finds them when the last guy arrives but I mean yes the community of two is a scaling issue and I looked at how would I fix that if I had to and if I had to I would invent some kind of a servo announce message that the servo broadcast one is saying hey I\u0027m here it would be signed with the discovery of the server so that every stop to it try try decrypting that message and say oh my body has arrived now I can contact it so this Chris but the discovery key for announcements will be used for signing and for being discovered it would be used for decryption of the ESN I got some news and still this clear okay we\u0027ll probably have to figure out like not you know you could use that gamma and things like that it\u0027s not impossible no I\u0027m not saying it\u0027s impossible I\u0027m just I\u0027m worried about the use of a key "
  },
  {
    "startTime": "01:43:29",
    "text": "for two different purposes in two different contexts okay yeah week with it but that\u0027s like a solvable problem I think no yeah also it seems it\u0027s a bit unfortunate in that we will be using something as heavyweight is to us for one side of the protocol but not TLS for the announcements in the the wider way I am here messages I don\u0027t really have a proposal for resolving that\u0027s just ya know Anna is too that basically if you send a serious message the terrorist message will include your unchecked proposal and you really want to have separate hand-checked proposal for separate people or separate Piazza yes I agree with that yes so so I mean you you tend to get this scaling issue anyhow because of the security requirements I guess my comment yes yeah okay I did have a possible proposal for a variant of yes and I that might make it a bit easier to deploy so currently in draft you you distribute I\u0027d have been the discovery key for all the clients and you use that to encrypt the s and I keen everything works but potentially rotating that discovery key is problematic I don\u0027t know how you would actually do that in practice perhaps you another issue right I was going to propose potentially instead of distributing the discovery key you distribute a certificate a basically a trust anchor that the server will possess like I have it certificate chain level root or chain up to something that is distributed out of band and then you can rely on the fallback mechanism that David Benjamin proposed for es ni to distribute the new discovery key in band and sort of rotate it a lot more quickly without having to build in any additional infrastructure yes and that will be a solution for this particular slide which was my next slide to say that there is one problem is one problem with anything that relies on a basically does see those discovery rely on publishing a public key and if you publish a public key you have a failure mode which is what happens if you return your private key leaks and you want to have some resiliency there and it turns out to have a symphony CS anion in general and with anything which is based on public key is that if you leak the private key but stuff happens in our case what happens is that if the public key is compromised not only can someone impersonate you but they can also go back to all the logs that have been captured by our concert earth in the last 20 years and look at every places you\u0027ve been and so that\u0027s not good okay "
  },
  {
    "startTime": "01:46:32",
    "text": "and the the solution has to be frequent key rotations and and that\u0027s something we have to walk on in practice yeah agreed I am kind of suggesting make it as frequent as possible and that you could in theory just always give have the server the client a fresh discovery he enforce a retry nes and i retry upon every single connection so it wasn\u0027t it doesn\u0027t help you with privacy why not the key is sent in in the encrypted Excel okay so you basically the several remembers the old key if the server if the client tries to use the old key you send them a week immediately there\u0027s no the idea and I apologize for bringing this up with the mic because it\u0027s not really well-formed or anything but so the coin just assumes it doesn\u0027t know what the key is of the server whatsoever it just happens to know how to authenticate a certificate that server will present because it\u0027s been given that\u0027s no good either why not because if if the client doesn\u0027t doesn\u0027t send something specific to the server in the request then every server responds and the clan will receive the certificate for the service at a present and that\u0027s not a good poverty okay yeah there\u0027s a trade-off there I would agree that that\u0027s not ideal but something you consider I guess I mean look but clearly we want to walk on on these details yeah clearly I could see for example incorporating the key rotation in in the handshake process the same way that you get a new session token each time you do a new session thing my question is so the es and I recommended mechanism to exchange the key is DNS over HTTPS there is an ID document yes correct so is this an alternate is that yes okay well to Chris with the coif on there I don\u0027t think you would use this to get the ESN a key for normal web traffic right this is not a this is designed for a very specific application it\u0027s not designed for I mean yourself or that sits behind the Akamai CDN or something it\u0027s not what you\u0027re looking at there okay and yeah I mean fewer than 40 minutes perfect so good quick question what\u0027s your thought on on session TLS session resumption and and does the server ever issue or ticket to "
  },
  {
    "startTime": "01:49:34",
    "text": "the client and then you use that later on for discovery I haven\u0027t thought this because I\u0027m you know now listening to you but that will I mean if the server issues a new such session ticket after the handshake yes actually I I look at that and that\u0027s the reason why I kept the ESN I design because the ESN I design is completely parallel to the session resumption so basically you do yes ni all the time no matter what because you need you need to understand yes and I to understand why so the ticket is valid trance and results for you okay and but if you do that then you can have either a full handshake or a resumption now there are privacy issues so if you are the client using that you have to be damn sure that you use a session to get only once so stepping in is chair I\u0027ve been noticing a pattern that anytime we meet together on this topic there is a lot of crypt analysis at the mic and you actually do make progress so I\u0027m thinking maybe a but then on the mailing list three months go by and not that much happens which you know we\u0027re all busy we all have jobs like no one is actually currently being you know a hundred percent on this would it help if maybe we set up like a sign meeting later this week with like a whiteboard and we can kind of let you bang it out would that be helpful yes all by deed we have time yes there would be a good idea okay there\u0027s time to be good yes I will see what I can do to help make that happen okay show of hands in the room who would like to act very actively contribute to this because this is probably gonna be hard to find times okay so other people who all right and Christian arts yeah cool thanks yeah yeah we will absolutely announce it on the on the list it\u0027s just like it\u0027s gonna be hard to find times that you know everyone can get to so we\u0027ll do our best Thanks um sorry sorry to interject maybe still one clarifying question on on the these keys are generated like these are "
  },
  {
    "startTime": "01:52:38",
    "text": "ephemeral keys for both took like for if if if there is a server that\u0027s like has a keeper and and one of them is to discovery key is it like ephemeral or is it like do envisioned this is printed on the device the the discovery key can be generated basically any way you should have it your public your public or a keeper right well you have to you have to then install it on the server and install the public key part as a discovery key on the on the otherwise clients okay and this is so I\u0027m not DNS SD guy to know it well enough but this will run like a you know in a local subdomain network and you won\u0027t be discovering across the internet we know that\u0027s not meant for this going across the Internet all right Thank You version thank you charter more specifically possible recharter I think this will work so Tom did an excellent job at loading up our DNS SD github with well the current charter that was pretty easy and also there and you see its github DNS SD WG if you\u0027re curious also there are seven open issues that have received zero comments so I\u0027m thinking if our people willing is there anybody willing to work on this on github is there anybody willing to work on this okay okay I will send out an email link to the github site and I\u0027ll go ahead and list these seven issues that Tom has started there and if people would actively specifically I think as you can see from the issues that Tom started us with there\u0027s milestones which of course chairs can actually update without necessarily reach our Turing but the refocus of the privacy I work I think was a key one and the privacy and data integrity so alrighty we will send out an email to the list all right thanks "
  },
  {
    "startTime": "01:55:43",
    "text": "this or does anyone have any comments or questions does anyone have any comments or questions about the reach are during and what we\u0027re doing there I think some of this is gonna require discussion because we have to decide as a group what new things we want to do and a couple of those things are new and a couple of those things are existing and so I didn\u0027t feel comfortable you know writing up a new charter to say we should now do these things because that\u0027s really for all of us to decide if we want to do them or not and and but yet I can\u0027t get any discussion to occur on do we want are there new things we want to do so like the finding things near me versus finding things I forget the other one was that yeah sorry we\u0027ve completely lost video so yeah yes yeah so so that is a good point thanks Tom I think yeah we\u0027ll want to discuss this on the list I think when Barbara sends like the list of issues hopefully we can spark a conversation there and make sure because you\u0027re absolutely right the Charter is just a reflection of what the room wants to be doing so it\u0027s important to agree on what we\u0027re doing not on before we agree on the text because otherwise it\u0027s kind of moved thank you so this wraps up our ESD session in Prague we was kind of great to see like some of our documents are moving forward or hopefully going to be done and half published the discovery proxy in before Montreal so we can all have champagne in there it\u0027ll be great and a lot of the other documents are moving forward nicely which is really cool and there\u0027s always many ups and downs with privacy or making good progress it\u0027s good okay so thanks everyone for coming and we will be meeting again in Montreal but in the meantime and do read the lessons because there\u0027s a question of interesting stuff coming there yes stop sorry one way I think Ted could you tell us what you\u0027re gonna do in this afternoon at the oh yes are you much of the hack demo yeah yeah so just FYI I mean I\u0027m gonna be sitting up the hack demo happy hour and maybe store we\u0027ll be there - I don\u0027t yes - we\u0027ll be there - and basically just like anybody wants to sit around and and like play with DNS SD in one way or another Mike and Stuart or I can help you to understand the API is that are available we can help you to build the source if you want to build the source and we can help you to do anything else we have a particular agenda unless Stuart is about to state one no I\u0027m reinforcing what you said at the hot RFC session on Sunday night Ted took "
  },
  {
    "startTime": "01:58:45",
    "text": "that opportunity to talk about what we\u0027ve been doing one of the things that we have discovered talking to people and talking to people at the hackathon is even though this service discovery technology is fairly mature now a lot of people at the IETF don\u0027t know what it does or in some cases have never even heard of it well have wrong ideas about what we\u0027ll have very wrong ideas about it so Ted had this idea which I thought was great that let\u0027s use that hack demo happy hour time slot as a chance to talk to people and answer questions so Ted pitched this at the hot RFC\u0027s told people would be there the audience so anybody in this room who wants to talk is welcome to come we were hoping to reach the people not in this room who know nothing about this and have an opportunity for some face-to-face chats thanks both of you I think this is helpful in getting our work spread out all right thanks that\u0027s a wrap you "
  }
]