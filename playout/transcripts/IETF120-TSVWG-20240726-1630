[
  {
    "startTime": "00:00:41",
    "text": "Thank you Thank you"
  },
  {
    "startTime": "00:02:08",
    "text": "Thank you Thank you"
  },
  {
    "startTime": "00:05:59",
    "text": "Thank you"
  },
  {
    "startTime": "00:06:29",
    "text": "Good morning We've already been through the round of selecting us scribe and Stuart is the scribe. You're sitting where? Over that, yep. So, welcome as I said earlier. This is the second of our TSVWG meeting. I'm Gori and this is Martin hi Martin hello good morning. And Martin's going to run slides for the meeting Let me do this up here just for fun This is the not well. It's still as important as ever on Friday If you haven't looked at it recently, please visit it again All discussions that the IETF are subject to the IETF note well and legal provisions It's important to observe the rules for anti-harismant and all the IPR related and other topics which the IETF thinks is important Please check this out. Next slide And here's our agenda. Do we have any anything particular on the agenda we want to highlight Martin? no changes the last session. So unless there's any agenda bashing from the room, we're good to go okay so there's a set of drafts these are all the active drafts Some of these drafts have completed a working group last call and we are now presenting them to make sure they are fine lines"
  },
  {
    "startTime": "00:08:00",
    "text": "inappropriate with the consensus of the group and some of this is work that's being started and some of this work is ongoing Any changes to the agenda requested now? I'll draw your attention to item seven This is a new draft if you haven't looked at it and you want to look at it before. We present that. That will be good. We'll do a call for how many people have read this when we come to it Slide. Let's now next slide That's right. So we can jump to nqb I want to to control. Thank you Thank you do anything? I'm not sure how to do that in the end, to be honest I just do this I can just drive drive to do anything. I'm not sure how to do that in the end, I can just do this. I can just drive. All right, okay. Good morning, everyone Do all the folks who have stuck around for Friday. Give an update on the NQB draft, so we're at version 24 on the Datatracker I'm greg white, Cable Labs presenting on behalf of my co-authors Thomas and Rudiger. Next slide Status of the draft is we ran a first working group last call in end of 2022 and into 2023 and that was on I believe draft 16 There were a number of draft 19 actually, number of updates since then that number of comments were received there"
  },
  {
    "startTime": "00:10:03",
    "text": "The draft was improved quite a bit with lots of good comments and review that round and so we ran a second working group last call, which ended just a couple, a few weeks ago on draft 23 23 So, I believe, ended on June 10th After that, the end, the, in review came in with a few comments, two editorial comments, and one question that was towards the end of June, and we have a mile two editorial comments and one question that was towards the end of June. And we have a milestone to submit this as a proposed standard RFC by August of this year, which is coming up very shortly shortly And in terms of deployment, Comcast has started a field trial using this PH in their network as of October last year and then they announced interconnection of the NQB code point starting in February of this year so they're connecting with their partners receiving NQB marked packets and delivering them all the way to the end user for residential broadband service Next slide, please. Go ahead and Jason will be coming up after me to give a more detailed update on the status of that trial The outcome of the working group last call there were approximately 80 mailing list messages from more than 12 contributors, a few invited reviewers as well. So thanks to everyone who read through the document again and or for the first time and did it send their comments a number of many of the comments for relatively easily addressed and those those were addressed in draft 24"
  },
  {
    "startTime": "00:12:02",
    "text": "And there were five remaining issues that I entered into the GitHub issue tracker so that we could work on them and get them resolved for publication of the draft 20 next slide In terms of the deltas, what was added after the working group last call so draft 24 added a new section 3.4 labeled applicable and so that brings together text that had been scattered through the document talking about the applicability of the NQB PHB brings that into one place. So it's more easily found in section 4.1 made a clarification that so that 4.1 talks about the sender requirements for marking traffic with the NQB code point and a requirement is intended to be that the application flow is sending at less than about 1% of the expected path capacity and knowing that that's a fuzzy term but that's what we agreed on as a working group as a good way to describe it But we provide us an example with today's network saying that that's approximately 500 kilopold per second And it was a little bit unclear that whether the 1% was the requirement or the 500 kilobits was the requirement and so clarify that that was tend to be an example requirement Also, there was a rate formula that talks about this smoothness of sending, which specifically mentioned 1,500 bytes changed that to 1MTU instead of 1,500 bytes Section 4.5 talks about total tunneling protocols and"
  },
  {
    "startTime": "00:14:02",
    "text": "particularly use of reordering sensitive tunneling protocols If a tunnel contains a mix of traffic, some of it marks, say, defaults and some of it marks NQB, those go in separate cues in a NQB, a NQB instance so they could arrive out of order If that tunneling protocol is needing the packets arrive in order, that could cause some problems, but the guidance in 4.5 now says, if you're going to do this, you should on the outer header mark smith a single DSCP so that your packets don't get split into multiple views into the two cues In added a new section in 7.3, so 7 3 which brings together all of the updates to RFC AD3 These had been specified just kind of in line in the document that, you know, implementations of RFC 8325 would need to do X, Y, or Z. We hadn't completely spelled out these are the text check in 8325, so that's been done now need to do X, Y, or Z. We hadn't completely spelled out these are the text changes in 8325, so that's been done. And then the other minor editorials. Next slide, please The five issues that are in the tracker So, these many of them I think were basically finished with So the first one, there was a discussion about the intersection with L4 and there is a requirement to the NQB draft that says if a, well, it was intended to mean, if a network node is implementing both L4S and NQB, then it"
  },
  {
    "startTime": "00:16:02",
    "text": "must do this specific thing But that wasn't super clear, and so it was misinterpreted as B being an additional requirement on L4S that's separate from NQB in some way, so made that proposed text to make that more clear so that we don't need to update RFC 9330 and 9331 because they already cover the intersection with DSEP That's fine. This one new requirement again only applies if an implementer is implementing NQB All right. So that one has proposed text 46 was ended up being so much editorial at the end of the day actually 46 and 47 related to one statement in the document that talked about minimizing incentives for mismarking of traffic Two kind of separate thoughts on problems with that statement. So we have now a proposal replacement sentence that maybe doesn't promise more than it than it should So that's 46 and 47 48 is, there's been quite a bit of discussion on the mailing list and in the GitHub tracker on this one Should traffic protection be mandatory to implement? implement? And I think we're beginning to converge There's still some discussion to be had, I believe but I'm confident that we'll get that one resolved fairly soon And it's all about kind of what is necessary for the IETF to mandate versus recommend to ensure that bad things don't happen in the network that they implements NQB Issue 49, should we explicitly"
  },
  {
    "startTime": "00:18:02",
    "text": "document the use of DSP5? So there was a question about RFC-800 interconnections and in those interconnections, the recipient may want the NQB traffic to arrive with a code point that is the top three bits are zero because there's some bit masking that goes on in the receiving side in RFC 8100 interconnects and we had in the work group talked about potentially documenting the use of DSCB because it's effectively taking the 45 value and stripping off the top three bits but recognize that that was problematic to list two code points for a single purpose in a standards crack draft. So we've got to prepare of just making the statement of if RFC-800 is operational receiving domain may prefer a different DSCP that allows for range-based classification So hopefully that suffices I see David is in the queue Do you want to ask your question now, David? More of a question Greg. So for those having figured out, I'm the one reviewer in Issue 48 And Greg, I think, let me see if you agree with this, discussion on issue 48 is now headed in the direction of what needs to be done so that traffic protection does not need to be mandatory not need to be mandatory. And it looks like that splits into three subtop which can be oversimplified as incentive security and Wi-Fi. I'll leave it to you to decide whether to break those out as separate issues or leave them so all bundled into the fore mega issue"
  },
  {
    "startTime": "00:20:00",
    "text": "Thanks, yeah, thanks for your comments on the mailing list and and articulating your concerns with that with traffic protection protection Yeah, let me take that offline and decide whether it's useful to split that out into multiple discussion threads But, yeah, thank you for that suggestion Okay Jay there, I actually think like it's really nice to do divide them too, because I'm getting lost on the discussion so if you have to separate discussions, I mean these are related, but we can actually conclude two separate things and discuss two separate separate and conclude perhaps some same kind of thing but the this discussion could actually help get separately. At least on my point to be, because it's hard to track what's happening And I was actually going to up my hair saying like, can you someone like what exactly happening was the background and maybe maybe today we can discuss it but it's up to you have we run it Yeah, it's a sensitive thing. Yeah, okay um is there a time for uh more detailed discussion? During the slide thing. Yeah, okay. Is there a time for a more detailed discussion? If you, okay, so I think the I'd like to comment on issue 49 first Yes, so from my perspective as chair it's quite okay to use two IETF as assigned DSCPs if we have a real need for that and there is some different pH appearing for that. And I think in this case there isn't So I think in this case you shouldn't be using DSCP 5 unless you find a good case for that. So currently that's off the time I think. Right, right. Okay, so I'm back to issue 48 I think the chair's position is how you summarise at the end of your"
  },
  {
    "startTime": "00:22:00",
    "text": "slide deck which is we would love to see a proposed resolution to this from the document editor which you think adheres to the working group consensus So if you want more time to talk about this now, that's fine if you want to liaise with the people who are discussing this on the list and then come up with text, that's all fine. So take questions if you want on that one Yeah. Well, does anyone have? well, maybe I should provide a little bit more background on 48 and then see if there are any comments from anyone in the room So the draft makes the assumption that the NQB code point is designed in a way that provides a shallow buffered best effort queue that is intended to sit alongside a default deep buffered best effort queue So traditionally in Access Network links with us, NQB is primarily intended for access network links so keep that in mind at the beginning. Traditionally, these links have a single deep buffer queue, works great for Cloud keep that in mind at the beginning. Traditionally, these links have a single deep buffer queue, works great for classic TCP protocols and other protocols that may send bursts of traffic, and they would much rather that the bottleneck link queues them up and place them out across the link rather than dropping them on the floor There are all sorts of other applications that have become more interesting as of late real-time applications that but, um, want a deep buffer in the network and would prefer not to be subjected to the QA queuing delay caused by a deep buffer in the bottleneck So the assertion is that if you have two cues, they're equal priority, one has a"
  },
  {
    "startTime": "00:24:00",
    "text": "shallow buffer, one has a deep buffer, you can let applicants decide which queue works best for them There's not an incentive for an application to try to steal anything to try to get its traffic into the wrong queue. As compared to some historical mechanisms that have been used to deal with latency-sensitive traffic to say giving a high-priority queue like expedited forwarding there you've got to now police that the traffic that marks itself as expedited forwarding. It really deserves to get high priority. So NQP crisis sidestep that prioritization issue by saying you've got two equal priorities cues, getting shallow and deep upward So the assertion that the draft makes is that there is no incentive for an application to miss markets traffic, but sometimes bad things happen, sometimes they're malicious actors that might try to disrupt communication So it is recommended to have a mechanism that tracks the applications that are flows that are classified into the NQ might try to disrupt communication. So it is recommended to have a mechanism that tracks the applications that are flows that are classified into the NQBQ. And if a flow is identified that's causing issues redirect that traffic to the classic queue. And so the nut of this issue is, should that traffic protection, if fact, be mandatory or is it okay for it to remain a recommended? recommended implementation should? And I guess some of the arguments for keeping it a should are there are networks where there is policing of code point usage your enterprise networks, for example networks where the ISP even manage the code point marking in their network before delivering it into the customers network in the case of access networks"
  },
  {
    "startTime": "00:26:06",
    "text": "And while this functionality is a good one, this traffic protection functionality, we recommend it. There are cases where it may not be necessary necessary You see David's in the queue. Do you have a comment on that? All right, I'll do my best to play His Majesty's loyal opposition So, Greg, I certainly agree with you that the design goal of this this Ph.B, was that there be no incentive mismarked traffic. However I don't think that, I think that remains a design goal or aspiration I don't think it's been achieved. Most because shallow buffered is effectively an undefined term in the draft And I think it's emerging from discussion that we don't understand the details exactly how to configure a shallow buffer to get to to completely remove the incentives not clear to me that we have to so that's on incentives I'll lump security together with class of equipment because I think list is discussion is very close to agreement on the class of equipment that most motivates this. There are means other than traffic protection to contain traffic that is doing stuff that it shouldn't with this PHB in a fashion of the abuser effectively only damage themselves. And I think somewhere in there there's a way forward where at least for the class of equipment on which the deployments are happening and that motivate this traffic protection is not mandated mandatory Beyond that I don't know what we do, whether we do, whether we applicability of that"
  },
  {
    "startTime": "00:28:00",
    "text": "class of equipment or say if you don't have these, other protections, then traffic protection is mandatory and then existing Wi-Fi is a special case of that of of that which has been a tarpet for a long time and still doesn't have any doesn't appear to have any really good, yeah, this completely solves a problem answer the other the point that's been made on the mailing list is that this is a best-ever service and tax can have on best effort cues They should be mitigated Having tools to do that is a good thing That's why it's a recommendation to implement traffic protection, but it is a best effort service So that's not a piece of it Yeah, I think the Wi-Fi part is that has been discussed quite a bit over the last few years on the mailing list We've selected a code point that in existing or many existing Wi-Fi now networks gives the NQB traffic a separate queue from the best effort traffic. It also is a queue that by default is high priority, which is not the intent of the NQB, PHB. But we made the judgment call at the time that the benefits outweigh the disadvantages, that providing the benefits of a separate queue for an QB mark graphic trumped the potential downside of applications using it to try to get high priority And one of the biggest rationales for that is that these Wi-Fi devices give high-prime get high priority. And one of the biggest rationales for that is that these Wi-Fi devices give high priority to fully half of the diff serve code point space. Anything with the most significant bit of one"
  },
  {
    "startTime": "00:30:00",
    "text": "gets high priority So there are all sorts of other code points that an application could use to get high priority in Wi-Fi. Using NQB specifically would mean that you might get high priority if you're going across a legacy Wi-Fi network, but you might not because the recommendation in the draft are that the NQB code point not be given high priority going forward So it seems as if it actually is in line with the incentives Yeah, I'm not at all sure about that, especially because there's at least one sentence in the Wi-Fi portion of this that is addressing this that I regard as just plain just plain unrealistic As I said, I think Wi-Fi is a tar pit. I don't know that we're going to come up with a perfect solution for it, but I would suggest to just making sure we've got the other two solved namely that we've got a correct statement of the incentive based on understanding and or lack of there of specifics of Q configuration and that we get the security stuff at least worked out for the classes of equipment that you and Comcast and the other folks working with this really care about and make sure we've got that, make sure we've got that nailed It doesn't look like we've got a fully general statement that would apply across the board to all classes of equipment Okay um thanks like to move on martin got a fully general statement that would apply across the board to all classes of equipment. Okay, I think we'd like to move on to Martin. All right, yeah, two points one, well, a point in a question. First of all, I've encouraged us to not spin out on this question. The difference between must and a very well-written should with very specific exceptions. I want it's okay to do something. It's quite small, added to the fact"
  },
  {
    "startTime": "00:32:00",
    "text": "that like edge network is going to do what edge networks need to do, like they probably don't need to be told to do something if they're if they're networks are threat Ed, you know, we're not the protocol police so like by all means let's discuss this but let's really timebox it and not hold the document for that for too long um is network protection is traffic protection always in the solely a matter of taking traffic and putting it in the normal? like Best Network queue or are there other mechanisms like bleaching? and dropping that are incorporated in that? concept thanks yeah yeah it does include uh options to discard traffic that's been identified by the traffic protection algorithm as well as when you're moving it to the classic Q queue, to the default queue, it's optional to remark it as default as well. Okay I'm a little more concerned about this with more, you know, something like dropping is obviously much more costly to the to the client And I'm concerned, I mean, like, I'm I mean, I'm from Google, like, I'm picking about Google search. I'm wondering, Google search is not really a particularly cue building application I'm considering maybe we should just mark NQB as a rule. Like, I mean, I don't, I just not a considered opinion. It's just something that's occurring to me So don't hold me to it. But like, it would be a real problem if we're putting these mechanisms for those sorts of packages are going to get dropped if we happen to catch them if we happen to cross some sort of threshold that is somewhat obscure um get dropped if we happen to catch them, if we happen to cross some sort of threshold that is somewhat obscure. So to the extent that's what we move a traffic protection, that's much more a problem than then like going to normal queue is five Bleaching is like okay Dropping is in my opinion bad. Thanks Yeah, and I believe that the draft does recommend"
  },
  {
    "startTime": "00:34:02",
    "text": "higher thresholds for doing the packet drop option. I'll take a look and double check that and make that clear. Pardon the interruption Martin, if the shallow buffered queue is correctly configured as shallow buffered, I think you run exactly the risk you described, which is that if you, if you exceed the threshold that you can't see on that queue, you'll get drops Right, so I'm you if you somehow exceed the threshold that you can't see in that queue you'll get drops right so yeah i'm fine with like like like by definition, a shallow buffer queue is going to result in drops when you exceed the bandwidth by first you know by some amount like that's obviously a property of this and that is fine. But if like I'm if there's some sort of larger mechanism that is um kind of like labeling me bad and sorry like, if there's some sort of larger mechanism that is kind of like labeling me bad and starting to drop my stuff, that is, that is a different hour Thanks. I have this here Making it mandatory feels like a barrier to deployment And in the absence of strong evidence of a failure of incentives, I would not make it mandatory I think it's sort of a waste. There's actually another attack that you could use, another defense you could use and that is for devices, hardware that can do virtually cues it at line rate you could unconditionally delete the duplicate match, which would in enforce it even if you're not otherwise loading the system And that, I know there are a lot of other vectors that do have hardware that can do that kind of thing Okay, maybe I'll follow up to you up line and should be good yeah I would recommend saying something fuzzy about in the absence of any evidence of cheap This is probably not important"
  },
  {
    "startTime": "00:36:00",
    "text": "but people should be prepared that it might be needed. All right Appreciate that. Thanks. Matt, I think this question has your evolved about as you would like to see, which is it won't be mandatory won't be mandatory and we need to figure out what the right text is to write about to write about its role or remove because or remove because it's not mandatory okay so i i see a few things here um close the line so we'll we'll stop this discussion on this one. I see that it be wise to separate out the Wi-Fi case. It might be wise to clarify a little bit what um what options we have for managing here I mean so they're written in the draft but maybe they're not quite so crisp in that particular place And I think we can recommend the editor to work with other people to try and come up with text that resolves us not quite so crisp in that particular place. And I think we can recommend the editor to work with other people to try and come up with text that resolves this issue. It looks like we're on the way to getting there Okay, great. Do you have two more slides, I think? just to wrap things up, the inter early review, three comments um two of them have already been taken care of in draft 24 the first one involves, again, that 500 kilobits per second And you know, even with the improvement made in draft 24, it's still in reading it with fresh eyes could be the rate equation could be misinterpreted as referring to the 500 kilobits number. So another just swapping the order of two sentences in order to resolve that, so hopefully that solved that one Next slide. Next steps I think we've covered that already So that's it. So when you expect to deliver documents? with 25 in? Are we talking about?"
  },
  {
    "startTime": "00:38:00",
    "text": "weeks, months, yes? Hopefully it is a week or two. Excellent, good answer Thank you Okay, so that took slightly longer than we budgeted in our agenda but we think we're still running with the schedule first speakers having the time so the next one up will be this man here And you don't have slides, is that right? Or you do have slides I do have science yes look at the science yeah I can only thank our marketing people that you know I usually I just use it plain light background So next slide, my name, by the way, is jason livingood from Comcast. You can update on our dual-in-Q trial So first, thanks to our partners, in particular to Apple, NVIDIA and Valve They've been invaluable in giving us app player QOE feedback and they have employees that are participating in the tests that are able to give us feedback as well. That's helped a lot In particular, some of the feedback from Apple that helped us iterate some of the boot file configuration settings that we're austin wright now. Next slide So here are the three questions What network areas are we going to deploy in? on what devices and when? And that's where of where we are in the trial. So next slide So the first thing that we're doing is we are deploying on what's called our virtual CMTS platforms so we have two different types of CMTS which is the next top from the cable modem. The integrated CMTS, so deploying on what's called our virtual CMTS platforms. So we have two different types of CMTS, which is the next hop from the cable modem. The integrated CMTS are the sort of old school routers, you know, big chassis line card kind of thing those are end of life from our standpoint. We're migrating everything to virtual CMTs which is a new virtualized platform and it depends as well on this new digital fiber node to in many areas the network in the past, it's been an analog file"
  },
  {
    "startTime": "00:40:00",
    "text": "node. It's moving to digital, which means from that node, we can go last mile, which is really last block or two, either EPON, 10 gig, epon, or HFC And I would say more than half the network today is upgraded to what you see here and we're pushing that forward The two different areas that you would see in those next year areas, one would be mid-split where we've changed the split of the RF spectrum that the upstream band pushing that forward. The two different areas that you would see in those next-gen areas, one would be mid-split, where we've changed the split of the RF spectrum that the upstream bandwidth gets and raise that. So in our mid-split areas, typically you're going to see a one or two megabit per second upstream instead of something more like 35 megs. And then full duplex areas are completely symmetric speeds 1 or 2 gigabits per second. Next slide And just to give a picture like today to serve 60,000 homes past that old analog or line card-based chassis, you know, you'd have 20 racks doing that. Today, in Gen 2 areas, it's one rack and we're in the midst of doing this Gen 3 right now So, you know, that's a much better situation for us, and we control more of the code base. Next slide. And by the way, that's code base control is important because you know that's how we've been able to add and sort of play with the downstream dual queue support And then just showing very quickly the inside of the digital load this looks almost exactly the same as the analog nodes Essentially what we're doing is we send a technician up on the pole they flip the thing open, they take the bottom cover out and they are just putting a new basic new shelf inside of it. So it's a very quick thing and it gives us a whole ton of benefits, which is awesome, among which is you can go 10 gigipan from there instead of HFC if you need to Next slide The devices, so what devices? The first device that we're going to deploy on are our own gateways. They run the software called RDK, in this case"
  },
  {
    "startTime": "00:42:00",
    "text": "RDK Plus. It is an integrated cable modem plus wireless gateway The customer can turn that off so they can run it in what we would call bridge mode and use their own home router if they wish to, but it works best when that integrated AP and router and modem are sort of all functioning as one. One of the key reasons that we're launching first on our devices is that we control the code base directly and we have been you know, regularly adding like every single release that comes out. We're tweaking features tweaking configuration parameters and so on And that also gives us the ability to sort of carry some of that dual Q support into the homeland. In parallel, we have customer-owned and managed retail cable modems that are getting certified wen lin the trial had a few different devices the Arras S-33 and a few others. We've run into problems with some of those, in part because of the chipset that those devices are running. So we've sort of pivoted on some of the retail devices and we're now focused on the ones that are ready for our full duplex deployments and there's a very small list of those right now But we're emphasizing some of those and so depending upon our exact launch time it'll either just be with our devices for 30 days or 60 days, or it might be our devices plus a small set of retail devices my goal is to have both of those classes of device ready at the same time. At the same time, I don't want to put any critical path dependencies on the devices and so I think the objective is let each of them go on their own sort of life cycle. And as soon as they're ready, they'll be added And for us, we have a number of devices, you know, xb8 is the newest xb7 both those are going to be ready, and then XB6, we have a huge number of people on XB6s. So that is sort of a fast follow that's in RQ as well"
  },
  {
    "startTime": "00:44:00",
    "text": "So working together as many devices as possible, one of the advantages of using some of the newer retail devices that are getting ready for full duplexes, those vendors that supply that are still really engaged in doing regular code updates to get full duplex working. And so it's easy to say slot in a tweak to this or that l4s feature so that seems to be why that's helping. Next slide So the million dollar question is when. And all I can say is kind of soon. It would be very soon if it was just up to me, but we're in that final phase for those of you that have done, you know, operator deployments and you know the broad permutations of stuff in people's house and weird things in the field and so we end up getting to like okay we think we're ready to go and then we're like oh we have this one really weird use case that affects whatever, two dozen devices And so we need to go fix that, and then you figure out, oh, that's a really simple fix Maybe that's a couple lines of code. But the team that has to do that work is like, oh, sorry, we've got this big backlog of you know, higher priority issues. We'll slot that in 45 days So we're in that kind of, you know, final dance which is usually a good sign because things are looking very stable operationally and you're just into the final things the blake provisioning systems, monitoring and other kinds of, you know, little bugs that we have to hammer down in fact some of those that are just totally unrelated to us but we've got some dependency on a code release in some of the devices or the CMTS. So hopefully very soon all the feedback from users has been very positive and I think I've shown in previous IETF meetings the benefits of, you know, cloud gaming and so on We've had a bunch of great conversations here with some new folks that are interested in doing more trials and hope to see some things there as well Thank you. Do you have any questions?"
  },
  {
    "startTime": "00:46:02",
    "text": "I see one peterson in Q. Go ahead Oh, I'll just say this is Sue. It does Thanks for that report. I just heard that you mentioned full duplex. Is it full duplex on the access, the Wi-Fi part or on the from the device to the upstream? Yeah, great question. When we say full duplex, we're referring to the doxas network. I see on the, from the device to the upstream? Yeah, great question. When we say full duplex, we're referring to the doxas network. So in the access network, you know, one or two gigabits per second symmetric over HF You know, Wi-Fi, as you know, is a little bit of the Wild West, so speak Yeah. No, that's a, that's right maybe you have a device with support will develop legs on the way Wi-Fi part. But thanks for the clarification. Sure matt mathis is there a quick way to check for our specific service? a quick way to check like with the current staff is I mean oh like if how close we are or what pieces are missing If you're a user, for example, like checking to see if you're ready in one of those VCMTS areas for example, for example. Yeah The short answer to that is not really. If you run a trace route, the as somebody that is certainly far more technically capable, you know, can that's like easy, right? Yeah, I've used trace route a few times Yeah, yeah, I figured. But you can look at some of the host names, and when you see the CMTS name, it's going to be very clear that's the CMTS But we are working on some sort of quick visual indicator It kind of astounded me that that didn't exist yet primarily the indicator that you you'd notice is did you get any messaging about higher upstream speeds? We're usually very vocal about, hey, you're about upgrade yet. Primarily, the indicator that you'd notice is, did you get any messaging about higher upstream speeds? We're usually very vocal about, hey, you're about to get upgraded to one or 200 megabits per second upstream You might need new device, et cetera, and that is an indicator that"
  },
  {
    "startTime": "00:48:00",
    "text": "you're sort of in a network that's going to be ready. Ah, because I did notice an upgrade that wasn't announced Ah. That happened to me, and it was to 1 or 200 megabits There you go. Then you're on a virtual CMTS Hooray Thanks, Jason. Great. Thanks so much And for people who are wondering, the part of the multi- a virtual CMTS. Hooray. Thanks, Jason. Great. Thanks so much. And for people who are wondering, part of the motivation for getting Jason to present here, is to facilitate the next work item And if you're somebody who's also looking at L4S deployment in your network and you want to bring a present to the next meeting then get in touch with the chair All right, next up the L4S ops draft So for those who aren't familiar, there was a lot of discussion during the definition of the L4S functionality around a particular scenario where a bottleneck link has a single queue L4S functionality around a particular scenario where a bottleneck link has a single Q RFC 3168 or class ECN active Q management mechanism. And if that is the bottleneck along the path and you've got L4S traffic sharing that path with classic traffic then the L4S traffic will get more than it's very share of the capacity In some cases, even bordering on potential starvation, a lot of cases it's far from that, but there are some cases where it could be problematic During the discussion, no one was able to identify that these bottlenecks actually existed in the internet, but they certainly theoretically could And so we wanted to write this draft to give guidance for how to detect them and if you happen to be running a network that has them what to do about it So next slide, please"
  },
  {
    "startTime": "00:50:06",
    "text": "I'll already cover the scope. So the status of it is that we've not made any updates to it for a while since 2021, in fact We agreed as a work group to keep it open as a living document as L4S deployment begins in case there are additional learnings that we'd like to include in the document so far we have not found anything that needed to be updated If anyone thinks we're missing something, now is the time Our milestone is to wrap this up in nobody anything that needed to be updated. If anyone thinks we're missing something, now is the time. Our milestone is to wrap this up in November at the Dublin meeting So the clock is ticking. If you think there's something missing, please make us aware on the mailing list and we'll have a discussion And the last point, this is an informational direction so it isn't as if once November comes week cannot learn anything new and we can't give any future guidance we can always revise the draft, so, or revise the RFC. Yeah, Matt. Yes if it's a living document, is there a reason to close it before you get further into the deployment? um well I guess for the reasons that if has sat now for three years and we've not detected the need to add anything to it it certainly doesn't hurt to keep it a draft and keep pushing along And what's the current deployment penetration for Elphoros? L4S? The only large deployment is the one that Jason just spoke about. Okay which might detect problems and it might not I mean, there's always a potential that some"
  },
  {
    "startTime": "00:52:00",
    "text": "new unknown interaction between classes ECN and accurate ECN or modern ECN will be dedicated discovered And although it bothers a certain class of people who score internet draft progress and stuff like that to keep this draft open forever, I could imagine a world where the stock draft is never closed because, in fact, it becomes irrelevant But you're not going to know that until you get into significant deployment deployment let's punt on that in dublin because that's a good question And in Dublin we would like to ask us chairs if we want to keep this document open or if we think that we have enough This is the important discussion. I mean the third option is we decide we don't need this document because we have consent that the issues are fixed. It's informational We can always publish another one as well. Remember, that's consensus that there are no bugs. Census? consensus that there are no bugs Yeah, right. And that's interesting, so it may be easier to publish an informational document and then publish a second one in three years of time, which says since this, not are no bugs. Yeah, right, and that's interesting. So it may be easier to publish an informational document and then publish a second one in three years of time, which says, since this, nothing happened. True, true But I've certainly used internet drafts like a little private wiki that I then threw away All right. I think that was that. Then I do have a very brief update on the L4S interops Next slide, deck point two very brief update on the L4S interops. Next slide, deck. 5.3B. Yeah. So we've been running an interrop a bit. Next slide, please At this IETF, this is the fifth in the series of interrupts that we've held in conjunction with the IETF meeting, starting with the hack this IETF, this is the fifth in the series of interrupts that we've held in conjunction with the IETF meeting, starting with the hackathon on the weekend and then continuing all week"
  },
  {
    "startTime": "00:54:00",
    "text": "We have new sticker as well The graphic is here if you didn't get a sticker grab me after the session. I've got a few left A lot of people are wanting to collect the full set In addition to the five at IETF, cable apps has hosted seven of them at our facility. And we have across that series of both IETF and cable labs over 20 organizations have participated in them averaging about 30 participants per event. Next slide, please time. So the new news a new set of Linux kernel patches for L4S, that's all the components AccuracyN, TCP Prague, and dual pi squared There are links there in the slide for kernel 6.1 and 6.6, as well as one specifically for ARM slash Raspberry Pi Second big news is a new open source congestion control object called UDP Prague that was released this past weekend to any application that wants to start using L4S congestion control in built-in to the application, I want to go to UDP there's a great way to do that It's still new, so bugs might exist so please try it, try it, send comments. There's also a functionality within it that's intended specifically for video streaming applications that's intended to integrate with the codec. During the interim it was, that was picked up and integrated into IPRF2. And so there's a feature I'm not sure if it's fully released yet but it's very close if it hasn't, but you can do a dash dash udpl 4 s or udp UDPL4S video to run tests that use that congestion controller. In addition, support"
  },
  {
    "startTime": "00:56:00",
    "text": "was added for seeing ECN information in the TCP BlackBock tests that use that congestion controller. In addition, support was added for seeing ECN information in the TCP black box logging and free BSD So that supports not just L4S, but other ECN information as well And then last Netflix was making improvements in their simple rate control, which is an L4S rate controller for video streaming Next slide. Upcoming up opportunities, so there's another inter-opt at cable labs in just over a week from now So if anyone is interested in participating in that registration is open. We do intend to also do one at the next IETF meeting in Dublin. Let me know if you have any questions or comments on that So thanks That's it Thank you, Greg Get in touch with Greg if you plan to do some interrupt testing, if you can go to the Denver Interop, the IETF hackathon, or anything else, may be very pleased to hear from you And next over to Martin I think we have enough time for the DTLS discussion yeah next we'll talk about SCTP and if you remember Brisbane. Yes, Matt I'm sorry. I had a late thought about the previous talk, not the immediately one, but about the internet draft. Another thing that we could do is ask vendors of equipment to put warning in their operating systems about people turning on obsolete options many things are possible Okay, back to SATP. So in Brisbane, we had a pretty long discussion about DTSS protection for SCT And if you remember, we had three different drafts two from Erickson"
  },
  {
    "startTime": "00:58:02",
    "text": "both of them affected to varying degrees by IPR And then there was a third draft by Michael and Hans And that one was not affected by by IPR however it depended on a document TLS extended key update that was not yet adopted by the TLS working group And there's an update to share now, because it was presented in in the TLS working group earlier this week and all the feedback that had been received earlier by the TLS working group has now been incorporated into this document and there seemed to be very little pushback on this document in TLS and the TLS Working Group is now running an adoption course The adoption call is still running for I think two weeks, but they've already been, there's been group is now running an adoption call. The adoption call is still running for, I think, two weeks. But there's been a lot of support for adopting this document in TLS Thank you probably have an update there that soon when the deal working group comes to in conclusion if they want to adopt this document and if they do then the draft can be updated to depend on a possible TLS working group item Is there any anything else you would like to say about this doctor? Michael? Then we can jump to"
  },
  {
    "startTime": "01:00:02",
    "text": "your other document which is RFC 48 4895 Yeah, Michael Dirkson I'm talking on behalf of the other co-authors So this is about the best document of SCDP authentication, which is a requirement for the DTIP over SCTP solutions, both of them, the one provided by Hennes and myself and the other one provided by Erickson. Next slide So the original scope of the document was to incorporate relevant changes from an old draft which was trying to add some clarifications to address two security issues reported by Erickson which means one is the use of directional keys and the other one is don't use the same algorithm sorry, use to different age make algorithms with the same keys And we want to generalize from H-MAC to Mac, which we'll just be reverting. We will return H-MAC-Shaw-1 and use the different algorithm as mandatory to implement and we will add, or we are adding, socket API considerations to make the implementation of DTLS over SCTP better Next slide. So this is the status of the first individual version basically editorial stuff and changing to XMRV3 Next slide This is the changes between the document we had at the last IETF and this"
  },
  {
    "startTime": "01:02:02",
    "text": "one. Basically, two things happen One is there's an error cause you send when you receive an auth giant using an HMEC identifier, you don't support or you don't understand And there was a discussion whether it was or you don't understand. And there was a discussion whether it would be better to just silently discard this and I think that's true and so that change has been made. And thanks to Timurferko, who read the document in a detailed way there were Various editorial improvements. Next slide This is how the, let's feature integrates in the SDP Hens handshake. So in the Enid and Inid Egg, you have three parameters One is a random parameter, which provides a 32 byte random number. That's unchanged You have a chunks parameter where you where the center of this chunk says I'm accepting these chunk types only in an authentic way, so there's no, it's not a negotiation, it's a declaration. And the end point can say which edge make algorithms it's, it is supporting. And we are trying to allow backwards compatibility so if some implementation is only supporting algorithms from RFC on the old RRF and the other side has via the API, indicated that it supports legacy stuff and it will work but both sides can also say we don't want to do the legacy stuff, only the new stuff. Next slide So that was the legacy mode. How do we distinguish between it? All the H-MAC algorithms defined"
  },
  {
    "startTime": "01:04:02",
    "text": "and the old RSC will be deprecated We will have new ones and if an endpoint is announces only the new ones, then it's not operating it legacy mode. If it announced both, then it supports legacy mode but it prefers the non-legacy mode And if it only announces the new ones, then it's not operating in legacy mode. Next slide There are two proposals I'm bringing up here, which could be integrated and one is the solutions for DTLS over SCTP SCTP It's useful to say, I want to accept only authenticated chunks. So you cannot require authentication for Init InEX shut So you cannot require authentication for Init Init X shutdown complete and off, but for all the other chunk types. And that would mean you would need to list them all So the suggestion is to when not operating in legacy mode, sending an empty list of chunks does not mean no chunks are required but all chunks are required So that's doable in a backwards competitor way, and it just makes the handshake shorter, because you would have to list I don't know, 250 bytes there if you don't do this. So that's something which is easy to integrate. It will only work it will still work with legacy notes and allow this for non-legacy nodes Next slide The other proposal is a couple of people brought up the question whether the replay protection when you're using STV authentication should be"
  },
  {
    "startTime": "01:06:02",
    "text": "better than when you are not using this So the old ROC says we don't improve the replay protection so you get the same level of replay protection but this is a this is a proposal to improve this. So when not in legacy mode, you would change the layout of the author chunk by adding a 64-bit counter. The sender would just increment for each off chunk it sends this counter by one. And the receipt would have a sliding window of chunks. It's accepting and it's making sure that an off chunk is only accepted once, at most once. And this is the same replay protection algorithm as done by IP IPSEC. This only works if both sides are not in legacy mode, since it changes the format of the earth chunk The question here is, should be into integrate Proposal 1 and or Proposal 2? are not in legacy mode since it changes the format of the auth chunk. The question here is, should we integrate proposal one and or proposal two to to make, to improve things? Is there a next slide? Do you want to take questions? now? Depending on the next slide, because I think the next slide says next steps. Exactly. So this is what what's still need to do. Integrate Proposal 100 or two depending on the feedback changing the text-based description to a more formula description, generalize the text, and basically address all comments which will be received received Magnus. Yes So, on Proposal 1, I guess on high level it seems fine, I guess"
  },
  {
    "startTime": "01:08:02",
    "text": "it's there's already connection between the chunks and algorithm which enables you to select which I mean that you bind to those two parameters together and the interpretation of it depending on the other that's already true for the both that both is dependent for us so I guess it's fine in this case but it does complicate things slightly slightly Sorry, it was very hard, at least for me to understand you So you are in favor of proposal? one or you are not I'm slightly worried about the impacts on the coupling but i think i would guess it's likely to be fine but it's so I'm indifferent in some sense from that but I see there's some little risk for some complications due to the coupling between the parameters and their processing Thank you let's talk about two instead, which have think is a good proposal I think you should consider just including the lowest X bits in the actual authentication chunks You don't need to send all 64 in each packet 32 would be more than enough In addition, due to the multi- multi-holming, I think you need to consider this this is something we have included in for the details chunk also is that because when you have replay protection, based on the transmission order"
  },
  {
    "startTime": "01:10:02",
    "text": "and you're not caring about which path and which just destination transmitting your heart beats for any additional paths will be a challenge in that you will have need to have a larger window that covers also the leak any additional paths will be a challenge in that you will need to have a larger window that covers also the latency difference in the different paths So your window four need to be large enough to cover those cases But I'm in favor of doing too Okay, so you're in favor of doing Proposal 2 and they didn't got Proposal 1, so maybe you can send that to the list and we can Yeah, okay Unfortunately, it's very, it's very hard for me to understand what you're saying acoustically John? Yeah I haven't told proposal two, but if it's about the details of Proposal 2, but I think to publish this in 2024 as a proposed standard, I think replay production is a must I think the requirements to publish something as proposed standard has increased in the last decades I'm also missing privacy consideration But VCP is that DIETF should always consider pervasive monitoring in all standards And here we have a security protocol that had no encryption You could argue that this is already"
  },
  {
    "startTime": "01:12:03",
    "text": "outdated, but at the absolute minimum, it should have a very clear privacy concern section, saying that's like, basically, this is not really recommended recommended So you mean updating the security considerations? of the document? Yes, with privacy considerations that this is not encrypted and there are implications for pervasive monitoring Any comments? regarding Proposal 1 or 2? Don't do it Okay, so I think we just going to be the discussion on the list. Okay, thank you And then next we have Magnus with an update on DTL S for SETP Yes so, I'm going to update on the both the work current working documents and our detail is shrunk proposal So, next slide I want to remind you about the IPR declarations that exist for these documents"
  },
  {
    "startTime": "01:14:02",
    "text": "where there's two on the first document the detail chunk has the one which has offers an non non-license requirement if you fulfill certain requirements, but it's comes to non assertion again it, etc So please read it. The other one is random It's like the other two. Next slide Just a short reminder about what the detail is chunk and handshake looks like So we have the call this detail as in SETP The detail as chunk is basically a detailed record processing inside the STP stack between the basic packet arrival handling and the actual chunk parts And this is keyed from a high layer where the detail is run detail messages for key management and session establishment and then push this keys into the record processing This can enable a split stack And those details messages beforehand, managed sent over the ESB specific PPD ID and when you want to re-key you ask generate a new detailed session that derives in you as key performs of an authentication, all these things And message fragmentation is done by SATP is normal because this protect, there's one record per SATP packet basis basically. So next slide So what has it happened since last? We used to meet an update, the draft update one aspect with this was the"
  },
  {
    "startTime": "01:16:02",
    "text": "replay Windows 4 for, because of multi-path and our multi multi-holming and the heartbeat mesh is being sent over different paths needs to be replay, the replay window needs to begin our multi-holming and the heartbeat smash being sent over different different paths needs to be replay the replay needs to be big enough to cover those packets we also clarified around the p-valids solutions indicator field and the fact that the is an array, if you ever would have more solutions than 32 you would just add another 32 bits for the bit vector We also clarify how you keep p-valid, reliable so if you Luce the P-valed U retransse off an RTO timeout And if this and you continue to do this until your T T-valid timer times out and then says declared session association establishment as failure failure We also clarified how error during handshake error message can be done used to deal a different situation situations And we also clarified what you do if you actually sketch an SSTP chunk bundled with the detailed channel and that is to ignore the other chunks chunks And we've done updated the P valid protection solution in the K2i and registry and mandated detail as replay protection being used. So those are the changes on the data the P valid protection solution indicator and registry and mandated details replay protection being used. So those are the changes on the detailed chunk draft. Next slide On the handshake, there's a few small updates, mostly the Toro improved mostly tutorial improvements. We have clarified that if you would actually have this super jumbo record limit, you would basically what this imply would be that you get an IPMTU support for SDP message up to 64K instead of 60"
  },
  {
    "startTime": "01:18:00",
    "text": "limit, you would basically what this imply would be that you get an IPMTU support for SEDP message up to 64K instead of 16K, which is the current limit and we also looked at considerations for data gram path, packetation, layer, MTCU, discovery, and how that interacts with the Dittlest record overhead and sci-fish changes, because they can change how big a sense authentication tag etc is added so next so we have an implementation work on our own on the third chunk ongoing This is actually we're trying to verify that this works with our intended use within the 3DPP protocols, etc and we actually have come to the current status if we have initial handshake and data transmissions working working on get, try rekeying etc but that's not fully fun functional yet, but by expect by next IETF meeting we should have a, be able to have a full report on on the successful implementation here Next slide There are a few open issues which was found during the review and preparation of the draft They are rather minor most are editorial. I will discuss the first one of the details chunk after this slide But the other ones we will expect to resolve rather soon in an upcoming update because most are editorial in nature This API need, if you need a queue is saying how many invocation if you need to have some help there in that API this abstract API or not, that's basically the question. Let's go to the next slide so we can discuss the open issue"
  },
  {
    "startTime": "01:20:00",
    "text": "if anyone has input. So currently for the details chunk, all detail is message coming from the handshake is bypassing the detail is shot and sent in their own shtp packets unencrypted, so they are only protected what detail already provides from protection for these handshake messages, etc So, but when you have a managed to establish the first and you have some keys in place, you could actually encrypt these And the question here really is, if you should, when this is, possible, should be encrypted It has some small benefits in high the details handshake from direct targeting from any adverse on path and it would allow them to bundle with other chunks if possible if they exist just that I went at timer transmission like hacking and stuff like that but the downside here we see if this if you have any kind of failure so that you can't send encrypt messages you will have to first as a send to detect that this is happening and then send resend the data it a soundtrack message without the association encryption in place, and possibly this without actually being able to use the encryption etc so it's it can make the whole solution a little more brittle from that aspect so if anyone has so any comments on this we're happy to receive feedback Okay let's go to the next slide So on the detail, over CTP, here just as a reminder, so this is what's in the"
  },
  {
    "startTime": "01:22:02",
    "text": "working group document currently and this is defining details ETLS encryption of the user message specifically taking user mesh and this is defining the TELS encryption of the user message specifically, taking user message, fragmented into multiple fragments each being protected by a detailed record and then sending this protected user message over a CTP. And this is defined as an adaptation layer It is relying on SCTP Oaf to protect the integrity and ensuring that the order of this detailed records per message user message, comes back in the right order on the receivers side these detailed records per message, user message, comes back in the right order on the receiversing side. And it also uses the parallel dataless connection for ekeying and using the details connection ideas for identification So next slide slide The only update for you resubmitted a version just to keep it alive. We didn't redo any we resubmitted a version just to keep it alive. We didn't really do any changes. There are a number of issues but we have been kind of waiting here to see what's on general, what's, what would be the working group's direction on decision et cetera, for details for SETP before doing much more work here So, yeah, I think that's the last slide. So any questions or comments? comments? Michael Thurkson, you made a reference to the, I don't know, exactly the name, Super Jimbo Yes. Datagram thing"
  },
  {
    "startTime": "01:24:00",
    "text": "The document was recently updated to not be limited by 65 the, I don't know exactly the name, Super Jimbo. Yes. Datagram thing. The document was recently updated to not be limited by 64K, but to go beyond that so are you trying to uh this document was updated but not presented in TLS, so are you what are the plans? Are you moving this forward? or not or? I think I have to your, so saying it's for the detail chunk. This is unlikely to be needed improvements because it's the only thing it does is bumps the IPM and they're saying the SDPMTU from 16k to 64k per packet and the deployment of larger MTU than for even 4 or 9K is not really in existence where we see this would be deployed. So if that, and most common is like 1,500 1800 and we don't see a need for it from that perspective. But John, maybe have comments on it. So that means you have a dark document you don't want to progress? We don't need the progress it's so it's it's Jumbo, no Okay, thank you It really comes comments? Okay, please continue the work It would be nice to see progress on this topic before Dublin We've been, we spent a lot of time preparing the ground for this and it'd be nice to report on that progress when we come to Dublin Look forward to that Okay"
  },
  {
    "startTime": "01:26:00",
    "text": "Okay, thanks, Magnus The last talk we will allocate 20 minutes for the talk, so we reserve some time at the end for some working group questions or discussion Go ahead, John Hi, I'm John Kapelli Mall and I'm presenting the requirements for net some working group questions or discussion. Go ahead, John. Hi, I'm john kaippallimalil. And I'm presenting the requirements for network collaboration signaling on behalf of my authors Dan, Sri, Srether, and Spencer, and Ben BED So I'll take a couple of slides to go through why we have this document, some background and a rationale for it, and then go ahead and proceed the details of the slides of the of signaling itself. So we've there were a number of drafts over the last two years that were proposed collaborative signaling from the host to the network, network to the host and server to network and these have been captured in these drafts that have been listed here at the very time and one of the suggestions from these group, was to put all this to together in a single draft that can captures all of these and the constraints around them and that was this attempt in this draft So in the next slide, I can go over the general rationale For all of these drafts that were in the previous one, the idea was to enhance the perceived quality of experience and an observation that using heuristics and implicit signals may not be sufficient in many use cases that will cover in the next few slides and that a collaborative"
  },
  {
    "startTime": "01:28:02",
    "text": "approach is worth looking at so that's what I'll cover in the slides that follow So an overview of what we're going to cover here. The draft is organized into the introduction and then a set a use case to motivate the signaling and a very new section that you know we've combined the operational considerations of a network for these kinds of requirements. And the the requirements for host to network in section five and server to network in the in 5 Okay, so this is an overview of the end-to-end system and the access network bottlenecks that will looking at Two access networks are shown here, the three mobile network and a wireless or home with an ISP network. And we're looking at the access network as is written over here, and they may be one or more bottlenecks that we're concerned about. From the wire side where we're concerned about variations in wireless link quality in very short intervals of less than a millisecond and the aim that when the feedback signal is trying to adjust the rate and other things that's a bit too late, it might be helpful to send information that can allow the network to collaborate not just the endpoints Another aspect is bandwidth, I'm going by on the second point, the bandwidth constraints in terms of the number of concurrent users or exceptional overload"
  },
  {
    "startTime": "01:30:03",
    "text": "This is a case more or less for signals from the host to the network as to how to handle or what the user things should be prioritized. Other aspects include interactive media requiring both high throughput and low latency We are also seeing that traffic patterns can change during a session when we start introducing like media or AI generated content and the periodicity with with these shapers work may not be so applicable at that point And the whole idea is that an explicit signal from either the host of the net be so applicable at that point. And the whole idea is that an explicit signal from either the host of the network with these constraints will help the overall utilization So to start, with here, I'm going to just talk about the, you know, the operational conditions and so the network attachment and transport in relation to transport flows So this is a diagram that's in the draft but I'm I've just modified it slightly to illustrate over here that and i use may have network attachments, I mean, clients one and two may have network attachments, which run these transport flows that are marked here as flow X1, X2, and X3 and our transport flows for an application a1 or A2. And based on the network attachment, there is a set of QOS and policy constraint that are applied. For example, flow X and X2 get the same I mean, an aggregate set of policies and QOS that's applied to both those flows, meaning in terms of shaping and scheduling and so on We have not gone into the details of how that signaling is applied. I mean, that is for now"
  },
  {
    "startTime": "01:32:00",
    "text": "outside the scope of this draft You could imagine that in a system like 3GP they're signaling to set it up and that bundle corresponds to a connectivity session that's marked as a network attachment here, but it's not limited to just that one case it's we've made it more or less a general system over here so keep on that one case it's we've made it more or less a general system over here um so key points are that one or more flows may coexist in a network attachment and network may shape flows distinctly, even with that attachment, which is very typical For example, a high bandwidth using flow may be shaped while others are not The whole idea is to deliver a high quality of experience for all the flows Going to the next slide, please So use cases, I'll just skin through all the use cases. It's documented in detail in the draft, but the motivating ones are media streaming as for example an I phrase containing a full video frame should have higher priority and if it's not available then the rest of the ones in that group of which pictures don't make that much sense sometimes interactive media which in addition also considers highly delays sensitive inputs examples of XR and group conference or P2P voice of IP The third use case is that a user may have preferences, for example, some, for example, keystrokes to a server may be important in the case of a game or some while audio may be important in other cases there may be mixed traffic that's the fourth use case that we've identified, where"
  },
  {
    "startTime": "01:34:02",
    "text": "an example in in the draft is that of a digital model of real-world apps multimedia and interactive engagements So packet, and in that case, a package of a street should be treated in the same manner And the fifth use case is that of honoring metadata for servers behind a gateway, as in the case of entry case, a package of a stream should be treated in the same manner. And the fifth use case is that of honoring metadata for servers behind a gateway, as in the case of enterprise networks. These are all motivated ones and there may be more but I think this is good enough to motivate what requirements that we have identified Going to the next slide So this is an important section I think that now binds together, I mean, or whatever is common to both the host and network signaling and also the server to network signaling These are operational considerations, for example based on that network attachment and so on what happens in the network. The aim of the network would be to maximize utilization, whether it be banned or lower latency or some other policy condition and these requirements identifying what should happen when so leave for the host to net identifying what should happen when solutions for the host to network or server to network signaling is put in place. So just quickly skimming through them policy enforcement metadata hints from network to client to adjust behavior They could, when there are multiple sets, signals, there's a question of classification complications The third one is about metadata scope because the network does not generally add allocate a quarter per application of stream or flow So how would that be handled? There's multiple bottlenecks probably as was illustrated in the figure before. The fifth one is about application interference This may not be the case for all cases, but in some cases"
  },
  {
    "startTime": "01:36:00",
    "text": "you might have different applications that in interfere with others. Privacy is a very big one that's 4.6 and the main points are that none of the user and information or application information should be revealed when you add this metadata 4.7 is talking about scalability that the amount of processing that is required should not should not excessive. I mean, what we say is it should not scale in the order of the number of flows We're talking about mobile networks So in 4.8, when a session moves from one attachment point to another, it should not require a whole lot of effort to set up that new, the session should continue as before And then there are construct and abuse aspects I mean constraints in terms of that the network will not be able to provide signaling and prioritization and all of the for every flow that it's trying to handle So these are the operational concerns that we've identified when we're talking about the flows. So going to the next please. So yeah considerations that we've identified when we're talking about these flows. So going to the next, please. So, here, this figure can show you we're talking about the host to network, network to host marked in blue signaling over there and then server to network as shown in the red section between the server and the UPF Next slide, please So the next two slides will cover the host to network and then the server to network so covering host to network method 5.1 section two broad requirements that's priority between flows and priority within a flow. So by priority between flows we're talking about some flow"
  },
  {
    "startTime": "01:38:02",
    "text": "of the same host being less or more important than that of the same host we do not try to solve interflow between different hosts That's a different problem in terms of fairness and other things. That's not covered here Priority within a flow, for example, in some case video may be of higher priority and in other applications audio may be of higher priority Going to section 5.2 with the network to host metadata what the network may signal to host One is that of assisted offloads when the network seeks to change resources during a crisis or overload conditions And I should point out at this point that we're not aiming to create one solution that solves all of these criteria and maybe some of these requirements are this point that we're not aiming to create one solution that solves all of these criteria and maybe some of these requirements apply in some scenarios and not others So these are things, this is just grouping together all the requirements and constraints that we have to consider And 5.2.2 is about network bandwidth and rate limiting policies That's also something that a network signal to a host And here it's the server to network requirements The aim here is for the server to provide some information to the network in terms of how it would like packets, or groups of packets to be handled. The real use case in here, is that of media where a group of packets and the handling of a group of packets should probably share the same fate, not just a single packet And so it's interesting to identify a media for packets and the handling of a group of packets should probably share the same fate, not just a single packet. And so it's interesting to identify a media frame or a stream as a group of packets. And that group of packets would have a priority"
  },
  {
    "startTime": "01:40:02",
    "text": "a relative priority And some of those frames may be more tolerant to delay or not And the last one is a little bit different. The wireless networks go to see every now and then, and so giving an indication of the birth size and the interval of a burst would be interested in terms of letting the radio go to sleep and radio the amount of power consumed so these are the sets of requirements for both host to network and network server to network. And I think the last slide will be to summarize and say what we should do with the next steps So just to go through it very quickly This problem has been presented in terms of all the slides which we identified in the very beginning in a number of IETFs from 116 onwards. And, you know, there were various recommendations from the group in terms of what we should do. And the last IETF recommendation, I mean, working group recommendation was to group these requirements. So there's been a considerable amount of decisions on the solution or of the requirements I should say not the solution really And previous meetings had shown a significant amount of interest We are interested to see if the group is ready to accept this as a starting point. Thank you Thank you for your presentation, John. And we would like to run a show of hands first to see who has read this document And I guess at the same time we could let's run it in the meeting still Can you file?"
  },
  {
    "startTime": "01:42:00",
    "text": "do that um can you come to the mic if you have any questions for job same time, we could, let's run it in the meeting still. Can you, I'll do that. Can you come to the mic if you have any questions for John? We'll run that in parallel So I can ask a question now or? What's the question? Go ahead. Okay, yeah thanks for the presentation, John i'm just wondering have you done an analysis of because it's a broad set of requirements, and I understand you have collected these requirements from a multitude of previous works. I'm just wondering, have you done an analysis? of how many of these requirements? are covered by different solutions that might have been specified in different standards bodies, for instance, 3GPP has a lot of work around quality of service UE route selection policies, etc. You have a lot of L4S work that might be addressing some of these concerns here and so on so i would like very much to see and analysis of like out of these requirements, what is covered by already existing mechanisms and why are those not sufficient? to handle these problems so so because right now it's a huge set of things here that that I'm not sure that all of them needs the same amount of attention and focus Thank you thanks Marcus I agree with you. I mean, the aim was to put these requirements together, and especially looking at it with the 3GPP side, there are a number of capabilities, for example, on the home to net I mean, host to network side, which 3GP has got an extensive amount of signaling to set up, you know, the different criteria user route selection policies and all of that So yeah, we can maybe give an analysis as to or we probably won't be able to capture"
  },
  {
    "startTime": "01:44:00",
    "text": "every use case, but at least we should be able to say what's covered in some of these major deployments like 3GP or an enterprise network and say, what would be applicable way. Yeah, that's a good common and we'll look at it for sure Marcus, were you potentially volunteering to help in this problem? Do you think we have time? I probably don't have time to write it up, but I'll be happy to, you know, review and make comments if you do that work Thank you. Thank you I've closed the show of hands. We had 13 people in the be happy to review and make comments if you do that work. Thank you. Thank you. I've closed the show of hands. We had 13 people indicating that they have read the draft Carry on with the mic Hi, I'll try and say this coming Altanais, Komeraki. Extending the previous question, how does this system differ from the existing data? plane-based flow identification such as the IETF? IP Fix protocol, which is based on Cisco Netflow? You know, basically you are indicating a control plane based signaling. How is that going to be better than a data-plane-based signaling that already exists? and is used? Right. Okay I would say that this signaling is not, I mean, it is controlled signaling, but it is a site I mean we expect it to be a side channel do the data flow itself So it would be, I mean, I wouldn't say I mean, maybe in-band is one way to say, depending on the solution, but we're only presenting the problem at this point. So I would imagine we use a side channel like UDP options or like DSS I mean, it would depend on the solution and but it's not a separate control channel, if that's so you're saying you can use I fix I'm sorry there's a lot of echo so I couldn't follow okay I'm"
  },
  {
    "startTime": "01:46:02",
    "text": "saying so you're saying you can use IPfix or no This is not that. No, I don't think I mean, I mean, that would be a solution space and we should allow people to look at that. But we would need some signaling that crosses network domains Thank you Hulku, thank you for writing the draft I think it's very good to have use cases and constraints between written down But I think it's a separate question if we should work on solving these issues or if this working group is the appropriate location considering that there are things like scorn prob of that's Viking group specific use case of these one of these requirements. So I think my question is, is this an attempt to write the specific use case of these, one of these requirements. So I think my question is, is this an attempt to write down a requirements documents that list what the working group should be working on? Or is it about writing down what could potentially be done? And I'd be much, very much really if it's still at it um i'll clarify as a chair what we pushed back on was we didn't want to see a particular solution i mean we obviously more people have solutions in mind. What we want to do know was the requirements in this space the opportunities of getting some benefit from different techniques, and to somehow know, if this is a sort of work that could be done here because I think over the time I've chaired TSBWG, this has come up every 10 years looking backwards still coming up. Are we at this place now where we can actually write down some requirements, some use cases that are particular? some potential solutions and understand that privacy concerns, the operational concerns, and the potential benefit. Does that answer? Thank you I hope that it's remote"
  },
  {
    "startTime": "01:48:02",
    "text": "concerns, the operational concerns, and the potential benefit. Does that answer? Thank you. I hope that it will be more clear that is the case. Thank you michael sweet, I think this is a very interesting document indeed, especially the scene signaling from the server or the client to the network However, I have a gut feeling that this list that you're presenting on all the requirements of things that need to be signaled is too long and I think it would be I don't want to suggest that you go into solutions but i think we should have at least an example for each of these things of well somebody has done that, you know, like a research paper, some industrial developers or something. For example, I got this thought when thinking about the very last item you had, which was the burst size for putting devices to sleep I mean, that is an example that sounds very useful, right? But if you think about it, I mean, at least I don't know what i would do with that information because right now there are ways to just put the device to sleep after transmission is over. So I would have to be convinced that this is there is something useful to be done with that kind of information before seeing a document that lists it And I think it would make sense to go through the whole list in that same way and just prune it a little bit and get rid of things that are maybe not so convincing because some are clearly very convincing and you know clear cases but some are less clear. So I think that will be, it would make the overall document more convincing Thanks. It's a little bit in line with what Marcus also mentioned. I mean, in terms of I mean, it's complimentary in a way And maybe we can have an analysis in the appendix of some sorts of the B capture"
  },
  {
    "startTime": "01:50:00",
    "text": "or we can discuss how we should document this. Yeah Okay. Thank you Tengi, same to say here. I brief arrest through the document. I think it's interesting. I know all the history about the things here I'm glad you mentioned about the mobile case here Actually, I'm thinking like a host to network network to host the kind of things. But for the keys, you mentioned the 3GVP, it's more like a network to network. But this network is not direct connected There are some feedback mechanism The run network are going to get it and send back to the core for core to access. This is like an L4F alpha i'll give a specific example so this is for you to consider it's like not host to network, but something maybe from like access network to a core network, the feedback for you to digest And obviously, this is a good work, or just the network to a core network, the feedback, you know, for you to adjust. And obviously, this is a good work, or just, you know, there's something. Another thing is like a lot like you to review their RFC public by IAB. It's RFC-Nive 9419. Yeah, the title is considered on application network collaboration use a using past signal So that RFC has already been down some principles that can be done. But that is not in any group, but from IAB. It's RFC 9-4 already laid down some principles that can be done. But that is not in any group, but from IAB. It's RFC 9419. It's like an application to network application to network collaboration using pass signals Thank you. If I may respond So 9419 is something that we have referred to. And I guess, you know, definitely agree with you on that, that we should, there are other constraints which we have not elaborated"
  },
  {
    "startTime": "01:52:00",
    "text": "on, but just referred to 911 with you on that, that we should, there are other constraints which we have not elaborated on, but just referred to 94419. So that's great. On the first one, the comment I would like to say that what's between the 3GPP core and the access may not be of specific interest to the IETF at large because it's within, you know, it's something that 3GPP can deal with. So this is looking at the broader end point and network as it applies to the idea okay a reminder that this proposal here is likely targeting an informational document about the requirements and opportunities, not the solution space. And before I say more, I will let Zahad speak if he wishes Yeah, Jahit So I have a couple of things to say, actually So first of all, thank you. Thank you I think I was kind of like pushing like put the documents together so that we can have a common view. And I'm hearing like now we have too much in the place but that tells me one thing I mean one of the things that I I think like would be very many beneficial is actually to see these use cases, like elaborate on those use cases. And I mean, what benefits they do and how so kind of gap analysis on an idea for protocol level like how we would achieve that one. So that would be like one interest thing too. I don't know like if it is a documenting, it's like, PowerPoint work, but follow up things, but I would like to see those like so that we can actually just like how important those if we, if we do this kind of signal, if we do define something like for streaming media and stuff like that or any kind of use case that we're talking about that how much we are adding up, how much we are making sense, basically"
  },
  {
    "startTime": "01:54:00",
    "text": "if we devise something. And what is already there in I IETF that actually covers that So, so, like, okay, we have already protocols and signals to cover those kind of can actually covers that. So like, okay, we have already protocols and signals to cover those kind of look and reduce the number of things there. That's one thing And now I think, the other question, like more kind of an eddy question is like, I would like to see like clearly where we are going with this from the, I mean, as the go mentioned, like this is kind of like we want to like to know like I mean, I don't think like we should really consider like how we publish these things, information or whatnot This is, I think, a discussion point right now like, whether, I mean, Qadju has a good, good point So, like, is this something that we should work on this working group? or we form new working group or something like that but base work could be done here, like looking into the use cases gap analysis and requirements, we can see like, this is something that we would like to work on The other thing that I'm thinking, like, some of the, if you look, with details on, like, some of the use cases and requirements, they are going from par flow to par packet level costs And this is something like what is not is kind of absent right now because i'm my understanding, we're talking about flow level quality of service and all this things. So that's another kind of the question that we should drive to see like whether we'd like to go for that kind of granularity of quality of service or not, and how you actually achieve that kind of thing So there are a couple of things here I think we should really focus on what we're getting out of this work so that we use our time in a good way and where we want to go it's a bit not clear to me right now, so maybe something to work with the author and the working group and the chairs to do that we use our time in a good way and where we want to go it's a bit not clear to me right now so maybe something to work with the authors and the working group and the chairs to set that up up"
  },
  {
    "startTime": "01:56:00",
    "text": "Would you like to ask the working group a question about the potential to become? that topic? Or do you want to wait until a document emerges which has that content that you want? Well right now i don't think like we're asking anything, we're sharing the information right but then then let the share information come and see and we have discussion more rather than we try to understand like what we are doing here with a goal like what we're going to what we're going to now we have this talk document that's good for education and good for understanding, good for bringing information but where do we want to go with this? So we need to figure it out so that we understand So you'd like a new doctor that is focused on the we might be publish, I guess, rather than providing a background to it Is that right? So I'm not talking about document here, my query I mean, this is not the only thing about the document. This is about the this discussion, this is about the content of the thing that I want to see that we're doing. And also, like, kind of like from like management point of what we want to drive with this all this thing that we're doing in this. Because it's still not clear to me like how much we should do here and what we ask us to do here right so kind of focus on that kind of the goal that we on it's still not clear to me like how much we should do here and what we ask us to do here right so kind of focus on that kind of the goal that we want to achieve and also back that up with either document or presentation or like research i don't know like more data perhaps Like you said, John, like 3GPP doing something, if they have already like way of achieving what they want, what we should do here then. So that's also like kind of like a question, right? Somewhere need to be answered Right, yeah, there is some coupling over there that we have to look at here Yeah. I mean, clearly we can"
  },
  {
    "startTime": "01:58:02",
    "text": "put that in the in the document somewhere Yeah, sure. I think it also be useful to get people thinking about this solution if we were to have an understanding that we would work on some of this and maybe not all of them but some of this. So I think it would be better to drive that. I mean, given all the comments and concerns, that we've addressed today in terms of not duplicating things, or that there should be research that's backing it and also a clear but even so, I think it would be useful to have this. Yeah, yeah, I completely with you on that one just like we might need to reduce and focus and see like what's what's the solution is best might look like and think about the philosophy of quality of service and all these things and improvement they want to do yeah thank you i think you got very good comments today, actually. Thank you Okay. Thanks, John come to the end of our meeting, son. It was really good to see people here on a Friday. That was very good to turn up and we would love to see more discussion on the list regarding the drafts we have in this working group. Thanks very much. Keep using the list and we'll see you in Dublin Thank you"
  },
  {
    "startTime": "02:00:05",
    "text": "Thank you Need to go topside, I think Read his mind Thank you"
  }
]
