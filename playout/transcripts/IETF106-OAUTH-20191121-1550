[
  {
    "startTime": "00:00:04",
    "text": "but if I need Aaron what do you see that there\u0027s a problem you know okay guys welcome back to the second session and I\u0027ve done a slight agenda bashing here so we had one leftover item from yesterday which got pushed to today this is the TR TX us summary dick is going to do that and followed up by a short summary from Aaron about the site discussions on OS 2.1 brian\u0027s next bebop to austin has two presentations on pushed authorization and rich authorization and then aaron is going to come up again and talk about the intermediary metadata and then we have Travis with some flames discussions that\u0027s all I have are there any other things that you would like to meet to bash in your gender nothing could I might oh wait I\u0027m Tony can you can you again scribe yeah an award-winning scribe do we do we have charm this was Ludwig was doing it last time Ludwig are you in the room okay awesome things there wasn\u0027t there wasn\u0027t I don\u0027t think there was anything yesterday right on Chava but but still it\u0027s good you know yep thanks umm very good we are good okay their card who is not at the PX off boss Coney you took notes so maybe you weren\u0027t there maybe that explains the notes okay so for the people out there quick summary we talked about a number of issues all right it\u0027s right here passing the request by a redirect has a bunch of limitations and security issues there\u0027s an awful lot of BCPs and extensions that it\u0027s complicated you know Justin put up this slide they just showed a whole bunch of the specs as being part of the issue a number of new use cases were described PSD to IOT user not present Annabelle had some interesting slides about some types of interactions that are not covered currently in o2 and then there were two "
  },
  {
    "startTime": "00:03:08",
    "text": "proposals presented one of them TXI aka XYZ potentially ba three versus sort of rawr par that are really extending to the questions then are do we pursue both of these one of or the other of them that\u0027s kind of one of the first questions that came up out of that whether we want to talk about those questions I guess first of all as any questions are and sort of as a summary people might have know okay well there was three hands going up so I was wanting to be inclusive it\u0027s 2019 yeah do we want to have any discussion or talk about this these questions okay [Music] right no one\u0027s going to the mic or anything though so I think one of the other kind of key outcomes from that is that we committed to having discussion further discussion on T X auth around what would if we were to pursue the new option of a3 oh we were gonna do that on GX all right but I thought since we\u0027re here we could see if there\u0027s more thoughts around this working group or a new working group if anybody had any comments around that we had him Kicks slide meeting this morning if I could ask or if anyone has ideas or approaches that would help us to come up with the answer to that decision right so one of the conclusions we came up with in the site meeting this morning was we would want a different mailing list than the Olas list for discussing a ton of brand new work that wasn\u0027t an extension if we really do that and that otherwise it\u0027s hard to track for people and probably have dedicated meetings to a big chunk of work and then another question or potential would be to do a design team within the existing working group so um there were a few folks at the buff who raised a hand to who were willing to work on this topic I\u0027m now it\u0027s some time passed um did you did you find some some more people who are the same type of people who are willing to work together like how do we how do we get this kick-started like who would lead the design team and and who would be willing to actually be on an assigned team to work on it besides obviously they\u0027re the authors of the proposals I hope well there is a Torsen who has had his proposals which are "
  },
  {
    "startTime": "00:06:08",
    "text": "really an extension so that seems kind of clear-cut work and then there which of today we\u0027re not talking and I think that on the agenda today is X Y Z T X ah stuff right yeah so the question is would there be people that would work on that yeah so sorry I got confused along the way we\u0027re talking about a design team with what scope so the question it would be if we\u0027re doing TX off and if it was in the Roth working group versus being a separate working group would you do a do design team for the TX off work within the OAuth working group that was that clearer I think Justin Richards just to maybe clarify a little bit these there was we had a side meeting earlier today these were all brought up as potential avenues and options of where the work can be done and how the work can be done this isn\u0027t saying that there was a bunch of people that said we should do a design team or something like that but just that would be something that would be more directly applicable to the OAuth working group there was a general feeling in the room and the side meeting though as dick was saying that it at least would need its own space like its own mailing list to kind of keep the focus on that whether that\u0027s an offshoot of this list or if it\u0027s a sorry offering to this group working group or a new working group or something else there was a general feeling that it\u0027s would be a big enough piece of work that having its own discussion space is important okay I just want to make sure I\u0027m tracking where you have an OAuth list we have a TX list and we\u0027re saying we need a third no no no we would use we would use TX auth like whatever because it\u0027s like whatever that gets associated with we would use TX I\u0027m sorry no no sorry about that although summarize it again if the TX off work was in the OAuth working group discussion for the TX auth were to be on a separate list the TX off list versus rolling it all back to the OAuth list it\u0027s Thursday thank you okay okay no worries there\u0027s no other part of this was just to bring everybody up to speed and some of the summary around the side meeting this morning okay Mike Jones I was waiting my turn to your question of "
  },
  {
    "startTime": "00:09:12",
    "text": "whether if we do this work which isn\u0027t I think a decided question I said it is not a decided question as far as I know I strongly believe that it should be in the Roth working group because that\u0027s where the collection of domain expertise is and in particular security expertise about what can go terribly wrong in protocols of this shape I\u0027m confused I feel like we\u0027re really getting a lot of what we talked about TX also we want to get a sense of the room of where we think the work and it\u0027s going to get done and that\u0027s the different conversation than we had at the ball okay keep going there so lisanna I would argue that if we\u0027re if we\u0027re gonna do [Music] this in a war then it in practical terms probably means three slots per week and it you know it will be quite a strain on the current working group sort of the management resources or the working group and that may need we may need to assign extra resources to cover that both seems to have enough on its plate as it is comment on that it\u0027s it remains to be seen if new work starts whether than existing work then slows down because I could imagine that some of you since y\u0027all since we\u0027re talking about the same people here that they may decide working on one sort of tea eggs also as sort of the the regular ORS at some point in time right I would assume I you guys you guys need to decide you you or do you want to Bush you come up with an extension Bush it here and push it there or what\u0027s the what\u0027s your thinking on that Annabel Backman Amazon I think it\u0027s pretty unlikely or unrealistic to think that work on Ross 2.0 and its extensions is going to halt the reason I i think it\u0027s unrealistic that is even going to significantly slow down because people are working on those extensions to solve immediate needs they have those needs are not going to go away just because we started to think about a bigger better way to solve these problems so the I expect that work to continue to you know for some time at a similar pace at least for the near future so I don\u0027t I don\u0027t really see this as three possibilities we do one we do the other "
  },
  {
    "startTime": "00:12:13",
    "text": "or both I really see it as we do you know what we\u0027re doing now only or we do both make Jones to your question about well are we rehashing something from my point of view I was in the buff there was no conclusion out of the bath to do new work there\u0027s a question on the floor about if we do this work do we do it in the oauth working group and i think again because the security expertise is here it should definitely be in the oauth working group if we do new work there\u0027s a question to the 80\u0027s and the chairs whether that would involve a reach are turing i think it would it would I mean absolutely I can - I completely agree with your surgery we were inconclusive tossed knowledge tit first of all I would like to second Annabelle so I wouldn\u0027t expect the work on or to slow down um I\u0027m for myself I\u0027m accelerating right now because we have to solve problems at hand so 300 is Ananda and a different time timeline from my perspective so I would assume us to work on both and actually on three aspects because yesterday an aside meaning we discussed - that one - that one potentially 2.5 I don\u0027t know I don\u0027t know because the extension we\u0027re going to talk about later won\u0027t be powered of - that one right and there is the TX off + 3 that\u0027s fine I mean in the end people will prioritize right and well Backman Amazon again - I wanted to respond to something Mike said as far as what is the open question asking if we\u0027re going to do this work do we do it in the working group doesn\u0027t make a lot of sense to me because you know the working group doesn\u0027t really have a conclusive say on whether or not IETF is going to do the work the working group might agree or disagree on whether or not it is work that that that we should expand the scope recharter ooofff to include that work but if you know members of the IETF you know demonstrate a need for the work and there is consensus that the work should be done somewhere then you know that that happens irrespective of the opinion of this working group just in Richard and I just wanted to address the point of getting the right expertise I mean I I "
  },
  {
    "startTime": "00:15:15",
    "text": "think that\u0027s it\u0027s it\u0027s a little bit of a red herring to say that if we to start a new working group we wouldn\u0027t have the right expertise because all of us are in like dozens of working groups I\u0027m in dozens of working groups with a bunch of you across different standards bodies and and within the IETF we have a way of reaching out to the right experts and bringing them in and I think that with something like this if we were to do a new working group or even to do a new mailing list which again I think is a good idea we would want to make sure that those people are involved that the right people are involved there are some really really brilliant people in this community that I think need to be part of this conversation additionally I do think personally that it\u0027s because OSU is going to keep keeping on for quite a while and we\u0027re gonna keep extending it and keep you know patching it and tweaking it and new security forward and things like that I think that there is a slightly different audience for T Axl style work versus ol2 style work with significant overlap but there are going to be a lot of people coming to the oauth2 world that just want to care about oauth2 and they should be able to do that and I think that\u0027s especially important because a lot of people raise the question of are we just going to confuse people by saying there\u0027s this new thing well one way to not confuse people is to say like there is a new thing and it\u0027s being worked on here to do something new so if you\u0027re interested in that new thing that\u0027s not done yet sure that\u0027s over there go alpha test go beta test right it\u0027s the spec is not written yet if you want to stay in the oauth2 space where things are more explored then there is a space for that I think it\u0027s too early to really decide because I only still don\u0027t know what our three is all about and we also came to that conclusion in the morning so we need a clear description of the scope of what Olaf will look like I\u0027m waiting for you just to refocus now so from my perspective the next logical step would be to really write up a proposal for the scope of all three and then then we might decide as a community as individuals on how to proceed I think that\u0027s makes sense instead of spending more time now because I\u0027m waiting to give my presentations so if I could summarize that feedback you\u0027re reiterating that there\u0027s two questions "
  },
  {
    "startTime": "00:18:16",
    "text": "to consider there is what is it that we need to do and there\u0027s then the question of how is it that we\u0027re gonna go forward we\u0027re doing that and these are certainly interrelated questions but we need to be considering both dimensions before asking my comment I\u0027m going to ask the chairs based on a chair excuse me based on that do we want to simply table this conversation for the time being pending more clarity on the Descamps the TX off work yeah it seems so that that\u0027s the right approach from the feedback we\u0027ve just got I would endorse that approach and I think we need to be again quite clear on what is it that we want to do and I think by then in numerating and being kind of clear crystal clear whether it\u0027s again 200 to 1 or 3 oh there\u0027s gonna be a lot of things to do and then we\u0027re needing to have a conversation on what it is to do I mean the key question for me is if we were to talk about a hypothetical new working group or a hypothetical recharter one of the key things for me to be figured it\u0027d be a bik\u0027s plane during that chartering process would be if I if someone came to us with a new body of work and I was holding that right now would it be clear how we would go about to do that work would it be clear if we had two working groups it would certainly be clear if we had kind of one kind of one working group which is not to say that\u0027s the right answer but the key kind of distinguishers do we know how we go kind of through that so I think we need to you know bottom line I think we need to write down first what it is we won\u0027t do and then we can engage in a conversation to how to split it apart or not at all um Aaron Preki from octa I just want to echo something I heard from the last meeting actually we had which I haven\u0027t heard come up again in this discussion which is that like yes there is absolutely going to be work on 202 dialects continuing for a very long time and the primary reason for that is that realistically getting people to move to a 3.0 is not something that\u0027s going to happen overnight by any means so the work on 3.0 is more about like long aiming for the future you know trying to trying to get something you know in front of people but sort of long-term planning rather than we\u0027re telling people to halt everything everything using 2.0 and switch immediately right so I think we just need to make sure that message continues to be something we get across we\u0027re not saying stop using 2.0 3.0 is better but wait for us to finish it because that doesn\u0027t make any sense and that would never actually work in the real world anyway so fine if I can summarize what I think I heard there was we\u0027ve talked about we need to describe what we\u0027re gonna do we\u0027re gonna then need to talk about how we\u0027re gonna do it and it sounds like perhaps there\u0027s a third third activity that\u0027s related to regardless of what we choose to want to do there\u0027s a communication we need to have because there are all sorts of stakeholders that are watching different parts of this kind of activity and we need to be crystal clear on the change "
  },
  {
    "startTime": "00:21:16",
    "text": "we\u0027re talking about embarking on to make sure you know we continue to have their active support and participation this is Justin I\u0027m all volunteer to take on the work item of taking a first shot at writing down what we want to do and I\u0027ll run it by Roman as a sanity check and then put that onto the TX off list for discussion sounds like a plan for me perfect Aaron can you quickly summarize the discussions are on to that one [Music] Aaron cracking again yes so yesterday we had a site meeting about OAuth 2.1 the discussion was very good discussion the sort of high level end result of that discussion was that seems like there is a pretty broad consensus on the idea that we need to do something to sort of clean things up there was definitely an agreement that it there is a lot of documentation to read the we didn\u0027t come to a conclusion on exactly how to proceed the main disagreement stemmed from basically whether or not any sort of new document should be should be saying things that are effectively breaking changes to the spec what I mean by that is not necessarily like nobody was saying we\u0027re gonna add new features in this but by doing something like requiring requiring the things that the Security BCP recommends that is effectively a breaking change to existing implementations which technically don\u0027t have to follow the Security BCP right now that was the main disagreement and I we kind of came to the conclusion that we need to discuss those more on a case-by-case basis I volunteered to take a first pass at writing up an outline for what a document could look like highlighting the particular aspects that fall on either side of that line so that we can talk about them individually because I think we agree that there was more to discuss there on the specifics so so in terms of the changes you were you discussing is sort of the best document or like because abyss document indeed it\u0027s not supposed to make breaking backwards but compatibility breaking changes but removing for example optional features is not such a feature or further detailing some yeah also not the the particular form of this document wasn\u0027t also was not something that we have you know landed on a concrete definition so I think that remains to be seen what the actual form of that will take based on discussions that we need to continue having so it sounds a little bit like we "
  },
  {
    "startTime": "00:24:18",
    "text": "need some more discussion and find out what specifically will end up in a document didn\u0027t then we can say like is this a peace process like an abyss can actually be also advancing it to along the standards letter if you will which would be useful I think oh it could be like you said that 2.1 it\u0027s something that is really different slightly backwards compatibility breaking changes although that one typically indicates yeah and maybe a finer point in the discussion of what tutor one would look like is was there discussion about using updates and obsoletes yes yep there was definitely some discussion or is that more conversation that\u0027s perfectly fine for just a punt was there was there resolution on that gun there was a preference for updates in in order to say that if you still wanted you to know do 2.0 that\u0027s fine if you\u0027re doing 2.1 you\u0027re bound by these particular restrictions there was a lot of as aaron was just saying there was a lot of contention about what it would mean to be compliant with 2.1 and how you would be able to support to oh and to one on the same endpoints or the same server or the same service or like there\u0027s a lot of deployment questions that would need to be better understood when we start changing you know shoulds into musts and adding new mosques that didn\u0027t exist ten years ago so to make sure i can reframe that so it sounds like what we\u0027re saying is we\u0027re preparing for an ecosystem based on this conversation that has 2.0 and 2.1 and we\u0027re making gonna make no statements about what they do with you know we\u0027re just gonna say we also have two not one that yeah that that was my read of it and so if you want to still do - oh that\u0027s fine you should follow the BCP which will basically make you 2.1 compliant yeah Annabelle back many Amazon just to add some more detail there the concern or questions around how big or how small a change 2.1 is from 2.0 and challenges around managing or living in a world where we have that 2 protocol ecosystem as a lot of what is driving the remaining question of do we actually do a 2.1 or are we doing a this which is not a 2.1 so yeah those questions are very much inner woman yeah we just we\u0027re just reporting back from a discussion and and there were different different opinions in my opinion and i "
  },
  {
    "startTime": "00:27:18",
    "text": "restate that now i would like to get rid of the security BCP I would like to roll that up in a new version after RC and if that operates on to Latour features fine with me because we actually have a discussion around that exactly but we need to support or we need to understand and to admit that there will be a world with two leto implementations running beside to that one implementations and even servers that support both so from my perspective we need to find ways to to make that happen right so and the to that o implementation can just RC 67 49 compliant from my perspective right so what you need to be able in an ecosystem to especially on the server provider side to offer migration path which might mean that you have both versions in power running and then we discussed how could we determine what the client needs is a policy based or is it is it have you do different set of endpoints and so on so I think there\u0027s a lot of stuff you need to sort out before we move forward and we have right now I think different opinions on whether we should make breaking changes or not comment from the jabber from Phillip restating that I mentioned at ITF 104 the name major/minor off version is one that doesn\u0027t need a BCP um but in any case we are looking forward to see that discussion happening under OS list so if you could trigger that soon I guess it will take a little bit a little while till we arrive at some common point so happy that you volunteer to to trick it out and lead that discussion okay hmm Thanks this is a little awkward to try to continue from where I left off on the last meeting that yeah I was try to start from the beginning go a little faster get some slides up so I\u0027m here to talk about some prospective new work it\u0027s an individual draft called deep hop that is loading the slides for it I put a lot of modules in - that\u0027s what I do yeah this this one start "
  },
  {
    "startTime": "00:30:19",
    "text": "yeah and this one maybe the other one [Music] there\u0027s more so real quick it\u0027s a draft proposal for a new hopefully simple and concise approach of proof of possession for OAuth access and refresh tokens and the idea is to do it at the application layer using app application level constructs and being able to leverage existing library support specifically JWT or our support so this can actually be something that\u0027s implementable and deployable a little history of possession the main motivations are to do something be better than better we\u0027ve had bear tokens for a long time we\u0027ve had a lot of attempts to do better some work out better than others mostly though we don\u0027t have something that\u0027s widely applicable this is partly motivated by the security BCP which rather aspirationally says that you should use sender constrained tokens I say it\u0027s aspirational because really there\u0027s not a lot of good options to do that right now and I say that kid that we lack really a suitable or at least suitable and widely deployables a political pop mechanism this is especially true around single page applications because the one thing we do have that\u0027s almost an RFC is the mutual TLS stuff the the user agent interaction and usability experiences doing in TLS in the browser are pretty much a non-starter for most deployments it just doesn\u0027t work so combining I I know I got really excited about it maybe too excited but it\u0027s just not it\u0027s not panning out so here we are again trying to try again hopefully with some lessons learned and another thing that\u0027s come up in in spas as well as mobile applications is a desire to be able to do proof of possession around refresh tokens as well for public client Steve a little bit stronger possession there so the basic flow is we have this mechanism which we\u0027re calling a deep op proof and it\u0027s just a new HTTP header it\u0027s the same it looks the same on all requests both the authorization server and to all protected resources it flows with the actual token requests usually a code exchange or whatever to the authorization server and it provides the public key and some limited proof of possession the corresponding private key in turn the authorization server can bind the issued access token to that public key send it back and then when it uses it at resource access it provides the exact same style of proof on each resource call in conjunction with the "
  },
  {
    "startTime": "00:33:19",
    "text": "access token that\u0027s bound to that public key and that\u0027s an extra check that the resource server can do so that top piece thank you the the the proof deep hop proof JWT is a JWT here\u0027s what it looks like on the inside the header atop here it\u0027s got some explicit typing because that\u0027s a thing we do now asymmetrical in the algorithm support and in the public key in jwk format in the header so and this is the key that signed it and the public keys there so it\u0027s basically just saying hey here\u0027s a jot I signed it with this key and you can know that because you verify the signature it\u0027s just showing possession of that key and in order to kind of give that proof of possession some meaningful context we try to associate it with the HTTP request in a sort of minimal fashion enough to make it relevant but not enough to be difficult or error-prone or hard to deploy with all the fun and pain that comes with trying to deal with normalization and signing they should be requests so we\u0027ve got a JT I claim in here that sort of encouraged but not wholly required to use for replay checking and we\u0027ve got some minimal information about the HTTP request itself including basically just the request URI with no or any other parameters just the the host and path and scheme as well as the method that was used and then the issuance time of the token so that the server has some understanding of how fresh it is and can enforce some window of validity there and there could be other stuff in there but that\u0027s the defined set of claims right now just enricher just really quick has there been thought about how extensible that body should be I realize pops only doing that and that\u0027s fine is there any thought about sort of what the namespace of a deep op + JA payload could have in it if somebody had something else they wanted to cram in there um not beyond like not past what\u0027s their other stuff go here ok that\u0027s that\u0027s fine and mansome mention in the draft now that sort of says as much like you could do more but but there\u0027s no explicit provisions for what that would look like gotcha okay thank you besides quick question any specific reason why replay checking would be optional so if you\u0027ve followed some of the conversation on the realist recently there\u0027s potentially some deployment issues at scale depending on how your architecture is for ensuring that the the one-time use of tokens is timely and accurate so you might be checking that validity you might be checking that sort of store of "
  },
  {
    "startTime": "00:36:20",
    "text": "IDs in a large cluster with an eventually consistent back-end to store that so you want we\u0027ve made some provisions to allow for things that aren\u0027t tightly transactionally oriented they could have really negative impacts on the system as a whole as well as you might you might choose to only track those within a local system only and sort of trade-off the cost benefits of this considering again these are things that might only be valid the might server might only consider it valid for the order of a few seconds you know I it\u0027s there\u0027s a there\u0027s a large continuum of sort of the level of security you can get to versus sort of the performance and the usability of this and we\u0027ve might not be the right place but we\u0027ve tried to sort of pick a meaningful spot in the middle that provides that utility without being too cumbersome to implement or deploy and so one last thing by optional I don\u0027t say it\u0027s optional but it\u0027s a should and it\u0027s actually a must another place with a caveat of within reasonable considerations for performance and inconsistency toastin as a co-author which just would like to add that you can different get different levels replay detection right if you don\u0027t do the gtii you get replay detection if someone wants to use the the header with a different race or server and if you put into the IDI they get you get the replay detection if that\u0027s replayed on the same resource or more I think that\u0027s a good a good distinguishment yeah in furthermore it\u0027s on the same resource research server at the same path at the same method in the order of a few seconds so it\u0027s narrow Annabel Beckman Amazon we talked in the previous session about the coming work for HP message signing so I\u0027m not going to go into that any more than just reminding people that that work is happening and maybe applicable here separate from that from the conversation on the list it seemed pretty clear to me that it would be helpful to have a clear statement of what what the threat model is for you know what we\u0027re trying to mitigate here with depop because the more of these things that you strip out yeah the more this just becomes another bearer token that you\u0027re putting in the request so it would really be helpful to understand you know once we strip all of that out are there threats that we are actually still mitigating here or have we just produce something that ends up making people feel safer than they really are yeah some tightening up of that I think well as with all things it\u0027s hard because I think everyone has a little bit different idea of what that is and the push to change this is you know there\u0027s different competing interests but it definitely needs to be some tightening up of the of the objectives around the threat model and what we\u0027re trying to provide I mean if there if there are competing interests and that "
  },
  {
    "startTime": "00:39:21",
    "text": "does argue for a you know more flexible model that yeah it argues for it but I don\u0027t know that it wins that argument no we have to have that argument I very much want to avoid a situation where the the client is in in the place of saying what is sine in this token because it has a lot of ramifications on how do you negotiate what that is what are the properties of that that actually provides and if we can\u0027t talk about it and I know we have a hard time yesterday talking about exactly what you get from what I\u0027m wholly unconvinced that the average client developer can make a reasonable decision well the client doesn\u0027t have to the resource own server does well that would then assume that you have some sort of discovery and metadata indication to say what particular aspects of the HTTP request are signed in the context of this resource that would be the API documentation for the API or calling and those are those are the things I\u0027d like to avoid again going back to this is meant to be simple easily deployable not a lot of options and if the scope of this is to be usable specifically and only within the domain where you\u0027re in a pure discovery world and and you\u0027re talking about a P is on completely standard interfaces then I understand why you would not want to be in that you know place where you have to negotiate that but the practical reality is that OS is used for all sorts of things that aren\u0027t you know just standardized api\u0027s and in those cases people have documentation for their API is that describe what needs to be you know how authentication authorization happens part of that can and if they\u0027re using something like this should be an indication of these are the things that need to be signed in order to protect this request it definitely could be but it doesn\u0027t have to be and one of the value of standards is avoiding the need to look up that stuff either in documentation or in dynamic discovered sort of metadata sorry I\u0027m under saying that that that there is value without yep there is value in that flexibility there are strong use cases for what we\u0027re what is what where you\u0027re actually specifically stating what what you\u0027re going to include what you\u0027re not and there are strong use cases for standardizing the format and allowing implementations and deployments to say this is what I need covered and this is what I don\u0027t both of those use cases exist and I think we\u0027d be remiss to support one at the expense of the other noted yeah I disagree yeah one last thing based on discussion on the list I believe you you or maybe it was Neil somebody in that conversation said that "
  },
  {
    "startTime": "00:42:24",
    "text": "that CPU cost of asymmetric crypto was not a concern at scale and I wanted to just state my disagreement with that we we have use cases where the time and and cost of asymmetric asymmetric crypto versus H max is absolutely a concern okay I don\u0027t think anyone said it wasn\u0027t a concern really we had that discussion early on like when Annabelle presented it and when I talked about the existing documents and there be a symmetric key mechanism we had that discussion for a moment we can go back to those yeah well I think that the more recent discussion was around the relative trade-offs whether the simplicity of not managing a symmetric key distribution environment and all the other things that come with that were worth the trade-off republic perhaps I misread or misinterpreted but I what I saw was that there was a claim that that scaling was not a was not a concern for asymmetric crypto and like I said I may have misinterpreted that so if so then that was an agreement I said it could scale out because of the nature of it you didn\u0027t but it didn\u0027t mean that there\u0027s not CPU cost but only that it could scale you\u0027re on Schaffer back to replay I think it would be simpler to always have a GTI always have a random GTI and leave it to the server as a should to do replay protection that\u0027s the current state of the draft there\u0027s just been awesome because you did mention missing GTI I didn\u0027t mean it that way I\u0027m okay it is required always from the client perspective there\u0027s a bit of wiggle room about just how strict the server needs to be with it but it\u0027s always required to be there and the server\u0027s supposed to I guess you say make a best effort at at replay protection toastin speaking as a co-author um first reflecting on Annabelle\u0027s question regarding the threat model it\u0027s being documented it can be found in section 2 so refers to the threat model that\u0027s documenting the security BCP and I think generally we need to keep in mind the scope and the objective of that draft I stated that yesterday I do it again this is a stopgap measure this is not intended to be at least from my perspective as a general means to do pop in the org world because we\u0027ve got another mechanism TLS and it works very well this one the original objective was to find something that works for SPS that wants to use access tokens in the browser please keep "
  },
  {
    "startTime": "00:45:25",
    "text": "that in mind we can change the scope but then we need to consider the consequences but that\u0027s that\u0027s the reason why we started at work this is Justin with what Torsten just said and again you know and brought up yesterday in mind the the scope and the threat model is not clear from the current dock so if we bring this in as a working group item then that\u0027s going to have to be very very very very clear because I think a lot of the discussion that\u0027s happening right now is because this feels like it\u0027s it it could be you know the resurrection of the whole low off pop infrastructure and that had all kinds of features like the server being able to provision keys to clients and symmetric crypto and all of this other kind of stuff which aren\u0027t part of this I think that this would benefit from a narrower focus like for example pixie had pixie was about you know public mobile clients protecting the auth code flow because they don\u0027t have client secrets and by the way here\u0027s how you do it turns out Pixies a lot more useful for a lot more than that and we\u0027re using it everywhere for lots of different things because it was a reasonably defined mechanism that found other uses this right now feels doesn\u0027t feel like that it doesn\u0027t feel like it\u0027s a specific point solution or stopgap as as Torsten said so if we were to go forward with this and to be clear I like deep hop I think it\u0027s a really clever way to have the solution and I\u0027ve implemented all these header processing things and stuff like that I I like this but we need but if we want it to stay focused it needs to be presented as focused in the text and in the working group we\u0027re not there yet I think we could get there if we decided to bring this forward Eric knee from octa I don\u0027t mean to like hone in on a specific point again but just to echo Annabelle was saying and relaying comments from people at octa there is definitely some concern around the asymmetric only keys and I know that a lot of my team there would not deploy it if it was asymmetric only would rather see a symmetric option so because of the speed concerns there so just keep in mind that we still actually have a working group of item if the symmetric version as well are so so in that sense we find of course when Annabelle presented her work I asked her whether it would make sense to align that what she presented because it was slightly different to in terms of header fields etc but that may be an option but "
  },
  {
    "startTime": "00:48:25",
    "text": "what I hear from numerous percent sort of presenters on a microphone now is that you want something very specific very specific need and not a generic mechanism and I think is that correct but what you do you want something else but but well I gave the specific example of the spot type applications and but as maybe I couldn\u0027t sort of where Justin came from oftentimes you know a specific point solution can be generalized into something more and so from my perspective I\u0027m trying to make this something that can be a reasonable deployable usable pop option for access and refresh token so we how we came here was um we had a working group item I still have one that is that has a symmetric and an asymmetric variant and then you guys started this new effort because you the argument was the other one is too complicated because it contains the symmetric the asymmetric and refers to some generic HTTP signing which now interestingly is being entertained now which is and now you are saying oh actually we could extend it to something more generic that doesn\u0027t make sense to me right that\u0027s what he just said nothing okay so no I\u0027m not saying it could be extended to something more generic I\u0027m not pushing for it I\u0027m hearing people say it should include a symmetric key option I\u0027m saying that there\u0027s a very serious trade-off with that okay in that this is simple because it relies on public private keys I understand the concerns I don\u0027t know I\u0027m not saying it\u0027s not a done decision but that\u0027s that\u0027s why it\u0027s this way that\u0027s why it can be as simple as just the client presenting this header every time because we\u0027re not negotiating keys that\u0027s why you get a particular security property of not being able to replay that across resource servers because you don\u0027t have to distribute this is not your key and get in the situation where the resource server can then impersonate another one because it has access the symmetric key so that that was sort of driving bit of this there are people that want it to be something different um I you know we\u0027re at a working group we have to work through that but so I\u0027m trying to respond to different comments and different desires for things one of the reasons you know the document you keep talking about has symmetric and asymmetric key options but it\u0027s it\u0027s strictly key distribution it doesn\u0027t do the the actual token presentation and proof of possession part which is right another reason that it\u0027s not not useful yeah well it it had that just in a separate document which this was just in some document if you recall which which I think now before the work we made its way into the at this meeting getting adopting this was and this was what anybody was talking about is that or is it a modified cabbage combined with "
  },
  {
    "startTime": "00:51:26",
    "text": "something something it\u0027s it\u0027s an illusion of that more of that yeah but it but there the idea was to separate out the key distribution from the presentation in two separate documents there was a decision at that time good good approach I don\u0027t know I\u0027ve got another comment from Jabbar again from Philip and he basically is underlining or stressing what Orton said let\u0027s not forget the initial scope urgent need to be solved the sender constrained spi tokens john bradley yubico one of the co-authors so again with scope our initial plan in the working group and discussions work we were going to use token by to center constrained tokens for single page applications some people over here that I\u0027m pointing at may have screwed up that idea what well not Dirk he\u0027s actually on the good side but when and we may eventually get token binding when Microsoft and Google sort things out and we cats and dogs live together happy so until given that that might not happen in the next short number of months we at the OAuth security workshop we said okay what can we do for a single page application since we don\u0027t have token binding in the near future and the answer was okay you could use web crypto and have the browser make a key pair and do a very simple signing operation so this is really only intended to deal with that single page application mechanism so I don\u0027t know whether given that we\u0027re talking about single page applications whether the performance issues are really all that concerning these aren\u0027t high speed you know high volumes clients server clients that are talking to two api\u0027s for other applications that doesn\u0027t hmm make any sense with force for native apps and host based applications they should be using the mutual TLS proof of possession because that does have better scaling options so this isn\u0027t intended to deal with all the native apps all the server based clients this is really intended for that subset of single page applications that need to sender constrain their tokens Justin again so "
  },
  {
    "startTime": "00:54:28",
    "text": "what if this were adopted with the very narrow very specific scope and all of the other fancy bells and whistles go into oauth 3 it\u0027s yeah sure what which fancy bells and whistles the ones that are being suggested or a key negotiations and all and all of this kind of stuff and sort of general proofing mechanisms and things like that while I agree with Annabel that you know if the time skills were better this ought to be using the general purpose HTTP signing mechanism yeah that\u0027s probably going to be a while in cooking but you know because this is a very if this can be a very specific thing then I think that it\u0027s not going to hurt if this exists and other solutions also exist so if there\u0027s a you know a spot for a symmetrical proof of possession or whatever then great you know if there\u0027s something with the next major revision of OAuth it lets you do all kinds of different keys or goes back to the the OAuth key distribution architectures where you know servers are distributing keys and binding them to client credentials and all of that other kind of stuff great I mean you know this existing doesn\u0027t make mutual TLS go away you it\u0027s it\u0027s very worth to to add another thing to the already gigantic menu to let people choose from that\u0027s true and yeah and we are in the we are not done adding to the menu was the was the heckling from the back this is not a value judgment this is a statement if you want the value judgment talk to me after but for for real though this having this be like this does this one thing I think fits and about just having looked at backup of the D pops back if the intention is really that this is specifically driven at at s pas that really needs to be cleared out that really needs to be called out more clearly in the draft because it really isn\u0027t right now you\u0027ve sort of if you read between the lines and knowing that you know that\u0027s what the authors are saying in forums like this then you can kind of see it but without that it\u0027s really not clear separately back to the asymmetric crypto scaling question everybody\u0027s focusing on latency but that\u0027s only one aspect of scaling if you have a service that is taking millions of requests a second that little bit of CPU time adds up and all of a sudden you\u0027re running your service becomes a lot more expensive so yeah that may not you know one one request taking a tiny "
  },
  {
    "startTime": "00:57:29",
    "text": "fraction of a second longer may not you know impact the end users experience but that doesn\u0027t necessarily mean that it\u0027s scalable the other thing to consider is scenarios where you\u0027re making lots of these requests in the course of fulfilling one you want to end user requests so are when you end user operation it\u0027s not necessarily just one hit here it could be multiple make Joan\u0027s Microsoft Mike Jones Microsoft Microsoft internally currently has deployed the old Roth HTTP signing draft that expired two and a half years ago because we need application level signing given the failure of token binding to ubiquitously deploy we would like to use this for all flows for all client types and please let\u0027s not do anything that prevents that from working Dolson um in answering over reflecting on what an apologist said I understand that I know that they CP o cost for a symmetric is I think to others or three orders of magnitude higher I think there are other ways to couple of that then using symmetric crypto we have at least two architectural option and they all document in the SP a BCP one of them is not to use access tokens in the browser and rely on web security mechanisms to protect a the lack to the backend and also in the in the in the in the latter case which is talked about having a lot of requests being executed on the on behalf of the of the user yeah just set up a back-end and and let that back and for all those requests and use a TLS so I think this is a much too narrow focus discussion yet yeah just my father\u0027s Annabel I\u0027m again echoing I think Mike what Mike said just was really a response to that that as a you know service provider we really don\u0027t want to have to operate you know significantly different authorization mechanisms you know across our ecosystem if we can avoid it and you know forcing that on people is not the way to get them to adopt things separately III feel like you\u0027re you\u0027re telling people that they should architect their application such that it "
  },
  {
    "startTime": "01:00:31",
    "text": "fits the model or the constraints of your authorization mechanism which seems wildly backwards to me like people build s pas that do not have backends but need to make lots of requests to to other services that use case exists if you\u0027re not going to support it then that\u0027s fine just acknowledge that this is not going to support that use case but you know we should be intentional about making that decision so Brian can I ask you a question you\u0027ve heard a lot of feedback at the mic ly what are what is the one or two questions you need resolution on from the work nor I I don\u0027t think I can say because there\u0027s a quite a bit of feedback from make it very narrow to make it do all this stuff I want well do beyond there\u0027s a lot of competing interests and desires here so I guess the do you now know why we came up with the more the sort of this broader thing I I think he went in a group at that time I think that\u0027s the problem yeah it was progress this well I mean I guess the first question is do we want to progress it in the group because the you know Torsten just my guess is and that it was popping up in my head a few seconds ago I think we need to have a consensus in the group whether we want to rely on to your last based mechanism for sender constraining because all the discussion now I have feared from contributions from Mike and Annabel to me point in a completely different direction I mean right now we are unable to provide a TLS base and mechanism for sender constraining for all kinds of clients and we drove the conclusion from that we need a stopgap measure for those that cannot really use em TLS which are s pas note the discussion is turning into all we have that mechanism let\u0027s make it a general-purpose magnify all kinds of plans and then I understand the need for symmetric cryptography and so on and so on and so on so from my perspective we don\u0027t have a real consensus around how we do how we want to implement sender constraining no I see it slightly different we have one solution for we have several solution for sender constraint one is token binding one is empty LS and one is mechanism based or the application layer or several mechanisms based on application layer which just haven\u0027t we we like them TLS because that\u0027s why we worked on and published it we are but we know its limitations and we also like talking bad English just sad about its lack of deployment and now we we need to sort of make some progress "
  },
  {
    "startTime": "01:03:33",
    "text": "on the application layer stuff which we failed to make progress on and partially because we can\u0027t agree on exactly on what credential types to support how the details look like what to sign but not a sign and that\u0027s that has been a challenge in the past over years in so here we are yeah I I agree with that um I think I\u0027ve just phrased it differently okay Mike Jones I believe that Microsoft\u0027s viewpoint is M TLS is great in certain constrained environments such as financial api\u0027s but it is virtually under Boleyn general purpose consumer applications therefore we felt get given the existent threats about stealing bearer tokens that we need as an industry to develop an application level proof of possession mechanism that works across the board for access tokens refresh tokens we\u0027re hoping that this will be that um we are running a little bit out of time under China so that because a little bit longer than we were hoping and I think before enable you I\u0027m tossing that was anybody\u0027s um cut the line here so I\u0027m the chairs will work with our esteemed ad to find a path forward on this I\u0027m how to advance this topic because we it feels a little bit stuck on that issue but I\u0027m positive that we find you find something out rather quick so expect a virtual intra meeting yeah give him what we just heard I would say not really yes we think that yeah we talked this side the last coming ed was from my perspective even for our SP a use cases d pop would not work for us we\u0027ll work this out right sorry that you didn\u0027t manage to get any further there must be something magic I\u0027m just like probably that\u0027s really it yeah I didn\u0027t even know passed that point okay sorry about that um we had on yeah Boston Boston okay thank you Brian "
  },
  {
    "startTime": "01:06:35",
    "text": "presenting the teapot work really appreciate that [Laughter] yeah yeah I would like to start with another yeah yeah a small addition to another small addition to another small addition to all its push to authorization yeah alright so basically the problem this the small addition to a small addition of o of once the solve is this that\u0027s the kind of for is Asian requests we are seeing in the wild when you use some of for example open ID connect mechanisms you\u0027re ending up with a really really bulky authorization request URL that sends through the user agent and it poses some challenges first of all is lengthy it has some impact on the latency on the robustness but there\u0027s also no mechanism for integrity and confidentiality protection which might be relevant especially if you pass transaction specific values or constrains regarding the authorization process through that channel we\u0027ve got a solution at least a partial solution that\u0027s the extension to all of that we are gonna extend it\u0027s the judge secured authorization request which I hope will be published soon it provides security for the authorization request by providing a mechanism to sign this the request objects and also has a mechanism to pass a request your eye into the authorization request if you don\u0027t want to pass all the data to the user agent and what we do now we provide a mechanism to upload the payload of authorization request to das and to obtain request your I to then use the draw mechanism request UI to send the data to das so for my perspective that\u0027s just the nets next step to bridge that to bridge that gap and that\u0027s how it\u0027s going to look like so there\u0027s just a small change with a step two so declined first sets up the authorization request in the direct post call to the a s and they asked somewhere stores did this payload and returns a UN to the client and that your and then in turn is used in the front end call to the a s all right so how does it look like on an HTTP level um that\u0027s a traditional OAuth request so it\u0027s a get that sent from the "
  },
  {
    "startTime": "01:09:35",
    "text": "user agent to today arm to the a s authorization endpoint what we do is we defined a new push to authorization endpoint with das and it takes the same parameters in exactly the same encoding and sends that why a post request that\u0027s the modification and what you also see on that request you can easily authenticate the client and draft says use the token or the a s uses the same token endpoint authentication method that\u0027s set up for a declined to authenticate the client for that request which also means you can only refuse to serve that client for example because the client isn\u0027t authorized to access or request a certain scope which adds a lot to the security of the protocol because then in the authorization endpoint you know I have actually authenticated that client before the authorization request hit my authorization endpoint that\u0027s really cool yeah and then the a s returns a request URI and the request your I is not intended to be used as a way to obtain the authorization data by any external system it\u0027s just a reference could have been an opaque identifier I think it\u0027s I would assume XYZ does it with an opaque identifier we just decided to do build on top of jar and that\u0027s why it isn\u0027t URM and that you\u0027re and then is passed in the authorization request and the es is supposed to use that or you are and to look the authorization the request up in a database and then just proceed question now just Richard just for a quick clarification in Xyz so yeah keep it on this slide the main difference between the way that this this works and XYZ is that what you get back in X Y Z is that entire URL and not something that the client composes other why is it is very much the same pattern yeah we stripped it down as far as possible but wanted to be compliant to to the rest of oh of and there\u0027s another option which is to actually send a signed and potentially a cryptic request object why the same channel so instead of using the payload we are familiar way from RC 67 49 use the payload has been defined by drower to send payload to das having the advantage she can do our application level crypto for example to do non-repudiation the result is the same you could request your eye and you send that request your eye to das so those are the two different modes that we expect out the advantages of the solutions are it\u0027s a release of robust solution for sending even larger "
  },
  {
    "startTime": "01:12:36",
    "text": "authorization requests payloads to das which are relevant in all the use cases I am working on currently and I think I described that on Monday and there is also a significant improvement in security for from my perspective relatively less cost of you cost because we\u0027ve got the integrity confidentiality and authenticity protection of TLS you\u0027ve got the client authentication up front of the authorization process which also mean you can authorize decline and Daniel\u0027s FETs feeling is that it\u0027s in resistant accounts against mix-up attacks and that\u0027s from my perspective better than having some systematic analysis of other people so are the analysis is still ongoing but we already really confident about that end early experience the show that\u0027s really easy to use I\u0027m starting with the developers of the a SS because some a s has already have implemented that and they that did really quickly and that also guided a bit just the way we should we wrote a specification and it turned out that the logic that\u0027s being executed at the authorization endpoint and the logics being executed that the token endpoint can be combined in a pipe that\u0027s at least but Filipe for example told us I mean if you have come up with different experiences there\u0027s no let you know now or as you like okay just nurture just add so I have yeah I know we got a we got area I\u0027ve so we did implement this spec as part of athletes next revision and while we weren\u0027t able to completely combined the off endpoint we were able to abstract a lot of the processing and I can I can state that this is pretty easy and sensible to do on an existing established AAS platform okay thanks yeah um Annabel Backman Amazon personal I just want to say I think this is like a no-brainer for the working group to adopt I definitely think we should do this okay we still friends Torsten why not you don\u0027t like my ideas of running SBA\u0027s I can live with that I did want to ask her how your have you thought about how this would mix with the device flow and if there\u0027s an opportunity to align the two of those because yes an excellent question what I just out of the top of my head I fear we are running into XYZ territory and III don\u0027t have concerns going that way but I think you will end up with a more conversational protocol and that\u0027s not the way o of two is designed to work but "
  },
  {
    "startTime": "01:15:36",
    "text": "we should definitely take a look into that and I would also include Seba even if that\u0027s not ITF stuff yeah yeah I haven\u0027t read this too closely but it seems like there might be an easy way to integrate to to get it to play well with device flow but yeah yeah yeah that could easily like blow things up yeah I thought about that also so if you can find ways yeah let\u0027s make it simpler in the end I\u0027ll take a look engineered now because we are running terribly out of time they can leave look Justin just to just to reinforce what Torsen just said when you combine par at the device flows Seba you know the the fappy stuff that predated this Yuma all of those sort of staging intent things into one protocol you kind of do get X Y Z that was the idea they they are not as compatible as they seem on the box unfortunately due to the nature of os conversations okay so as I already mentioned there are implementations out there I I count at five of them so my last question is would the working group consider to adopt that as a working group I document I\u0027m going to ask for hum please hum if you think that we should adopt this document as a starting point for the working group please some if you can please hum if you object to making this a working group item okay and that was clear strong positive response to thank you okay that was the warmup you have [Music] two minutes that reminds me on the first presentation of the charts I\u0027m for introspection responds that are different mode ly so honestly two minutes not really I was part of it okay um all right then I talked about just briefly talk about the problem the proposal and we\u0027ll ask you to add up the draft right so the problem is is about I would say complex authorization processes Tony I try as best as I can complex authorization processes that need more data as you can today pass in a scope so let\u0027s assume you have a payment API you wanna the merchant wants to to send the payment or get some money the question is how does the author how "
  },
  {
    "startTime": "01:18:39",
    "text": "does the resource all know that it a user actually authorized that this merchant is allowed to to get that money and that\u0027s that\u0027s the key question that drives the rich authorization stuff because in the end the authorization server needs all the information to render that user consent right so and that user content contains transaction specific values is rather complex and as context and the short form of that is we have come up with a proposal to allow clients to specify this kind of more complex authorization requirements in a structured way to some we use something that I was initially calling structured scopes but Mike asked us to not use the scope terminology so we came up with the authorization details name so it\u0027s an array you can bump into that JSON objects that are specifically designed for the needs of a certain API that\u0027s why they are typed so the a s can differentiate what type of authorization request object is that can I combine them cannot do not combine them you can combine them you can send them everywhere or you can use a scope yeah it\u0027s in the third revision we\u0027ve got some positive feedback even on the list from people that are new to our community I just put in a citation here from a guy from Mozilla I think it\u0027s he\u0027s on the line as well there are two implementations already existing at all fleet and the prototype at yes comm I would like to consider you to adopt that as a working Go button so who has read the document mentioned Justin and Bryan are co-authors of the document that tells you something right because you may have just written it yeah how many non authors have read it yes three are kind of half and four people in the goal that right at the draft I think we will do a call for adoption on the list and give people a chance to also sort of provide some feedback and so on but I think that\u0027s that\u0027s good good stuff two more from Jabbar who read the document all right so thank you yeah we we will do that um Tony did you capture that yeah "
  },
  {
    "startTime": "01:21:39",
    "text": "okay cool perfect yep yes sorry Travis that we have eight minutes okay well I\u0027ll get started even before the slides came up we\u0027ve been talking in various venues various places about this problem that Torsten just talked about and and I\u0027ve been proposing a different solution to the problem and to make that a little bit more tangible I wrote it down as a specification I\u0027ve been proposing that that that problem can be solved using the claims request parameter from open ID but the pushback that I get is that well that\u0027s bound to open ID and a lot of people want to do API security only using OAuth and so in this draft the what I\u0027ve done is I\u0027ve lifted that out so here you can find the link to the draft lifted that out of open ID and made it usable for API access using just ooofff explained how we can use this in non OAuth or non open ID Connect flows i\u0027ve stipulated how the the input can work not only on browser-based flows like authorization and implicit but also the output which is something that\u0027s missing from open ID the draft has additional examples that aren\u0027t found in open ID some defining some clarifying terms and then the entire specification or the draft specification is compatible with open ID erinite i see you there but i\u0027ve got 19 slides in eight minutes it could is it okay if we wait a little bit because I might even address your point so just to know what what we\u0027re talking about if you\u0027ve ever seen an authorization request like this where we have the claims request parameter which is even liked Orson\u0027s example he just put up this is what we\u0027re talking about so it\u0027s basically a query asking for certain claims to be asserted by the AAS so the terms that I mentioned we\u0027re using claims claim name claim value from the job specification essential form open ID but rewritten so that it\u0027s not bound to the end user and some others that are defined in the the draft importantly claim seeing claims request object these are things that exist abstractly and open ID but aren\u0027t aren\u0027t given a specific name so a claim sink what we mean by this is the the part of the request that\u0027s that the client is saying this is where I want the claims to be asserted I want them to be included for example in an access token a claim might say I don\u0027t know I want them to be asserted but I don\u0027t know where they\u0027re gonna go so it might just say the claim sink is question mark or might say I want them in every every destination so I\u0027ll use I\u0027ll use star it might also do ID token or user info if the AAS is also an Opie so requesting "
  },
  {
    "startTime": "01:24:40",
    "text": "claims so the object here I\u0027ve been in a name a claim scene query object and a claims value query object but basically what this is is a way of querying for certain claims to be asserted by the the authorization server so we\u0027re asking that claims be put in a certain sink in a certain destination the access token ID token and that touken specific to a certain resource server and then we can also have preferential values to be a circuit but it\u0027s really really important to keep in mind that this is a query this isn\u0027t a demand from the client to say you must assert this value so similar to like what poor Stan was saying there you know I want this transaction I want this information this account here you can see another way of doing that I can say okay I want a value of the count 1 2 3 or otherwise account 4 5 6 this is essential to me for a smooth operation of a ization at the API and here I have a payment ID with a value of a certain payment number so another thing is essential claims so an essential claims like I just said is a claim that is required or essential for the smooth operation of a task by the resource owner at a resource server it doesn\u0027t mean that it\u0027s a required value so the authorization server should not respond with an error if the essential claim isn\u0027t asserted with those values or if the claim isn\u0027t available at all for that resource owner and and essential claims are defined by open ID connect but there is nothing in open in D Connect that says anything about it like it\u0027s got to be there it\u0027s a required claim so the draft could create something called a critical claim using something similar to JSON web tokens where it has a crit member in in the JSON object saying that any Jason pointer or it\u0027s a it\u0027s an array of JSON pointers that point into some part of the request to say that this is critical like if the authorization server can\u0027t assert this claim or claim with this preferred value then the authorization server has to respond with an error so this this helps the the client to say ok I\u0027ve got to have this payment ID to be authorized and if not then I need an error back Jason pointer also defines how to do the escaping of the slashes which you can see an example of in the draft I mentioned these special claim sinks this this third one here is the binding then to the resource indicator where the claim scene could be a URI or URL of the protected resource so that you could get claim scope to Pacific resource servers if the client has that knowledge of knowing that certain claims are destined for a certain API the draft binds this to a code blown implicit blow which looked very much like what\u0027s in open ID "
  },
  {
    "startTime": "01:27:40",
    "text": "Connect but also the ROP C and the client credential flow it also talks about token refresh took an introspection and I wanted to get to token exchange but I ran out of time so the authorization flow and as I mentioned looks pretty much the same as open ID and are the difference though is this bullet here that the response includes the space operated list of granted claim names so similar to the way that that scopes are returned on the token endpoints so that the client knows okay you asked for this but you you got this so if the client asks I want these claims but it doesn\u0027t get all those claims asserted then it will be given those claim names that actually were asserted are OPC and CC can also specify I want to have certain claims to be asserted some of them can be critical as I\u0027m essential so it ends up working similar to the scope request and in all four of those flows it defines some errors oops sorry had to find some errors and it does so in a way that maintains compatibility Open ID Connect but it\u0027s very open ID connect does isn\u0027t very rich in its error codes for that so it defines some additional ones that can be used refresh I know I\u0027m going on time but I\u0027ll do my best here quickly you can send the claims request parameter to do down scoping so to say just like you can with sending the scope request parameter to down scope if you\u0027ve done that and then you refresh again you can up scope back to your original grant this is difficult to implement I can speak from experience using the Scopes and claims together makes this hard and policy changes make this hard but those two parts are left out of the specification so it doesn\u0027t talk at all about using scopes and claims together like open ID does and it also doesn\u0027t go into handling policy configuration changes so reef is actually pretty simple as far as the spec is concerned token introspection when you introspect a token respond with a space separated list of claim names that were authorized so that the API can see the extent of the the scope of the token as far as the claims go I know I know I know so this oh yeah so it\u0027s in there the important part is that critical claims be supported because you might be talking to an Opie and open ID Connect open provider that doesn\u0027t support this so this is helpful to know that okay they\u0027re implementing the OB is also supporting this draft or the AES is only supporting this draft so I think that that\u0027s the point on the slide to be aware of open questions I think the essential part for movin IV Connect is kind of like another it\u0027s confusing and oftentimes it\u0027s like why do we need to do this it it\u0027s it doesn\u0027t mmm so I think it should be dropped from the draft but I wanted to have some broader input on that maybe some restructuring of the document to avoid redundancy with the different flows how do you integrate it with the resource indicators I\u0027d like "
  },
  {
    "startTime": "01:30:41",
    "text": "some suggestions on that and I\u0027d also like to talk about the integration with token exchange in the next version of the draft oh right the token exchange the resource indicator tie in and of course the the leftover considerations haven\u0027t been created and also a way of registering clients to say that they want access to certain claims so full disclosure curity we\u0027ve implemented all of this we had to do most of it because it\u0027s in open ID connect but the other aspects like the the output of claim names and things like that we have implemented and we have no patents on any of these things so obviously be out of time we\u0027re going to have this virtually into a meeting obviously we need that not only for the other topic but also for these type of things so at this point in time I think the only question I can ask is who has read the document 3 I think we need more people to read the document um so I think it relates nicely to the purse nation doesn\u0027t give earlier on do you want to say a famous last what errand or do you want to deep dive into a technical discussion about this I want to do the opposite II deep dive which is back up to the high-level view of this high-level all of this and I\u0027m sorry for being so blunt we\u0027re out of time I think this is actually the completely wrong approach bringing things from open to connect into this because ID tokens are meant to be consumed by clients and understood by them access tokens are explicitly not and this feels like bringing knowledge about authorization servers and access tokens into the client in a way that the Torrens proposal is more about expressing the goals the client is trying to achieve rather than how it expects the a/s to achieve them I feel like that\u0027s the line that this is crossing and I don\u0027t think it\u0027s appropriate yeah strongly disagree we we can discuss that\u0027s good we always have different perspectives in the group so it\u0027s kind of normal um and we\u0027re going to have a discussion on this and the story will continue when we have our meeting I will send out an a doodle poll for dates in December and and of course it\u0027s December I know December stuff leading into its January to see what works for you guys and we need to look at more time obviously to cover these topics that we left out Aaron had one presentation we didn\u0027t got to so that will be covered too and there are few documents still in the group which hadn\u0027t been talked about this meeting because the also weren\u0027t here Victoria for example his document and so on and so on I don\u0027t want to go through those okay quick suggestion maybe we should have three sessions in Vancouver three sessions is not an option two sessions is all the working group sessions um our workload varies sometimes a little bit when we make the "
  },
  {
    "startTime": "01:33:42",
    "text": "request then sometimes there\u0027s barely anything and then you get totally hyped up on something sorry you it\u0027s not that it\u0027s not that you can\u0027t ask for three by policy working groups get two slots max so you can\u0027t ask for three so the that my cutter guidances if you feel like you need three you need to be having more virtual neurons god I should have said I should have said that earlier yeah working groups can\u0027t get three slots you "
  }
]