[
  {
    "startTime": "00:01:26",
    "text": "yes you can [Applause] what I don\u0027t think mark would you like to verify in the meeting also I think it\u0027s totally up to you did you did you want to run off with your computer is it yeah I mentioned that my keyboard doesn\u0027t work myspace board died the other day it works I sent up the slam out so if you have an epic repair kit in there I would appreciate yeah [Laughter] "
  },
  {
    "startTime": "00:04:42",
    "text": "though we\u0027re four minutes yes please yeah hi everybody we\u0027re gonna get started in a moment if folks on this side of the room could consider moving to this side of the room we might have a more intimate discussion hello test test test [Music] alright let\u0027s get started we\u0027re a little bit over time sorry about that welcome to HTV Biss in prague this is our first meeting of two we also have another meeting on Thursday slide so here\u0027s the note well please do read it this is Monday so it\u0027s a good time to reacquaint yourself with a note well check out the BCPs at the bottom alright next slide alright so we know well blue sheets are going around right now please make sure you do sign one of those and we\u0027ll need a minute taker and jabber scribe do we have anyone for that yet don\u0027t think so could we get someone to volunteer to do minutes in the ether pad and so by the way we will be doing the core document issues today so if that feels like something you want to take notes on please volunteer going once no not yet we can\u0027t do it yet oh hi hi "
  },
  {
    "startTime": "00:07:43",
    "text": "Marie hello mark do you have your computer with you yeah would you like to take minutes yeah just hook me to make sure the major things get in because I will my attention may drift a bit but yes I\u0027m happy to write things down for you Marie sounds pretty jet-lagged who else is here I\u0027ll coach the new guy okay great thank you and poke him if he falls asleep all right and anyone in jabber yep great thank you one other announcement that we do have is that we are going to have a change of responsible aid for the group so Alexi has been doing a fantastic job of aiding us so far so thank you for your service as ad and we will be switching over to have Barry as our ad starting on Wednesday I think so Thank You Alexa and that actually concludes the second time that Alexi spend the ad for this working group and it will now commence the second time that Barry will be the ad for this working group so we\u0027ll NEET we need Lisa to come back to get the trifecta alright so just quickly to go through our agenda today we are going through HTTP core and we\u0027re gonna have some updates from the editors and then spend the remainder of the time going over the issues that are labeled as discuss there\u0027s a preview of Thursday we\u0027re going to go through all of the extensions and talk about quick and HTTP 3 as well as proposed and related work and with that I think we should get started so Julien did you update your presentation last week that\u0027s true oh yeah thank you okay you tell I was probably flying at the time so right would you like to come up and give your presentation Julien [Music] "
  },
  {
    "startTime": "00:10:53",
    "text": "let\u0027s large rock and spacebar sorry one slide back okay we submitted new drafts before this meeting that\u0027s our link there with stiffs and I don\u0027t think do we need to review anything with it fathers describes no okay next slide a bit of statistics we\u0027ve got still a few errata that we haven\u0027t dealt with some will be rejected during this session I hope by Aleksey so I\u0027m I\u0027m keeping track of the HTTP errata and map them to github issues and so that we always have a complete picture of where we are with the errata there\u0027s a summary page linked from that slide but it\u0027s also on the front page on github x1 so half of the issues that have been raised against the old specs have been has been closed a few more today of the 74 that were open last week 50 our editorials so I guess some 20 plus a few more non editorial design issues we have labeled a few of those with with a discussed label because we want to look at today and that\u0027s what we are going to do now I think there are no more slides thank you shorten to the points okay no Oh wrong side sorry sorry it\u0027s hard to type of the bandit that\u0027s definitely not the right website okay I could have I could have alright "
  },
  {
    "startTime": "00:13:54",
    "text": "so we\u0027ll start with the issues we\u0027ve marked as discuss and go from there I think let\u0027s see if we have time for other issues so the first one here is issue 203 expect should be a list header we noticed in the discussion of another issue which we might touch later on that in the HTTP excuse me this effort way back ten years ago I guess we made a decision to lock down the expect header to just one value of 100 continue we said this mechanism is not useful for new extensions we don\u0027t intend for new extensions to be identified or defined and so we\u0027re gonna lock the the syntax of this expect header to just one value the problem with that is that it was originally a list header and it is now no longer a list header which creates some interesting problems in error handling and in how the headers defined because we\u0027ve changed it\u0027s a V\u0026F retrospectively and so we discussed this briefly we have netters meeting just before the meeting here and we discussed returning it\u0027s a B and F to to be a list header so that it behaves in reasonable ways when when more than one value is encountered that will probably entail defining some error handling for a couple of different situations and and we we almost thought that it was an editorial issue but we wanted to flatten for the working group to see if anybody had any concerns about doing that if you have such concerns now would be a good time to talk about them does everyone understand the issue okay I\u0027m very tempted to ask if anyone cares about the issue but I was so we\u0027ll go ahead and incorporate what we think is a good resolution for that and if people have an issue with that please bring it up you can thank you that would be lovely next up is issue 202 we had a request you know we went in HK Phoebus we talked a little more precisely about how some requests methods syntactically can have a request body because we really want to keep message parsing generic we don\u0027t want to have to have a message parser understand the specific semantics of an HTTP method to be able to par as a message because it\u0027s not reliant upon the method and so we tightened up language about that to make it clear that you know get and delete syntactically can\u0027t have a body it\u0027s just they don\u0027t mean anything and we had some some an issue raised here that we weren\u0027t clear enough in that in that people think that because we say a payload within a delete request message has no defined semantics and it might cause some existing implementations to reject the request some people interpret "
  },
  {
    "startTime": "00:16:55",
    "text": "that as I can define the semantics myself and so we have people continuing to use requests bodies on getting delayed in there\u0027s some controversy about whether that\u0027s a good or bad or allowed or disallowed thing an HTTP because effectively we although we clarified you know the difference between a body on a message at a generic level and a body on a message for particular methods in terms of whether they have semantics or not we didn\u0027t clarify who\u0027s allowed to make the decision of when a body is defined for a method can if we don\u0027t define semantics of a body forget for example can someone come along and say well for my resources yes yet has meaning I get body has meaning and so we discussed this before and and the conclusion that Roy and Julian I came to which we wanted to bring to the group and start a discussion here was it seems that that we probably forget can strengthen that with languages along the lines of something like senders should not generate requests with message bodies to make that pretty clear what what that means we want to reinforce that\u0027s not coupled with the parsing that a generic parser doesn\u0027t have to understand the message body but but strengthen this notion that if you try and create a get with a message body you\u0027re gonna have some bad interoperability of problems because proxies and CD ends and load balancers and generic servers and fetch and web application firewalls and everyone else will very likely blow up if you try and put a message button again and and then the other thing we discussed was for delete some folks have use cases for putting message buddies on delete to to modify the semantics of that delete I think Julian was saying that some people want to do things like say that when you delete this still keep it in version control for example or so keep it a history of some sort or or if you have other features around what is effectively a file system there you might want to modify those semantics and the question there is you know is is a message body the right way to convey those semantics or should they be message editors and what advice do we want to give us a working group in those situations and it seemed to us that that we need to have a conversation as a working group about what best practice is there before we can come to a decision about whether or not we want to make recommendations about bodies on delete does that seem reasonable to folks as a direction to go on both of those or any other comments form an orderly line okay I\u0027ve got a thumbs up from Mike I got a thumbs up from Victor hey and from Allan okay we\u0027re now gonna go to a thumbs up base communication protocol okay we have multiple thumbs up go alright I think the practical implication here is that we\u0027ll go ahead and do that forget and we\u0027ll probably open a new issue to start discussing what buddies on deletes might mean and "
  },
  {
    "startTime": "00:19:55",
    "text": "whether that\u0027s actually a good idea or not and that might be a much more involved discussion Patrick are you going to talk at the mic oh well you there\u0027s a mic right here man it\u0027s all good no you\u0027re not there we\u0027re prepped for everyone else yeah I was gonna say I think the same reasons that bias get it which are essentially you know you\u0027re not gonna get end and interrupt right if you just a little closer I think the same reasons that bias the decision you\u0027ve talked about forget which is you\u0027re not going to get sort of end n Interop around that message body getting through apply just as strongly to delete so I would encourage the authors to sort of start from that position on delete as well instead of with a blank slate personally I agree with you Patrick but I don\u0027t necessarily represent all the editors in that thank you yeah fight fight fight Oh Victor well what what joins getting I think oh I just wanted to say as a as an author of HTTP reverse proxy there are application authors who really believe that can get having a body is a good idea and they ruin quite a bit of my mornings so I would appreciate this to be clarified strongly Thank You Julian Koshka so when we talked about it earlier today I made the point that we probably shouldn\u0027t have too many categories of payloads ignored payload discourage payloads embraced and so on and I think delete is very similar to options not very similar to get and that I that\u0027s why I think that the answer for the lead is different then forget it that\u0027s a good point actually so um the the other model we were looking at if you look at the language around options if I can get it up here in readable form is that readable for folks let\u0027s see where is it a client that generates an options request containing a payload body must send a valid content content type header field describing the representation media type although this specification does not define any use for such payload future extensions HTTP might use the options body to make more detailed queries about the target resource responses to the options method or on cashable you know really I think we might even want to modify the language of there a little bit because there\u0027s an implication there that only extensions to HTTP you know someone might read that to say that only the HTTP working group can do that which is not quite true anybody can mint a media-type so anybody "
  },
  {
    "startTime": "00:22:55",
    "text": "can and and I was I was concerned that that we still might be in the same situation where we have application firewalls and other folks wouldn\u0027t take a payload on on a delete potentially and and Julian did point out that most web application firewalls don\u0027t like delete . so III think that\u0027s it\u0027s it\u0027s reasonable to think about using this kind of language for delete personally but I\u0027d like to get a little more data first any other comment Julian can yeah if you could open that just a yeah that would be nice you mean you probably editorial I\u0027d say next up quicken HTTP number 194 we\u0027re gonna discuss later I think Mike Bishop has a presentation for together for this Thanks okay sorry Thursday yes that\u0027s on Thursday sorry yeah next up 165 updating stored headers so HTTP caching requires stored headers to be updated on a 3 or 4 or ahead response but we didn\u0027t we neglected to do a bunch of stuff we didn\u0027t specify what to do about HTTP one connection related headers you know conceptually those headers are kind of removed you know before they\u0027re put into the cache or forwarded but we don\u0027t actually specify that really clearly anywhere and then we noted that other browsers amid other headers such as content dash star next WebKit dash star headers Apache has a whitelist of headers that it uses when it\u0027s updating there\u0027s a bug I raise them to pat you awhile back for that I think that\u0027s one it\u0027s with them and intermediaries are also reluctant to update headers for performance reasons because you have to rewrite an on disk and and because headers are potentially unbounded in size that\u0027s difficult to do depending on your architecture as an intermediary as a as a cache and so this issue is is basically what do we do about all of this if we go down aways there\u0027s a discussion about individual ones I went yeah those chairs are really interesting aren\u0027t they where is it there we go I created a test suite that does this and some other stuff and yeah that\u0027s an eye chart sorry it does some "
  },
  {
    "startTime": "00:26:00",
    "text": "interesting stuff here if you start with a lot of green and then we quickly have implementations that don\u0027t do any header updating for performance reasons and then we have implementations that make some decisions so like the assertions that all browsers act the same didn\u0027t turn out to be true so content food for example is updated in two browsers but not to other browsers an X content foo and so forth and so on but then the browser\u0027s all do the same thing for this block of headers here for content location content md5 and content type and then we go back to to varied behaviors for other things like X frame options and X X X X X X SS protection who came up with that and then there\u0027s some weirdness around cache control and public key pins and a few other things then we get a cookies which cookies are special in so many ways so we gathered some data and then I believe Geoffrey did oh no Geoffrey did a PR where was there we are Geoffrey did a PR it\u0027s Geoffrey here hi and so this PR I\u0027m gonna have to make it smaller there we go adds a section and this was discussed in the issue as well talking about storing response header fields so saying that when a cache stores a response it needs to prune some header fields and that\u0027s the hop-by-hop header fields which are listed in the connection header and we actually had a discussion just earlier about whether we need to have a fixed list again of those are not because then practically most implementations have a fixed list as well even if it\u0027s not the connection header though still prune it for things like transfer coding and stuff like that in connection and header fields listed the no cache response directive in the cache control header field which is according to my testing so hopeful but but anyway that\u0027s a separate issue I\u0027m actually think we have an open issue open for that and then a list of header fields here and to do that the above list is not final and then there\u0027s another section that\u0027s added which is header fields that aren\u0027t freshened up on a 304 so ones that or actually I think ahead as well correct that when you fresh and headers on disk or in memory that you don\u0027t include these headers and that\u0027s common coding content length content location content md5 range type e tag proxy auth te frame options exit press protection and the X content - WebKit headers and so I\u0027d like to have a discussion about I think this general personally I think this general approach is is about the right one with some tweaks I think the big question is what are the right headers to put on this list and I think I said in the ticket "
  },
  {
    "startTime": "00:29:02",
    "text": "some of these are our slam dunks you know connection keep alive proxy off stuff like that where it is obviously tied to connection context that makes no sense to persist this stuff set-cookie set-cookie - are interesting because in my testing people do actually store those on disk whereas that one that\u0027s under other I think so yeah they store cookies except for a couple of exceptions which is you know always gonna be the case so I want to understand more why those are being put there and and of course things like public key pins in SDS the overriding concern for me being here that if we have some special headers that aren\u0027t based upon the connection context there may be more special headers that people especially browsers when I add in the future and we don\u0027t have a mechanism to updates all the proxies in the world simultaneously so I\u0027d really like to understand why some of these headers are on this list and in the browser header fields that aren\u0027t fresh and once again like I can kind of understand why content length is there and content md5 there\u0027s not even a there but for some caches content type if you have a content provider and they put the wrong content type on a response and then they correct it you know or other metadata they correct it in their server configuration and the the CDN or the reverse proxy wherever else is a downstream cache doesn\u0027t do that update then that\u0027s gets stuck in their cache and that\u0027s not a great situation so I\u0027d like to understand what the reason is behind some of those as well as well as the X content and X WebKit which is we saw are not consistently implemented across browsers Mike Bishop Akamai but speaking from my experience making this list at Microsoft yeah we made the decision to exclude basically anything that dealt with content interpretation on the logic that you are caching you\u0027re pulling from cache because it hasn\u0027t changed and if it hasn\u0027t changed that means that nothing about how you interpret that content should be different if you want to change give me the same body but tell me it\u0027s now a different content encoding or a different content type I\u0027m going to interpret that differently and get a different output than I previously would have that\u0027s a different response that should have a different attack Jeffrey this is Jeffrey askin I want to say that I made these lists so that we would have the structure to put to discuss things in them I am not prepared to defend any member of the list okay I wen overall "
  },
  {
    "startTime": "00:32:03",
    "text": "concern here is is that we have different components that are behaving in different ways pretty radically if you combine the Apache bug with the fact that some CD ends don\u0027t and reverse proxies don\u0027t update headers on disk and the browser behaviors were they omit some headers as if I\u0027m a Content person and I update something on my origin server and it doesn\u0027t change in all these caches for a variety of reasons that doesn\u0027t seem like a great experience for anybody so we should we should do better but that\u0027s my overriding concern here yeah so so Martin Thompson if you are a Content person and you change some of these things and you know that they\u0027re not going to change as a result of if you\u0027re just sending a three or four response then don\u0027t send a three or four response but you do need to know and I agree that it\u0027s worth having some rules written down here I\u0027d like to understand what the principles are behind the selection here this looks like a random grab bag of things and you can reason about each one individually and say okay well content length maybe that\u0027s being used for framing of the response and therefore we might want to be a little careful with that one and just ignore it but etag I mean yeah is it possible to produce another retag that that is valid for the same content and I don\u0027t know how to reason about that one yeah and so is this stuff about the resource or is it stuff about the request or what have you and so if you go back to the previous list these are these are things that don\u0027t hit the disk those all appear to be these are things about the connection or things about the request context that don\u0027t really relate to the to the the actual representation that we\u0027re talking about or anything that might want to be persisted if you took talk about that being your principal then I think we could probably get behind something along those lines but I don\u0027t know what do you do for some of these other things I mean I mean in the case of things like cookie it\u0027s that cookie you know the what I have always understood is is that if you don\u0027t want your cookie cached you don\u0027t make the response cacheable and if you do want your cookie cache and replayed other people or you know reuse then you do and and the weird thing is that\u0027s what everybody\u0027s implemented right so but but there\u0027s a common conception a lot of people have the cookies aren\u0027t cached automatically and that turns out not to be true that\u0027s not true and the web still works so you know what that merely suggested they might be the cookie might still be on this list but you say that some of the things on this list might still be cached by by intermediaries and therefore if you don\u0027t want to be it persisted on disk you need to use know the cache control of the appropriate sort what and I can kind of see that for set cookie because it\u0027s so intrinsically in the the architecture of what we\u0027re "
  },
  {
    "startTime": "00:35:03",
    "text": "doing what concerns me on this list more is something like clear site data which is very new and and we may have another new one like that in two or three months or you know I mean my quest produces a lot of these specs so do we add more stuff to that list over time or do we just tell people if you put clear dead any response don\u0027t make it cacheable it seems pretty reasonable to me so that speaks to a different approach entirely then which is to say that those things that are on this list don\u0027t necessarily get the special treatment but instead that if you are providing one of these things that\u0027s on this list expected to be cashed if you don\u0027t want it to be cashed therefore do the do the following thing well there\u0027s some things on this list that do need special treatment like a proxy authentication right I think connection yeah yeah if you want to draw the line there I think connection is pretty clear yeah yep connection is special and and I just in terms of where some of these other things came from as far as my research took me it looks like somebody put this stuff things like X content and even the contents and the content - stuff in - I think Mozilla in the early 2000s and I think patrick said that the actual history was lost in the sands of subversion somewhere and that it taken an enormous effort actually dig it out but and it looks like other implementations have to a large degree cargo cult it from that and I think I strongly suspect that the original reason that a lot of these were put in was because of a miss reading of the language in 2616 around entities that we eventually identity headers that we eventually removed because we realized it didn\u0027t make any sense but of course that was done before we did 2020 77230 so these 3 20 20 to 30 so yeah if people if we can come up with a and I like what you said before if we can come up with reasonable principles for why things are on this list that\u0027s great but I don\u0027t want to just put them on the list because we\u0027re not sure why they shouldn\u0027t be on the list you know this is Jeffrey asking again this second list is all things that the the cache may fail to cache it\u0027s not a requirement not to cache and so I was super inclusive here if I if I knew of a client that didn\u0027t catch them and this this list may just be a copy of what Chrome doesn\u0027t in in practice doesn\u0027t cache I included it there there was no thought behind it I\u0027m inclined to take the ones where all the proxy s are all the caches or sorry all the browsers act the same way a lot more seriously but the assertion that you know if you cache this header if you "
  },
  {
    "startTime": "00:38:03",
    "text": "don\u0027t do that it\u0027ll break something it doesn\u0027t really wash with me if there are a couple of browsers out there working fine in their cache yes so this this list is is to allow the existing implementation variability it was to to describe reality not to say anything normative okay and it\u0027s fine with me if the room decides to say something more normative that\u0027s just why they\u0027re here okay can we get the browsers to align their behaviors I understand they\u0027re really keen on that it\u0027s totally plausible yeah okay and this this is the mechanism to do it just okay yeah it\u0027s something maybe I should talk a bit more and on the issue and maybe in the hallway and figure out a way to chop this up and attack you know the categorize these and figure out where we need to focus more yes okay cool Thanks one last thing by including this list in there you do have normative force and their normative forces on the generator of the response and that is to say that they have to generate a complete response and can\u0027t do something like a 304 if they want to update this information thanks Marie if it\u0027s giving Murray a week so I would be a little less than than promiscuous in this case and and and like I said principles I want to end up one just actually dig down a little bit on something you said earlier which is the content producer if they change one of these things it\u0027s not the same response and they shouldn\u0027t generate a three or four the problem is their implementation does it for them they don\u0027t have control over that right and so their implementation has to be aware of that needs to right yeah and that\u0027s that\u0027s challenging the problem here is is that no matter what we do some implementation behaviors are going to have to change and implementers don\u0027t like changing behaviors for lots of good reasons right and so yeah and so whatever decision you make has to be pretty firmly grounded in something and I don\u0027t know what this list is granted and I think I can see where some of the formalist get is grounded but this one is a little hairier and I think I prefer to simply have well clients I don\u0027t want to exclusively limit this to browsers but clients agree on on what it is that they\u0027re not kind of update technically its cache of specials can be anywhere right they\u0027re not associated with a client or a server well sure but yes it\u0027s a Cassius Cassius yeah okay there we go that was status codes and caching next up is a fun one it\u0027s head of terminology a number 111 and we said that last time we didn\u0027t want to bike shed this in a big room with a lot of people because that would be a complete waste of time so he bike shed it in a much smaller room did me oh yeah no that\u0027s this much I like speaking nevermind okay updating "
  },
  {
    "startTime": "00:41:03",
    "text": "sore hitters serializing ahead of line so honest as in web platform tests we discovered the browser serialize request header lines differently with Chrome not serializing the space after the colon if the value is empty presumably this only affects HTTP one I\u0027m not sure how it relates to HP core I think it\u0027s worth documenting otherwise he\u0027s looking at trying to do this in the fetch but they\u0027ve tried to stay clear of requiring particularly things there and so I think I made a suggestion down here let\u0027s say keep on going Roy okay that was yours okay so I think that the proposal is - I thought I had a proposal in this one this one so he wants he wants us basically to say that when you see realized an HTTP header line and they had has multiple value and you combine two header field sorry that you combine them with a comma and then a space I believe that\u0027s my no he\u0027s actually referring to this this Roy fielding he\u0027s referring to the space after the colon for the field name so oh that name a hole in space and who wants that to be a specific serialization for browsers in particular and as near as I can tell the only response we can have to that is what I put at the bottom yeah as my common it is we don\u0027t have a common serialization format for HTTP messages it kind of defeats the purpose of having this loosey-goosey syntax anyways and we can\u0027t really do this through what what working group doesn\u0027t say okay you for developers are going to all agree that\u0027s a gay sorry we\u0027ve got 5,000 developers and none of them agree on anything so so I mean what we have in the draft right now is this is what the recommended serialization is that recommend the the noah base before the colon in a single space after the colon and as far as i know every single producer produces that unless they\u0027re trying to deliberately attack a service it seems to be enough so I don\u0027t see any further purpose I know now what I was I was thinking there\u0027s another issue we have which is about the comma and I have different feelings about but I think I agree with you here I just don\u0027t see enough of an issue here to bother I mean I guess the only other thing is is "
  },
  {
    "startTime": "00:44:04",
    "text": "it he\u0027s not asking for us to add a lot of text but I\u0027m not seeing a particularly large amount of value and anybody else have any thoughts about him Martin you\u0027re looking very no not caring okay okay all right well I think then the the notion does anyone have a problem with closing this issue with no action in the room all right well take that the list but that sounds like the way forward if no one can mustard if on I can\u0027t convince us to care about it then that\u0027s what we\u0027ll do this is a fun one quoted cache-control directives number one twenty eight so in my testing I was checking to see whether cache-control max age equals quoted in thirty six hundred is is handled correctly by caches and I can show you the results it\u0027s depressing of all of these caches the only ones who actually handle quota cache control are Safari and Apache traffic server life congratulations and so the question at hand then I don\u0027t know how to give her this window now is you know it\u0027s not interoperable should we change the spec to reflect that and I noted later on in HDTV Biss where is my cursor there it is we I thought we decided to make this should not generate must accept we actually did something a little more subtle I think we made it should not generate to accept was that where we have them up Julian and so the question is should we changed the requirement levels here and we discuss this as the editors earlier on and we didn\u0027t come to any conclusion at least not until I went out to get some water did you come to any conclusion after I went to get some water No so the actual spec text heater is already a little bit confusing oh come on so we we first say here they have an optional argument that can be used both token and quoted string syntax for the directives defined below that define arguments recipients ought to accept both forms RFC 6119 I believe even if "
  },
  {
    "startTime": "00:47:04",
    "text": "one is documented to be preferred for any directive not defined this specification recipient must accept both forms and then for max age we say this directive uses the token from the Arman syntax see eg max age equals 5 not max age was quoted 5 a sender should not generate the quoted string form so I guess the question is considering the incredibly low level of interoperability for quoted string forms here is should not adequate can we communicate this any clearer or not I don\u0027t have incredibly strong feelings about this I would like to see stronger Interop but you know Julie the one thing that we found while you were away is that at least for one test case where you said that HTTP the failures process that it can\u0027t possibly fail so we need to investigate why you have a test fail of that yes and maybe if resulted in the test sheet is wrong for HTTP D it\u0027s also wrong for something else so we need to find out what\u0027s wrong here that\u0027s I think what we need to do next yes you say it could possibly fail it\u0027s just not failing for the right reason [Laughter] and to continue on that that\u0027s exactly the thing that we\u0027re investigating if what we are trying to understand is are there powers that are written in the same way that still do not accept that so is this a conscious decision by a programmer to reject that value and if if so why or is this something else that\u0027s what we need to find out excuse me all right so I think we just need to continue taking away what\u0027s going on there um destroy again if possible is if we go through these issues if you can identify something that needs to be attributed or assigned to an editor please do so now because I will forget this tomorrow I mean so Patrick is recording kind of what we talked about in the actual issue that\u0027s great yeah and I think in this case we need to do some testing and refinement the tests you know for me it\u0027s it\u0027s just if we can give the clearest possible guidance to people using the web from an interoperability standpoint and I feel like we fail well sometimes what we provide is so abstract or so nuanced that it goes over people\u0027s heads as we saw with the get body discussion elsewhere I just want to try to clarify that that\u0027s that\u0027s that\u0027s why I\u0027m raising this kind of issue that takes us to 120 status codes in caching 72 34 "
  },
  {
    "startTime": "00:50:06",
    "text": "says that response can\u0027t be stored if the cache doesn\u0027t understand its status code that seemed odd to me because at least for part of the life that spec one of the principles we had was that you can look at a a response and not have to understand that status code and still how to cash it so the cache control directives define the caching semantics of a response in combination with the requests and lots of other context of course and we talked about cashable by default a little bit and so that you have that I then dug up the thread put in the best discussions that led to this which we can actually link three to through the wonders of the web and we decided to tie the cache ability of a response to understanding its cache to its status code so that we didn\u0027t have to go and figure it out for each individual status code I guess that\u0027s what it says here and and as I say here you know the problem is is that if I want to deploy a new status code then caches have to be updated to understand that status code before they can cache it I can\u0027t just say okay here\u0027s that is code for 49 or whatever and it\u0027ll work automatically with the reverse proxies and ctn\u0027s and browser caches and be stored properly which seems like a nice property if we plan on introducing new status codes ROI notes I think that that we don\u0027t you know he doesn\u0027t have a problem discouraging the definition of new status codes it is a constrained space so maybe it\u0027s okay that rolling out new status codes is a little bit slower because they don\u0027t initially get cached and so we talked about this in Bangkok and then I\u0027ve remembered that there was another part of 72 34 that says no to all status codes can be cached if the response and current has explicit freshness information so we actually conflict with ourselves now which is not great and then I talked a little bit more about what I just said which is introducing new status codes I think Roy one of the main points for you was that if we allow any status code with caching metadata it be to be cached that implies that we can\u0027t introduce new special status codes like 206 we are or something that some like 206 were the status code is saying like say we just a new status code to handle the specific 304 header fields that wouldn\u0027t normally be updated but in this case we want them to be especially handle easy yeah we take that yeah I don\u0027t think any of that\u0027s likely but yeah that\u0027s a technical distinction my concern about the change here really is more of what "
  },
  {
    "startTime": "00:53:06",
    "text": "are we trying to fix in the sense that all we are we actually what condition is so important that the cash be able to cash a status code that it\u0027s never seen before I mean caches are there for a reason they\u0027re typically to improve performance why do we need improve - to improve performance for this specific type of response given that we\u0027ve never seen it before so to the first point about - SX I sketched out here that you could define new extensions to allow special status codes to be defined and be exempted so that\u0027s you know it\u0027s it\u0027s it\u0027s ugly but it\u0027s possible so that I don\u0027t think that takes it off the table in terms of why do you need to cache it I don\u0027t know I\u0027m a caching guy I like caching you know my company caches I let play with browser caches if we introduce a new status code I\u0027m really impatient to get the freaking thing cache you know I don\u0027t want to have to file a Firefox ticket and and a Chrome ticket and are there any other browsers that Safari ticket I guess and and I guess it\u0027s just three tickets really I used to be more right but we\u0027re talking it\u0027s the only explicit freshness yeah so you know but you want it to be cached by caches that don\u0027t actually understand the new status code sorry but you want it to be cached by caches that have not yet been updated to understand the code now you understand the desire to have it be cached by caches that understand what the code means but I don\u0027t see the performance desire to have it automatically cached even though the cache does not understand what it means but it just doesn\u0027t seem to be a problem we need to solve hashing is a generic function you know the semantics can be decoupled from that of the new status code you don\u0027t have to understand the status code is cache it well sure but unless it\u0027s doing one of these things yeah but even I mean most at most caches operate on the presumption that they\u0027re only caching a limited amounts of resource responses because they have space controls wouldn\u0027t well you know typically caches don\u0027t try to catch the entire web you know they have some limitations per cache I think it\u0027s fine you know I mean what I\u0027m saying is that it seems very odd to be I to to be going down into this level of detail for a performance improvement that we is very mystical but you know if you want to solve it in general that I can understand that from a theoretical point of view I think especially for cases like when people are doing caching of api\u0027s for HTTP API for example and they\u0027re more likely to use some more esoteric status codes and I I would like them to be able to use the full capability of the cache not just what\u0027s in the normal web footprint and then you know if you look at the "
  },
  {
    "startTime": "00:56:06",
    "text": "status codes that we\u0027ve introduced over time you know 6585 the additional HIV status codes which you and me and yeah just you and me worked on all of these you know have potential caching cement that could get some value from from caching or at least some of them you know killing your requests for example in certain circumstances and certainly for five one which was other big one that we added a little while back and yes that you know you have to be careful to make sure that when you catch them they are served again in in the right circumstances but we have the mechanisms to do that now so so it\u0027s ice I I grew of that and I suggest that the step forward is next step is to say sounds great mark when are you going to promote the propose a cache control thing for the case of this is really a to a six kind of situation it\u0027s right there is it in there already yeah right there okay what\u0027s up right there okay so I\u0027m gonna import pull request are you is this assigned to you right now our are trying to give you a task item so I don\u0027t have to do it um can you give alright can I give you a test can you give me feedback on that straw man mechanism and see how much it makes you puke ah sure and and then we\u0027ll go from there sure if that\u0027s something that you see is halfway viable then I can I can flash it out you\u0027d have to do it right now okay okay you\u0027re busy man it\u0027s okay so here\u0027s the fun one 111 that was so impatient to get to before so we a number of us have noticed that the terminology around HTTP headers is fuzzy and an awkward and and misunderstood a lot even we need more precision when we talk about these things especially now that we have not only HD 1 but HB 2 and coming htv-3 and their different ways of actually carrying these things in the wire and so I think in Bangkok or there abouts we decided that we didn\u0027t want a bike shed this is an entire group so Julian and Roy and I bike should have this for actually a surprisingly short amount of time earlier today and we came up with a proposal that we wanted to walk people through and see what how much people like this or disliked it and so what we thought we\u0027d do is introduce a number of new terms in the semantics document so generic to any version of HTTP a list based field refers to a field that uses the the list rule or similar construct in other words comma separated multiple value header field a singleton field refers to the opposite of that a field that does not use that kind of rule it only is this supposed to have one value now they\u0027re gonna be circumstances where due to an attack or "
  },
  {
    "startTime": "00:59:08",
    "text": "a bug or whatever else a singleton field has more than one value in their comma-separated and we need to describe how to handle that sort of situation we actually have another open issue to talk about that for our existing headers a field item refers to a single value in a list based field so a list based field is composed of field items and a combined value or a combined field value refers to all instances of a list based header after combining with commas so that\u0027s the end result of the common algorithm we have of I need to understand the value of this header field but it might be split across multiple instances and so here we are and that\u0027s actually a term that\u0027s already used in fetch so that\u0027s a nice harmony that we have there and then in messaging we use field instance to refer to a received on the wire field name value pair so the one lying as it were maybe we should call it a field line but I think instance is probably okay we can bike shed these but these are kind of the distinctions that we\u0027ve been thinking about for a brief amount of time today Julien you have additional thoughts a feud line wouldn\u0027t make sense and the http/2 context where you have the same thing on the wire but not every line does that improve things in people\u0027s minds does that help I see thumbs up from Alexei that\u0027s fantastic even though we\u0027re breaking from the great tradition of mime Allen to the mic please Allen from delts clarification so anything that\u0027s list base is implicitly combined about or can be referred to as combined or is there sorry I couldn\u0027t quite hear that it is everything that\u0027s list based combined abble yes but really Singleton\u0027s are two in case they\u0027re syntactically bad all headers are combined able right yeah all header fields are combined abut some would end up in semantic errors after you combine them right Jeffrey yes can except for setcookie which is magic set cookie is always special yes thank you mozilla that\u0027s not why I have the mic so when a other specification that perhaps not part of the core specifications makes the reference to a response header maybe knew the value where they were particularly response header and it receives a it receives a nit during last call that that\u0027s not actually defined term what is the suggestion here for the replacement for the colloquial response I think in our current we haven\u0027t addressed one aspect of the discussion that we previously had but the current thinking is is that in almost every case "
  },
  {
    "startTime": "01:02:08",
    "text": "what other specifications we\u0027ll want to be talking about is a combined value because they are not interested in or or if they\u0027re talking about a part of that combined value it might be the the filled item but that\u0027s pretty long and they might say this is a secluded field or this is a list based field but beyond that they\u0027re mostly - when they\u0027re talking about the value it\u0027s usually the command million but the idea we talked about earlier was that in addition to this terminology we would also have a section about colloquial terms and what they might refer to so they would still have a definition in the spec it\u0027s just that we wouldn\u0027t be using those those ourselves anymore other than yeah I think that\u0027s very positive because adding you know a new term to this mix I don\u0027t think it\u0027s going to make the problem you know Interop any better with people that do feel like they you know understand the semantics but have no idea what a combined field value might be yeah so so formally if I were to talk about for instance content length I would talk about the content length header field combined value is that is that the the formal I severing of I would I would probably start by saying the content length header is a singleton field it\u0027s combined field value does la no but if I\u0027m talking about in a spec that I want to talk about the value of the thing in that spec I don\u0027t need to say that a singleton I can simply say this computer defining it yeah yeah I\u0027m not defining it you could just say well you could just say that the cunt is there any sense in saying value just using value in that context I mean what what we\u0027re probably going to end up saying is is that in most cases when people use the term field value they really mean the combined field value you know does anyone use that field in that context sorry because people talk about the value of the content length header yeah I mean it that\u0027s the colloquial so that was the other thing which I mentioned which II didn\u0027t get to is is can we omit field in some cases yeah and I think that colloquially there\u0027s no question that people do that the question is whether specifications should do it I got from Roy that you\u0027re definitely not gonna do it in this spec and you may encourage people in other specs not to do the same but as a question of correctness I think you know if I remember our discussion in Bangkok the field in the room was that it\u0027s something we should consider allowing I think my gut feeling is is working in a place where in our specs we don\u0027t do it but we don\u0027t disallow it with respects yeah and we and we provide people with a hook to do that that\u0027s a very fine pragmatic approach yeah yeah yeah and and I guess what I probably want to sleep a couple times on this and make sure that we\u0027ve covered the space adequately and we don\u0027t need any additional terms and that these fit all the uses that we have I think we\u0027re most "
  },
  {
    "startTime": "01:05:08",
    "text": "of the way there though I think this is pretty good progress Jef Raskin um Martin\u0027s comment made me realize that you should have an example of referring to the combined value of a field so that people have a thing to copy when you wind up with spec wording examples are always good yes thank you okay how we doing on time okay okay do we have anything else today yeah okay next up 54 method registration should include cash ability and Jeffrey you raise this actually so I think we came to a place in discussion where people felt that this wasn\u0027t useful to put in the registry is this where we\u0027re still at and I think you know the terminology around cache ability is is always a little bit confusing because we talk both about cashable methods and cacheable responses and those are very different things and if you have to walk through the entire algorithm to use them both to figure out when you can store something but having said that Jeffrey is this still something you feel like would be helpful or every convinced you this is Jeffrey askin if you scroll down to my later comment I\u0027d believe I still agree with it so the my original complaint was incorrect I suggested some changes to the wording that would have prevented me from getting confused enough to file the initial complaint and it they might be editorial but I don\u0027t know okay I\u0027m happy to flip it to editorial intake that is a way forward if everyone else is my Krisha if you could scroll back down for a second past my hump down down okay so you wanted to address the 7540 issue by parenthetically adding also known as cacheable methods where so can you repeat that in your last comment you suggest addressing the problem with getting rid of this that it would create for h2 by parenthetically adding also "
  },
  {
    "startTime": "01:08:08",
    "text": "known as casual methods but I\u0027m not sure where you propose to add that yeah that\u0027s a good question so basically I think the the discussion here seemed to go in a direction of saying that cache ability is a property of the response not a property there West and we also have h2 in push that depends on requests being cashable yes up really so as you as you say the algorithm is more complicated but I don\u0027t know if the right solution to that is to just simplify away one of the considerations yeah I think to me the heart of this issue or at least this confusion in the editorial sense is that we use the word cacheable in a couple of different ways and if we can find it a better term that would be great and then we need to find a way to back port that to 7540 so that it\u0027s the linkage is preserved issues you rightfully point out I\u0027m happy to try and do that editorially and if people have a problem with how I do it then we can talk over it then I can\u0027t do it my head now though so I\u0027d say the the other option would be to remove the requirement 7540 it\u0027s like I don\u0027t know at least I don\u0027t remember why it\u0027s there I think we\u0027d have to consider that pretty separately because that was does a pretty extensive conversation for example HTTP Bush doesn\u0027t have a way to put a body I don\u0027t think on the request that\u0027s being pushed on the promise so that would be problematic for most on cashable request methods or many at least it\u0027s intact to me there\u0027s nowhere to put it if I remember correctly yeah that sounds interesting but it\u0027s not a product of cache ability that that would be different yeah that would be an entirely different requirement maybe yeah anyway it\u0027s not our spec so we don\u0027t have to worry about it all right well let me go and see if I can and hook all that together in a sensible way that clarifies this and then we\u0027ll see how much people like that next up 51 mime sniffing actually I think we\u0027re almost done this one now aren\u0027t we do we need actually talk about this one with a group or look go ahead so we have a PR on this one I believe where\u0027s the PR there we are that\u0027s the "
  },
  {
    "startTime": "01:11:11",
    "text": "right one no no it\u0027s not [Music] 186 oh thank you thank you I\u0027m just wide oh great oh yeah that\u0027s not helping is it so basically we\u0027re we\u0027re changing this text we already talked about mime sniffing kind of indirectly I think and this just hones that a little bit to link it into they establish work on an online sniffing that the what working group is doing and referenced that and give us some advice about how to do that encourage implementers to provide that means to turn off and so we referenced the UM I\u0027m sniffing speck we had a point where we also referenced the X content type options header field as a way to turn it off from the server and in discussion we removed that because it was basically pulling in a reference to the entire effect specification even though this is like basically three lines on the fence back and we opened a bug on the mime sniffing spec to ask them why they didn\u0027t even mention an X Content ID option seems it seems like it\u0027s relevant there does anybody have any strong feelings about this or comments he commented I think before we had our discussion let\u0027s take a look real quick honest says X content type options is definitely recommended to some extent it\u0027s the only way to avoid a certain set of issues I think Julian was tempted to add the phrase a certain set of issues to suspect that he can charge himself so if folks are happy with that we\u0027ll just merge that p.r does anybody feel like we need to match next Content ID up options explicitly I see shaking heads or at least a shaking head okay number 30 is field name syntax which one is this ah yes we talked about this before so header field names are defined as tokens it\u0027s an extremely permissive syntax including some characters that are "
  },
  {
    "startTime": "01:14:11",
    "text": "surprising to many people and so I proposed that we find some way to cut that down so that people don\u0027t have weird characters in their head or field names with the possible security vulnerabilities and Martin just thumbs up that and we had a lot of discussion on the on the lip on the issue and everybody thought that this was a swell idea and then we talked about it in Bangkok and people were scared of changing things so we backed away from doing that and I was confused because I thought we had consensus to constrain the and the syntax of header fields and we didn\u0027t so I think that\u0027s here we are in Bangkok no real consensus concerned about compatibility reconsider on on impact of a case-by-case basis and then we have a little bit more data coming in so what do people think about this I I\u0027m I still believe that it would be good for the web overall if we didn\u0027t have header field names with exclamation points or dollar signs or other fun characters in them call me crazy especially considering the the places that they get exposed in and it seems like some implementations are already limiting this set and not experiencing horrible consequences in doing so what would make people more comfortable in in pairing this list down maybe we could get some telemetry from browsers maybe we could get some telemetry from CD ends what would people like to see here um so anecdotal experience about things that are already forbidden in either field names or fields values is that I saw a lot of I saw some people break their services when they moved from HTTP one where it\u0027s forbidden but tolerated 2h2 where it\u0027s forbidden but actually it breaks the connection so I think getting some telemetry would be good and I suspect that telemetry to be nonzero even though H do currently helps in bringing everyone into the fold when it comes to the current restrictions I I\u0027m not sure I understood you there because H 2 doesn\u0027t constrain the set of characters except in terms of case case normalizes but it doesn\u0027t disallow these special characters I think the breakage that I saw was around non ASCII characters in header field names or header field values both "
  },
  {
    "startTime": "01:17:12",
    "text": "fine Mike bishop also in favor of getting some telemetry I was mostly wanting to comment that when we were doing each pack originally chrome did telemetry of how frequently different characters occur which is how we generated the othman table so that data it may be difficult to find because we have different people now but the data does exist somewhere and worst case could probably be we created what can you move to your just further away just yeah if only we had a chrome engineer here sorry Colin unfortunately there\u0027s no good because it concentrated on names and values we\u0027re interested in names or names because we have we have relatively short in coatings for coats and equal signs which are not even under consideration here I hope I think equal signs are allowed by I\u0027d have to check no no it\u0027s token nevermind I think it would be joining him I think it would be good if we actually had a few examples of problems caused by these characters and practice like open back reports or evidence of breakage I\u0027m not convinced that we actually have a problem that we need to solve by essentially changing the protocol Allen findell just commenting on header problems that happen between h1 and h2 we actually experienced the opposite problem because HVAC you can have all kinds of characters get decoded out of your HVAC decoder which are not valid necessarily for HT semantics so sometimes we see weird stuff come get h2 new lines and things like that so it seems like we could gather data based upon existing web traffic and it seems like it\u0027ll be good to get that both from the browser side and from a high-volume server but the browsers I guess the server-side the population is a little more constrained you can also probably candy TV archive yeah yeah thank you and also I think we can probably examine some implementations to see what they allow and disallow and that might be very interesting in the forming this kind of decision and I can also probably put some tests at least for intermediaries to look at what some of them do so I guess this is an we can flag this needs data and and maybe we can make some progress that way if we let me ask if we find data that shows that you know a number of implementations already clamp "
  },
  {
    "startTime": "01:20:12",
    "text": "this down to to a subset of what\u0027s allowed by the spec and we have data that that you know the use of these characters is an out layer is there a will in the group to try and change this back does that help is it just the discomfort that we don\u0027t know I see some nodding heads I just go back to a little bit to the specific example there was an attack on servers called shell shock which was an attack on the bash executable and one of the pathways to that was the CGI interface and what how the CGI interface used environment variables to construct requests and the problem we encountered with an Apache was unless you\u0027re careful about translating the received header fields those header field to turn into hgp underscore header field name in the environment and that becomes an exploit for shell shock for some of these characters and so internally we we\u0027ve already removed some of these characters from that which we\u0027re willing to accept which is why I\u0027m finally removing some characters so that\u0027s what our experience has been in why we\u0027d want to move these characters in a specific example of why whether we have to or not I don\u0027t know Branko moana is there in any case anyone knows of where these characters are used in headers for real reasons it have is there any obviously we\u0027re only a few of the hundreds of thousands of people who do things with HTTP but if we don\u0027t have a single case where it is useful and then cutting it out makes sense to me right I think that\u0027s important comment it\u0027s also an important comment to note that the tale is very very very long and people operating with what has been clearly defined within that you know we would need a compelling reason to break compatibility with that and perhaps we have a compelling reason but that should in my view really be the bar and I will remind the authors this is a you know a business document essentially right and so if we are documenting the fact that many implementations currently restrict this set right and so for inter operation you should work within those constraints and we\u0027ve got some comments from like H a proxy and I think nginx in this list that suggests that might be the case and I think this makes a lot of sense for core if we\u0027re really discussing this as like this is the way we think the protocol should be for security reasons that might be a different document yeah okay so let\u0027s "
  },
  {
    "startTime": "01:23:18",
    "text": "let\u0027s gather some data I my sense is is that this first proposal that I made to cut it down really substantially might be too ambitious and then maybe we just need to look at you know there are a few problematic characters that a lot of implementations have already blacklisted anyway so let\u0027s just recognize that let\u0027s see where we go clarify rules around the half-closed TCP connections issue number 22 this is a of course against the h1 messaging spec and Brad points out that HTTP says nothing about half closed TCP and and there\u0027s a lot of back-and-forth on this issue as you can see in bangkok we said we need to collect data about behavior but we didn\u0027t assign that to anyone so I I\u0027m bringing this back up now to figure out how we can make some progress there of the people who care about this issue I\u0027m not sure if there\u0027s anybody in the room we\u0027ve had some participation from folks in the room but it seems like the folks who really care about this or folks like Willie and Brad fits and because of how were you is there he is was this is this one of the issues that you were really interested in if remember no not really oh well you live in hope so does does anybody want to volunteer to try and collect some data about this because otherwise I don\u0027t see a way to move it forward [Music] David you you referenced a different issue from it oh that\u0027s a quick working group okay my question I guess my question would be specifically what data are you looking for because the the data you asked for in Bangkok was does anyone do this yeah and we found a few old and rare things that do and really I think the question is how much are we willing to break the old and rare clients to have a more predictable behavior for everyone else I don\u0027t think there\u0027s data to be had about that I think that\u0027s working group it\u0027s more of a judgment call yeah I think another part of the problem is is that if I characterize the folks coming forward and asking for this it\u0027s it sure would be nice it\u0027s kind of the approach they\u0027re taking and it doesn\u0027t seem like a lot of other people care and so there\u0027s not a lot of energy and when you\u0027re talking about potentially breaking things that\u0027s not enough to get across the bar Allen from Dell I\u0027m sorry "
  },
  {
    "startTime": "01:26:19",
    "text": "because I was part of that discussion in Bangkok but I\u0027ve forgotten what is the behavior we are proposing with half-closed TCP we don\u0027t define it at all yeah so so you know it could have a couple of different semantics I think the proposal let\u0027s see like do you so basically nice though yeah basically the issue is when an application closes the send side of its TCP connection technically from a TCP standpoint all it\u0027s saying is I have no intention of sending anything else but I\u0027m still here in receiving right but there are a number of servers that take the perspective that once they receive the thin the client has initiated closure of the connection and they are no longer interested in the response now when I worked on issue visas we found a couple of clients where I as had that behavior it broke them we had to help them river it now they are rare it\u0027s like an old version of.net and it\u0027s something in Java from IBM that we don\u0027t have no more detail about and I think the list has know through the issue a few others may have been mentioned I think clients that are clients to half-closed and we\u0027re trying to the request is can we give guidance to servers that it\u0027s okay to make this assumption or that you must not make this assumption because right now isn\u0027t Anton find surfers have gone both ways and if client and server pick different directions that the connection fails at the end of the request so I mean I think the only thing I would wowthat\u0027s waked up the only thing I would add to that would be that the servers generally interpret or when they do interpret the half-closed as essentially a full abandonment of the session they are right for some approximation of several nines worth of being right and there are some scaling properties in true associated with not doing that right so sometimes you have clients that just plain go away and black hole they send a fin and they disappear off the network and that creates a bit of a problem for the server who is really insistent upon you know viewing this as a half-closed and sending the response you know buffered and retried and all that kind of thing so they\u0027re just doing what is right more often than not and so if I were to to clarify the rule I would in my view say that that\u0027s an important scaling property of HTTP and and we we should be biased in favor of that instead of really old clients that are kind of hard to identify while still acknowledging perhaps in the document "
  },
  {
    "startTime": "01:29:19",
    "text": "that you might create some very old legacy breakage Mike Bishop I\u0027ll also note that in the definition of connect for h3 we have the text that clients should not attempt to use a half-open TCP connection it will break for some percentage of servers Martin Duke I just pointed out that when you try to implement a 2 to 1 or 3 to 1 proxy the logic is very different and - I believe in - and certainly in 3 the stream needs to be finned before the response there\u0027s supposed to be fin for the fonts come so you\u0027re trying to mirror that to an h1 connection on the backend it\u0027s not impossible to implement but it\u0027s someone more complicated Martin Duke I just wanted made a good point which is that for clients there is a signal if they no honor to get anything that\u0027s called TCU reset and they should use that if they don\u0027t want the data and it\u0027s perfectly reasonable to shut down the sin side of a connection and wait to receive the rest I can imagine it being very reasonable to say clients should not send a half closed but servers have to accept it just that\u0027s I think that\u0027s the most conservative approach so I guess do we want to figure out do we want to do any text here like do we first want to say like should we clarify this do we agree that this is an area that has lack of clarity so do you want him on that okay let\u0027s go on that yeah yeah how many people have an instrument like how many people care about this raise your hand if you care about this offense people have moderate bro again I I think somewhere in that in the in the issue I volunteered to look into it when we get to that part of rewriting the messaging spec because right now we haven\u0027t delved into how do we pull all the semantics out of the messaging and we are set to do that very soon in theory at least so I you know I\u0027m still on the hook for doing that I still agree that needs to be done but I don\u0027t know what shape or form it will be at this point "
  },
  {
    "startTime": "01:32:27",
    "text": "somebody has a pigeon let\u0027s drive okay so let\u0027s try to see what people think let\u0027s do a hum and the question will be if you think that we should add text to clarify client sending a fit to make a half closed TCP connection please hum this is to add text just just add some text to clarify behavior it doesn\u0027t matter what behavior it is should we even be adding stuff first well I\u0027d like to how much do we ok so please help now and do people think that we shouldn\u0027t clarify anything and just kind of leave it as is please hum now okay so stronger for adding stuff but there are some people who don\u0027t care so do we I mean what\u0027s is the proposal to say that the clients should should use it as a point of signaling like that we should define semantics around it well the tension no I think we need is the tension that I understand is that on the one hand some clients want to use it as a signal and on the other hand some servers are saying well often that signal is trash and I\u0027m wasting resources and I think that\u0027s the tension here well specifically for this report Brad wanted it as an indication that the client is no longer interested in the content and that receiving a half-closed was treated as equivalent to receiving a reset and the the problem with that being is that it\u0027s never really had that interpretation asked there\u0027s always been acts around trying to you for other reasons so the question was really should we add a new distinction that says if you receive a half close you must not send a response because that would be the distinction and I don\u0027t believe that is something we should add to HDPE Mike Bishop again I honestly I think the first thing we need to put in there is client should not do this and then between whether the server should ignore that the vin arrived or must ignore that the Fen arrived nee must is probably less breakage because otherwise you have to shoulds that can "
  },
  {
    "startTime": "01:35:27",
    "text": "overlap and break and that\u0027s where we are today it sounds like a proposal at me people want to people understand what Mike just said as a proposal Mike Cunha restate yeah my proposal would be client should not fin the connection until they were done with it and servers must not abort a response because the client said then questions about the proposal and friend out was it ever legal for an HTTP 1 1 8 HT v10 post body to be terminated by a fin because our code will work that way if you have no content I think Patrick\u0027s looking something out Jeffrey you had a question yeah this is Jeffrey askin I\u0027m sympathetic to Brad\u0027s comment in the that\u0027s on the screen that it is difficult for them in a in a portable way to distinguish in from reset I don\u0027t have any personal experience with this and Brad isn\u0027t here to give his argument so taking taking the proposal which would say no you\u0027re wrong seems it seems strong just a clarifying question on my cruises Martin Duke about Mike\u0027s proposed law I want so the intent of these should not is because some servers are likely to not comply with us the response was yes that\u0027s the intent yeah I\u0027m not clarifying I guess I\u0027m advocating so what you know Tommy Tommy consider the Holmes but um I I think the server must not reset might be overstepping giving some existing server behavior that I think actually is in the interest of HTTP and the internet although I mean I I appreciate the technical consideration of the long tail of the 1995 CGI client but I\u0027m not sure like that\u0027s actually the decision I\u0027m proud of even though I would like to meet Mike Bishop I in terms of respecting existing implementations they should not any should makes perfect sense but then the reality is that that permits exactly the failure mode that we\u0027re that the issue says we should try and figure out well I mean the other option and you know Roy doesn\u0027t like it but I mean the other option is servers should close the connection upon receiving a close from the client yeah maybe should sir or should not saw the right thing but then you might need to add a bit more text explaining the problem that actually might be the right thing explaining what why you know "
  },
  {
    "startTime": "01:38:29",
    "text": "this text yeah Eric Kinnear I think I\u0027m slightly opposed to the server should close the connection but at the same time I\u0027m sympathetic to the desire behind it so if there\u0027s some other way to accomplish that that\u0027d be real nice but at the same time I\u0027m not sure that there is right I mean I I can see that there\u0027s probably some room for the editors to massage the text on it you know even if we go in kind of with mention of saying you know you must not just use this fin to reset your connection there\u0027s gonna be some wiggle room I imagine of saying you know but maybe you can put it on a list idle out quickly because it\u0027s you know you do something else but don\u0027t use that alone as a signal okay so should we come in the room okay so based on Mike\u0027s proposal I think without really specifying if it\u0027s a should not or must on the server so proposal is the client should not send a fin when it\u0027s still expecting a response and the server should not must not is discouraged from just immediately closing the connection upon receiving a fin right if you support this idea as a way to resolve this issue please hum now if you do not think this is a good way to resolve this issue please hum now okay so it seems like we had a decent hum in favor of using this approach going forward not knocking the walls down with its loudness and we had a couple outliers on the other side but I just asked if if you hummed in the other direction can you raise your hand okay the acoustics of this room are horrible I\u0027m just trying to judge how much of the room that was the other direction being they were both incredibly weak to my ear but it\u0027s okay oh I don\u0027t know if we can do that could you put up your hand if you support this proposal Mike wish the bishop proposal yes it will be remembered in history as the vision proposal and if you do not support the proposal okay we have we have three ish do nots I think good sound and anybody interested in explaining why they think this is a bad thing you have yeah yeah okay maybe a little more discussion but sure well at least we have a communal direction maybe "
  },
  {
    "startTime": "01:41:31",
    "text": "we can we can address those concerns in the PR okay great but that is further than I thought we would get there okay number seven this is Julian\u0027s oh yes so Julian made the comment that we should probably discuss what it\u0027s appropriate to do something like defining the the syntax of a header as an alternation of two different things like either a star or a list of things and whether that\u0027s a good thing or not and and and error handling around that because it\u0027s an awkward construct in a lot of cases and I\u0027m made the content comment that I\u0027d prefer to document this as an anti-pattern and he agreed but when he objected for alt service he was in the rough and Roy said so I guess you know how the three of us feel how other people feel so how many pedophile definitions have this problem if range there are a bunch that do star or other stuff and as a practical matter if anyone goes star and then put something else in yes I mean in invalid or not it\u0027s still gonna get a comma splice in there and it\u0027s gonna go often do whatever it does so it\u0027s a it really is elicit syntax anyway so yeah I mean I think I mean go ahead well effectively everything is listed effective if this ROI effectively everything is a list syntax mechanically from the semantic standpoint I mean the the reason to have a star there is a shortcut not a validation scheme or whatever so I mean if you have a start comma whatever it has the same effect as just star there in all those cases so it\u0027s never really been a concern in the past I mean I agree that from a cleanliness perspective it\u0027s it\u0027s kind of been pooped on but that\u0027s it\u0027s not the only thing that we have that\u0027s weird in a CP so I don\u0027t think at this point I don\u0027t see any way to fix it Felix hanta accepting coding is an example where you can have star comma other things there\u0027s a bunch of them in Julian just to "
  },
  {
    "startTime": "01:44:35",
    "text": "clarify this is not about changing the spec in some way it\u0027s I guess guidance about for people defining new head of yes and I think while the choices to either have it explicitly as an odd service or to just make it a list and put the constraints into the pros and we have the related issues that talk about we started our fields and the question is is this a list our pair of years now if the grammar is this event I think it\u0027s causes more confusion than the potential more concise a BNF solves so you\u0027re explicitly including headers like in fringe where it\u0027s entity tagging or HTTP day not just star yeah ah but I did actually change the spec since this was put in here so that\u0027s no longer a concern at least from others to other restrictions standpoint in the sense that you know there\u0027s a part of the spec where it says where it talks about you if you have list format you it\u0027s a comma separator this is list format and if you don\u0027t have if it\u0027s not defined as list format then you can\u0027t use the comma you can\u0027t have multiple forms of that and what it now says is if you have at least one of the alternatives for the field definition being a list format then you can have a comma separate so from there used to be a logic failure in the spec now it\u0027s just an ugly failure and like I said but we can change the spec all we want but that\u0027s not going to change the fact that there are there exists these definitions for these header fields and one unlikely to change them just for this reason I don\u0027t think anyone\u0027s suggesting that we change if range for example it\u0027s the question of do we recommend this is a good practice for new headers and you agree that we should okay so so job I just wanted to point out that there\u0027s if we have the syntax s and the ID service example we\u0027ve got potential into our problems then for instance you have star comma and one recipient might say that doesn\u0027t conform to the ANF and ignores it and the other sees a list type head of length one and says that\u0027s okay so um actually it\u0027s clear in this case not star but you see my point so if you have clear comma is "
  },
  {
    "startTime": "01:47:35",
    "text": "that an inverter tailor-fit instruction a much cleaner way to do this would have been to define clears a special value and then you know to register it effectively and then just if it appears in the list and it has that meaning rather than doing this weird thing yeah yeah I don\u0027t remember you bringing that up obsession insist it stupid marks didn\u0027t mark it used to be that way in the earlier draft and in the end it was changed okay so that was the consensus for some reason that\u0027s probably McManus all right so it sounds like we just need to try and figure out what to write down in the recommendations for new header fields I will point out that with with structured headers this is impossible so that\u0027s a nice attribute of that okay so before we leave the topic of core I would like to thank the team as Julian pointed out in his presentation there\u0027s been a ton of activity around this since we last met this is mostly thankless work but I will offer my thank you so you get one in there many others should do the same and if you would like to make 1,400 github entries yourselves I\u0027m sure you can you know make the acknowledgments but I wonder if the the editor team would like to talk about schedule and how they think this project has been doing is a pretty big scope and you know what we have in our future yeah we actually talked about that earlier and I think we\u0027re still very confident we\u0027re gonna be quick yeah I will have a better idea sort of this time next week but certainly we intend to do a lot more work on it this week during this week so hopefully the pace will pick up incidentally I know I for one and terribly consumed by other things than this just to be clear when he says we and this week he means Julian and Roy not me this yeah right I mean yeah I plan on making all the changes that mark objects to and this week and then next week why is this so much churn in the caching spec do have a target date in mind is it this year um I think it\u0027s this year I think that yeah I think it\u0027s this year for me at least personally for me a lot of these issues I wanted you know I\u0027m in this mode where I\u0027m writing tests for the cache and stuff and I want to make most of the stuff in the cache expect covered by tests we haven\u0027t started "
  },
  {
    "startTime": "01:50:36",
    "text": "doing that for the other specs but you know we potentially could that could do that too if people wanted to put resources into it but yeah when I want to make it it driven by implementation behavior where I can so that\u0027s taking a bit of my time right now but yet I\u0027d say working group last call Singapore ish would be aspirational I didn\u0027t say way to Singapore meeting okay thank you yeah thanks I see you on Thursday thanks for getting through that one more blue sheet in "
  }
]