[
  {
    "startTime": "00:00:16",
    "text": "okay it's the top of the hour welcome everyone uh this is a session of the uh that net working group at iedf112 louberger and myself janusz farkas co-chair uh the working group and we are uh thankful to ethan grossman our secretary for the great minutes and have uh provided us uh behind the scenes the uh agenda details are available at the usual place links are provided here as well on this slide next slide please it's a reminder that we operate under the ietf rules and policies captured in the ietf note well so all the rules apply and by participating here in the iitf you agree to follow these policies and procedures please check if you are not familiar with that as a reminder this meeting and the contributions become part of the permanent record so by participating you acknowledge the recording there's a list of bcps here highlighted that drive our operations and in the next slide we would like to draw attention uh to to one of them the code of conduct it has been there uh before uh it is uh uh i think it's going well in in the working group just a reminder that we expected to behave towards our colleagues respectfully and with courtesy and"
  },
  {
    "startTime": "00:02:03",
    "text": "professional next slide please okay mythical yeah you you have found it you are here that's that's good and um we also have the usual uh way of chat and jumper uh combined in mythical as well available and the jabber link is in the bottom as well the blue sheets are automatic in this electronic meeting no need to bother with that and please join us for the note taking in kodi md or hashtag what is the name at this moment the link link is here and also available via the materials please help me taking and and make sure that your points in the discussion have been captured accurately uh the agenda also available online uh i think that's enough for this slide maybe the next one okay the sessions at uh this idea sorry for the typo it is itf112 uh we had a joint session with pass and mpls working group on monday this is important for us because mprs is is one of our data planes and uh the evolution of mpls is being discussed in these joint working group meetings and also in uh weekly regular design open design team meetings if you are interested join them too there was a a contribution presented related to that net and we discussed that one here at the deadnet session as well please uh check the recording if you were not able to attend we are here on wednesday in the main.net session next slide and slide please okay so this is our agenda"
  },
  {
    "startTime": "00:04:01",
    "text": "after this intro we will have the om work items on the agenda and after that some data plane uh related contributions on payoff bracket ordering and uh the second half is sort of newer work items uh first uh discussing continuing the discussion on on on the requirements on moving or towards a larger scale networks some people were considered in the beginning and some solution ideas at towards the end on the achievement agenda next slide please an update on the on our status as a working group we have a new rfc published on uh the data plane ib over mpls we have two documents for which publication has been requested uh that not bounded latency draft and the newer one is that that net yang is progressing many thanks to all the contributors who have to make this step and we are looking forward to finish both of these documents and then go to the final approval procedure and get them published we have two working do group documents that are not on the agenda uh they we have the op oem package uh there is no specific detail on ip uh at this meeting that's a sort of a bit later stage in the in the queue uh first we are working on a framework and an mpls and an ip that was the discussion and the other one is the control airplane framework on which there was an update provided on the list next slide please okay we have received the liaison at the end of july from itot study group 13 on work items related to deterministic communication"
  },
  {
    "startTime": "00:06:00",
    "text": "this falls in to our scope and the work we are conducting here so this liaison has been provided as for information to us but as it is very closely related to our work uh we suggest to respond to this liaison and discuss the details on the list next slide please okay just a reminder on the ipr procedures we follow uh strictly the usual ipr procedures and there are two points when we request ipr call prior to so in the beginning at the end prior to working group adoption and um towards the working group last call and also we have a step that we request uh upgrade statements to be made clear if there's a new outer in a draft next slide please okay we have been working remote for a while and just to to remind people that our main forum is the is the list so please please use the list comment and there have been good discussions i'm really glad for for that and uh we have opportunities for virtual meetings in addition to the regular ietf meetings as as needed we can schedule interview meetings uh as we just had uh recently and uh we can also have informal working meetings to advance our documents we used to do this for data plane and then for yang actually now the young has been completed and the one that is ongoing and we we have a bi-weekly meetings on the progressing the oem work so these meetings can be"
  },
  {
    "startTime": "00:08:02",
    "text": "set up by by the chairs and please reach out to us if you see uh other topics that should be discussed or would be beneficial for the group to be discussed um either way in our interim or in informal working meetings we can we can set up those meetings and this was the last slide as the intro any questions okay hitting none then let's move to the first presentation from greg yes thank you um good morning and um so this is an update on uh our framework for operation administration maintenance in a dead net next or at least so in 111 meeting uh the working group agreed to uh merge um part of their um draft into this uh document um on oem requirements for uh that net service sublayer layer and uh we welcome uh balash indiana as a coffers uh we continue discussing uh documents related to that net oem in our bi-weekly meetings and uh thanks janice for leading these discussions so there are more significant updates as mentioned so we integrated these requirements for deadlift subnet service sub layer and now are the requirements in the document structured in three groups uh general.net oem requirements uh"
  },
  {
    "startTime": "00:10:00",
    "text": "requirements for forwarding sub layer and for service sub layer next slide please so among uh general requirements and this is not a complete list it's just the highlights so the oem sessions are between that net uh maintenance and points uh supporting uh and should be you able to use a proactive and on demand monitoring and measurement and uh proactive is uh something that is uh continuous and periodic uh using uh probe packets and on demand it's more understanded it's basically initiated by an operator and it has a terminal lifetime of the test session um must support unidirectional oem methods for example as continuity check and measure packet delay and packet class also support uh oem for bi-directional deadman flows next slide please uh for the forwarding sub layer um be able to do path uh mtu uh discovery be able to use a remote defect indicator support monitoring levels for resources allocated for the given that net flow and for example these resources are include but not limited to buffer location and transmit schedule of calendar"
  },
  {
    "startTime": "00:12:00",
    "text": "support monitoring any step path traversed by the particular deadline flow next slide please uh for the service sub layer so that is the part that we integrated and it's new to this document it's not new it's been discussed uh by the working group but in this document that's an update um so oem functions for that net sub uh service sub layer and support discovery of the dead net relay nodes and uh in a service sub layer these relay nodes are node that met nodes that implement support one of the packet replication elimination and or the preservation sub functions support the collection of that net service sub layer specific information and that specific information is related uh to the pre-op sub functions and relay nodes support the ability of exercising functionality of packet replication elimination and oil preservation functions and that is really important because this is a new mechanism and listed new mechanism for oem and it requires additional special instrumentation for probe packet and ability to control uh this sub functions pre-offset functions support to use alarm indication signal between that net relay nodes and so that is important uh then uh discovering a defect on um service layer and indicating uh the propagating our medication signal to the"
  },
  {
    "startTime": "00:14:01",
    "text": "client sub layer support performance monitoring in a dead service sub layer with a pre-off in use any questions about their requirements and the structure of the document because that is new as we added um there is section on the service sub layer so we separate it [Music] into the general and the forwarding sub layer yes uh lou you have a question a comment can you hear me no yes ah okay i muted that guy yeah he did it backwards sorry um you're you have a metric section that seems a little light my expectations are going to beef that up um while you're doing that i think you're it would be good to have um requirements for each of the metrics that you're talking about you know whether the metric is required or not or you know it must should may that's it okay thank you okay uh next slide please so while we were working on the requirements we found several open issues that we consider not to be entirely editorial and that's why we are uh highlighting them uh in the presentation and uh one working group uh to uh discuss it um so the hybrid oem and that's uh using their classification rfc 7799 and as a oem measurement method that combines uh passive active uh measurements"
  },
  {
    "startTime": "00:16:01",
    "text": "um is often represented by on path telemetry methods such as for example in situ oem and alternate marking method and telemetry information um can be collected and transported in banded out of bank so the example of invent is one of their options trace options documented in oem as where the information is collected in packets either hub by hub or and by uh to end uh so hop by hub it's a transit notes uh iom nodes uh add uh requested telemetry information in the data packet that serves as a trigger and end to end as an ingress and igor's only um collect information uh but in addition there are out of band methods so where their information is uh stored locally either for direct exporting uh immediately or for um aggregation processing and exporting of some calculated uh performance uh metrics and uh so this um uh out of band methods can be either using um yank data model so they use in combination with a model driven telemetry uh or use some other methods well known like grpc kafka uh else so um what we're asking is that the current document states that that net oem may support hybrid performance measurement methods but in our discussions we agreed"
  },
  {
    "startTime": "00:18:00",
    "text": "that uh these methods can provide valuable and important information especially uh important for uh streaming telemetry information that used uh for network analytics and uh then in combination with out-of-band uh collection entrance um of information uh provided important and uh valuable uh operational uh mechanism so the our proposal is that makes support of the hybrid measurement methods mandatory so to change must and we understand that this discussion uh to be on the mailing list and uh i would like a working group uh to discuss it and um come to some conclusion uh so further are we proposing to splitting um the requirement that combines proactive and on-demand oem into two requirements uh that just the convenience because um it's much easier to evaluate the conformance and then uh when we are talking about uh if we need the new mechanisms or we're uh doing a gap analysis and we're uh need to do the checklist uh attribute uh to two separate requirements rather than just say okay that's uh this mechanism can be used for the part of this uh requirement that is confusing and uh another is um what we found is like thought is inconsistency but we uh discussed it um so it's uh two requirements in the general session um are related to unidirectional performance measurements and uh they seem as duplicate"
  },
  {
    "startTime": "00:20:00",
    "text": "so and uh yeah actually it's like in a second and it should be ten not in first sentence and eleven um so we just uh want to remove the first sentence so that's uh probably more editorial and next slide please so we'll continue our uh bi-weekly discussion and uh everyone is welcome uh to join um so this is our open um calls uh please comment uh review the document and uh we think that we are getting close to the stable document and uh probably uh at some point uh before the next meeting uh will uh be ready for the working dual bus call thank you any comments questions uh greg i'd like to go back for a moment to your this hybrid discussion yes uh the so uh you made two comments here about uh um one is about off path or out of band um so we have had uh in um sort of traffic engineering we've done a lot of out of band um uh for the response and uh response messages or for feedback you know so on on path or in band for forward and then off uh out of band off path for reverse um we need bi-directional messaging and you're doing one-way oam that definition is a little different than rfc 77's 99's definition of out-of-band uh for them they use out-of-band to talk about act uh active and passive so when they're talking hybrid they're talking passive monitoring versus active monitoring"
  },
  {
    "startTime": "00:22:00",
    "text": "um well so 77.99 they they they they have actually the two types of hybrid uh but um it's it's their the title of the rfc is active passive in in between so um um itself uh the hybrid methods that use some that add some information to the data packet are hybrid because uh they need to um mark packets uh as in alternate marking methods to create the flow of uh marked packets that identify changes in batches and uh iam which inserts it as a minimum inserts the header that indicates and lists uh of informational elements that needs to be collected um and a node or requested to be collected at the node um so uh their collection methods out of band uh here is uh interpreted as being uh out of band relative to the monitored uh data flow yeah i think i think we can have more discussion on this maybe on the list but i think for um you know out of band for responses is something that's you know well established and certainly we're going to want to support and so the requirement all looks good actually i think the text in the document is pretty good it's really just your characterization here that i had an issue with okay the the other thing is that telemetry is usually about monitoring of oam not the oem itself and um you don't use telemetry in the dock document right now at least i didn't notice you're using it um"
  },
  {
    "startTime": "00:24:02",
    "text": "i'll have to read what you mean by telemetry uh because um the the examples you gave are more about monitoring oem than actual oem right um again um so the telemetry um usually differentiate uh two components uh so they're uh generating telemetry information and um uh collecting transporting uh such information and their protocols that used so can be attributed or characterized as uh on path telemetry information because uh the other methods that uh now we discussed are uh model driven um telemetry that is um based on yank push right and that's more about getting that to a central controller or to some monitoring than to do the oam on along the data path mm-hmm and i think those concepts in a way that for me at least is quite confusing oh i'm sorry um yes i i didn't mention because i didn't go um into details of uh what's being discussed now uh by ippm working group so uh there is a a very uh useful uh proposal of uh iom direct expert so uh where um the information indicated in the data packet that telemetry information to be uh stored for the local processing so not to collect in a data packet but uh just to generate originate this information and then uh their processing is uh determined by the local policy so it"
  },
  {
    "startTime": "00:26:02",
    "text": "could be either exported directly uh from the packet to the collector and the collector can be again uh the collector can be in the eager ingress node uh or egress node of uh the monitored floor or as you said that it could be a some controller that will use it for uh network analytics yeah that that discussion would be great to bring in here because that's the context of how you're using telemetry so if that's how you mean to use it you know i i think bringing it into the document making that clear would be great okay okay we'll work on that okay thank you okay hi uh vargo is speaking and on behalf of the counters i will present uh this draft which is oem for the net service sub layer next slide please so there is this draft is uh has the intention to to collect uh the service sub layer specific oem topics and the text is targeted to be moved to virgo drafts and this is what greg was in the previous slot highlighted that some texts were already moved from this draft to the oem framework document this document is focusing only on the service sub-layer oem so forwarding sub-layer oem is out of scope in this document and we are currently at version 01 and next slide days the next slide is showing uh what is the content of the draft and there were"
  },
  {
    "startTime": "00:28:01",
    "text": "updates made so section 4 this is what were already moved to the oem framework document section 5 dealing with that net ping which is describing oem processing at the.net service sub layer so what a relay node should do when it is serving that net oem packet the new text is added based on the weekly discussions uh uh about uh the service sub layer oem challenges so we have added uh illustrator illustrative example uh just a very uh simple network uh which is uh which can be very useful during discussion of oem related issues and challenges uh we have also added a subsection dealing with that net service sub layer specifics but by it is uh somewhat specific for for oem uh there is also a section dealing with what information needed when that net oem packet is processed so this information have to travel with the oem packet and there was also a section added about a possible format of the net ach next slide please the this slide is just summarizing this this new text and this is as i said mainly the outcome of the of the weekly discussion uh and the discussion on the list about oem so the service graph in case of that net it is segmented in multiple parts because the the forwarding sub-layer parts are terminated at the deathnet relay nodes and there are some special characteristics of a deathmatch cellular because the prior functionalities they are acting as a as a pair pocket protection"
  },
  {
    "startTime": "00:30:01",
    "text": "and that means that all the parts in a service sub-layer graph they are active and they are forwarding traffic and they may have a different number of hops and as usual it is mandatory to use the sequence number for for that net series so the main main challenge is that the oem packets must follow precisely uh the same path as the packets of the corresponding.net data flow next slide please this slide is showing a possible format for the net ach associated channel header the associated channel header is is used for for many years for oem purposes but its size is limited it is only 32 bits and if during the discussion of of that net oem stuff we have identified multiple pieces of information which have to be present in a definite oem packet and it would be hard to put all these information in a 32-bit uh field because some part is already reserved for other purposes so the first nibble is 0001 and in the vergio version uh with version 1 we can highlight that it is about that net associated channel header there are in the in the draft some proposals regarding what uh type of information should be there and for what purposes they might be used this is something up to discussion uh the the major uh uh conclusion that we wanted to to highlight with this slide is that uh we need to add additional 32-bit uh to to the ach and create that net specific ach"
  },
  {
    "startTime": "00:32:03",
    "text": "so how how many bits for sequence number node id session id and so on are used this is up for further discussion and level and flags fields are also something to be to be defined in more detail and discuss level would be something to to create oem domains and flags can be used for example to to control uh the service sub-layer functionalities for a given uh that net oem packet um next slide please so uh with this update we have included in the in the draft the proposed changes and clarifications which were on the list and during the biblically oem course uh we are still looking for further comments discussion as i said this is a a discussion draft in order to to help to make text of the virgo documents so the target is to have a common understanding inside the group and and consensus on the that net ach and that net being functionalities and these are practically texts these sections to be moved to the group document and here we mean the net mpls oem document thank you any questions okay i think uh you know that last point about moving into the working group document is something would be good to address early uh if this belongs in the working group document it should be there rather than as a separate document i don't quite understand why it is a separate document and the flow of the two documents are not well aligned and"
  },
  {
    "startTime": "00:34:00",
    "text": "so having it as a separate document to me is not not a positive thing if we're going to merge it we should get agreement from the working group and do it quickly um i know greg is going to present next on the working group document it'd be good to hear his opinion on that as well okay thanks yes um okay so um this will be a very brief uh update uh on uh oem for um that net and with mpos data plane next slide please okay so uh we received uh very good comments from belarus and we addressed them uh so he is agreed that everything is much better now and thank you polish and next slide so that's it um um yes we you just uh uh heard and um seen uh the new proposed for uh that net ach format and i absolutely agree and uh we discussed it with bolas and yanash about how to proceed and we just felt that it's uh need to be presented and discussed by the working group and the working group will decide uh if it can be merged into their working group document so uh please discuss uh also as yamash mentioned uh in uh shares update uh at the top of the meeting um their new format for that net ach format was presented as joint pals"
  },
  {
    "startTime": "00:36:02",
    "text": "mpls and that networking groups meeting uh that discuss advancement or new architecture for uh mpls uh data plane and uh that was uh well received and uh what was uh the good comments is that saying that oh guys uh great that you are not asking for another first nibble but rather use uh flexibility of uh versioning of ach for your purposes and there were no concerns that we need in other 32-bit steps and some comments said that oh now you have more space and you might increase their um sequencing space so match it to uh detonate control word um that's something that uh definitely worth uh considering uh but will require some uh more work uh in general again i would to um working group uh to discuss whether it agrees to changing their uh current format that is documented in the working group document adopting uh effectively importing their text and new format from the individual draft and so i would like the guidance from working group chairs on how we can proceed with this discussion and arriving at conclusion okay thank you it would be good to hear from the group if there's any comments or and particularly objections to basically moving the technical content from bellagio's draft into the working group track"
  },
  {
    "startTime": "00:38:09",
    "text": "actually i have a similar question here and also now from npr's open design team so i don't know what what's the procedure of this sorry at least for me you're breaking up um uh if someone else heard yeah did you hear the question not for me for sure yes it was breaking for me too if you type it in if you cannot fix the audio file yeah fun if you could just type it in the question into the uh um jabber or i don't know if you want to try again okay and am i audible again again or i will tap it in the in the chat box i could hear that fan you actually sounded good there i don't know if you want to try one last time i'm sorry maybe maybe it's the voice is not good the quality of the voice is not good i my i audiobook again okay follow up later uh fan if you want to try one more time we could try it if not yeah please please try okay um do you remember again"
  },
  {
    "startTime": "00:40:03",
    "text": "yes okay so a long latency i think um my question is was the preceding procedure um between this new dent ach format imported and the mprsd open design team because i think they are they are relevant so do we need to first follow the mps open design team result and then imported this then that ach format or we import it first and then align with the the discussion of mpl's open design team yeah i'm i think there are um there are three things first is the discussion from npr's working group and the second is this the discussion of this new that net sh format and the third one is the is to move this um new format from individual uh draft to the uh to the mps working group shaft yeah i i think the clarification of to these questions will be helpful thank you um so stewards probably can answer because in regard to their open design team or stuart were you going to try to respond yeah i was what i was i was going to talk to this subject um so in terms of the the the ownership in inverted commerce of the structure of nibble one aches that probably belongs in pals which is where we created it in the first place no one has no one has"
  },
  {
    "startTime": "00:42:00",
    "text": "found any use for those reserve bits in the last 20 years so um we can think about making them essentially a parameter of the um channel type which i think is what was uh what was shown assuming i'm we're all talking about the same thing but i think it would be as well to sort of socialize this in the sort of pals mpls space um uh just to make sure that no one in particular the pal side of it to make sure that no one can think of any uh serious long-term issues for doing that but the principle of making those reserve bits a um a parameter of the channel type is probably okay which i think is what you were proposing so i think going to the couple of questions that were asked about um i think procedure-wise i'd like to address those and then uh greg if you want to get back to technical that would be good afterwards um so we have we do have the joint uh group we are coordinating with them this was presented there uh so that that's happening uh and that needs to continue to happen in terms of the documents and what we do in this working group i think it is worthwhile for us to document what we believe is the working group position and then make sure we synchronize it right now all we have is an individual proposal that that doesn't carry the same weight as this is the direction that working group would like to go so if this is in fact you know blind document does in fact represent the direction the working group like would like to go i think we should bring it into the working group document and continue to socialize it and as the work progresses uh if it if it gets uh it could end up getting moved into a pals document it could get moved into a joint document and then we work with the chairs to figure out where it is but you know we'd like to keep the process going at the same time we're um"
  },
  {
    "startTime": "00:44:02",
    "text": "you know coordinating so being able to represent whether or not this is a working group position or an individual position i think is an important step although i think it would be useful to get some earlier feedback than that so that no one is surprised and there is no and and any corrections can be adopted earlier i can't see anything wrong with this but i just think it would be really useful to have that discussion sooner rather than later and i don't think it would be 100 but it was presented in the joint meeting is that not sufficient i must have been asleep i was taking copious notes during that meeting and i don't remember it but still i must have been asleep and once i'm losing i mean it's one of us has lost whatever is lost i thought this was presented in the joint meeting maybe i'm wrong yeah i was i was i presented this uh part of their talking so i joined janus and uh as a buffer of nuclear build craft and i presented uh their uh definite hph uh four minutes and some uh one of uh good comments somehow rather it went below the radar but um um anyway i think they're probably more or less in sync anyway yeah but your general point is correct and i and i completely support it which is independent uh well in parallel with what we do in this working group and what we decide in this working group we must uh socialize coordinate with the joint uh activity that joint design team the and uh and we may we should be aware that anything we do here it could be affected by that for example what we agree may be modified based on the the joint agreement between the working groups and in fact we may take the format out eventually and run it through"
  },
  {
    "startTime": "00:46:00",
    "text": "the pals working group if that's the end decision um but you know having agreement of this working group i think is an important step you've seen mpls making you know doing the same thing of of putting together positions that are right for the mpls working group and then we'll we'll coordinate between the working groups cross working groups uh uh to get make sure we have a uh an answer that works for all at least that's how i'm seeing the process i should mention janos is being quite because he's a co-author on the work so my only concern is that someone in pals will remember something or other that that breaks as a result of this i can't think of anything yeah that's needs to weigh in on this i agree with you a hundred percent thousands of million and maybe the right thing is is if we that net uh end up last calling the document we do a joint last call okay greg you had a comment and we should uh try to wrap up because yes it's usually important we are running over brief technical comment um so um we believe i believe that um uh this is important and um so i would appreciate the working group uh discussion on the mailing list and uh derived conclusion uh in regard to um updating their working group document and uh inc with their new um that net ach format uh their uh interaction to the work of open design team uh one of their documents that uh working as now its individual document of group of uh contributors on finally creating um their registry for the first nibble after mpls stack and uh value uh zero for the first uh value one for the first nibble is"
  },
  {
    "startTime": "00:48:02",
    "text": "reserved for uh pseudo-wire ach and now it's to the wire that net ach and uh based on uh direction from mpls working group or direction of open design team is uh that any new mechanism should not uh impede on existing functionality and uh it can be used as it can be used is it used uh currently so uh to minimize interaction so probably that means that it will use a different uh first nibble value for its header post stack so with that i can close this presentation and let's move the discussion to the mailing list greg as author in fact we'll just call you editor you can change yourself to editor of the document but as uh editor of the working group document um would you conduct a poll on the list to see if there's objections to bringing in the technical content of bellagio's document into the working group document that's very good idea thank you lou and i'll shoot an email to the working group with that question great thank you okay so this slide drag is about how to provide pre-off for the net ip data plane and i'm presenting it uh uh from the code or sienna fergus and andrew mills next slide please uh so uh this document is focusing on how to add the po functionality to the"
  },
  {
    "startTime": "00:50:00",
    "text": "that net ipp ip data plane uh it is listing the requirements for adding pre-off and it is also providing details how we can do that there are solution basics described encapsulation are also described in the document there is a detailed pocket processing it is also dealing with the flow aggregation topic uh and the defines in detail of the the pre-op procedures uh next slide please we are currently at version uh or one and there were these updates in the document it is quite stable so there were some editorial updates typos some grammar were corrected and we have received comments on the list in order to clarify that this solution is based on uh on tunneling techniques so this is what was explicitly added to the document the solution creates a set of underlay uh udpip tunnels between an overlay set of that net relay nodes uh the text of the document is quite stable uh so next slide please uh so just to summarize uh this draft is really leveraging the existing data data plane building blocks there are no new header fields specified this is a general solution verbs both for ipv4 and ipv6 and and pre-op defined for the dotnet service sub-layer the solution uh is applicable irrespective what routing techniques is used underneath the detonate service sub layer so any ip rooting techniques can be applied and last but not least it does not require any additional processing on transit nodes"
  },
  {
    "startTime": "00:52:02",
    "text": "the document is quite stable so we are asking for very loop adoption on on this draft thank you torrelis please go ahead so um i think we're stuck in the discussion about the point i raised we went back and forth and i think it would be good to have an audio discussion about that not necessarily here um in in the meeting but let's find some time afterwards because i don't uh think that i saw a you know satisfactory answer to the problem i raised with respect to the need to consider how the elimination function and the jitter or buffering that it necessarily creates can be integrated into any of the possible bounded latency uh calculi that we may use in a way that it doesn't mess up the calculations for um you know whatever shaping queuing or other processing is done for the bounded latency you were giving some explanations but i i couldn't make heads or tail a lot of them tell us my my understanding is that your comment was regarding the pocket ordering functionality draft and not regarding this draft no no was the the packet elimination function the elimination function which basically um you know creates the jitter when the primary uh flow uh you know let's say you have the a and b flow um a has the shorter latency b has the longer latency um and obviously um you know if all the flows from a come then"
  },
  {
    "startTime": "00:54:00",
    "text": "the elimination function doesn't really do anything right it just drops all the one from b but as soon as something in a uh is missing you need to forward the the same packet from b and obviously there is a lot of um you know jitter between a and b and kind of the differential path latency and taking that into account in a way that um we can simply drop the elimination function into the forwarding chain uh and don't mess up the calculus for the bounded latency of the queuing in before or after the the pre-op i think that that needs to be worked well through and it might actually you know uh require to have uh some you know buffering function in there to avoid pushing off the increased jitter into the poor calculus of the bounded latency shaping yeah um this is a clarification question what does that have to do with this document as opposed to am i confused here um because i thought isn't it isn't your comment just a general statement on pre-off as opposed to pre-op and ip i mean this document scope is oh oh sorry then then then i may have made uh that uh comment on the on the wrong document here i i don't think we actually have an active document that's your comment um they based on oh yeah no this is no i was talking about a personal document yeah so so is this but this is bringing in pre-op mechanisms that exist in mpls into ip and i think you're talking about the base mpls ish base pre-off in mpls and now wait a second so it applies to you know it's generally i'm not saying your comment's wrong i'm saying the comment is generally applicable to you know an rfc that we have and to any data plane yeah not only the uh [Music] comment i think it's a valid comment i"
  },
  {
    "startTime": "00:56:00",
    "text": "don't think it's a valid comment on this document because this document is just taking a mechanism that we already have defined and applying it in a different data plane so i think your comment is a good one and perhaps warrants its own separate discussion given that we have an rfc on it no i yeah i think it's the right document i think the uh yeah the you're right that that this is not specific of course to the you know um just yeah yeah to to the it is not specific only to ip i'm going to pull my uh joker card that it's a 4 56 a.m in the morning sorry perfect perfectly fine i think this is a great discussion i would suggest that if you run independent of this document because it's a general point that's stuart sorry so i am a bit confused as to why we need to write this document so we have um mpls written and that includes prayoff and we have a document that says how you carry that over udpip so do we miss something somewhere i mean i don't understand why inheritance doesn't mean that this just works and there's nothing to write but maybe i've missed something stuart i i think here the main intention was to to make it clear and obvious how it can be done so so i mean i would have thought that all wasn't the all that we needed to do then it sounds like maybe it's not obvious from the original documents is to write a one-line update to the udp document that says by the way you can do pre-os"
  },
  {
    "startTime": "00:58:00",
    "text": "because surely everything just follows and we don't normally sort of micro document things that are already inherited in the in our existing stacks i think we've um gotten uh a little bit better about helping people understand how to use the technology as building blocks so an informational document that says how to combine things you know has we've done those in other groups so i don't think it's off completely out of scope maybe one more thing to add is that the dotnet ip data plane document claim no pre-op for ip explicitly pre-offer ip but there is pre-offer mpls and that's what it was carrying now so maybe you need to write a document but it doesn't i don't think it really needs to be more than one line to say by the way you might not realize you can do this go and read these other documents uh even though the queue is closed we'll go to pascal and david we're way over time we're gonna just so as a heads up to other presenters we're going to end up squeezing your time a little bit reducing your time pascal you're up yeah so i'll try to be quick so we're talking about encapsulation and as we talk about encapsulation we and for ip right we basically uh lose the the visibility of the inner flow unless we have to dig deep in the packet so we end up in the discussion similar to the one we just had at raw which is basically how what basic what identifies a copy of the packet um you know the sequence number and and the flow id or something uh is is typically what we comes to mind in that row we kind of make a difference between the flow identification as being the upper layer udp thing versus what goes in ip and if you if you take that path it means that you need to have ipad ip"
  },
  {
    "startTime": "01:00:00",
    "text": "information in the ipad there is an accentuators and here we are saying hey we are tunneling and still we don't change anything we don't add anything to the to the others and so question comes to mind how do you find the flow how do you find the sequence counter i mean all this is needed so first of all sequence counters are needed only on the relay nodes and on the that not really you know into the list um just because we're way over yeah yeah okay so basically by my bottom line let's take it to the list i agree my bottom line is there are different documents which talk about the data plan for ip we need to reconcile this as opposed to just adopt one we need to understand why this what those different documents are saying and how that that needs to be combined or what right so pascal you're saying it's an implementation guidance document this is useful and so you're countering stewart's point correct not not uh i'm saying it's probably not sufficient uh we if we if we really want to do something in the ap later plane we probably need more than just a tunnel i think just a tunnel may lose that information we care about or it's never been there like secrets yeah i think so you're actually making a different point and i think that's valid is we should leave room for true ip solutions in the future all right david please go ahead last time if one is prepared to run the mpls or udpr or ip uh data plane end to end and i think stewart's comment is correct that uh there really isn't much to say however if one wants to imply encapsulation over only part of the path so that we're going to pre-off over part of the path without running that whole data plane end-to-end then there's some interesting stuff to done i think pascal's been busy uh been been helpfully exploring some of it in his comments okay thank you uh look forward to a good discussion on the list on this um clearly there's"
  },
  {
    "startTime": "01:02:00",
    "text": "interest and uh disagreement so uh should foster some good discussion uh the uh bellage you're up next uh you originally scheduled for 10 minutes gonna cut you down to five please i i will do my best yeah okay so this is about pocket ordering function and uh i have quote or stefan kerres tobias tobias here and janos farkas next slide please so this draft is version 2 and it is dealing with the situation that replication and elimination functions may result in out of order packets and this is what the packet ordering function uh algorithms can correct and restore the original packet order next slide please so the document is is quite stable uh we have uh added some made some editorial updates uh since the last version uh there were discussion uh on the list uh and it is also related that orless uh commented in the previous slot so we have made it clear that packet ordering function may cause delay variation however how to eliminate this delay variation this is out of scope in this document and dealing with the delay variation is a net forwarding sub layer target and it can be achieved for example by placing a digital buffer or a flow regulator like a shaping function after the probe functionality so this is definitely word for discussion but this is something that is out of scope in this document because this document is focusing on what algorithms you can use in order to achieve"
  },
  {
    "startTime": "01:04:00",
    "text": "the pocket ordering functions and we have also updated the security consideration part of the document referring to the security document and highlighting that these algorithms does not imply new security concerns regarding the post next slide please so we have the discussion on the list we have made some proposed changes updates uh we feel that regarding the prof algorithms how it is working this is something pretty stable we have received good comments for the previous version and and updated the draft according to that so here again the next step is planned to ask for very loop adoption thank you uh dollas we we can't take the problem of um being able to define um the latency calculus for um the pre-op function out of scope of when we're defining the prior function right just hand waving and saving this forwarding plane function so i think we should discuss that so because this was always the problem with with with the bounded latency that we need to have a linear model you know that every component we're adding to the path you know can be calculated by itself and you know not pushing off some unknown uh latency variation um to to to some undefined step yeah i i think this is why we have separated the sub layers we have defined the service sub layer dealing with protection and we have defined the forwarding sub layer dealing with the latency and jitter-related issues regarding that net flows no but i mean the the point is about pushing pushing from this document this function this component some undefined uh you know"
  },
  {
    "startTime": "01:06:00",
    "text": "later engines data off to something else is architecturally not the correct thing this is this is basically a you know a latency that needs to be possible to calculate for this function and then there is really the question does it make sense then to push off um the the problem of how to fix these things so that it becomes linear again to some other component yeah but we're running out i sent you an email let's let's find some time to discuss this more please okay um i i think it would be very good to get a informational document that talks about how implementation should manage that issue tourists i don't know if you want to contribute that or work with balaj to to do that and whether it's this document or a separate document um you know that would be i think really help the working group it's a good issue you're bringing up uh that implementations need to consider i don't think we're talking about changing any of the data plane uh behaviors it's really just the the calculus that the essentially the controllers have to do so it's it's a good implementation uh uh guidance document so that would be really nice worst case my contention is that we should consider that the elimination ordering function need to have a shaper um per flow in it like you know the uh the like the shapers we have associated with the queues and ats for example right the the cues are what we do on the interface and then we have the shaper for them and likewise the same shaper could be required you know for the elimination ordering function and that would be part of the elimination and ordering architectural component so that's the worst case look forward to reading the document thanks thank you"
  },
  {
    "startTime": "01:08:03",
    "text": "uh please proceed you have ten minutes uh yeah okay um hello this is pony from channel mobile and it's my pleasure to talk about the requirements of large scale deterministic network next slides please okay here is the motivations uh in the last entry meeting which may talk about if more queuing mechanisms should be considered the requirements were presented and would like to work in the requirement draft first so we submit the new draft and hopefully it can be used as the standpoint compared with the plantation at the entry meeting the new draft has more uh analysis about the large-scale domestic network influence the queuing mechanism and based on which we put up some new requirements and next slides please so let's have a recap on the different levels of application requirements and obviously of use case gave the requirements of industrial uh electricity buildings and so on some of them clearly specified the requirement for lateness let's say a jitter and well some not for the so far when providing uh deterministic network service network network providers always face the problem of how to match application demands to the technology um um so um the service can be um clarified one is uh uh one kind has critical as is such as remote control or cloud plc or manufacturing and differential protection of electricity and there are also some relatively lower levels of srv for consumer networks such as cloud gaming cloud vr the user of these applications hope to"
  },
  {
    "startTime": "01:10:01",
    "text": "have a better network experience but they can tolerate it to a certain extent if the network quality is not so good sometimes moreover uh such users are willing to spend more money for high quality network service and they need some aspects because they have no industry barriers and can tolerate exceeding the upper boundary of latency within small probability they have relatively lower requirements for the network and may be easier to deploy an excise please and here are some deployment and application status of literary deterministic network so we won't give some much explanation about it um just want to show that um [Music] this draws on both operators and enterprise users begin to put forward deterministic requirements for the large-scale networks but the used technologies are not exactly the same so you can see more work is needed for network service providers to successfully sell that net type service to customers okay next science please this is a requirement to a list according to the uh differential um application requirements um including the tolerance time uh synchrony and supports the large signal hope propagation latency accommodates the higher link speed this giveaway tolerates failures of links and all nodes and wg chain changes and the support incremental device updates next slides please quantum one is to tolerate time a"
  },
  {
    "startTime": "01:12:00",
    "text": "synchrony including four situations first is to support asynchronous clocks across domains and one of dennis objects is to stitch tests and islands together which may have different clocks and are not synchronized so the mechanism should be able to support the interaction across time domains the second is storage data and wonder within clock synchronized domain within a single time synchronization the main different clock accuracy is expected the large-scale network should be able to recover or observe such time variance within a domain and across multi-domains third is to provide mechanism not requiring phone full-time synchronization it is really hard to achieve the full time synchronization in large scale networks when considering the diameter of network topology and it is designed that the same performance in terms of the boundaries and the data can be achieved when full-time synchronization is not used such as the frequency synchronization used in the two trials and the last one is to support a synchronization-based master method due to the large amount of traffic in large uh secured network and some of them are a cyclic and and not all the networks or device support synchronizations such as ats um use perform based synchron uh nervous shipper to achieve boundary latency and the formula proof shows it effectiveness next size please um quantum 2 is to support the large single hoop propagation latency the distance of"
  },
  {
    "startTime": "01:14:00",
    "text": "transmission transmission transmission is long enough to generate a larger latency that line for cyclic based method the length of cycle must be either set long enough into buffer case or other mechanism should be provided and come through is to accommodate the higher link speed the large-scale network normally use higher link speed especially for its backbone and with increasing of the date rate the scheduling cycle can be reduced which requires a more precise time control and if the network cycle times remains the same more data constant which requires more buffer space which impose more complex buffer or qmag management and larger memory consumption next size please the requirement for is to be scalable [Music] it's inc include two aspects the increase or decrease of the network device influence topology and discovery mechanisms for example the ultra low latency of application spot network would require the net extent to every 5g base station which might be hundreds of thousands for one operator and for the massive traffic flows it is almost impossible to identify individual rb flow at the net plan because the larger overhead and resource reservation for massive number of flows so flow correlation is required individual flow may join and exist the aggregated flow rate rapidly which will cause dynamic in identification of aggregate than netflow and requirement five is to tolerate failures of links or nodes and tableau changes"
  },
  {
    "startTime": "01:16:01",
    "text": "network link failures are more common in large sql networks but switching or re-convergence of routing will cause high length of packet loss and retransmission which is usually in seconds before the network is stable again and it is necessary to support a certain mechanism to adapt to figures of links or nodes and topology changes next slides please requirement 6 is to support incremental device updates since some applications that require relatively low level of sle it will bring acceptable for those applications to tolerate a deterministic low probability to exceed the upper boundary of latency for those applications some simple solutions that may be realized by update and configure the ingress and egress device or part of network service network device are expected meanwhile they're critical as if some applications can be achieved by adding the existing or other new mechanisms and updating more service okay next guys please and here are some proposed q magazine besides test and insert service they are not included in the boundary latency draft which is will be published soon we list them and also give some analysis about the levels of deterministic uh synchronization or notes the cost stability and the flow aggregation the first one is based on as a frequency synchronization and multiple thick like cyclic buffers that can be proved to provide the boundary listening and the jitter it is used the flow aggregation and the scalability is also good um and the second um"
  },
  {
    "startTime": "01:18:01",
    "text": "uh is micro robust decreasing uh since it's interrupted but given the time i think it's important too um the okay requirements are really good but you don't have to discuss the alternatives out there or do a gap analysis to do the requirements and this is going to cause a lot of discussion and argument and it really is separate from your point about uh requirements so i think adding this having this in the presentation and the document is uh actually diminishes from the document so it may be best to remove it and have it in a separate document so we can focus on the requirements if that's okay and an interesting time to go to your next slide okay thank you thank you um okay um next steps uh wait wait wait more analysis and discussion about the requirements i will come and people who are interested in this work please contact contact me yeah and any comments the question uh in terms of the relationship of this document uh compared to the one you presented at the interim [Music] with which so what's the relationship between the two documents because it's a zero zero document uh yeah um i think this uh question may be discussed later after this presentation we we can take it to the left and i mean the question was to you like is it a replacement and so on because in the interim the takeaway was to develop the requirements further i got that but uh yano"
  },
  {
    "startTime": "01:20:00",
    "text": "let me take it to the list yeah okay uh is the person in queue uh actually i answer janos question so it's a quick answer very quickly yeah because i'm i'm one of the courses of this of just now the zero zero version and the one presented in the interim actually there was no mature um draft so basically the draft presented just now is the very first version of that so that's that's a quick answer for that what's what's being presented in the interim actually is a basically a collection of the information it's slide it's ppt slide space but there is no mature draft based on that that was i mean yeah let's take more discussion on this topic to the list and um then the requirements related to the queen mechanisms and do you consider other skill networks such as reducing a macro burst and enhancing their results and their roots i i did not hear you yeah so so uh my suggestion would be if you have questions comments to the previous presentation then please take it to the list and let's get started with this presentation because we are over time yes you have eight minutes thank you"
  },
  {
    "startTime": "01:22:01",
    "text": "start giving your presentation okay okay okay and so uh this draft is also about the requirements for the wide aerial ip domestic networking i do hear me your slides are already shared can you start talking to them i i i could hear you fine in previously but uh yeah she may be having a problem please please uh please proceed with the president yes please proceed yes please proceed okay sorry unless slide please is it only me who doesn't hear her i i see indications that he is speaking i first i can hear her okay i will proceed first uh we discussed about the possible problems with the wide arrow ip deterministical networking uh we divided it into two parts of the work they are deterministically networking and wide area network for this mystery network we should consider two issues first different services requires different shaded satellite cues for example 400 microseconds delay is required for audio and video but no more than 100 100 micro seconds delay should be guaranteed by industrial application second problems with resource location rules should be taken into account account for example resource should be located for the deadline"
  },
  {
    "startTime": "01:24:00",
    "text": "but it will lead to low efficiency efficiency of resource utilization uh for the roots uh the strict uh latency and the jitter commitment peru should be provided and it must not change due to the lateral changing it's especially in pref uh function like the owners proposed the latency and the jitter of the two disjoined rules uh we cannot have two big difference and cannot be changing moreover interdomains root should be taken into consideration and the second part for the wide aerial network the two features are largely older large-scale network and multiple dynamic flows there will be large scale levels overloads and long-distance links and they will impact on the latency and the jitter and the multiple capabilities will be existed such as flexi and sr turners and maybe multiple queen mechanisms are provided and co existed and finally there are also large number and multiple types over dynamic flows coexist uh so micro bursts may be emerged from multiple flows last slide please so uh based on the problems for uh with the white aerial ip did administer networking uh we listed the requirements uh based on the problems first is the differentiated the network uh differentiated the battle desolate queues of the multi multiple services their deflate flows could be classified based on their"
  },
  {
    "startTime": "01:26:00",
    "text": "data cues in the figure show for example over deterministic service can be provided such as low latency jitter and the low latency just low latency and so on second is the large scale network it's a it is required to reduce the size of the lateral topology and integrate their multi comp scalability resource to achieve the optimal beta data use third is the high efficiency of the resource and the rules resource classification and modeling is required along the explicit path with the route with the guarantees such as bandwides lanterns jitter and the packet loss should be provided the last one is the guarantees of multiple dynamic flows so shaping and their queen processing and their aggregation of multiple flows should be provided to reduce the micro uh burst last night so this is the solutions considerations for the wider area ip deterministic networking we for the solutions uh we suggest to solve it from three direction first step is to uh locate deterministic resources second step is to establish the domestic routes and the validity to achieve their deterministic accused so last night please so uh the the draft is also about the"
  },
  {
    "startTime": "01:28:02",
    "text": "requirement or for the large-scale uh or wide aerial um net deterministic networking uh we welcome the comments and this discussion thank you comments question i think it's the right direction to classify the categories of levels of use case but the problem is that whether it is the right time to be standardized now uh maybe in the future more suitable because in the previous draft we also mentioned that but we don't give the details of of it and for this draft i think um some details of analysis are expected and since it's a little um conceptual i think and another question is that we have two requirements draft and what i would ask what's the other i think about that yeah yeah thank you uh so for the first question brings you a classification uh over the deafness service and dirty uh the details should be provided um so we will um do the research and provide the details for the um classification of the data service not just their their uh not the nancy and the jitter"
  },
  {
    "startTime": "01:30:00",
    "text": "we will provide the clarification for the other requirements in the draft it looks like there's a good opportunity to discuss this builder on the list i think you know if we can look at having the documents be merged that would be great if not if we could figure out where there's agreement and disagreement thank you very much so i believe you're originally scheduled for 15 minutes uh we only have 10 minutes available for you [Music] yes please proceed okay thank you china um and this is a false version of the microphones decreasing in this layer 3 network for low limited traffic dropped next please next second this page will show some modifications firstly we adjust the catalog to clarify the purpose of the draft our purpose is to explore explore the methods to decrease microbursts in the network and we add a new session to analyze the requirement of the method to decrease the macro first and as an example we we show we introduce a method to decrease the microburst next page please okay this is a simple test uh from my colleague and we want to show this page to show that the"
  },
  {
    "startTime": "01:32:00",
    "text": "traffic has uh instinct or positiveness i i will introduce uh something about it the traffic passed through a 4g network and fixed the access network and they are between two cpes with gps a test package will be sent every 60 millisecond and the test lasts about 10 hours the minimal delay between the two is about seven milliseconds and the maximum delay is about 700 millisecond and the average delays is about 26 milliseconds it can be observed that the ip traffic has uh instinct or both he needs because we can see that some of the packet experience a long delay in the between the two cpes next page please okay we introduced three ways to disco decrease the microburst this document uh many folks on the micro bus on the interface which is different from the the micro aspects in the previous page but they show similar characteristics the three ways including includes uh the traditional ip in a light loaded network this second scenario is very similar to the situation of the last page and the second is the tsm mechanism such as cqf it means cyclic cueing and folding and the last method is introduced in"
  },
  {
    "startTime": "01:34:01",
    "text": "in this chart as an example to decrease the microburst on the interface next page please and this page will introduce the traditional ip in a light loaded network a network will be not will not be congested for critical traffic only if that the criterial traffic has a higher priority and there is only a small amount of critical traffic in the network uh however in in that night we want to convey more critical traffic in the network so this traditional ip method perhaps not super for the for our mechanism being considered in that net but uh the ipod has a good scalability because most in most cases only perpetuate the treatment in the forwarding node is needed but in theory every folding can only provide an unreliable connection as shown in the last page we can see that some sometimes a long delay is caused by the person in the network the next next page please the second method to decrease uh the microphones in the network is the tsm mechanism such as the cqf uh of course the ctsm mechanism all can provide a reliable path through the network uh in that net network uh the be traffic will be forwarded by using the traditional ip forwarding method and the deadnet traffic will be forwarded by using the tsa mechanism however the test mechanisms are much more complicated than the ip folding so"
  },
  {
    "startTime": "01:36:01",
    "text": "they cannot have a good scalability as the traditional ip40 does but we think that the scalability is essential for a large scale network next spirit please so we explore a third method we are looking for a mechanism that firstly it it can have a good scalability uh it is to say that the intermediate node should not uh perform a process on the data plan and it also can provide a better performance for the critical traffic it is to see that we can provide a different treatment for the critical traffic and then we go get a better user experience on the inter intermediate node we suggest to separate the process or control plan the data plan because we think that in a large-scale network the status on the aggregated detonate traffic on the control plane may change frequently uh because uh the the the track the net flow may contain a lot of subfloors and they are aggregated uh we should not assume that a control plant on the intermediate node can interact with the data frequently for example to change a shipper parameter frequently we think that on the date plan some self-decision process should be supported next paid please so uh we propose a method as an example in this method we can do the shipping on at the end edge and try to keep the traffic shaped on the intermediate node"
  },
  {
    "startTime": "01:38:00",
    "text": "we do the uh we on the intermediate node an intermediate node the graduated critical traffic will be shipped again as a whole on the interface uh we suggest some self-decision process in the shipping and the purpose is to maintain a reliable or reasonable buffer death while shipping the traffic the first step in our stock is that not to forward the packet as soon as possible as the traditional ip forwarding does because we think it is one of the reason causing the microburst on the interface next page please it's about the next time or the drop we will [Music] call for comments and continue to modify the draft and we also call for contributions from anyone who are interested in the work uh i think this is the last one last page and welcome for comments thank you any comments uh thank you for contributing the work and we look for a discussion on the list and uh anyone who's interested uh please uh uh you know contact the authors or make comments on the list uh thank you next up i guess tourists all right so this is about the um uh oh the title is wrong this is about the mpls um tech uh traffic class queueing uh for cqf next slide"
  },
  {
    "startTime": "01:40:02",
    "text": "so the the concept of tech cyclic queueing and forwarding was proposed to that a long time ago that was in um i really only get one minute sorry my counter is at 30 seconds maybe that hopefully that's wrong i'll there are too many buttons i just haven't updated it yet sure um right so um so we introduced that uh in 2018 first uh as a concept and you know got uh you know lost uh running around in itf working groups to figure out where we could standardize this um then we reintroduced the concept in 2021 with a new variation of that draft so i think you know that's that's why we said let's let's let's make make something that actually can be standardized by uh um you know writing down uh how this would actually work with the encapsulation that we have and otherwise complete data plan for which is mpls um and so uh the beauty is also that um it only requires uh some three to five values out of uh you know um a qs field and so in mpls we're using the traffic class field so we introduce and explain that work in the interim um so the 01 version added a co-author and that one thanks andy had kind of alerted me to the problems with the yang so i had longer discussion also with young expert and i ended up removing the yang references and text from it and replaced it with uh something that you know would allow us to forward to to carry forward with the specification independent of an additional yang model to to manage it um so that we don't get that conflation of of context in one document uh next slide okay just a quick summary so cyclic cueing and forwarding um is a an old technology from tsn that's"
  },
  {
    "startTime": "01:42:02",
    "text": "uh available um and used in campus industrial networks um with speeds uh smaller than or maybe even up to 10 gigabits it uses two cycles for the forwarding uh the main issues is that when you go to higher speeds the um clock synchronization accuracy requirement goes up linear with speed which also means that the cost of the clock synchronization goes up with speed and it cannot support um you know links of varying or larger latency because it is synchronizing packets upon receipt based on the receive timestamp of the packet um and not something in the packet so um you know the latency of the links has to be very small so something like a few kilometers so the the solution and that was even you know discussed in tsn but obviously adding a packet header field is always pain so that's why also a tsn didn't want to do it but that is really what is necessary to reduce the requirement in clock synchronization and its cost and then allow arbitrary long wide area network links and also links with jitter that obviously even in you know high-speed gigabit ethernet and other links like mobile links come through forward error correction and uh re-transmissions at at lincoln lower layer um so that technology is working in hardware so uh we we did prove that with um you know proof of concept hardware implementation just on fpga for that cyclic queuing and 100 gigabit um standard metropolitan and uh wide area network routers so at 2 000 kilometer range and less than 100 microsecond end-to-end jitter because that was just the cycle time and i'm not going to go in the details of how multi more cycles like shown on the right give you more uh variability in"
  },
  {
    "startTime": "01:44:01",
    "text": "you know jitter or clock inaccuracy but that's pretty much the reason to go for more than three cycles next slide so why is this important and that goes back to the two big challenges the operator we want to have a service provider class network solution for that net to be successful even enterprises want to adapt standard network operational models from service providers for anything that is larger than you know a building network so we do not want to have perhaps per flow shaper state for the bounded latency and cqf is the only relevant proven standardized option today and in this tcqf this tech cqf simply expands it to you know the tagging in the packet as opposed to derived from the timestamp and then of course the challenge number two and we heard that from the prior two talks as well most industrial tsn applications want and need low jitter for example higher jitter may incr introduce the need to run ptp in the network purely for client devices add ptp stacks to the client devices to resync control loops because of the introduced jitter and the current uh uh latency alternatives to cqf have really the maximum jitter right so zero queuing latency when there is no competing traffic and maximum latency under maximum um competing traffic so tech secure is my opinion really the only short-term option that solves both challenges um there are some other options but they would all require new packet headers because they can't get away with just a few uh values to indicate the necessary you know queueing state that we need to make it work um and and you know all of these you know additional options don't have any um i"
  },
  {
    "startTime": "01:46:00",
    "text": "think um deployment validation or standardization uh uh track record next slide so yeah so this is this is basically all the stuff that we could do beyond um this draft and where it gets interesting but also difficult um so and that gets pretty much to extension headers um for uh what we want to do um so we could do one for bounded latency now um for for for additional proposals but i think we should be careful not to do a one-off right so um and maybe you know in the matter of time not go through all of this but so there were other in in the interim there were other um you know options for uh low jitter brought up i also um you know published one particular mechanism last month so feel free to read up on that all of these options may have slightly different parameters mine for example has one time stem and then a sequence of priorities to achieve the same calculus that tsn ats has so that it can be pushed back but you know there are one of other things um you know um jack of stein proposed a stochastical bounded latency solution so i think all of this is much further out before we could successfully deploy it i hope we can and will work on it but so i think that that puts it in a separate bucket from the tcqf which i think is ready to deploy now if we had a standard to actually allow interoperability so which brings us to the final slide next slide please so here are pretty much my two asks right so you know working group adoption for uh this tech cqf draft and um you know if if that cannot be adopted because there may need to be charter changes uh let's let's try to figure out how to work through that process quickly i don't think uh it"
  },
  {
    "startTime": "01:48:00",
    "text": "really would need to you know be considered to be any different from the pre-op work that we're doing which also deals with algorithms in the routers and has since we started that net and then the second ask is to think about how we can get towards something like a net us design team with more regular and informal meetings uh yeah but thanks for the working group chair slides that you'll make the with the webex available so that's great too pre-off latency um not sure if there's anything else on the qs side um and then maybe you know start discussing there the uh the current drafts uh that we already have i want to bring into the working group for for the round one deliverables and then the round two um for these you know new packet header encapsulations what functionality you want to have there all right that's it thank you thank you dollas so maybe one one thought on um the working group adoption that uh uh perhaps uh so so we are developing the requirements and i think that goes before solution so i guess it would be good to have a working group document and developed by a working group agreed on requirements before diving into solution well i mean we've been you know on this for four years this is working we know the industry needs it this is this is not necessarily covering all the operational requirements that we have um so i think uh you know any of these larger scale requirements documents would be a broader scope then i think what we do agree to be you know uh the requirements for a bounded latency solution right and and and and remember that you know we don't even have anything for the other bounded latency solutions from the management plane either so i i think"
  },
  {
    "startTime": "01:50:00",
    "text": "there is no need to delay um this this this this can be pretty much done in parallel and you know if in my working group the the ads even wanted us to first work on the solution in parallel if at all you know uh work through uh you know the other aspect so i think that's that's always in the eye of the beholder how to sequentialize things so i i do think we uh have a charter issue to work um the shares can start working that with the ad and probably come up with some proposed text maybe you would get the id at least to agree with in principle and then bring it to the working group for review and comment and run that process and in that time it would be great to see more discussion and input um into uh in this document and we can run those in parallel um as i said right i think that that and i think that was a little bit the conclusion uh what you took down at the end of the interim i i think it mostly applies to what i had on my slide as the the second part which was you know uh looking into all these you know novel things as opposed to the very short-term things that we've also been doing with pre-off and where this air draft would fall into but yeah fine thanks yeah i mean we've had the discussion before the queueing has typically not been done in the routing area since this is um uh you know different for the routing area we want to make sure that the isg and the ad is fully on board with it i think just doing going off and doing it without their buy-in is just going to cause problems down the road when we try to advance it through the isg so again again parallel we can run it in parallel and um uh certainly uh try to have um a text"
  },
  {
    "startTime": "01:52:00",
    "text": "that is either uh complete or fairly mature by the next meeting well as i said in in one of the joint meetings i think we we did have the discussion i think that there were more people you know pointing to the fact that the work done on on pre-off you know is effectively also a qs function and that had been started we can have that discussion on the list uh it's not going to change we're going to work with the ad on this sure and the isg so i mean we can keep talking um but uh we're out of time on this slot more discussion take it to the list uh certainly technical discussion we're hoping does happen on the list um and with that we're on our last slot one this is about the bgp flow specification for the flat flow mapping next slide please so this knight listed the rfcs related to tsm deadplanes including display framework ipo for tsm mps over tsm and tsm vpn over mps so in the figure show the satellite may provided the deterministic service for the tsm and the system and the deathlet ip and the mps flows may be carried over tsn sub networks let's slide please so we mainly discussed the requirements for the flow mapping there are two parts over uh requirements for the flow mapping the first one is the primary primary requirements of the controller play for the tsn and desolate flows mapping the mapping between tsn streams and the data"
  },
  {
    "startTime": "01:54:00",
    "text": "flows is required for the service proxy function at data engineers and the mapping table can be configured and maintained in the control plane second one is the aggregation over deadlift flows one two one and the n two one mapping must be supported for example aggregating multiple tsn streams in a single internet flow must be supported so based on the requirements uh were provided in their listed offices so this document proposes extensions in control play to uh bgp flow specification for their flow mapping by using their traffic filtering rules to identify the packet and they're using the association associated action to map the packet to the related surface so let's just slide please so we proposed to extend the bgp flow specification for the tsn string mapping to that letter flow as we were learned the string identification function are defined in archery and so based on their existing uh filtering filtering rules this document proposed proposed earlier type in l2 components flows back type for tsm traffic filtering uh for example the uh mask in uh the max surface data unit unit in mask and the match screen identification"
  },
  {
    "startTime": "01:56:01",
    "text": "so uh moreover for the traffic action of tsn strings the action is to uh define to accept their tests and streams that matches the rule and the mapped extremes to the data flows so this document also proposes proposes the sequence action extending the community next slide please so and so forth there uh that last flow matching map into tsm string uh this document also proposes a dcw type in l3 components flows back uh for that letter mps flows uh the extended action for and data traffic filtering is to accept that flows that matches the death rule and the mapped flows to the tests and strings so uh the document also proposes a test action uh extended community uh the test profile can be converted to the string related permit parameters and requirements including ts string id string handle sequence number and the traffic scale scheduling information let's select list so a last step we plan to present and discuss in idr wg and we want to get more feedback uh comments and the discussion are very welcome thank you any questions comments two minutes jeff thanks luke i'm going to apologize i actually only caught a portion of the presentation after i was flagged about"
  },
  {
    "startTime": "01:58:01",
    "text": "this um you know i've read the draft uh very slightly uh i do see that it is doing much work with flow spec a quick word on that um the base flow spec rfc which is the version of the protocol is known to not be extensible so there is work that is starting in idr to do a flowspec v2 so i think you're going to find that uh some of your changes will probably require the flowspec v2 work in order to become a viable protocol component idr should be holding an interim on flowspec sometime uh very likely early december and we'd invite you to present there thank you thank you i will thanks jeff and uh i will uh change that uh extensions to flows back or version two last version but in this presentation i i i'd like to get some feedback for the requirements of the flow mapping thank you now from the uh i think the net side i think it's important to um qualify the document that it's really focused on tsn mapping not uh just generic net uh so making you know having the document identify its scope as tsn in the title the abstract the the narrative part that would be important in terms of the process standpoint i think we you know i think debt net is the chairs are happy for it to be run wherever the ad thinks is is appropriate whether that be net or idr uh sounds like it might be best to run it with idr given where um uh flospec is and what"
  },
  {
    "startTime": "02:00:00",
    "text": "jeff commented uh i see he's back in queue so i'd love to hear hear his opinion on this as well thanks luke uh so the the first thing i was going to say is that we do have i'm having trouble loading my agenda whether you're on the presentation slot or not but if you were not a presenter for idr's session tomorrow we do actually have some available time so please consider yourself invited to present if you not are already there and jeff after that um if you could let us know sort of what the opinion is of the group and uh we can coordinate with our ad john uh offline uh to to make sure this ends up in the right place uh that would be great okay and last comment for you to give your time back um certainly an idea we can help uh look through the php protocol extensions and you know much like other plumbing protocols uh it will be up to you guys to determine whether this makes sense as a mechanism for deadnet thank you gotcha gotcha thank you very much um uh find anything else you want to say before we end the session yeah thank you thank you jeff thank you i will uh contact the jeff and to see if we if we would like to present okay great thank you all for a good session uh really appreciate all the contribution and good work um uh janosh apologizes for not saying goodbye he had some audio issues but thank you all and we have a chance of maybe being in person the next time at least some of us so hope to see some of you at the next meeting bye now"
  },
  {
    "startTime": "02:02:07",
    "text": "you"
  }
]
