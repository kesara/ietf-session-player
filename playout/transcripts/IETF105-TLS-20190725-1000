[
  {
    "startTime": "00:00:15",
    "text": "all right morning everyone welcome to the second TLS session if you\u0027re not here for TLS you should stay anyways can you go to the next slide apparently this is working here\u0027s a note well you may have seen this many times so far so please note it well do we have a minute taker birthday Patrick thank you Jeff scribe oh thank you Jonathan all right blue sheets are going around please make sure you sign them to reiterate in discussing various issues and you know raising comments please be professional be polite be succinct at the microphone mistake your name to help the minutes taker and jabber scribe so this is our agenda first start off with a quick update and details 1.3 some quick bashing - we\u0027re gonna reorganize and put the return reach for bid I\u0027ll check and the connection ID draft after ESN I and then go through a bunch of individual drafts that had been brought to the working group for discussion so we went through this earlier this week so there\u0027s no change here and same so alright I guess we can just get started with UTS 1.3 there are no slides to just give everyone a quick update Dave Benjamin\u0027s have some very helpful comments and review of the draft which were incorporated in the latest update from Becker all of which there\u0027s one outstanding issue I believe occur wants to quickly comment on yes so I think I got all David\u0027s issues um there was like one editorial issue which somehow I\u0027m Minister losing can\u0027t find again but if someone finds it I\u0027ll fixate it wasn\u0027t major um the only outstanding technical issue is that the question of whether it should have to produce key separation between DL 7.3 and DTLS 1.3 so in recap in um I hold so tell us what went to a details remote do i do believe do not have key separation because they don\u0027t include a transcript in the hashes in quick what we did was we did key separation but not internal key separation so that the internal derivations are the same on my my intuition is we don\u0027t need this reaches 1.3 because we hash the whole transcript for the transcript will be different because all the version numbers not different the the entire Hammond messages get Marshall up and the head shake messages include different headers so there should not be possible these a detail some point through transcript for a tale some point to be transcript um it\u0027s also not entirely clear what the impact that would be even if so even if the leaf key even if the leaf keys were the same it won\u0027t be possible to substitute packets because the does "
  },
  {
    "startTime": "00:03:16",
    "text": "integrity Church is different so my intuitions don\u0027t do anything I can\u0027t actually prove that um I\u0027m curious if people think about how they want to result I think Martin has some thoughts resolving we\u0027ve fairly straightforward yeah but you know I can imagine number of ways I\u0027m changing these mention point changing the initial see the initial seed initial expansion seed so um people think we oughta do ski separation is not going to be expensive to do but um I I think when we did if ur quick there were some there are some sadness from employers about having to dig that dig that deeply their key schedule though that may be different with it staff which is well integrate these guys as opposed to quickly kill us yeah so someone Thompson the concretely the the difference between the two protocols aside from maybe the choice of extensions and all those sorts of other things is the message sequence numbers that we have in in the handshake messages and and to my knowledge that\u0027s really the only thing that we can rely on big difference that\u0027s court that\u0027s correct as the version numbers you know that\u0027s him right and I\u0027m not especially concerned about that I do want to I do think the property is is important I don\u0027t want someone establishing a TLS connection on the assumption that they have certain properties head of that and then get DTLS guarantees I think that would be not particularly great but I don\u0027t see any anything concretely preventing us from from a lie on the message sequence number stuff it\u0027s um doesn\u0027t seem that important how it\u0027s done yeah if it\u0027s if we are not sure we can we could easily use the detail s instead of the TLS string in the key derivation function we be done with it yeah that might be the easiest thing I have to count to make sure we\u0027re not over by one but I think we have enough room my recollection of the space that we had available was that we had a good amount of space though not a lot okay like 13 or something was the limit from memory okay well so I guess in that I mean I\u0027m sort of like I\u0027m tempted to be conservative unless I\u0027m pretty I guess the reason we didn\u0027t do it in quick which books to think or sad so unless someone is actually sad about this - which is to be conservative so I think what I was just is why don\u0027t I go count and if we have space we can just do it and if we don\u0027t have and if we don\u0027t have space in the back and ask we can choose a different string and tie like and Els one through something so just D yeah but is anybody sad about that okay I\u0027ll make that changes in your draft and I\u0027ll do whatever counting though I think kazoo ho and Martin are we asking you to help me count all right and so then efforts done did you have homework yeah we have a three interoperable implementation embed a "
  },
  {
    "startTime": "00:06:16",
    "text": "mint and NSS so at Martin gave a comment yeah so I raised a comment on the connection ID draft yes that I think also applies to to teaching less one point three so we should sorry that\u0027s on the agenda okay yeah so there is that other technical yes some problem that we have to think of it yeah and once we work through that assuming no change we will likely start the working with us call for that again and before with it right on that note do es ni all right so this is just an update on encrypted SNI there are a couple major changes that went into the latest version in particular there was a bug around how we deal with HR and potentially leading to nonce and key reuse so we fixed that with the temporary patch that basically uses two different labels when doing key derivation to avoid deriving the same keys and once\u0027s and using them to encrypt two different messages we improve some text regarding trial decryption for certain cases where you want to admit the record digest from the client hello yes and I extension for various use cases where that might be applicable we landed the greasy sni patch although David Benjamin raised an issue yesterday indicating that\u0027s not yet finished and not yet perfect so there\u0027s still some a little bit more work to be done there and we also move the DNS extensions out of the es and I key structure itself so that the new format is a you know a single structure that has an extensions blog for DNS things whatever DNS things you want to put in there that would be the address set that\u0027s currently specified or some other thing that might be specified in a later drop and then also the es and I Keys blog next slide please and then there are some minor changes as well just to kind of clean up some editorial nits and improve readability of the text and so on so I encourage you if you\u0027re interested just check the diffs for these thanks please so there are a couple there were several open issues the ones on the left are the ones I\u0027m gonna talk about today and these ones require some discussion and potentially some non-trivial changes to get right the ones on the right also are open and just require some more engagement from the folks here to sort of come to closure as to what to do particular compressing the server name and the client hello whether or not that\u0027s something we want to do there\u0027s not been much activity on that particular issue the greasy sand on extensions was preferring to get earlier from David Benjamin and then the Aeson I include the zone DNS Tony effects problem patrick has a had a PR that needs to be updated for that to address it in potentially we can do that at some point or we just you know do the HP service record thing "
  },
  {
    "startTime": "00:09:17",
    "text": "so anyways next slide please we\u0027re sort with a problem that is existing in the current draft so assume you had the the following topology where two servers in your suppose a phenomenon reset have different cypress tree configurations provided or just enabled for whatever reason so hosting on top supports both AES and cha-cha goes beyond the bottom only supports a yes next slide please and then suppose your client sends a client below in which he prefers a s over to cha and sends it along and some on path adversary interception slide please and then swaps the order of the cipher Suites such that cha-cha is preferred well he\u0027ll get back if he sends this packet to host a as a server low that has chosen cha-cha and if he since that over to host B you will get back a server low that only or yeah a server low that only supports a s therefore sort of distinguishing what host was used when connecting to this particular or when opening up this particular connection I mean this is possible night now because the only thing that we use for one more side [Music] right because the only thing that we bind to the es monkey extension is the key share in the client hello and nothing else and so this simple example kind of illustrate said oh the cyber sweets must also be bound to the east my extension but it\u0027s sort of perhaps not the best thing to the best approach to sort of patched these in a sort of piecemeal fashion so go add more and more things as we discover they they need to be found so ideally all non ESI extensions and content in the client hello must be bound to the sni extension and then we kind of just solved this problem in one fell swoop that would prevent probing based on modifying any parameters in the client hello because everything is bound to the s and I extension and by virtue of including the key share as part of that said you prevent the cut and paste attacks that are currently prevented so I think what needs to be done is to find more things to the ESI extension next slide please but there\u0027s also another example in this case assume the client hello same topology setup server supports the tooth host supports the same size tree configurations this client sends a client hello in which he prefers to try over yes and the adversary just absolutely nothing he simply just forwards them to two different hosts and gets a response back he can then distinguish what the sni value was based on a prior knowledge of what the ciphers we can support it so board ii cities are for those particular house next slide please there\u0027s really nothing we can do about this if a server an omni set of quotes "
  },
  {
    "startTime": "00:12:19",
    "text": "is configured in this particular way we can\u0027t stop an adversary from doing this sort of probing without modifying any of the client hello contents so ideally servers that are in the same anonymous that respond to climb level message is the same way for every done yes and I piece of the message yeah Chris I\u0027m not sure I\u0027m following this can you scroll back once like sorry so what is the relationship between these two servers there are different origins so different origins the different origins I\u0027m not assuming any I\u0027m just assuming that they\u0027re it\u0027s but supposedly in the same anonymity set right but why isn\u0027t why isn\u0027t is this assuming you\u0027re not binding in all the way does it be your assuming you are binding on the properties right yes right okay so the ever say doesn\u0027t change anything in the client although he just simply affords them but I guess my point is one of them shouldn\u0027t be answering right sorry one of them should be one of the I mean one of them only one of the matches vs and I yes so why is the other one answering at all [Music] yeah perhaps it\u0027s a grease extension or it\u0027s a greased TSN I value but I guess in that case yeah perhaps you\u0027re right what do you want to go to fall back if there was purportedly in the same anonymity set do you get the fall back yes I mean I mean there\u0027s a basic problem that I think that it I mean it certainly is correct which is that um that but I mean so David and I were talking at this I don\u0027t really see him here but um that you know um it\u0027s really the case that just by watching you can probably watching how the server responds you can learn whether it\u0027s here be because you learn whether chooses GCM or probably 13 or 5 so like Polly something like as a practical matter they have to be safe or speedy attacks they have to behave identically or you\u0027re just take your home yeah that I mean like probing a sign observational II if I just if I have the connection go through I can\u0027t figure out which one it chooses right so I think so I think like I also really have to behave ethically in this case yeah yeah thank you so yeah and to Martin\u0027s point you should fall back so proud Sicily not the correct example but the the underlying point is the same could he go for water slide please oh no no it was your it was the yet the the anonymity set the partitioning would slow it have a potential solution here I think what you really want to say here is that servers must produce similar choices for its server hello extensions and server hello rather than having completely identical responses across everything because once we passed the server hello everything everything is encrypted so if you have an extension that\u0027s responded to in encrypted extensions you are "
  },
  {
    "startTime": "00:15:22",
    "text": "allowed to make different choices at that point it\u0027s your I guess that your cryptographic configuration that needs to be consistent across all of those things in the same yeah that\u0027s more crisp incorrect yeah thank you they\u0027re itchy yeah yeah rich so like my yeah I was yes to what Martin said I assumed that it was always going that was sort of implied by the dock and it\u0027s not currently stated so and you probably explicitly state yes yeah make it explicit and point out the dangers of what happens if you don\u0027t do it Martin could you open an issue perhaps for that that would be great right so moving on so this is the the more interesting attack that came up in discussions with Eric and David and Stephen and it basically works like so and this is assuming the current draft client sends a client holo with es and I valid es and I another Greece extension to a particular host who sends back in HRR the on path adversary then by virtue of responding to an HR swaps in its own key share swaps an attorney s ni encryption of encrypted SMI value of whatever and then sends it to complete the connection to the server if the server doesn\u0027t check that the s ni value that\u0027s in the second client below matches that of the first or rather checks that the inner contents of the es and I extension matched that of the first client hello perhaps because he\u0027s made a determination based on what sni to use from the first client hello then the server will happily complete the connection sending the certificate and corresponding SMI value which is so I could based off the SMI value from the first client hello so the adversary can just finish the handshake and look at the certificate to figure out exactly what s and I or probable s ni was used to complete the connection this is not great so moving forward so ideally what we want is the server we want to require the servers to do this check and we can say in text you know the servers must absolutely check that the contents of the first years and I extension match that of the second otherwise fall back to the public name or do something but this is not really a cryptographic check in any particular way and it\u0027s also prone to implementation mistakes or servers you know people including servers choosing to you know skip over that part of the text in which case a client is still kind of in a bad position so ideally this would be achieved somewhat cryptographically and the proposal actually if you just go forward the proposal is to our a proposal rather open to suggestions as we\u0027re all open to "
  },
  {
    "startTime": "00:18:22",
    "text": "suggestions to include something from the ESN I extension in the key schedule that has the that has the effect of effectively binding that PSNI extension from the first client hello to the duration of for the rest of the handshake effectively and I realized that people may react negatively to putting things in the key schedule but I think of all the options that gives us the guarantees that we want in a pretty intuitive way so I mean of course subject to formal analysis from our friends yeah all right so Mountain Thompson to be clear here this is this is us making it impossible to do the wrong thing other than simply leaving that up to implementations and so at servers to do that on their own discretion and there\u0027s a number of ways in which people might take information from the first client hello and try to save effort in processing the second one and because this is a pretty significant cost in terms of processing I can see how that that might be the case yeah particularly when you\u0027re talking about using the innocent I extension to wrap on that first client allow so kind of need it on the first one there\u0027s a strong temptation there yeah exactly I don\u0027t have a strong opinion on what we do here but changes to the key schedule awkward but doable yeah awkward for a number of reasons like where in which direction does it go into the key schedule how do you like is it coming as a PSK but what would you do then if you\u0027re a resuming session has a PSK or put it in HD Sharon what if you want to do another thing that happens to modify the key schedule which will be discussed later yeah so the post quantum hybrid stuff yeah the draft that Douglas has is is actually a really good sort of formulation of how we sort of think about these sorts of problems and I sort of wonder whether we we need to think about this more concretely in in the abstract a little bit before we start taxing these sorts of things absolutely thank you thank you yeah I mean it seems like we should probably separate out two questions one what is the general strategy was to follow here the second is part of the specific mechanics of how it\u0027s done in particular as Martin suggests if we\u0027re getting to the point where we think when I do a lot of key schedule additions then it\u0027s probably worth cooking up some mechanism for doing that generally that that allows arbitrary and searches at each point um I\u0027m not gonna say I regret not allowing that before life is complicated enough but probably some problems solved now the thing I\u0027d like to understand that I don\u0027t think I understand yet is what the sufficiency set is for things that are going to solve this problem namely this efficiency set and we is it enough to just have something in the key schedule do we also have to do a digester or you "
  },
  {
    "startTime": "00:21:24",
    "text": "know a binding across the line hello I think we\u0027re getting complicated enough now that we\u0027re gonna need some formal analysis to reason about it we you know we had some initial puts on this but that\u0027s so super the next step probably rather than discussing exactly what to do here um is to sort of leave this is an open question and for input and then let the in and have to a small review will go off and like interface with you know Karthik bhagavad and Kaz and like have them help us work through the problems but I think no kidding getting new ideas like fantastic because a new idea is great we\u0027re trying to say which ones did you now seems like not very practical that yeah I mean we could even form like a design team of course to go off and focus on this particular problem the current thinking now is to do both the binding and the key said you assert it seems like be most conservative and kind of intuitively you want to include everything in the client hello into the extension but of course of the chicane based on analysis and outcome from discussions with our friends so I don\u0027t know which of you is first I believe it was me Jonathan Holland CloudFlare and so I\u0027m currently trying to write a draft on how to inject stuff into the TLS key schedule without breaking all the formal proofs with Chris so that is definitely something that we should probably do but just a question on this you comment on why this can\u0027t be done in exactly the same style as the PSK binder so you just include the same stuff as the PSK binders would have included you mean have the yes-mo extension be the penultimate extension in the client hello just before the PSK binder well I wouldn\u0027t define it like that I would just say the truncate client hello doesn\u0027t include things that say they aren\u0027t included and all of the ones that aren\u0027t included must go at the end because you know you can\u0027t do cyclic hashing so yeah that is one of the options yes it\u0027s the issue with that is that if we have to do this again for whatever reason then are we going to start just stacking up extensions on the bottom of the client hello what about the ordering for these things and it it becomes tricky and there are other bubbles as well to do the binding I\u0027m not I\u0027m not proposing a specific solution right now I\u0027m just saying perhaps we should do that we should do the formatting but yeah this is one of the reasons why I\u0027m trying to define the layering thing this Young Christian rhythm oh yeah I mean when I see this business of incorporating all es and I all client hello extension in DSN I you know I just went through the motions of updating casual code from the drug co2 to the grazie Audrey and are some cut paths that become really witty you have "
  },
  {
    "startTime": "00:24:24",
    "text": "to go to all the extensions because effectively you get valuation of who\u0027s on top and and if we have to solve the who\u0027s on top of that oh I am the SNI extension and on top but no I\u0027m the bisque extension on top oh it\u0027s that kind of stuff is not healthy yes I would agree so so I would very much like you said it whatever secret we treat we inject that secret somehow to make a binding but we we don\u0027t require all these chaining of extension and interdependencies because it makes the code very fragile to be clear are you suggesting that we don\u0027t need to bind the things like the cipher Suites beyond the key share I don\u0027t know that we need to find none of them or just one of them but I would say that a requirement to bind all of them resource in code that is table to maintain sure we\u0027re just this proposal is trying to take the conservative approach where we might you know say we minted this I receive just I mean the only thing we included with Kiesha in the service suites and we discover oh shoot there\u0027s this other parameter that could possibly be unbounded and used to break yes and I we just have you best to forget avoid that situation and doing everything does so basically like the fact that I mean \u0027if we somehow inject the result of the secret into the handshake key then we are guaranteed that an attacker will not decrypt the handshake fear the accurate handshake and then we are only concerned with what leaks in the clear text cell hello and that becomes a much more tractable solution not quite funny but perhaps we can talk about fine I think Becker yeah I mean the message here is clear we went through a couple cycles of this and clearly we\u0027re not you know the trolls yet the reason about it so I think what I\u0027m interested in doing as I indicated earlier is getting the tools to reason about it so I\u0027m perfectly happy with all the suspenders approach in which we have several things and that may in fact be valuable for other reasons as we\u0027ve discussed um but what I\u0027d like to understand is what every individual component riding is doing and which attacks is stopping so that we have a complete model of attack picture because it seems like what happened here and you know not maybe anybody cuz I was involved this is just anybody else but what happened here is we had a partial ma TAC model and so we closed attacks we know about but then we didn\u0027t have a way of reasoning about all possible attacks so I\u0027d like to get the point where we can resolve possible attacks so that we know we were doing their thing and then if we need Alton spenders on then fine or if we determine the bottom spenders is good also fine but I just wanna sure I understand what everything is doing a yeah great thank you and yeah there is some research on exactly what you would need to include in these scenarios by Kartik so we "
  },
  {
    "startTime": "00:27:25",
    "text": "should ask him absolutely he\u0027s on our list actually quickly go back I\u0027m sorry so the the issues that I just described led to these three questions the first of which i think is a we have a very clear answer for do require that server serving the same boundary set sort of behave identically yes unless anyone objects to that you know speaking out for peace we discussed the binding issue so perhaps continue that in the smaller team or on the list or whatever and then relatedly will work on how we do the binding of the first and second client below and the HR case yeah Kyle how nekritz I think if we make the number one an absolute requirement that the most sense prevents any changes in a distributed system at all so I think we should make sure we know the implications of exactly that like absolute requirement yeah so I require I don\u0027t mean like put a must in there like service must do this but like they should do this if they don\u0027t here\u0027s what here\u0027s what could happen Nick Sullivan closer I think yeah question number one does complicate the deployment pretty significantly and I would not be in favor of firing that it\u0027s different if you even if you\u0027re using a single proxy various web websites or domains will have different configurations for different reasons and forcing them to conform to the same cipher suite said is is not necessarily going to work I would like this DNA and anybody set to encompass as many domains as possible rather than singling out the ones that have special requirements I suspect this is mostly just a text editorial issue I think we\u0027re in agreement that yes ideally servers that have similar configurations are that there\u0027s many servers in the same and only set that have this particular configuration not like all the servers that are under control of a particular operator looking shaped exactly the same way but yes about suppose I anger it respectively yes and I it seems kind of undesirable to have entity generating the HR our client follow be able to be different from the entity generating the original client below in the first place in TLS maybe it\u0027s a more general problem than just es and I\u0027ve fix it or TLS itself where we can guarantee that the entity generating that new client hello during the HRR is the same as entity to generate the original client alone in the first place so are you are you asking are you saying we need a mechanism - yeah I do let me move that "
  },
  {
    "startTime": "00:30:25",
    "text": "the client who sends the second claim hello is the one that sent the first one yeah I mean like there\u0027s nothing specific - yes and I hear right it\u0027s just a TS and I exposes this thing like we don\u0027t get the privacy properties out of this because there\u0027s a law unanalyzed case in TOS in such a way and so we expect it to get these privacy properties but we didn\u0027t get these private properties can we fix TLS 1 3 2 such that we\u0027ll get these privacy properties back from the TLS protocol itself well you don\u0027t need these hacks for yes and I but it\u0027ll just work generally for any other extension that we had in the future yeah very good point I think I\u0027m next so on this question one certainly we can it\u0027s possible to not require that all servants a matinee missus behave identically but probate this is the point of the comments making earlier that definitely does leak information because the way you think about this is imagine that you have an enemy set of K servers and K minus one servers all prefer AES GCM and the K and and the case server and the other remaining server first chacha poly so all I have to do is what watch the transactions and she actually comes through a shop Holly I know it must be that Kaiba it\u0027s one server it\u0027s like that\u0027s not a probing a tactician observational attack and so like as David Benjamin pointed out that\u0027s not as good as a program attack but it\u0027s certainly a plausible attack and so they send to which its head to which servers don\u0027t you know don\u0027t have the enemies that maybe I know they don\u0027t petition to me set in some ways and there\u0027s not really much to do about that and rich Inglewood I think and the advice don\u0027t want to be do the best you can have like uniform configuration and you know yes and I is not a pretty is not only a perfect defense it\u0027s a partial defense and but the advice is that just pursue a movie set though so the circumstances thank you right can you tell us I was gonna say this I think so this one thank you benkei dark you know I had been thinking similar things to what suppoed was thinking about you know is this a more general question and I think we did briefly consider this when we were writing kill us one three and we concluded that we didn\u0027t want to make the server have to do the work all the time to keep the state because didn\u0027t matter that much and it may just be that the conclusion here is if you\u0027re gonna do yes and I as the server you have to do more work seems reasonable rick stalls like am i just on the server side to echo what the browser side said yeah if they\u0027re not looking the same then you can partition them operationally so don\u0027t do that yep don\u0027t shoot yourself in the foot Erik now go knock my 10 plus one to what Nick was saying if we especially in question one if we can provide guidance but if we start trying to enforce things too much it\u0027ll just require lots of fried it may be mean that people operationally destruct splitting things down and defeat the purpose Thank You panel microts as far as a question of this being a more generic prom I think one thing that\u0027s special about this is that we do have we do have the potential to use "
  },
  {
    "startTime": "00:33:26",
    "text": "some kind of a shared secret with the client key share whereas most extensions we do not have that and usually we\u0027re sending a HRR in response to not having an acceptable key share in the first place so I think this would be a little bit more difficult problem to solve generically yeah good point thank you all right so well continue that discussion on the issues and any issues in on the list the next big one is HP key and whether or not yes and I should adopt it so for those of you who are not familiar HP key is hybrid public key encryption basically EC is but in with Kem\u0027s and Dems the contract for HP key is that you generate whenever you encrypt to a public key you generate a new fresh P share effectively at for each encryption and there\u0027s a cipher suite that says exactly what algorithm you use for doing that encryption algorithm any açaí currently we basically do EC is but diffie-hellman and we reuse the key share currently meaning that in on getting an HR you would send the same client PSNI key share that you sent in the first one and the cipher suite used to negotiate which particular algorithms for DCIS is sent using sent in the east and I Keisha are using the TLS cipher suite spec forward so the benefits of HP adoption here are that we don\u0027t roll our own crypto and we use something that the CFR G sort of blessed in a way the drawbacks beyond it being an active draft currently and still under act and under construction and still you know in need of analysis are that by changing the es ni key share effectively on HRR you are forcing the server to do another public key operation and processing that that might be a deal-breaker I\u0027m not sure so I mean there may be other benefits and drawbacks as well perhaps Martin you want to raise one young man Thompson the the size of the packet starting to get pretty big so you if you have to put two separate caches in you\u0027ve expanded that you see space and we have primitives but the flipside of that is that we have primitives that reuse of a key share it doesn\u0027t work for and so we need to be aware of that so we were looking at s idh for instance and you can\u0027t reuse a key share in that context sorry the eastern a key sure is already separate from the client hello key show you some handshake oh right sorry but yes there\u0027s also the issue you\u0027re mentioning about right if we were to go back there would be that issue yeah David Ben David Benjamin so I think it might make sense to look at this after we sort of sorted out all the like binding stuff because that might change the things we want out of our "
  },
  {
    "startTime": "00:36:26",
    "text": "crypto box thingy for instance I don\u0027t know if hpk lets us derive some like random extra key to stick in the key schedule and so if we decide we want to do that then this might constrain us so I would suggest we like make this decision last very good point I agree with David\u0027s vision with a slate from the amendment which is let\u0027s sort out what we need and if it\u0027s close enough to HP key but not exactly HP key let\u0027s call Casilla for G and tell him to change it I think Richard is in the room hopefully and I\u0027m sure he\u0027d be willing to change it so in for since we wanted you know and you know I don\u0027t know you call it but HP key plus and slurry random output like that seems like pretty easy to generate so presumably like let\u0027s you know the purpose of the work in you know CF 4G is partly to support the work here so all right yeah that\u0027s certainly approaches well one more important issue hopefully can get this really quickly and that is of split mode currently the drafts supports both shared and split mode in the split mode case basically the the client facing server has to send some secret key material to the back-end server right now we suggest basically doing that by sending it prepended to the client hello on the TCP connection encrypted under symmetric key that the two endpoints have been to share and you might want this for some use cases slide please next way so benefits there may be use cases that require this drawbacks of course that this does add complexity to the document in it depending on one\u0027s perspective and they might constrain the things that we could possibly encrypt you might imagine in share mode and ease and I would only share mode you could potentially encrypt more than just the SMI like AOP and etc it\u0027s also potentially part of a more general protocol that Ben will be talking about a little bit so I posed the question to the group should be included to what extent or drop it Erik or scroll again the document is not really included or not included it just says this is consistent with its operational mode and then it has some hand-waving about how you implement it so I\u0027m not quite clear on what complexity is being is being added here if we get to the point where including it we\u0027re having a docking which can paddle like I see as a requirement rather than as a function in this protocol maybe be requiring it to be compatible with the split mode if it turns out that that crime is like clothing with a lot of pain we can revisit it but until then I\u0027d like to have the requirement key to be written down so that we remember it because I think it is an important use case where maybe we can\u0027t get them all but like let\u0027s not let\u0027s not like shortener sites until we know we have to would you just quickly assuming like the proposals that "
  },
  {
    "startTime": "00:39:26",
    "text": "Ben came up with was fine would you be okay like referencing that instead of describing sort of the thing we have currently well I mean if you need the thing we have currently mean the ridiculous hand waving at the bottom about how to like sense yes yeah yeah totally okay that part is fine but I think that it\u0027s important how the preparatory material it says like supposed to work this way so that people remember how that\u0027s supposed to function so as we work on the document and we\u0027re up great okay okay yeah this is Daniel can go more so I definitely think this is an important requirement for this case they\u0027re going to be people who want to operate a protected server in the back end that can\u0027t share the content with the front end server so yes please make sure that this stays is a requirement okay see ya agreeing with her and TKG also there might be more than one way of doing the back end of this bit mode in future so I think we keep the requirement I\u0027m not sure we want to normally say here\u0027s the 101 true way of doing it in this documents that\u0027s fine with me yeah so we can update the text accordingly just maintaining the requirement and then describing potentially one life one might go about doing this and I don\u0027t think we have any time for the rest of it so please take a look at the issues there on the github page or on the github repo comment I will try to summarize the what are the big open questions that send lists encouraging people to comment and regarding the earlier more non-trivial changes I guess well if anyone\u0027s interested in working on this particular problem we can get together with our formal analysis friends and kind of breakfast Oh Christian raised his hand and I\u0027m sure they look people who we\u0027ve been talking about will be interested as well so I think that\u0027s it unless there any end of the questions great thanks connection ID [Music] I try to be brief so the connection ID topic Dissidia at the moment three documents I would like to talk about um the first two on the top are the connection ID for the me TLS 1.2 the connection ID for the 1.3 which is in the detail s 1 2 3 specification itself and then there\u0027s a new document on the bottom and I will get to that in a in a minute it\u0027s like so this is the the regular behavior so you if you remember and I\u0027m not going to repeat the the use of the connection idea again but we had regular client ID device talking to a server via NAT and the not obviously changes the IP address source IP address and and the port as well typically and so you have the connection ID in the payload which associates the or links to "
  },
  {
    "startTime": "00:42:30",
    "text": "the keys and the algorithms so everything good so far the not makes these modifications and that\u0027s exactly the intended behavior next slide unfortunately late in the in the process we found out that we be missed an important security consideration it\u0027s really a shame actually because some of us worked on this in a mobility space beforehand so you should have actually noticed it but blanked out on that so here\u0027s the case imagine that Dennis and on path adversary\u0027 who is kind of like a gnat but is able obviously to change the source port of the packets that pass through and so he changes it to redirect the traffic to some remote server any in case there is an asymmetry between the traffic that goes from in this case the client to then finally the victim then this adversary is able to make an amplification attack that\u0027s obviously a problem what I didn\u0027t describe in the slide is the case where there\u0027s an off pass adversary who injects some packets but thanks to like obviously there are properties of DTLS with authenticated packets that\u0027s not possible because the attacker can\u0027t mint the packets with the correct key to make them pass through the security checks and so you wouldn\u0027t update the the finding in your database to send the returned traffic to this newly indicated IP address without actually checking the cryptographic parts of the packet models it is a small amendment here the adversary does not necessarily need to be directly on path there can be an observer that is what\u0027s the next size of packets here right going to the next slide yeah actually this is this case so we talk about this one that you just raise Martin you see the slight shift of the box in my great drawing skills so the as Martin said there the attacker doesn\u0027t need to be on path so it\u0027s not he sees traffic flowing by but he can\u0027t modify it but what he does here is what this color coding is supposed to indicate he basically after the packets from the client to the server pass through that grocery B plays a packet but changes the source and an IP address and port and as a consequence if the server doesn\u0027t check for that replay he would send the traffic to again to the victim so the other "
  },
  {
    "startTime": "00:45:31",
    "text": "observation here is that routing on the Internet is not always ideal and so you might end up with in a situation where the adversary has a faster path and can they they can copy a packet and replay it and be the real pack to the server it\u0027s a it\u0027s a race condition thing but you\u0027re also able to mount the same attack without relying on the anti replay properties that you know there might be implementing yeah so in some sense we don\u0027t necessarily you don\u0027t necessarily need to enable the anti replay protection which we TLS offers you could rely on a newly defined rule which we haven\u0027t added to the document yet it\u0027s in a github repository Aztecs but needs some discussion on that the server needs to before sending it to this new IP address he would actually have to check whether this is indeed the newer packet in terms of the sequence number and so on even if the reproduction is disabled that would be one possibility to deal with with this case so that that would only deal with the case where the an old packet was was copied it wouldn\u0027t deal with the case where a live packet was raced to the server true if you go back one slide of course there\u0027s also the possibility did not do basically black hole traffic which is sort of what this figure is supposed to indicate needless to say that if there\u0027s an adversary on along the path he can as well just drop packets without having to reroute them unnecessarily that\u0027s also a possibility so what I\u0027m trying to get to here is that we have updated the DTLS one or two connection ID traffic some text to describe those threats and also the Daedelus 1.3 specification to include the discussion of those what and that\u0027s if you go back to the second slide there\u0027s there is a new document out there that provides a DTLS based return route ability check which is this document at the bottom there is of course also the possibility to expose these address changes up to the application layer protocol via the TLS or detail a specific API I and let the application deal with it that\u0027s possible as well in some cases for depending on what type of application traffic you have these issues that I just talked about may not be as severe as they look like because for example in coop you typically don\u0027t have or you don\u0027t have this one message to the server and then a huge amount of messages going back because of the stop-and-wait nature of the of the protocol it has a congestion window of "
  },
  {
    "startTime": "00:48:32",
    "text": "one so so that\u0027s not there but in a generic case one could imagine that DTLS is also used to secure traffic where you have a high asymmetry and then making use of those return route ability checks specifically provided that the DTLS layer makes a lot of sense yes amount on something the other thing to observe here is and I\u0027ve got a credit Eric here who\u0027s sitting out of there Eric Kinnear has done a lot of analysis on this thing for for quick and there are there are a couple of other cases that you might want to consider in your throat model depending on on the decision you make there\u0027s a good write-up now it\u0027s it\u0027s a it\u0027s in a pull request on the quick specification I can send a link to that to the mailing list the returned your ability check that you describe does not necessarily cover all of these cases adequately unfortunately and so there\u0027s a there\u0027s logic that you need to apply in both both endpoints in fact in order to make sure that you\u0027re not subject to attack so I would encourage you to read what we\u0027ve done in quick and read Eric\u0027s analysis event and I would suggest that you copy that design let\u0027s not do this to us yeah we obviously looked at the quick text and that\u0027s a good idea that\u0027s also why we decided to have a separate document on this because it can advance independently of the other stuff for those cases where that type of concern is is big enough warrant the return routability check procedure and i think it makes sense to have something at the DTLS layer very much like you guys did in quick workers Cola so I think there\u0027s two questions here one of technology and one of perhaps three one of the layering on a document structure so the when we decided to add the connection ADT else one point three the general concept was that we\u0027re gonna have the machinery that you would need to do the connection ID because I said look at the transport layer but that any of the machine we need to handle the changes in connection changes in IP address we put somewhere else and I think that this existence this RC document is a good example of why that\u0027s a good design decision because it means that we can worry about the migration case while continuing to let the base protocol dance and this is the same decision roughly made for details one point two so what I think we here\u0027s life suppose we do but for technical reasons and also for expedience reasons I proves that we say in the two up two drops up top of this the CID draft the CID Gotham one point three draft here\u0027s the machinery for connection ID and DTLS shouldn\u0027t automatically do any kind of response to this issues except the packets as it is in should and should not adjust the pure "
  },
  {
    "startTime": "00:51:32",
    "text": "address and then it should say um here are some considerations about what you would generally need to do and her adjust the peer address and um and they pits responsibilities of the application or some future extension light bill or he draft to tell you how to actually do that and that lets us advance the wire format Mechanics for people who need them and then on and then and codifying the return reliability check with quick and get it and get the right answer so that\u0027s how I program oh yes sorry my question was whether that meant at the PR number 70 on the CID draft goes away after finding a little bit but I think um I think no I think I think it needs to duplicate the text did see in duplicate the text that\u0027s in one well when you take the Texas at one point in 1.3 and the PR number 70 harmonize them and then land them of both places and they\u0027re roughly correct but I think that the the thing that is in 70 that is not in the 1.3 one is a little bit disgusting about the general kinds of conditions are wouldn\u0027t your honor which would be safe to you know maybe get maybe do a fast response and also a prohibition on the do clear prohibition they de lost activate itself it would be nice if we have the same text in 103 and 1.2 currently and there\u0027s different text in in those two documents I think it would be nice to harmonize with so you you\u0027re gonna work on that on a plane somewhere we put some separate flight for this you\u0027re on the trail you guys are gonna run for a long time and you can talk it out Eric Kinnear Apple so one high end we should definitely talk that would be great it\u0027s looking at some of the attacks I think one of the pieces that is most interesting here is the hand how you handle when you notice that you\u0027re receiving duplicate packets that potentially share a connection ID or or not where some adversary in the middle that\u0027s observing your packets is racing them because I think that\u0027s one of our only identified paths towards kind of being a little bit more resilient to that kind of attack and it seems like there\u0027s a little bit better chance to harness some of that here then there isn\u0027t quick so I\u0027d be interested in chatting more about that offline and see if we can kind of merge some of those things together hey Martin let\u0027s keep it quick yeah non Thompson I think you want to move all of the migration pieces into this doc into this RC draft and actually talk about that as a migration document based on personal knackers suggestion wonderful we have our marching orders thanks thanks alright come back to us so "
  },
  {
    "startTime": "00:54:41",
    "text": "this is by way of an informational presentation more than anything else and information two ways I supposed to tell you about it and get people\u0027s feedback the context here is well that there\u0027s been an increased interest in having an ache which has smaller messages or is generally smaller this was initially prompted by some of the work in wait for the firm they differ IRT to have compact key exchange yes so um the question is like you want a compact key exchange like what do you do so we feel like an enormous my time on one three getting it right or at least as right as we know how to get on skype mr. Feeny why you studied with all these papers with like a lot of implementations it\u0027s already a pretty large fraction of traffic from browsers and we\u0027re seeing increased on other places as well it\u0027s like a fully general protocol or at least maybe too general and we\u0027re already seeing a lot of attention points like you\u0027re seeing subsurface and and maybe it\u0027s RRC staying in yes and I but like what it really isn\u0027t is not super compact the original design wasn\u0027t that compact and we didn\u0027t like really make much effort to make it more compact but a few places we try to shrink things down but generally this was not a design goal in large part because so many the applications of TLS involved certificates and certificates are so large that basically that dominates the size of the packets next slide so there but it\u0027s turning out there are other applications where people like to have much smaller much more transcript first of all all not transcript - I should say a much more wire image this is I say initially prompted by some work on IOT but also we separately had conversations in quick about how big like the quick messages are and how nice it would be if we get them a little smaller especially in the client hello we\u0027re we\u0027re narrow or narrow your strained at the first twelve hundred bytes um unless you want to have some sort of extra machinery is david benjamin is pointed out so the two general approaches to fixing this or addressing this one is to keep the protocol general but just like trying to cut out all the gratuitous encoding overhead so TLS is full core true this encoding ever had a very common idiom will be to have some damn map data block which has length defined and then have it be a vector of things which has a length in front of that and so now you have the length of the thing and you have the length of a vector and like those are complete duplicative but they\u0027re still there and it\u0027s especially this is actually a real source of engineering defects by the way or you\u0027re like right on you\u0027ll forget yesterday like you have like the extra length field you forget the interleague field and you have in our uh problems i\u0027ve made this mistake a number of times i\u0027m sure other people have as well you\u0027re gonna move all the redundant life fields there\u0027s also lots of places where we have like fixed length length fields for things which are almost never as big as they ostensibly are supposed to be so a really common pattern would be like handshake messages can be up to two to 24 bytes long i don\u0027t think it ever seen to 24 byte handshake message unless someone deliberately made it that long by like adding a bazillion certificates so I think Barnes and I made pathologically made one one day on the plane but generally it doesn\u0027t happen but nevertheless you\u0027re always consuming "
  },
  {
    "startTime": "00:57:41",
    "text": "three bytes for the length of the of a handshake message all the time so this is a gratuitous and again this wasn\u0027t a big deal when like when we did one three because there\u0027s plenty of room but if you want things do small scriptures and so we have variable it\u0027s possible to replace those are very thin to jurors and these get smaller there\u0027s also a number of places where you have values which you could say we\u0027re explicit or implicit where they might be implicit so a good example here is that if you only support one one with the curve type then why are you bothering to say here the curve types of support and here are the key shares that go with it so you can imagine saying look I just gave you the key shares and I\u0027m not going to take any others - don\u0027t bother or like bothering me with an HR there\u0027s also some places where it looks like there\u0027s been excessively long crypt of variables the random is a good example it\u0027s not really clear we need a 30 talked at random now of course we all like chewing up a bunch of white but we increasingly using up that space for various kinds of Sentinel values so it\u0027s not clear how much room we actually have left but it does seem like you slim that some there\u0027s also some questions about whether or not we may finish earlier because face is quite long so this is effectively just like TLS 1.3 with a better encoding and uh and it\u0027s and so you basic and morphism between 1/3 and and and ctls and it\u0027s pretty easy to convince yourself those the same protocol and if you look at all the analysis working the proofs all those all analysis work was basically done without really looking at the where encoding and deal anyway and certainly doesn\u0027t pay much attention differences how long the length field sign so that\u0027s like strategy one strategy to which was tested by cross the bhagavad is to sort of give the other direction and say let us like remove generality and instead basically have a compression layer that takes sort of your fully general TLS protocol and then compresses into a reduced version that goes in the wire and you probably want some kind of explicit or implicit rate parameter that told you what that what that compression has just look like and then what you end up with is a very small wire transcript but what you probably want to do is then we decompress that into like a full TLS transcript that you feed in everything and so you think of it\u0027s basically a compression layer between those two um this is I think has the nice property yes hi and I\u0027m a native English English speaker I\u0027m struggling to follow you at your pace would you mind slowing down your speech little no sure please thank you right would people like you to restart this slider so just continue so as I say that you probably want to eat the transcript and then we expand it back into the full TLS transcript so basically you have this tails two point three for all the key schedule etc on this essence the advantage that been all the things that you were essentially compressing down get be we get like we we materialized back in the transcript so you know the negotiation is correct this probably this may or may not require some kind of cross protocol defense to avoid having CTLs talk to TLS four point three you can think of that as a feature or a bug depending on the perspective so that\u0027s why I say you may not want that on either approach it has "
  },
  {
    "startTime": "01:00:43",
    "text": "like the reasonable chance of keeping the existing proof valid which is the main thing we\u0027re trying to do that that the main theme here right is we have a protocol which is spending those that we spend a lot of time engineer and we spent a lot more time engineering adding these two we\u0027d like to continue getting value out of that while still having a compact on protocol rather than having just have a separate line of compact protocols that then have to increment only be in it be extended all the same ways that we\u0027re sending TLS to give you a concrete example of this I was 80 back when we did the conversion we did colonel and so we had this process of having to like incrementally add curve to five five one nine everywhere across the IETF stack and it was this is a giant effort of like crossing out like P 256 I\u0027m writing to five five one nine it\u0027s not happy to do that very nice if we were wanted to say say add post quantum next slide so here\u0027s like a concrete example it just shows how much like redundancy we\u0027ve managed to create here\u0027s like the client holo that stray up tails and point three client below so the first field is the protocol version which now we\u0027ve abandoned because need ago she and supported versions the second field is the random value which is as I said 30 to our hats long the third field is the session ID which by the way we\u0027ve abandoned because we now we do PSK be the fourth field of cipher suites you\u0027ll notice that has a two plate length field and can allow you to have 65,000 bytes worth of cipher suites now we haven\u0027t defined 65,000 sorry 32,000 Severus wheats and I can\u0027t imagine any sensible person wanting to advertise that money so there seems to be a fair amount of extra slack here that you don\u0027t need on then we have professional methods have our mentioned removed compression and then finally we have extensions and again the extensions could be up to 65 kilobytes long which like is pretty long and you\u0027ll have lots of reasons to believe you might only need like a couple hundred bytes of extensions typical client hellos range in there sort of 200-300 bite range for this area example I am a big person that you think of bestowing the transcript because if you remove the legacy session ID which is at a give you a damn number I mean your transcript is gonna be somewhat affected yes so this you would have to you would have to not do like a simulator for this but one member that member that unless you drink a pat mode if that\u0027s an empty string anyway what advantage of recover of reconstructing the the entire original GLS three point three is that that makes it the the existing proofs trivially applicable because you could act like you\u0027re actually sending the full thing even though you\u0027re falling sending much smaller that\u0027s the intuition that Karthik gave us so next slide so this is what you can do if "
  },
  {
    "startTime": "01:03:44",
    "text": "you\u0027re like trying a little bit and really only a little bit so you say well look the protocol version will cut it under one plate because we don\u0027t have a zillion versions the random was linked by half because we don\u0027t Lanie deep 32 bytes again we don\u0027t need a lot of cipher suites or make them one pipe long then we remove other things that we didn\u0027t need the version of string becomes shorter V and then we take say for sweet so we have a variant length on the encoding for the length and so you don\u0027t need to burn up to us extract at on like and oh by the way oh I forgot to mention the extensions fields you\u0027ll notice has its own length field but it\u0027s not just a however the vector is even though the extensions takes up the entire remedial message it\u0027s like simple subtraction will tell you how long the offenses field is so once again you have extra slack next so that hence you say basically these tensions field now is there in the message so if you take this treatment and you like apply it to tell us as a whole you can actually a pretty substantial amount of reduction in message size um so this is like strategy one strategy to next slide if you really like to really go crazy and like have like you know here is like a mail i cup say three or four octet profile that describes exactly all the cryptographer parameters you can do really well you can have like the initial bite contain all of the cookbook variables which is to say if the random and if you Hellman key that zero is like over the zero like I\u0027m not have any circumstances in which zero beating South to pull value for a few min cake but in any case so you can really shrink things down if you try hard next time so I regret that I didn\u0027t have like the original versions because it trust me that these numbers here are like much smaller than the number of you started with um and um so you do a pretty good job next slide so this is like pulmonary work hence informational there are another obvious places to do optimization we\u0027re working with Bhagavan other people too like basically the other see see what we have to do make sure we have enough isomorphism the proofs actually carry over because that\u0027s the whole point of exercise I see Jonathan Lawson\u0027s that\u0027s on that on where she will try and decide whether we want to follow the compression strategy which seems like more compact analysis it did where I spent the transcript but I think the converse is about this week um we can beam very much towards capacity expansion Adam Adam Angley so you presented your two options but they\u0027re not mutually exclusive right you\u0027re going to be doing both yes yes in fact one of the things you might do with a transcript compression is do those Russians yes so you cool the the numbers you had on the benefit seem kind of small but is this worthwhile though that what is the the motive for like stripping off a few tens or twenty bytes basically so normally these IOT use cases where basically incredibly small microphone exercises and they\u0027re trying to get within like they\u0027re trying to get "
  },
  {
    "startTime": "01:06:44",
    "text": "inside of like three packets instead of like five or six because the these queries not the way protocols oh no sorry these this is this is a this is not a good slide because it doesn\u0027t show of you where I heard it ah okay so typical tools client what was more like you know more like 150 bites kind of thing okay so yes thank you sorry yes thank you for putting that up yeah for ten bites I wouldn\u0027t do it here Ben Schwartz I just would like to suggest benchmarking this against plain old compression like maybe broadly with with static dictionary it\u0027s a good suggestion thank you and also you might even want to consider putting that on top of this you could do both I\u0027m Lester thank you so good suppose I hear you in just a clarification question a near example you said client flow but are you applying the same technique do DLS cipher text records and yeah the draft has it has a whole thing for all these things yeah there\u0027s still plenty of places to turn the crank but yeah I expect this might be redundant but just to make absolutely sure the intention here is to show isomorphism as you say in this slide right and then to provide whatever arbitrary transformations during that demonstration so you could for instance apologies you could for instance use a single byte and have a bit in the byte to say the presence of any of these fields and then interpret you could do protobufs whatever that is the intent correct yes awesome yeah I mean the ultimate objective is that you should be able to take any new extension to TLS it\u0027s just go directly over so you get it for free when you want to do in this compact though that\u0027s the like ultimate objective so then connect I saw in jabber but I didn\u0027t bring my laptop out just to check this is still assuming like inorder reliable transport I\u0027m sorry but I just can\u0027t hear you at all this is still assuming inorder reliable transport yes yeah although you would of course like you could obviously have a CD TLS as well right deep there\u0027s actually um the vast majority the overhead of the test handshake of course is in the TLS handshake it\u0027s often not in the TTLs extensions but those are also fairly bloated and so this places to remove things as well yeah and just a different point with my own hat you know if we think about this sort of as a TLS for you know one octet version then that\u0027s sort of just like non non backwards compatible and we can you do all the stuff the way that would make sense without this historical legacy so kind of make some sense for your applications was my question somehow relate to produce is there a well is it a completely new but to call incompatible "
  },
  {
    "startTime": "01:09:46",
    "text": "with jealous 1.3 or can we do it somehow negotiation whether the compact encode interval encoded it\u0027s used so they see Telus clients can talk to full-on put three their last service yeah there are couple of angles there I think one angle obviously would be to have you know to have a like non CTLs quite hello followed by the server sending you see TLS another angle would be and this is the one perfect and I talked about is to have sort of a translating device who only gets the who doesn\u0027t get any of the eight key material but only gets the the only gets the a ad key material and that can do these fashion internally so we listed a bunch options input in itself can count for example if you put some magic value in I don\u0027t know where tion field that will turns that it is compared encoding yes I\u0027m not I\u0027m thinking device you need it thank you right so we had to cut the line and let\u0027s keep it I guess it\u0027s the sink it\u0027s a GL so I think you basically just said this but if you want to keep yourself honest and convince yourself that this is a security irrelevant transform implement it as untrusted shims like on either side that\u0027s in fact that the importation you have is does is is that it yes I the numbers on the slider from an implementation we did in mints which is implemented in exactly that way it\u0027s there\u0027s a compression there interpose between the handshake and the transport if you do that I think you have very good confidence that you haven\u0027t broken this QCD remaining welcome you mentioned the wafers in a document predetermined side for sweets is a potential compression candidate do you have any thoughts as to you what a what a server would be expected to do if a client tries to actually negotiate negotiate would be pretty different cipher suite and the server does not know what that client Cypress we would it be dropping back to to to you a TSP TLS handshake I think in that case we fail and we fail I think so yeah which will have some other thoughts but I think that you only that you get the mat I mean the maximum compression you get is if like basically you have pretty right right yeah it\u0027s like the usual compression trade-off like the more you pre-negotiate the better compression you get and in this experiment that we did we kind of turned the compression dial all the way to nail everything down and see how far we get I expect you know when we look at you know the comparables and ad hoc there\u0027s likes a little bit of negotiation in there I think they have like a couple of Cypress Suites they can negotiate so I think as this develops my answer and discussion I think this will go on the lake working group but as we have the discussion some of that will be added in but probably in using some of these you know optimized encodings that the Necker mentioned said you have whatever a little bit of "
  },
  {
    "startTime": "01:12:46",
    "text": "negotiation we need to to make this work d mine and I have quite sensitive now I think we should need to take it to the list we got some other I\u0027ll be like nothing is so people wanna talk hello i\u0027m double steel from the University of Waterloo and I want to talk about our draft on design for hybrid key exchange in TLS 1.3 next slide so just as background there\u0027s been a variety of interest in using multiple key exchange algorithms in the handshake as part of a transition to post quantum crypto and a variety of internet drafts Huynh implementations over the past few years I the idea to focus on key exchange rather than authentication is that we\u0027re concerned that quantum computers could retroactively Li decrypt but they can\u0027t retro actively impersonate parties I so the goal here is to develop a framework for using multiple algorithms simultaneously next slide one thing we\u0027re not trying to do is pick a particular post quantum algorithm we\u0027ll leave that to the NIST post quantum standardization process next slide so at the last IDF meeting Chris presented on our behalf the first draft which contained a menu of design options on overall design aspects so how to negotiate which algorithms and combinations should be used how many algorithms can actually be combined just two or more than two how to transmit the public key shares and how to combine the secrets the feedback we got from the working group was to avoid changes to the key schedule and to try simplify the menu of options and down to a couple of candidates next slide so that\u0027s what we\u0027ve done in the draft today there is still the menu of design options just so that\u0027s kind of reference we\u0027ve got two candidate instantiations which I\u0027ll talk through today the first option directly negotiates each algorithm and separates the key shares the second one kind of follows what some of the implementations have been doing having code points for each defined combination copy also added a new key DF as suggested by someone in the mailing list next slide so in the first instance iation we\u0027re kind of taking a proper approach where everything is done separately so this follows an earlier draft by William white and others I the algorithms are negotiated individually so there are new named groups called hybrid marker 0 hybrid marker 1 which don\u0027t actually mean anything in themselves they\u0027re just pointers into a hybrid extension where each marker is mapped on to the groups or key exchange methods that are meant to comprise that onto each part you can suggest as many combinations as they like and they\u0027re indicated with these hybrid markers and we can allow you know multiple algorithms we put a maximum of 10 but there\u0027s no reason that you can couldn\u0027t have more than that next slide so once those have been listed in the "
  },
  {
    "startTime": "01:15:49",
    "text": "negotiation we have to convey multiple key shares one for each algorithm so in this approach we use the existing list of client key shares send one key share per algorithm and so we don\u0027t require any new data structures on this at least in the client hello are they server hello as it stands doesn\u0027t allow for multiple key shares to be transmitted so we have to kind of hack that in and so the way we\u0027ve put that in the document as it is is to have a data structure encoded inside of the existing a share server hello that basically concatenates these key shares next slide then we have to combine the shared secrets so once the key exchange has been done we have the cryptographic keys on and in the approach that we\u0027ve got here on the slide are these key shares are concatenated fed into a key KDF and then the output is put into the TLS 1.3 key schedule in the place of the existing diffie-hellman key share so concatenate KDF and then use it as it is now okay so that\u0027s the first candidate on the next slide there\u0027s the second can to get so this follows more what some of the implementations have been doing and this is a simpler approach from an implementation perspective on you define new code points for each combination you want to consider so you can see we\u0027ve just extended the named group enum here to list new combinations so P 256 with postpone and algorithm 1 whatever it ends up being P 256 plus quantum algorithm 2 and so on and there\u0027s no internal structure to these code points it\u0027s just a new code point and then on the next slide to convey the key shares then we just conveyed the concatenated public keys for each of these new code points so this really requires no changes to the structure of negotiation or any negotiation logic everything is just a new key exchange method next slide so to compare these the first instantiation we have new negotiation logic and a new extension to convey these the list of algorithms but it doesn\u0027t require any change in how the key shares are conveyed or it doesn\u0027t require multiple groups to be defined for each combination whereas in Canada instantiation 2 there\u0027s no change in negotiation logic or protocol logic we had this combinatorial explosion of named groups and you might have to send duplicate key shares so you wanna advertise P 256 with algorithm 1 and P 256 with algorithm 2 you have to send to P 256 shares so those are kind of the trade-offs between these two instantiations next slide so we\u0027d like some feedback on how to proceed either these options being more appealing and then what the procedure should be for document this hey thanks for doing great a great presentation there we have ten minutes for discussion Jonathan winning CloudFlare it\u0027s obviously as someone who did one in the formal analysis analyses I\u0027m very against changes to the key schedule and I think actually your first approach "
  },
  {
    "startTime": "01:18:53",
    "text": "could be wired into the key schedule in a sort of standardized way and given the other things that we want to do with the key schedule we should just first work on standardizing how to inject new keys in to tell us okay so we have a few options in the draft IV I mean I\u0027ve been discussing with Chris our manly option number two it\u0027s not worth all that complexity to save 32 bytes don\u0027t mess with the key schedule we\u0027ve already shipped it looks great yeah benkei doc so I mean in terms of the trade-off I know I\u0027ve already told us what to do but you know sort of a question of if you have a pretty good idea that everybody is going to be doing the same sorts of things same sorts of algorithm combinations and it\u0027s pretty clear if it\u0027s like totally out there and you can be trying all sorts of random combinations that\u0027s when you may want to be doing it independently it\u0027s basically the same question is why the tailless cypress wood means and you only took some that out forty on three all right thanks yeah I don\u0027t think it\u0027s clear at this point how many algorithms there will become honest whether it\u0027ll be two or five they haven\u0027t given indications yet so that may affect the decision going forward what\u0027s not going to have a large number of algorithms that aren\u0027t being combined most of the time it\u0027s gonna be 250 states or curved 55:19 combined with some post quantum algorithm and there\u0027s only going to be sort of two out where that was being combined so I think that motivates being the second option for how you do combinations declare a hybrid hybrid Sabra sweet mutton Thompson I\u0027m gonna speak for candidate two as well and option two I don\u0027t think I think that\u0027s been implied in the discussion that you got here but I want to say that explicitly one of the things that you kept saying throughout the presentation that irritated me a little bit was you kept saying concatenation which is not necessarily injective so we want to make sure that\u0027s that\u0027s crisp in people\u0027s minds because that\u0027s kind of important if we talk about things that aren\u0027t simply fixed sequences of octet now I think most of the things that we operate on use that as both inputs and outputs but we need to be very clear on that point thanks thanks yeah for the key share we\u0027ve definitely got a data structure encoding for the shared secrets right now we\u0027re just doing actual concatenation but with the proviso that this doesn\u0027t make sense that they\u0027re not a fixed length Marko NCSE I\u0027d like to thank you for bringing this draft of the working group but I found it a useful reference I\u0027d like to speak in favor of option one here I think it\u0027s good to have the informational document that "
  },
  {
    "startTime": "01:21:53",
    "text": "describes the different ways of doing these hybrids and they\u0027re the pros and cons of each so I think that that\u0027s useful I can see scope for both of these actually but I think they doing one in the first place would be good I\u0027d also like to speak in favor of 20 key options in there for having their the hybrid designs to be as general as possible so possibly incorporating more than two algorithms into the hybrid and the possibility of combining classical algorithms as well as just most continents in there people have been as okays people have been assuming that nist will only approve to our rhythms or three albums that may be the case however each algorithm of that they\u0027ve been under discussion have multiple parameter sets and we\u0027re likely to want each premier set to be treated separately instead of only having three algorithms we might have a total of 12 parameter algorithm primer set combinations and that should needs to be kept in mind I think Watson said what I was going to say I drew just enjoying standing up yeah so Martin Thompson in responses just got there I think this is something that we would ask well I would want us to ask for CF RG to address because I don\u0027t want to have I mean this explosion of parameter sets I want one option preferably maybe two and that maybe two different options and there may be different sets of options for different use cases but ideally it\u0027s one maybe two for the use for any individual use case that makes sense yes miss always under specifies these things and where the ITF has not then finished a specification bad things have occurred right right and I mean PSS is an example of that and it\u0027s pretty hard to use and that\u0027s got like two parameters yeah yeah when it finally happens we will have to nail down all the parameters but even so I\u0027m not worried about a combinatorial explosion because the first element of this tuple is always extra five five one nine because who is doing modern stuff and still using p2 five six yeah I agree thank you doing this hi so this is as mentioned on the topic of of yes and I split mode next slide so I\u0027m going to use the term load balancer here this is maybe an idiosyncratic usage of the term but the load balancer is this thing in the middle that\u0027s doing the splitting or the forwarding or the proxying I\u0027m gonna call the load balancer I am particularly interested in "
  },
  {
    "startTime": "01:24:54",
    "text": "a kind of load balancer that I call an SN I proxy so that traditionally has been something that inspects the SN I and then forwards to a back-end that is determined by its SM by the connections SN I and the nice thing about SMI proxies is that they don\u0027t terminate TLS so they\u0027re in a sense they\u0027re the highest point in the stack that doesn\u0027t terminate TLS is the most information you can get while maintaining end-to-end to it TLS next slide so the motivation for this is split mode es ni and I\u0027m going to draw a distinction here that I don\u0027t think is clear yet in the yes and I draft between partial and full split mode so the the key difference here is that in the es ni draft you must know the es ni private key in order to reply and formulate a working server hello but if you have a variety of backends and they all have this private key then you have a widely shared private key so for example if you are operating a large commercial service or adversary could simply sign up for your commercial service learn medias and I private key and then use it to decrypt s ni on the wire so for that reason we would ideally like to have full split mode where backends do not have the years and I private key but under the current specification that that means that they can\u0027t answer in the server hello next slide so parses that mode is kind of the new term you\u0027re introducing here right if they\u0027re real it\u0027s not a real thing that we\u0027d never want or is it like the ES and I draft uses the word split mode to describe both of these things in different places with him draft personally I never considered that middle line is something that anybody would want and it\u0027s if it\u0027s covered by the description then maybe the description is not sufficiently precise maybe this is gonna be a rat hole but I\u0027m also surprised by this I thought that the way I\u0027ve written the specification aloud was designer and falsehood but it\u0027s of course possible I made a mistake so the I am if I remember the text correctly the current es and I draft says that you can implement split mode either using the encrypted Z hat or by sharing just pre sharing that was dumb if I did bring Katy it sounds like everybody only wants full split mode so maybe we should just make that change next slide so there\u0027s this is not the only case where somebody has had a proxy in the middle of the connection and wants to send some information along with the connection to the backend the major case where this is done already is "
  },
  {
    "startTime": "01:27:54",
    "text": "in the proxy protocol which is almost entirely used just to inform the backend of the true client IP address which is no longer visible to the backend but it can and it has been extended to incorporate lots of other information especially actually when you are terminating TLS at the load balancer it\u0027s widely implemented and it\u0027s completely unencrypted and insecure so while we\u0027re in the business of trying to forward some secure information between a load balancer and a back end maybe it would be nice to set up a clear path forward for people who want to do that in a more secure way next slide so the proposed architecture here which is completely lifted from the es ni draft is to simply use a PSK that\u0027s pre-arranged somehow between the load balancer in the backend to encrypt some proxy data which is basically just a bag of data and that includes things you need in order to answer the yes and I if you\u0027re doing yes and I it includes the client IP address if you would have otherwise used the insecure proxy protocol and the backend just does some symmetric crypto to decrypt and use that info so this this is what the draft says currently and in response to the draft there was some very thoughtful and detailed analysis on the list and a couple of other architectures were proposed next slide so one proposal which I believe was made by Stephen Farah this is my attempt to capture a proposal by Stephen Farrell is to simply do TLS in TLS so rather than specifically encrypting the proxy data open a new TLS section between the load balancer the backend right the proxy data into that stream and then write the client hello and and everything that follows from the client and similarly the downstream responses from the server would be in TLS would be decrypted and forwarded to the client so this is is is very clear I think it\u0027s the the cryptographic properties are nice and clear but it is computationally intensive we\u0027re spending a lot of time encrypting ciphertext again jonathan Hoyden cloud player in putting a TLS session inside the TLS session does not give you clear cryptographic properties you have to bind them together using exporter keys on the outer one and then some magic on the inner one if you want to actually get the security properties you think you\u0027re getting yeah it\u0027s it\u0027s a lot more complicated than you might think christian we demo it when there is some you know work going on in the quick working group on the load balancer protocol i don\u0027t know whether you\u0027re following that there is a draft in the quick "
  },
  {
    "startTime": "01:30:55",
    "text": "working group related to load balancing i think eventually we are going to have to square these two concepts i think that the load balancer draft and the quick work group so far I think addresses largely separate issues mostly related to connection ideas and my diction it\u0027s correct but I mean yeah dad we dated like I don\u0027t air to pee on there was some theoretical research like I don\u0027t know how else to say this that was done before quick was announced to the IETF about client there\u0027s our intermediary assisted packet loss stuff which has many very similar properties and I suspect that you should look that up okay next slide so that another alternative architecture this is my attempt to capture a proposal described by Martin Thompson is to use an Oracle to decrypt the yes and I in the simplest implementation that would mean that the connection is forwarded to the back-end completely unmodified and then the back-end contacts an Oracle and asks it to decrypt the yes and I information this is nice and clear but it\u0027s probably too slow to implement in this literal way you\u0027d really want what I would call push Oracle you could imagine implementing this with HTTP to push but this becomes a really complicated and potentially flaky setup so next slide the my questions are should we be pursuing this at the ITF in TLS especially given that we\u0027ve also been talking about what\u0027s appropriate to go inside the ESI draft in my view there is an interoperability question here there is essentially existing work in the form of the proxy protocol for communication on this link it\u0027s not secure and I think it\u0027s worth trying to do better and I think that the use case in US and I is important and worth trying to serve and if people do think that there\u0027s work worth doing here then there\u0027s an architectural question you know which direction should we be going here before we really hammer out all the details long Thompson I\u0027m not gonna get up to talk about the details of the protocol but I think we also have a third question which is an organizational one which is where work "
  },
  {
    "startTime": "01:33:57",
    "text": "like this happens if we have working a quick working group that is addressing a very similar use case it seems to me like this straddles this working group and that one it would not surprise me if there were other people that had similar similar uses maybe maybe this is something that needs to go to sec dispatch or dispatch or I don\u0027t know Jenn area let\u0027s put it in Genoa yeah I\u0027m sure Alyssa would love you yeah I mean generally enthusiastic about this I don\u0027t have fun with the details that carefully so I\u0027m going to pine on them yet Martin\u0027s probably right that we do need to think about where this ought to go perhaps what I see area directors that\u0027s very helpful but perhaps some of the considerations ought to be what the security problem how much is a security protocol versus like an application information protocol um my suspicion is it\u0027s actually a security protocol based upon the comments but other things like that that if we don\u0027t think about the security aspects we may be sad people but it may also be the case that the the question the security questions are well isolated and can be you know can be handled separately you have a secure transport and then like figure out the binding mechanics then just stop so I don\u0027t know yet but might be more useful or work on some of the other cases of what kinds of information you might want to carry in this protocol and then we have some sense of where we were I dunno if there were a couple maybe members of my clan but yeah that seems like a question the baby in the SG should think about you where to do this work so y\u0027all duplicate efforts jonathan oeid and clapper again I do think that there\u0027s like in three drafts and there are six currently adopted drafts that all do basically a very similar thing from a theory level in terms of like finding stuff into TLS so maybe as a working group item we should start considering how instead of doing exporter keys we do some sort of importer keys and not directly but like there are a bunch of drafts that try and do this we should just solve it Steve yeah so I think we should standardize a solution it should be you know done we shouldn\u0027t do something stupid basically and I don\u0027t I don\u0027t yet know what architecture IDEs recommend I think I did some or Eric nygren Akamai um yeah this topic has come up a few times I remember even I think in the first HTTP workshop this came up as a big topic because the current proxy protocol or the Kirk proxy protocol isn\u0027t really with air quotes isn\u0027t really standardized and there are plenty of "
  },
  {
    "startTime": "01:36:57",
    "text": "cases where vendors will ask for implementation of it but in but the lack of security here does not make it appropriate in a bunch of cases where it\u0027s being used but any finding something that is efficient enough that\u0027s probably closer to your first one is going to be important because if we just do this but totally change the shape of it no one\u0027s good it may be that that it\u0027ll be hard to switch implementations away from the curve from somebody\u0027s current insecure use cases okay thanks I think the outcome here is to talk to the 80s and figure out there\u0027s some grander plan that we can figure out what to do with all right thanks yeah back to the plan of coordinating between the is Jean ivy we\u0027ll put it on the agenda to chat one product so if Nygren talking about I\u0027m gonna be talking about a proposed HTTP service record next slide the topic of this conversation or the motivation for this came out of a number of conversations have been going on it came out of ES and Ikeys discussion where as we\u0027re looking at having this ES and I record which would be a new record for clients to go look up a lot of complexity around how to handle things like multi CDN and proxies and other use cases kept showing up in it and yes and I try to solve that as a well what ends up being kind of a more holistic problem solely in the context of ES and I started creating both either a complexity risk but also a composability risk of how when some his next issues start coming up we\u0027re gonna have to try to cram those into that yes and I record or maybe we should take a step back and look at some more things more generally on one comment on these slides is that that these slides are from before we actually presented an HDTV best and there have been a number of conversations since then and I think one of the big open questions that that\u0027s come up is is how much would make sense to go and generalize some of this beyond just the HTTP use case and I\u0027ll talk a little more about that later but some of the top things at least on the HTTP front that are that there\u0027s a desire to address right now in parallel is the encrypted S\u0026I keys that we\u0027ve been talking about here on transport protocol and how do clients start using HTTP 3 and quick without having to go through I redirect through on the a legacy TCP protocol is another one that is another one that comes up and how do we can bootstrap into that via DNS especially if there are better end up being better privacy properties if you can go straight straight to quick rather than having to go go through it tcp on indicating origin default other than origin defaults to http so that we just have this that when someone puts a a bear name into a browser and types in example.com being able to have a clear "
  },
  {
    "startTime": "01:39:59",
    "text": "way to say hey this goes straight to HTTPS without having to do that redirect through it clear text HTTP and having a more secure default on next slide so the approach here is to look at things that is having a single new record that browsers can resolve in parallel with the a and the clients can resolve in parallel with Inc on in parallel with Ain the Inc soiree and particulars is not really browser specific despite what this slide says on the but also look for some of the extents that is is have reasonably good usability from an operational perspective and has some performance optimizations baked into it so which we spend a lot of time on the yes and I key side of how do we make this so that doing this extra lookup minimizes the performance impact impact an overhead number of round trips but also having it be extensible enough so that when we want to handle the next case beside beyond the few that have been identified that we can add this in in a reasonable fashion but also something that is compelling enough for to convince clients to implement it because when talking with the DNS off group over the years and they have a specific issue around a the zone apex problem and what and which they built S or the SRV record to address a number of years back and there\u0027s some frustration on the DNS side of hey we created S or V we kind of meant it to be for the HTTP use case client never really started using it and so something that can break this chicken in the egg of of ok we\u0027re gonna introduce in your record but convinced both enough clients to implement it but enough server operators and and yes providers to implement it may help them get past some of the standoff here but also gives and I think another goal is look at Israel way to to especially as clients start using doe or other things is there a way to have more more secure defaults we can move to this help close out some of these these kind of insecure by default straight to http and then having to upgrade up to our use cases next slide so the general approach here on has is you can look at it as being somewhat similar to extensible SRV it\u0027s that and a reminder here is it within DNS if you get a bunch of if you get a bunch of individual our our sets back there\u0027s no wouldn\u0027t necessarily associate them so if you if you do a resolution for a a es and I record meu do a resolution for a record and a quad a record on there\u0027s no way to determine that those actually came from the same source in a multi CDN case some of those may have come from one CDN the others may have come from the other CDN so if fundamentally what you need to do is have something where you have a single resource record that kind of binds the number of attributes together if you look at even SRV SRV does this by saying saying for this given name that i\u0027m trying to look up here is a a kind of this this the actual "
  },
  {
    "startTime": "01:43:02",
    "text": "server name and the port number for that and associates that together because you may have different because you may have some server names which implement some ports and other server names that implement other ports so HTTP service basically takes that and extends that and allows additional attributes to start getting associated onto that in a particular case for TLS yes and Ikeys becomes one of those but you could we could potentially see other things being associated on there in the future next slide the I won\u0027t go into great detail in in this here this was probably more some of these details of being talked about in more detail in in the DNS and DNS op and HTTPS there are two there are two forms for this I won\u0027t go into great detail on this forum but if next slide the alternative services forum is the one that the on yes and I keys which would come into play for the HTTP use case there\u0027s a within it you have a service roommate a a service name that indicates what the name is or if example SVC three-dot example dotnet would say that when you\u0027re if you go to SVC three if you want to if you\u0027re on the top line here for me is would be be for example that if you\u0027re trying to get to SVC dot example net you should use SVC 3 dot example not met over quick to put on to port 8000 3 unclick with a particular set of es ni keys or you could go and use SVC 2 dot example dotnet over HTTP 2 on a different port with potentially a different a different set of yes and I keys next slide so one of the questions that come up on list is as well as in conversations is what\u0027s the relationship of this 2 to the yes and I the es and I record that was proposed and I think there\u0027s there\u0027s a third example that I don\u0027t or a third scenario that\u0027s not covered here so kind of it if I fundamental I think there\u0027s a it makes sense to separate out the ESN Ikey format itself um from the way we\u0027re distributing it through DNS and looked like some of the most recent draft versions at least pull some of the DNS extensions out of that that record and then the question becomes what do we do about the DNS records here um I think I see there being a few different options here one of which is to say that you have purse a per application protocol binding that says the described would describe how you would want to use on yes and I keys for a given protocol so for HTTP we could say go use the HTTP service record and then there could be a generic you know simpler finding that says hey go you see yes and I record another option here is there\u0027s been some interest of saying ok HTTP service seems useful for other use cases maybe it should be generalized to not just be HTTP specific on in which case you could have that that more generic HTTP or that "
  },
  {
    "startTime": "01:46:02",
    "text": "more generic DNS record use case could cover the ES and I case as well and corporate support for yes and I keys and therefore potentially eliminate the need to have a separate yes and I record next slide next Inc terms of next steps when I wrote these slides I thought that http-based we\u0027re gonna be talking about this afternoon might be the best home for adoption for this on after talking into DNS in DNS off and talking to the dots and the chairs it may actually be that DNS off is a better home for that and the DNS up and HTTP this chairs are talking on that front there\u0027s a a place in github where we\u0027ve been working on this until we get it adopted in a particular place there\u0027s a on the name server side the on the DNS are there\u0027s been interest in this especially because it solves some other problems they\u0027ve been interested in on so there\u0027s a bind nine private type implementation they got done by Mark Andrews and in the hackathon someone did an unbound implementation it\u0027s under good evening CloudFlare if I understand this correctly the client would that the first resolved HTTP as we see and then do another resolution for Delta active name the Enders there\u0027s a bunch of optimizations proposed in the draft so the judge so the if following the optimizations the client would do resolutions of the a quad a and HTTP SVC in parallel with each other and if things and similar to the some of the cases in yes and I if things go right you once you get off once you get those records back you shouldn\u0027t have to do any more in the cases where they all point to the same thing and there\u0027s not a multi CDN use case showing up on another one of the kind of open issue slash questions has been does it make sense to put two can follow the path of the yes and I record an inline or have a way to in line with the a and quad a record straight into the HTTP service record they\u0027re a bunch of downs there a bunch of upsides and downsides for that for example not in lining not in lining them and having them be separate make some of the proxy use cases like proxy connect work a lot more cleanly because long as you separate some of that out on their hand in lining it helps for performance and in lining it also may reduce some of the the complexity of client implementations right there was a proposal for yes and I for the multi city and problem and well the were two proposals one was embedding the addresses in the yes and I record and the other one was like advertising a separate name or whatever and the reason the second one was in big was that it would require two resolutions and that wasn\u0027t like a good idea and if you do if you strut if you structure and there\u0027s some recommendations in the draft of "
  },
  {
    "startTime": "01:49:02",
    "text": "history if you structure things right on you do have you and we took I think there was some discussion on this and some experimentation on this in the it\u0027s a nice side you can get cases where where if you do those in parallel the you can get or you may be able to get a reasonable enough hit rate that you that it\u0027s not that bad performance wise we got about 10 minutes left folks thanks for sending this I\u0027m certainly more than happy to outsource the work of DNS hacking to again as people as long as it actually meets our requirements so I think you know the is also under indicated the reason we selected the current design was because we felt like that was going to have the highest probability of getting you an answer in the time frame the efficient if it turns out that that assumptions are incorrect certain look a different thing um seems like the question of whether inlining is possible well certainly there\u0027s you say there\u0027s no reason this can\u0027t contain inlining so it\u0027s perfectly compatible with that if that\u0027s the way you decide to go I don\u0027t really understand quite the relationship between TLS which would be the first consumer of this and DNS apple wrapper would be the you know ultimate producers of it and I want to make sure that that rich it was well specified and if we didn\u0027t end up back up way behind something that was very complicated um or complicated uh there was in take a very long time another working group because we serve a lot of deployed yes and I relatively rapidly so those you my concerns but if we can manage of an efficient processing besides certainly having something which was not designed by TLS people to be shutting the DNS would be a superior outcome IR thanks for presenting this up I\u0027m a little bit unclear what\u0027s specific to HTTP this record has seems that it applies to tell us generally and I think that is the that probably been the biggest side effect of feedback on this so far is that it makes sense to generalize this and I think it the the exact question will be how does it makes it like what is the right form of generalization of this and but I think if my if this got adopted within a work and this month at would one of the reasons why DNS thought maybe more on a more attractive place to general to adopt this is that it would be that we could go and look at what is the right way to generalize it there such that for the on the that we don\u0027t have the some of that we can minimize the performance impacts deal with a bunch of these corner cases that were coming up in the SNI design but do it in a a way that covers a bunch of the other cases and then they\u0027re made in addition VA may have value of being a subsequent patch or thing on it saying for the HTTP use case here are some additional ways to use if possibly as it as one general one HTTP our name and one or one HTTP specific are our type and one more generic are our type that have roughly the same form roughly the same or have the same format but has some additional "
  },
  {
    "startTime": "01:52:02",
    "text": "semantics layered on for HTTP I guess more specifically my answer is which part of this is only HTTP it seems that it\u0027s only the alt SDC the things that are HTTP specific in this are the that we use the all types SVC formatting for it and that the treating the that not using the underscore labels for the HTTP 443 scheme so that you so that that you can just to deal with some of the wildcard use cases for it as well as the the HHS GS style for proposed default behavior Thanks as I mainly I think you you started from sort of an SRV record and that\u0027s why it looked me that the sort of redirect host is mandatory in this textual format but why why do we need that why do we need to name say that the CDN like I so I\u0027m assuming your stuff the IP address is in there because that makes sense but I don\u0027t understand why it\u0027s not just a blob of key values on the and so in particular you do need to get the idea you do need to get the IP address as a spammer or some way of tying to something that will give you IP addresses or have the IP addresses directly in there because to handle them to handle things like the multi CDN use case well you don\u0027t know because let\u0027s say that I\u0027ve just got one server like you can look up it\u0027s a record and you can look up its HTTP SRV record which gives you a bunch of other information like I don\u0027t need one I don\u0027t need this redirect name and like I wouldn\u0027t need IP addresses but obviously if you\u0027ve got multiple CD ends and sticking IDs makes in that makes sense I don\u0027t understand why this host name field is mandatory in this record value and what in the what would so one thing that host name field can be in the in the draft is it can just be a dot which says it\u0027s the same as a record oh okay so it\u0027s already optional it\u0027s just textually prioritized yeah there\u0027s a way there\u0027s basically a way to say use a specific formula in that case I would textually demote it but okay Thank You Tommy Polly Apple so thank you for sharing this in a very fun but I\u0027m definitely in the camp of people who says this should be a generic thing I think that doesn\u0027t it core sense so just +1 to all of that yeah and I think just with regards to how much is in line versus somewhere else maybe one way of kind of breaking that up because I think "
  },
  {
    "startTime": "01:55:02",
    "text": "there are a lot of other things I would like to see that maybe aren\u0027t appropriate to actually fit in I\u0027d like to get those somewhere else but maybe we could have a split of things that are shareable between multiple names multiple records that is external and that actually mitigates some of the look up cost right so if I had a CDN deployment that had let\u0027s say I want I won\u0027t actually be able to use this for like dough server discovery of say like these are the right things to do for that and if those are all sharing properties between names then that\u0027s something that can go fetch kind of a generic CDN configuration from some name but you allow me to look up through this but if you have a specific key for just that particular name that that stays in line because I think this mechanism is a really great way to allow for this extensible vocabulary going forward right I think to some of the why do we have names rather than IP addresses also goes to that because the others like an example of that case would be if you have if you want to advertise both h2 and and HTP 1 1 and and quick for a set of a and quad-a odd records you may like combinatoric lee you otherwise end up with and i think you end up with a potentially huge set of things and having that indirect level of abstraction helps address that and I think like for the ESI key itself one of the questions because is that do you in line of basics before of that or do you have a name reference or do you allow either case on Bulow either case because I think there\u0027s a trade-off between the performance impact of doing in Direction versus message size on especially in the face of caching right and if you have like totally unique yes and I keep every name then have them in line but if you have a way to derive them generically for the also thank you radically a plus-one to making this more generic I think that sort of argues against putting an HD abyss but could be either Indiana self or TLS I want to point out maybe that you know perhaps everyone\u0027s aware of this already but like yes and IKEA is a property of the IP address not of the name so it does seem more sort of straightforward that the IP address be in here because otherwise you basically when you do a parallel implementation you do an a and Akane and in a service record lookup but if you\u0027re unlucky and the chordae for you get the quad-a for a different CDN then you\u0027re like oh wait you have to basically walk the intermediate cname chain of the of the of the HTTP service record and then do another look up for a quad-a for the name that you had and so that the CDN Empire is good or you get lucky it\u0027s efficient but if not and it\u0027s very complicated to implement on the client so +12 putting IP addresses in there I guess my question of Akamai just making the observation that this is this is an outgrowth from having the old "
  },
  {
    "startTime": "01:58:03",
    "text": "service DNS record just wipes in the same repo and that alt service is applicable or could be applicable to other things to meet GPS that hasn\u0027t been defined for that and so this is a step in that direction and could eventually be generalized but I think we\u0027d have to figure out what it means to have an old service record for something that is not only the origin mm-hmm Dan York internet society but not speaking for Internet study and so to Lorenzo and Adams case I\u0027m somebody who wants the the domain name in there because I\u0027m from the DNS side and I want to use this for the cname at Apex fixed to be able to point for our food comm over to a CDN in some case so that\u0027s where I\u0027m looking for that my question for you though Eric and thank you for presenting this work in these places and doing all this will require client implementation across all the clients for this to work correctly correct correct I think that\u0027s well and similar to the yes the es and I record would also presumably need the same thing okay and I\u0027ve seen a number of people doing prominent client standing up here but are you the chair the co-chairs are you not the co-chairs the authors are you involved with talking to those about getting this into their thinking we\u0027ve been having some Congress we\u0027ve been having conversations with in with some certainly some browser clients haven\u0027t yet had that as many conversations with non browser clients like and one one cunt I think the in one at least one conversation it was clear that that when you stir when you start having a fairly rich stack that provides an abstraction like an HTTP abstraction or a top style abstraction that you can fit this sort of thing into that abstraction well what becomes trickier and may also be trickier with with yes and I as well with the s and I record is when you start having a much closer to the metal style set of abstractions and you\u0027re still dealing with things like get hooked by name and and connect and such that it does add a lot more complexity to that that class of client ok I mean and so I would I hope other people who are here who have clients that could consume this will be talking to you my one concern just looking at it is that you are it is capable of solving a good number of different use cases and with that comes the complexity of implementation that I think we just there\u0027s I guess a question on mind around the scope of it and how how much how many of those use cases we really try to solve with this these here doing this work and I think that\u0027s also a balance on how general to make it cuz the more general it starts becoming as we\u0027ve seen with many things here the more risk you start having of having it "
  },
  {
    "startTime": "02:01:03",
    "text": "be way too complicated on the client side one one reason why I\u0027m somewhat less concerned about the that that some of the client complexity is is for enough of the use cases for enough of these cases that want it I\u0027m having robust client libraries that people can use that handle things like TLS verification well and DNS in connection management well it\u0027s probably it\u0027s going to become increasingly important because a lot of the people who do the hey I\u0027m just going to use some of the underlying primitives directly without really understanding them well have there seems to be an increasing risk as those primitives started getting more and more complex that that they won\u0027t do some of this they won\u0027t understand the caveats and for example won\u0027t do Saint Els at Vassar verification we\u0027re at a time basically I should shut up yeah Thank You Adam thank everyone for showing up we had some different presentation requirements this time so please let us know what you thought about the presentations this time just Els chairs out I attempt at org thanks blue sheets where the blue sheets [Music] [Music] "
  }
]