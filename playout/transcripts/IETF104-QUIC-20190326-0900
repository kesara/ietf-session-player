[
  {
    "startTime": "00:00:04",
    "text": "do this okay everyone this is quick good morning little cabal in the shut it down just shut it down Acker shut it down if everyone yeah but he\u0027s Joe your record so if everyone could have a seat this is quick we have two hours today and two hours tomorrow I believe think so yeah so let\u0027s go ahead and get started first of all this is the note well statement you should be familiar with this but if you\u0027re not you can find it by searching for IETF note well on your favorite internet search engine including waste and gopher and anything else I guess these are the terms which we participate in this work under regarding intellectual property regarding your behavior regarding things like harassment code of conduct so if you\u0027re not familiar with these please do take a look at them we do take them seriously and indeed we have an almost Budds team if you have any issues regarding people\u0027s conduct so if you have any issues please do talk to Lars or I or the other folks that are nominated for these roles spacebar is broken there we go administrivia blue sheets are going around thank you Joe no we\u0027re trying to go that\u0027s weird okay we have scribes thank you very much Patrick McManus with a backup of Brian jabber relay Craig volunteered to relay whatever happens on jabber thank you so much and we are using the ether pad that\u0027s linked from the minutes correct sorry from the agenda correct just if folks we start having performance problems on that people who aren\u0027t actively editing disconnecting might be a good idea because the ether pad does tend to have some issues once you get a certain number of people on there I\u0027ll let you two coordinate that in in the case that it becomes necessary if that\u0027s all right our agenda for today I reload I just did [Music] so we had the hack of thought on the weekend today we\u0027ll have a quick report of what happened at the hackathon from Lars and then we have one discussion from the editors about discarding old keys and then we\u0027ll go into the focus for today is mostly on the recovery draft so ian is going to go over what\u0027s happening the recovery draft and the relevant issues and we\u0027ll try and focus on that take advantage of the time we "
  },
  {
    "startTime": "00:03:05",
    "text": "have here in Prague with the larger IT have to talk about that since when we have our interim meetings it\u0027s often the case that we don\u0027t have all the right people in the room if we have time permitting after that we\u0027re gonna have a quick discussion of quick connection migration and then on Wednesday we go into issue discussion on transport TLS and HTTP talk about our next steps and I don\u0027t think we have any other as time permits there\u0027s one pending that will be on Wednesday if it happens ok any bashing on that plan of work ok so before we get into that a couple of quick things all I need to go back to this don\u0027t I so as you know we have a changeover of the Guardian a DS so we wanted to take an opportunity to thank Spencer for being an ad for the life so far over the quick working group thank you very much for your service stand up thanks for troubling us yes and we\u0027d like to welcome our our new ad Magnus Magnusson please stand up and make sure of it is you [Applause] [Music] sorry don\u0027t go to the mic for bad jokes please so yeah that\u0027s Magnus if you have any problems with the way the working groups running or or and you can\u0027t resolve them with us Magnus is the person to talk to make sure you forget what he looks like No okay that doesn\u0027t work I guess and one other thing we wanted to mention we have scheduled an interim meeting for May the 20 the week of May the 20th I believe in London yes the hotel rates are surprisingly cheap we\u0027ll see how this goes we consulted with a lot of people before we chose that date and time and we waited as long as we could to see what the future would look like and then the future changed very quickly of course so we\u0027re still going ahead at this time I don\u0027t see us canceling the meeting unless things get quite dire which some people predict but people sometimes get in the habit of predicting dire things so we plan to see everyone in London that week we have an interrupt two days and we have a two day working group meeting scheduled with any luck this might be our last interim meeting for the quick v1 walk you do that after I can get a very reasonable rate on it trust me Wednesday we\u0027re going to talk "
  },
  {
    "startTime": "00:06:05",
    "text": "about this right yeah so there\u0027s so it depends so whether or not we\u0027re going to keep having interims will depend on how quickly people will want to make progress and some of the stuff that is next on the agenda like media / quick and multipath right so let\u0027s talk about there on Wednesday and we I see as also still organizing interrupts but since they\u0027re not ITF events that is sort of a bit orthogonal to whether we\u0027re gonna have an interim and and indeed one of the things we\u0027ll talk about is having physical interrupts separate from interims but that\u0027s that\u0027s Wednesday so today let\u0027s get back into the agenda Lars how did the weekend go went well can you click on the thing the the thing that says sheet somewhere if you go up yes that the Google Docs thing right so so we\u0027ve been doing this for a long time now basically this interrupts at a hackathon um and we have every time there\u0027s at least like one implementation that either hasn\u0027t participated in a long time or is new so this was no exception it\u0027s starting to look pretty solid in terms of the base functionality it\u0027s there\u0027s a lot of green happening and you you see that that you know there\u0027s pretty broad inner up across the board it\u0027s a little misleading so some columns are dark or some fields are darker than others that\u0027s because we we added a bunch of new tests for this inner up round that not a lot of clients have implemented the tests for yet like you know Natura binding or but the other guys peak CCN and so on so it\u0027s a little bit misleading because I\u0027m guessing that if more clients we\u0027re testing these things you would see darker shades of green because some servers already support them except that if they\u0027re not tested for that yet so it looks pretty good I will point out that so my personal opinion is that for specifically connection migration there\u0027s a whole bunch of edge care case testing of who needs to happen at the moment everybody seems to so if somebody tests this maybe to be the exception of Christian I don\u0027t know everybody\u0027s just sitting passively seem to close support in spider ports the IPS doesn\u0027t change to support number changes and there\u0027s not really any artificial reordering or any fancy stuff like that being introduced yet so I expect we were gonna hit some more corner cases there but it looks pretty good and given that night so this is a - 18 that we\u0027re testing here 19 is already out with reasonably minor changes at the recovery and and trans what level I think many of more to changing on the HTML side it also looks pretty good so this is the compared to the last time I think we did this there\u0027s a lot more h3 that\u0027s being tested which is very very very nice Mike always says it would be excellent if we actually got a browser very soon that that did h3 over quick because that "
  },
  {
    "startTime": "00:09:06",
    "text": "seems to be a catalyst for many things we\u0027re kind of hopeful that might happen soon and and if we get more than one browser that would obviously be even better but I think it looks pretty good but but the devil is in the details and there\u0027s the basic functionality when you have a nice clean path between decline and the server things seem to work really well up I\u0027m guessing that there\u0027s gonna be a whole bunch more issues when we\u0027re running over some you know stranger edge case for us so it\u0027s arrium so the ietf network is a pretty good test because it\u0027s usually not great in terms of packet loss and again they had so in Bangkok and here there\u0027s a box in the network that likes to order UDP packets by size which means that so the knock knows about this we\u0027ve we figured this out in Bangkok it\u0027s it the box is present somebody found it during you interrupt because they were wondering why they persistently get this one ticket after the other that is why so the ITF networks an excellent test network but we we don\u0027t have sort of a lot of repeatability here yet and then this comes back to tooling and and Ottomans has supported Christian Kushina Itamar yes one thing I did observe in his intro up is that lots of stuff are working well but if you start digging like for example if you start trying to download hundred megabyte or something that you do find issues and there are lots of issues about confusion between the transporters one way on the other way or these and that so dust is and and then the retransmission and the management of flow control I mean we need more tests they\u0027re in a I I agree so I think of the the first stacks are now sort of getting to the point we\u0027re doing well I think nick has been doing performance testing for a while but but some of the other sects are also now getting to the point where the X we wonder what kind of through Patek they\u0027re getting and and where they actually try to push a lot of data over connection or multiple connections and that exposes a bunch of stuff I\u0027m Jenna you\u0027re just two notes one eye on that on that point I think it\u0027s super important for people to start doing attention to the tooling stuff and and we are having presentations in psv area on quick tooling and that\u0027s gonna be very helpful for working on performance going forward I\u0027m hoping that those folks will also show up to the Interop to help people integrate their tooling with their own implementations I don\u0027t know if we can do anything to support that but it\u0027d be lovely to actually figure out if there\u0027s a way to support because at least one of them robinus is a university student and lovely to get that support I mean one thing is we have a bunch of students and academics show up that I mean if you profess over and you have students that are looking for master\u0027s thesis topics this is not I mean there\u0027s PA cheese here too but a lot of tooling is more like a master level kind of exercise but it would actually help you know a large part of this community significantly if there was some more open source being "
  },
  {
    "startTime": "00:12:07",
    "text": "written along those lines well then and it makes for a pretty nice thesis so come talk to the implementers I think everybody has things like that that are pretty baked and somebody could go and do a master\u0027s on ya agree the second point was to me you talk about browser showing up browser did show up and actually did manage to work this time so I don\u0027t see it on a chart though so I wasn\u0027t there for that so maybe which browser chromium yeah but guessing so thank you for saying that so so yeah that was a I didn\u0027t know that that line was actually chromium rather than just the library oh yeah I was gonna run for that okay great I let skinned Ozzy fill in the blanks there very briefly okay it\u0027s kasi who just want to clarify that that is the chrome implementation of quick but we did not test the actual browser because we as you could see we have the handshake benign HTTP so the browser is not gonna render anything useful yes hi which is nice very briefly um Erik Kinnear from Apple we have flouted books there we go hello that\u0027s better Eric Kinnear from Apple we have loaded quick over Safari so all the way through the stack top to bottom awesome so yeah yeah can we use that someone can we get a build for that is that something that\u0027s possible at some point okay I catch no yeah I\u0027ll take a new phone any day but I think that was a Throwdown to the chromium folks but is the implementation actually called G quick that\u0027s super unfortunate oh it\u0027s not G quick that\u0027s right I\u0027m sorry that\u0027s what it does it\u0027s not it\u0027s still dodgy fuck all right all right anything else only interrupt okay Thank You Lars oh there was a discussion where they\u0027re gonna do a virtual interrupt day between now and London and and what version we would do it so if you will care about that I think it\u0027s on the general channel on slack and if you\u0027re not on the slack and you want to be honest like send email to them mark of me yeah for those not aware we\u0027re using slack as a way to coordinate between the implementers it\u0027s not wear any normative discussion of issues happens or anything covered by the IETF no well happens it\u0027s just for coordination between implementers okay so Martin Thompson discarding old keys please so this wide dick was updated I think yesterday and it\u0027s out of date so I\u0027m gonna go through it anyway part of the problem here is that we\u0027re dealing with I think three or four different things "
  },
  {
    "startTime": "00:15:09",
    "text": "that would the various reasons decided to lump into the same bucket so let\u0027s go ahead and we\u0027ll see if we can make any progress here but I don\u0027t hold high hopes next sorry I should not be so negative early in the morning so talking about discussing initial keys as soon as possible there\u0027s some debate about whether that\u0027s a goal we\u0027re talking about discarding the handshake keys weren\u0027t appropriate and there are some problems that we discovered in key updates that need to be fixed probably the biggest one being that if you if you update too quickly and both peers do that at the same time you can end up in a situation where where one peer cannot possibly just basically force to drop every packet on the ground basically kills connected connection the the agreement there was that we would limit the rate of key updates to one per RTT and how we do that is for debate but that was the basic basic idea there there was an express preference for explicit signals over implicit ones some people still think that timers are a good idea but we\u0027ll get into that as I sort of work through the different options next place do you have a clicker nevermind so the basic idea that we were talking about and this was something that Nick came up with in the interim was having an explicit signal that we could use to say it\u0027s okay to move to the next one or probably maybe more precisely it\u0027s okay to throw the other keys out because we\u0027ve got these ones and with them we can proceed anyway and so there\u0027s really three distinct cases that we were concerning ourselves with here and and each one has some different nuances to them and so I think we\u0027ll probably go through that a little bit more detail as we go and I\u0027m waiting for a clicker let\u0027s see how this works out I notice that marks not willing to have the ITF clicker attached to his machine let\u0027s see if this works does this need to be turned on or something that\u0027s not working next so we\u0027ve had four proposals I think there may be a fifth one now I\u0027ll see if I can do that one justices we work through this one the first three of these use frames to sort of signal that things are ready to go the fourth one steals one of those unused bits that we have in the first octet to create the signal there\u0027s a fairly substantial differences between the first set and the last one and in "
  },
  {
    "startTime": "00:18:10",
    "text": "some regards but essentially they\u0027re all some sort of explicit signal that we\u0027re ready to throw away the other keys the difference is in when they\u0027re sent and how they\u0027re interpreted and what you what triggers you use to progress to the next ones next page please the first one this is my attempt to capture the state of the discussion out of the interim in Tokyo and this is the first set of changes that you can see here on the slider over the past day the idea was that you would send this this frame when you believe that when you have read case for something but we realized in discussing this that what you really want to do is say send this frame when you expect the peer to be sending with the corresponding keys it implicitly identifies the keys this is a point of difference with some of the other ones if it if the frame is included in a packet that\u0027s protected with key X then it means that I\u0027m willing to receive the corresponding packets that are protected with the corresponding key it doesn\u0027t have a an explicit counter or something in there that identifies these things and so if you start sending these back these packets after key updates that means something different which is which is something that we sort of do with acknowledgments but maybe acknowledgments are so special that they\u0027re the only ones we can get away with out with I don\u0027t know when you receive one of these things at least used to say when you send it but when you receive one of these things you know that the older keys that are associated with keys from the previous epoch are safe to be discarded you may want to retain those all the keys the the ones you use for reading packets for some amount of time and there\u0027s some discussion in the document about how that that works but the basic principle is you can your opposition now we can throw those ones away and you can proceed to make a new key update which i think is because the key fix for the key update problems that we\u0027re talking about next place I\u0027m going to show some pictures hopefully these decipherable at that range it\u0027s very difficult to get these things on the one slide but essentially what happens here is that when you send the first handshake packet you say well I\u0027m expecting to receive packets that are protected with an Shakey\u0027s at this point so I\u0027m going to send this frame in that first handshake packet and when you receive that packet containing this frame it means that you\u0027re okay to proceed to the next one and it also means that you\u0027re okay to throw away the the previous keys and so if you look at the the third initial that\u0027s sent there "
  },
  {
    "startTime": "00:21:12",
    "text": "from the client which ostensibly contains an ACK of the server\u0027s initial when that arrives at the server the server may have thrown out the initial keys depending on the ordering of things same happens at one RTT you\u0027ll notice that it\u0027s not sent in the first one RT t packet because the server doesn\u0027t have the ability or it doesn\u0027t have an expectation that the that the client is is sending in one not one RCT keys until it\u0027s it\u0027s gotten the one ITT that packets from the client this is I think doing double duty here as the I think the thing we\u0027ve discussed many times is the handshake done frame and we would use this as a trigger for other things okay yeah so just trying to make sure I understand at this point so let\u0027s take that first transition if the let\u0027s assume the like as being natural that the initial and the first handshake from the server bundle in the same Datagram and that the server and the client supplementing lay back so what will happen here is if the point where the client is ready to send initial it\u0027ll already have received them processed the keys ready flag in the first hand and an intuition of the circuit right that might be the case unless shoulder that\u0027s gonna be delighted X in this case because you\u0027re gonna be sending packets you just your stuff the accent it well so sorry you\u0027re quite the client is not let\u0027s say the client is not intended in an act upon receiving the initial packet prior to receiving the rest of stuff in the Datagram right yeah you can call it the lay back or not as you please um so um so it processes the through the initial and the handshake and we\u0027ll have processed this frame before it sends the like that the color sense the exploitation is you will suppress transmission da frame it could do so yeah what\u0027d it do so or would do so or must do so and what\u0027s the interaction with the AK that is and that imagine is imagine that for some reason the Act does not appear in the server\u0027s initial the Act does not appear in the service and so now you have outstanding own act data the expectation is you would drop it so you would drop which so so if the app does not appear in the server\u0027s initial yep now you have a case where you\u0027ve deleted the key or you could delete the key for the rules right but you haven\u0027t standing on act data one well that\u0027s the question I\u0027m asking right I tend to establish the rule what the proposed rules are arguing the the proposed rules were that you can you can drop everything on initial packet so you can throw that stuff away and now you have a you have a different channel for for establishing that you don\u0027t need to resend that initial packet okay so but "
  },
  {
    "startTime": "00:24:12",
    "text": "more generally the rule is and it is me me I don\u0027t think this the only case that can happen maybe it is more done where the rule is that on that if you have outstanding data on an empath that could not be sent they cannot or should not send other epoch when you receive he\u0027s ready on epoch M + 1 or M + M + anything then you can be said that you see effectively so that an AK or you you start test me right but yeah you throw away all state for the the previous case so it\u0027s not just the previous keys it\u0027s all the state associated with it which means crypto frames in the works yes thank you yep there\u0027s a bunch of discussion about that you have to throw away recovery state and and various other things as well next place so the K update is similar here the difference being that you again you don\u0027t send the key ready frame when you send the first packet in the new epoch you send the keys ready frame when you have an expectation that the peer is sending packets with the new epoch and so for the for the for the peer that initiates the key update they wait until they\u0027re seeing packets from the new epoch before they they send the frame and the consequence here is that you\u0027re allowed to update once you\u0027ve received the the frame and there\u0027s there\u0027s no way that you can use this state machine to do anything faster than one key update per round trip and that achieves the goal it fixes the problem we can go from n to Oh without actually having packets from n in flight and that causes the M\u0027s and the O\u0027s to be indistinguishable from each other and the connection to fail so we we patch the hole next place so david brought up an alternative design for this one and this one that essentially says rather than using the expectation of keys being ready you look at the data that you have to send in a given epoch and you say has all of this stuff been sent to the other side and acknowledged and so when you have no more to say you then are able to do the key disposal and and and move on to the next epoch this shares the property with the previous one that it implicitly identifies the the keys it does have a little wrinkle for the initial handshake transition it\u0027s it\u0027s a special case like with the other one you send it in the very first packet and that triggers the the drop of the initial keys in the same way that\u0027s a little janky in some ways because it\u0027s not it\u0027s not a consistent rule that you follow but it has fairly similar "
  },
  {
    "startTime": "00:27:12",
    "text": "properties next slide will give us a little bit more information about how that works and so it looks very similar but you if you look again at the at the picture here is this the one that did you drew David because I think once I think you you had the retire keys in the first RTT packet of the first one RTG packet from the client is that right is this right okay it looks fairly similar to the other one the difference is if you look at the one RCT case you send the retire keys frame later at the client I\u0027m not sure that I understand out though do you want to speak to this David yeah I\u0027m trying to show understand - so you send retire keys after all the data that in the epoch that you\u0027re retiring has been acknowledged yeah this is the this is the question please yes jarett\u0027s cannot see google so we\u0027ve been kind of going back and forth and I think what Martin has been doing a good job demonstrating is we can\u0027t find a like a really clean solution but in indeed in that particular design that was the one I had a few weeks ago the idea was that you send retire keys when everything that you want to sent there has been acknowledged from some implementers opinions it turns out in some cases it\u0027s hard to know when stuff has been act cuz your act Roisin ernie and your is kind of disconnected so in that case we could actually bring that message earlier the system still works without that was the initial design yeah so yeah this one is driven on driven by the the receipt of the acknowledgement for the handshake packet so once you once you\u0027re sure that you\u0027ve received everything once you\u0027re sure that the PIA has received all of your handshake messages you can then send the frame so right yes it is and just as an alternative another way to key off which we were talking about last night is to key off the TLS state machine transition we\u0027re on the client you don\u0027t react necessary to a single packet but when you\u0027re separate to us implementation off the top tells you I am now connected the handshake is done then you can send it then that also works you see if I didn\u0027t restate what you just said which is that um let\u0027s take this case let\u0027s take the case of the server just for convenience that the server would send retire keys upon receiving the clients finished so in this diagram what identical I know it it\u0027s the acknowledgement that\u0027s in the same packet well I know but they\u0027re the same packet well no he just said like my point is that in this case those two are at this droids have two identical timings right and so John you were saying he\u0027s proposing a different rule which is this on the state machine right yeah so that was suggesting two different two different rules that are effectively the same which is not the "
  },
  {
    "startTime": "00:30:12",
    "text": "same right well no no not in fact no not in theory nor in practice but in a lot of cases there will be yes I thought yeah why wouldn\u0027t it oh yeah this one\u0027s in the dark and okay I\u0027ll go over there next time I just want to clarify another way I think of staying who\u0027s dating what and maybe this is what dude just said is that once you are done sending at that encryption level you send this frame and once you have both sent and received this frame and an encryption level then you know you are done and you can move on and that\u0027s that\u0027s my mental model for for how it works and there\u0027s a variety of ways you can decide that you are done sending in that frame it could be an acknowledgment or it could be I have henskee keys so I know the peer got my initial well that\u0027s an implementation to Pancho\u0027s on each pure side when you say but just to be clear done sending means is in this case the police means I know your side had received it yes yes yeah like so so particular you couldn\u0027t send it you you couldn\u0027t you in particular you cannot send retire keys um for the in in the one that first one our key because you don\u0027t know she meant to rush transmit the handshake right right right you need to you need to wait for some acknowledgement of some sort yes yeah great just just as like give you this I\u0027m not trying to argue at the bat merit so these things are to try and understand oh yeah well in a minute I should make sure I really understand exactly bill proposing right and that\u0027s the point of this this exercise here that I\u0027m going through is to to sort of plot out the designs base for these things then we can talk about the principles that drive them because that\u0027s important too next next slide will actually highlight some of the interesting ways in which there\u0027s changes so what\u0027s interesting with this proposal is that you send this packet in the very first packet you send in after a key update because when you initiate a key update you have to be sure that you are done with the previous previous epoch so what this doesn\u0027t show is the next key update but it does show that you can initiate a key update once the once the retire keys frame has been and retires keys frame becomes the things that you would send in this epoch that need to get completed and transmitted and acknowledged before you move on to the next phase so it\u0027s no longer crypto frames that were concerned with here it\u0027s the retire keys frames that you would use to drive that that decision-making process so that I know how to restate that maybe maybe Jonathan restated in another way but I disappoint of clarification actually yeah the repair keys are encrypted with the old keys right no they\u0027re encrypted with a new case oh right because okay so the assumption is that I know that the peer has everything it needs to to use the new keys "
  },
  {
    "startTime": "00:33:12",
    "text": "therefore I\u0027m sending the techies under the new key so basic design if the K update is there is always you can initiate it when you when you know that the other size radiator and we\u0027re putting the signal in at that point yeah yeah thank you that\u0027s not in my head more questions yeah um so it seems to me that this actually is importantly different from the rule we applied in the previous slide which is the rule applied in a previous slide was the data has been delivered and knowledged through a living on this slide however is not the day has been delivered in knowledge because I can just send it I can just send it again the new epoch and so and it\u0027s like I guess I\u0027m struggling to actually wrap my head around exactly what the rule long and apply my code is so this this becomes the the data that you you have to send and have acknowledged for the next update I understand but but the point is that like on it um so I\u0027m sending an M right you know and I play like all sorts of data like stream data are standing in am right yeah and that but that the stream data does not matter for the purposes of this calculation I I understand but on the question is when can you send retiree keys right and you\u0027re gonna say on but I mean you\u0027re gonna say you can summer hierarchies well the previous hierarchies has been acknowledged right yeah yeah so okay you told me the so the rule of the retired keys proposal is you send it when you are done sending at the previous thing so that is the rule so let me finish at the mic please occur so so yes I will expand so rule is you send it when you know you won\u0027t send anything else at this layer so for let\u0027s say this wait for the handshake layer what that means is everything\u0027s you\u0027ve sent as handshake has been act for key update there is a very key difference which is no pun intended the fact that what you retractable Smit frames at layer m at layer n so the you know you\u0027re done sending at a buck m the moment you have keys for a buck end because you know you will never send anything at a buck em anymore you don\u0027t need a mac at a park m he\u0027s just like I have the keys I will never send anything o\u0027clock anymore yes I understood this point but my point but the point I\u0027m making is that that\u0027s like three different tests in the Co to have to make for each different kinds of transition because the first rule use they did is not like a mechanic\u0027s enforceable and the other ones and the other ones all the things mechanically enforceable yeah so that\u0027s absolutely fair yes it is a the what makes it kind of clean is the concept the implementation of this is not necessarily clean and I agree with that that\u0027s why we\u0027re all arguing about these things because none of them are perfectly clean clarification questions are in sweat Google um if that matters "
  },
  {
    "startTime": "00:36:12",
    "text": "anymore in this conversation so does the AK really need to drive this um because we\u0027re not like actually looking for axle retired keys we\u0027re just saying you\u0027re done sending listen well you in this case you need to use the acknowledgement to drive that otherwise you don\u0027t get the round trip and we\u0027re back in the soup again when I\u0027m going to send them a retire keys in one directly and then the other direction because if you if you drive this just off the retire keys you can get the simultaneous update and then you end up with no round trip between that and the next one you can have you can actually end up at a situation where you go from em to end oh and you skip the end and you\u0027re back in the in the situation where you have packets coming in at 1:1 endpoint that a marked em and then oh and they have the same key phase bit on them and they\u0027re indistinguishable possibly there\u0027s a detail of key update I don\u0027t understand but if two people simultaneously update wouldn\u0027t they be in the same key phase at the same time they will be but one of them doesn\u0027t necessarily know that the other one has initiated the update and so if they both simultaneously update and send the frame at the same time and from one side the packet is lost sure but that side will receive the frame from it appear and think it\u0027s able to make another update and it can do that let\u0027s say half an RTT later that it updates again and so if all of the packets that it sends in that middle update a lost you will have key phase zero a bunch of lost packets on key phase one keep a zero again and what it\u0027s pscs is I tried to initiate a key update and the other side didn\u0027t do anything except it started sending me gibberish and that\u0027s all that\u0027s all we have at that point yeah thanks for clarifying I need to think about that month that\u0027s real fun that that\u0027s the the essence of the bug that Martin found with the the key update situation Martin zoom on protocol apps so looking at this diagram for key updates it seems like all we are doing is looking for the AK for the retire keys frame so this would be equivalent to just not sending the retire keys frame and just looking for the up for the ACK of a packet in packet phase n in fact the retire keys frame is strictly worse than this because it\u0027s a single signal as opposed to a continuous signal correct yes that is a nice observation thank you let\u0027s move on to some of the other ones with we\u0027ve got some more interesting options coming up if though if these ones weren\u0027t already interesting enough "
  },
  {
    "startTime": "00:39:12",
    "text": "for people so max key updates takes a different approach entirely and it says well we have this thing that we do in the protocol where we say that there\u0027s a limit on how many things you can do of a given type number of streams the number of bytes on the stream the number of bytes in the connection and we do the same thing for key updates we say you can initiate three key updates including the ones you\u0027ve already done up to that point and so the you have a frame that has an explicit counter in it so we deal with some of the retransmission logic problems that some of the other proposals had you don\u0027t drive things over hacks you don\u0027t dry it you don\u0027t have some weird retransmission logic for the frame in case of a key update you simply have the frame that you send you can send them out of order if you wanted to I don\u0027t know why you would but same sort of logic that we have for for max stream data and all those sorts of other ones and you use that to fix the key update issues use the first one of these to signal that you\u0027re willing to start doing key updates and then you simply send them as you get key updates in a way that allows you to control when the key updates happen and like most of these other ones it it means that you can hold off the key update in two till you\u0027re probably ready for it what Kazu has kazuo proposes in this one is not doing anything for the initial two handshake transition and using the text that\u0027s currently in the draft that some people are unhappy about for driving that transition and otherwise just using this frame to say when when when a kid updates are possible I think the the very first one of them would be used as the basis for signaling maybe we\u0027ll need to do things like migration and all sorts of other things we should talk about migration as well because that\u0027s something that\u0027s come up next slide please I think we have something here and so the idea here is that you have the the implicit drop the initial keys somewhere I\u0027m not sure whether this is entirely correct but you have the initial drop of the drop of the initial keys driven off implicit signals of some sort and then once you\u0027re ready to start doing key updates whenever that happens to be you you send this frame saying I\u0027m distantly updates I think 1 or 0 is the first one I\u0027m not sure whether that\u0027s I don\u0027t think we fixed that one I put 0 in but I think we might we might want to say that you know one is the right answer there but that\u0027s another problem yeah Jonah you know just again point of clarification what is that what is that number supposed to mean so the number means the number of key updates that you\u0027re willing to accept including the ones that have already happened so if I this guy\u0027s no key "
  },
  {
    "startTime": "00:42:13",
    "text": "updates have happened you send the frame I\u0027m not willing to accept any more key updates on this connection it\u0027s what 0 means if you were to send one it means that you can update once so if there isn\u0027t 3 that means that your work you can update 3 times oh I see so it seems from my perspective I\u0027m willing to do travel decryption to get post packets because we don\u0027t have put any explicit way of signaling which which keys are being used on those packets so the moment in domer I would send that would be when I have both the read and the write keys available for this and this doesn\u0027t say anything about what what the trigger is it\u0027s entirely up to the endpoint as to when it sends this could that happen any sooner than my keys that are available sure if you\u0027re willing to do trial decryption you can send this way earlier but as a practical matter you\u0027re going to do this when the handshake is done and you\u0027re you\u0027re ready to start reading with the new keys and you\u0027re sure that you want you\u0027re fairly sure at least that you won\u0027t be receiving anything with it can be confused for the key update that you\u0027re looking for so it seems to me that I think maybe this is the point you are trying to make by saying maybe there should be one it seems to me that it should be one because you want to allow for the next update to happen right okay yeah and then we on the same page right yeah so a mistake on the slides Christian Reda mom when I look at these diagrams there is one practical issue that I have is that I know when I can stop sending any given ebook right because I mean if my back is severe acknowledged I know I don\u0027t need that anymore I could get rid of my right key I could get rid of my cache copies I could get better many things what I don\u0027t know is when I should stop acting whatever is sent by the peer because what I don\u0027t know take the case of this diagram there the client and check contains there so the client finish the the first kind and check okay and the the problem for the client for the sellers to know it is to stop acting that saying if the clients repeats it because it believes it hasn\u0027t been act etc so that\u0027s the rule I mean they will at what point do I not need to worry about sending repeated acts and things like that if you would like to think of it that way Christian you\u0027re welcome to thank you Victor Oh silly if I have a question so what are the circumstances under which I would want max key updates to have any value other than 0 or 1 when you\u0027ve already had key updates and you want to enable more so the number continues to increase it\u0027s not a it\u0027s not a 0 1 it\u0027s a it\u0027s an - "
  },
  {
    "startTime": "00:45:13",
    "text": "it\u0027s like a flow control it\u0027s like a flow control kind of thing that\u0027s the way you need to think about this one all right I would like to accelerate this a little longer next next place this one was in an earlier version of one of the four requests that I put together I think because whoever suggested that we create a continuous signal by using a neck one of those spare bits that we have in that first octet essentially the bit would be you can you can initiate a key update from this and you it\u0027s carried in every packet so it has the the advantage of not having the problems that I think someone pointed out about Martin pointed out about the frames that we have if that if the packet containing the frame is lost then you delay any updates by another round-trip this one every packet contains the signal doesn\u0027t have any special retransmission rules it\u0027s just a different way of signaling things I think we\u0027re probably what we need to do now is discuss the the principles that are driving this one rather than then talk about the specifics of the of the signaling and talk about what the what the triggers are for generating that that signaling so I think I have a little bit more but I turn over what\u0027s here can we skip ahead see what\u0027s there all right let\u0027s talk about this they don\u0027t all use a frame again slides problems but there is an explicit signaling in all of the proposals what\u0027s interesting about all the proposals that hasn\u0027t been discussed so far is that endpoints can block CLE updates by not sending the frame and this has some nice properties for some from some angles and otherwise what Kazuo pointed out is that with the ability to block a key update you can also control the number of keys that you have active at any one point in time so it\u0027s always the case that you can limit the number of right keys that you have to one because you only ever need to write with one particular set of keys typically during the handshake is a little bit funny but generally you can limit that to one but the number of Reed keys that you have active if you allow unbounded key updates there\u0027s the possibility that you need to maintain multiple of them if you\u0027re concerned about not losing packets simply because they\u0027re on indecipherable the time limit there is something that we\u0027re suggested but primarily the time loadings exists deal with reordering on the network and delay packets but you can do things like delay the time that delay the time that you send the signal so that you have a period of time to accept all the packets from the old keys before you allow even newer keys to be installed then you can work at things down next place what\u0027s "
  },
  {
    "startTime": "00:48:15",
    "text": "different is where the where the signals have happened so because I was arguing for an explicit counter any of these proposals can be modified to use an explicit counter and then you don\u0027t need to worry about it David\u0027s one less so because the way that it\u0027s that the logic works drawback is it\u0027s more stuff it allows for more than one update it can be wrong if it\u0027s wrong just ignore it but there\u0027s a bit more logic involved in dealing with it the problem with the encryption level and the ambient signal is that you need to worry about retransmission rules whether it be to drive for the logic forward or whether it be to suppress free transmissions of the of the frame and it\u0027s smaller but you know whatever these things are infrequent so I don\u0027t think we need to worry about that one it all that much next because there are suggest that the implicit signal on the initial handshake handshake transition is is okay others use an explicit signal the thinking here has evolved a little bit those people who would prefer to drop initial keys as soon as possible we should discuss this now I think if you want to talk about that basically decided that you can throw away the initial read keys as soon as you have hand checked keys if you want to use any of these mechanisms and the reason we might want to do that is that we want to make sure that endpoints don\u0027t accept connection closes for instance in initial packets and allow for denial of service for a connection that has gotten to the point where you have shared shared state of some sort which would appear so let\u0027s talk about that for a little bit before we move on it\u0027s Ganassi Google so absolutely the initial keys are the ones that we really have a security problem if we don\u0027t drop as soon as possible for exactly the other reason they\u0027re not authenticated and integrity protected anyone can send anything there so they\u0027re the ones were even though I\u0027m putting a very strong proponent of an explicit signal all the time over something implicit you can\u0027t physically send a message at the handshake level that the client like it\u0027ll receive it necessary one RTT too late so or those are that\u0027s on the server you know so what that means is you have to key off of having the client and server hello\u0027s which means that now you have the handshake keys so as soon as you have the handshake keys you need to toss away the initial and one do you want to talk about the being able to discard the read in the light and set the times I think that\u0027s the key property here yeah there\u0027s some interesting things to consider about the right keys in this context but the the risk of denial of service comes from having retaining the "
  },
  {
    "startTime": "00:51:15",
    "text": "willingness to receive initial packets which are not authenticated as you say and if those initial packets come from an attacker who\u0027s willing to in injector connection close then you enter a situation where you\u0027ve all to someone close in the faction after you\u0027ve already reached the state where you you have keys that you share with a bit with appear now you don\u0027t have have an authentic hadith appear at the point that at this point but you do have case with someone start that who are you eres caller weren\u0027t really needed are we um that is your name right you\u0027re wrong yeah pretty much yeah I mean so this is a set of trade-offs and instead of trade-offs is a really quite minor palace or disclosure and a system which already has an ALICE but it serves exposure at this point in a handshake like 20 milliseconds earlier against complexity in a protocol design and so uh I\u0027m if it turns out that it\u0027s convenient to discard the keys earlier then I\u0027m more than happy to do it in terms that\u0027s inconvenient I\u0027m not happy to complicate the protocol for no particular extremely modest security benefit if at all um the UH and the complexity here is the complexity of having to manage the statement for this particular scenario you\u0027re talking about where it\u0027s the server sending his first flight with the initial and the handshake is a server having to separately manage the app state machine for the initial and the handshake in the case of the loss of the initial packet from the server the client in that these servers or nearly services in the show be retransmitted and we spend an attack on it I\u0027m Indian and zero if that is lost do if that is lost then you\u0027re basically driving about some other similar signal right you\u0027re actually not so the idea on the server is you drop the read keys for initial you keep the right keys so you put your server hello in your list of retransmit of all outgoing frames and you\u0027ll just your machine you\u0027ll keep sending it until it get sacked they can\u0027t be act exactly and then once you finish the entire handshake you just toss the whole initial infrastructure away so that\u0027s when you throw the read keys and the right keys all the outstanding packets die so that\u0027s not as clean yes it doesn\u0027t get actually you just shoot that whole piece of memory in the head yeah and quite possibly you\u0027re like five or six times even though actually you would even actually run an analogy before it because the client certificate is potentially large and the end hazard has no events so no the server the what causes what what is it "
  },
  {
    "startTime": "00:54:16",
    "text": "that causes the server to stop retransmitting its first flight and the answer is that it perceives some acknowledgment from it from the client what is that message and you handshake packet yeah this is like holding your piece of machinery to solve this like really incredibly trivial screwed apart so that\u0027s exactly what was complaining about hey you\u0027re right but I I would just say I don\u0027t think that it\u0027s a trivial security problem because like there\u0027s one of the things that we\u0027re trying to tighten versus TCP the twenty milliseconds before you had actually torn down but not the 500 milliseconds after yeah so I\u0027m not gonna cut the queues now but I\u0027m very conscious that you know we asked the wider ITF community to come and talk about recovery in this session I don\u0027t and it seems like the number of people who are really engaged in this discussion is relatively small and they see each other a fair amount so let\u0027s continue but let\u0027s keep in mind that maybe we have ten or so more minutes to do this and see if we can make progress in that amount of time okay hello yep it Mike so in in Tokyo I like the idea of using a unified explicit signal for dropping this the keys or all keys but looking at the different proposals that that were presented here it seems like the initial and handshake keys are special and we will need special rules for them anyway no matter which of the three three or four proposals we adopt the rules for initials will be special so we might as well accept that it\u0027s a special case and build a special case for this and use the explicit unified mechanism for only for the key updates so I now prefer having an implicit signal to drop to drop initial keys because I realized that there\u0027s a pretty cool thing we can do can you go back a slide to the diagram oh yeah just pick any diagram the other one so the server knows when it sent its server hello so the server can drop the initial keys right after receiving the initial packet from the client so the server will only accept a single packet with initial keys so there\u0027s no injection attack possible in the direction of the server yeah I think this was the point that was raised before there are complications with that unfortunately yeah the the primary "
  },
  {
    "startTime": "00:57:20",
    "text": "complication there is the denial of service amplification mitigations that we have in place and so whatever we do there would have to you\u0027d have to go back to the microphone not to deal with those but for the mitigation of the amplification we don\u0027t actually have to read the packet for for being unblocked by the 3x limit we only need to receive a certain number of bytes from the same address what in those bytes doesn\u0027t matter at all ok yes I\u0027d like to say that I\u0027m very much agree with what Martine said ok is that the initial is special and you have to consider that any implementation will be tempted to do something special for the initial packets so we could just as well acknowledge that and say yeah I mean basically if I have my handshake keys I don\u0027t need the initial anymore at least on the client side and on the server side it\u0027s pretty wise to keep it until you know that this good client has handshake key too but it\u0027s yes what Google yeah I tend to increase agree that at this point we probably should need to separate these signals that\u0027s mostly what I was gonna say the other comment was that David and Martin\u0027s comments are interesting ideas I think it\u0027s best to think of those as optimizations a server could perform rather than a necessary feature of this mechanism because I think if that\u0027s what I think that\u0027s a better way of thinking about personal people operating under risk in order Montes environment any injection attack you have to have assets that clients initial do your clients initials require generate your notepad can be valid for the server and his connection period so your 330 peers to be that the attacker for some reason has access to the clients initial can\u0027t like can\u0027t like give the packet in before it for the other quarter that happens and also can\u0027t transmit its own bogus initial the other direction which which recalls the client about the connection down like neither of those things is true in particular the second one is it true on and in particular to look so let us say that you have an attacker who\u0027s on path and but KITT but can\u0027t control and this guy\u0027s back by the way my request was when actually when a threat model for this situation as opposed to think we\u0027re using trying to find a tax they can count on that there are basically they\u0027re there their attackers which are on which are on path you can see the traffic and will always win there and can always put their packet in front there are attackers which can they put their packet in front and their attackers which turns on those are three categories of attackers on the first kind of attacker will always you\u0027ll turn the connection regardless of anything we do here second kind of your attacker you might say would not be able tear that connection because it will "
  },
  {
    "startTime": "01:00:20",
    "text": "always this race to the server but then with them in the waste a client and so they only have to be a posture which is slated for Sur which has to be president between the client server they said that the client initial which caused that has me turned out so someone please describe to me an attack it\u0027s actually defended against by by this mechanism on that the best answer yeah I can do that so the thing is if a client receives an initial packet that closes the connection a client might be willing to wait for a certain time if it receives another and another initial packet that looks valid because the client has the interest in establishing the connection so if you receive the the attackers initial you just say like okay it looks like a connection close but a wait for another 100 milliseconds or so you can send the fellows so for how long not a question closes so go hello with a won\u0027t if you have one key like all this stuff about how all the stuff out how we\u0027re gonna like put a branching tree of like all the possible stage from the server it\u0027s complete extra textual Iyengar\u0027s I think it\u0027s already starting to happen and it might be worth actually not just continue this conversation elsewhere but I was gonna say is separated in the conversation what Martin said Martin\u0027s him and said earlier is important in another way which is that the conversation for went drop the initial keys can be separate from what to do with the handshake keys and one oddity he\u0027s I think it might be useful to actually separate those two conversations because then you can talk about a threat model for the initial separately and deal with that separately so I\u0027m going to suggest that we share this particular initial position discussion because it\u0027s not going anywhere and we don\u0027t have a lot of time but I would like to say if we can make some sort of progress on the key up that one here because I think we got pretty firm they are related if you consider that they\u0027ve considered related then you can use it we decided that we would use the same mechanism for the two of them but I think we\u0027ve come to the realization that I don\u0027t think anyone\u0027s arguing for having a sign mechanism to the two of them so hang on so let my so hang on if we end up having the same mechanism for both of them after we saw the do problem separately we can use the same mechanism across the board that\u0027s it\u0027s unnecessary to start with that posture record line after occur except if somebody wants a speaker innocent hasn\u0027t been in the malign yet yeah I\u0027m just saying that we don\u0027t need to started that posture we can solve the problem separately if the mechanism and that ends up being the same we can have the same mechanism across the board I just wanted to respond to it cuz and well there\u0027s a merit of service coming in child case as far as possible because that approach allows only the client use the plank has the capability of handling multiple pairs of case then it would "
  },
  {
    "startTime": "01:03:20",
    "text": "defense without requiring service to do a costly work so I think it\u0027s a bit there\u0027s a benefit in letting the server to drop 10 buckets I shall read case also that\u0027s possible yeah I think there may be some setting offenses but like I\u0027m like what I\u0027m asking people actually worked out like I\u0027ve seen a lot of the law of discussion this working group for the past year and a half of like very specific attacks then we\u0027ve had various picks defense forward any concrete theory about we\u0027re actually trying to publish and what I\u0027m asking for is a concrete or we\u0027re trying to accomplish about what exactly the hacker is allowed to do monetarily not allowed to do scan analyze a protocol against that and the reason I\u0027m putting back martin again saying let\u0027s just cut this case off is because on the like if you saw the cases in all these cases separately and it\u0027s highly possible there\u0027s a reasonable solution is pretty good for both of them and then we\u0027ve sold them and we sell them together that\u0027s good and and if you say like let us build the absolute maximal solution for one and then not solve the other one that is possibly and with a very bad solution the other one because we because you haven\u0027t tried it tries all together that\u0027s why I\u0027m pushing back on separating them so the reason that I suggested that is that these are very different things that we\u0027re discussing one is a bug and the other one is it is we\u0027re dealing with this threat model question that you raised right and I think we can fix the bug because we all agree that one party T explicit signal is the way we solve the bug and so I would rather fix the bug move on of that with that and try to close that discussion and then we can argue to our hearts content about the other one but it may not be the case that the best solution for the bug the decision that by the people proposed works well for the four other case and so which case will we we can say well we\u0027ll just put the bug fix over to the other one I want to make forward progress that\u0027s sort of why and and said I\u0027m trying to do as a voice is a trade peaceful solutions they don\u0027t make forward progress generally it seems like we\u0027re getting to diminishing returns in the discussion here or indeed we\u0027ve we\u0027ve been there who in the room is in sorry Ted we\u0027ll get you in just a second I just wanted to ask who in the room is interested in and feels invested in the outcome of this discussion quick show hence okay it\u0027s mostly the usual suspects Thank You Ted please go ahead teri I\u0027m not sure whether I\u0027m a usual suspect or a diminishing returns possibly both yeah so the point I got up to say here is actually to reinforce something that I think we said earlier which is that if we do split this off so that these are two separate cases then it\u0027s relatively easy to then look at what we\u0027re optimizing for in the two different cases right and what we may be optimizing for in the two different cases can be different and then in fact I believe if we just took the the retired keys proposal and said look retire keys works except in this corner case where you have simultaneous key "
  },
  {
    "startTime": "01:06:25",
    "text": "update unusual to begin with and only one side of that simultaneous key update experiencing a packet loss of that key update we can actually say okay that that\u0027s a that\u0027s a bug that causes a reset and it\u0027s it\u0027s gonna be rare enough that reassociation in in quick is relatively cheap let\u0027s just do that if what we\u0027re optimizing for is we never want to throw the packets on the floor and therefore we don\u0027t want this case to to exist then we can go ahead with a zero sorry with a one RTT solution but your your functionally believe it or not going to be reinventing the spin bit in in the course of this by saying which one of them can can actually update at any particular time because though the way out of that that Sam nice open problem is to only permit one of them to do it per RTT and one side to do it per RTT and guess what you just reinvented so I\u0027m I\u0027m really happy that this group is so good at going back to the drawing board every time we discussed this issue we discussed this in Tokyo and had largely the same discussion and I thought that out of the discussions of Tokyo we at least made progress on the key updates thing but it doesn\u0027t I\u0027d like to see if we get somewhere towards in conclusion on that and even if we have to wind that back I\u0027d be happier my making forward progress on that then and and and just for but from my perspective and Lars please say if you feel differently I\u0027m willing to let the editors organize the discussion of how we make progress on getting the stuff incorporating documents just abdication of responsibility yeah that Martin is proposing support you man Jesus Christ I\u0027m less interested in having a discussion in the working group and coming to consensus about how we attack the minutiae of each individual issue of how we stack it in the documents I don\u0027t think that\u0027s a productive way to use our time so I know this is but not not on the topic of normal technical details here at all but we have had actually fairly good success with using small design teams in this working group I think in the past even on thorny complicated issues we\u0027ve actually managed to make some thing I know it\u0027s not the best necessarily way to go forward but as Martin just said we\u0027ve gone over this several times and every time there\u0027s just more things that show up and it\u0027s we are going to keep going around in circles until somebody says well we\u0027ve got this is one thing one way of doing it and it\u0027s good enough and we move forward and it seems to me that if you can get a group of people together in a room we said this that was my next suggestion was you know the number of people who raised their hands looked a little bit too big for a successful "
  },
  {
    "startTime": "01:09:25",
    "text": "design team so if we can pare that down to thing on the order of I\u0027m thinking eight ish people who are willing to spend some time this week we might be able to make some progress I just wanted to know that that was outcome of our discussion and talk is that when you designed him yes but we didn\u0027t have the chance to get them together for an extended period of time here we\u0027re trapped in Prague for a week Bernhard at the minute least a bug right we\u0027ve actually hit in inter up so that that is something that we certainly want to fix urgently and the other issue we\u0027ve actually also hit with at least one stack did something that was legal according to what we wrote down but it cost interrupts is that have not worked very great so those are not sort of your mate made up problems actually sort of they need we need to fix them soon if we want to ship b1 Brian hi Jana one thing that I sort of noticed while I was trying to keep up with that discussion is this it does seem to be emerging consensus around splitting these right like so that that seems like rough consensus and I would say that that might be the starting point for the design team is do the dog I mean it seems like that\u0027s where you were in Tokyo I wasn\u0027t in Tokyo but this team forms I would personally prefer if if somebody was coordinates who wasn\u0027t an editor or otherwise already doing ten different PRS right so so you don\u0027t have to step back if you but but so somebody who is whose understands this particular problem spies and and has maybe a some spare cycles to corral the usuals together David thank you okay cool so if you\u0027re interested in this talk to David and is it something that that you know folks can make a little time this week to have an initial discussion at least and indeed if we could have a very short report tomorrow at the meeting that\u0027ll be fantastic if anyone\u0027s interested please come talk to me at the end of this session here I will try to according on some time because it\u0027s gonna be hard to flavorful I put out there maybe lunch today might be an issue might might be not approach this is everyone\u0027s kind of making faces let\u0027s talk to at the end of this and then we\u0027ll figure it out just show a hands who\u0027s interested in being on this design team David have a good look around please yeah I see victors Kazuo everyone picked me on the quick so I don\u0027t miss anyone\u0027s name if you don\u0027t have that send me an email they create a channel there if you would I\u0027ll create a channel okay thank you we\u0027re not doing any working group that\u0027s like indeed I sit down Thank You Martin uh where are the blue sheets who has the blue sheets one second one who has the other blue sheet and who has not seen the blue sheet please raise your hand now okay we\u0027re still missing a blue sheet I\u0027m a little bit concerned yeah okay next up in sweat and if you could drive people people "
  },
  {
    "startTime": "01:12:26",
    "text": "need that can you draw this long yeah all right so first thing when I start off weather update of recovery sings Bangkok so we\u0027ve changed quite a number of things next slide so a review of key points just about quick in general just so if you\u0027re forgetting from Bangkok pocket numbers monotonically increase in send order a cranes acknowledge one or more ranges of packets there\u0027s an explicit actally on each act frame and the pier communicates the max act too late that it\u0027s going to use typically the time or value during the handshake so each pier knows what the other appears max act delay is there\u0027s an overview at ITF 103 from TCP M pitch other did it\u0027s very nice as well as 104 just yesterday so the slides are linked for my slides so there were almost as many changes since draft 16 as there have been in all previous revisions I realize that when looking at the release notes so yeah there\u0027s been a fair number of changes I\u0027m gonna try to go over all of them feel free to ask questions and yeah but we only have I think maybe now five design issues still open which we will discuss right after this next one so one one change that sort of simplified a lot of things is the old texts and the old pseudo-code assumed that you are either running in Thailand threshold boss detection so that\u0027s you know in in some time-space fraction of an RTT or in packet threshold so you know kind of a typical FAQ or dewbacks iowa packet threshold loss detection we are currently assuming now that you do both at the same time this simplifies some of the mechanisms actually because before if you had only packet style you still needed early retransmit which is a separate timer based mechanism whereas now the standard time based one kind of subsumes it yeah so a larger change is to merge TLP and RTO into something we\u0027re now calling probe time out quicks TLP and RTO were always subtly different from TC P\u0027s and it was not really particularly well thought out that one of them had a very different formula than the other so as you can see TLP was 1.5 times s RG t plus max AK to lay with also a min time out RTO was you know s RT t plus RT T bar these two equations have something to do with each other but are not particularly well related TLP sent one packet RTS n "
  },
  {
    "startTime": "01:15:27",
    "text": "two packets RTO has exponential back-off Tila P did not it there was really no I think really good reasoning for the difference between the mechanisms besides kind of historical accident so we combine them so the time out is now very similar to the old RTO formula smooth our TT plus max of four times RT t far and kate granularity this is actually taken from that see is tcp our RTO RFC so we\u0027re still very much in keeping with the tcp principles by using this value and you send one or two back three transmittable packets one this expires so oh yeah yes Touche thank you returns middle has also been renamed to active listening I believe that happened right before Bangkok but yes that is mm-hmm they are intended to be the same thing there\u0027s literally a wheel place one word with another because we transmittable head and they get ambiguous meaning is an editorial change ping ping is a returns middle and oculus are active listening yes I didn\u0027t I don\u0027t have slides for that but yeah it was a purely editorial change just matte one maps to the other do you some on Thompson just to clarify we Trent retransmitted all those notion that doesn\u0027t have anything to do with it whether you\u0027re gonna actually retransmits something it\u0027s perhaps a bad night it\u0027s the one we have right now and no no we have a cola something now yeah echo listening right yeah sorry we had a tree transmittable but it was wrong because you very well may know he\u0027s gonna ask you some questions about this one rightly so like I got what it used to be called and I still don\u0027t get what you are no wanting to call it it is now called active listening because eliciting act elicited it was yeah only miss that what does that mean but I\u0027ll read let\u0027s try that with the few accents because this is a strange word it\u0027s AK eliciting like something that actually gets gets a receiver to send an acknowledgement back Eric near so do we actually need those to be the same thing I know that right now it seems like everything is but say we wanted to in an extension Nasri transmit a frame but still have it illicit acts but those are two very different concepts that are admittedly related but very much not the same thing for the the recovery graft the word retransmitted doesn\u0027t exist anymore I noticed that yes that\u0027s because it\u0027s "
  },
  {
    "startTime": "01:18:28",
    "text": "not it really it was just a misnomer gotcha so that\u0027s the whole point is it confused people understand so we realign the word which is not quite the same thing as saying that they must be equivalent they we renamed the word to a more what I believe to be a more appropriate word which is active listening gotcha yes it is the concept is exactly identical as it always was before so just to make sure I understand the concept here is that you send a packet which would cause the other side to send you an ACK if it was gonna send axonal within the max actually yes that is the entire concept thank you it\u0027s it\u0027s in the it\u0027s described much more nicely in the definition section of the draft I did not put that in here because I did not realize that this issue was going to come up so we did remove menarche oh this is in keeping with the max actually or the mad draft from TCP and so men RTO is now replaced by a combination of K granularity and the max actually so next slide so Nick banks very nicely word up an excellent PR that took a bit of work from from a variety people but was really nicely done to redefine the concept of what persisted congestion is so before there\u0027s this concept that when you\u0027re RTO expired you reduce your sea wood so in TCP when you are do expires your you see or she went to - and you know that\u0027s kind of how you deal with persistent congestion and then you unwind that if it turns out that the RTO was furious so in quick we took the opposite approach because it was a little bit easier to implement and a little bit cleaner than instead of doing an undo process you actually wait until you get a signal and then as soon as you get the signal you decide was that a spurious RTO or not and so in terms of packets you send it\u0027s largely identical however there are certain cases in this process during do - where the timer\u0027s our chef that you can actually extend the RTO essentially and you might not actually have you know an RTO or to RTOS or three darts year as fire and instead you might just you know trickle out some tiny amount of data for that period of time and so the key concept here is c1 is reduced to minsu and when all packets prayed prior to an acknowledged RTO packet are lost over a long enough period of time Oh next slide sorry that\u0027s what I meant to be reading knew that didn\u0027t make any sense and the period is currently three tons the PTO time oh so this is in terms of time very very comparable to the old text so we tried to keep the functionally as equivalent as possible but this takes into account the fact that the application might be driveling data for a long period of time and the PTO timer "
  },
  {
    "startTime": "01:21:29",
    "text": "might not actually fire just a clarification that\u0027s about three times beauty with the exponential back-off right it\u0027s three times the PTO time out is the current default in the draft it\u0027s written as 2 to the K persistent congestion threshold minus 1 times the PTO yeah I\u0027m out ok and K persistent congestion congestion threshold defaults to 2 and so it ends up being 3 times the PTO demo next slide so there we are now going to limit active a to max actually so currently the the concept of active a is you have an R DT estimate that is actually observed and then the P R communicates ok you know there was this much delay back time before I actually sent that that action so you can compensate in your SR GG measurements however one could potentially say well I know I have 100 millisecond or it\u0027s T I\u0027m gonna give you like you know a 95 millisecond actally and you know that will cause you to shorten your timer and especially with the you know I mean RTO that could potentially like cause appear just previously we can spend a lot of data either intentionally or otherwise so next slide so nobody now limited to a minimum of actally and max act delay and that ensures that the peer is incentivized to actually advertise a max act away value that is kind of consistent with what it actually believes it can it can it can achieve and so if it ever does is an overlay Lomax actively value it\u0027ll just come out as you know into PSR TT measurement just like it wouldn\u0027t tcp excellent yes we we had some nice text on discover discarding recovery state so this came up earlier with the various keys ready proposals and basically there are a variety of situations in which you need to actually just discard your recovery state because there is no way that it could possibly be acknowledged so zero RTG rejection is one dropping keys is another and the solution is fairly straightforward you discard all the recovery state for those packets in terms of like tracking what\u0027s outstanding and you remove them from bytes in flight because they can\u0027t be acknowledged or lost and you will never know whether they are acknowledged or lost so this is a fairly mechanical process but particularly critical of given the conversations about key dropping we\u0027re having yes so previously the quick draft did recommend packet pacing if at all possible however it didn\u0027t really say like what to do if you weren\u0027t fast the packet pacing and so "
  },
  {
    "startTime": "01:24:31",
    "text": "now we\u0027re actually specifically saying that you should be doing slow start after idle if you are not pacing and if you are pacing then you can send up to an initial window and then you must pace out the rest of the rest of the window so we think this is in keeping both with kind of common desk processes and operating systems like Linux and also providing a suitable incentive to add pacing to stacks instead of sending very large person to the network proving proving myself so one comment yourself in the when I was reading the draft where this is defined it\u0027s currently defined as the idle state of the sender is defined as when there is nothing to send right and there is nothing outstanding in the network but in if you look at the tcp RFC that define how to respond to idle it basically says that there has to be a peep there\u0027s a period defined for which it has to be idle before you reset the clinician would know so that period is defined to be a birthday time-out essentially how that ends up being like me not even TCP but I think we need to need a more crystal definition of what idle is after which you drop the congestion window so that is missing and the other thing I would like to point out is is not not many stacks are doing TCP stacks are doing this by default not many stacks are doing pacing and that means that you\u0027re doing so so after a slow start over after I do okay yeah I think quite a few Linux stats are now doing pacing after I talk were yeah I mean can you file an issue editorial or otherwise about what the first point so yes thank you general you can just add a comment to that I mean I think there\u0027s there\u0027s a difference though right semantically when TCP defines this to be clear they do there\u0027s no talk about pacing at all so the expectation is that bursts are okay right after you\u0027ve gone into idle I think the the premise that we\u0027ve operated on and maybe that\u0027s that\u0027s the issue that we need to discuss the premise we operated on here is that if you are pacing then you should start pacing immediately as well and and the idea is that you shouldn\u0027t send a whole initial Windows worth or you shouldn\u0027t send the whole condition Windows worth of bursts up front now this is different from what TCP does and I would I would argue that TCP should also have this recommendation not to burst at any point in time but that\u0027s a premise that we\u0027ve applied here absolutely agree I think this is a good change all I\u0027m saying is that for implementations that are not facing the the idle period needs to be defined more crispy you mean more liberally because it is it is different right now it\u0027s just defined as immediately I think that needs a little bit more debate but yeah yeah I\u0027ll open an issue and then we can discuss Thanks here in Banjara so I think rate limitation draft has some solid rate estimation draft has some sort of a notion of idle connection which is a little more elaborate than what we are aiming for here so I was wondering if we "
  },
  {
    "startTime": "01:27:32",
    "text": "can apply that in general they\u0027re very possibly I think they can I go back to what John and Praveen were just talking about I think it probably makes sense to figure out what our our core goals are here it seems like a good core goal is to to ensure we don\u0027t drop large earths into the network because the network\u0027s likely to drop them and so we need to balance that with trying to be a little more liberal with implementations that don\u0027t support pacing so yeah if you could add a reference to that draft to the issue that Praveen opened that would be very helpful next one oh did you want o make a livin I would actually have expected Cori to be here because there is a TCP window validation right after like you spent some time and I only actually decrease your congestion window are you planning to somehow provide a reference to this let\u0027s say more about how to decrease your congestion window in idle oh there I think that is currently referenced in the text but we don\u0027t actually I think it\u0027s a informational reference but there\u0027s no recommendation in regards to that because if I understand aquatic it\u0027s like either you do pacing and you keep your congestion window forever high level right or you don\u0027t do pacing you decrease it so there should be some middle ground you should reduce overtime that\u0027s what it is do do you think that\u0027s common best practice or do you this is an honest question sorry you wanna figure the details all didn\u0027t start an issue for us Jana shakes his head Gouri so July anger we\u0027ve done this right in pcbm for quite a while it\u0027s called new cwv and that\u0027s the that\u0027s the draft that\u0027s actually that reference in the in the quick draft we\u0027ve gone through yeah sorry yeah the RFC now and that\u0027s that\u0027s already referenced in the quick draft and we basically said what what Ian said is that you know we have stuff they\u0027re saying you can follow the recommendations there but we\u0027re just doing the bare minimum required here I think the same considerations in that RFC apply here completely I think the bare minimum is resetting the window going first as part of the new TV thing and placing was the big thing and what you do afterwards I guess we can just read the read the document again carefully and see if we can see anything but pacing after being idle is the big thing that really makes a huge difference sorry to close that off I think can be ended up having the discussion on the issue here in the room Maria you\u0027re right it is that\u0027s exactly what the draft says right now is you collapse the "
  },
  {
    "startTime": "01:30:33",
    "text": "condition into as soon as you go idle and that\u0027s the conservative behavior if you want something more liberal than go look at me so you see the V is what it says a please take a closer read and yeah feel free to file an editorial issue if you think it\u0027s just sufficiently clear so we moved the pseudocode to the appendix the text was always intended to be normative and complete I think there\u0027s still a few more PRS to to make that actually true but there\u0027s also ideally a goal that you know the pseudo-code might compiled by that some definition of compiled in the board Python but it\u0027s it doesn\u0027t it currently not but yeah but the main goal here is to make the text a little more complete and to make it clear that people should be primarily relying on the text and relying on the pseudocode just to for clarifying questions evarin program Python in 12 years yes the the text for particularly the pseudocode for multiple packet number spaces has been greatly improved this is all pretty much editorial work but the draft 16 essentially said like you should do loss recovery in multiple packet number spaces and kind of left it at that at the current draft traffic 19 you know has the the various studio code updated so it kind of indicates what you should be tracking in multiple packet number spaces and is generally clearer about how this should have done that\u0027s up next I think we\u0027re at the end okay so these are just a bunch of and these are basically the release notes in 16 17 and 18 so you can thumb through those but this is the end of another slides you want me as they appear for issue discussion if there any questions or other comments and people have their discussions when have about the recovery draft now\u0027s the time Provine microsoft i noticed one more change that was not mentioned here which was not grow the condition window application limited that\u0027s a deviation from TCP and I think we need a lot more careful consideration before we put it in the draft Oh interesting point I think is it possible that made it into draft 16 and that\u0027s why I did talk about it\u0027s in draft 19 right now so yeah okay I\u0027ll go I can go dig that up and yeah I can find any issue as well because I think that means a little bit more discussion before we put it in sounds good anything else question right so we we have the new process for that we\u0027re already applying to transport and to TLS sorry that\u0027s also I think this might lead to questions that that I don\u0027t want to answer but recovery and HTTP at the moment do not follow a new process yet do people feel like specifically "
  },
  {
    "startTime": "01:33:36",
    "text": "recovery is ready to be declared as capturing the consensus of the working group in - 19 and I\u0027m going forward we would apply this more rigorous process or do we want to leave the editors with a bit more freedom to make rapid progress on on the next version I guess will be 20 and maybe then decide to rein it in and and just to remind folks you know the editor still have the ability make purely editorial changes in terms of rearranging things and rewriting things that don\u0027t affect the normative heft of the document relatively freely under the new process I think the question is whether that\u0027s going to be possible whether the rewrites might impinge upon that and need some working group consensus at this point okay pravin go ahead Praveen why I think a little bit more interrupt testing with like laws and they might help so we read out all the issues the other thing that might help is some sort of testing of TCP and quick on the same link I\u0027m not saying that we want to close the document and freeze it right so we want to move to so in for HTTP and for recovery we\u0027re still giving the editors basically full control letting them run ahead and change the text and if people disagree right we\u0027re rolling back this this would flip it around where any changed at that mark and I decide is not purely editorial would need to see work group consensus first so this is what we\u0027re doing in this late stage process at mark send email about and and the question is whether we wanna start applying a late-stage process to recovery and then there\u0027s going to be similar to the discussion for HTTP that sounds a reasonable to me okay I thought he would Ian thanks I think we\u0027re getting close I think it might make sense you we have a variety of changes I hope to discuss today on the issues I\u0027d like to close those out and then maybe start the new process it started with draft 20 okay that\u0027s that\u0027s my I feel I think I think we\u0027re pretty close to closing all the substantive non editorial issues that are open and so yeah that sounds like between now and London kind of yes that would be my preference okay so maybe we can do 20 and then do it on list consensus call contributed okay so on over here go ahead I think we\u0027re just now starting to see a lot of people actually doing Interop with recovery and finding bugs and I\u0027m encouraged that most of the bugs that we\u0027ve found so far I\u0027ve been in the implementations and not as much in the spec but at the same time given the amount of stuff that we\u0027re trying to focus on I don\u0027t think we\u0027ve been steered wrong yet in recovery land by having the editors have a little bit "
  },
  {
    "startTime": "01:36:38",
    "text": "more freedom to to fix things up as necessary so I don\u0027t I don\u0027t have any objection to to kind of raising the bar for that and switching to the new process but at the same time I\u0027m not seeing as strong a need for it given the amount of time that we\u0027re trying to put into everything else I agree with you right transport is the one that seen a lot of issues open against it continuously and that we want to control recovery has been much more stable and it\u0027s much the more steady development right and and it\u0027s mostly sort of that eventually we want to basically have we were kind of unusual when we started out because we wanted to move fast where we gave - yeah there\u0027s lots of leash and now we want to maybe become more like a regular ITF working group where is actually consensus based it won\u0027t change much here I agree with you it\u0027s just being clear what what model we\u0027re following right so I just want to interject one there the other part of this is that as we move along having the editor have that a much capability also puts a lot of responsibility on their shoulders and and part of the discussion around TLS and and invariants and and the transport was that that was in some ways unfair to the editors and so we\u0027re conscious that we don\u0027t want to put too much on Ian\u0027s shoulders here the other factor for me is is that in an ideal world I don\u0027t want all the documents I would like all the documents in one process rather than having a split process because that\u0027s its own kind of overhead so July as one of the editors of the TAT I can also say that we we really what Kinnear is saying what I\u0027m seeing now is that there are people who are starting to interrupt and finding things you just suffered of income and talk about something that\u0027s been there for a little while but that\u0027s because they are starting to actually pay attention to the traffic now and I personally think that the load on recovery has not been very high in the past it\u0027s not been very high and we don\u0027t I don\u0027t think we and EMI can I think we might agree on this but I don\u0027t think that there\u0027s a lot of there\u0027s not a tremendous amount of churn on this and in the draft itself I feel like there\u0027s some amount of agility at this moment would be useful so I\u0027m gonna I\u0027m gonna push back against the late stage process yet means proposal was that we\u0027re doing it we would maybe think about it for 20 and then I will also want to say that the late stage process really only makes the difference for design issues and I don\u0027t see very many design issues for recovery they\u0027re mostly editorial where either things were unclear or there\u0027s a buck in the pseudocode or the text but we\u0027re not like this we\u0027re not designing a new pedestrian control protocol here right we don\u0027t have very many of those like I don\u0027t think that\u0027s true I mean literally that the two things that that one other things that being brought up is a design issue the application limited stuff and we just fix a persistent congestion thing last which was a big design issue what let\u0027s not faceplant on the exact mechanics of this I think we could do this we talked about this again in London so let\u0027s let\u0027s drain the cues and then yeah I was just that we target London ish for the same "
  },
  {
    "startTime": "01:39:40",
    "text": "process breach in Tokyo which is surfacing the final issues last call for movie ad and then if editors feel like they need more time after that and we can discuss in London if they feel like they don\u0027t then we get I think that sounds reasonable yeah hi Brian Graham oh I would caution a little bit against this because I don\u0027t think that the interrupt testing on recovery has pushed any of the implementations anywhere near the end of their envelopes like which is where we\u0027re recovery stuff is is more likely to show up I would say that we really need to have a few implementations trust tested to the point like so praveen\u0027s praveen\u0027s you know run it on a challenging environment with TCP as well would be another thing that I would want to see before we say hey this is done enough that we can that we can sort of go at the home stretch Martin Gauri Martin Duke yeah just to amplify that I know about four to six weeks ago Christian compose on slack that we add a Interop letter or some sort of at volume testing possibly in parallel TCP and I think doing them in Interop is probably the next best thing actually someone deploying something like the latest draft in production which it doesn\u0027t sound like it\u0027s close Gouri fares back and yeah and I think the auditors are doing a great job here that they\u0027re really kind of trying to buy to the problem but the underneath they\u0027re trying to it with a new set of mechanisms to make these things work and I\u0027m worried we haven\u0027t done the congestion collapse testing and really whether we got the words right so I\u0027ll be really lost to freeze it I think they should be given time to do it until the numbered if it\u0027s not about freezing the docq yeah okay I know the process but everyone so we wonder we want to work as we are we have been working for a little while longer and and echo made a suggestion that maybe you visit us in London I think that\u0027s what we\u0027re okay yeah I I don\u0027t I get this on the amount of testing or the stress testing but it does sound like that was a good suggestion is we\u0027ll talk about this again in London if we think that it\u0027s appropriate then then and we\u0027ll start the process in the list right after London if somebody from the editor from the from the implementers wants to write up a proposal for a stress test for throughput tests that that we could all sort of implement I think that would be useful and and pick a letter anything else for Ian and or recovery we do so sherry can you do tomorrow is that okay okay great thanks so why don\u0027t we spend most the time on your shoes and then we\u0027ll put you in I think we can get through all I hope well that\u0027s Brian not true I hope we can get through all let\u0027s work on hope okay but I don\u0027t know if they\u0027re prioritized correctly do you listed occasion design issues recovery I sent you a link on slack that\u0027s mostly correct except they did not exclude editorial good moment then okay I think "
  },
  {
    "startTime": "01:42:46",
    "text": "I think I want to talk about them approximately in reverse chronological order so most recent first but I have to see the list where did you send this link it was on the slack editors channel it was probably the last message that gets sent okay yeah sorry I don\u0027t know I was looking back so let\u0027s do the initial arty at 100 milliseconds for comments most recently so 2184 so the the core of this issue is what should be the initial handshake timeout when you have absolutely no other information about the network for some reason what are the defaults so praveen at the very bottom helpfully pointed me to a paper by a Googler from 2009 that kind of did a cumulative distribution of parties over the Internet and said if you in the if you have a one second timeout\u0027 you will have a like two percent spurious retransmit right according to those slides that yeah I point to and RFC 62 98 recommends a one second timeout\u0027 my understanding is that is no longer the Linux default I think the one is default is 300 milliseconds can someone correct me if I\u0027m wrong and so there\u0027s there\u0027s sort of a divergence between common common practice and what is recommended in the RFC the the number we currently recommend is a default RT RT g of 100 milliseconds which results in a initial retransmission of 200 milliseconds so you know obvious here that we might be able to pick our 200 milliseconds 300 milliseconds cos Linux does it and one second because it\u0027s in the most recent RFC that references this text to delight with some pros and cons here picking a larger value by default is actually not all that bad because it might incentivize implementations to actually try to do something more intelligent like remember recent RTT estimates or do other intelligent things that might be overall beneficial to the network so I don\u0027t have a super strong resistance to it at this point I think I resisted it more initially saying that it seemed you conservative but certainly implementations can choose to use other information and that is explicitly called out in the draft so I\u0027m gonna let proving go first cuz he opened it but I please there I kind of agree so I think but the recommended value in the RFC should probably be conservative with text there that implementations may choose to use previous information to you know see it the oddity I think it\u0027s only a problem when you\u0027re completely going blind into a network because you could be like on a satellite link and then cause foodies retransmissions no reason I think that\u0027s the reason we have a conservative value "
  },
  {
    "startTime": "01:45:47",
    "text": "by default but yeah if implement I think we should actually make a recommendation that implements patience try to use the previous carriage path or TT as much as possible in that if we do that then I think the conservative value is not be that much of a problem in televised here is your suggestion that we use the one second value from RFC 62-38 that would be my recommendation I think we should also run it by the Linux kernel implementers so you do TCP to see why they changed it to three hundred milliseconds maybe they have some data that we don\u0027t know about yeah if anyone here could add anything about that idea for and go first a slightly different touch if we choose one second and those people who get routed over satellite hops are very long devious routes because the operators decide to do that for their traffic still function and if you have some caching method then we can also deal with it but please don\u0027t optimize just for 99% of people than 1% get a big problem yeah I mean we\u0027re mostly talking about one spurious retransmission of a single client hello so it\u0027s almost people it\u0027s every well well that bends Eliza\u0027s remembering information hopefully so to go with the point that I think we\u0027re converging on Michael yep Amina first oh I\u0027m sure yeah I have one question which will go to the initial oddity that it applied to zero additi connection or just to initial or one oddity connection in practice you would never expect it to imply to 0rc connections because your RTD connections should have the type of cached information associated with the zero TTT information and I think we call that out in the draft and if we don\u0027t we should I\u0027m pretty sure we do so we basically say if you think you know do reserve our two tier assumption you should really store their RTT of the resume connection what we don\u0027t say is what useful anarchie oh we don\u0027t we don\u0027t say what which if that\u0027s what you should be transmitted that we say I think we well yeah so just just a level set here how many issues do you think you need to get through here in like three okay this is the hardest one we\u0027re a little tongue constrained so let\u0027s let\u0027s focus please go ahead microcosm we have a working document about RTO considerations in general and T CPM and the statement there is you must not use a value less than one second capital at a must all right now the other thing you said you cash the Archie you use a cash value for the Archie Oh formula for the RT for the initial RTT from the previous 0tt connection which could be one year ago the in practice these credentials typically expire between 24 hours and 7 days so just one clarification that is "
  },
  {
    "startTime": "01:48:52",
    "text": "not just one spurious retransmissions depending on the value they take even with exponential back-off it could be two or three yes although the number of users are networks with more than like two second RTT is more than one second right so if you pick 200 then it\u0027s like 200 for about the one second okay lower than one second then there could be more seriously transmission x that do have a Trekkie greater than my composure it\u0027s not number of uses it\u0027s for some users this is all the time so it sounds like so I heard mild reference to to go towards one second but point out that maybe Linux uses 300 millisecond explain that if you can cache it you benefit so I don\u0027t know if that\u0027s the way forward here let\u0027s assume that\u0027s the proposal on it I\u0027m gonna think I\u0027m gonna suggest something here pretty specific you actually have Michael Dixon point of RT o consider as a draft and eCPM and you\u0027re gonna have to you know basically be seven between these two drafts for the iesg to stamp this anyways so the draft actually and I\u0027ve discussed with McCallum and the wording here and it\u0027s very carefully written it says in the absence of any knowledge about the latency of the path the RTO must be conservatively set to one second to just counter what Michael said this actually gives us room to do three hundred milliseconds or whatever small value we want in zero RTT and I honestly think that we need to we it\u0027s okay to be conservative in the non zero oddity case simply because it\u0027s not the common case anyways and so it seems to me that we should be focusing on the zero oddity so I think that\u0027s weird yeah I grain with why yourself so right so we\u0027ve got ten minutes left so let\u0027s drain these queues or move on to the next - you actually can can i ask does anyone strongly disagree with the idea of just changing the default - one second and then maybe tightening up the text about 0rt and making it clear that you really should try to use you know some more appropriate value if you have better information I see agreements before you answer that have a question or you use one second increment today but we we will sure I mean question because like if none of the browser\u0027s use one second then like it\u0027s like silly to say one second and claims generically use like like ten milliseconds that it\u0027s oi to say one I believe this will strongly incentivize us to keep a aw ma of recent handshake RT values and use that instead that\u0027s that\u0027s the implementation I\u0027m just making sure that\u0027s my implementation plan sure okay I\u0027m not I\u0027m gonna use one second when the browser starts up and I have no information and never again yes okay Tommy Tommy Paulie so I like the direction of this I think the one second with caching is a good approach with regards to zero or TT I think we still do need to make some recommendations "
  },
  {
    "startTime": "01:51:53",
    "text": "about what you do in the absence of any RTT information because you can definitely do zero RTT on a different network right so if I was on life I have never been on the cellular network before I don\u0027t know the RTT there I do need to differentiate that so when we\u0027re talking if we\u0027re giving guidance about caching RT T\u0027s I think we do need to be very specific that you can\u0027t assume the RT T\u0027s are the same across completely different network attachments that\u0027s a good clarification although I would add that most of the time when you\u0027re doing zero to T you also need to have source address validation and that would be different across SL what a Wi-Fi network so you you could do the resumption the the TLS presumption but right but you could do source address validation to be living descending like three packets or something yes sir sure sure but you still may if you are doing 0 TT just for the TLS resumption then you should take this into account yes that\u0027s a good point Craig Craig Taylor relaying Ingemar Johansson note that LT in some cases can have a ping RT t greater than 100 milliseconds because of various battery saving technology on the other hand a flood ping may give 40 millisecond RT t as the radio is kept alive so that\u0027s just a practical example of yeah sub1 at one second yeah mu can we just change the name from initial data T to initial one entity are you requesting a name to drop the English word and request maybe I should clarify with you just one point that in terms of cash values I think it\u0027s cash per path so it\u0027s a source test IP combination so when you change the networks you will be using a different source address and as is equivalent to starting the browser search basically your only new network with no previous target information so you should not use cash values soon get through one more unit so while we\u0027re getting through so what appointed up doing testing we\u0027re doing interrupt but it\u0027s actually very helpful to have two short initial oddities because that means you\u0027re a double handshake packets in flight and that triggered a bunch of bugs infil for interrupt testing you might want to keep using the the value for a little while longer I actually this is a question for the for the group there\u0027s a park tissue sender control delayed at ratio this is helpfully opened by bug Brisco there\u0027s extensive discussion but at this point I think we\u0027ve all decided that this is probably appropriate for an extension or a quick v2 is there anyone who objects to us closing this and declaring that I or someone else should write an extension for this Oh Bob do you still care I\u0027m not saying it\u0027s not a good idea and I very much want it but in the interest of all right Briscoe I just want to explain the implications of not doing it the number of networks of link technologies do act thinning and the reason for "
  },
  {
    "startTime": "01:54:54",
    "text": "primary reason for putting this you know and they\u0027re all written there are three main reasons in there but the primary reason was that I wanted to make sure that quick did that act finning for them to discourage them from trying to work out which were the acts and thinning them yeah it\u0027s a very good point yeah I think there are excellent technical arguments are you are you okay with punting this to version 2 or an extension or an illusion I believe so yes because that we can see whether it happens yeah I think some experimentation would be very valuable ok yeah I Jenna and God I think in the meanwhile you all definitely recommend as I\u0027ve had to a couple of people that the smallest packets you see on the wire are not necessarily axon quick I just sort of make that point because people have asked me that question for exactly that reason because they want to thin those packets I\u0027m like no actually the smallest packets are not necessarily AG they could be just packets carrying ping frames so don\u0027t do that can we can you open an issue and manageability for that you yes yes Oh to them so it sounds like we can close this as a quick v2 which is our kind of label for extension or next or whatever it\u0027s already part sir one more issue I warned it which I think it we can close now so there is a good number of TLS probes ok PTO is now be one or two twenty one 85 so this is this is fairly simple the the text has been updated substantially I guess my my question to both Praveen and the rest of the group is I believe the text currently says I cannot remember if it says you should send one and you may send two or if you should send to you or may send one but I think does that we\u0027re pretty much kind of on one of those two recommendations do people have particularly strong opinions on this or should we just stick with whatever\u0027s growing in the draft which I apparently cannot recall because that should one me too okay and then there\u0027s a consideration about why you might want to do - I believe about - wait actor I actually think it\u0027s about packet loss clip so question the participant congestion definition sort of depends on the dis currently right because we previously said it\u0027s three times PTO so if the implementation does in one time video do we need to clarify the definition as well this is the number sorry this is the number of packets I would say this is sorry this is not the number yes this is the number of packets this is the registration yes this is okay yeah so I guess this is persisting iteration and so so the text going to be issued for one and may for two "
  },
  {
    "startTime": "01:57:54",
    "text": "just should one like like you know that\u0027s actually perfectly fine okay this is not position condition this is the BPO yeah I think we can close that\u0027s good you got any more yeah we can do one more is there aa 23 93 I have known this for Nick banks ugly I don\u0027t think next year but there\u0027s a question of when K granularity which is the alarm granularity and the max act delay which is the peer specified max actually should be added whether it\u0027s before after exponential back-off this issue suggested should be after is currently before it seemed safer to do at it before and that\u0027s why I did it that way I\u0027m not sure if that\u0027s a well reasoned argument proving to me it seemed like we have replaced min RTO with granularity which actually kind of makes sense to me because even in TCP we never allowed you to set my not you\u0027re below the time of granularity so kind of makes sense that we cannot have a time or lower than that right and in TCP the minority is included before so in that spirit I think keeping to a glamour ID before is consistent with what TCP is doing like if you look at keygen right is a replacement formula at you then then what we have right now is actually correct but it right at the end I actually posted a comment yesterday where there was one possible change we could do to the equation we could probably take that offline but I think keeping K again and write it before is probably more consistent with PCP Jana you have 15 seconds July anger I\u0027m gonna agree with that and give just one more add one more comment which is the whole point of exponential back-off is that we waited this long and didn\u0027t hear anything back so we should meet about twice as long it\u0027s a rule of thumb it\u0027s not you know some sort of magical expression that\u0027s only going to give us the right answer here the point is to try backing off and backing on back now until you receive a response and then you collapse the whole thing down anyways so there\u0027s no long term effect to this I think just packing the whole thing off exponentially makes a ton more sense because that\u0027s the amount of time we waited all right thank you our cause this one no actually thanks okay Thank You Ian it\u0027s 11 o\u0027clock we\u0027ll see you all tomorrow hopefully Thanks I\u0027m missing one blue sheet it\u0027s ready with Bob okay good so if you haven\u0027t signed yet go to find Bob corner "
  },
  {
    "startTime": "02:01:12",
    "text": "[Music] "
  }
]