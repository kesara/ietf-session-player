[
  {
    "startTime": "00:00:04",
    "text": "foreign welcome all to ohai um we are your chairs Siobhan and Richard which is joining remotely and uh we have uh note takers I think Martin and Sean are going to help thank you so much I'll put a link into the origin if you can put a link into the chat for the for the notes we'll do yeah already [Music] um this is the note Bell you've probably seen it by now but please do note it well uh it concerns um the patent policy and um and as a reminder like there is the ombuds team that you should feel free to reach out to and also just specifically for um this meeting there is the on-site tool that you should be using that helps um get numbers for it kind of serves as a blue sheet and it's also really helpful if you can use that to join them IQ so that we can be Equitable towards people joining remotely as well uh helps with Cube management essentially and also if you're remote then make sure that your audio and video are off unless you're presenting um and headset is always recommended and as a reminder that if you're not speaking then you you must wear a mask um and yeah I think that's everything so just to make sure everyone knows the main protocol draft for obliviously HTTP was submitted and it's in the ad review stage so that should be"
  },
  {
    "startTime": "00:02:01",
    "text": "hopefully getting published soon and then we also adopted one new draft since last meeting uh and Tommy's going to be talking about that and unless there's anything to be said about the agenda um going once going twice I'll ask Tommy to present all right okay hello everyone so I'll be presenting our Discovery uh draft and this is about uh bootstrapping the use of an oblivious HTTP Gateway uh using records that we find in DNS this was discussed at the last ITF but as it's newly adopted I'm going to give a brief recap of the use case and how the protocol looks uh before we go into the open issues okay so this if you saw the presentation last time this should just be a reminder but if you didn't uh the Discovery Model assumes that we have a client that knows about a Target service that it wants to communicate with some HTTP service out there and the client also knows about one or more oblivious relays that it uh is willing to work with or it has credentials for or what have you and the target service Also may have an oblivious Gateway that it works with which"
  },
  {
    "startTime": "00:04:01",
    "text": "can be co-located with the target service um but essentially you can think of this as the target service is willing to be accessed over oblivious http so that clients that would prefer oblivious access to direct access can use it and so the goal of the Discovery Model is to let the client use some relay that it knows about it or it selects to reach the target through the Gateway that the target indicates um so this is the main model you can have a variance of this where the client is strict and will only communicate with this target service if it has an oblivious Gateway because it's not willing to communicate directly but either way works so in order to do this we need a couple different protocol mechanisms and there are three of these that are defined in the draft first is a DNS service binding parameter and this can go within the svcb or https DNS records which is effectively just a Boolean parameter that says this service has a oblivious Gateway foreign the second mechanism is we have a well-known URI that is the URI for an oblivious Gateway that is discovered in this manner and the third mechanism is a way to actually look up the oblivious key configuration on a Gateway URI which in the case of Discovery here will be that well known the reason the protocol has this shape"
  },
  {
    "startTime": "00:06:01",
    "text": "is that we need to make sure that the discovered Gateway and its config are actually strictly bound to the Target because access to this target through the Gateway is replacing any other certificate evaluation other trust you have in that Target and so you need to prove that the Gateway has authority over the target resource and this effectively means that you have to co-locate them um at least in terms of something that is able to uh do TLS termination for the Target and um past the normal client uh trust evaluation so as concrete examples based on how the document currently spells things we have an example of a DNS response which would have its normal um svcb parameters it can have some alpn but it adds a new parameter which is oblivious here the um actual well-known location is dot well known slash oblivious Gateway and the way to get the key configuration is to instead of doing a post you do a get and you say that you accept application ohtp keys and then you get the key config so it's quite simple um if you have questions I guess we could take him now or at the end but this is just a recap and we have a couple different open issues that I wanted to highlight uh so first I think this was from Ben was about the parameter name currently it's named as oblivious he was pointing out that this that is potentially too"
  },
  {
    "startTime": "00:08:00",
    "text": "broad you could have other things that are oblivious in the future particularly if you're using this not on the https resource record so the suggestion was to change it to ohttp that seems fine to me does anyone have thoughts or objections or should we just do it maybe hi uh so after considering the the sort of one of the other open issues here I think that um I think let's park this until we've solved some other things uh in particular if we I that oblivious changes the behavior of the DNS client for example telling the DNS client to not use DNS cookies then uh maybe we or for example if it tells the DNS client don't use other transports if they don't support obliviousness then maybe it actually is a cross-transport flag maybe it is not HTTP specific so uh I guess it's not clear to me yet okay all right so let's come back to this one then and let's have the other discussion the comments in the chat seem to be fine with ohtp in principle so Ben let's come back to this so the next one uh was a source of confusion and was a problem of a lack of clarity and a bit of confusion in the document that needs to be cleared up the issue number 29 was originally raised about the media type being used for DNS cases so The General uh the generic use case let's say you have an https record and I'm just going to some random HTTP resource in that case I think it's quite clear that you have"
  },
  {
    "startTime": "00:10:03",
    "text": "just normal media types being used for ohdp with OHP request and response and you have bhttp binary http one of the use cases that we have that's a variant of this is using this discovery to have oblivious DNS resolvers that are accessed over http and so this is the case where we have a DNS scheme svcb record and it's not https the current text has issues um I think based on the discussion on the issue the correct outcome is that you know really the media type from the perspective of the Gateway and the target are all the same as they would be for http um this is the Gateway does not see anything different it just sees oh HTTP Rec and response it has binary HTTP inside that gets turned into an HTTP request to the Target the target itself is a dough resolver and it just sees a normal do request over http um that is distinct from a theoretical case that you could have which would be uh ohttp wrapping just the raw DNS message because technically you don't really need uh the other bits of the HTTP response every request and response that are in bhdp it's just a wrapper but uh that does add media type complexity and is no longer just a generic Gateway and I think we should avoid doing that based on that um any questions oh and the nice thing is uh you know we had Odo before but now technically this is"
  },
  {
    "startTime": "00:12:00",
    "text": "uh DNS over oblivious HDPE so we can call it a Duo d-o-o-h anyway I'll stop now Ben so just as a document matter I want to stress that this is creating a Divergent so I I agree with Tommy's choice I fully support it uh I wonder if we should claw back the the ohttp draft and make some changes because right now section 4.6 of the ohttp draft lays out a sort of speculative design and a couple of paragraphs of like here's how you could use ohttp for DNS but it's not this it's the other thing so we're now going to be in the situation where we have a spec for how you do dough with ohttp and we also have another document that outlines that spec incorrectly um or outlines essentially a competing design that we do not have a spec for so uh I think this one we could certainly remove I mean I can let Martin no other speak remove the example um I think you definitely you can have other things other than bhtp inside and I think though oh the main ohtp document is correct in its advice of what to do if you do that but I don't think we need to do it here Ralph I feel like so this means if I'm sort of riding a doe server I'll have to support kind of door over H2 the whole Rage 3 and then uh dough over hdp and then there's the Adaptive DNS draft that is a different encoding right that is odor"
  },
  {
    "startTime": "00:14:01",
    "text": "yeah so right oh Odo is its own thing I I think actually this this approach makes it simpler for implementation even though technically you have a little bit of extra packaging because you can run a completely unmodified H2 doe server as the target service and then you have in front of it an ohtp Gateway that receives the ohttp request encrypted decrypts it gets the binary HTTP and translates that into a request to the unmodified H2 doe server now these are co-located so you're doing decapsulation Etc in you know two things right next to each other but it allows you to have unmodified doe server code if you have the DNS message directly within the ohttp encapsulation then that effectively is meaning you have a doe server that has to directly speak the oblivious HTTP request so that is potentially more work foreign in it right right but once we eventually get to a world with only ohdp you just need to OHP Gateway that's generic and you have a dose over that's generic you can just slap them together and there's no custom code written for this all right thanks Martin thanks Sean for doing the note-taking um Martin Thompson I'm not really sure what sort of um thing we're talking about here um because you can do all of these things"
  },
  {
    "startTime": "00:16:00",
    "text": "we probably should choose one though and I think for anyone doing uh oblivious dough then this makes a whole lot of sense I think this is the natural wrapping what's on the slide is what what is the natural wrapping for that sort of thing you have an oblivious HTTP Gateway that's just a an oblivious HTTP Gateway you have a doe Target and the two could be independently implemented and everything will be fine I think there's there is a separate design that says that you've got an oblivious dough I I believe it's DNS which looks very much different to this potentially has a different rapper potentially has a different thing on the inside but that we don't need to Define that here exactly that's what I'm saying as well um and really the only thing that's relevant for this document is saying when you receive the oblivious or whatever we're going to call it parameter over an svcb record for a resolver do you then assume it is this and we're just going to say yes it is this this time okay I guess Martin are you out of queue now okay um so that is that one I think it sounds like people are okay with re-clarifying the document to just mean this because it's a natural thing to do uh the one last issue I was going to bring up was specifically again around the DNS case if you're getting this from DDR which is the thing defined in the add working group where you have learned about your resolver from a special use domain name dns.resolve.arpa"
  },
  {
    "startTime": "00:18:02",
    "text": "in that case in order to trust the resolver you need to validate the IP address in the Target certificate and the text currently in this document says you know if you were doing um the oblivious dance to get that Target then either before you're doing things obliviously you need to just directly connect to that Target and validate a certificate or you create some separate proxied connection through a connect proxy or whatever you can still validate the target certificate and if you have validated the target certificate then you can go ahead and do the oblivious requests I think this is the simplest way to make sure we solve the security there um but the issue was raised so does anyone want to do anything else Martin yeah mountains again I think this is probably something we can leave for the DDR uh draft in the sense that um you have a reference identity that you're using to authenticate the server that reference identity may be different to the thing you put in DNS to query it but you still have reference identity and all of those rules apply on the DDR side of things as much as they apply here maybe a note but I wouldn't put any normative language around it if that's at all possible yeah that sounds good I I would need to check the current document but I believe it doesn't have normative language okay so that those are the main issues we have um I guess going back to the naming now that we've talked about this Ben did you want to"
  },
  {
    "startTime": "00:20:03",
    "text": "so the the question I I ran into was uh on the one hand uh so in the DNS record you run into this thing it says oblivious um does that only apply to if I'm trying to use do um or does that apply to any use of this DNS server so as an example I'm a suppose I'm a client that is fully prepared to speak oblivious doe and I get one of these service B records back um if I also support DNS over quick uh does the oblivious instruction also apply to DNS over quick in pursuit of some future specification for oblivious DNS over quick which doesn't exist right now or is it only for uh for use with oblivious HTTP so like maybe one answer so one answer is it only applies to oblivious HTTP your options are DNS over quick and there's DNS over HTTP or an oblivious DNS over http so forth another option is to say it actually applies to the whole record and so what we expect the client to do is speak obliviously um to any of these endpoints and uh and if it doesn't know how to do that then it shouldn't use transports if it basically if it supports oblivious communication over some of these transports but not others then it should probably only use the transports that it can speak to obliviously so maybe that's totally coherent can I answered that I oh so that that's not how DNS works you have resource records so that means in every research record you have a kind of oblivious or yes or no so if you have a quick uh record and"
  },
  {
    "startTime": "00:22:01",
    "text": "this would be an additional resource record uh the the service B DNS binding uses a single resource record to represent uh HTTP TLS quick etc those are all wrapped in no no there are no recent record sets you have a couple of lines each having kind of a specification one for DOT one for doe one for whatever no a single well it's not that's optional but uh you can form a single service binding record which says alpn equals H2 H3 doqdot yeah I don't think you should just to respond to event I think your original issue and your suggestion was correct I think it based on this really needs to be ohdp because otherwise we do not know what that future thing is or what it would need in a parameter so the presence of this means you can access this over normal vanilla ohttp with a normal Gateway doing binary HTTP in it and that is all it means if you have some other protocol it gets a new marker and that is not done here which is Richard Burns is an individual and I was exactly what I was going to say here like to just like off fortiori like we don't you know you we don't want to bundle all these protocols together because you don't know who they are and because this is providing the contact point we don't want to force all of those things to be implemented on the same contact Point um so like yeah definitely let's keep these things separate"
  },
  {
    "startTime": "00:24:00",
    "text": "how about this that should be better so uh I I agree with the prior speakers um in part because it was very confusing for me to hear you can do uh DNS obliviously um I don't even know that we know what you can do DNS obliviously means as a client the client's not oblivious right the it's the the point of oblivious these oblivious protocols is to keep the intermediaries and the and the server oblivious about what's happening uh and so the client needs to know what what kind of state it needs to trim uh to reject um all of that stuff and I don't think we actually have answers for that at the different levels so um uh yeah so so ohtp yeah um yeah I I concur with what everybody's just been saying I mean the the specification is two things it is an encapsulation format for talking to to the terminal Target HTTP server and it is a set of indicators that you provide to the Gateway and like in the in the end and so if in order to provide this functionality for some other hypothetical protocol like DNS you would then need an encapsulation format that is used to talk to talk to those um those systems and things and in the cases of you know in the in in the most likely that is like called TLS or called quick um and so like it's not like understandable like that's just like completely asking for this working group so like um so really specify the HTTP thing and and leave other things other people um and in particular like you know just to like harp on this a little bit if you were to say if what you wanted was to provide like a like a conceptually similar service to this that did DNS but was like the military they were tunneling the name of the Gateway is called mask foreign"
  },
  {
    "startTime": "00:26:00",
    "text": "I think that is all of the issues so on uh authors and I think we have enough to rev the document and take it from there I think that's it then thanks Tommy all right um we're doing really well on time tiru are you going to present the um oblivious relay feedback do you have any friends right yeah hello everyone um good afternoon I'm thiru I'll be presenting updates to the obvious relay feedback draft uh this was presented in the last idea of when we had received some good feedback and we updated the draft to address those feedback uh next slide please yeah next slide yeah just a quick recap uh for those who haven't read this draft this is primarily written for the case that was often rate limit incoming requests for various reasons um if the server rate limits the relay then it would harm all the clients using that way and that's the problem we are trying to solve with this draft next slide please so just a reminder that we are required to wear a mask inside so please do put on your mask if you don't have it on already foreign clients uh the feedback we had received from the working group was to use the work happening in HTTP API working group and be co-authored with the author of"
  },
  {
    "startTime": "00:28:00",
    "text": "that draft and he helped us update it to use the service parameters that's being defined in that uh right limit headers next slide yeah so that's the change that we're bringing in to update the right limit policy to have a new parameter to Signal the rate limit to the relay next slide so this was all there in the previous version so that was just a quick recap so what the draft does is it it sends two values one value to integrate to the relay to rate limit all the clients and the second value was breaking beta finding clients uh the big comment that we received from the working group was can that be abused uh by the Target uh if the relay starts rate limiting clients so that it would help the target to De anonymize these clients so we updated the draft to address these comments next slide yeah so uh if if in case the rate limit is for a client which is probably sending some malicious request which the target has identified uh then what are the prerequisites for the relative even start rate limiting so the first the first two uh prerequisites have to be that it has to be serving a large number of clients sending large volume of requests otherwise it's going to ignore that it needs to have a very large number of benign clients for which it is not doing any rate limiting versus the number of clients for which it has to do the rate limiting the third rule is that uh really does not immediately rate limit the offending client so what it does is it basically starts watching how many requests from the client are indeed malicious for which the value 2 was provided versus the request for which there was no value provided uh for instance some important it is sending a large volume of malicious request the idea behind that rule was malform request typically has some pattern which is matched by let's say a web application firewall uh whereas valid HTTP request should not be linkable in"
  },
  {
    "startTime": "00:30:00",
    "text": "case if you want the Privacy protection for obvious HTTP so that way the target will not be able to partition the anonymity set of legitimate clients so that was the idea that we enhanced this specific section to handle uh the big issue that was raised with regard to Red limit being abused by the Target for malicious purposes uh next slide please uh even in case where I think Ben raised this comment that a rate limiting uh field for all the clients could also be misused in case if for instance there are very low volume of clients sending uh requests once in a while so we have set email prerequisites for that that after the rate limiting there has to be a good enough high volume of messages from a large volume of clients and uh dividing the rate limit uh fairly among the active clients could create a timing pattern of requests that could possibly be uh strongly correlated by the Target to the anonymous clients so we're just relying on the mitigation technique that's already defined in the obvious https which discusses delaying requests to increase the nonhead we set into which in which the requests are attributed to so that should that we think should uh with the previous one and previously two we believe that should address the side effects of rate limiting all the clients uh next slide yeah I think we have addressed all the comments from the working group so far and the requests for working production um I'm not sure that I understand your argument about um about how this preserves the uh anonymity for the clients I I understand that you it doesn't permit the Target to fully partition the state space of all users but it seems to me like what you're saying is it's okay if"
  },
  {
    "startTime": "00:32:01",
    "text": "the anonymity uh or the or the is able to partition a small percentage of the users is that is that is that the mitigation that you're proposing here yeah if there are small number of clients then they will not apply a medication because that makes it quite easy for the Target then to identify the clients yeah but if there's a large number of clients then uh the relay and the relay receives this feedback that says this is the particular you know block further request from this client and the relay acts on that behavior acts on that request they can still you know that allows the identification of those specific that specific user right no it does not because the if you go back to the previous slides where we were discussing the the previous slide yeah we really does not immediately act on a request from the target it starts noticing how many requests are getting these kind of malicious requests so uh for instance if let's say there are 100 requests coming from the client and there are like 99 requests which are being said that they are malicious and there's just one legitimate request which is one uh then then I and it meets the other criteria then it starts doing that and and for a Target it's it's quite impossible to know that all these requests are coming from the same client if it had already known that then there is no need for it even to send that signal back to the relay uh this doesn't sound like it has the guarantees that I would want as a client to use this but but maybe I'm misunderstanding I'll let uh next books in the keyboard hi uh so in general I think that this is if we"
  },
  {
    "startTime": "00:34:00",
    "text": "the full sort of cryptographic seriousness approach of like you know there shall not be any leakage or like all leakage shall be Quantified and understood exactly but this is a really hard problem uh this is like because the timing we're talking about like timing correlation things that depend on you like what actual clients timing behaviors were and it's not even really clear to me how to formulate it like what are the assumptions that we're making that how much does our threat model cover um for example clients who are whose timing is supposed to be uncorrelated you know that they're issuing requests randomly but their timing becomes correlated because of a rate limit applied to them by the relay uh I think that so like even the threat modeling it seems non-trivial here and then this like client-specific targeted rate limiting is even harder to understand uh it's not clear to me that this state machine has a bunch of mitigations in it which uh which actually are so strong that I'm not sure that it actually works as a defense anymore like a malicious client can just send a lot of requests for a slash like a lot of really boring requests along with whatever it's malicious requests are and now the relay looks at the percentage of malicious flagged requests and that percentage is not high enough so it doesn't apply any rate limit uh so my advice would be forget about the client targeted requests let's just try an informational draft on the question of like good practices for a relay to um to implement rate limiting which by the way doesn't even have to be explicit even if you don't have an explicit rate limit from the Gateway at some point you're still going to have to turn away some fraction of requests and so I think there's some some interesting questions about what are the best ways to do that that leak the least amount of"
  },
  {
    "startTime": "00:36:00",
    "text": "information how do we model that problem that's an interesting solution but if we'll look into that yeah thanks sorry I'm a little puzzled how are you defining malicious not like technically but we're using the properties of malicious are any many malformed requests which matches for example your web application firewall patterns of attack right sorry which what if you have a if you have an attack pattern in the HTTP request right like like a large garbage volume which matches some specific web application firewall rule which you have seen some alternate family using and you see that they're using some specific headers that's how you detect that it's coming from that and and you don't see that coming from average directly so I'm sure tkg is concerned about the anonymity set there's no way for the as far as I can tell there's no way for the Relay to verify that these are malicious and not just cleaning wishes and it seems quite clear you can use you say you can't be used for partitioning but of course it can because I just like so so I I believe like I see a set of requests that I think are all from one person and um I don't know for sure but they seem to be correlated and so what I do is I fly them all as malicious and then I see if that to see if it throttles back and if it does then then I verify the guesses for one person and since you have no way you're going to find them malicious that doesn't work so I think if you want I think so I think like I'm also concerned about the ability to actually demonstrate this is safe I think um you know one potential Avenue would be to um uh um would would be to um have the uh the server the server Supply the key to the relay so they really could verify for themselves they're malicious of course now we're in key committing um I'll just say that right now um but like I just don't understand I don't think it's gonna work to make the servers more that things are malicious for the reason I just indicators okay um and I I guess I understand people think it's a problem but like you know like like I mean it seems I guess I guess it seems to me the example you"
  },
  {
    "startTime": "00:38:01",
    "text": "just you just said like filter it out like I don't really understand I don't understand what the value why is it helpful to throttle this data you can already attacked the problem those malicious requests typically a filter that you drop those records yeah but if it's if it's getting overwhelmed right and it wants them to be dropped right why if it's getting overwhelmed pretty scary but I mean but it's because it's slower to process those requesting the other requests yeah it's it's just trying to save its uh resources from processing those bad reviews yeah like I guess I'm just not that I'm not that excited about computational Irish attacks here all right so we're at time on this slot um thanks for the presentation too it sounds like we need maybe a little bit more clarity on the threat model here before we we move ahead um so yeah I think we're going to take that uh take that back to the list thanks all right checking the agenda here looks like next up is Ralph Giles presenting remotely on uh unreliable ohttp extensions Ralph all right I'm trying to get the slides to show up did you request a SlideShare there we go great take it away all right so my name is Rob Giles I'm presenting work I did at Brave along with Chris Wood who was a Cloud Player and this is a proposal for an extension to oblivious hdb that for unreliable delivery so uh for those of you who are new to O HTTP which is probably not most of you but was certainly me um so the idea is this works is that you have a client that wants to send stuff to a Target and without them learning too much about each other so there's a relay service the client encrypts the"
  },
  {
    "startTime": "00:40:02",
    "text": "data for uh using the gateways key send it to the relay the relay forwards it to the Gateway stripping the IP address so everybody doesn't learn what's in the client's request the Gateway doesn't learn what the client's IP address is and the Gateway proxies the unwraps the request since it's the target the target responds like a normal HTTP server would sends it back to the Gateway the Gateway encrypts it to the client sends it to the relay who remembers who the client was and sends the encrypted request back to client okay simple enough so for uh we have an application where we're using the star protocol which is there's been some interest in over in the Privacy surveying measurement group to do Telemetry submission like things about it or things that applications are doing they want to submit it to some server and the way this works right now is the client uh constructs the message sends it to a web endpoint and rather than the web endpoint doing processing directly or speed and simplicity we just shove it into a queue and then there's a batch job that runs on separate uh with separate missions elsewhere that pulls the log down out of band and analyzes it in a batch and so this simplifies the infrastructure the endpoint can be really fast all it has to do is append to a log and uh because we're doing sort of aggregation of the data it's not helpful to look at the data individually but we can look at the IP address if it's coming from the clients who can associate the eventual things that we process with the client's IP address so we could build a profile of individual visual clients from what they send so that's not as privacy preserving as you'd like so if we use oblivious HTTP we can solve the IP we can break that link with an IP address we just start to relay which talks to a Gateway which talks to the endpoint but now we need two new services and since we already have this custom thing that's listening to for the endpoint maybe we can just teach the battle oblivious HTTP and combine the Gateway in the endpoint so the relay talks to the endpoint which then stuff thing is into the log so one less"
  },
  {
    "startTime": "00:42:02",
    "text": "service we have to run and then the log could be processed out of band later so that works sort of the same as before we just added the single service we have to put in to handle the relay but teaching the endpoint about oblivious HTTP complicates the code a lot I mean remember it's supposed to be really simple it just takes bodies from like Jason bodies that's been submitted by the client and it shoves them in a log file so now we have to implement oblivious HTTP we have to do so we can do the request and response serialization we need to provision keys for it and so it's a fair amount of extra code and security service we need to audit and the endpoint was supposed to be simple so the inside I had think about thinking about this is the only reason we need I believe it's HTTP parsing and hpac encoding and all that sort of stuff and so we can return a 200 okay because this is just a submission service we the client sends data it's a report or something it's done and it doesn't the server doesn't ever actually return any data it's just yes I got your response and because we're doing our aggregation processing offline in a batch job we don't even validate the message content so the client is sending nonsense we don't find out in time to tell them you send nonsense so there's actually no real value to encoding the empty body with the 200 okay Response Code with oblivious HTTP but that's what the spec requires so to address this we uh Chris Wood and I wrote a draft for unreliable delivery is what we're calling it which is just an extension that says instead of requiring that the Gateway return an encrypted response to the relay which is sent back to the client what if you were just able to say 202 accept and return an empty body and that way the Gateway doesn't actually have to understand anything about oblivious HTTP other than this is what you respond with so it's two lines of code instead of 500 or whatever it takes to implement uh"
  },
  {
    "startTime": "00:44:00",
    "text": "oblivious http so simple enough uh the client could opt in by setting certain headers uh what we suggested except and then a message oh HTTP acknowledgment message type so signal that's okay with this Martin Thompson suggested maybe we could use the prefer respond to async header which has a bunch of stuff you can attach to it to say how long you're willing to wait for an answer and things like that uh also given that the in at least in our application the Gateway will probably only support this method uh probably it should be possible for the out-of-band configuration that tells the relay how to talk to the Gateway could also say we only accept this so the Relay can reject traffic right away that doesn't that tries to do something else so it seems to be there are some advantages to this like it makes it easier to secure the Gateway code because you don't have to do code you don't have to do key provisioning and it's just much simpler code it gives you more ways of deploying oblivious HTTP within different Frameworks and another nice Advantage is that because you don't have to deliver right away because the Gateway and and the Relay can just respond 200 accepted right away and then buffer the message by H delivered later that gives you a much larger window when you can Shuffle the data send it in a different order and that helps defeat traffic analysis where you try and figure out which clients and which message based on when it was sent on the other hand there's more config to worry about and the relay at least has to be configured to accept this and not reject it as a not valid oblivious HTTP and it's not suitable for a lot of applications because you don't get any acknowledgment other than the relay hurt you um there's no way to re-transmit if the transmission fails there's no way to transfer State and confirm the state has been transferred if that makes any sense um Ted did you want to ask a clarifying question right now or was that just in the queue for a later question okay well I'm at the end anyway this is so that was our motivation and so I was"
  },
  {
    "startTime": "00:46:02",
    "text": "just curious if is there interest in the working group in addressing this as a use case um what do you think of the draft are there any technical improvements you could suggest because it seems like there's lots of ways we could do this and it's unclear how it interacts with other things like service discovery uh Ted Hardy Cisco uh I I usually try and come up here and say what I'm enthusiastic about here and and unfortunately in this case I'm afraid I'm up obvious uh occasional curmudgeon hat on um and I apologize for that I think what you're actually trying to do is to create an oblivious star service so looking through the draft and and following through to the distributed secret sharing for private threshold aggregation I get why you would want a um an oblivious star service but I think what you're doing to try and get there sets my teeth on edge uh there's a whole bunch of stuff in in your draft in the way you're using HTTP uh that just kind of hurts um so an example of this is is 202 in general for my experience is a a final server's answer hey we've accepted this but we haven't processed it you're using it in a relay in a way that I don't think actually matches what people in the web world are going to necessarily expect and in your description of how you signal this um you're using you know accept headers in a way um that that really are bizarre to me in particular using um accept headers where star dot star means that you might use this just it's bizarre um I I think the the basic idea here that you want an oblivious star service well good go ahead I just don't think that trying to make the oblivious HTTP become the star service by throwing in these um uh these message headers and and reusing"
  },
  {
    "startTime": "00:48:02",
    "text": "202 the the way you're doing it is is fine so if you think what you want this working group to consider is adding a um a deliverable for for an oblivious star service I think I would be behind that but I wouldn't actually want to start from this draft and I apologize for being the occasional curmudgeon uh in that response I'm just going to inject myself here real quick with a clarifying question um could you clarify to what degree this draft is specific to Star and to what degree it's kind of generically providing a service where there's no response needed it's just a submission endpoint I think of it as as completely orthogonal to Star I mean the way star Works means that we have this particular architecture where we have to submit things and we don't care about writing back because we're relying on the crypto to make sure that's Anonymous except for the IP address but it seems like you wouldn't have any example where you have this sort of simple input thing where you want you don't want to have to generate the keys you don't want to have to have a key so that you can just respond okay I think it applies to any application like that so it's not specific to Star it's not even specific to Telemetry it's just sort of this Edge case where it seems simpler not to have to run two services to talk to your target when you're already having a custom endpoint so that's really the use case that I care about okay thank you oh actually I'm sorry I think Tommy is next to the cube time all right here we go audio is on um yeah I mean I I agree with Ted that the spelling in the HTTP bits needs more discussion however I am pretty positive about this I think the you know I don't want I don't care about a response use case of oblivious http makes sense um I don't personally like the use cases"
  },
  {
    "startTime": "00:50:01",
    "text": "I've had for oblivious HTTP have wanted responses so far but metrics collection and others can definitely use this I think it is applicable to more than star and so I think it fits within this working group so I think we should adopt it I think we should adopt it with this document um acknowledging that the details can be respelled I I imagine you and Chris are not particularly wed to I'm not what is the way it's written at all like I just want to be able to not have a key in the in the Gateway right and I think that's something that the working group can work on together and I think it is an ohdp problem and so we can do it together here um the one suggestion I would make is maybe renaming it uh saying unreliable every time I hear it I have to remember what it is again um so maybe something like no response submission only one way ohtp something like that all right thanks yeah um I I guess I'm less positive about this um so I think for several reasons so uh first I think like like the the sort of like the motivation for this of like you know I'm gonna Implement like a secret sharing protocol just polynomials but I'm too lazy to do hpka like I just like does not motivate me at all um like um it's not lazy stuff it's about protecting the uh but simplifying the implementation so there's less Security Service like the endpoint that's doing the HTTP hpac is has to be open to the internet whereas the thing that actually does the decoding in our proposal is it's not by log server yeah you've heard of rushed I imagine um so uh I I just I this just seems like I like like I'm sorry the the motivating case of like you know of like this whole line of operation is that is fine to expose those things the internet so I like that this is like a substantial security Improvement I just don't buy"
  },
  {
    "startTime": "00:52:00",
    "text": "um the um all right so but I mean but I think but they're more like relatively like this just changes the entire properties lectures of this system of HTTP in general where HTTP is a protocol where you send a message and get a response and that response says things and maybe it just says thanks but it says something and so to say well no I just don't want the ACT that's not the way designed to work and and so it's like and and you can and you can see it actually has a significant impact on the threat model which is you taking a system which had an end threat model for delivery and now has it in the middle front mobile for delivery and so if the um you know if the if the uh if for instance the proxy decides that it simply wants to like gag some set of clients because if we do something so that's the reason two reason three is that the designing a protocol that is like by Design um you know one way like this where the client gets no feedback whatsoever when something is wrong um is like I understand you don't want to do the VSS checking in line but like format checking like lots of things can go wrong and to have a design that basically is like the client should kind of blind these 10 things to the server and not care if they cannot care if they're valid like that seems like fundamentally incorrect critical design even if you know all these topics so I'm like less positive about this workout yes um I I don't think it needs more break time at least all right thanks hi uh Ben Schwartz I think the the thing that I find interesting here and and compelling is really the batching idea the delay in batching um for privacy and for efficiency reasons I don't really see a security benefit and it's not about the efficiency of the of the Gateway or Target really they can always batch and buffer on their end if they want it's really about efficiency and privacy provided by the relays this I view as an increase in the Privacy"
  },
  {
    "startTime": "00:54:00",
    "text": "that that can be offered in oblivious HTTP in some cases um you know I I think that the points that have been raised here are definitely valid this is in a sense a very deep HTTP level change um and you could imagine spelling it as like a header to the proxy that says uh you know I don't need a response that has otherwise in a sense nothing to do with with the rest of oblivious http um it could apply to any HTTP request proxy so uh but I do think that's a very interesting thing to be able to specify uh I think you know to some of ecker's points it would also be really interesting to take this in in really a like high latency messaging Direction where you sort of treat this as um as like oblivious SMTP like this is uh because this really looks like a an email mixed net and in that case you actually can get a response it's at very high latency and that high latency response can be useful for things like detecting misconfigurations or confirming that you're not subject to a long running attack foreign which is like besides gagging clients I wondered if this gives a method for the Relay to identify clients by batching in certain ways to indicate properties about the clients or you know there's funky things I think you could do and I I don't know that's like an addition to the threat model here that's something to consider thanks great"
  },
  {
    "startTime": "00:56:01",
    "text": "David scanazi HTTP Enthusiast I'm find myself agreeing with a lot of people including people who are strongly disagreeing here so um on one hand I I see why this is useful I can kind of uh buy that like in some submission case you want to simplify things but I also see that like uh when this goes in front of as you know it would because it the way an impacts HTTP semantics we would tell the HTTP about them and they would like probably pass out uh how do we uh square that and I was thinking about it uh so you have two benefits from doing this one is that the client can far and forget quicker and the other is the uh less cryptography on the uh an encryption on the uh gate weight if I'm getting the terminology right which one of those do you care about is it both or a single one my motivation was mostly the Gateway I mean the client okay in my case yeah all right no no that makes sense in that case would it make sense for you to keep HTTP the way it is and just send an empty response uh because like you know HTTP we already have a flow for errors where you can say like no I'm not going to give you an encrypted response because like I've forgotten the keys or something and you could add a response that is like yup A-Okay I'm just not sending you a response so the and then that triggers the relay to say oh A-Okay back to the client the same way where today if it sends an error the uh the the relay sends that error back to the client so that I think addresses ecker's concerns that uh like there's no longer a response you don't have any way of hearing errors back because I think that's a real concern but it solves your cryptographic problem so that might be a way just a thought okay I think that's what I'm trying to"
  },
  {
    "startTime": "00:58:01",
    "text": "do but unless I'm misunderstood I don't think that address is ecker's concerned because it breaks the tunnel between the encrypted tunnel between the client and the Gateway because the Relay can see that you've returned an empty response as opposed to incurring in returning an encrypted blob which represents the empty response yep that makes sense thank you again uh I apologize for for getting up to to kind of restate something but I think I want to pull on something that was set up in the chat room and connect it to something that that Eckert said it's like if there is a use case for this that doesn't require the oblivious property um then the clear thing to do with this document is to take it to http and work through the HTTP process to to figure out whether there are new methods involved new response codes involved Etc that's if if that is true this is the wrong working group for it because that's where we do core changes to http if there isn't a use case for this submission service that doesn't require the oblivious property then I think you have to do a much clearer job about describing what it is about the oblivious property and the submission property that have to be tied together in some way that's better than the threat model change uh that I see in the document now I I honestly don't get that personally and it may be just because I didn't read deeply enough into the interconnection you're making with with your use case but the document I don't think carries that out of why if this is a submission service it must be oblivious to be a success and if that isn't the case then this is the wrong word oh I'm out of order I guess"
  },
  {
    "startTime": "01:00:02",
    "text": "oh um cool I think to move on uh Ben did you want to present thanks Ralph okay uh causing that rough it sounds like the feedback here is that you know there's there's some folks who are um in tune with the use case but it sounds like we need to drill in a bit on the how we measure the HTTP semantics and kind of how we make things fit together nicely so thanks for the presentation thank you okay double check so this uh I presented about this idea at the last ITF meeting um and since then this draft has had a I I've made a lot of changes to the flavor text and basically no changes to the actual technical content but a lot of the normative language has shifted um definitely people seem to think that it was too normative uh and it seems like people still think it's too normative but um so the the technical proposal has not changed the biggest difference I would say is that I've tried to generalize the description to also talk about how this idea applies in the Privacy pass context and it seems like probably uh in the future this draft will will move to privacy pass if there's interest in continuing to discuss it at all and uh and so that you know fair warning if this is a topic that interests you"
  },
  {
    "startTime": "01:02:00",
    "text": "you might want to start coming to privacy pass sessions so just as a reminder there's Now new terminologies that I've changed the terminology compared to the previous draft but this is the same idea there's a client there's a proxy and there's an origin that holds some desired HTTP resource it could be any kind of resource and our goal is to fetch that resource in a way that guarantees both consistency and authenticity consistency meaning everybody sees the same version of the who wanted to send uh I think I probably just lost my connection to meet Echo I'm going to reboot you're fine now oh no sorry about that I I've had an unstable connection to meet Echo hmm so that the key idea here really is uh that if you need key consistency you probably also already have a proxy and you probably already trust that proxy not to reveal your identity to the the destination where you're trying to use this key consistency because otherwise your IP address will give you away to that destination and uh and so the key consistency won't be sufficient to help you protect your privacy and avoid becoming linkable so if we're sort of willing to make that assumption or narrow our use cases to cases where that assumption applies then uh the whole problem becomes a lot easier the key consistency problem you only need key consistency among the other users of this proxy because you're"
  },
  {
    "startTime": "01:04:02",
    "text": "distinguishable by essentially the proxies exit IP from users of other proxies so that narrows the problem enough that you can actually solve it using plain HTTP caching rules and we don't need to invent any new logic when we apply the HTTP caching rules in a very specific way which is one of the intriguing things about this design um I'll just note that the design the draft has a bunch of language in it about how to avoid different kinds of leakage there are a lot of different ways that you can leak and and I think these these ways are not trivial they're not it's not obvious how this leakage happens so I think it's worth documenting but uh Martin on the mailing list pointed out that this normative guidance is not actually necessary for the protocol to work so we'll have to figure out some way to um put up warnings of the appropriate kind without necessarily invoking normative language but the real thing that I want to present to the working group is this question is this actually how we want to do it because the remember this is not an abstract design about like here about key consistency this is a very specific protocol and there are a lot of different ways that you could build a protocol like this and they have quite different properties so I want to mention two things that are not what's in the draft one would be to employ bespoke consistency logic at the proxy slash relay point this The Trusted proxy intermediary that is uh that we're trusting to help us protect our privacy right now the draft essentially applies some some very subtle and specific interpretations of some existing HTTP Concepts like if"
  },
  {
    "startTime": "01:06:00",
    "text": "match and immutable and if you just while the those interpretations are are essentially within the standards they're not necessarily the default reading of those standards and so this is a little bit of a sharp edge right we we're claiming that you can reuse effectively I'm I'm claiming to you that we can reuse existing HTTP Machinery but actually only if you configure it in a very specific way and the other problem is that because HTTP resource caching doesn't have any built-in concept of multiple versions of a resource like one that's about to expire and one that sort of is already also valid and then the Cache can hold both of them and make sure that the clients are gradually updated from one to the other before the old one expires as far as I can tell you can't do that just using HTTP caching logic and so because of that this design has a Thundering Herd effect where all clients have a single version of the resource and if the resource ever changes all clients need to flip essentially simultaneously to the new version and so you could get load spikes at times when that happens maybe obviously I have not implemented this and another question is do we really want this double check or do we just want to sign the object because if we just sign the thing like in the ohttp context if we sign the key config with uh with essentially the certificate chain of the of the origin then of the Gateway origin then we don't need this double check we only have to fetch once and and everything becomes well that the network the flow diagram becomes a lot simpler but the setup becomes a lot more complicated now I need to build some kind of signing system and you know handle key rotations resign my object before my certificates expire so so this is my big question really like how do we want to do this"
  },
  {
    "startTime": "01:08:11",
    "text": "all right so Ben is that uh time for discussion yeah all right I have a suggestion on how we approach both of these questions and that is that we ask the Privacy pass working group to take them on this um this this sort of line between these two groups has been sort of a little fuzzy on this consistency question and we decided to adopt the key consistency and uh correctness uh draft in that working group and it seems to me like that's a good place to to have that discussion where the sort of architectural questions about how we do consistency and the requirements and what what have you and the general approaches I discussed there along with this as a fairly concrete instantiation of these things I'm not sure what you mean by the first alternative here in terms of concrete specific steps and so I'm a little leery of saying let's just take existing specs and then reinterpret them very creatively that's risky and I'm certain that I don't like the second one because uh the signing thing it is much harder to reason about and I prefer to avoid that sort of thing I think two requests is for the for this sort of thing perfectly tolerable okay Tommy hello um yeah so overall I like the approach of doing a get and something through a forward proxy um and that part I I like that it doesn't require any new protocols being designed or applied like it is merely a technique that a client can apply if it has"
  },
  {
    "startTime": "01:10:01",
    "text": "proxies available to it I think specifically for the document all of the dependencies on the access service descriptions and other stuff I think that should just go away like that that's fine if that ends up existing but I don't think that's fundamental to this yeah I have removed that uh those are those are now they are I've still structured the examples that way um but there's no there's no longer any normative dependency on that got it okay I was I guess I was looking at the most recent version and it is I guess yes examples as like kind of like a unadopted thing like it's a bit distracting um okay um so I agree with Martin that we should talk about this in privacy pass uh now that we have key consistency adopted there I personally think also like that all of this can probably go into that document if it is just about technique applying and not new protocol work um and then the question I had for you just about the caching bits what happens if the caching headers you get back are not what you are normatively requiring in your document but the values of the keys still match via my double check what's the failure mode there so the the client is supposed to essentially reject right this means that the origins the attack is uh so if if you don't have cash control immutable for example then the server can send you uh can can reply to the sorry the the Gateway can rep or the you know HTTP terms the Gateway can reply to the relay with a"
  },
  {
    "startTime": "01:12:02",
    "text": "um with a key config with some long lifetime you know a week um and that can go to the client and then the the Gateway acting as a different client can can send another HTTP request to the relay that causes it to flush that cache entry and replace it with a new key config so now the next client gets an its own you know different key config that also has a cache lifetime of week now both clients have long-lived distinct key configs so and the and the requests that go over like the forward proxy uh the relay server manages the timing perfectly so that it gives out the same evil config to the same client uh uh so the the client keeps it cached locally for a long time um it doesn't need to the relays but the point of double check is that I'm checking that I get the same key via two different methods that are presumably unlinkable and so if you're feeding so for the ease right so then so client a and client B have different key configs um they send get requests um directly to the uh to the Gateway origin with if match header with an if match header saying here's the basically the version of the key config that I want is this one valid and and they get it back again and the reason for that if match header is that the Gateway needs to be able to rotate the key config and it doesn't know a priori whether a given client has the old one or the new one so uh so it can't just always serve the new one or the or the it sounds like maybe we're"
  },
  {
    "startTime": "01:14:00",
    "text": "that part of this match is causing us to trip on ourselves a bit and maybe there are other approaches to handling key rotation anyway we can discuss more thanks Becker so I found realistic caveats quite concerning um um like and I'm quite concerned that like perhaps AGP caches not behave the way what everyone hopes they behave um and they won't be very sad people um um so I think like by the way to try to tease a couple things apart which is detection from uh in particular detection from enforcement right so like if we just went back to the dumb design right and forget about caching you say look I just query directly and like we're through a proxy and the IP addresses are different and now you're not timing attacks I suppose this is why is why you don't want to do that right um that's how we get to this this design right uh yes locations different IP addresses and check the match right yes you also like I said need to worry about uh how to handle cases where the key config has actually changed but sure okay so I can imagine it's all that like you know um forcing the server to get a list of every key it's ever used and and that kind of thing right um you know you haven't maintain our block a blockchain basically of you know a hash Channel lookies um so um I guess this gets me to my second point which is um that say that we have mismatch what then and um and the natural Thursday is okay well I'm like culinary times um and but like I don't want to be right and so I think you actually need the key to be signed by by the DVD certificate anyway and the reason is simply that that's the only way you can demonstrate that you can Target someone's reputation in this base and so like if you think of the logic of CT right logic is a t CT is is that the certificates are all signed and there's an assurance by the um by the ca"
  },
  {
    "startTime": "01:16:02",
    "text": "that the certificates of the log and any time you see a signed value does not log that's evidence in office right and so I think that I think that we need the same structure here which is basically some kind of structure here which is basically that there's a plot that that there's an understanding of what the values or value is supposed to be and any value any value that's outside of that of that period um if self-verifiable or self-verifying therefore it's kind of official evidence of fraud but I just like I guess I just worry that we're gonna build cooperatus that's going to allow us to detect this kind of malfeasance and then you're going to like and you're going to be like you know like basically reduce the posting on Hacker News does anybody else see like this right like this book is key and it's like oh but then like I see the hacker newspaper I take it down it just seems like very complicated I think we're going to end up having to sign anyway and so maybe I'd like this so and so like I guess if you buy that argument then I'm not sure what that gets then I think maybe by that argument then you may have to step back and say if I'm signing then what other pieces of the puzzle um are are changed right um so that that's I I don't know what I think about this but I'm just trying to like work through the entire problem at once instead of in pieces so next again speaking this individual contributor here um yeah your very first slide here but had uh end Beyond um so I kind of wanted to push on that a little bit kind of ask what the right level of thinking about this is um you've talked a lot about key consistency but as I think Nick Jody pointed out in the chat there are a lot of other resources on the web that one would like to be consistent like you know the Nick reads privacy policies I'd like to like make sure that I'm getting the same jQuery as everybody else um so I mean you you could scope this it seems like the requirements are broadly pretty similar with regard to those things even to the level of reactions like Ecker uh which is phrased um so I wonder if this is actually a pretty General thing now it may be that"
  },
  {
    "startTime": "01:18:00",
    "text": "um you know if this is a critical property for something like privacy pass that would be you could it could be addressed there first and then generalize other things but yeah it's not really this is seeming more General than an Ojai problem so like maybe the right direction uh to go with this is kind of you know if it's really critical for privacy pass which it seems to be like hit it there first but with an ice these other applications that's an interesting point this is really talking about HTTP resource consistency at this point not just key consistency is Eric in person or remote or remote perhaps Eric is trying to find them available now for some reason might meet Echo is taking forever load up for me today but you're on Audible yes okay yep so two comments first just sort of for the info people in here repeating something I said the Privacy pass working group a couple of weeks ago both this and the the other consistency draft the informational one they both work well in my mind either here or in privacy past so let's pick one and work on it there and looks like at least for the other draft it was adopted over there in privacy passed so okay let's let's shift this over there now too just so they can be together in one place and that makes perfect sense um in case anybody doesn't know I am one of the co-chairs of privacy pass um and in a way that's part of what I wanted to present this here in this cycle all right but I and many others seem to think yeah let's just push this into privacy pass and Ben gets to deal with the hats problems from that but as far as the actual Solutions here I maintain that this is one reasonable solution this problem um I think that the fact that we rent all these caveats and potential pitfalls and stuff is"
  },
  {
    "startTime": "01:20:00",
    "text": "the big proof that this is a very difficult problem that anything you have is going to have those so that's why we need something like this draft to spell out a possible solution because otherwise there was some time with their own bespoke solutions that just have all these problems because they didn't realize the issues so we need something like this whether it's this specific solution or the other two Alternatives you present on this slide I don't have a huge opinion it would be nice to solve a Thundering Herd problem but at the same time Solutions I've tried to kind of to solve the Thundering herds problem was had problems poked in them so it's always comes back to this is a difficult problem so we don't come with an absolute better solution it might be a matter of yeah let's publish this draft with this solution and it's usable for anyone that isn't quite as susceptible to the Thundering Herd issue and when we come up with a better solution that isn't thundering or hurt susceptible we'll come with a yet another draft for another alternative solution that people could use is not a huge problem with having different options of the space if we have to publish multiple protocols so that's fine so thanks I do want to try to avoid you know defining a ton of these I think no I think we're all going to be happier if we can more or less Converge on on the smallest manageable number of these yeah but uh two solutions one is simpler but subjectable of Thundering Herd and the other one is a little more complicated requires more logic but is more useful for bigger parties that care about huge amounts of traffic spikes and all that sort of stuff that those two solutions seems like a reasonable number to end up with Mutiny so yeah cool um yeah I think it sounds like we have consensus that this should follow draft key consistency into privacy passive if the chairs of privacy pass agree which then can speak to that um uh yeah so so future discussion of the"
  },
  {
    "startTime": "01:22:00",
    "text": "draft will go in the Privacy pass working group um follow us on follow us uh if you if you want to talk about it more all right sounds good um we do have a little bit of time in case anyone has any other business um going once going twice if not thanks all for joining um Richard did you want to say anything else yep thank you thank you everyone good session yeah see y'all next time thanks to our note-takers Sean Martin"
  },
  {
    "startTime": "01:24:07",
    "text": "foreign"
  }
]
