[
  {
    "startTime": "00:00:21",
    "text": "i think we're gonna kick off all right welcome to um chapter 113 of the ops area working group a joint meeting with ops area hank and i joe clark will be your host we have ken wren joining us from remote and we have quite a few other people so welcome out there and meet echoland everyone who is joining us for the ops area working group as a reminder this is an ietf meeting and as such the note well applies i'm sure you've all seen it and read it but there we go my private my uh confidence monitor went off um but as a reminder all of your contributions everything you see at the mic is uh is public and subject to the um the ietf processes and policies as another note we are a collaborative group of people we're all working towards a common goal of making the internet better so as such we have requests that you would treat each other with respect and that's that anti-harassment procedure there as well"
  },
  {
    "startTime": "00:02:01",
    "text": "so this is our first hybrid meeting i mean i guess you could say we've always kind of been hybrid we've always had some remote participants but this is unique we are for the first time since singapore and in 2019 we have some in-person participation you can either choose to join that with the the meat echo app so you can see a qr code if you're here in the room if you scan that on your phone or mobile device you'll have the meat echo light version um if you are presenting with that you can use it to adjust the slides but it looks like we have a clicker actually i don't think that clicker will work so we can also move the slides for you um and if you wish you can join the meet echo heavy uh by clicking on the video icon in the data tracker agenda and you can follow along for remote participants this worked just like before hopefully you're all signed in to meet echo and like i said i see a number of people there so it looks like that's all being very successful um what we're going to do is go through our agenda first and hopefully by this time you've had all the information you need so you can you can look at that there um as i mentioned i'm joe clark we have hank joining me here in the room and we have 10 remote eliot lear has via email i have a paper trail to prove it i see him online graciously agreed to scribe for us and i know rob wilton has done so in the past very well i might add so i cannot underestimate the appreciation i have when it comes time to upload the minutes and make warren happy meeting materials are up to date so you can go there and date a tracker and see that and as al always yes we're meeting in meet echo as well where do we stand uh we have some great news actually we've got three new rfcs published since our last meeting"
  },
  {
    "startTime": "00:04:00",
    "text": "in 112. we have the first two of the layer uh the ln or lxnm models so we have the common and the l3 you can see if you read down a little that the l2 is in uh with the isg and waiting a revised id and we had uh 21 2160 published on export of mpls segment routing label type information ipflow information export so um great work so far and we've got a lot of drafts progressing so we have one in the rfc editor queue that's the network telemetry framework i have been a bad chair and i need to close this working group last call on vpn service performance uh monitoring uh we got some good comments on that and there was a revised i believe a revised a id just came through and we have a few close to last call um we'll we'll start that after uh these proceedings at some point some of the mud s-bomb and the service attachment points which we'll hear from today hank or tian ram is there any thing you'd like to add to status okay moving right along so you are right here right now uh in our administrivia section uh and then we have i'm not going to read every agenda item you can see we have as usual a quite packed agenda for ops og our ops area working group and then we will hand things over to our illustrious ads and they will do an open mic and i know warren has something to say um is there any reason to bash this agenda and i know that there have been some bashing already and we've shuffled things around to kind of accommodate people but any other bashing before we kick things off no okay then if we could med wherever you were at"
  },
  {
    "startTime": "00:06:06",
    "text": "thank you thank you do you want me to be in the slides or i can um i can load those up for you you're doing sadly it didn't come in order but i think i've got you right here so you can can you see him okay thank you thank you joe so the um yeah so the uh this will be a short update of the service attachment points to report with rd i would say the um the recent uh changes to made for this in this specification in next slide please yeah so this is this is just to uh to remind the i would say the uh the context to um this is the structure we presented last time so the for disabled attention points thanks are really simple we have i would say um a new structure that we enhanced uh the service at um at the node level um we model just um just to have a list of um services points that are i would say identified with the uh notifier and we uh down the list of services to um to that one so the the document wasn't in the last call sorry in the um production uh call for adoption in which we received they would tell a lot of useful comments from the uh from the working group and that revealed i would say a lot of issues that are listed in the in the next slide so basically there is one i would say one important thing that was raised by benue that we if you want if you can just please move to the next slide as we uh we are i would say assigning the uh or associating multiple services to uh to the same service attachment points there is a need to um to uh to amaze to display and to use filters just to uh specifically have a topology for a"
  },
  {
    "startTime": "00:08:01",
    "text": "given service and not for all of them um with the old version we have with the model that was really difficult to do so the um this was one of the um i would say important feedback we received from from the working group uh there's also another comment from the uh from dhruv then this one is also important is how to associate between the um the service attachment topology and the the the physical one so we need to have a glue somewhere in the model to to um to let us i would say easily graft the uh distilled attachment point topology into the the physical one uh there are also uh various issues that was really i would say for example if you want to cover uh not only the um the user to the network interface but also for the services that are i would say requested from a pure network and for that one we need to have i would say some discussion about the um the network network network interface and there are also um a lack of examples to illustrate how the model can be put in into practice so in order to um to address all of these issues we we have updated and proceeded with many revisions of the specification that can be uh shown in the next slide um so rather than index in the uh the serious attachment points by its id we are we we are now having something which is structured based on the service itself and under that the service we have uh added multiple um leaves and parameters there in order to um uh to address all of the issues that were i would say listed in the in the previous slide we also added a lot of examples uh as appendixes uh to uh really illustrate how the model can be used in various contexts we used vpn for uh here for uh for that purpose because the the working of is working on i would say in ill two and three eight three uh services but the"
  },
  {
    "startTime": "00:10:00",
    "text": "the same exercise can be done for other services uh we use also to have one comment from from joe about the uh the mapping uh and for that also uh we have we have added multiple examples like next to to to explain how we can we can we can we can manipulate the model in order to use the map in between the service and the service attachment topology next one please um we also receive the um the yank docker reviews there's nothing i would say major there there is only comments some nits about um renaming some some leaves and so on and it was really straightforward but but but that's still a good a good review from for from martin either for that we don't we don't have any um any other appendance on this document that we think that we are we are ready for the working of last call and know that that venue is is currently a review and the uh i would say the draft to to check the uh the mapping we i mentioned earlier but this can can be handled as part of the working of classical if the worker decides so all right any comments or questions uh on service attachment points i i didn't know i appreciate the revision and i noticed benoit had i didn't get to read it yet um just before i came here and like i mentioned med will ah looks like scott's joining the queue and you're here scott go ahead scott hello there we go there you go i was triply muted apologize so okay so can you go back to the tree i just have a simple question i hope it's simple"
  },
  {
    "startTime": "00:12:01",
    "text": "uh right there this tree so i what i'm seeing here is that you have a node and then you have a service with a service type but service type is a key an identity re so is that really a type or is that an a pointer to an instance of a service because the way i'm looking at this you could only have one service you could only have one service of a service type for a node couldn't there be multiple services that are the same running over a node just looking for some clarification there thanks yeah that that that's a good observation actually you can have multiple services under the same node and the the multiplexing will be done by the attachment interface itself in which you for example you can have multiple sub interfaces that can be associated with the same service and you can use that as a demultiplexer if you need that other comments i see rob approaching the mic uh robertson cisco as a contributor in that scenario though wouldn't you end up finding the sub interface as the uh service interface the circuit interface what does the sap always define the physical interface the sub does not always require a sub interface to be present but it um but i'm not sure the cd and the case you are you are referring to is so if you can just i would say clarify for that would be great uh if you yeah if you had"
  },
  {
    "startTime": "00:14:00",
    "text": "multiple um pseudo-wires point-to-point survivors or vps surfaces then they would all be terminating for the same pe device and each of those would have a separate sub-interface on that on a given pe interface um to each of those different services i just wanted to check that that could be modeled here basically on on the back of scott's comment yeah um yeah i need to check this one for the specific specific case i can do that offline to to really check it if it works on that on that case as well okay thank you dhruv i see you in the queue i think this will be our last question thanks uh drove here uh one question met uh in the document we say that this model can be seen as an inventory model and i have a little query on that like you know because i i also noticed that in c camp there is a document and they are also asking for feedback on where to do the network inventory model and i all my first question is is can really this model be seen as an inventory model i wanted to get a feedback from the room as well or are we misclassifying this and also to notify the working group what do they feel about a work that has been done in ccamp on the itf network inventory is that something that we need to also be looking at in this area yeah that that that's a good question for me it's still an inventory model but yeah it's up to the working group to um i would say to check the other work and to see if there is something to be here to be said there thanks thank you very much ned rob i think i can remove you from the queue okay"
  },
  {
    "startTime": "00:16:00",
    "text": "um next up bow can you hear me we can thank you hello everyone this is paul uh i'm going to present this uh young model for network and vpn service performance monitoring drug on behalf of all the authors uh next please uh the first thing i want the working group to be noticed that is that this draft has just to close on the working group last call and during this last uh working group lab school we received uh several helpful comments from the minutes so we thank adrian joe for their helpful comments and uh these uh in all these comments we have a major uh there's a comment uh there's a suggestion that uh that inter site between performance monetary type can be added to the model because uh right now uh like before this um in this zero three uh version we have only uh tunnel based vpn performance monitor type so uh now we'll talk in the next slide and uh we also in the github uh hacked all the issues that we all and we also uh addressed all those issues so"
  },
  {
    "startTime": "00:18:02",
    "text": "thank you next please and here is the the comments that i just mentioned uh i put a figure here that to show what the comment is about like before uh like this uh there's three uh version we have only the tunnel uh we put uh in a blue color that in the overlay uh vpn uh topology their workflow link between this virtual node that represent a qpe there and uh but we we don't have that um we don't have exact volume method to measure the virtual link oem so we use the tunnel performance monitor metric to represent that virtual link om statistics so um there's the comments is about that it also should be allowed that like inter uh vpn access interface uh that that because they are uh there are um already uh some common uh praxis there that uh used uh uh like t-ramp and other oem method can be used to measure that per vpn uh uh performance monitoring so uh so in the the first uh revision four we add a a new node uh we call it uh vpn performance type and we also use the choice definition so"
  },
  {
    "startTime": "00:20:03",
    "text": "the reason why we choose uh type choice is that we think the inter vpn access interface performance monitor can cover the like the the tunnel part uh measurement so we think so these methods two measures uh on either of them can be used to represent vpn performance monitoring uh that abstract link performance monitoring so that's the reason we choose choice so we like to hear uh if there are other uh comments on this so uh this is a major one left for the working group discussion and that text please so uh since uh we think they have addressed all the issues so the next step is the the author's impress iesd publication so that's all are there any comments on them comments um bo on the um on this choice yes do you think you have enough so last hall is is like i mentioned wound down do you have enough input here is there others in particular that you would like to get um insight or or thoughts on before handing this up to the iesg uh right now we we have published uh revision4 to like already uh add this choice so i don't know if that make uh"
  },
  {
    "startTime": "00:22:02",
    "text": "our working group labs call like their other is need another uh last call you um [Music] i don't know um listening to you talk it sounded like there might need to be some other eyes on this it seems like a substantive change that just snuck in once the window opened it might benefit from another week or so once things settle down i i'd like to understand how what you feel um you you feel comfortable with um given given what you've just stated here oh i'm i'm fine with uh you i mean uh we definitely um we discussed this uh is to like we we hope that a working group can have more review on this because in that way that will be more uh the text and also the model will be refined so i think uh from my viewer i'm buying this so if matt and other authors don't have other like they don't have other opinions on filemakers okay thank you other comments got a few minutes okay thank you bo thank you benoit all right so i'm going to present the same work i'm trying to buy you some minutes"
  },
  {
    "startTime": "00:24:01",
    "text": "something to talk right now well it would have helped to put it in order there you go we did all right so okay we produced new versions of this this work uh i'm going to be quick here and again by you some minutes so the next slides i've got one intro on what this work is about i printed multiple times i don't plan to go through it if it's new to you quickly review the the slides now on the next slide joe we added in in the version two of the draft we added information about circular dependencies there were discussions with edius lear and rob so we added that in this latest version we added a specific example of uh you know how to uh prevent circular dependencies okay in the next slide please what we've been adding also and that came from our prototype is that whenever we have like the health score for a subservice sometimes we don't have it yet because we're busy calculating in the prototype you're reporting zero as a health and somehow it was a mistake it was just missing right it was selling the wrong information the service was not up and running so we could be waiting until it's stable but what we choose to do is the proper way in yang by having a union it's either missing or it's calculated it's calculated it gives you the health score so that's an improvement okay on the next slide please i want to stress that we've got some implementation of that the day x agent by de lies university"
  },
  {
    "startTime": "00:26:00",
    "text": "has been presented already at the itf a couple of ideas ago we have this picture from a prototype that was done at cisco that was coming it's coming from the the presentation in the itf also and we've got the huawei prototype as well on the next slides the status is that i want to thank the people who provided feedback there is no more issue except that there is a discussion on the list with joe and we need to update the the yang module one more time with the counter 64 on the version and after that i believe that we are close to being done and from the other point of view we're close to a good last call um as a contributor i i responded to john today i yes okay the version i'm not in love with it but whatever the the example that the like implementation suggestion i think would also be a useful addition um just for others who might want to understand how best to to implement some of the the health and weighting so we're going to post a new version very quick yes and after that it's up to you guys comments on sane see anyone coming up so thank you benoit wow cranking right along uh thomas"
  },
  {
    "startTime": "00:28:00",
    "text": "yes can you hear me we can we can perfect thanks a lot joe so i'm talking about uh yeah just one sec so now is it better is it better yes it's better thank you okay perfect so i'm thomas from swisscom so this is about export of segment routing ipv6 information in ipfix next slide please so just to give some background so uh segment routing uh can be leveraged in the ampeles data plane and also in the ipv6 data plane so we have with rfc9160 uh the extensions needed for adopting it on ampullar segment routing just in a nutshell to describe uh basically the ipfix entity 70 describes the mpls top label stack section which basically describes the label the the the experimental bit and the bottom of the stack bit while the basically the rest of the amplis label stack is decomposed in ibifix entity 71 to 79 separately the ibfx entity 47 basically exposes the ample stop label ipv4 address while ib entity for 46 basically from which routing protocol that prefix and label has been coming from and since this was the only change between emperors and mpls segment routing so basically there were new routing protocols such as ospf isis and"
  },
  {
    "startTime": "00:30:00",
    "text": "also pgp and pc being introduced uh we are updating the the ipfix top label type registry next slide please so in order to bring uh data plane visibility in srv6 uh basically in a nutshell uh we are um uh so in so currently uh sov6 is already deployed in service provider networks we have the first few cases which are actually providers are migrating from mpls towards sov6 and we believe as autos it's currently data plane visibility is missing especially in such uh migration scenarios uh it's very beneficial that we can see actually uh how much traffic is being forwarded or dropped towards a seat so in order to gain visibility into srv6 basically the segment routing header needs to be exposed uh the segment routing has described in section 2 of rfc 8754 next slide please and when being decomposed in in ipfix we have the ipv6 srh segments left basically describing at which point uh we are in the in the segment list while the ipv6 srh tech and sfvsh flex basically exposing the text and the flex from the srh header and uh the ipv6 srh segment type basically describes which routing protocol"
  },
  {
    "startTime": "00:32:01",
    "text": "that the city is coming from next slide please the ipv6 srh section is basically exposing the entire srh in a series of n octets while the ipvx srh segment list section is actually doing the same thing but only for the the segment list itself uh we have also ipv6 srh segment and segment basic list which is basically exposing the srh seat list as an ordered basic list next slide please so there is uh two ways how we are able to expose the the the seat list either as a as a basic list as all the basic list or as an entire list section uh we had some feedback from the mailing list so depending on implementation one could be more easily implemented as the others and the difference is basically where the decomposition is done either on the export or on the data collection side next slide please there is some some operational considerations regarding the compressed seed container so currently at the spring working group the srh compression is being discussed so in context of ipfix basically it has no direct impact because the c uh the the cc container is still a 128 bit long uh ipv6 address"
  },
  {
    "startTime": "00:34:03",
    "text": "but uh it contains basically multiple uh seats in uh in a cc container and they are mutually exclusive uh it probably makes sense that we are adding in the draft document an operational consideration consideration section to describe what needs to be done on the iphix data collection site to distinguish between an ipv6 sheet and sees it container uh from what we as authors understood it most likely doesn't bring much added value if we are actually decomposing the decisive container in the compressed sit but here i request feedback from the mailing list next slide please so the current draft status we already received feedback from spring ops awg and the ipfix doctor for the feedback we introduced the ipv6 srh section and soh section segment list section uh and we added the ipv6 sfh segments left so that we can express at which position of the segment list uh the forwarding is happening and that's useful for detecting forwarding loops uh we updated the operational conservative consideration section to describe the difference between the ipv6 srh section and the srh segment list section uh in which case which one makes more sense and we over updated the iana consideration section to be in line with rfc 8126 the document doesn't introduce any new protocols it's for documentation"
  },
  {
    "startTime": "00:36:01",
    "text": "purposes however because new ibfx registry have been introduced we specify the document as internet standard to be in line with other documents next slide please uh next step uh so do you recognize the problem statement that data plane visibility is missing in srv6 we as authors believe that this document should progress quickly through itf to void that private enterprise code points are being used for srv six deployments and therefore we would like to call for adoption at ops awg that's all from my side any questions comments uh elliott hi thomas thomas um just uh speaker is if you want to try again elliot yeah my question was uh just you know people who are implementing can you repeat the question again yeah it i asked do you know of any implementations yet uh not yet we are [Music] we are aiming for having an implementation in vpp by itf 115"
  },
  {
    "startTime": "00:38:06",
    "text": "does that answer your question yes thank you yeah okay thank you thomas good thanks a lot marisol hello thank you cheers for having the um luxury to present here in itf first time presenting live previous time we were presenting the mlmo a data model life cycle management and operations the version 2 we are running actually version 4 which is uploaded already on the data tracker the authors we have been adding developers who is also here on the list of authors and we can go to the next slide i want to give an introduction on where we left it in the previous version we had been defining several data sets where they were looking more into the assets assets if you remember the definition and if you have been tracking on the mlmo asset is referring to any hardware software or virtual entity that we could represent part of the infrastructure infrastructure running and we have not been adding any new attributes as part of this new version it is more on the flexibility and the scalability that we have been adding to the different young data models modules"
  },
  {
    "startTime": "00:40:01",
    "text": "that we have been working on if we go to the next slide please if you can see and compare with the previous version everything that is in yellow is new we have been adding on this flexibility and consistency on the structure where we have been defining instances and every one of the modules that we were defining in previous version is called an instance now where they are called based on the idf lmo module we have defined those jam modules based on the lmo and the assets features incident and licenses are part of it we have been adding organization and lmo users as well they were attributes as part of the licenses module and with this flexibility that we are adding it could be as well something taken by the vendors as a specific implementation on top of the attributes that we are defining and data sets and the flexibility that we are talking to is adding a consistency how the structure has been implemented on the young modules and we are playing with the augment of the jump modules in order to build more attributes on what we have defined already okay if we go to the next slide um marisol can you also just make sure that we got people from remote systems your audio is coming out okay sorry no problem perfect and in the way we reference one module one young model to another we have been um including the on this structure how we call and how we reference in previous version we were defining assets and sub-assets as part of a container same thing for licenses"
  },
  {
    "startTime": "00:42:02",
    "text": "and sub licenses features and sub features here on this structure we either adding and complimenting on how we address different reference from one to many in this case access to features we can have uh many features in there users to organization we have the one-on-one relationship and this can be very flexible on how it is referenced with the new jam modules if we go to the next slide another example of what the extension we have done with the flexibility and consistency it is how we call this combo structure where we can reference a previous instance in this case licenses we can represent in a better way that it was done before on the on this example that you have here on the licensing on the next slide for organizations here's an example but it has it it applies to the other um data sets as well we have this hierarchy represented with a parent and child structure and an organization you can see clearly an example how to use it and we can call organizations within organizations as part of this hierarchy structure and in the department on it this is a an example of implementation based on xml it is not really important on the content for it but you can see an asset represented with different attributes features are part of that assets and licensing can be referenced as well within that asset our asks and next steps we welcome and appreciate feedback we have been setting up these site meetings where we have collaboration from huawei from"
  },
  {
    "startTime": "00:44:01",
    "text": "benue from telefonica as well from luis and we are open to get more feedback on it we have this meeting set up every two weeks we will be extending it to be every month just to make sure that the good work is addressed on the side meetings and as part of the next steps we understand and this has been discussed and we can ask the alias the actually the the working group here uh we have been discussing the licenses is a complex issue and we understand is a complex issue we are working to evaluate how to tackle licensing and we are working camilla specifically together with sweeta are addressing this licensing concept and we are addressing as well and for the next revision we have to really work on that how to iterate through the young modules going to more specifics on how we define the type of attributes going to the anoms against identities and also some of the attributes that are stuck tackled as mandatory and there are some specifics on how we define addresses as well as part of the assets but those are specifics that we can discuss further as well now we are open to questions and welcome your feedback on what has been done so um i spoke to you earlier about this and i just wanted to share some comments i've made to you here um i think this is a very interesting problem to be approaching and i think it has a lot of potential value the tricky things to solve is making sure it has both enough"
  },
  {
    "startTime": "00:46:00",
    "text": "flexibility to be widely applicable to different vendors and things and at the same time having enough commonality that you can then um correlate that data together and make use of it it's not sort of too different so i think it's trying to solve those two problems together which is quite tricky but um it would be useful it can be solved now as to some practical suggestions for this for example i think that the open config platforms module is sort of trying to solve a similar problem in a very specific case it's not exactly the same and they've and the way that they've built their flexibility is to allow this sort of arbitrary parent child hierarchy to be set up and then flattened into a list and you have similar sorts of things with this sort of parent point or maybe children pointers so i think that's a good thing and then they're using identities to identify particular properties or sub properties and extending it that way so i think identities is probably better choice mostly than enumerations because it allows more flexibility i also think that trying to concentrate on the core subset of the functionality that is widely applicable would be a good starting point and then to try and build extra functionality honors augmentation young models or a separate draft might be a good way of trying to get a good common core that people can work on yes thank you rob i i think we as you mentioned before we were discussing on this it will be good to get the review on those specifics as well answering on the on the list just to make sure that we have a good review but agree agree with with all the comments and we could even reduce the modules just making sure that is common to more vendors right and this is kind of the exercise that we want to do on the iteration uh going forward i'm moving to call for adoption as well as soon as possible but yeah thank you for all the comments um bow"
  },
  {
    "startTime": "00:48:08",
    "text": "can you hear me yeah yeah i have a clarification uh question on this so this model is the device model or like a noise bond interface model of like network controller so i didn't get the question her question was is this a device level model or a northbound interface model like on a controller we consider an asset to be as well a controller then it depends from where you look at it at the asset level right it is a representation of it could be a device physical or virtual or it could be even a controller right from a software point of view or even a service as well so this is not device model uh from your it's not a specific explanation okay thank you then one last comment so bernoullis so i want to address two points uh so first of all the inventory because we've seen that it was discussed multiple times we even learned today that there's a c camp uh inventory model so there are multiple definitions of inventory uh there is like the uh the inventory like the entity map in the past and you got the young male for that there is like the inventory for what is in the end a platform or device so to make the link with what beau was mentioning there is like device but whether you see this on top of a controller they still need to have the same characteristic device it's like an id it's like a vendor it's like an os it's like a type and all this and we start to have this in many different"
  },
  {
    "startTime": "00:50:02",
    "text": "places so that would be good to have the same consistency uh okay maybe i'm dreaming of a grouping a grouping where we've got the same the same thing in yang right but that's something we have to pay attention to to not redefine the same thing over and over that's one point and the second one is about licensing so you you mentioned i was attending the course yes and my main feedback was that licensing is very complex i understand what we want to do that makes a lot of sense for multiple use cases but all this has to be multi cross vendor right that's why we are here to do standard and that will be very complex so my feedback in those calls were that maybe where this is too complex right and we have also addressed uh on that question or comment it is complex we want to see how far we could get on the use cases that we are operating and we are working on that and camilo and sweeta are the main people looking at that at the moment and we will be following up on the side meetings from that on the inventory we have been also discussed previously to this meeting on how to address that i would say that it's not a use case specifically from this dml mmo having inventory but we have to define somehow those entities that we are addressing what we call assets and there are some attributes already defined if the working group decide to go to an inventory approach we will be helping and supporting on that idea as well uh thanks marcel i ran a poll uh while you were talking uh of the participants 20 uh decided to either raise or not raise their hand there were 14 in"
  },
  {
    "startTime": "00:52:01",
    "text": "support of the work and i was curious as chair you're not asking for adoption but there does seem to be a lot of people working on this so i i think we do have to address some of the questions that that have been raised and see how we want to proceed but in interest of time i think we should probably have this conversation on the list and move forward but i appreciate you coming and presenting next up we have ken who i saw you online yes thank you and uh this is a already adopted work item i asked to go a little bit later because i had a conflicting meeting earlier so uh yeah just an overview as we are looking to update the tls transport model of snmp v3 so next slide so the effort was approved after ietf112 we've updated the fingerprint algorithm the big challenge there is that the existing algorithm references tls 1.2 hashing table that hashing table will no longer be maintained now that they've migrated to 1.3 and that that's a hash of the x.509 cert the um we've received comments we've addressed all of those comments we've posted a new draft so i think we've resolved everything now and if you go on next slide the big change uh is that we figured out how to handle this hashing table um initially we thought thought about the concept for replacing the fingerprint algorithm that results in changing all of the mid op objects and uses the new identifier table that's"
  },
  {
    "startTime": "00:54:01",
    "text": "a major overhaul to the nib so we wanted to avoid that the second option was to maintain using the 1.2 hashing algorithm table we talked to the people that are in charge of that table they did not want to continue maintenance that table because that would imply any new hashing algorithm could be used with tls 1.2 so they wanted to avoid that the good news is that we determined that we could actually just revise the definition of our fingerprint algorithm to use a duplicated table if you will so take the tls 1.2 table as it exists today that is not going to change copy that to a new table revise the definition of our fingerprint algorithm to point to this new table and now we can extend that table as we need to the only question has been whether or not this would constitute a normative change to uh ken we lost you if you can still hear us it seemed to have timed out for some reason and flipped me on mute um okay so uh um the uh bit but we determined by consulting with nib experts that we would be able to make this change without having to go back and revise all of our table structure within the nip so this is a fairly easy fix and that is what the most recent draft reflects next slide uh there were some other items uh that we've updated compared to the current"
  },
  {
    "startTime": "00:56:01",
    "text": "rfc we've clarified that authentication and privacy are always provided that's just the natural part of tls 1.3 we remind your readers of the updates in 8996 which prohibits tls versions prior to 1.2 we are prohibiting the use of the zero rtt feature of 1.3 clarifying tls compliance requirements and updating uh we made some minor edits to capitalize some keywords uh to be conformant with bs bcp14 uh we also changed a couple of instances of may not with must not to be a little bit clearer and next slide so uh there are some edits that i've discovered uh since the last draft that will be in an upcoming draft shortly the first item is really given that this is just a simple update at this point we should probably revise the name of the rfc or the of the work to be updates to the tlstm rather than specifically citing version 1.3 of tls we should remove the double quotes that are within the description clause of s mp tls fingerprint just some other nets removing references that are not used in this document removing the appendix examples because they're just identical to the existing rfc and the the final change or a question i have i think is whether we should change the name of the proposed table so as i mentioned we are duplicating the existing tls hash algorithm table to create our own that is currently called snmp tls fingerprint algorithm table"
  },
  {
    "startTime": "00:58:01",
    "text": "my thought is this might be a useful registry for other efforts within ietf so perhaps we should have a more general name such as infm multiversion tls hash algorithm registry justified next slide uh so that's pretty much where we are i think with those final edits we should be pretty close we will send it out for a final review and comment and then we can start the last call process i think um and we will also make sure we distribute this to the tls reflectors as well since it can impact them any questions okay i'm going to i'm going to draw a line in the sand oh sorry you just beat me without hats so sorry no had no chair head on um so i guess that also uh in in cozy uh they're working on uh uh hashing algorithm um index it's probably uh worth a look they want to do that so if if there's overlap just swing just make sure that the indices are equivalent i think that's the most important thing um i think the tls might have a different subset than the thing cozy wants to do but again there are indices in there today so if three would mean the same three the confusion would be way less so i think that would be interesting to think that's just from my side i was gonna say something maybe similar um as a contributor i i honestly i feel my gut my initial reaction was it might want to stay snmp is the name"
  },
  {
    "startTime": "01:00:00",
    "text": "of the registry just because of what we ran into with tls where if if it does cause some sort of semantic change down the road if others want to add things to it that essent that this wouldn't support um but uh hank brings up a good point if there are overlap that that aligns maybe then that that can help inform your decision can okay uh i i think we would want to avoid any changes to the existing tls 1.2 table uh any reassignment of those numbers on a simple basis that if we did it would break backwards credibility um but but but any if there are additional items that aren't in that table yet we can certainly add those yep absolutely don't want to change and rob is in the queue just to sort of i've not read this latest version of the draft so um my one question is and you may already cover this is if new items were added into the existing tls 1.2 io registry what process would be involved to make sure they also updated into this new registry is that some of the draft should have some text to update how that is processed to make sure they're copied here and that that doesn't have to be done as like a separate manual step does my question make sense i it i think so i think it's just uh how do we add a reg a new registered item uh i would assume that ayanna has formal processes for that i'm not sure that we need anything in our text but i'm happy to just happen to hear your comments so i think my question is more about and again my misunderstandings but is this this recipe is meant to be a superset of the tls 1.2 and 1.3 is that correct yes so so i think i kind of shepherded some of these questions to the tls alias"
  },
  {
    "startTime": "01:02:02",
    "text": "um my understanding is they do not want to add any additional entries to this because tls12 which is all that the original registry covers is not going to add any more protocol and apps are any more algorithms so adding 1.3 algorithms to here with a one byte uh registry value would uh imply that they work with tls 1.2 when they don't my under again my understanding is that there will not be any more additions to this registry and that is why um they recommended we fork our own okay so i'll phrase my questions like different ways if this is an snnp specific registry then it'll pick up some default values to start off with how does it need to make sure that if there's new entries added to tls1.3 they also get updated into this snmp registry and if so we want to make sure there's text to make sure that happens automatically and not having to be a manual step that's the thing i'm trying to get it no that's a good point yeah yep good point uh yeah elliott uh quick comment um yes uh just a question what is the registry policy for tls 1.2 for the tls 102 registry in question uh it's an expert review um okay so what they're saying is are they shutting down so somebody should take an action if they think that this is going to be a problem like they should take a standards action to shut down new entries otherwise you know it's up to the experts right and the the experts are meant to be guided by you know whatever their their best knowledge is so it doesn't sound like you can absolutely affirmatively say that there will be no"
  },
  {
    "startTime": "01:04:00",
    "text": "new entries that's fair point [Music] again i was going off the what the those experts replied to us with but that that is a fair point um and in that case the text would probably need to cover the addition to either the tls 1 2 or 1 3 and registries thanks ken thank you benoit all right so i want to present a draft which is about data manifest for streaming telemetry we changed the title we improved it thanks matt for that this is actually data manifest for contextualized streaming data and we posted a version two this week with a couple of updates so let me go to the next slides i want to make sure that you understand why we need this so the idea is not to expose new young objects but the rather to define what we need to keep as metadata what we call a data manifest as contact information to make sure the data could still be interpreted if the device is not accessible any longer or the device being updated or as new configuration the end goal is that from let's say a data collection point of view a big data lake we want to make sure that we could do the under my detection and the enclosed loop so on one side we have the product capabilities which mean that i could tell if a specific yang object supported unchanged or not though so i could configure it but what"
  },
  {
    "startTime": "01:06:02",
    "text": "we don't have is that i don't know or it was actually metered right and under which circumstances specifically whenever the device is not there any longer so on the next slide let's take an example we see this from a data collection vantage point on the left we've got time one with a counter which is value is 42 it's always 42 right and the status is up now i'm in time which is now and there are no updates and i see this from a pure data collection point of view so what's happening well there is a problem because my telemetry has an issue or there is a bug or the sender the router is overloaded so can't send anything or there is no problem because there is just a long cadence in my telemetry or there is no problem because it's unchanged it has not changed or maybe there is this feature in my company which is super redundancy which means if they haven't changed don't say it to me and i've got no way to know this from a pure data collection point of view right so i will be i might be drawing the wrong conclusion in terms of anomaly and the connection this is the entire point here so on the next slide we want to propose data manifest so basically context information and there are two of them the first one is the platform manifest right characterizes the platform producing the data and you see it could be perceived as inventory this was the camera was making before the source router the source device and the other one is like the data collection manifest characterizes how and when the telemetry was metered okay the principles here is that whenever you stream telemetry"
  },
  {
    "startTime": "01:08:01",
    "text": "this contact information must follow the data right and if the data are moved to a different place there still must follow the data because without the context we have data and we can't take much information about it much actions about it sorry next slide so that's the typical p yang tree and uh we've been adding at the top like the vendor and by the way we added a nacio from the madrid university as an author this was his feedback and this is aligned with the again the platform information coming from the young catalog because we always deal with the same type of tuples right we also included the the full yang library to get information about the data store we corrected a small mistake that this young module was read right no it's not it's only read-only along with the data you've got this contact information you're not supposed to change it it's from the source right and the package sets so on the next slide this is information about the data collection manifest right we're telling like well per subscription id well what is the requested period the actual period the unchain yes or no su presidency and we added also from widget.com there are some potential interesting use cases there comparing what is in intended or candidates on the next slide we could ask ourselves how frequently do you do we update those two manifests the platform one it's only one ever get a platform change typically a reboot chain of os okay so not very frequently now for a data collection one we update it whenever the collection condition changed typically i change the cadence"
  },
  {
    "startTime": "01:10:01",
    "text": "i've got the new subscription orders the correction third is adjusted based on cpu all right on the next slide we're thinking well we should be using telemetry information well that makes sense because it's a information about telemetry and that should follow with telemetry and we could be using the unchanged so that we would make sure that if some information about the context changes then we would reliably receive it and automatically and directly receive it okay so let me go to the next slide let me just say on this one that you actually in a draft how to map the data to the data manifest let's keep that one and go to the next one so we identified a couple of uh improvements right and that's where if you want go to the mic at the end and discuss this well one of them was about uh the source of data and the self-assertiveness how do i know that actually if you are a vnf or router well can i trust you right and there's also the issue of data integrity what if someone would change this information now what we need to do here is actually analyze the threat model right which is basically management traffic inside your domain but we have any way to do it right personally i always believe pragmatically that if someone is changing just this source of data he's able to attack you on the front maybe you have bigger problem than just changing the contact information but you know we'll have to pass security 80s at some point in time so let's analyze the third model open questions uh well we could do that for other types of information the context right for snmp for ip fix well ipfx if you do sampling you want to know you're doing something to the same complex information type"
  },
  {
    "startTime": "01:12:00",
    "text": "same type what about virtual devices what about vnfs right do we want to mention if there is missed collections that's also something pretty interesting to understand from a data collection point of view and what about the yank packages which is a topic in the the ops area that could potentially be included and i believe this is no maybe one more slide yeah so the conclusion got a couple of good feedback meteria nacio and i would like to understand from this working group if you recognize the issue and if you believe that we should work on this from an author point of view from different horizon we clearly believe this is a problem to be solved because we want to solve the issue of autonomous networks for which we must have closed loop for which you must have another detection thank you rob yeah rob is a participant uh thanks ben well i think to recognize the problem so absolutely um i definitely think this is a very interesting problem i think it's very hard one to solve and i think one of the key questions it looks like you are returning the metadata per subscription is that correct which i understand why you're doing that because otherwise it's going to be too much data but i wonder actually whether to really solve this you almost need the metadata per leaf field that's being pushed off the box because if for example you've got a subscription an interest goes away and it stops returning data that interface i'm not sure whether you would spot that but if you do it per the leaf node then you end up with too much data so i think it's an interesting problem to solve i don't know what the solution is so i i don't think it's good to work on it but i think it's tricky it's tricky there was an mrg like a comment about digital twin right and the gentleman there"
  },
  {
    "startTime": "01:14:02",
    "text": "mentioned that somehow we start to be in the world of uh data oh forget it now data driven ai which is actually trying to find out because all it is sometimes they want to have all the data right we have to be slightly pragmatic specifically whenever we speak operators so this is trying to find out how much data do we need at the minimum to be able to solve the problem ideally everything per node all the time every single flow data plane in practice there is like uh middle ground so i agree with you with your statement and with the subscription id we could find that find out which notes are in there and that's a compromise but but in terms of wanting to know um both when a value was was actually written and how fresh it is those two properties i think are important so i think that is i think it's interesting problem so hi this is hank again uh with no heads on so um so your this manifests how i understand it is um combining quite a few of um different types of information so it's all from the subscription side so the subscription also deals with the same problem at the beginning you sell everything whatever you subscribe to you don't know what the receiver knows so you get a full iframe so to speak and that's the same with metadata you would give the full meta that i want but that can be slimmed down later and then outside of the subscription context as uh like uh integrity i heard and when i hear integrity sometimes i always always think remote attestation trustworthiness so i might have some future comments on that because i think that's also metadata that will change because especially if the identity of"
  },
  {
    "startTime": "01:16:00",
    "text": "the composite system changes due to vital elements changing and then for its expressiveness and trustworthiness changes although the data and the leaves will remain the same so i think yes it sounds to me like an interesting problem thank you i'm sorry diego we're going to have to cut it off okay no no it's just what just say that uh developers developers yes thank you no it's precisely this we we are right now very much involved in projects that are related to this too not the data the metadata because we are right now when you analyze how the network is behaving we are feeling the deluge and we need and this this kind of initiative is something that is of extremely extreme interest to us just to as a as a node thank you thank you oh oh okay that's great okay um i thank you um so i'm misha wang from china chinamobile so i will present this work uh in-band flow learning framework also on behalf of uh louie and friend the courses so okay next slide please um so the network telemetry is uh provides a network visibility and tools to the state and behavior of a network so it is a crucial to network operations and load supervisions so from our operator's perspective it is important to monitor the live traffic including the delay and packet loss and previously we have presented the problem statement of the event flow"
  },
  {
    "startTime": "01:18:02",
    "text": "telemetry deployment on the last itf committee so just mention that we really have a large scale of um 5g backhaul networks like um like uh 40 400 000 network nodes and um already have um fifty hundred thousand um base stations so so this um issue is really um important issue in our large-scale network and in this draft we are going to propose um a framework of the indent and flow based information learning mechanism to try to solve the problems in our deployment of the television okay um next piece also first the framework of the in-band flow learning includes three components of service discovery and telemetry deployment and telemetry adjustments so for each components there's many functions i like in service discovery um the main function is to do flow characteristic acquisitions and in commentary deployment the main functions are to figure the telemetry type policy and instance and for the adjustments um the most important function is for aging so um there are still methods to do uh those functions um so the differences between the methods we listed here and then the controller trigger or deploy all the device deploy or trigger and sometimes they work together to to complete a function"
  },
  {
    "startTime": "01:20:02",
    "text": "so okay next please and here for the service discovery we consider is a process of sampling to the service flow which is being transmitted in the network and in order to further determine which flow should be monitored and depends on the characteristic of the service flow like ip source address ip destination address tcp udp port numbers vrf interface network nodes and also can be mac address or the combinations of these characteristics and to target the service discovery is to obtain these flow characteristics from the traffic and it can be configuration triggers you can based on the database of a planned service flow information which is stored on the central controller and uh we can obtain it from the network operations so um such as a table of services uh between the base station and co network equipment uh in our 5g backhoe scenario and we also can do device triggers like live traffic sampling and to relies on the capability of forwarding plane of a network node okay next piece the parametric deployment um functions are type policy and deployment so first type we should um consider is end-to-end type or hope i hope type for end-to-end um you can just got uh the report from the endpoint and uh egress node and for"
  },
  {
    "startTime": "01:22:02",
    "text": "hobart hub um each node on the path should report the um performance monitoring yeah and for the telemetry policy is to determine which flow should be monitored um it can be um a lot a lot of strategies and policies um i just put an example like we do in the base station or mainly based on ip and port yeah and for the deployment it can be deployed by the controller or it can be deployed by the device itself so okay next please and for adjustment there's two scenarios um first is the route convergency so when the service flow uh switch to the other forwarding nodes um like in some protection or rock commodity scenario uh to monitor the same flow information a new telemetry instance is required to add on the new transit or e-grass node depending on the service telemetry type and for aging so regarding um iv or event or a performance monitoring running on the fourth pass or there is no flow that that meets the policy uh during a period so the aging of of the iv or in band performance mandatory should be supported in order to recycle the network resources and the instance should be delete or once it becomes still so it can be controlled by the central controller or um the network can do itself oh okay i think"
  },
  {
    "startTime": "01:24:01",
    "text": "we can um so for the next step uh we will update the draft according to the feedbacks and we are warmly welcome any comments or contributions to this one okay um that's all thank you uh good evening uh thank you for your draft um the i i have to say in your presentation it was just a little too high level for me that is to say what are the triggers what do these triggers look like what functioning what functions are intended to be triggered um i guess the next step might be [Music] for everybody to go read the draft or at least for me too but uh what i'm looking for i'll tell you what i'm looking for will be a little bit more meat in terms of the technical steps that would lead to interoperability thank you okay i see um i will write it down and i will do to to specif specify the um methods and the functions with the colossus okay yeah hi uh this is charles eckel and um i have to confess i haven't read the draft yet but i appreciated your presentation and um one thing i was wondering is do you envision uh some of these flows just being configured like where the application or an operator or someone who knows certain traffic is expected to be on their network they they might actually want to"
  },
  {
    "startTime": "01:26:02",
    "text": "just configure or let you know about ones that exist and could that happen in parallel to learning the flows as well question is that um uh so we can configure the flow learning and the same time um the customers can uh can um you know can start flow learnings themselves is that in that question yeah i guess so i was wondering uh explicit configuration rather than kind of autonomous learning oh yeah um [Music] that's a good vision i think i'll never thought about that before because for the fight back home is um more like the operator's uh privacy networks and it's not open to the real customers now it's just connecting the base stations and and our code networks yeah and um maybe if it is um [Music] in the near future um if there is uh some enterprise customers uh connecting in our networks and we can do that yeah okay thank you okay rob uh make a quick you're cutting into your time now uh fine okay so um i just wanted to basically and say thank you for watf and i may haven't read the draft on all i only skimmed it i think my one question concern i have is this work looks like it might overlap quite heavily with the ippm working group and i definitely think it would be useful for you to present there"
  },
  {
    "startTime": "01:28:00",
    "text": "and get their feedback on this because i don't i'm not sure we should do much with it in upc if ippm aren't supportive and so i think i'd like to understand exactly what the scope is of here and how that relates to the ipp and working group that makes sense this question so we have proposed the uh problem statement in both ippm and ops awg and we think um so this work is not um so technical to how to do the performance monitoring but more related to how to manage uh or how to deploy the large scale network to support the performance mandatory so um so last in the 112th ietf meeting um we discussed with drill and so i think it is can be done here of this work okay if we do that i think i need to shut the chairs but things would be very careful coordination thanks rob thank you uh germain can you hear me we can hello okay let me present um this chapter problem statement and the use cases of adaptive traffic that collection next slide please motivation first i t curry network network needs to"
  },
  {
    "startTime": "01:30:00",
    "text": "provide real-time traffic visibility to help little work upgrade quickly and accurately look at the network congestion and packet loss make time timely pass adjustment for determining services to avoid congestion on the other hand this assistant simply at a mini second intervals will generate that constant variable amount of data which may claim smart transport advanced resource we will load the service service for data collection storage and analysis our object objective is to explore the adaptive traffic data collection mechanism so as to capture real-time network state at 10 million minimal resource consumption let's next flight please yes problem statement uh iv network is of traffic-based calculation but a long-time operates highly up telling the traffic visibility for lateral management system which cannot reflect like this kind of baseline catalyst speakers first the observed average network traffic mask the characteristics of chico best give diet snt is widely employed to collect uh collected electrical traffic at five minutes intervals second in spite of low uh low link usage such as setting to 14 percent evaluate bandwidth utilization mailing claims have still been received about four per year in theory applications with this sensitivity of this delay and loss"
  },
  {
    "startTime": "01:32:03",
    "text": "large quantity of operation of relationship indicate that that based alumni layers a case frequently in of race car really workers such as lighting rain and repair uh country natural quality network backbone network and in the data center by means of telemetry techniques we can capture the complete aspects of mac based traffic harvey it is improv privacy to give the real-time traffic visibility at the cost of resistance sampling at a millisecond intervals last slide please please as long as that's your traffic data connections not amazingly a real-time portrait of interface traffic included categories takers of telling the all holistic and genuine characteristics of intel interface traffic is the basic requirement for this statistical multiplex model of it network which is of great significance of war traffic prediction network planning network capacity expansion and network of optimization and so on and the longer long congested little conditions which high face at the time of 55 percent above millions level 70 cycle is enough but we are detecting a congestion state or trend assembly cycle must be turning turning to milliseconds to capture a map of interface so it is essential to explore the adaptive traffic data collection technicals to"
  },
  {
    "startTime": "01:34:00",
    "text": "depict multi-dimensional real-time portrait of interface traffic localistic at the minimap resource consumption let's start please next steps we will solid commands and find the draft accordingly possible implementation and verification that's what thank you hi xiaoming um thanks very much for your presentation um two comments the first is you may be able to do a fair amount you may be able to get a fair amount of information um if you're interested in particular thresholding activities by using the event map which is already defined in the itfs you might want to take a look at that the second point i want to make is that there was an excellent presentation earlier in the week at the irtf open meeting about a b comparisons for research which looks at monitoring methodologies and it might bear on how you want to look at this problem as well okay okay sorry i i don't understand what you can see okay i'll try my apologies um there exists a mib a management information base called the event mib and the event mib this is event as in an event happens"
  },
  {
    "startTime": "01:36:00",
    "text": "it allows for threshold configuration so that when say a certain rate based counter exceeds something or a queue depth exceeds something you might decide to do additional reporting through that event map this already exists in the ietf and may help you i don't know if it solves completely your problem statement but it may help you address at least part of your problem statement the second point i was making is that there was a an applied network research award presentation that talked about ab comparisons um for uh traffic treatment um done by a a woman who was at least doing some work with netflix and i thought it was a very useful way to avoid buy a thing of results something you also may wish to to just have a gander at a look at excuse me thank you uh okay we are not okay and looking into that but my my easily ability is available please uh sometimes please send your comments and the question to me by email thank you elliot if you could summarize that on the list that would be fantastic thanks and thanks xiaoming for presenting we have our last presentation and on the floor is yours"
  },
  {
    "startTime": "01:38:04",
    "text": "can you hear me we can yeah okay so uh hello everyone um we have our also on the call so this presentation is about a young model for data export over ipfix um next slide please so we have uh an existing model so sorry first of all we are looking at uh ipfix as the uh one of the options for bulk data export and one of the main options so mainly in the broadband access nodes where there is a great need to export a lot of data uh to the to a centralized location and there is also one more application where there is a need for exchanging data internally within the node so that is the ictp case where uh uh data for two channel terminations are exchanged between uh the two uh uh ng point or ng point of boots are within the same board so that is one more application next slide please um we have an existing uh yang model uh which was written by benbow but it it was in the early days of netconf yang and uh and meanwhile netconfian has evolved a lot and even the application of ipfix has also evolved from just packet sampling towards bulk data export so we have we see quite a lot of limitations there where it is closely related to packet sampling closely tied to package sampling and there is a mandatory uh requirement to support a ctp"
  },
  {
    "startTime": "01:40:00",
    "text": "but satp is not used widely and we don't see a hope i mean or see a adoption in the future or two a wide adoption in the future too um apart from that we also had uh i mean have some uh outdated references to interfaces and uh uh statements which i mean uh leaves which are not no longer uh valid in the net confiyang world next site please so uh okay we already had three divisions of the previous draft so the draft underwent a name change because of the change in authors so the previous draft which we did had envisioned a replacement for the existing 6728 model so we had tried to update all the entire yang that was that in 6728 split them into three different models to for the ease of use in the uh deployment so iet ipfix had exporter and collector psamp had the peace and specific functions and bulk data export focused on the cache and the bulk data export related parameters so and we also made https optional instead of mandatory to allow for deployments that use tcp uh mainly uh with uh tls and also updated the referencing to reflect the current uh reference interface references and addresses so okay next slide please so we received a lot of comments on the uh model um one of the main comment being that it is too long and it is covering a lot of things that uh needle uh quite an extensive review so uh based on the comments we have revised"
  },
  {
    "startTime": "01:42:00",
    "text": "the model uh so the new uh draft name on the new draft model is an updated version where we have uh removed the psamp and the collecting process and we have tried to focus only on the bulk data export part of it so which has the ipfix exporting process and uh ipfix exporting process and the bulk data export part of it so uh this is a shorter version of it uh plus we have uh stuck to only tcp as a transport protocol and uh removed the file uh operations and the file and http and udp so which udp is not secure enough so we have stuck to http uh sorry tcp here next slide please okay so so it's rather a small uh uh uh display of the young tree so basically we have the idf ipfix exporting process on the top and the bulk data export which is which is the configuration of the template ipfix template at the bottom next slide please so uh okay we uh we understand that this needs to be an ad document but after the comments were addressed and we called for an adoption in the mail mailing list but we have not received any feedback on that yet so we would like to know uh the comments and if there are any challenges in moving towards wg adoption for this draft i think the next slide also summarizes the same maybe one more point to add is that there is an open liaison request from bbf and uh uh the link to that is shared here so uh uh bbf is actively looking towards uh"
  },
  {
    "startTime": "01:44:00",
    "text": "this draft getting adopted as an rfc yeah any questions comments we have a couple minutes for comments i tried to run a poll but it wasn't asynchronous i was trying to see who had potentially read this new version of the people who were able to respond five uh out of the 13 and out of the 18 participants said they had so that doesn't leave a lot of people who maybe read it rob uh yes so thank you for thank you for persevering because i know this has been quite a long and quite hard process for you to try and get this work progressing so um as i understand it before i was an aed the previous um ops management lady agreed to ad sponsor it but it hadn't progressed at that time and there was concern raised that the previous version this was trying to uh obsolete uh the previous uh standard track rfc and i was thought that was inappropriate to do that through sponsored i personally i mean i don't have that much experience with ipfix myself and i'm keen to try and get these things through the working group as much as possible i'm really pleased that you've um cut down the size of the draft i think the previous 150 pages down to 50 pages which mostly just yang now um with a bit more so i would please ask the working group if they can help give this attention and try and get this one through because i think it's important that we actually help the bbf who are trying to do the right thing here and i would rather try and get it through the working group and get more eyes on it and get a good document then they gave our the ad sponsor path which i don't think would get quite a good result so thank you for bringing this here yeah thanks rob sorry real quick and i think given his as chair i think given the restructuring we could do another uh call and see if there is renewed interest in picking up this work yeah just to reiterate uh we are no longer obsoleting rfc 6728 so it's an"
  },
  {
    "startTime": "01:46:03",
    "text": "entirely new draft that we are proposing now [Music] uh elliott and sorry if we're difficult to hear i'm trying to get into the mind because it might express yeah you are a little faint joe i i don't know what's going on but um my suggestion here uh to the working group i like the idea of the call for adoption i would delay it by a month and then um maybe the chairs can harass us a little bit on ops area working group to make sure that we're reading because uh it it does sound like it's it anytime we see something that that you know there's clearly some value in the concept clear if bbf is asking for it that's even more important and you know to at least pay a little attention to it and um you know i i think though that the small number of people who read it as indicated on the um in the poll is a little bit concerning so just a little harassment from the chairs and giving a little extra time to read it um it could allow us to to get a better read on on whether it's ready for adoption [Music] yeah you can you can get any time joe with that hank anything to add so we had some uh um documents in the uh early agenda stage uh that uh might could we could be in the candidate state for last call at least for review i think they were mud related i guess and and so we didn't they didn't come up today we will take care of that if we press some review buttons here we will uh confirm the editors and then go from there"
  },
  {
    "startTime": "01:48:04",
    "text": "thanks and with that uh rob and warren would you like to take us home i gave them more than 10 minutes i win how long how tall do you think i am anyway hatism that's too short well this is this is for the first time i've formally been standing in front of you as an ad which is sort of quite nice um and the first time so um i think it's really if you've got any questions for us it'd be lovely to hear them um normally when we ask this sort of question we get no response even in the uh plenary yesterday there was no questions to the isg so probably the opportunity to have no questions here but we would invite them um we'd also invite any feedback and comments back to warren i that's also something we actively like and look for um and the last point from my side is that if there's folks that are interested in stepping up and helping doing like um doc sheparding or they're interested in like working with chair roles that sort of thing then do email warren and i contact us and we'll see what we can do to help facilitate that sort of path in the itf and my turn so as you all probably know i've been doing this a.d thing for a while now and i am still enjoying it and it's still fun but at the end of this year slash march of next year i would have been i could have finished my third term and i think it would be good if there were other candidates for the nomcom to choose between and for the community to select from so i don't yet know whether our toss might happen in the ring again it's a nice hat though you must admit um but you know i would like to chat"
  },
  {
    "startTime": "01:50:00",
    "text": "with some people about what it's like being an ad how much time it takes the fun bits the not so fun bits so if you think that you might be willing to run for op cd please let me know um and i think it's always good for there to be some new blood and changeover so you know this is sort of a plea for people to step up and be willing to serve it is fun um i mean you do have to work with rob but other than that it's fun crappy's right behind me um no i mean it's a fun job one of the nice things is you're expected to read all of the new drafts and so yep we all know how that goes but you know if you're forced to read them you actually end up learning a bunch of interesting things you're like wow i would never have read that if i wasn't forced to and it's actually it really is one of the better parts of it maybe not at the time but um it's a reasonable time investment but you know the first what year is fairly unpleasant while you're trying to figure out what you actually have to pay attention to after that it becomes a lot easier when you're like this i don't care about this i don't care about that i'm gonna work on you know build up a structure and a system um and yeah once again you know please consider doing this um it doesn't have to be a full-time job if you let it become one it definitely will but no it really doesn't have to be and please come and chat with me chat with rob etc and open mic there must be at least some set of questions you can't possibly think that we're doing an awesome job all the time can you um alan the mike ah okay hi i'm trying i was trying to turn on my video here but i think i did the"
  },
  {
    "startTime": "01:52:01",
    "text": "wrong thing all right here we go there we go hi hi so um uh here's the question and and um it's one that um folks who have been following the upstairs mailing list probably have some inkling about i was the stuckey reviewing the the quick manageability draft and uh in that draft i happen to find that uh there were statements where essentially the the authors and then ultimately we found out that it was a strong working group consensus that they wanted to at least recommend um network admission uh settings where we as operators network operators where we would not uh look at the version number uh and consider that as uh as part of uh admission control and that struck me as maybe out of bounds for uh uh for a draft to specify or a future rfc to specify because admission control is enforcement of policy and i don't as an operator i don't as an operator want any rfc to specify policy so i'm wondering if other operators agree and if the ops area in general agrees and it's going to take that kind of consensus i believe to do something about this because in my comments back uh what i've heard you know from the authors who are i consider both friends"
  },
  {
    "startTime": "01:54:00",
    "text": "um and other folks from the working group who are friends that this is this is working group consensus and we can't do anything about it so it's ultimately going to come to a head somewhere um i'm not getting much uh satisfaction with that particular point but that's the one i wanted to raise here today thank you so elliot is your comment on this uh it's a clarifying question um so hey uh uh how you doing al um my uh my my clarifying question is is the is is that in the text because the information might be unreliable or is it in the text why is the recommendation made because it it may be that they're saying this this is something that operators should not rely on for policy because it may it could be completely bogus or or whatever the case may be what was their logic well i've heard lots of feedback on that some of it is that the version numbers will change fast that there will be additional work on this and and a new version fairly soon and the the underlying uh sentiment that seems to come through is um you know treating operators like they were back in 1998 where there was you know you know very infrequent changes of network policy and they like to relegate operators to uh you know the fact that their only role is is ossification and and i think that's a you know it's a it's a very much a convenient view for uh the the particular working group to take but i i would contend that it's very"
  },
  {
    "startTime": "01:56:01",
    "text": "much of a view from the past thank you so so i mean this is warren i mean it is somewhat of a difficult question because i think some of it is also the belief that seeing as you can't really tell what's in the stream you're potentially blocking or you know doing admission control on something which is somewhat arbitrary right like whether it's version x or version y you still don't really know what's in the rest of it and so what are you making this decision on um and then there's also the sort of what if we try and deploy this and realize that we get stuck because somebody has done admission control in this and now we can't deploy a new version so i don't actually know what the right answer is i mean i think it's perfectly fine to raise it as a concern and after a few back and forths you know you could only just throw your hands up and be like well this is what i as an operator and other operators think and let us know and you know rob and i can try and do something like put a discuss on it or something um right if they end up in the position where you express you do upstair review it's incredibly helpful if you try and push the position and get too consensus but if you can't you know let us know and we can try and do the this is what the operators are saying and it's a valid concern and it needs to be addressed um you know we'd prefer not to be left kind of holding the bag but that's kind of what we're here for and then i'd prefer if rob does it because after all say wg is his side so one follow up to that uh quickly warren um i i'm raising it here that the"
  },
  {
    "startTime": "01:58:01",
    "text": "the question in the topic because um i mean right now it's my opinion uh as an operator i'm trying to find out as if as you said um are there more operators that share this opinion and we have some time to figure that out um and then and then the other the other side of this is i i think it's a perfectly reasonable policy for operators to decide on uh that they admit of traffic with version numbers that has a published rfc and then i don't you know and then if i want to see what's inside i can do active testing i don't have to do uh i mean the other the other point of view that that was inherent in this in this draft uh as it moved forward but was an implicit part of the scope and we've discovered this in the comments is that they really felt all that operators would do would be the passive on the wire monitoring and that's not that's no longer true and and it's it's not it's particularly uh untrue in this case i mean you know we've been challenged to find new methods to manage our traffic and and one of those methods is apparently you're going to have to be uh setting up our own endpoints and terminating the traffic ourselves and trying to figure out what's wrong with it all this and this is all under the assumption that the operator wants to support quick and that seems to be anathema to this working group as well yeah i mean i think you've identified sort of one of the key bits here which is there's definitely a tension between some of the views in you know certain working groups like quick and some of the views of operators like there's a tension of a belief that operators are out to be difficult and no information should ever"
  },
  {
    "startTime": "02:00:01",
    "text": "be exposed to them ever because they will just do bad things versus the operator view of like well if you want to pass the traffic over my network i kind of need to know what it is so i can protect my network from it and you know that was somewhat discussed discussed and kathleen's effect and crypt and a few other ones and it's definitely the tension is definitely stronger in certain groups and areas than others um but yeah i mean i i think it's perfectly reasonable for operators to want to be able to force policy on whatever they like um i guess one thing that i'll note is even if the rfc says you know you can't do this if your box has the knob your box has the knob um this sounds very much like the nuclear option of like i don't really care what urfc says i'm gonna do x which definitely doesn't help repair any of the tension but yeah like i'd like to know what other operators think on this topic if they've been following the discussion etc and i think i stepped in front of rob yes i was just going to continue from a different perspective i think that one thing's important they're saying that this has working group consensus on this decision but the documents that we publish have to have itf rough consensus so i don't think that that alone is sufficient to say you can't discuss this has already been decided that's definitely not in scope and as warren says we will help support you in that the the the side of it that the ops the ir reviews are really important from us because you help offload a bit of the work from warren and i that we've had an opt-i review it means that we don't have to necessarily spend quite so much time reviewing those documents and when we have 400 pages of documents to review uh along with everything else that's really helpful so so abd all the ops dr reviews are great and really helpful on this particular point i think the other thing that might be worth pushing back on is saying can this be expressed in a different way so rather than saying you should not do this field you should shouldn't do this filtering"
  },
  {
    "startTime": "02:02:00",
    "text": "say these are the problems that can arise when this if you do this filtering and then so it's not enforcing a policy it's just saying consider this when you're when you're applying this that that might be a sort of compromised way that gets the message across without putting any rules in place yeah and i tried some alternate text and and it was rejected uh i don't you know the answer was i i don't want to change the consensus text there you go sorry and just one quick note i mean yes as rob said you know upstairs really helpful if you run into issues like this it's also extra helpful to just drop rob and i a note so that we know to be paying attention earlier and more attention and not just sort of look at the upstairs thing and be like well there was some discussion and it got resolved so yeah yeah sorry man but i think i already did that [Laughter] well uh just a couple of things oh hello this is diego hi diego good to see that you have a so well decorated wall behind you it's uh it's amazing yeah it gets them out of my drawers well no yes you were asking for for the opinion of more operators and for us it's a it's a concern and you know it's a concern and we have been talking about this uh quite often um precisely probably i remember some time ago there was in the in the transfer group there was a draft that was promoted by uh gauri fanhurst from the university of edinburgh that was very much involved in this precisely about the operational implications of the use of transport transfer pervasive encryption and all the like and uh my impression is precisely they don't they don't fly as they should but probably this group is one two this is one that is very adequate to raise these concerns because it's about we're talking about operations we're not talking about anything else we're not questioning at all the right of everyone"
  },
  {
    "startTime": "02:04:00",
    "text": "to have a privacy in the communications or whatever it is about well but we want to run properly the damn networks and this is something something again that i had tried to raise these uh going in some conversations with people from icehock is about the implication this would have in the sustainability in the economic sustainability of the internet ecosystem not when talking about sustainability i'm not talking about green things or whatever that is important as well but it's about that there is a group of different uh um entities that have been making money and earning earning a decent life from from operating the internet if we push in in a single direction this would be would make the internet unsustainable in the current terms and for example the basic network service would become i mean the only way if the if we go in that direction it will become as a state monopoly and i think that very few people would like to see this happening here and in many other places in the at least in the western world i know it's a fully political opinion i know but things have consequences and we have to learn to live with that so five minutes over closing your marks my only closing remark is thank you for the work you do yep and extra thanks to upstairs and extra extra thanks to anybody who's willing to you know consider running a cd have a great evening everyone this concludes uh observing wg so germany"
  },
  {
    "startTime": "02:06:01",
    "text": "yeah it's a germans oh i don't know yes so i literally tripped over a chair"
  }
]
