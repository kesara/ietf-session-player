[
  {
    "startTime": "00:00:24",
    "text": "I'm you Welcome everyone. We will start our session this is the an emerging meeting for Of one sixty seven sixteen. So some some information for participants for for remote I hope you connected through the meeting and that you should turn your audio and video of while we are not speaking or sharing. Thank you. On, we would like to remember that there is Iot of policy for to wear mask all the time, except if you are an active speaker, presenter sharing. So please wear your mask while in the Iot meeting rooms. Also, even if you are attending in person, please log to the vehicle echo. You have an on meeting tool this allows to record participation of the session. If you want to raise questions, during session, Please also do that by joining the queue few ago. I will manage the queue. And please keep your audio and video of please. Thank you. So we have a a number of note slides"
  },
  {
    "startTime": "00:02:03",
    "text": "that we like to go through before going into the actual content of the meeting, but this is important. Reminder for different It and iot of policies. So the R follows the etf property right disclosure rules. And indeed... In these slides, you have some pointers also on the behavior you're supposed to have for to Declaration in the context of the It etf. We have also some privacy and code. So as a and until to any Iot activity, you acknowledge that written audio video and for photographic records of meetings maybe be made public. Your personal information that provide to the Ir will be handled in accordance to the privacy policy that you can fight other the link on the slide. As, or attendee, you agree to work respectfully with other participants. If you are with this or experiencing, different issue with this perspective avi you can... Contact the team or contact any member of the Irc and. So now also a reminder that the goals of the R, So Internet research task. We do conduct research it is not in installed development organization. The Iot focuses on longer term research issues to the internet while the parallel organization, Etf engineering task. Focuses on shorter term issues of engineering and stone making. While Can publish informational and experimental documents in the Rf series, its primary goal is to promote development of research. Such collaboration and and exploring research issues with Internet protocols, application, architecture and technology."
  },
  {
    "startTime": "00:04:02",
    "text": "And if you want to know more bit about the approach of the In the contact of the, you have also a nice Rf seat. You can look into These are some useful links you can access the materials of the meeting, access to the meter core and also so the share notes, the video of the session will be available. Later on the Youtube channel. A bit of updates on the stages of the research group especially concerning, let's say, active documents. So for some time now, we have the digital tree network comes at an architecture document that is an adopted with documents. The let's say, the new one that we have recently adopted, we are earning and official announcement of that on the meeting list, but we use the meeting to make this announcement. We have a new research group documents, so the file option was done earlier this year, so we have no a new research challenges in artificial intelligence for network management as a research group documents. This will be changed to become draft energy Ai challenges zero zero. We will ask the offers to proceed with that. And also instruct the authors to provide a new revision. Will address the different comments and suggestion received during the the file option. Around the next speaker, we also have a few words on the the comments received during the call for For. And we would like to really thanks all of the reviewers. People that have express different opinion support for the adoption of documents and all the offers in occupants. To this discussion in the research group. There will be a bit more in in the next percentage presentation. Some other research group documents that are in the pipe So these are not research group document, but individual draft, but they are"
  },
  {
    "startTime": "00:06:02",
    "text": "especially looking into a different set of use cases related to based networking. So there are three, but let's say Use cases that we have in the pie for some time, but the reason see we have also two new draft that has been submitted to the I mean, for to the to the research group electric management intent and one that that transmission intent. So these are new draft, but we have not yet seen Let's a discussion on the middle list or inputs from the offers about the next step for these documents, this will up soon. What we like to suggest also because this is ongoing let's say work item for the research group. To start some dedicated discussion on the Ib use cases in the context of the energy. And also we will invite for a dedicated meeting to address collectively the use cases aspects of investing working in indian. So this will be announced. We will make some more research group announcement. Soon on the mailing list So as I said concluding the Ib items of the research agenda, I think we have covered most of what we intend to do for this topic in the research group, we have still to go through this set of draft on use cases and see what could be the the good outcome want to produce with that. And for some time now, we have at least three topics that seems to anchor partly into the the research group. So we have different activities related to Ai in our for network management? This will be the top the two far free following parts. We have also network digital twin. And green networking related aspects. Our discussion with Ji jerome was to try to understand for these topics, what the research groups wants to do about them."
  },
  {
    "startTime": "00:08:00",
    "text": "Because these are pretty big topics. We have to understand what could be the value contribution in terms of research outputs for the research group and to define this collectively, so that we know also how to let's say, steer our energy to what's agreed outcome for these topics. So now entering a bit more on the content part of this station. So this is the introduction in which group status. I just give We will have a first part of the meeting concentrating on artificial intelligence and data for Network management where we have four talks. So stages on the the newly adopted draft. On the challenges. There will be Jung presenting on the consideration for the deploying Ai service in a distributed approach. We will have a talk from catalina on network that asset set quality problem. And then Diego an approach they've been working on on with yang into an network data fabric. After that, we will have presentation from Chris on network digital twin for the functional functionalities design aspects of performance oriented digital twins. Finally an update from Alex on the different draft. And let's say ongoing activities in Etf R related to green networking that's the agenda for today. And I think we will very he jump to the first presentation that will be by by. Do you have anything else to have before we switch to your presentation? No no no. That's not just welcome everybody. And for joining. So we can I have no no document? So long"
  },
  {
    "startTime": "00:10:04",
    "text": "Okay. You can see the slide. Yep. Okay. Okay. Thank you. So again, I can see later everyone. So I will the regarding this document with the challenges and completing and Next slide, he's. So we have version which is version to know which was based of course of that we received already from the feedback from the call adoption, So just as remind us the code of partition was based on suggestions is in one version. It ended in February first. We got a lot of positive feedback as you can see here more than twenty people reported document no one was more and we take current And based on the Command we have the that's a big note. We the different. Like, please So of course, there has been a lot of, let's say minor change and editorial changes, so which is bus. In order two... There was some relevant papers and so. Have a little list of let's, I twelve for the race as a reader. We have been in the review we received of some someone highlighted some B between Ai and. He had some let's say kind of this gave to to in the beginning of the documents introduction to to make the the distinction?"
  },
  {
    "startTime": "00:12:01",
    "text": "We also yeah. Corrected some because you know as was document let's see And plus already before it it becomes a left. We have some issue between in the section four to to calculate character sorry to characterize each that car regarding some criteria and for some of them missing so we had in it. We... Okay we some to at some clarity classification of sub. And was yes somewhere so we're thinking based on the paper resolved. To highlight least straight. Next slide, please, So no worries, which maybe that interpreter I would say. So of course, we we received different comments regarding the eye Maybe as a reminder, this is also a section that had in mind Is a already origin of the documents that people to decide because it didn't content at that time. Of course, the discussion is okay here it was totally justified. So we send it to this by adding a dedicated let's say, is too sub sufficient, I would say. Order to address both when we we we think I would choosing This for network management management programs. But although as is distributed and that network is also by, describe some challenge regarding the network management that can support district. We have some let's say say citation for. I think that's note."
  },
  {
    "startTime": "00:14:05",
    "text": "Basically it's what we try to do here. Where is it two far? For and network management or is tribute to the high. And so basically where try twenty eight sets term challenge that the good level of coupling between the two, let's say is the two to develop two planes play in the Ai plane Next slide, please. Okay. So we also receive a comment regarding the relationship between Based management in digital. So for basically two topics that are is that our? Of course, you can have but They can, of course can be used very example Ai to some digital and it networks that's for sure, but it's not... Let's say it's not as it's mostly kind of a use case. I will say in that case, as I that ready correlation. So we tried to with that explaining to section that they put right here. That both of technique if we can be combined, but as our difference let's save objectives somehow. Okay. I think long give me the control on the slides. So they can can go myself now. Thank you. So and so some x it's a change is that we So it regarding the one It's a last section we have on the joint document. That with be based projects and another products system, different comments commands. Regarding the lack optimization functionality of Learning. Invite on invest. Twelve hundred solution. So that will be a problem if wanted of the system of course production."
  },
  {
    "startTime": "00:16:04",
    "text": "So we elaborate a bit of these challenges we're getting representative picture twenty seven nine to I know that's up as that are possible to full of areas is research to do why this is the document type. Are providing for solutions as go a document. And we also had because we said come really interfaces issues with Ai and the. So of course, we are agree is important. You to have something that's runs. Into your system. So and pollution. We need also to take care of that as also is important towards the right for example ai framework networking measurements. From where the two use. Of course, this is a bit with two was for a license document again year I just put here's some of text. I gonna just to then condition, you want exactly to go to the document and see what does the change here. You have the reference. Where you should look at if you want to see documents. Okay. For us recommend comment, Okay. We have. You receive comments commands regarding to add more the discussion of specific that they should use the resolve such of challenges As I said before we try to illustrate possible solution us to to for certain challenges. We had some reference. To have that. We received also some comments commands regarding that this document out, of course, would be let's say Address twelve both, let's say the Ai that we have a lot of processing of."
  },
  {
    "startTime": "00:18:02",
    "text": "And maybe easier way around networking guy is maybe a little bit of... I signal just So this is something piece that turns out with with reflecting ultimate to make sure as right. Oh, it's eighty days and friction. But, of course, we were... What we want through here we document goal is very not to provide solution. Otherwise it complete scope. The document? So we just... Let me put you as example. Exact team of for which challenges, what solution you should use, actually, is already challenge itself if the team section dot one. So we try to rates But of course, it's not good. It's in not is possible to be you to say exactly for which challenges what we should execute. In terms of solution to be there to be used We received all those comments that could be good to feedback from the operator. Of course, get to the feedback from disabled site. So we encouraging to give the perspective on the current documents. And like, maybe just to be minimize that. We have, of course, terms address we once, but if you just for the least to be document, this quarter say to... Because we got different contributions many people from different, let's say. And when windows in then this group of. Takes assistance from all these people already already incorporate some type of some this feedback, of course, was in previous joshua So know, it should zero too. Okay? We feedback from. So next step? So I think long, as you say in information, so we because no"
  },
  {
    "startTime": "00:20:00",
    "text": "at the time I prepared slides, there is no yet new fisherman where we're regarding should as you say so no, it can become research would document. So for this for this step, it's it's so seems very good because in our opinion, it's a very hot topic pick the Ai in order area we are including ours So it's It's good as is document no and not too manage. I think it's become every documents. So no way we tried to it's now you can try twelve have really. Very date to to move firstly, maybe two routes with so wish at least towards information or certification. And that's it from my side. So of course, any question we'd be happy to answer. Just didn't been All that questions. For these traps to all the offers. Is a recently research document. I think it's as you mentioned, has be pretty stable before becoming draft? We now. The second version of the draft, it's becoming adopted And the idea is that if the content is stable and weak estimate estimated value. To proceed say swift fleet towards I mean, to push it towards publication if there is agreement with that. Any comment. On on the document. Everything's clear. Thank you. To the next presentation?"
  },
  {
    "startTime": "00:22:05",
    "text": "You're can go ahead. Okay. Could you hear me? Yeah. We can hear you well. Okay. Thank you. Good afternoon. On at. Okay? I'm sorry to attend the cover meeting. Goes I'm on a. So I can join in Mr not in person. Okay. This is the of the deploying ai services. Know, distributed approach. The third. Okay. Next page, please. You have the control of the slide. Okay. Okay. Thank you. Yeah. This or history and status. Last year. We submit and this year, we published the third and Also, it is the third time presentation. Vision of this trip. Follows. The first thing is to Yes. Now we are targeting on the deployment of Ai services until I remember that in ai care, we spent what thai to find or possible then adjacent item, in lake or working group. But it is not easy because usually we think about Ai public. We also think about training. But if we think about training running. I Room"
  },
  {
    "startTime": "00:24:01",
    "text": "our side. So if we Google from training to impress So I Six there are a lots of room to do. Or can whole plus but only I suburb. Also hardware like lower pop, and air chipset that can be used for provide so to do this, we must consider the system the outside to provide Ai implant services to this. We consider Not only of the model or the also consider which is the best services and objective of the put in the point is or can be a different. For example accuracy latency they talk resource utilization, etcetera. So there lots of punctuation to you, with employ network computation, system ratio. Yeah More there? Starting p. Communication vessels device capacity the imp data, etcetera. So the intention, the motivation of these maps to the of outside Ai issue and the pine is password and aviation items in the n emerging. Yes. In the the left run the meeting when I preset this I pass three two com... To k and the one comment. So first switch on just Okay. It since we lost the audio from Mu. We we can see you speak, but we don't have the audio. In the room."
  },
  {
    "startTime": "00:26:01",
    "text": "We take guys? Can you check, please? And then, can you try to speak again see if if it's better? Okay. No. Hello? Okay. Exactly Okay. Thank you okay. So so he that side. So in the the date on will be back. Yet and. Is and quiet. Okay."
  },
  {
    "startTime": "00:28:01",
    "text": "So by I section session I So if you see we will see a client can So I people I some that Yes. Sorry to interrupt... Can you try the studio mute on right disconnect and reconnect because we have a very Would you hear? Or if you can withdraw from the queue and rejoin the queue as a speaker. Maybe will Okay. I... I tried. It's good no. Yeah. Please go ahead. Can you try to continue now to see if the voice is okay? Okay."
  },
  {
    "startTime": "00:30:01",
    "text": "Yeah. It's good. Yeah. We You well now. Thank you. That So in the, we have those three network completion structure who proprietary the services And then we have two u compression or one server ratio. So if we look at group's click group or specification. Me I is I easy eight hundred zero six for the one two one two one. On mobile computing or market acceleration, m metric test and ky. When I say this document, I think I think if we it is better to have those... Similar document because, this document are good good document to provide the board the specific and the board general information on how to provide some mobile edge computing in the all what's it inside so So I tried to follow on this So I add some dock punctuation doc of the hardware So as as you can see, Okay. So I want to skip... Edit the same to the last meeting. So though my last My last... Yeah. Okay. This is I remember the disconnect list to comment command by jefferson So he went you or make a simple line. We telling a documents So my answer is that his draft is also little late to the challenge document and some text can be added on. For example distributed be to the air ai services, lightweight,"
  },
  {
    "startTime": "00:32:03",
    "text": "services. So when I look at the challenge document, so repeat Ai services and the right wait services is already ecosystem. So I don't know how to handle similar context. But I found a bit deployment as even is not ego in the challenge document. So then, deployment deployment is could be insert what could it be edit? With challenge documents. Also, what? I think that this trip can be deployed as a different document because this graph is to focusing on the Ai influence of air services because the existing team telling partner growth any items. So the focusing point is deployed. Okay. Now this is the last phase. So if some text could be edit what could it be inserted with telling document for your network structure, blah or conservation pull computing their top blah blah it can be able to like, You say thing sets six point three. And section six point four. Put example. So I don't know. I I'm I'm not the editor of the general document. So I want to ask and I want to follow the procedure of this an. Okay. Sure. Thank you. Thank you. We have questions for young for the document on the distributed Ai. For me, I believe it's good that there is let's"
  },
  {
    "startTime": "00:34:03",
    "text": "say some alignment between your documents and the challenges one on on the of course to topics that makes sense. Don't see the need to have... Let's say, for instance, too much integration of basel of documents to the challenges. I don't think this is the goal of the approach and will not be if you show to the research group, I think your document has been there for some time. What would be interesting to know is if you want to a it like research group document and what would be in fact the final form of this research, what will be the contribution you see the impact that these document will provide whether it's a kind of a list of recommendations based on your experience, say okay, if you want to go towards distributing Ai services, on constraints infrastructure what could be the recommendation, the learnings. It could be also to have maybe some I got use case or a real field deployment experience that you want to sharing in the documents. But I think we need to find a way for one for the document. I think it's pretty stable pretty interesting what the content is so far. And to really make a a good position in the impacts as Document could be and then we can move forward. Okay. Thank you for your. So I some point, I agree with your command to to do this. We need a more time and we need the board input So I encourage other person who have interest of this rep. Then it is very to join to trip this work. Thank you. Thank you. Our next printer will be Catalina. Hello? Can you hear me can you hear me? Yes. We can hear you. Yeah. Let me just bring it this."
  },
  {
    "startTime": "00:36:05",
    "text": "Can I manage this presentation? Can you see my almost Yeah. We have just slide on the screen and I give you the control to move up the slide. Okay. Thank you. So anytime you are good, we can stop. Yeah. But I cannot control. Okay. And Hello everyone. My name is Catherine Lexicon. I am receptor from university of applied sciences in long. I would like to spread the words about network data quality problem, and I would like to show my for of quality assessment. As my colleagues said before network management area needs novel solutions. We need first and other methods and artificial intelligence can be helpful here. We can observe in research papers expansion of russian machine learning techniques. But it is still a challenge of to grades machine learning model that works in we have different algorithms volumes. But those algorithm available my are based on data. And the results are this good as the data that we use whole thing. And we can also notice in research papers. Complaints on the lack of the high quality datasets sets. And... We can see also that we focus on model quality rather than the dataset quality. Even though I Quality data is the cornerstone. Or evidence base that making. And particular assessing the quality of"
  },
  {
    "startTime": "00:38:01",
    "text": "network data is for a overlooked area here and I will say also neglect area. But what does quality is it difficult to say? It is difficult to precise the commission usually, and he said the data set to be of high quality if it's meets and requirements, or its intended used. It is quite wide and definition, but generally, we would like to have strong data complete data, which and the problem very well. Which is correct correct, precise then accurate But usually, we can meet money problems in later. For example errors, nice outliers, we can offer we often work with datasets, we can meet different tools. For data clinic? Know the all back of those problems from data said but is not usually in order to say that our data it is a representative or complete for a example it's difficult to you this this tweaks we can also meet sophisticated approaches space on testing and, but is not And today I would like to show you the method which we presented on on conferences. This is very old called pigmentation testing. The statistical method. This method is usual used for evaluation of"
  },
  {
    "startTime": "00:40:00",
    "text": "significance of results based on the rest. I'm in here at arrangement of data datasets assets. How it works in our med. First, we have our data sets already have dataset. With observations, observations in block and with labels set. It means that we work here with classification problem And in labor said we have labels represent classes that we have that we recognize in our dataset set. We are doing commercial learning pipeline on this data. And we obtained performance results through results. And in the second step, we go rotation. Accommodation it is shopping. Changing of position. Labels, it means that after rotation, we will have changed labels. For example if we have what labels. To if we have binary classification problem with pool process, we we'll have label service and ones and after presentation some labels will change to some zeros we change the one and some once as you can see, we use special documentation means that we will pay only pack of labels and we will set policy. And first, we will tell one percent of labels for a example later five but cents and five cents, fifty five cents for example. Order to have better picture on the problem and to check and the sensitivity of our methods. To be more to be more accurate"
  },
  {
    "startTime": "00:42:01",
    "text": "we repeat by patients times hundred times in order to obtained on distribution, this can be evaluated by other statistics. I will say about the key values later here. And this after presentation. We are doing the same russian machine learning pipeline as premise but on the x block and Y, our new label sets after presentation. And after this learning pipeline, we obtain performance scores after fermentation. And we have for example four one plus classifier hundred results. And we compare the results with original one with cruel. And it is expected that after changing of labels, we will obtain horse results. Because we think that we broke a structure we both relationship between x and why because we assume that our data is strong and have a very good relationship between x block and labels. But it is not expected. If we thing better results after fermentation. Done before, because it is signal that we have about quality date data. And it means that after introducing our methodology, will obtain results in the table. For each classifier from the pool of classifiers, we we will have"
  },
  {
    "startTime": "00:44:00",
    "text": "calculated values. And it will be incorporated for each level. Three example four one five as as you nine step I will go later. In order to say something about it this portion of performance results after fermentation. Comparison to original results, we have to define he hypothesis. Our hypothesis is that's our datasets is random. It means that we can change something in our neighborhood and we never thing results. How to evaluate this hypothesis. We have the define the volume. The key value is calculated as follows closed, we summarize the number cases when we had better results after patient than before. And we divided this number by the number of foundations. It it means that if we standard times, our latest, we have hundred performance after. And if the number of... But the results is Hi. It means that something is working, like in our data set we cannot project reject our hypothesis. It is likely more can likely said that our dataset is crappy. But in order to be more precise, we have to set alpha. Alpha threshold in order to say based on p value if our results is significant or not and if we set the volume set point zero point zero"
  },
  {
    "startTime": "00:46:02",
    "text": "one if we want to be more sensitive. And if p value is lower than or a equal. To alpha. We have evidence of specific significance in results. But if value is higher than Alpha, it means that our this is kind be rejected. And interpretation is important here because if we have full of classifiers, we I evaluate wait each results for all results. And if all models performed bugs, and we observe non significance in results. It means that the is back but if some model will platform perform good. We will opt serve small values of values. We have significance in the results, we can say that data is. And now, I would like to jump to on the slides here I prepared... I want the to show your result based on the very simple datasets sets, toyota dataset and you can back I come back here. After the presentation maybe but I will focus on network and data And now because of time, It is also important to say that if we recognize one person of labels in small data set. We have small number of flavors from the implementation. But if we have a huge dataset set, one percent means that we have two a lot of labels. It means that we have phases for change of our approach and we"
  },
  {
    "startTime": "00:48:03",
    "text": "in the next in the second policy. Demonstration policy, a number of labels regardless of data size, it means that find, for example one, labor five flavors can leave us at sat is that of page. Labels. And I would like to show you one use case. It is in the end data set data publicly available and step in Sd the network with this data as has seventy thousand normal observation and a lot of different well known. We consider it here pro products and we created data with two thousand two thousand and twenty dollars observations. It was three data. And in the second step, we add that to these data, five percent of mis lovers. It means that we directly change zero once. And once two zero or around gonna five percent of miss flavors. Of of labels. And it was six datasets or already. And additionally, on the next three dataset, we introduced ten percent of these label it that we had nine data our rotation policy is as follows. As you can see, we tested for the following call of classifiers current kind of from different groups of classifiers coronavirus. It is interesting that we did in touch high parameters parameters, it was set default and we used in this experimental, it is important metric that can be used for security all process problems and we can control how had has had been"
  },
  {
    "startTime": "00:50:04",
    "text": "that. And as you can see, we've had close base data. Without an information. Base features, no. I says no port numbers, no private, and they and new work on this one. And I would like to show you results. Here we have we can see fermentation charts I have to explain This one. Diamonds represent through results. It's it's can be seen. Then in first column, without when we have data set out, and they just without miss Lovers. We have quite good for good performance. And here, you can see of performance after presentation. We have hundred points for every classifier. And black points means that the results after the presentation do what's better? Done before. Than before. And we can compare this with results on dataset with we can see more black points. It it it means that in more cases we observed here but there was results after rotation done before. It is signal that something is wrong in the relationship it between data and labels and for labels we see much more black ones. And we also can calculate the slope of points because the higher quality of data said. Slow."
  },
  {
    "startTime": "00:52:01",
    "text": "It is pushed and the slope is based on the regression line. And intercept is taken by from the all sets calculated for each class and Maximum is is the slow. The same information is reflected in P tables, we can see a lot a lot of red numbers, it means that in these case, We had p values bigger done point zero one because here we set alpha that one zero one. And as you can see, in each case with mis lab data we had non results for one, two, five, ten twenty five labels. But for original, and datasets. We can see that we can say that these data are good because we have some classifiers fires po one classifier for twenty thousand observation data. Is is performance. It means that we can say that this and this data is is okay. It's good quality. It is interesting because here you can see through results. And for all classifiers, for original data set, we have hundred percent even if some classifier detected that some problem some problem in the relationship between x block and why. And in second column with a five percent of like labels. We can see high results also, but we know add without our methods, it will be impossible. Directly say that this is introduced because we we did change the change of"
  },
  {
    "startTime": "00:54:02",
    "text": "labels from the one from and from one to z or five percent of miss labels. And we often see these results in research Papers And often, we we are not able to explain why these results is not one, for example, This method can help you check the the problem in a relationship between x No y. And here, for ten thousand percent of these lives, We can also see quite high results. And as I told you before we can also analyze slopes. It is color in order to evaluate data with numbers and worse data said the lower value of for each case. Per of course, doesn't detect all data problems. We are still not able check if think us and call a whole problem. We need data for these method. Possibilities of classifiers. We have different classifiers and we cannot control how and they work. And also we have to with computational costs. Because if we repeat, times. In case on this method, we have many iterations. We have to wait longer for results. But if we want to obtain good information in the end, it is worth waiting my we really need high quality data sets and I think that there is the strong need to have cooperation between researchers and"
  },
  {
    "startTime": "00:56:00",
    "text": "the industry in order to go further. Sweet cable assessment of and then data quality is critical. For building reliable high quality models. If we want to if we want to have numbers, useful model that can be put into real networks. And four methods in the dataset and quite the office process, but is not no method which so and a problem in may. Thank you very much. If you have any questions, please let me know. You can also me of presentation. If you have a feedback comments everything what Thank you, Kat. Very interesting presentation. Do we have questions enough presentation. Okay. We allow the exception diego ago. Thank you. Hello good good afternoon for for us. Good morning for, I guess. The is the the T there was a presentation of a tool that this called probably here that was arising as well. How what not exactly the same because it's not about the data sets per say, But if Remember world, they were analyzing the way which the learn models also how biased by the by the data. This this is... I mean, looking at it it looks like the both approaches are quite quite complementary. Are you aware of these do you have any idea? I don't see After in the room is. Well anyway. Yeah. So Well,"
  },
  {
    "startTime": "00:58:03",
    "text": "Maybe to give the context to Catalina. I mean, in in a previous session in the test meeting there was another paper presented by Austria, which is also in their room here presenting framework for on transfer of of Ai models. Which as Mentioned, there is a bit of complimentary between the two approach I think he is pointing to that. But Yeah. Yeah no. No. Do you want to phrase the question to cut know it's more like... Yes. Know. I mean it's it's a business precise about whether she she sees that there is So so, kind of evolution of all these tools to assess and we were talking about this assess how data could be made could be made available in a room which they could be used for basic collect models evaluating models etcetera. Because these this per quarter currently is a tool that is, let's say, isolated and focused on whatever the data sets. Right? Is is that my? Yeah. This could be part of a mechanism for a on how metadata on the meter say on the datasets around they are usability or or whatever? It is difficult question because it is focused particularly on the on the relationship between reservations and labels. This is this is the the clue of this method. But unfortunately, I didn't see previous session, and I have or really but... I I I believe that this is very important for check it but back... Course maybe, yes it can be complement. Thank you. We I mean, there room, maybe you can make a comment out. We have short on time, but what I will invite is that"
  },
  {
    "startTime": "01:00:03",
    "text": "this topic is of importance to the research group we we're planning any way to invite for further discussion. So Please after make comment, we will close the discussion after that, but we will invite for follow ups on this. Yes. Yes. Thank you. Thank you for joining for the presentation. Really interesting work. Commenting on the previous question. I do think that the approaches are complementary and can be used together special, because the our approach looks a lot into the not direct between the correlations between x and my as your what does, but a lot more on the how each how the x affects the y. In in the classification process. No problem. One question I did have about your work is that you seem to look at the direct correlations between X and why and and in your assumption is that if the performance worsen after the perm presentation, then you had a good correlation between x and y, and then you that means that the data is good. Did you taking into consideration the dimensional of x, I'm I'm I'm I'm thinking if a lot of different features on x might be a lot of different spur correlations that data that the the the the models might still pick up after perm the y labels. You look into that or was that a factor of your situation? Thank you for your question. Not yet. Not yet, but we realized that we have to check it, but it is very interesting for ex block. Of course, it is more complicated than and positions in y only Yes. Yes. I'm I'm totally agree. I have to work on it also. Yeah. Okay. Thank you. Okay. I see that we have Marco in the queue, will leave the floor to Marco to"
  },
  {
    "startTime": "01:02:00",
    "text": "ask him the last question, then we have to move on. Thank you. Thank you very much. Marco swiss So when you have a classifier you're, basically, you are measuring the correlation between X and y. Right? So if you make a perm presentation, which it's basically a random change. Right. You are losing the correlation. So I would say that if you have a high for example, recall for example, in your example. Sorry. Is zero point ninety five. I would say that that data as high correlation and if you make a rotation, you have lower correlation so lower record. For example. So doesn't make mean that if you have good results in your classifier year, the data site is also good. Because you have high correlation, This is the problem that if we have zero point ninety five. We we don't know why. We don't know why we have this because because if we have problems with correlation between y and x it is only one reason for for the for reason result. We we can have other problems in data. The let's perfect performance results. It is only one is only one. Because we... First, I I showed high quality data sets and just you saw hundred percent or for detect. And based on these, we checked if we are able to detect miss labels. But if you have no perfect data set it is difficult to say that the problem sliding on the a relationship between x and y. I see. Thank you."
  },
  {
    "startTime": "01:04:00",
    "text": "Thank you very much. Thanks again, Kate for your presentation. Thanks for the questions. We have to move to the next presentation, Diego, and if you can make it slightly shorter, it will be very appreciated. So basically, This is Yes. This is an introduction to to some work that we have started in Tele that is very much Well, it's connected with this work with is about trying to to enhance the way in we are moving around data to be applied in different and move on this So the idea, the Idea is to we we trying to to build a data fabric, a general data fabric four... Well, not only own, network for net management in general on the one on the one side, where we are very much focused right now on monitoring and how to read the different data sources on how to make the combination of this data in a way that can be useful for the different consumers, taking into account other things, This is not what represented here yet. We we are thinking about better representation of this because this area that you have here, we have been discussing with With other the people and it's not clear that source can become a consumer or schumer can become a source for in other cases. Well the idea that we are trying to go beyond what we have right now in terms of of monitoring with with jan, I'm trying to make an integration of those data with all data sources. And as I said,"
  },
  {
    "startTime": "01:06:01",
    "text": "using this as a platform for the collaboration of sources and consumers. For this, but we are trying to follow is this is the data fabric Part? Not right to produce, which is an abstract view of the of the data process And so facilitating the the integration of resources and new consumers the in the Fabric. For the the is that we we are following second gonna... Well, favor to the graph model for for employment implementing the the data relationships. No, please. So for this, I'm looking for something that is standard, we we found that that there is Ongoing standard that was created. Sometime I go for facilitating Iot interactions and for has being around for for a while. And the world... And and has been connected with with some people that were researching Tele as well, and the network part of an organization that is called the five foundation and this is A el. And nd is is the Ali is model for building this data fabric with the information model that this based is on on a level property graph and that can be with S semantic semantic information using the semantic web construct And as usual, serial as Jason because this was this is in from the days of of Json. Right? Now probably being see c, but it's from the days of Json and an Api, that's is a raised Api that provides information about the different context the different referring sc us that are being used, basically, and support properties that that is extremely interesting if you want to to"
  },
  {
    "startTime": "01:08:02",
    "text": "perform a a completing explanation of the data for sure, the make any for for queries and and subscriptions. And And well, it's it's a totally this this approach neutral. I guess that tourists speaking. This one, please. We are making a... We have started with with mapping from the different data nodes on the energy as in Gs model, basically, containers their entities and relationships and properties that belong to the entities of the relationships, And you well, this is the the initial mapping that we have earned with some notes because container basically, spontaneous I was basically lists in more cases and we are this all with something that has at least all something that is related to with another entity. The both of things is at the that we are trying to model certain leaves say some of the leaves specifically the leaves that I also say with that with with the reference with Ns initiated relationships, can you move on? As an example, here, you have that there is a but particular property there, which is the the the type of the interfaces example we can discuss about this if your interested the later on, but it is that certain, of these references are not just pointers are are model themselves. So we can reason about these references and we can provide something that is is extremely important for us. That is the relationship among the different sc, jan that we are working with. Move on, please. So... Well this is very fast this is about producing the different data stores that are now supported by jan. We have found on this was"
  },
  {
    "startTime": "01:10:04",
    "text": "part of of a long discussion on how we could model this there is a a a data Id featuring in in Gs you'll leave that allow us to to model this and At the same time, we believe that this it will allow us to model to support the idea that they how we can the digital twins collaborate using the the the the same data fabric. Move on, please. We are not working on a prototype just to two to experiment a little bit with the mechanism we have defined so far for the mapping. And currently, we are testing with the using Gen push and some cisco others that is the ones that we have found that support an Md mba we want to to focus on the translation aspects and not on the on the rest of things. And for example, today, I learned that the in the project Thomas has run away but here. In the there is a generator of them push this is something that we done to use, and probably we'll get the rid of the cisco for the moment. Not that we have anything against it But but we prefer to make the the people that work this focus on the translation process and not the in the data collection. Move. And well, these are the list of research challenges that we have identifies what is be sure that this translation and the transcription mechanisms that we have built general enough, we have focused so far in a few models we want to be sure that we... The the... That these transaction mechanisms are are complete. Is how we can go beyond on well to the other side. Mean, And considering other"
  },
  {
    "startTime": "01:12:01",
    "text": "consumers and sources of data and make the whole interaction in in the data Fabric, we have done so with prom use source about we want to go into something more a little bit more ambitious. Sure we want to align with this work on the Well, this gigantic native connection with Ka and the idea that some of the tools that we are currently using will be substitute by by the the the tools that that being developed developed now. And to start a direct collaboration with the group that is working on in Gs because all the things we have detected some details that will be desirable to twofold evolve. The the last part which is equally important for us is that we want to It's a it's a phone's data fabric. We're not talking only about monitoring, but we want to address as well controlling. The other half of the control loop is something that we want to model as soon as we can. And that's Thank you. Okay. Thanks Diego for being quick. We have pedro in the queue. Other have question pedro? Yes sir can you hear me? Yeah. This pedro will be short because we still... I would be let me maybe very short. And you work I saw that in the prototype, you building on so that you have a streamlined in the connection between the let's say device, the translator and then the broker and then then. Why not connect all to their vas. Remember the work we you can't translate and feed to device etcetera. You can do all hard or within the last why not Do you know it so for thing it to to to to to help you here in person george should be close to. I I had I had a but particular are Nothing nothing because Lorraine is going to complain that we are talking about not."
  },
  {
    "startTime": "01:14:02",
    "text": "No. The idea this was to illustrate the fact that the translator was right to the to the broker. Using the the best for communicating them for sure something is something that is... Well in fact in the current would say that in the current implementation, the broker is connected to the bus. So it's simply to show that there is a translation. No. I understand Thank you. Okay. Thank you. We have to move on for fairness to the other presenters. Thank you. Thank you, Diego. Chris for the performance digital twin? Hello. Good afternoon. So this is... And you can jump. To the next slide. This is a companion to jody pace draft presented in two iterations over the last two meetings. On so called performance oriented digital twins. First, I'll do a brief recap of of what that is. I'll get fairly quickly into the idea that the mapping of these twins to consuming applications or use cases is not unique. It's one to many. That gets into the idea of managing concurrent datasets and computing sessions with these twins. I'll talk about that. The real world aspect of dealing with variable networks that is equipment composition available instrumentation and, of course, the the whole usage of these things is to explore at least partly hypothetical scenarios, so that introduces variability as well. I'll talk a bit about performance engineering really the way to think of this is some walk through at real implementations and less"
  },
  {
    "startTime": "01:16:00",
    "text": "since learned and hopefully the idea to sort of expand on understanding of the the context And the concept. Okay. Next, please. So the just to recall from the draft from the last two meetings. The idea is that this version if you like the digital twin is is an analytical function or application. So mean... And, of course, it's it's a replica of the network, but it's not just a static copy or photograph it's there to emulate behaviors. Of the real network. Right? So something is saying in this scenario, I want aspects of predicted performance of the real network. A large part of that scenario definition it is a twin will come from the state status composition instrumentation of the network as it stands. But, of course, it's what if scenarios to at least part generally at least part of what's being presented is hypothetical. Okay. And I'll talk about models that are inside that's a little bit later. Now, of course next slide, the digital twin architecture draft paint some more expensive picture of the function of a digital twin, but a way to consider that is you've got this kind of analytical function inside. And then you're completing that with what amounts to other management functions you have at least a closed loop based on the analysis provided by the the twin or the performance oriented view of the twin Obviously, when you're going from intent inputs all the way to control outputs, there's a lot going on. In this work that's referred to as a flavor of a... If you like active digital twin bidirectional directional syncing digital twin. But next slide, please. Another way to look at that collective thing is"
  },
  {
    "startTime": "01:18:01",
    "text": "it's a management plane or management and control system. Right? And then that context said borrow language from Etsy that. For example, the P is a management function that provides management service. It's an analytical one. There consuming applications of the information that provides Generally, they're providing scenarios they're trying to find some optimized scenario based on the answers conclude some kind of action to result. The thing I wanna stress here is that you can have in a realistic management system, you can have multiple twins of this kind. But in general, you're going to have multiple processes think functions that are using interrogating this digital when operating concurrently. Next slide. And one illustration of that, I'll focus on the flavor of performance oriented swim that we brought in in the last meeting as the first revision of the the pi draft, and that's the so called optical performance digital twin the function of this one, we have an optical transmission network and the predictions of performance that were after our optical transmission performed So basically, what's coming out is in this given scenario of network channel optical channel, service configuration, etcetera, what are going to be the result in Channel powers noises and especially margins. How well are they going work from a transmission? Perspective. And again, the two incoming arrows, these are basically this is basically the input data. It's just meant to reflect that at bottom there are two sources. There is the data from the twin. And there's whatever you're substituting or complementing to define the what if scenario that you seeking to emulate. Okay. Next. Now in the in that draft, we said, look, there are a lot of use cases and therefore related management applications that will work with this thing, covering a wide range of"
  },
  {
    "startTime": "01:20:02",
    "text": "operations automation or optimization on the optical network. So the the one at the top, this is if I wanna do channel drop rewrote basically, I wanna find a formula of powers batch sequencing of operations that's going to give me operational integrity. I'm not gonna drop continuing channels. They're not gonna fall out of of margin spec. I'm gonna bring everything up in a way that it works. Risk mapping if you know, I simulate some faults and I look at the unaffected optical channels. Will this still work in the current condition of the network. My restoration map will it work. Right? And if not, I can point to some you know, renewed restoration planning. And then we get into service planning, network planning, And these things all have some degree of embedded optimizations so repeated interrogation based on a hypothesis performance information returned decisions made leading to action. Next slide. The thing to note is that what distinguishes these applications is not the information coming out of the twin. And to first order, it's not the functional models that are involved. It's the scenarios presented for assessment that are different. Right? So you get into this idea that, you know, it's many to one, a single twin which is supporting the concurrent function and that sequentially presented requests in large numbers from single application use cases. So how do we deal with that next slide, please? And and of course one of the key differences among these scenarios is what's real data reflected from the twin and what's part of the hypothetical scenario. Right? So if we start with our provisioning optimization, then obviously, the network is as it is. Right? We're only"
  },
  {
    "startTime": "01:22:00",
    "text": "changing channel configuration. There are existing optical channels that we are not touching but we're adding and dropping others and optimizing their powers and the sequence in which we do things. If we go to network planning, right? We're playing with not only the mapping of optical channels to the network. But to some degree we're playing with the composition of the network. If it's brown field or incremental planning, we've got existing network that's reflected by data from the twin and then we're adding others. If it's greenfield, it's all hypothetical. Right? So you get this this mix. Slide, please. And I don't see the clock so on kinda weighing in it here. So obviously you get into this notion have you've got concurrent sessions that you need to operate rate with several implications one it's life cycle. Right? Every one of these operations from each one of these applications has has a life cycle that's driven by the consuming application. It can be a one off computation or in fact that can be a continuing a continuing computation yielding changes in the answer depending on changes in the data from the Twins network. Model composition. Right? So I mean, with each difference in scenario, we're going to construct what amounts to a different model from the atomic pieces, there may be considerations of computational order. Where the data comes from some of the data maybe real data from the network or or present today prior alright? Others may the result of partial modeling. Right? There may a sequence of modeling steps. And, of course, the data itself At root, we have this master data from the real network, and that has to continue to evolve it has to be available to all of these applications, but it has to remain un by all of these scenario based presentations of data for calculation. Okay. Next slide."
  },
  {
    "startTime": "01:24:04",
    "text": "And here's some schematics from our own implementation you know, a few things that you see Obviously, you've got tricks like you know, we have session ids attached to each computations so we can track what's associated with what. On the data management side, well we have to figure out the depending on the answers that you know, the the characteristics of this scenario presented, we have to figure out a sequence of calculations using the models therefore where we start with the data and we decompose this into sequential operations. The the so called real time data there, that's the twin data. So from this perspective, it's read only. There's other things that can write that. But not these computations. Different levels of the computational sessions. Will create certain data that's selectively now available to the sort of superior sessions. And obviously, these parallel sessions if you can do that within a single computation for a single application. This just maps generally to concurrent support of many applications. Next, please. Just a little bit more this idea of network variability So, you know, first of all, from both the real network that you're twin to and then differences driven by the scenarios you're considering driven by the use cases. There's going to be variability. You're gonna have different equipment types you may or may not have specific models for them. Depending on whether you've got a piece of equipment in the real network, you may have an instant instance specific model or at least a type specific model. If it's purely hypothetical, the best you're gonna have is the type specific model. You might have a generic sort of functional model that you have to use. Similarly for data,"
  },
  {
    "startTime": "01:26:02",
    "text": "There's going to be differences and for example, instrumentation on the optical net work we may have different types of points of power measurement, channel power measurements. What we'd really like is to have ubiquitous direct measurements of optical to noise ratios. Right? The better instrumentation we have the less modeling we have to do and the better answers we're gonna have. But we can always flexibly use modeling with available instrumentation and to get at the answers we want. Right? If we have power measurements, we can use modeling to get to our noise signal to noise ratio from there we can get to margins. Right? So this also gets the the idea that, you know, there's there's a clear sort of source of information preference hierarchy. That we build in. And also the quality of data builds over time. And that that with operational experience if you like, and that's going to improve the the quality of of predictions. So because we we have to move to the conclusion. Yes. Okay. Yeah. Sorry. It would been helpful to have the clock up. Just the last slide, obviously, for performance, if there's a lot of these things going on single applications could present you know, a sequence of many computations think of an optimization. So obviously, performance is going be an issue. You wanna use all the usual tricks in addition to the data management and the the workflow management and linkage issues But, of course, the models can in fact useful be on the network elements themselves. Right? Because they've direct access to their own data. And they may in fact be a logical home for instance specific models. Obviously those need to be federated at the collective level, but that that is an architectural possibility. Okay. That's it. Thank you, Chris. So for being short on time, we have to move on to give at least a few minutes back to Alex. Thank you."
  },
  {
    "startTime": "01:28:14",
    "text": "You. Basically almost a a lot of time. How much time do I have? I mean, you have the remaining time for the end of session that that that we can that good people. Maybe try to cut it from ten to three. So... Okay. So this is update on the challenges and opportunities in green networking, Next month, please. We because we presented on this one actually before in this in an here. The purpose again is analyzing challenges and opportunities in green, sustainable carbon neutral and support networking as this is one of man kind challenges and actually it attracts increasing attention and also here. At. We presented an earlier version of this before here, Next one, please. There been various enhancement refinements addition actually, the document has gone significantly. We don't have time actually to talk about the details. Maybe go to the to the next slides. I don't know how much time we have. It can probably... We probably need to skip across this. Please take a look at the document I should also mention tomorrow, there is going to be a side meeting on environmental impact in networking, we will talk about this from there as well if your interested in this topic, please come there, We will help a little bit more time to discuss these things there. But as far as is concerned, you move on to the next one, next one? So one thing to mention here is There were two drafts. Actually, one is the probe statement and challenges. Challenges and opportunities. The other one are green metrics there's a companion draft"
  },
  {
    "startTime": "01:30:03",
    "text": "we presented green metrics in Ops Aw that the dramatic stuff is probably closer to standardization. So less of a research topic than this chinese and opportunities therefore, basically, the proposal of the request is basically to to bring the green metrics graph to W g and actually where we were accepted there and have the challenges opportunities for green have bet be here and does have that be adopted by by N this is actually really... I believe where it belongs, and this is basically what I wanted to just put out there for the discussion. And sorry that we had to keep it so short I think this is the main point. That that I got to make that that pointed of perhaps requesting feedback on that well from the chairs and put also on the on the mailing list. Thank you. So the session is officially over, but if you want we can still get some comments. To Alex or the draft on the way forward for the problem statement and challenges and opportunities the location to the end and he comment on that If not, yes. That there there will be a side meeting dedicated to environmental impact tomorrow. I think it's such Once tomorrow at one one Pm, you can fight it on the side meeting wiki. Of the Atf one sixteen website. And so thank you everyone for the attendance to to the session. Thanks presenters on and remote apologies to the last two presenters for getting short on the presentation. We invite you also to share comments questions and our discussion on the mailing list. This is the central place for discussion of the research Group. On the topics we have done today, we have follow ups So the Ai challenge is distributed Ai. That's quality that I set as"
  },
  {
    "startTime": "01:32:00",
    "text": "future positioning or digital tweeting, there is group and green Networking all of those will be subject to specific communication to the research group to organize how we want to approach this research questions in the research group. So please stay tuned on the list and we be in invitation for kind of follow meetings on an adult basis. Thank you everyone. Have a good day good rest of the week."
  }
]
