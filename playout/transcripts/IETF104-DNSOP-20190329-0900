[
  {
    "startTime": "00:00:10",
    "text": "[Music] good morning everybody Warren has started the blue sheets and their journey around the room will be starting the session in a couple of minutes waiting for a few more people to find their way and thanks [Music] [Applause] Oh [Applause] [Applause] [Music] [Music] [Music] "
  },
  {
    "startTime": "00:03:36",
    "text": "[Music] good morning everyone Venus up session 2 this week let\u0027s stand the procedure here I\u0027m Beto Susanne over there Timmy\u0027s in the room these are the chairs Warren our ad then is our jabber for this for this morning\u0027s session and so sorry Paul yeah excellent thank you Paul is the scribe or sodium in yeah the minutes make minutes taker please state your name at the microphone show your tag to Paul if you ask for get the note well take care of that everybody notes the note well blue sheets please fill in the blue sheets it\u0027s a good crowd we didn\u0027t want to have this kind of size ball but a little bit we could do with half of the size of the room but we definitely want large rooms next time again so fill in the blue sheets agenda for today normally Tim takes care of the nice pictures I was not that inspired to I do the towing car so we one thing we people say well you bring too much work into the working group so going into the working group but also we want to move further with the a name we added yesterday actually yeah on the agenda and move it again ahead so this is the team towing car New York this session primarily is about new work so there\u0027s four presentations two presentations on new work three days for new work one presentation by Steven about other working group activities outside the Dean is up but should be mentioned over here our work is on data tracker and on github so we try to be as transparent as possible please talk to us if we aren\u0027t some other thing I should mention I was told me but actually I should have done come to the conclusion myself is there was yesterday there was an pump award and some of our colleagues in the room and it was the best data set award on cue name minimization collection and short message is nothing to worry all good so cue name is great it\u0027s good for the working group to know that we are doing work that makes sense here I think this is the agenda so long data tracker I don\u0027t have to go through the different items here we end with the a name discussion we have five minutes I think "
  },
  {
    "startTime": "00:06:38",
    "text": "we can get started Giovanni can you thank you any other questions about agenda actually we call it agenda restructuring No okay thank you is the clicker I will switch slides in not in a minute that\u0027s in couple six so good my name Freddy thanks for being here so early this morning last day of ATF if they try to keep all these des folks for the last day you have two sessions today right so here we go first time you presented this raft here I had ITF version of a tree already this is an information or draft oh yeah here I had put here the list the links for the versions I had sent to the lace over there responses are not we are doing this draft on a github and also that the NS all chairs have asked us to try to get feedback from other sources or other operators and I did that and there\u0027s a link there for the discussion or at least alright so this dress it\u0027s like a product of work of 13 researchers that have been doing we have been doing a bunch of research breakers on DNS over the last three four years and what we have done is get those papers try to find recommendations gather recommendations for operators DNS operators there were like four IMC papers one pem which is the conference it just happened by the way but that papers are here um the problem with papers for operators are they tend to be long it take a lot of time and I see that that in L folks at the side the end they like the papers but sometimes they don\u0027t have the time to read that so our idea is to get this papers put it on a list iterate through the list and apply at T to longer to read write a filter on that and just bring the recommendations so that\u0027s exactly what the ops folks ask and accompany it sida knows all right let\u0027s do this try to have tangible direct recommendations and if those recommendations are backed by measurements so if you want to know why we pointed to the papers there so the target group here is large authoritative DNS operators with global traffic um like I have my own personal domain I don\u0027t need to follow the recommendations on this raft for my domain that gets no traffic at all so this is the recommendations in a nutshell we have six of those here and these are the reference papers here you know be going through each of them now the first recommendation states that you should use equally strong IP anycast in every authoritative server that means NS record by the way to achieve the like start over even loads of distribution so the recommendation derives from the fact that a resolver we did a measurement paper on that and if you have for a certain zone four five whatever authoritative nameservers and s records resource you get to choose which one "
  },
  {
    "startTime": "00:09:38",
    "text": "they\u0027re going to send the queerest you but they\u0027re gonna send queries to all of them in regardless of the round-trip time between the resolver and l2 rotative closer resolvers would get more traffic so for ops that means that all right so if you have like multiple rotators you have taught my sort all of them they all have to deliver good laters for a global clients and by definition unicast can\u0027t do that a site a client in California we always have longer latency to alter it a unicast server located in Europe or Japan because it\u0027s a graphical distance so this original paper recommendation number one recommended using any casting I was rated nameservers all your NS records and have like strongly and strongly here in the cast means like in terms of peering and capacity and phase out unicast and we have that lie that not me my colleagues as operations team that I know they have deployed that we used to have seven or 82 name servers a mix of any cast and in the cast and now have only for any case um recommendation member to routing can matter more the location so this is the case when folks are gonna hire or engineer alternative name servers and if there\u0027s also sort of assumption that if you have more sites more instance more locations you\u0027re gonna have lower latency so paper number two he or show that\u0027s not always the case this was as analysis that they have done with right passes and they measure the median latency to different route server ladders and you see the size of those deployments like air route has 144 sites around later instances around the time and see Ruth had eight and they\u0027ll deliver similar median latest values between 30 and 32 milliseconds for all this right headless probes so in other words when choosing that you have to be careful not only considering number of sites but also the peering in location where they actually located and why this happens because BGP is agnostic your geographical distance so the recommendation on virtual here suggests that you should consider route a net current connectivity also when engineering DNS any can\u0027t services they\u0027ve also found that web sites that is good an offer global latency but if you really want to have more change in here for DDoS attacks recommendation number tree this refers to fir filter and refers to collecting any cast the tyranny cast catchment Maps ahead of actual deployment can improve engineering designs so let\u0027s say you have run one authoritative nameserver with five instances you want a one at the new site in LAX you it\u0027s very hard to know what\u0027s gonna happen with this traffic how your traffic\u0027s gonna shift once you\u0027ve announced the new site in Los Angeles for example so one way to do it go about that use a recommendation or headless paper paper number tree the elders have developed I was not going to study when the Khalid\u0027s were to use for if little it\u0027s a ICMP "
  },
  {
    "startTime": "00:12:39",
    "text": "based tool that maps the catchments on a direct I\u0027m sorry I don\u0027t have the time to work over all the things here but you can ever even use that before deployment in a new perfect that are you gonna deploy any caste or on prefix study announced for the same locations but not in your production network and you can actually predict the catchment and the curio distribution they run that on be Route one be route went from unicast to any cash that it predict very precisely how would be the load query distribution to the la excite it can see that were on a 1.6 was predicted 81.4 was a little depth of the surgeon percentage in LAX and this tool has been deployed on any cast that\u0027s bad there\u0027s a testbed that we have a bunch of tests they\u0027re a bit route and a large an operator as well I like recommendation over for when under stress there we should recommend is to employ two strategies so let\u0027s say here you have your your any cat your any cast name server with this sides here those locations actually and there\u0027s a DDoS attack so what\u0027s gonna happen that BGP is gonna map this attack which are like IP addresses to different sites and let\u0027s see BGP will give you the distribution you kind of have no control over that the depends on the BGP map in your upstream provider the client source of attacks and in this particular example here one thing you can do it\u0027s if you\u0027re LAX sites is big enough you can say well let this one burn let\u0027s run try to handle the traffic and the other clients of here are gonna be fine so one strategy during the doors didn\u0027t often Laurette lax site which is taking 50% of the attack became a degraded absorber clients going they\u0027re probably gonna have problems trying to get an answer but the others are gonna be fine another thing you can do is do a bunch of manipulations on routing you can like prep and routes withdraw routes inácio sites which be black holding in an attempt to chip the traffic into a distribution of queries that matches your capacity your sights your locations and Vegas the best option depends on attack itself and your infrastructure specifics as well so so that\u0027s the that\u0027s the summary so two strategies either do nothing allow the website to play and become like absorber or withdrawal and try to ship the traffic what should have a new project working specifically on that to try to figure out how we can actually do this better details we recommendation number five suggests you should consider using longer TTL values for NS record for DNS records whenever possible details they said like term limits or how long queries should remain in resolvers cache it\u0027s a sort of a ephemeral replication for those on file anyway study number five immolates DDoS attacks with various different packet losses we gotta use IP tables to drop packets of those losses and this figure here shows blue here our clients get an answer and "
  },
  {
    "startTime": "00:15:40",
    "text": "the arrow going down around ten before ten seconds ten minutes here shows when the immolated DDoS attack started and you see here that this are phased at all the cash was working if you would get an answer you cannot get from the authority to service anymore because you wrote down for this experiment and you see here people get an answer from the cache but once the cache expires nobody gets an answer although like people who had served stale so cash is very important it\u0027s a key component of DNS resilience and TTL is highly correlated to that you their choices have the power to say how long it\u0027s gonna be in the cache there for how long clients can resolve the domain in the unlikely event or the event of unavailability of this authoritative servers so caching is a key component resolver will do their job trying to resolve the domain they gonna try to switch from server to server even if that means like hammer doctor tape service even under those effects so recommendation number five is like use longer details whenever possible but of course there\u0027s no one-size-fits-all solution here we\u0027re actually working on a new measurement paper for the next conference and measurement conference and that exactly works on try to figure out a better way you recommend details all right recommendation number six sure infrastructure risks collateral damage during attacks so you gotta be careful when engineering DNS services colocation implies you share some parts of the infrastructure and this study number four we found that when the routes were attacked back in 2015 some Danelle sites co-located or they had some sort of a share infrastructure they also suffer observe higher rates of packet loss under NL even though that I know was not attacked and the dine took all the 16 attacks show similar results multiple zones were partially reachable when these NS were attacked so the conclusion the recommendations I you gotta be aware of share infrastructure risks like if you share for structure you\u0027re gonna be running at risk of course there\u0027s a economics in here and involve this well sharing is cheaper usually but it gotta be aware of that so that\u0027s what I have to say here\u0027s a list of recommendations I would like to thank all the reviewers and I\u0027ll be happy to take any questions in hi George Michaelson I pay my could you please go back to slide 8 yeah 8,000 doubtless Propst is basically most of the Atlas network isn\u0027t it yes X only so this is not this is not a distance equalized distribution of probes 5,000 of those probes are in Europe 5,000 of those probes are one hop from DC D kicks or m6 or links where there will be any caste instances of these routes so in the statistical distribution of the average latency the rtt most of the european nodes are low RTT from a route but if you are in South America or Japan "
  },
  {
    "startTime": "00:18:40",
    "text": "or Korea or Africa these figures would not happen I don\u0027t think statistically your median RTT figure matches the reality of the different distributions of these routes um so yeah thanks for coming I was not personally involved in the study some of my co-authors were so this is right Adler\u0027s in life I\u0027m not sure which year Duran that but we all know their rap has some sort of bias towards here that\u0027s a fact right but you\u0027re using this as a justification for routing over location density and notes and saying there\u0027s an equivalence between their distribution I don\u0027t think this is possible I okay Wes so sorry co-author Wes her - karai\u0027s I am real quick point that I think we could get into the technical details of each of the studies in here and I think from the perspective of today it would be best to decide two things one as the draft worth you know pushing forward in the idea and - right which academic papers are worth you know like keeping in the draft as a recommendation and maybe we throw some out maybe somebody has some more that we can add in this was an academic peer-reviewed paper so you know there could have a whole discussion on the merits of the paper but I think that\u0027s out of scope does that make sense but but not want to get in it\u0027s perfectly in scope yeah I agree it\u0027s a chair I think this discussion is very good bring the operations also well read the documents give feedback - gee oh yeah thanks lastly Minette note the second operator to employ and it costs more than fifteen years ago I my first questions be what\u0027s your what\u0027s your plan future for this document what would you like to see it become so this is information a draft if you gets a toughest to the working group or black to become a recommendation RFC yeah recommendation as lawyers for our etiquette service operator system uh but our informational is the goal not BCP no no I I like the things that you observe in this document but I would very very strongly recommend against calling them recommendations observations fine suggestions so things to think about fine don\u0027t make them recommendations because there are so many different things going on out there on the network but if you start to recommend things going in one direction document that carries the stab RFC you will shift the entire DNS business into going that way because the customers will point to this document say we must have this and when you do that you carry you take away all the diversity that we have today and that diversity is a very good balance I\u0027m somewhat diversity the comparison you did between unique arts and any cost because I think there\u0027s lots of stuff in there but you make correct observations but I\u0027m very averse "
  },
  {
    "startTime": "00:21:41",
    "text": "to calling them or to shift that into recommendations so if you if you change the entire tone of the document into these are things we have observed observed and these are things you need to think about when you when you deal with in the relationship with any cost operators and so on I would happily support it but but in the current tone that you have I will not support this document all right thanks for your feedback I think observation what we do so our idea for this document it\u0027s like in the papers you observe a bunch of behaviors and we wrote in the papers recommendations derived from those observations each of them they are backed by large-scale management so I think it would be I\u0027m not I\u0027m not positive I\u0027m not so sure about changes term because well they\u0027re observationally papers themselves but yeah I can have a discussion about that what you\u0027re doing is that your recommendations and these are five people recommendation to the entire DNS community I\u0027m sorry the idea from the RFC stuff on that and I\u0027m sorry I\u0027m not buying into that oh yeah that\u0027s that\u0027s fine but do we have data you have papers that would write and recommend you to read the paper soon yeah but I don\u0027t want people to do it in one and the same way no I\u0027m sorry multiple parts and I want this to be observations on things that that playing the role of thank you in violent agreement let me know I think I think we\u0027re gonna close the queue after Peter I think that\u0027s a valid thing I do think that we need to take that back and think about it I I don\u0027t think observation is the right word either but let\u0027s not wordsmith now all right I find that I\u0027m Stephan BOTS mayor however hat I walk for ccTLD operator I already told you that it was a great research or thank you for everything on the recommendations advice so yes mmm-hmm etc one concern is I think it was already recorded as an issue on your draft it\u0027s not for ulcerative or nameserver operators it\u0027s all very big also it is named several operator so people may not exactly the title on the introduction of the draft today it does not reflect this so people who manage a small zone or not so small actually may don\u0027t see what\u0027s the point I\u0027m and for these peoples are a lot of recommendation - such as several DNS providers no Smurfette cetera so I suggest that a title on presentation of the draft that could make clear that the scope is much more novel yeah so you\u0027re right you know when I first made a first version we one of the most of the comments we got was like "
  },
  {
    "startTime": "00:24:41",
    "text": "can you specify what\u0027s your target audience so we did that in a document but we did not reflect that in the title so I should of that Thanks very observation hello play different like powerdine you can actually slide 13 yeah yes so it\u0027s obvious that at the beginning you have on the present - dinner after an hour ef-0 but the distribution over that I will look very weird to me would expect a sharper drop off explain that so hang on so exactly like as 30 minutes I would expect it to be closer to half so this is the this experiment you had a TTL of one hour so allow all the probes on resolvers to run send the first queries with no problems at all and then at time equals to 9 we start to drop one out of the packets ok so you started to draw pretty quickly after getting yeah yeah get into the cache there are many more expressing a paper we vary when instructure drop in about the details but it was just the easiest to show here and what happens is like here you see like this is the time that the TTI was still valid and then just see like here a lot of people start to expired and did here everybody expired except for those who serve stale content right so in the rural situation you would see more records go away earlier if you would sit in the the function as well might have been in cache for longer and yes sick starts yeah so thus resilience of being in regardless to cache depends when the actual record was fetched in order this ETL if that\u0027s what you mean yes perfect yeah absolutely Joe a bleep IR I like the idea this and I\u0027ve actually read for these papers oh thanks which is surprising but so I\u0027ve got a couple of observations though one of them is that none of this that these papers taken as a group are really about any caste not about the DMS I mean I know that they have measurement they used services that are deployed using any caste in order to make measurements and those happen to be DNS services but the papers themselves are not really about the DNS with the possible exception of this TTL one but to be honest this is one I haven\u0027t read and perhaps I won\u0027t because it seems to say that when things expire they expire which I think you know just hang on hang on a sec so if we think of it as just an any caste collection of papers and appreciating this a nice idea to take these academic insights and actually produce them something operational from them the problem that I have with this draft aside from the topic matter is that I think the papers I\u0027ve read had quite nuanced and subtle conclusions that worked very very carefully framed they didn\u0027t make general observations across the entire system because there are some good papers and they made very specific observations that you have to understand in the context of the measurement they didn\u0027t make very broad claims however this document does make very broad claims and I think you\u0027re trying you\u0027ve drawn recommendations that are overly broad given the justification of the measurement and I don\u0027t think it\u0027s it\u0027s sensible to say this recommendation advise suggestion whatever is justifiable because there "
  },
  {
    "startTime": "00:27:42",
    "text": "was measurement if you look at the measurement the measurements actually it looking at something very very narrow I think you have to be very careful about taking and I say this is somebody used to play Tony cast a few times and I know that it\u0027s a lot more complicated than you can summarize in six recommendations um yeah thanks for your feedback I mean of course there\u0027s a lot of details in here if this was more like a literature review of any cars related stuff published to a rounding audience about academic insights into into any class routing I think that would be a lot it would be a lot easier to understand what the draft was for because as it stands I don\u0027t it\u0027s not that I just disagree with the word recommendation I think whatever you call it these are too broad and and you\u0027re presenting them as something that is true across the board and it\u0027s other than that\u0027s right um I think it is well yeah I think you\u0027ve got a good high level discussion going but I think the drilling down in the details that\u0027s good feedback for you but also drilling down in the details can go to the list or another bar although it\u0027s all boil away for that later Cody Nick I am one of the many extra fishy Oh historians of the working group well I hate to do this but 15 years ago so Alicia Jean and her team had had a draft out on TTLs and they came based on an academic paper peer-reviewed and so on and so forth came basically to a similar conclusion that you presented here it turned out that the working group couldn\u0027t agree on this because there are multiple considerations that kick in when it comes to to TTLs in particular so if at all I I recommend in that case to drop this topic from from the list of issues that you cover in the document because for example in the previous session we had someone having good reasons maybe to argue for shorter details in certain circumstances that said TTLs are not necessarily consideration for authoritative server operators they are considerations for people designing the content that is zone maintenance then that might be a different audience however what Lehmann said what Joe said I\u0027m all in favor of making these economic papers accessible more accessible to operators by way of literature survey like like Joe said but I also don\u0027t fully agree that the papers should result in recommendations the observations and that for that matter the selection of papers could benefit for a bit more diversity in contributors compared to what we have today so different opinions would be yeah we\u0027ll be going to get the full spectrum second okay thank you thank you yeah thank you do so so the action point for us or for the working "
  },
  {
    "startTime": "00:30:43",
    "text": "group was called is it ready is it should we go for a call for adoption I think first we should go for more discussion on the mailing list there\u0027s interest in this subject but the opinions are yeah well we need some discussion on the mailing list and then we go further thank you yeah I\u0027d like to thank everybody for the feedback and for reading his draft thanks a lot we had a we had you didn\u0027t hit a social justice in this idea but this is how many people will feel like in the regular social maybe in the morning yeah okay please go ahead yes this is how everyone feels by Friday morning so Dina\u0027s cookies are a measurement against amplification text the the current we\u0027re a botnet is used to let bot sense a small query to a name server which would result in a large answer because there are source IP addresses are spoofed and the source IP address is the IP address of the victim victim you look at other large answers so the cookies are there to sit have a relationship between a query sender and a creative II player and to make it work both so I\u0027ll part everything needs to do the Venus cookies you cannot have one our tortoise sheriffing in a set of authority surface not doing Dena\u0027s cookies and also the solver needs to do Dena\u0027s cookies to benefit from this and so not even the cooperation is desirable so this is I just described it basically client a query sending name server which is usually a resolver since creates a client cookie from the IP address of itself and the IP address of the server at selling to the name serve thee out Dorsetshire firm actually derives from the client cookie antique light IP address and some secrets the surfer cookie returns that to the client and then next time the client sends along the surfer cookie with its client cookie and the server can recognize its own cookie because it can recalculate its from the clients and then when it receives a fellow surfer cookie it it knows I had interaction with this client so its source IP address is not spoofed "
  },
  {
    "startTime": "00:33:43",
    "text": "so I can serve at large answers or not do response rate limiting so when you have DNS name servers in a anakov set then it\u0027s important that the surf cookies that are created by one server are recognized or can be verified by the other sheriff or otherwise the whole effects of cookies is gone so there was this first implementation of cookies in a bind and there was a second implementation of DNS cookies in knots and they didn\u0027t match so that was unfortunate for a few people that deployed these cookies and so Andre and I submitted the draft to deal with this to come with a single way to create surfer cookies and at a hackathon I participated with whittled and bit Alexis and we made a interoperable surfer cookie implementation from this draft that works with bind not power Dena\u0027s amnesty and unbanned and so the the draft was just perhaps a sketch on how to do it I think most important thing to take from this is that we managed to make it into a operable with the the the defenders show quickly in in a single hackathon donat is like and Mark Andrews also created a draft how to create surfer cookies to deal with this problem just before the submission deadline didn\u0027t make it yet so he had a meeting with them yesterday and decided to merge them so far what came out of this for us - so in our initial draft we had multiple algorithms but from discussion with with Donald we decided to to have a single table for INR separate history in a surfer cookies versions in the DNS registry that just says this is this version of how to make cervical keys and the current version not of users set hash and here\u0027s a cookie with this length thinks that we still need to do is to think about a write down how to do surface secrets or alpha though "
  },
  {
    "startTime": "00:36:43",
    "text": "and how to do is regularly implementation advice on how to do that smoothly and then x8x test factors and so because we have multiple algorithms initially T initially in our draft it\u0027s now called Deena\u0027s cookies algorithms I think since we now have just one single algorithm and one single version it\u0027s better to renamed it off the shelf that\u0027s it Paul Hoffman why did you choose SIP house given that it\u0027s like not at all standard and is brand new and pretty much isn\u0027t in many of the crypto libraries yet I mean it will be it\u0027s it\u0027s not like obscure but it\u0027s it\u0027s newer than anything and it\u0027s faster by a bit but why I pick something like that I think I can answer that this hombre and I see while the sea flesh was chosen because this is a good fit and it\u0027s even though it\u0027s a new it\u0027s already used everywhere for full collision resistance if you look at it\u0027s everywhere it\u0027s in all programming languages you use the sebaceous used for collision resistance so even though it\u0027s nude it\u0027s it\u0027s a good very good fit so right now it is it already also in the standard libraries or it\u0027s the code is available so you can compile it with your well the code there\u0027s a reference implementation from the authors there\u0027s multiple other implementations and OpenSSL one one one has it I\u0027m not sure about other other crypto libraries but but recent open ssl has as dog Rahman or even though the API is the standard open SSL API so it\u0027s cryptic yeah also since every answer to require a neat a cookie you need something that is really fast so the initial are feet the existing Deena\u0027s cookie actually suggests sha but that\u0027s just to slow that better would be a a a es or chef has a really good fit a bit Alexis ballerinas small follow-up to what the Andre said the reference information is licensed CC 0 so it\u0027s public domain okay okay we wanted to go for fast-track now but I think this it really solves an operational problem we had a operational problem so we want to we\u0027ll send out a "
  },
  {
    "startTime": "00:39:45",
    "text": "call for adoption that\u0027s in working group activity document draft later on the mailing list but I do see I think in the room positive vibes I think positive in accepting this work as a yeah I think the most important thing is that all the fairness cooperated and synchronized on this but the form of how to exactly create a surfer cookie is also in the discussion cushion right now for example little test some ideas about it Warren Kumari quick note we should probably make sure that if we do it up to we make sure that the various people of security groups actually you know get toads they can come along and have a look this is good points thank you very much thank you so hi I\u0027m Suzanne Wolfe and usually I sit over there as co-chair of DNS op but at the moment no hats I\u0027m also a in a few hours ex-member of the IAB also a hat flung away but I wrote this draft which I didn\u0027t do a lot to draw attention to and sure enough it didn\u0027t get much so the purpose here is to get people to read the draft and comment and hopefully make it a better better work subject is RFC 67 61 in special use names we are not here to recap the history again well to to fight over the history this is my personal view of the broad outlines of what happened and isn\u0027t the most important thing here but since it was several years ago only started to need to RFC 67 61 establishes a registry for domain names that are be treat to be treated as special and outside of the DNS it requires that the use of the proposed special use name be described along certain axes but mostly those focus on how the name interacts with the DNS there are some broader architectural questions and protocol questions that are not addressed at all this was in the interest of providing flexibility but it also means that it can be hard to apply and the registry policy includes iesg judgment and their the the boilerplate on the registry has standards action and iesg approval which again provides for flexibility but also provides for challenges in consistency and and and clarity Deana stop actually agreed earlier you know a few years ago to discuss special "
  },
  {
    "startTime": "00:42:47",
    "text": "use names broadly we got some orchid we got some decent work out of it we got some insight out of it RFC 8240 for special use domain names problem statement seventy six eighty six dot onion and there was some discussion although not a lot of conclusion of the impact there is a liaison between the IETF and I can some discussion about how to impacts on that and refinements to that and after we had gone as far as we could as Danna stopped to sort of study the the parameters of the challenges here we asked for next steps from the is Jake what do you need further from us and at this point it seems like the question that it would be useful for us to focus on is how should the is G and the IETF apply the notions in RFC 67 61 regardless of the drama around the edges of these questions it seems to happen and will continue to happen that IETF dug working groups sometimes need special use names in the protocols and there are real questions there protocol and architecture relevant questions around how do you specify such names how do you pick a string how do you decide what you need in the context of making a protocol work in addition 67 61 allows for uses outside of the IETF standards process in a sense the boundaries are a little bit unclear it\u0027s also the case that there would be a need to coordinate under certain circumstances with ICANN just as we would with an SDO that overlapped IETF responsibility for certain protocols or registries in a case for instance where the proponents feel a stirring might have to be delegated as a TLD for the protocol to work properly a situation that has come under discussion in several cases the IETF cannot do that it also may be the assurance could be required for the string that the string won\u0027t be delegated as a TLD to avoid name collisions and for a protocol to work properly and again the IETF is not in a position to speak for another organisation regarding what it will do with its responsibilities you know this is the kind of thing that arises in a liaison and inter organizational relationships all the time so what the draft attempts to do rather than boil the ocean of what should all of these abstract questions resolve to tries to provide some specific advice some specific guidance primarily to the ietf community about how to use this notion of special use names in protocols to be developed in the IETF the intention is that the advice might be more broadly applicable but the primary focus is here in our "
  },
  {
    "startTime": "00:45:47",
    "text": "backyard it acknowledges that needing that having a case where you need a TLD can be really difficult it makes things harder and that names elsewhere in the hierarchy of domain names are going to work for for protocol purposes most of the time we\u0027re suggesting you know I\u0027m suggesting that the idea that I ATF working groups you need to think about if you\u0027re if you\u0027re allocating domain names as part of your protocol or assuming certain behavior around domain names in your protocol you think about what characteristics they need to have one date the names need to have are they going to be human visible if not it doesn\u0027t matter if they\u0027re the string is pronounceable for instance think hard about whether especially his name actually helps we\u0027ve seen discussions and and you know barroom arguments about having a barrier that it might actually be a better protocol design without them you know it can be an easy solution but it\u0027s not necessarily a good one again try not to need a TLD just because it\u0027s so much more work than a name elsewhere in the namespace if you\u0027re talking about an IETF protocol and IETF activity now as to what happens to this from here we have we\u0027ve had an informal request and morin can speak to it in any more detail if it\u0027s appropriate again the ISU is looking for guidance they would like to have an IETF consensus document which may or may not formally update 67 61 but the intention is probably guidance for IETF working groups and possibly to non IETF proponents of special use name reservations as a second-order goal it seems like a good idea to avoid each request for a special use name going to DNS op for ad-hoc review since folks here are not necessarily going to be experts on the protocols that are great that created the requirement for a special use name or the characteristics of that protocols use requests can burn up a lot of time and cycles and we always have a lot of work to do in the working group on other topics and it just seems appealing from the engineering point of view that we could reuse some of this challenging and painful experience we\u0027ve had there\u0027s another issue that we discovered in the course of earlier discussions about this that could be rolled into this document having to do with the IAB and DARPA RFC 3172 for instance it turned out that the way that a certain need in the home in home net was resolved for HR PC was that home DARPA was delegated as a special use name and that required action by the IAB "
  },
  {
    "startTime": "00:48:47",
    "text": "under RFC 3172 it required standards action and specific review of Vienna considerations and it\u0027s one of the things that we could do is update RFC 1771 3172 to allow the IAB to act in a slightly wider set of cases if that\u0027s what we want it\u0027s a thing to consider so next steps some review what considerations are missing from the draft there\u0027s got to be more advice that we as the people that understand dns can give other activities in the IETF about how to pick domain names and interact with the with the i8 with DNS we can go ahead and update 3172 or not currently there\u0027s an IETF standards track RFC required for the IEEE Abita Act but some of the pressure for special use names is coming from outside of the IETF does it make sense to say that under certain circumstances which we would specify a delegation under is available beside side of standards action what about dot all which DNS op spent some time on and couldn\u0027t quite get to closure on should there be a reserved name sandbox for people I have to do ad-hoc allocations of reservations should it be designated by the IETF do we need to propose some new mechanism for coordination around the possibility that there will be a compelling need for a special use TLD at some point I don\u0027t think it requires new process we have a liaison relationship we have a good history of the IETF slays on relationships working out reasonably well but again it\u0027s something to discuss do we adopt it as Dan asam go for it Warren\u0027s jumping out of his shoes would you mind going back to slide 5 sorry Warren Kumari so I\u0027m sure everyone here remembers the onion discussions and they were long and painful and it would be really really really nice if we could avoid having those sort of discussions again so I know that the working groups really tired of this topic but it would be great if we could you know work on it again spend some time getting some sort of closure so in the future there is some guidance and we don\u0027t have sort of start the process again and be like what did we do last time so yeah I\u0027d really encourage us to work on it you know whether it happens in DNS off or somewhere else I think it\u0027s a problem we definitely need solve and thank you for writing it I really want to reuse some of that extremely painful experience Jim I can use this Mary or I\u0027ll turn microphones thank you these very tall people in the room front so that Jim read a couple of comments and I think "
  },
  {
    "startTime": "00:51:49",
    "text": "the question but not having the DNA sort working to do the review of these proposals for new special use names is a good one but I do think we need some kind of review process to be part of this yes we put it politely maybe something that an expert review palette could be convened to do with that round have the confront the whole of the working group but I do you think we need to have some kind of broad perspective and understanding in case someone\u0027s asking for a special label that\u0027s already been used or know something already similar to the use of that particular new label elsewhere in the DNS so that kind of visibility would be useful to try and manage some of those elements secondly I do think the point is to think more about the liaison with ICANN and one thing that concerns me with all specialist name thing is the potential in the future if I can in its infinite wisdom because to create new TLDs is that we have people doing forum shopping and double dipping or perhaps some accounts the ITF to try and severe an application for a new deal teal has been submitted into the icon process and we must have I think gonna have to have some language around that I don\u0027t know what it would be but we have to be aware of that as a as a distinct possibility it didn\u0027t happen while strain round but I think it made real happen the next thing especially when people aren\u0027t happy the set of strings but rejected as part that I can\u0027t process and I think some people who are titles particular things but might come to face here and say hey I can\u0027t understand know the ITF will retinal internet draft give us a TLD and just as a closing line and yeah we do have four or five minutes for discussion on the mic powered we just want to make one point of clarification and the recap of what we did I think that one bullet point I was definitely missing is that we froze the use of 67 61 and said we\u0027re not considering any new domain names and that actually selectively left out some names so so it actually opened us up to really selective process why we did adopt onion and it didn\u0027t adopt some other ones and so in that light I think it\u0027s really important to say if we do not update 67 61 we must move it to historic I think part of the point yeah I think part of the point here is that we don\u0027t want I\u0027m not gonna argue the history with you like I said but I think the perception that the process is arbitrary and subjective is exactly what we\u0027re trying to build away from so you\u0027re right thank you that mic cause young wrote off as the person who started the whole thing I guess I wanted to briefly share my experiences what has happened now I don\u0027t know if you\u0027ve been at the DA NRG group given that the group decided that we should not have the dot new TLD we have now released software that "
  },
  {
    "startTime": "00:54:49",
    "text": "basically allows the user to use the root zone and overwrite any top-level domain as they choose which has had basically the answer you know do you need a new TLD no we could have just used a collision and we\u0027ve done usability studies and the result has been spectacular users can no longer tell apart if they\u0027re using DNS or gns so the migration to a new protocol is much easier if you don\u0027t use a new TLD so the usability has been greatly improved and that would have been good advice to have been gotten early on thank you where\u0027s her Aquarius I I want a second Jim\u0027s notion that figuring out how to have this really how to have the input from Mikey and as critical importance and challenging at the same time second thing to the chairs don\u0027t let this drop don\u0027t let you know that we we paused way too long with this issue and as hard as it is and as much people need to do expert review on it from multiple standards organisations it\u0027s critical we solve this you know confident I think there\u0027s one recommendation missing which is very important and which would call people to till the right actions regarding sixty seven sixty one sixty one sixty seven whatever I even forgot the name number and that is sixty seven sixty one does make the name special it doesn\u0027t allocate you the name so this is not second way to get a teal the urine Montiel d or anything prior mistakes of application of their RFC non withstanding so you if you have a name you can declare it special by registering it in that particular registry but doesn\u0027t get you the name second I doubt that DNS up is the right venue for this I don\u0027t have a better one and when it comes to liaising with ICANN the previous occasion showed that both organizations were happily conspiring together to avoid the problem now the next one around is and you mentioned on the slides home Corp and Mail and I could imagine interesting fireworks if the I if I can just throw this over the fence to the ITF to say well we have a draft here just register these as special so we can blame the ITF for blocking those names and I\u0027m not sure that the ITF and especially the ITF leadership would like to be in that position at least I hope they don\u0027t want that Stefan Watts mayor as it is written in today\u0027s draft it\u0027s mostly recommendation for ITF developed protocols such as don\u0027t try to reserve a TLD that like the thing which was done with that one at the beginning but it doesn\u0027t solve what "
  },
  {
    "startTime": "00:57:49",
    "text": "is the real problem because besides okay the inside the IETF there is not really any problem the problem comes when people from the outside wants to register a name as a special on there is no proper way to greet them and to direct them to something proper we have not been able to reserve that out for instance for them so they will continue to reserve TLD because it so I seem to do for them and then we will still have the problem on I can also because when you say that I can\u0027t we cannot force I can to lock TLD to be them even tip from being delegated we cannot but we can talk to I can say that this one is used in practice on I can can do it by itself because I can decided not to delegate a dot on that cop the smell because our actually used so input from the IETF could be just one more input for the ICANN for this decision but at this time the draft for me is not really interesting it doesn\u0027t serve really any problem because it gives advice for people who already know about it so we\u0027ll problem is how to greet requests from outside part of the attempt here is that there\u0027s sort of a taxonomy of different cases where there\u0027s inside the ITF and outside as you\u0027re saying and the other distinction that we end up making because of the the inter organizational implications is single label name I don\u0027t even like the term TLD because it\u0027s it\u0027s it\u0027s you know in its oh it\u0027s overloaded but seeing the label name or not the other but the other dimension is are people asking for the name to be allocated sorry they\u0027re asking for it to be allocated in the sense that they\u0027re either asking for it to be delegated in the Deanna\u0027s with specific behavior for example an unsigned TLD was what HomeNet was asking for at one point or is is what the with the protocol and the proponents are asking for that the name not be instantiated in the D is just the collisions beautiful it just reserved so the collisions can be avoided and to me at least these are distinct cases and you know the document tries to discuss them accordingly but if there are other approaches or if that means refinement yeah yeah I think that\u0027s valuable feedback okay so the question I think will have to go the chairs to discuss how to forward discussion on the list well we\u0027ll put on the spot to consider what we\u0027ve heard here also but my real goal was just to get review for the document and get people who are not too traumatized to ever think about this subject again to help us do something constructive here within the cases that we can actually deal with Thanks thank you one small remark "
  },
  {
    "startTime": "01:00:49",
    "text": "one small short I guess this is kind of related to my earlier thing would the working group be willing to please consider working on this you know either specifically here or even just review the document please review it send comments you know plea for for work here yeah thank you you need Steven course working group presentation and now sorry not cross but if if for not no word no working I\u0027m sorry this is a former failed working group crossover presentation thank you for the context in history year and so I\u0027m showing you it so hi I\u0027m Steven is Alex this is an idea of Alex\u0027s basically slides so it\u0027s essentially looking again at the problem at Deeb and was trying to tackle to try and see is is there a small bit of that problem small a bit that people might be willing to kind of tackle and then publish records the idea basically is that if you have two two related domains that one of them can can declare this relationship basically asserting the relationship without in this draft giving any kind of strong semantics about that there\u0027s an extensibility mechanism that would allow you to later on say there\u0027s a particular tag value if you have some semantics that goes with the relationship so for example this it shows that the example that calm is related to the department example become so next slide it there was a zero zero version of this that had dkm style use of txt records and tecum style signatures for doing some authentication and we gots a bunch of comments on that on the D bound list so we put out a zero one that kind of flips over and has optional signatures that are DNS X file and a new or Ora type which I may have messed up because it\u0027s the first time I\u0027ve written a draft that tries to find a new Mora type the signatures kind of provide an anomaly in a sec environment they kind of provide some insurance that the declared relationship is more likely to be real than otherwise it\u0027s not a very strong kind of guarantee and the next slide is one that Lex is going to talk to about use cases so I wanted to talk a little bit about these cases in in my day job I spend time doing anti abuse and email so in in some of those analysis we find that we can\u0027t always determine relationship between two domains that appear to be related and then sometimes we may need to err on the side of caution and that doesn\u0027t always work out well for the end user so it would be beneficial in our world to be able to say that yes example.com is really examples mr or for example the marketing department may use "
  },
  {
    "startTime": "01:03:53",
    "text": "an outside vendor I work for a large company sometimes without knowledge to the DNS team the mail team whatever else they go outside and they creates you know whatever they feel like at whatever vendor they feel like and you have and then they don\u0027t understand where the mail doesn\u0027t go through creating new domains for example uber calm decides they would like to launch a new service called uber eats they might want to determine straight a relationship companies by companies all the time you may want to you know for some reason or another show that sort of chain of authority I guess something more for first even I think use internet surveys your research I suppose being I don\u0027t wants a map the web it sounds kind of hard when I say like they have but uh yeah and then something like was sort of on the first slide example dot F are an example de I don\u0027t know how commenters I mean we I am living the States so I don\u0027t know how common it is for a large brand here to say like McDonald\u0027s com McDonald\u0027s ifr McDonald\u0027s about de and how can I actually determine their relationships we we used to have a lot of not a lot of data but there was data in who is and some of it was reliable some of it was not and that\u0027s been sort of going away making our jobs even more difficult so I\u0027m hoping that something like this we and work toward to make it more obvious that these relationships are the link does exist some oh so uh there\u0027s a link to their the name of the draft and we\u0027ve been having discussions on the D bound list only because that seemed more appropriate I suppose what I think we were told to some random ad told us to do that so that\u0027s where the questions Brian Dixon one of the things that I think is a concern is the difference between an explicit declaration of non mapping versus an implicit lack of declaration which can be interpreted either way I think it would be very helpful to have the explicit declaration of mapping or also the explicit declaration of non mapping ie somebody can put a defensive record that says there\u0027s no other related zones Oh Alex mail phone if that 80 I\u0027m concerned about two things actually for one you you gave a very great definition of what the relation the semantics of the relationship is besides that this is somehow related so I\u0027m I\u0027m wondering how how can I semantics of the protocol be here when not even the relationship definition of what does this record actually mean is here so quite frankly that would render it completely useless and the other point is there like a couple of other mechanisms out there I\u0027m "
  },
  {
    "startTime": "01:06:54",
    "text": "thinking about HTML based meta tags related pages and something like that redirect whatever so I wonder whether if you put something in the DNS like this does it apply to each and every protocol each and every future protocol it\u0027s it\u0027s very opaque yeah sure I mean I think it\u0027s fair comment and I mean there\u0027s a cesspit of semantics that you could get into and we try and we\u0027re trying to hold it now maybe that would work maybe it wouldn\u0027t work that\u0027s that\u0027s a good question I think later I mean right now we\u0027re trying to avoid that issue maybe that\u0027s feasible maybe it isn\u0027t but I think if the if the semantics are not clearly defined and it\u0027s actually a useless indication you\u0027d see I mean right now in the current in zero one it kind of says we\u0027re declaring a relationship but not defining the semantics and there\u0027s a tag if you did want to define semantics for later they\u0027re in more specific place I\u0027m closing two Q\u0027s always go oh this one okay and then then somewhere in the middle or at the end okay go thanks to Jim needs pepper comments Stephen and there\u0027s an interesting idea but I\u0027m not sure the DNS is a police for representing these kind of semantic relationships I think the idea be able to say these things are kind of equivalent it\u0027s potentially useful and interesting but as Alex was suggesting it perhaps creates other potential problems further down the line and we need to think male author but more about that but I\u0027m still not all that convinced we should be putting that kind of semantic meaning into the DNS the DNS is really essential lookup mechanism to receive some data about an object and I\u0027m not sure that kind of semantic meaning is appropriate for the DNS and then the second question would have for use how is your proposed record type any build if any really different from dname so there was an extended discussion about the dname question on the debug lists sorry have me following that was general Sonia and and some of it I didn\u0027t understand so I\u0027d point you at the list and okay thank you for timekeeping we have about five minutes so please give everyone the opportunity to ask a question but debrief Joe am PIR I actually think the cesspool is fine I think it\u0027s actually had an advantage not to define exactly what it means because and I just not and this is I don\u0027t think I look up mechanism so this is why T name would actually changed query behavior we\u0027re not talking about that because we find a PIR that when you try and cluster domains together to identify when you\u0027re doing business intelligence about the scope of registry for example the mechanisms that you have to try and cluster these domains together are horribly messy but to do with Whois data that\u0027s vaguely similar or words that are common or this specific to the web because you scrape the web but you find out the veil thing is in common and it\u0027s incredibly resource intensive to try and do an inaccurate so I think this would be great if it existed but my question is what incentive does it the main name holder how to actually publish these "
  },
  {
    "startTime": "01:09:55",
    "text": "records if there was something like deacon where if you don\u0027t publish it you don\u0027t deliver mail to google then that\u0027s a good incentive right it\u0027s like reverse DNS and v6 nobody would do it at all if it wasn\u0027t familiar to Google and places like Google but there\u0027s some more policies is there any incentive here for anybody to ever publish these records I mean I sort of would think so I mean again I come from a large company so we do have our marketing departments do things that make our lives very difficult so they could Ardi nesting could go back and say we we\u0027re gonna work with you to make sure this is correctly attributed to our company and then we\u0027ll work with you at some point later to make that really work the way it should I mean it seems like it would be something for their operations to make it ease their lives but I mean ultimately it\u0027s it\u0027s from my also from the anti-abuse perspective it you know if you want to try to create a new domain name and you don\u0027t have the time to say create a new reputation for that domain in terms of messaging reputation you know you can say okay look this is linked to here we are a legitimate domain that now is going to be associated with for example ubereats an uber I mean it\u0027s I can\u0027t say it works the same way for all use cases but in that case and I think there\u0027s some you know a good example of why it would be useful I think imagining that the marketing departments who are already not following the rules which somehow choose to follow this one is a bit I would encourage you to find something like an anti abuse use case to provide some incentive because it would be really good if they existed but brief questions and brief answers please my pal said this actually ties back a little bit to what Joe said but I\u0027m having a hard time wrapping my head around the use cases you mentioned a lot of them but when I look at the incentives for a lot of those use cases they all seem to boil back to anti abuse and and potential and and boil back to the interpretation by anti abuse researchers and that so if that actually is the real single use case then it might be better just to say that and and if those other use cases have other motivations why people might want to use them for that maybe say that too so right now I\u0027m having a hard time understanding how it\u0027s useful in those other cases and when I look at the anti abuse situation I start to wonder what the possible interpretations of the absence of the records could mean and and and that get that starts to feel like it could be kind of messy and so that that might be a vote that might be a suggestion towards actually making it a little more semantically meaningful rather than less thank you next john reed Akamai quick question about directionality in the draft I know you say it\u0027s unidirectional has any thought been given to recommendations around the best practices to which direction it should be should the you know email marketing provider at its "
  },
  {
    "startTime": "01:12:55",
    "text": "customers the other way around either way those lists can get real big real fast and I\u0027m just wondering what you know thought has been given to that um and also how sorry once you set up the directionality how do you make sure it\u0027s gone on both ends when the relationships over I mean yeah I mean from my perspective it seems like the sort of the largest or most well known domain wins but maybe that\u0027s not really how it works so I mean maybe is if I don\u0027t know if there\u0027s an alphabet compa that seems less well known than google.com sure so but you we think ultimately if alphabet com is actually the real parent of Google that that\u0027s where it should kind of feed up through but I know it\u0027s really the relationship that you want to declare I suppose right so some recommendations around also please on the mailing this is a Marie from our co-chaired eBay and I\u0027m totally fine with you using my mailing list because we narrowed it in a useful with it anyway so again the T sort of took half my point you should probably say something about what happens when you find a unidirectional assertion because that may be meaningless it might even be a threat like I\u0027m claiming an association with your domain to try to gain some benefit maybe what has to happen is I have to go to you and get some confirmation that the opposite is also true so that doesn\u0027t seem to be addressed in there at all Alex what I heard Sam Wyler what I heard you say as you went through the use cases was this is a way for but what if I want to know if these two domains are related I think the real question comes when what does a piece of code do when it seats one of these I think that\u0027s why your use cases are not fleshed out enough part two someone at the mic said that they weren\u0027t sure if DNS was the right place for this I will draw everyone\u0027s attention to a proposal from my quest called first party sets that involves JSON objects served over HTTP I don\u0027t know if that\u0027s the right way either but it is a different way and may have a differently scoped set of use cases than what you\u0027re looking at part 3 this signing with straight authenticate keys thing is crazy thank you so Warren Kumari Google I\u0027ll try and keep it really short um so I\u0027m not entirely sure that there should be in the DNS but if it is I would like to build a habits that I can say Google comm is the same as google.de not at lookup time but so that people who are doing abuse stuff can have a look and draw some correlation what I\u0027d like to be able to do even more is be able to say in Google com Google Doc BD is not a sort of Google property so I can sort of disavow a bunch of their name domain names and I think that would be even more useful than we would say what ones are the same okay Jane you\u0027re employed by the internet society but not speaking for them so first I want to say thanks for bringing this draft here I think it\u0027s good to have you we\u0027ve often talked about wanting to have people bring an operational you know usage of DNS and "
  },
  {
    "startTime": "01:15:55",
    "text": "where you\u0027re seeing issues with it bringing here so thank you for writing this from bringing here I guess I would just have two comments one you mentioned that you would find it useful for for your work and things have you spoken to other vendors or software folks or people who might implement this in terms of where I\u0027m going is I think it would be useful to talk to people who might be consumers of this and find out would they and a minute you know and that kind of thing and see whether that would be Oh Murray saying okay so so I think that would be something to be useful to have and to be able to do that so that maybe a hackathon or something completely looking at some of those kind of things for something and the other part is a comment in here I think I\u0027m a little concerned with the trust by the way I\u0027m from one of those communications departments that does that kind of stuff and you know this would be kind of cool we could use this in a couple places but one question is what prevents some less ethical marketing folks or somebody from claiming that they\u0027re really associated with another domain you know I mean I might be able to say that hey my domain is associated with google.com or something like that so trust me I\u0027m important so I think that\u0027s the one little thing that because not all my communications colleges are ethical that\u0027s where the crazy signature thing is trying to help but yes Murray again also not employed by our paid by I sock I think this possibly has applications in the Demark space as well because we tried to we wanted to capitalize on D bound and it didn\u0027t work so it\u0027s possible that this could be an add-on to that somehow so there\u0027s maybe a possible use case okay thank you so your question further we review discussion on debounce mailing lists and yeah questions or comments there or to us or whatever okay thanks thank it okay then it\u0027s well thank you the final agenda point here yeah you will go through the slides oh no blue sheets anybody not sign the blue sheets just raise your hand okay so who\u0027s up for a short introduction no no no just historical so we had a discussion on a name in Bangkok Tim prepared well the problem space is well known I think we don\u0027t have to go too into this also given time there was the C name a name discussion HTTP I just felt it was kind of all the different repels of Health themselves or together we\u0027re in the deadlock so we want to separate this discussion so we can have the HTTP discussion we can have the C name discussion if we still want "
  },
  {
    "startTime": "01:18:56",
    "text": "to pursue but don\u0027t let us start with a name discussion actually that\u0027s why we\u0027re here now I also want to point that out sorry I want to point out draft written by Denton York about all the users or the web commercial perspective have a read of it and actually given time I want to give the floor to UX new yeah but I see the title gives well speak for yourself actually about the day named draft status and okay so I think I\u0027m I\u0027m here because I made some confusion on the mic on Tuesday there I said that it might be a good idea to have a separate direction with aiming to have a different scope smaller scope so can make more progress that caused some reaction on them mailing lists so I thought maybe it would be good idea to get this to the working group we covered a little bit of a quick history like this this is done by DNS providers this is not going away so aiming for office written by Evan and data and people came along to that lots of discussion made a very complex solution in the - or one version and then we thought if we\u0027re on a bad bad bad here so there was a complete rewrite that\u0027s the - OH - version that Tony finished it to me that is very nice document all the complexity has gone away it doesn\u0027t rely on resolve equate and got a lot of feedback on the mailing list after everyone a little bit silent so how do we proceed with a name is basically the same and when on the list and looked at the discussion and got a little bit of requirements out of that so the Ingham stuff shoot free support on a flying demon sack does not require service changes except further like the are type miss work with resolvers that don\u0027t do any name like but never implemented the resolution should not be required in the surfer to be possible but it\u0027s not a requirement and must be working in a multi provision or model I think the o2 version does that so basically I think "
  },
  {
    "startTime": "01:21:58",
    "text": "there are two things to go forward one is iterate on the current draft and please make sure that the discussions focus on what\u0027s in there and and notice that it actually has two requirements several justices or we can reduce the scope and just just get rid of all the resolves of processing and secondary server processing with the idea that we can come to reached to an document faster like this less contentious stuff test we do scope or we can iterate on the current draft I\u0027m finally both I would like to hear what the working group thinks about that user open I like the current draft as is I would like to implement it Guilhem tour by the way in our metal ops Brian Dixon Go Daddy I\u0027ve piloted extensively on the lists and one of the main issues with any of the current drafts are the requirements for authority servers to act in a way that previously only recursive x\u0027 needed to which is fetching and storing and updating the targets of painting and that does not scale for authority servers especially large ones so I don\u0027t speak for my employer GoDaddy but it\u0027s a major concern that we clearly have an interest in not having problems that don\u0027t scale it\u0027s it\u0027s basically it\u0027s an existential threat so it hasn\u0027t been addressed adequately by the the draft and I don\u0027t think it can be due to the requirement for the fetching and updating of Records other than the specific local ones so I think I think you need to be addressed in a different way in a different place but that\u0027s that\u0027s my analysis and observation and I think it needs to be strongly considered and when you say in service do you mean the whole thing or like in the name server itself like an implementation that in the authority servers there\u0027s a whole bunch of different aspects of this one of which is it interferes with geoip because for at least our implementations the authority servers for a given zone are centralized and pushed out to anycast locations they\u0027re not differentiated so querying an authority "
  },
  {
    "startTime": "01:25:01",
    "text": "server returning a record the the sibling record is not going to be geo differentiated and that breaks all of the geoip stuff that the painting targets are expecting it just doesn\u0027t work and right no way to make it work the second aspect of that is scale recursive scale by query authorities scale by the number of zones so if you look at the longtail the issue is you\u0027re now placing recursive level transaction requirements on that changes the business model and it does so in a very negative way because typically the long tail of zones don\u0027t see query load there\u0027s no way to recoup the costs of doing what aining requires so to your last comment I think he need it would be nice that the document or as a successful document would at least have to resolve our a name processing to improve and make the a name resolution better for the client to your first point a geo RP yes that\u0027s a different thing if you\u0027re going to do tailored responses then the document doesn\u0027t work but that\u0027s the same with like Dean a sec you\u0027re with your PL so they\u0027re not doing offline signing you are required to do online something because you\u0027re doing tailored responses it sends true for any resolution so if you want to do aiming and 0 IP you\u0027re have to implement it sort of in your secondary server and that will scale actually and the draft doesn\u0027t prevent you from doing that either you just have a bend a little bit the rules like those providers do and I would have to take I\u0027m closing the line yeah Shanker so Bryan and I was closing the line No well otherwise let you argue and why\u0027s that sorry no otherwise I have to interrupt you during a discussion and I don\u0027t like to do that either I close the lines so just very quickly the my understanding is the reason this draught exists is because people have implemented things almost exactly like this so the claims that it won\u0027t scale are just false I mean we do this other other large authoritative servers do this so it disco yeah so I\u0027m sort of gonna repeat that anecdotal evidence that it that this sort of thing does work I implemented or was involved in implementing this with for a large genus operator with 3.7 million zones we ended up we ended up having to do ramp up and back off algorithms such that the more "
  },
  {
    "startTime": "01:28:02",
    "text": "often we witnessed a target change the more often we queried it to see if it had changed in order for the ones that were very stable to we could essentially ignore them that helped it work really well but yeah it works we did testing although we never ran this in production we did testing with n simulations with up to 10 million domains and that was fine so yeah I don\u0027t particularly see that as an issue but there\u0027s projects is ethnic as was mentioned it just works in the practice and it\u0027s implemented so I proposed to cut it into two documents first one just specifying how we do some transfer and how do resolving part and don\u0027t specify where you should do it so it can be in the provisioning system or in the off or in anywhere you want in your particular implementation and I think that this would go a long way because it would allow people who use this already in existing deployments like Dyna and whatever to have more than one provider because once we have this on transfer specified you can just move or use two providers and so on and then if this actually works and gets implemented by these big guys who offer this service now we can go and work on the second document which could say okay if I\u0027m Venus software developer house in Poland is in my coat only one high up I didn\u0027t buy that it will procure nearness because we just finished a name JD in this a name that with our provider that actually also resolves propagates a DNS or multiple a name recurs and we are very funny last night and it\u0027s works just fine I\u0027d really need my it would somehow break it so just one comment which was just from the the high level the statement that what is currently being offered is being done by DNS providers I think it\u0027s a mischaracterization as being offered by vertical integration some suppliers that do both authoritative and recursive or do DNS plus web hosting or similar kinds of content related stuff so it\u0027s different that\u0027s you very short comment on this no okay thank you for the shortness thank you so so you can summarize if you want now I\u0027ll let it you do it now a couple of things here I think we of course we take it to the mailing this and also the discussion of one or two documents so it might be for the process easier to proceed with two documents but I definitely want to hear "
  },
  {
    "startTime": "01:31:02",
    "text": "that a little bit more on the mailing list and the church will associate together with you and with the other stakeholders or does the pen holders of the document how to proceed Tim any other questions you meant remarks you want to make here as a stakeholder iterator I think Brian\u0027s incorrect answer who does this I think thank you materials for this I think one document is good we can scope it down and not put a second document out which will just sort of confuse people initially right so I but yeah we\u0027ll sit down and I people sort this out person nails I heard little people less that\u0027s not so many comments it\u0027s a or you really have to split it I think we should it\u0027s right on the contract I think we should iterate it and um I give this scale everybody does it now right uh all the vendors do it everybody does it so yeah I don\u0027t see that as a problem even so let me just real a comment on that Tony Finch who\u0027s been involved with this asked I\u0027d like more descriptions on the list from vendors on how they do a name so to the comment that people are saying they they already do this and scale this I think Tony\u0027s sort of saying why and not realizing the time send to lists and likewise for people who would say we\u0027re in here saying the scales and stuff would they support this would be useful okay to ocinski Tony thank you of course then you follow this I\u0027ve talked with the vendors about this they owe each vendor feels their secret sauce has tastier than the other vendors secret sauce and they don\u0027t like to share but if we can find some of that that would be great but that\u0027s my experience talking it with them under NDA not actually getting solid answers so you know vendor a see it\u0027s much tastier the vendor be sort of thing so but a useful idea of Tony thank you the search for common ground continues thank you yeah Thank You Madison thank you yeah we need time kind of three minutes and there\u0027s no need to to leave the room because there\u0027s deep right ask for yourself just just stay around but whoever has the clipboards please bring the blue sheet so we can take them in Secretariat thank you [Music] [Music] "
  }
]