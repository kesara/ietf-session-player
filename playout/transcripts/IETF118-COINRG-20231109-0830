[
  {
    "startTime": "00:00:18",
    "text": "Can I do the control, Jeffrey? Like, Okay. And when you have the control, okay, so Well, maybe maybe we just Jeff, you can just keep the control. For the whole person. Yeah. Yes. I can control it to the right now. So we start. It's 9:30 in Prague. Right? Mhmm. And we can probably give people 1 or 2 minutes. Yeah. So your video is not showing here on the screen in the room. I'm I'm and grab it or see if I get someone. No problem. No problem. Yeah. Just let the slide show the data screen. Yeah. So we can see the slides here. Okay. So let's start. Welcome to coin RG. So this is Jeffrey, one of the co chairs, and the other 2 co chairs if and the Massachusetts are also online. It's a they have in a very difficult time zone. And we also today have, Ike. Ike. Helping us in the meeting room as delegate, culture, and sent to Ike. Somebody should say? Please start introduce the, child's line? I don't have a control because she could you move to the next slide? Okay. So, of course, hi. This is Marie. Of course, computing and the network, follows, the note well of the"
  },
  {
    "startTime": "00:02:03",
    "text": "So, especially, I think what has always been a problem is, the the patents So if anybody in the presentations today, has an issue with patents or has nose of patents. That have been declared against the material. Please, come forward. Next slide. Again, so this is the policies, everybody should know that the session is being recorded. So, again, this is important for people both presenters and people who ask questions, Next slide. So, obviously, this is a bunch of, administrative. We have the new tool which seems to work pretty well and it has automatic blue shades, which is fantastic. It has, everything's integrated now. So that's fine. Again, Ike, is in the room, so he's gonna be able to help us moderate. And, Please, everybody's online. Please keep your your audio muted and video off. And, It says headphones jointly recommended, but for Neely, I'm not having any right now. There's the chat which is also integrated. It's on the I for me, It's on the left hand side of the screen. There's going to be, Eve is going to lead note taking, but everybody has access so people can add. And, of course, there's going to be the the the presentation will be available, after the recording. And, will also, I think, be uploaded to the IETF YouTube channel And, our mailing list is is IETF the cohatirtf.org."
  },
  {
    "startTime": "00:04:02",
    "text": "And, of course, the meeting material are are on data tracker and everybody has access. Next slide. So it's just a, a a a re I would say, A reminder, IRTF is not a standardization body? Is this a research? Organization, So what we present is research. There is no goal of standardizing anything And, so I think it's an important thing because I keep seeing that and a lot of emails, you know, like, people send I would like to bring this or that to standardizations. So I'm going to present it to the IRTF folks at the wrong place. You should actually present that to the IETF, not us. Next, so you wanna take over, Eve, talk of the agenda, or should I Sure. Sure. I'll I'm happy to do that. We're gonna begin, the session with research topic followed by, research group draft updates and then individual drafts and then some additional new topics that we're introducing in terms of the research topics, very excited to have, Ikeer at this session because he was supposed to present, the end to end discussion topic at the last IETF, or I'm gonna get a couple of ITFs to go to Japan IETF, and, unfortunately, fell sick. So we're excited that you're you're here. And we'll do that at this session. The second research topic is one that was presented at sitcom this year, again, so it's terrific that we've got Heiyouong, with us, to present that. The 3rd research topic"
  },
  {
    "startTime": "00:06:00",
    "text": "is, something that, Ming Wang Zhang is going to present She is a final year student at Technical University of Denmark, and she, did this work in collaboration with folks at, University of Oxford. And, it was it first appeared in the IEEE transactions, Oh, I think it's I Tripoli I OT journal is what it's called. And there's also some exciting, follow on where to it that includes federated learning. In fact, I wanted to also point out that Ike has been a constant, participant in the Coin Research Group, and, he's a PhD student. At Aachen. And is, kind of a very senior PhD student. So we have multiple students here who are kind of in the final stages of their of their studies. So make note. For those of you who might be hiring. We have a couple of drafts that have been updated, that have been adopted by the group, The use case analysis draft is one that it has a companion draft. And it this one analyzes the use cases that are have been described in the companion draft in which you'll which I think has just gone to last, last call the directions for computing in the network is also, an important research draft that has an update and, along a weighted update, and it was just updated right after the last IETF. And so, dirt, control will be presenting that. There are There is a new hangout. Hey, you will, also be presenting a new individual draft on the requirements of unified transfer protocol and, of course, related to what Aika is also, presenting earlier."
  },
  {
    "startTime": "00:08:02",
    "text": "The, the other draft is an update, to some material that was presented in a previous IETF on, evolution of cooperating layered architecture for SDMs. For computing data awareness. The final topic on the agenda is Very interesting work. I think, it is it goes by the acronym of AI for me. It is collaboration among, several entities, notably the BBC, R And D, arm of the BBC. I believe that, Dan King will be presenting as opposed to Rajeev. But no matter, I'm sure it'll be really interesting and this is just to give you a little flavor of this work It is in collaboration with 2 universities, University of Surrey, and Lancaster. University, And I hope I got all of those names correct, but, and this is really more of, a teaser to queue up a potentially longer discussion about it when we have more time in the agenda. I did wanna thank many others who offered to present in this session for whom we didn't have enough time. So let's continue those conversations to get some of your work aired Either when it's ready enough, or as the, clarity of how it's related to the group becomes more apparent so stay tuned for other topics, in our next session, Back to you, Either Jeffrey or where we should say left side. Okay. Let me introduce this. Document statements. So yesterday, plusplusplus yesterday, I sent a email to the list. So we basically, we set finish date, for the last call. That's, 2 weeks after this"
  },
  {
    "startTime": "00:10:01",
    "text": "IETF week, week, So please review, read this document and review it and send the feedback to the nearest or the office. And, we have other two documents we update, and we will we are we update today, And then there are other individual, drafts. Okay. Yeah. That's more, individual jobs. Okay. I think letter of that's the plantations. I are the first one. Right. Oh, k. Then lower again. So I'm Ike and this is actually not stuff that I've been doing along. So, basically, this goes back all the way to, HDF last year in London. We had another presentation and afterwards, but quite a few discussions on network computing, the end to end principle transport and so on. And then also ongoing discussions on the mailing list, and, together with Jeffrey, And with their trustmen who can't be here today, we try to kind of make sense of the discussions, try to condense some statements out of, the discussions, and Yeah. Just try to gather some thoughts together so that we can maybe give additional input the discussions here at the working group. And what I would like to do here today is, basically just to pose a few statements that we've, we thought might be interesting. And, I guess we will also see a lot of those aspects coming in the presentations afterwards as Yves has already said. So for example, in the"
  },
  {
    "startTime": "00:12:01",
    "text": "coin directions draft or afterwards in the, transpart, presentation. Okay. Yeah. That's the intention that I already stated. Just the interesting part, maybe the abbreviations at the bottom. So I will be INC for a network computing and the end to end p slash a for the entry and principles slash argument because there's always people using both of app off versions. And, the Slides will be quite full, because we've tried to make himself contain so that people can also just look at them afterwards. But I will try to mention the most important aspect of each slide. So regarding, the opinions that we gathered, we first had to look at different mental models, for in network computing. And then we had the first aspect that was brought up network computing is something like a wire with bumps in it. Where the packet transfer emulates the wire where we then still have kind of end to end session, over that wire, but that we also extend the functionality that can then be executed in the network notes. But here, then the question is, what kind of functionality do we actually wanna also include those devices. Another aspect was that INC might be more about pushing innovation into the network. So basically decoupling, the innovation in the network from what's happening on the applications at the end hosts. And then finally, we also had the view that, and that in network computing might actually be different intermediate connections. So from one end to an intermediate, then from that intermediate the next intermediate then finally to another endpoint."
  },
  {
    "startTime": "00:14:00",
    "text": "Where then still there's some kind of this overall connection but where we might have different individual ones here. So those were different mental models for a network computing that we saw. I think some of those are already also reflected in the, new or updated, co interactions drop. Do you wanna state your question directly coming, or should we to the end I kinda caught Colin Pickens. We can do either way. I I the the first and third ones seem very concrete. The middle one seems much fuzzier. Yeah. I I agree. So, basically, what we just try to get a different statements or try to group them and those were those that we thought match best to those mental model And it's only basically meant as a inspiration to think about different ways of we could think about IC. And not it didn't intend to really define or, dig deeper into what people could have meant with those statements. But I agree that that is school 47. Yeah. We'll then head on them, as the next aspect I look at the different functionality, that I and C could provide. And, so basically, that we identified 3 different groups of functions. The first one was escalated. We just haven't execution environment somewhere in the network that can basically execute any kind of functionality the second one would be it. We have some kind of atomic compute functions in the network that could be used by many applications And it's that one. That we're really application specific functionality So I guess the 3rd aspect is, what many people do with P4 or a lot of additional, application that they try to build in the network. And here we were kind of wondering"
  },
  {
    "startTime": "00:16:02",
    "text": "where the different lines lie between those different groups of functions. So, for example, where the atomic computing functionality ends and where the application specific functionality starts, and what kind of functionalities network should support. How many functional, how many functions the network support and so on. So really this could be one way to look at things. So from the functionality that is provider. Another another view, would be the layer view. So as the network is typically we have a load transport. The, the first question that we also had in our transport draft a way a while back. Was basically if we even can't form functions on the transport layer given that there's an increasing trend for end to end encryption. And One way of thinking of this is, that we put or of the impact of the different layers we're thinking about, is, was made at the example of routing where we the one hand side saw that if we put networkcomputing functionality on layer 4. Then we could basically just have the general routing as we have today. And then an overlay that, tries to route between the different coin elements and then could take into account, for example, the compute capacity of the network computing functionality, however, if we push the network computing one layer down onto layer 3, then we would have to update basically all of the routing that we have today so that it also includes c compute functionality or compute facilities. Of of in network and shipping. Seems to be kind of a lag in between here sometimes."
  },
  {
    "startTime": "00:18:02",
    "text": "Nowadays. So, the the view that we had was, the state the view on statefulness. So where we basically had that today since February. You often try to have us, little statefulness as possible so that packets can traverse network, rather self contained, And here we, the strength where we saw a distinguishment between, application, specific functionality on the one hand side. And then the statefulness and, or statelessness on the other hand. And, the In essence, we then kind of saw different categories that might arise so that the non state for generic functionality, that could be provided by, by, in network computing might be the best. Suitable option because then basically everything might still work as it books today. And then we kind of had few more steps in there. With stateful and application specific functionality at the bottom where we basically have, that if if if some device suddenly, turns off, then state gets lost and everything gets complicated. And we also have application specific functionality there. So that It's really important for the network computing devices to know kind of functionality they have to execute at yeah. So those were different views and opinions together. We then, Hark back to the, enchantress or argument. Is also something that we especially had in our presentation in London and we then based on those, on this general statement, try to kind of find, different views on this, entry, end principle or argument"
  },
  {
    "startTime": "00:20:02",
    "text": "we saw quite a different different views. Some there. And, yeah, I'm sure if I'm gonna go through all of these statements here. But, so so maybe that's something that you guys could do after the meeting as well. So have a look at those different intentions maybe and kind of find out where on the spectrum of all the different, interpretations you said. I guess some of you will also find your own words on, on the slide. As I said, I've many collector or we have many collected, statements that we saw before. And I actually have another slide with additional statements of this, So, basically, yeah, this is, what has occurred during the discussions that we had after London or in London. And Now, the, the main question that arise for us was how we can actually move on from this. So how what's can we make up all the different opinions that we saw out, the different views that we had how can we move forward, And, one question that was asked there is basically, how we can now actually combine or make inc work in light of the end to end principle or argument. And one aspect there was the simplicity and, transparency aspect so that we maybe try to make functionality as simple as possible and then we also at transparency and and Yeah. So what are we gonna do next? More. Are we gonna try to do next? Actually, we're only interested in input. And Also, only intend to provide input for new discussions. As I already said at the beginning, I think that lot of these aspects are also covered in other drafts and other presentations today. And I guess"
  },
  {
    "startTime": "00:22:02",
    "text": "what we should try to do at this point is just continue with the scattering of, of the different opinions and try to condense that even more and even more. And then come up with, a joint interpretation of of these aspects. And I think that, for example, the, the direction draft is an ideal position for that. And what we have here basically on the slide, is, that we could maybe try to define concrete research problems or feed statements on some specific issues, try to solve those issues, to enhance our understanding of the overall topic and then continue from there on. Tool then kind of just iterate, over the of over our understanding network computing and, And are all the original contributors. As I said, I've managed condensed or we've many condensed the statements from other people as well. So thanks to you, also, if you mentioned on this slide. And I guess now we still have 3 minutes for discussions or comments on this Okay. That Yeah. We have a few people in the queue. So let's start from Alicia. First of all, I think this effort of clarifying concept is very important. Because otherwise, the future would be built on this unstable ground. One thing I'd like to point out, however, I think it's really a good understanding of what is in network computing. Which layer it is. The question you asked, and also what is the end to end principle? I saw you actually have a quote from the e three d paper. But, this is a confusing point. The I think that you quoted from the abstract of paper. But then in the paper, it's just south. The further elaboration, unless statement you just called yet,"
  },
  {
    "startTime": "00:24:02",
    "text": "And that I don't know why it's actually the sticker here. It's on the I remember clearly, it's on the top of page 2. If you go that far, It actually stated that to say that the the functions that we requires the end of knowledge. To do it right. Therefore, providing that questions function as a future as a feature of the communication system itself. Is now the positive one. It's not about just the it's a optimization. It's not possible. Then the quote sometimes as in complete the version, the function provide you the better communication system may be useful of the performance enhancement. But but the fundamentally, you should remember the the sentence before it. Providing that the quantum function in the natural I think in this support, most of you didn't pay enough attention. And, also, I just want to point it up. Application or computation itself. It's at a application level. Is it doesn't mean in network computing means it dragged that app the application level function into the network level. Think we should keep that clear. But the longer discussion. Let's do it later. Yeah. Yeah. So thanks for the Yeah. No. I I Yeah. I suggest that we maybe go through the other question or comments because we are quite a lot of, attempting the agenda. Okay. So Doug, please Hello, Doctor Kutsner, HKUC. Thanks very much for putting this together. A lot of work. I I know. So just, regarding the end to end, discussion. So This is, of course, quite intricate. And, so I agree to, to listen at, this needs to be read carefully and also interpreted carefully. And and I was just thinking"
  },
  {
    "startTime": "00:26:04",
    "text": "one way to make this more productive could be maybe to move a little bit from the high level principles, to to concrete examples and then discuss what we actually want to achieve. And I think one good use case for this could be, this, like, collective communications scenario. And I think the click I can see paper is also talking a little bit about these these issues. And, then end to end, for example, could really mean that you have some assurance and identity in the system, and you know, you know, who's authorized to modify bought and you still have, you know, some some assurance of what's going on without, making it impossible to have this supporting functions in the So in in this direction, I think this discussion could be, made, a little bit more concrete and then have better results, ma'am. Yeah. That also goes online with what I said on the a second to last slide with these key research problems. That question. I see. Yes, Cody. Hi. Colin Perkins. I'm all the rest I'm standing on tip twos, and this one is too low. So, yeah, I think this is really good. I can get it's really an interesting discussion to, to have. And I think trying to work through some of these issues is is critical. You seem to be starting from the basis that we have to confirm to the interim architecture, and you have to conform to the layered model of the way the Antoinette is designed. I'm not sure that's necessarily the right starting of some and given that we are building something which is at least potentially like, distinct from the way the internet works. And I would due to maybe not constrained thinking so much by what what works in the internet"
  },
  {
    "startTime": "00:28:02",
    "text": "think about what might be an alternative way of framing the discussion given that you may end up with a system, which is quite radically different to the internet. Yeah. I mean, that basically boils down to in what scenario you What scenario we wanna use the network computing. So I mean, if if the intention is to have something that we could use on the internet as well, then we kind of have to have these limitations But if we only try to aim at, more closed environments, then it might also be more of a of a greenfield. I I think I'm I'm possibly thinking slightly more fundamentally. And not I'm not thinking internet versus limited domain. I'm thinking internet style protocols versus something which is radically different to the internet. You know, more like the way ICN is potentially radically different and changes the whole model. And and one of the possible outcomes of a of of research in this space is models which fit within the the broad framework of the current internet, and one of the models is something that's so radically different that concepts don't translate. Okay. from Zoom. You got Just responding to to Colin's, last point, there was 66 very nice, networking channel session yesterday afternoon. It unfortunately, in parallel to the tenor. And one guy put it nicely when it comes to the trying to deploy things in the end. And if it doesn't work, we can fix it in the overlay. And so you can always experiment with things if you seek for the appointment in the, in, in the internet and do something overlay style. That shouldn't necessarily be the the fact that you wanna have real growth deployment doesn't necessarily need to constrain the architectural thinking. But, actually, I wanted to make a different point. And And and"
  },
  {
    "startTime": "00:30:02",
    "text": "One of the things that has come up repeatedly in the group, and I believe this also trying to train through your slides, is that we when talking about network computing, we make different be jumping between different levels. You implicitly said at some point packet even though it is by far not clear that a packet is the right level of abstraction, data unit, or whatever to work with, that, of course, has an implication with a state or more or less stateless P4 entity can actually do meaningful things on a on on a packet. Whereas for certain functions, p force, which is to just create, Whereas for others, when we, whenever you need to worry about encryption statefulness, whatever different units would be more appropriate. And so so this kind of conflating whether we are talking about a switch, a router some application layer entity of of some sort of of proxy intermediary or whatever. I think we need to be careful to distill to to disentangle those also across these discussions and make those explicit. Otherwise, we run the risk of always trying to do everything that is usually applicable only to one to one of these different layers or to one of these different elements. And so I That's, I think, one fundamental thing we need to take care of when trying to advance this further in order to make it clear, a distinction have been meaningful things that can work I had some other point which I forgot by now, but maybe this is, you know, Yeah. Thanks for the addition. I agree with that. And we your your web is the last one. So I locked the queue. So please keep it short. Thank you. Hi, Wes Hardaker, ISI. And to back up Colin with one more point, you know, It's hard to think about greenfield type of deployments where you can just forget everything going on in the network, but one One thing to remember is that the internet was created as a network of networks."
  },
  {
    "startTime": "00:32:02",
    "text": "And it started with individual networks that weren't necessarily doing the right thing, right, I remember the early days of coin, and I'm not a coin expert, but there was a good model of of, an explanatory greenhouse type of you know, mechanism where there's lots of stuff in a greenhouse that needs to talk to each other communicate with each other and do computation. I would think in those types of environments, it's like, how do you solve one you know, one set of examples in one network that you can completely destroy and start from scratch. And then later figure out how do we expand this to sort of the the larger internet scale that's easier to think from one small example. Yeah. Thanks. Thank you. Thank you all the comments. Very useful. So I could do would you response in shots general, for the oldest comments, where we move it to, the list offline. Okay. So I kinda had the left. Since that's next to one, how are you? Are you online or in the meeting room? Ma'am, I'm in the room. Okay. Okay. Yep. Good morning, everyone. Thank you for giving me this opportunity to present this work published in this year's CCOM, This is John Work with my colleagues from Chuhai University. Packing University and, the way you Shanghai. This work, named Click Inc, which is about how we will, automate the development and deployment of, inc applications in in a confined network, particularly scenarios, data center network. First, a few caveats here. So, in this context, the ink is a in in academia is a very different from the coin in"
  },
  {
    "startTime": "00:34:02",
    "text": "I e, IT about ARTF. I believe here we are actually the quite RG cover, a lot wider, space but it but for us, there's the ink in that in network computing is a particularly focus on the very, narrow scope that, we are trying to utilize a programmable, switches in the data center network to offload partial application, functions in order to, either, improve the performance, reduce, application latency or reduce, system cost for example, the number of servers required are the power consumptions used So, also in this work, you must see, if you look at paper, it's a covers a lot of boring details, but here, due to the time limit is also that might not be of interest to the group. So I will only, covers of, high level motivations and some ideas and some preliminary results of this. The network is evolving from the function, devices to SDN, for example, the open flow which separates the control plane and the data plane. And eventually, it's in we evolved to a new state that there are many, programmable, deep learning devices which allow us to customize a network, networking functions in nature. And This may include the programmable ASIC, IPGA, network processor, and Mark Nick, all of these different, heterogeneous devices. And, people, researchers start to think about in addition to customized forwarding functions. There might be also possible to, as queues out certain computing functions, in this devices."
  },
  {
    "startTime": "00:36:00",
    "text": "Therefore, they might be able to offload a partial of, application logic you know, those devices, to use this limited computing capability and the memory, or, some tables on the device to accelerate the application. So this actually, lead to the a very hot research area in recent years in academia. Okay. So, if you look at this, conference in this year, there are actually quite a few, related work has been published. Covering the key value store, cash, or the consensus operates and, digital learning, in network aggregation. And the, database query acceleration. Or, this is Durham. Actually many more forks and this cannot be covered as this single page. But however, all all this is just to try to explore the visibilities of using the some program of the y to support such functions Therefore, they are all, usually based on a very simple model to do that, the only consider, for example, only consider a single switch, how they can map the function into this single switch. And the signifying many other things, Lex, and that's what topology next like, if the resource is enough to support the whole function, or, you know, the capabilities, maybe something has to be simplified, or there also need to support the basic, forwarding functions so they make a lot of simplifications on that. I guess that needs to slight So let's see. I can also drive it you know, Okay. So there are many, problems of the those solutions. The first,"
  },
  {
    "startTime": "00:38:02",
    "text": "Our developers actually need, to program their own ink from scratch. That's not the the you already assume there's nothing in the switch. So, but this ink application is strongly coupled with the device. So they have to learn many details about the device on how to program that. And, the the designs are very hard to reuse. And, also, the developer itself also need to be the net need to be the network operator. Because, they need to develop the complete solution cover not only the app patient itself, but also the, actually, the, forwarding networking functions, how you can actually forward the packet to the, to the target servers. And they need to take care many details, like the and parsing on a per set, per hook or handling from layer 3, layer 4, protocols and how to crack correctly deliver the packets in the network. And the sole then the the the the art closely involved in the development, and the network operation. They they see very hard to decouple this two rows. And the the application development itself is very challenging. There are hit genius devices and the complex topologies. And also reliable, resource and the capabilities in devices. So so Actually, the, problem is very daunting. Next slide. So there are many works, but, our related works, for example, the IPDK and Docker, the, trying to unifying the programming interface, particular network, devices like the GPU or, server. However, it can now support the cross device programmable, program, a tritian another work, flight plan, they they they can actually allow users to to to partition a single application and map those"
  },
  {
    "startTime": "00:40:02",
    "text": "parts into different, devices on the packet forwarding path. However, you have to user have to do that manually. It can automate this process. And the lateral form, Eibaba is, also, is a similar high level goal with us. Trying to automate the program partition and map this to the different devices highway, their algorithm is, it's low. If you have a relatively large deployment that will be, very, very slow to achieve that. Also they can now support certain devices like the newly emerging SmartNix. So in this work, clicking, we hard. Try to decouple the, network, operation with the ink application deployment, development. And we also supports the multi tenant applications, try to isolate different applications, in the single device. So we can simultaneously accommodate multiple of them. And we automate the entire process. Next slide. So the concept is, you you may already heard about 3 there's a work about in, ink router and in, no, no, there's a, click router and click MP. So the highlight idea is to make the process simple as simple as possible that it's just a a few, click on the mouse. You'll selects the marginalized, the components, then combine them together. They can form a automated solution. So here, we want to achieve the similar goal and, but we are relying on some critical abstractions with first we consider the entire network as a big, big, big device. We call that one big device abtraction And so it gives a, developer a sense that, they are only dealing dealing with a single device. They just focus on their"
  },
  {
    "startTime": "00:42:04",
    "text": "application logic without worrying about, lower level details like, natural a device capability and the topology. So, we can see all the device and the language, and decouple the network from the e application itself. Then make each ink a program just as a plug in Next slide. So the high level, we use a a Python like language, as a programming language for and we, support 3 different modes. 1st, we build a library of templates. So we should summarize several, several, very important to ink, applications. So, users can just use this template to quickly, instantiate sun incapication. And also, they can also use, the this templates as some more more modular components. Are in the library, we can build their own, Applications, from based on this templates. And, also allow user to actually just, from program from scratch. They can just, do their, customized functions is also possible. Next slide. So the high level, architecture is like this. So we first developed as a, program using the language and you mentioned before. Then we have a a front end, the compiler, the competitor basically, compose that converts the program into the intermediate representative. And, Then next step, we'll, just, consider, available resource and that for apology and the capability of the devices, the many countries consider the same became map the program into the devices."
  },
  {
    "startTime": "00:44:00",
    "text": "It's possible we need to partition the single application into multiple devices. So of this is done in this, in this step. We need to consider many constraint also minimize, the partition cost And after that, we, we, you know, which part the program map to which devices. After we have that, for each, snippet of the program video, have its own target devices, then we will use real converts. The program into the target device language, then maybe use the target devices a compiler to further program this device. Into the target into the target executable file. So after that, we we can't we finish the deployment of the entire program. Next slide. So, I may want, due to the time I may want the keeps this present. But the key point here is, previously you're you're already the critical part of this is that actually maps, how we can map the entire program into the different devices. So, you really, mess we use the ILP or SMT type of a risk, server to solve this this, compliance program. However, if, we can see there's a network, a relatively large network y'all. These masters are very slow. So for example, the Lara user SMT Solar to to solve the problem, then, the performance is not good. But for us, we the dynamic programming based algorithms to, simplify the the mapping process and we, we can achieve the similar result, Alexa SMT. But, it's much, much faster on a large scale network. Next slide."
  },
  {
    "startTime": "00:46:00",
    "text": "So, yeah, this, this slide just show a little bit more details how we abstract of the the entire program into a, instruction based, the graph. Than based on the graph and the, the the device, type on the, on the, on the forwarding pass, then it became partition scrap layer on the layer based partitions, then you can map each party into a different devices. So We also annotate each, each ink application. So this annotation is, carried with the designs and, which can be used to, to allow us to remove a certain, in application. When we raise and no longer need it. So we can release the resource for other applications. Next, please. So we use a No. Please conclude quite quickly. People in the queue. Okay. Have a software based emulator. We use several behavior models based on for Tofino, Tritriding for an IPG, to map it into a factory based, data center. And we also have a a several physical switch devices, to build a test bed that Slice So the, experiment results show that we can actually, fully utilize a different, resource in different devices. And our, programming, you can see for different applications, we use much shorter, a fewer lines of code to describe the entire application compared with using other languages. And also, our dynamic programming mapping program allows to achieve the similar, performance as a result as M SMT, but with much shorter time. Next slide. So you can see, we have achieved a much better scalability is a very large, topology. You can, the"
  },
  {
    "startTime": "00:48:01",
    "text": "performance is a linear increase, but, if you use as, I'm Ahmatisse, time increase exponentially. We also demonstrate how we can do the incremental deployment for searches that help application 1 by 1. Thanks. So, yeah, maybe you can read this slides and, I mean, So any questions? Yeah. Doug, please. Yeah. Doctor Kocheraj, thank you very much for bringing this work to us. So this group has been say, discussing or had, like, a malaria, like, a creative tension in between say, distible computing concepts and then, trying to leverage programming with a data plane, like before. Yes. And, also in the light of this end to end discussion, it was always quite interesting to see it. So how could we make productive use of of, these facilities And so the the one big device abstraction is a kind of interesting way of dealing with it. One question. So, what's the failure model for for the system. So, what happens if something goes wrong at run time. Do you have a concept for that? What was the, what's the failure? Failure model. That's a a good question. We that that will be the future work. Actually, we now have a some, we we always assume the regular topology and, so if it does consider the video model, yeah, that's a good question. And also we have a we we consider there's a comment base forwarding program. So, therefore, we can couple of the forwarding is a function itself. So in the, entire working flow. Last step actually It said, involve how we merge this app, ink functions to the base forwarding functions. So the that, program developer doesn't need to worry about how how did the packet actually forward it?"
  },
  {
    "startTime": "00:50:04",
    "text": "Yeah, Alicia, please. Alicia Chung from UCLA. I think it's an interesting idea about the treating the whole network at the shipper device. So that you can perform optimization. Related question is that is this, privately owned the network, and therefore, you have no security considerations. Yeah. We assume this is only, meaningful, you know, very Finance for, for example, the data center are owned by a single owner. So but they can, you know, use a resource, a server resource, a natural resource tool. Simultaneous support different applications. I agree that with that can fund the environment. This is, you know, greater optimization, but that assumption probably should be stated with a big fund Yeah. To make people understand the scope of the work. Yes. Thank you. Thank you. How how are you? Let's move to the next one. Yeah. And it should work. Yeah. Thank you Yep. So, good morning, everyone. I'm from Technical University of Denmark. So, I'm a fun final year PhD student at supervised by Professor Law Statement And it's my pleasure to be here to share the a work prepared in network analysis for smart IoT gateways. And, this work was done when I was a visiting PhD student, at the research group that by professor Noah Zuberman, So it is a joint work together with Changal, Lars, and Noah. So Yep. So last year, during the call NRT session in London, our colleague, Changan, has shared,"
  },
  {
    "startTime": "00:52:00",
    "text": "practices and lessons learned from the in network classification. So the core idea of in network classification is to offload the, machine learning inference to the programmable network devices. So it can train, map a trained machine learning model, to the programmable network devices. So it is the internet for machine learning. Infraced concept as introduced by, Doctor. So in previous presentation, So last year, Changan has introduced, 2 representative work easy planter. So, Pender gives this, rapid prototyping framework solutions, to, lower down the bar to develop this in network classification. Design, So so far, it supports more than 11 machine learning models, including the 15 variants depending on the resource constraints and the devices. And it can also be run on multiple hardware targets such as the programmable switches, a PDA, GPUs, and so on. So in this case, we have seen that it can achieve line rate performance as well as the, brought to, services such as the, security analysis and all the tick detection and so on. So Starting from there, we were wondering if we can utilize this machine learning in network machine learning capability, other scenarios, So then we start to think about the IoT scenarios Oh, sorry. Yeah. So the in IoT scenarios are One of the motivation is that this year's we have seen an increasing interest and study on, utilizing the, machine learning capability for data analysis in IoT Networks. So though we started to wonder how in network classification can bring any benefits to this kind of, services. So a little bit background here is that"
  },
  {
    "startTime": "00:54:04",
    "text": "So this year, as we have seen the best development of 5 g, And even the upcoming 60, So 5 g, in 5 g, there is, requirements about the ultra reliable low latency, communication. So specifically, it requires the performance, in different IoT use cases, such as in industrial, process automation. This kind of service will require the low latency. Lower than the 15 milliseconds So that means we also need some, advanced analysis and monitoring solutions for, to adapt to this kind of low latency requirements. And also at the same time, we have seen an increasing concern on the IoT security. And, we have seen that the attacks are, evolving and, with union patterns, still silly. So that raises emergent, attack barriers and poses the threat to the network infrastructure, And meanwhile, on the user side, this, IoT devices quite distributed was the limited contributing resources So that indicates the lack of, security matters. So that leads to the question we want to ask here. So combining all these factors, we have seen the fastest spreading dress with the training patterns and AI 2 networks. So can, in network panel classification do something for it? So Well, if we want to utilize the machine learning capability, One of the typical solution is that we can deploy this machine learning based analysis in the cloud, so it can, utilize the abundant, reach resources on on the cloud to give a advanced analysis and analyze the complicated attacks but it it is also limited in fast reaction. So"
  },
  {
    "startTime": "00:56:00",
    "text": "That is what we are bringing this in network classification solution, So what's the in network classification capability we can offload the machine learning inference process from the cloud to the, IoT edge in this case, we can, analyze the traffic at the time when they arrived at the edge devices, and decide whether they are malicious or benign and decide whether we would forward it or not So in this case, we can achieve a festive mitigation. So but when we are during our development of this idea, we have met 3 main design challenges. So firstly is the, can we achieve this function on cheap IoT gateway devices. Because the prior work mainly focuses on the performance on the high performance devices So but in IoT Networks, most of the devices they are quite cheap with, limited resources And the second issue is, we also have seen the needs of round the clock security operation in IoT Networks, So can we support a continuous defense or a continuous model, based analysis towards this emergent arrest And thirdly is this distributed deployment on the on the IOT edge. So I will introduce our solutions 1 by 1. So for the regarding the first two challenges we present our, solution So it achieves the, real time traffic analysis. Introducing the in network classification, into the IoT gateway. So, we prototype our work on a respite and it's based on this public platform. So it runs the p 4 based, platform inside the raspberry pi. And, so In this case, we think of we thought about the resources are quite risk constrained."
  },
  {
    "startTime": "00:58:03",
    "text": "So we utilize the 3 best machine learning model inside this, prototype to lower down the, resource resource consumption and, given this Our network deployment. And, so the graph on the right corner presents general overview of the workflow of this popularity line. So it forms a closed loop and, involves 3 main components. Attack defender, log labeler and model So model mapping is the one that maps the stream based model into the data plane. And it's based on the fender. And the attack defender is the one mainly plays the role here to achieve the, a network analysis and mitigation And we also have the log labeling here, mainly for a runtime model updates. So it actually enables those continuous designs. So A little bit more details about this design. So we try to, see whether we can achieve it at runtime specifically for the IoT gateway scenario because we want to avoid function recopulation, lower down the maintenance overhead So in that case, we introduced the digest based logging method. And also we introduced supervised based, labeler to proactively labeling the connected records and also trigger their model retraining process. So, also, when we get this remapped model, found another issue that, when we try to enter this model, into the data planning at runtime, it somehow disrupt the, forwarding process. So then we introduce this, shadow table updates to, enable the hit list, remapping and insertion of the regenerated table rows,"
  },
  {
    "startTime": "01:00:00",
    "text": "and, table models. So That is the basic idea of the Papier. And, besides the prototype on Yep. Beside the birth of that, respire pie, we also have it run on the a real gateway. And, we utilize the public data set to evaluate our solutions. And it it verifies that our solution can increase the, see on emerging attacks and also achieved the sub millisecond mitigation performance And we also are evaluated on it, about the overhead it brought to the Raspberry Pi and it shows that it gives negligible data, and only 88% on the CPU utilization. And so, so far, all this this popular solution is based on the single device deployment. But in IoT scenario, devices are deployed and, distributed by So with an introduce the, Fleet 4. So to explore how the solution can be set scalable to, distribute this scenario So in this case, we deployed the Papier and, also, which is the in network classification. And the distributed gateway scenarios. And we introduced the federated idea to manage the model training and update process among the disreputed notes So, with this Federated idea, we can not only share and, coordinate this model updates, but also it can give this, model sharing process in, relatively pressing for the ringway. And the right corner presents, per our preliminary valuation, and it shows that this design gives the,"
  },
  {
    "startTime": "01:02:00",
    "text": "accurate performance with the, relatively low communication overhead. So Yeah. To give a summary? In this, work, we want to illustrate that the in network classification can also bring benefits to the IoT scenario. And, it is feasible on the cheap IoT gateway devices. And, due to our design and due to the introduction of the in network classification it can, give this, swift analysis towards a merging attacks and, react efficiently towards the against this detected incidents And also with this free for idea, it can be scalable to distributed devices, and we are still exploring more details about it. For further work, we are trying to, study how to optimized our resources on the chip devices and also we are trying to enable more services And, if you're interested in this work, you are very welcome to scan this QR code. So to access or to our open source solutions and we are actively maintaining that. So lastly, we list our works here. Yeah. Yeah. Thank you. We'll start work here. So, and we want to we would like to acknowledge the founding and our, and our colleagues for their support. And that's pretty about the sharing today. Thank you very much, and I'm happy to take any comments and questions. Durkoto, actually, you'll see. Thanks very much. So, just to categorize this, so in the taxonomy of things, we are discussing here This seems to be like, a traditional, like, in network function, like, and so on. So question on your work what is the assumption on the traffic that you are analyzing with respect"
  },
  {
    "startTime": "01:04:02",
    "text": "to encryption, for example. Yeah. Thank you for this question. So it's a very good one. So because, in our scenario and in our gateway, we are assuming that due to the consideration of the power consumption Oh, the traffic is in plain text. So, they are not configured with a very strong encryption strategy. So in this case, we can pass more information than we want. And it would enable a better performance. Thanks. Thank you. Yeah. Alicia, please. By the way, it's not me. That's the newcomer I've created for her. Hello, everyone. I'm sorry for about this because find the the right tools. So, my name is, I am from Umizia. I am new cameras to IETF program. I want to thank you so much for this great presentation. And I want to know if you have evaluated the energy consumption in your scenario. Yeah. Thank you very much for this question. So we didn't directly, test the energy consumption because, when we try to test it, we find the the change is very hard to, make distinguish So we used the CPU utilization and temperature to, partially reflect the power consumption, metric. Thank you. If there has no further questions or comments, let's move the next one. Thank you, Ming Minga. Thank you. So let's start with the draft update from Yong"
  },
  {
    "startTime": "01:06:01",
    "text": "It's very Good morning. This is from. And this draft is about the use case analysis for computing in the network, and I have been presented at, last meeting in San Francisco to and This is the reminder that I have interested about this the the the status of the drop. So, the leader of the drop has has changed it to me And then we, at the last time, we proposed to change title, from the use case analysis to the child resource challenge of competing in the network. And, also, we plan to make the scope of the trap broader and were generalized according to the new title unfortunately, we haven't updated and submit to for this meeting, but, what we would like to do is we have collected, quite a number of the new research challenges So we I present today and I would like to get the feedback from the floor. And then we reflect a comment to the draft. So we decided to, update the dropped her later on. So according to the new title. We kinda delete the chapter 3, which was the point use case taxonomy. I think we did this is not needed anymore."
  },
  {
    "startTime": "01:08:02",
    "text": "And then, the requirement as well, we try to focus on the research challenging in this draft. So but we keep the opportunities for coin. And then research questions from the coin use case, this has been done already. So we'll keep that. And then the that that session 5, the research channels will be the provided usually in this trap later. And before I pre provide the research challenged the least we categorize the resource challenge in and and like, a 7 category, So here, we have this table shows the main category as well as the self category, and the way the description and also the challenges they will present in the later we we aligned to the all the number of the challenges to the this category. So well, to go over more detail about the challenges, research challenges on the go through details in this table, but just briefly take a look, the, read the category, what we have, here is the first one is the coin fundamental And the second one is the enabler, to tackle key operational challenges And the third one the liability and robustness and then the security and privacy and ethics Yes. If if And then, we have we'll have the interoperability and legacy integration."
  },
  {
    "startTime": "01:10:02",
    "text": "And then the last one is economics and business perspectives, and it's like And I'll we have, like, a 16 business challenges in this presentation. So please read the challenge the carefully and then give us some feedback about it. So the first one is a heterogeneous network software So, how can coin solution capital to the network with a mix competition, the capability at, how can they ensure the consistent performance? And the second is the, dynamic resource or location so how can we decide which test compute, and which one, has to be forward And then the security and privacy concern is the how do we ensure the data security especially when some come, computations are uploaded to intermediate low that might may not be fully trusted and then, optimize the data transfer is the how can you design the protein call, they decide the optimal location for computation versus the simple data transport. The Thank you. And state management is a when computational functions are executed inside the network. The man is in the state, become a challenge, so how can stay for competitions we maintained and, migrate it or restore the after this disruptions. And then the programming abstraction. Is the, the coin needs a novel programming model,"
  },
  {
    "startTime": "01:12:04",
    "text": "that allows the, developer to specify where and how their application logics should run within the network. And then the latency concern which is the coin reduces the latency because the computation can happen closer to the beta source, but, introducing the computation within the network, can also increase the latency if it is not managed to properly. So, it needs to determine the balance and identify the use case of the world's latency policies can maximize. And then the 1st tolerance and reliability and introducing the competition and let them know that requires a new strategy for the both tone tolerance. So how do we handle the mood failure as especially including an active competition. And how can we ensure the data in teagerty, and reliability in such scenarios. X Lite And then the, in October, will it be an standardization there will be a need for standard call and interfaces and the practices that each sure the seamless interoperability between different vendors and devices. And then the load balancing is with the coin, the net note will not just the handler to data, but also computation tests. So it, the the computational task needs to be evenly distributed and no node becomes a bottleneck due to the computational overhead And then the energy efficiency, the implementing compute patient at every new"
  },
  {
    "startTime": "01:14:00",
    "text": "that will know, you can increase the energy consumption So it needs to find the efficient algorithm and hardware solutions to keep the energy cost minimum. And then scalability it needs to ensure that the coin can scale efficiently without compromising performance or increasing the complex fee becomes the it's complexity. It needs to be a scalable in both in terms of the network size and the demand. And migration and flexibility. Given the dynamic nature of the that will go. There could be a scenario where a active temptation might need to be. Migrated from one to another node. So how can this be achieved seamlessly without the data goals or succeed with latency. And then, economic and business model, how do we model the cost associated with the coin? So how do ISPs and, cloud pro providers, bill, their customers when computation is distributed across the network. And then the evaluation metrics and patchmarks, the extender the benchmark and evaluation metrics be needing to gauge the performance efficiency and suitable, suitability of the coin solution for various applications. And the last one is integration with the legacy system. So the, how how can the legacy system can be in integrated or the upgraded to the support to coin without significant"
  },
  {
    "startTime": "01:16:00",
    "text": "traction or coast. Mixed Yeah. This is all we have collected so far. Please give us a comment about the resources And then we'll we'll get the comment and we reflect the comment toward the trapped. So we'll submit the trap as a new version. Yes. Comments? Yep. Thank you. So, looking at the four slides of the research challenges that you just outlined, they appear to be very generic in the sense of being applicable to essentially every system you could possibly construct. And now you had a, you started out with the statement that you have been broadening the scope, and I'm I'm wondering whether this is actually a very use full exercise or, helpful in getting actually concise and, reasonable document ever finished. We have been usually pretty good at working with rather tightly scope documents in order to wrap up the respective work for something as big as a bit the risk of going to boil the ocean in this one because you never might know when you are really finished And so, all these vague statements about, research challenges that again could be applied to any distributed system maybe an indicator that the scope is too broad. So I think it's worthwhile to have a discussion on how much scope there should actually be. In order to have this a fair chance to get it to completion at some point. At the moment, I I see this going way overboard. Yeah. Thank you. Like, I understood, and I will try to and worse split try to to more specific way or make his little doll. Thank you."
  },
  {
    "startTime": "01:18:01",
    "text": "Rolling plus KIT. Just a quick comment to with respect to the reliability that also comes back to the end to end argument. I mean, one of the consequences of the end to end argument is that you If you have less functionality inside the network, the more robust it is because there's things can break. And so here, I was missing an aspect like what about isolation? I mean, if you put functionality inside the network. Things get more fragile. Potentially, if you have side effects that one computation of function maybe has Things fail has side effects. On others. And so that kind of how can you achieve the isolation is potentially also research question. That comes back to the the end to end argument effect. Looks Well, we'll consider as a challenge your comment Yeah. Thank you for providing such a comprehensive list of challenges. They are very real one. The useful, but, I my feeling is that it's a little bit less structured. Many of them, as I can see, they are actually closer related or maybe either relationship with them. So it, my suggestions is better to organize these different challenges, the grouping them, be on different categories that can help us better understand that. And also, as you said, the first commands that the the maybe, the use cases and then the the scope is too broad now. So maybe different, know, a speck of this, problem space may face different, challenges. So it's better to, you know, again, maybe we can have a classification on the different use cases. And so we have have a fixed set of scenarios and for each"
  },
  {
    "startTime": "01:20:01",
    "text": "scenario, maybe have its unique set of challenges. So if we have this kind of organization, that will help us better understand this problem of scope. Thank you. Yeah. Thank you. Your comment for the first a comment that actually, we have the the categories and show the table. Yeah. I haven't discussed the provided to details about the this categories but but what was we dropped we update the draft, the the all the the tells will be described under the certain categories. So it will be grouped. And then for the second one, also, I already reply that, will it consider make the scope narrow down later. Thank you. So, Diego, you will be the last one. Okay. Okay. Perfect. From my side. No. It's a it's a compliment in the same that, Gerald was mentioning before that this horse mean, the the the definition of this many of the problems as it were shown there, we're very much general problems for these heated systems. Probably here, and I would say that see as a suggestion of how you can focus on this. And something that came to my mind. For example, you were talking about, load balancing is more than is about, how to explore a convergence different techniques because right now, you have load balancing in in cloud in cloud environments and you have long balancing in the network. How they can be combined and or integrated because it's not that we had to invent a new mechanism for low balance. That we we should be able to integrate them and make them consistent. Just a just an example. So probably is is about these convergence or or alignment of them trying to identify"
  },
  {
    "startTime": "01:22:01",
    "text": "which are the challenges for aligning them, not that the general challenge, but the challenge of the current solutions that we have right now for the network that we have right now for the generally distributed computing and how they can be mixed. Just as a as an idea. Okay. Thank you. I think that they, the time It's not you know, to, to talk about it. So I I just gave the line of the what we are, try to think about the challenges. That's how I think of how it look. It looks to general things today. I think maybe next time we'll we'll bring we update the houses some more specifically to discuss. Thank you. Thank you. And let's Go to the next one there. Okay. Thank you, good morning. So this is, joined work with, Jacob and, Timo Packing. And, so earlier, today. So Colin, alluded to the the concept or the idea that, so coin could also take, say, more so so fundamental perspective on what computing in the network, means and maybe doesn't have to be so much constrained. To say existing, say, concepts or business models that are often floating around. And, so interestingly when this group was formed, 2 years ago, there was a discussion, how should this actually be named? So, like, in network computing was a popular term at the time, and I hope you also solar to date. And it was, Dave O'Ran at the time who made the proposal. To actually call this computing in the network so, like, this slightly subtle, difference name, different name."
  },
  {
    "startTime": "01:24:00",
    "text": "To express, the idea that this is not just about you know, the traditional concepts of, connecting, compute servers. So, like, you do an edge computing or just normal client server, settings and so on. So the idea was to, So have a scope that includes distable computing concepts, network data plan, probability and then try to figure out, how these different words could fit together. This is a little bit the spirit of, this draft here. And, and so it hasn't been presented here for some, some time. And, so let me just run you through, the the whole structure and give you some idea what this is about. So we have already seen today that in network computing can be conceived in many different ways. So, very old concepts like active networking. We have seen today, data plan, preliminary, running which those functions things like service chaining. So lean more like mechanistic things that, are been done in the IETF, but also, general distal computing. And so this this draft tries to kind of make some sense out of this. I'm not saying we have succeeded yet, but, we try to propose, so a direction also capturing the discussion that been going on so far. And, so lists some, say more researchy research questions, as well. Next slide, please. Okay. So we are, talking about these different types of network computing systems and trying to, disentangle, a little bit. So, I can make it clear what is actually what, what is the difference and so on. So there's a bit of a terminology part, as well. And, then there's a section that tries to characterize, So"
  },
  {
    "startTime": "01:26:01",
    "text": "like these, like, main strengths. So computing in the network? Or is this packet processing? Or is this network computing okay? Mentioned earlier. And then just trying to illustrate this with a few examples. And then in the end, we we distilling kind of shortfall but not very shortlist of challenges. So, yeah, this is a, problem that I'm I had to know the meetings, and to take out, I don't really want okay. So, yeah, the different types inevereignty Systems, So active networking, edge computing, data frame probability, say, application layer, data processing frameworks and things like It's Phyllis Jamie. So in network computing, what we are typically doing is we're using just networking to connect to compute instances. So that could be, Execution environments, VMs, microservice instances, and so on. And so quite often there's some some kind of interaction types on top of a black box network model. So, like, RBC, RESTful communication, and so on. So we know CDNs who could got could probably easily fall into this category. So from our perspective, this is not really computing in that purpose. It's just plain old connected computing. So we we are using this every day. So packet processing, that refers to, where basically middle boxes or maybe the IoT security gateway that we earlier thoughts into this category. So, like, transparent middle boxes that, apply some processing on the packets so here we, it was more like the packet inspection. You could also imagine some transformation, in, in some scenarios."
  },
  {
    "startTime": "01:28:00",
    "text": "Of course, quite often this is ignoring security and, like data provenance and so on. And, active networking, could maybe be seen as an abstraction. So for programming this packet processing from an endpoint perspective. So programming processing then later, down the the path, also think of. And contrasting this with data plane programming. So, we have like, seen examples. So these are, like, extractions of different types of network switch hardware, typically, or I will say that network hardware, in general. From, from, more like a switch or network probing perspective. And, So the challenge that they click, I IMC work also had that was that the programs that you can actually create, they are, very much constrained when the capabilities of those platforms. So limited instructions have limited memory And so typically what you have there is things that operate on flow up sections of individual packets and, so yeah, basically doing things like natural action style processing. And so this is, of course, very interesting and can be put to use, for example, with this, like one, one big, system extraction that we saw. But the challenge here is also in distillate computing systems Normally, the units, of communication are not packet. Right? So you have more, like, application data units. If you're, yeah, in food security, then encryption or, say authenticity functions, then then this becomes very hard for these systems to do a, a useful, job here. So, one challenge or one, I think, yeah, one interesting challenge in our work here."
  },
  {
    "startTime": "01:30:01",
    "text": "We think is, making productive use of this kind of really powerful, but really low layer platforms. In the ATF, people have a lot of experience with network functions virtualization. So this is just network computing applied to telco functions, put bluntly. And some of these functions, they two things that processing and forwarding packets. And then you could maybe steer the forwarding these things like software defined networking and so on. Next up. Okay. And then service Sunshine is maybe a more dynamic way of just steering the traffic in, in those, system and implemented by encapsulation. And so now comparing all of these things, So sometimes network computing and packet processing also go where together. So, for example, in, network utilization you can achieve through data plan, programming, and to provide connectivity between VMs there are things like Etsy, multi access edge computing, a network by saying in this category. But this, again, this is not really, computing in the network, in our enormite. So what we think is quite interesting So earlier, how you made the statement that in academia, in network computing has a very so a limited focus or, like, specific focus on this data plan for unfamiliar things, that's of course only one part of a good email. There's another part of a good email that is more computer science or distillate computing oriented. And they are looking more at these problems, right? So the eyes a range of very successful application layer, this is the computing systems. Also in, like machine learning, training, and so on. And These are, quite elaborate when it comes to"
  },
  {
    "startTime": "01:32:01",
    "text": "programming models, abstractions for that, and so on. But they could also really benefit from a much better support and better integration, in the network. And I think that this is an interesting question. So how could the network support such systems better. So this could be seen as a resource allocation problem you could think about, joint resource optimization computing, networking, and caching and so on. And we had been discussing this a little bit, in this, draft. There's one section that, then explains a few examples that we picked. This is maybe a little bit eclectic at the moment. But so we picked one system that we developed, earlier computing computer first networking ICN, which takes a really different perspectives. So fully decentralized, computing framework, tooling complete, based on, on on ice So a bit what colin also alluded to earlier, and then we'll be compared this or a list of a few other things that people may be more familiar with. Like, actual model things, stream processing and also talked a bit about art. This little machine learning, which is also quite interesting. From a, computing in a network perspective. And then finally, I, I don't have time to go through this, but, so we are we are picking some challenges, but we think are relevant for for research And, so let's let me not read this to you, but if you enter us a piece of it, if I close a look and tell us if anything, is missing. And then as next steps, what we think could be useful, so this this week there is a discussion on collective communications. And so, that's like, one communication, approach in machine learning training. And we talked about this a little bit, but we think that this could be more specific"
  },
  {
    "startTime": "01:34:01",
    "text": "And, so later there is a draft presentation on transport abstractions. This could also tie in to this discussion. That's, our into the next steps. From a maturity level perspective, we think this will probably need a few more iterations. So our goal is to capture the discussion that's going on here in the group. So, we will probably see this a few more, meetings. Thank you. Yeah. Hi. Hi, Concho. Thanks for the work I've had a look at it off as well, so I like your angle there. One question that came to my mind, especially given maybe my first presentation today and also the, use case of former use case analysis draft is how we actually make this not a, battle on different fronts where we come to or basically do stuff at the same time that we could join together and how we actually make this a joint effort where we can make the best of every angle that we have here Yeah. Things, I had the same thought when I saw the earlier presentation that's definitely something that we should, talk about maybe we can find some time, in this week even or on could be also for an interim meeting. I think we have several things that are somewhat touching on say, related areas. And, this is, it's not a problem because these things have been developed in Paris somehow. But, I mean, now maybe the good, time to which which which reconciliation these things, Yeah. Let's talk. Yeah. Alex, Claire. I think so. So one comment that I would have. I think there are a lot of things that we could do, and there are a lot of potential challenges and supports, which are there. But one thing that I'm missing a little bit is the why? Right? What are the problems that we want to ultimately solve with this? That you cannot solve"
  },
  {
    "startTime": "01:36:03",
    "text": "well, basically with with autism, I think, probably maybe true to orient and, taking some of those research challenges better, it try to, to, to, extract, actually, some of those problems. And then when you look at solution for this whole, that we don't look at it, that just points on sake. Right. So, I mean, I, I did a bad job in expanding this year. In the example this is section we, try to motivate, this, we could do a better job. And We'll look at it. Thank you. Yeah. Maybe. David Drew from Huawei Technologies. Thanks for your presentation. It indeed is very interesting. Especially I'm looking at your next steps want to address the collective communication, parts. I don't know whether, you know, we have a site meeting with someone about collective communication optimization. Where, we will also present, one of our drafts called the signaling, in now computing, we tried to address that as well. So we may discuss about it. That's, and I'm also interested in your direction, maybe we can talk about it at all. Discuss for the new transport for the correct. Yes. That's at, 3 pm this afternoon. Yes. 2:30. Poppy. Okay. Thank you. Okay. Jeffrey from a city in the University of Hong Kong So it's not my, Jia had So I have to, one comment and that's the other question, if actually the the comedy is about the communication, collective communication in this slide So"
  },
  {
    "startTime": "01:38:00",
    "text": "in my view, collective communication is not more specific about more genetics than machine translation because it's a basic function can support many distribution applications at the supercomputing and, aggregation function is just one of the communication, collective communication if we look at the definition of collect communication in the HPC community. That's my comment on this. And, is that. So you mentioned, at the beginning of your slide, you mentioned that you will propose particular direction for coin. But, the name of your jobs at elections So I'm wondering if you are trying to you are planning to explore alternative delegations, or we or you stick to one specific direction. Thank you. That's a tough tough one. So, yeah, Well, the the idea really was to kind of, kind of set a scope for the the work in this group And, so we think, of course, the more we can narrow this down, the better I would say we are not yet quite yet at this stage, but, I think there is now an emerging better understanding what what the original contribution of this, root could be So, it would, I mean, we we are not nearly finished, but we we think, this draft could, could make could kind of characterize, the problems and, know, make make a understandable, description of the research problem and, say the challenges that, it includes of course, they are still different perspectives. Like, some people coming more from a data same remedy, world, So it's probably not"
  },
  {
    "startTime": "01:40:01",
    "text": "very wise to try to really have, like, the one unified, view of of doing things, but at least, you know, making it a little bit more, concrete and a little bit more narrow. Like, that's a lot go I admit that I didn't read your draft but that I really enjoyed this presentation. I think it's really important to clarify the concept and the definitions. That's very first step towards a great work. Didn't read before, but I will read up their draft afterwards and hope I can and get some, comments in Yeah. That would be highly appreciated. Thank you. Okay. So if there are no further questions, estank, duck, Next one. I'll call you again. Thank you. In this, talk, I will introduce, a new drop. Talk about a requirement for a general transport protocol for a specific site of, in natural applications. Next slide, please. So, still in the narrow sense of, ink, we are talking about how to use programmable switch, to accelerate the applications. If we take closer, Luke has a current very promising, applications which in that for aggregation, cashing agreement. They all follow a same, pattern can call that remote procedure call if you move up the a standard view, send a single packet, with a message. And expect there's some reply from the server, to, also has a single packet to get the result back."
  },
  {
    "startTime": "01:42:02",
    "text": "So, is this, the the computing can be solely or partially done by the network devices, in the network. And the results can also be replied from the device or from the and the server. So, but they all follow the similar, application pattern. Next slide. But, but, apparently, first thing we can observe is that it's 3, bricks, end to end the pre cyclical ops transport protocol because, even in the network, we need to, touch the packet payload So we need to, at least, cross the transport layer to reach the application layer data. So this, we can see this is the new end to mid point to end rather than the pure end to end model. So we somehow need to support that. And to transport later. Next slide. And we also have some, classification on the different, in service model and also the communication pattern. For the model, we have the device only model, which means the entire computers down in the network devices without involving the server. So we call that device only. Also, the the the drop can be joined, joined today down by the device and, the server. And the final result is only returned from the server. We call that, device and server model. And finally, there's a hybrid hybrid model, which means So also the packet will be sent, through the Internet devices and reach the final, destination server. However, the the result can be either returned from switch or from the server. So that's all possible depending on if the epic, the the computing can be done in speech or it can be partially done. On the other hand, we have different communication patterns. For example,"
  },
  {
    "startTime": "01:44:04",
    "text": "The first one, we call that sync, synchronize the, collaboration, of, you you can imagine, they said, including the collective communication patterns, which need the other, join workers to synchronize their, request. On the other hand, there's other application like the map reduce. The, actually doesn't require the, strict synchronization between the workers So we call that asynchronous collaboration. And, finally, some other application next key value store, caching, we call that. Is this just a the individual requirement, request query from the one server to another. Query server, so it doesn't need a collaboration between multiple workers. So we call that, individual request. So we can see in this, table, we have some crossing that, that's based on the some existing, solutions. They actually take this kind of a combination to, to to combine it different service model and different community communication pattern. However, they all follow the same, like I said, same remote procedure call, like, application pattern. Next slide. So, yeah, but they all share some I should share some common transport layer services. If we don't have this, unified transport solution that we will end up with customized design for each liberal application. That's gonna be not very efficient. So that's about better summarize all the common service and the transport layer and provide such a unified design that can be shared by different, applications. So that's my be, that'll be ideal. Next. I already, in the draft, a survey on the, all the different, different kind up, transport later protocols."
  },
  {
    "startTime": "01:46:04",
    "text": "And none of them actually meets the requirement, in this scenario. So we do need to consider having new design Thanks. So the share, the the new design should meet the call me requirement like simplicity, general, or morality and, openness and compatibility, Next. So the purpose of drop is just, simply risk the community awareness of the problem and, help us to understand is the problem is space and try to explore the opportunities, a collaboration, I'll I'll be okay. This start to think about the possibility. Thank you. Yep. Stark, please. Yeah. Thanks. Good call. The question is, of course, how to do it right? And, So just a question to you. In in some of the discussions we had. So for example, on collective communications, one concern that people had is that well, this idea of having the network, so helping you with say, aggregation or something, It does not really work in the presence of connection oriented communication. Mhmm. So, that seems to suggest that a more data oriented which could be useful what you agree. Yeah. Yeah. So as I said, even for this, kind of a clap, communication. It's also for the it's a RPC Lex. It's like know, servers, the workers have sent a single packet own message and then get a single packet back. So so that's a that's a note of streaming service. If it's streaming service, the problem is much more complex. But we do have sessions Right? You have a job and involve a lot of workers, but the or standard individual packets. The difference is some of them need some some"
  },
  {
    "startTime": "01:48:04",
    "text": "synchronize, work, but some some just for the individual requests. But still they share the common RPC led communication pattern. So I think in this sense, it might have a a single, transport layer protocol can actually satisfy other requirements. Yeah. I'm afraid we have to keep the discussion shot. Just click that quickly. So you keep mentioning the word packet. Do you think that's the good structure for for these protocols, I mean, because typically, we are talking about application data units, that could be several packets and so on. So what is the level or layout, which this rental protocol should operate in your Sure. I I do quite a transport layer is a apparently, it's above the network layer and below the application layer. It's a some common surveys like guarantee the, congestion control. Packet loss, recovery and, also maintain the fairness between the different sessions. So I think that those are common services should be done at this later. Okay. Let let's talk about that. Oh, yeah. Maybe talk offline. Hi. Colin Perkins. Think that your last comment there gets to to the heart of my concern here. You're approaching the transport layer In the way it is designed for the internet, within that work computation, I don't think we have the same model anymore. And I don't think the the model of a connection oriented transport between 2 endpoints. Which provides a bunch of reliability and rate adaptation and that's thing is necessarily the right model for thinking about systems with in network computation. It would urge you to think more broadly about the possibilities. Mhmm. Okay. Yeah. Yeah. In in my thinking that's, might not be, connection oriented."
  },
  {
    "startTime": "01:50:02",
    "text": "Protocol that that will be very hard to achieve, but, fortunately for this, kind of, this they set off, applications or maybe the connection. Yes. Maybe, no, sorry. But let's keep the discussion very short so that and move further discussion in the list. Alright. I could please Yeah. Hi. Hi, Gunther. Just a few pointers. So we had a draft in this group a few years back. On transport issues. So and I guess a few of your issues were already customer. Yeah. Yes. I'm I'm aware of those jobs that it's, yeah, we're talking about a a similar issue and, yep, I, you know, maybe we have have more discussion on that. And the second pointer, I think there are already also some treat proposals regarding Chen's book or transport like protocols for in network computing. So I can remember a April last year at the I can't remember the conference right now, but I will get to you after upwards. Thanks. Thank you. I thank you. How are you? Let's move on. Carlos. Okay. Thanks. I'm Carlos. I'm presenting this on behalf of my co authors. I'll try to be very, very brief So next slide, please. So this is just an evolution of, document that, is already published as an RFC was the the result of, another IRTS. Working group, which is cognitive layer architecture for software defined networking class. We propose a layer, control architecture where we have different strata And on each of this strata, we have different, different planes. Originally in class, we have, what we call transport now we we are name in that to connectivity,"
  },
  {
    "startTime": "01:52:03",
    "text": "strata and another one for services strategy. So we superb basically the concerns and the responsibility of this different things. The services and the connectivity. And then on each of them, we have the different planes. So in the current document, what we proposed, that was already presented in idea 100 1617. Installment this class architecture with, different strata. So we added a new stratum for computing for compute, basically considering the distributed resources that we may have for computing attached to different points in the network. And we also propose to add new plane, a new plane on all the different strata, which we have been changing the name, but basically has to deal with the data related for each of the street. Excite this. So here you have a picture that try to represent this. The terminology actually is not the last one. So you can see the service is straight on the stratum and computer stratum and then different planes. Resource management, control, telemetry, which is this one that, I mentioned before related to the data fix of the stratoon. Next slide, please. So 10 years from the previous version, presented in the last ATF, we have changed on this, what I mentioned, that is not updated in the figure. The telemetry plane to learning plane so sorry to determine the data analysis plan originally call let me play. So we have kind of updated the name to something that we feel reflects better what it's it is about. We ended in the draft, the figure that you saw before trying to appoint the the potential interpretation that there is a kind of a hierarchy between the different stratum, which is not the case. And, the main change in this version has been the having some pointers to possible means of communication between Australia. Planes, although we we have been only considering the startup for the time"
  },
  {
    "startTime": "01:54:00",
    "text": "Next slide. This is basically the different examples that we have considered so far in the draft. So we have communication between application service, and we listed their different options that can be used. The same for service and connectivity service and compute. And compute and connectivity. And there are some things that are already existing document and existing work and some even discussions on ongoing discussions on different working groups at the 80th. Next slide. Which is the one, the the last one. Sorry. The next steps that will identify, sources of this contribution is to add more deployment use cases online with the discussion of the research group and potentially in the future, depending on the feedback that you guys may provide to consider asking for, are the adoption, sub point in the near future. Any feedback. Comments. That would be. Thank you, Carlos. Actually, I cut the queue. I locked the queue. Okay. And the thing to keep it short. Let's move on to next the last present presenter. And I'd say, if there were some comments or questions for the for Carlos's talk, please take them to the mailing list. Hi. Good morning. My name is Daniel Clean from Lancaster UN. University, I think on the agenda, Rajeev from the BBC was due to present. So thank you. This is, essentially just a short, introduction for a project that we're working on in UK with, the BBC. So essentially, the BBC is, a very large organization that is, developing content for not just the UK market, but our and smashingly we have around 25000000 license fee payers, 2 1022, and approximately 400,000,000"
  },
  {
    "startTime": "01:56:00",
    "text": "consumers or BBC content worldwide. And the BBC has a quite a, pedigree of technology Innovation especially obviously for media, but not only limited to media, as you can see here. And what we wanted to do was just kind of signpost the project to some discussion that we're going to be having, in cats tomorrow. And essentially, AI for me is I'm trying to forward to next slide. So that's So AI for me is taking, the next step of a media distribution moving away from linear content. So essentially streaming over the internet's, a particular program or object and moving to personalized media. So interactive and this poses, you know, several significant computational challenges for the way that, media networks a bill and content is distributed. But, you know, the point I want to make here is just to underline the scale essentially we're talking about. And, and this is applied research. So what's being developed in AI for me. Will have commercial applicability in the very near future. So compared to linear media, object media is essentially taking a variety of, media objects and then augmenting them with, virtual reality backgrounds transcribed content, binary sounds, overlays. And there are examples of personalized media that are very short, in x like Thanks. And you can actually go on to the next slide here. There is, her personalized media for very short content, maybe a weather broadcast, but also personalized media, for a concert or, music event as well as sports. What AI for me is doing is essentially"
  },
  {
    "startTime": "01:58:03",
    "text": "distributing several resources in the networks. So these are computational storage, CMS, and then delivering to different users that are attached to the network. So there'll be a variety of handsets smart TVs, consoles, So from a a coin perspective, you know, what are the research chad challenges, well, really they're leachable. And although we requested a bit more time, for this session, clearly, it was a packed agenda. So we only really had a few minutes to introduce the project. What we'll do moving forward is, either submit, an Internet draft if that's the preferred model. Or come back with a very sort of narrow, but deep discussion on one area of compute in the network. As I mentioned, tomorrow, really talking about traffic steering and the need to set up a service instance that interconnects several of these sort of, functional components that are listed here Next slide please. And as you can see, we've got sort of 2 control elements We've got our, cloud orchestrators. So, essentially, we've got compute, which are a combination of CPU and GPU where we have to offload Confice cut computational capabilities, from the user's device, maybe on a local node and actually how that's evaluated is, actually part of the AI for me, app application prep process, and there are, requests for types of services that are pre computed near real time, so relative to when the user wants them and those will be sort of pushed to CDN nodes and then stored and then consumed when the user actually needs it. And there, of course, several challenges between the AI a cloud administrator on the network controller Next slide, please. So we we have, so interesting use cases that that maybe we can, drill into much more detail, other a future event and also"
  },
  {
    "startTime": "02:00:00",
    "text": "linked to some specific papers. I bought AI, machine learning specifically, you know, has significant, role I think to play here. This is, sort of just in the 2nd year of, of our 5 year project. As I mentioned, you know, some of this applied research will be used, for the commercial network. Final slide. Please So please, if this looks like an interesting project. And, you'd like to get some more information about it, then check out the website, and also, contact me or Rajiv directly tomorrow. We actually have a 30 minute presentation. In the Katz working group where we'll be sort of diving into much more technical information, about sort of the compute or optimization placement, management, and network, optimization as well. Thanks. Thank you, Dan. Daniel. So that's all for the presentation today. I wonder if, if or Mauricio say you have some thing to say. The 4th inch. I simply wanted to thank everybody for staying with us, and for listening in despite whatever time zone you might be in that is absurdly different than prague. Reaches A? Any last words? Okay. Okay. Called the wrap. Yeah. And, yeah, particularly thanks to, Ike. For your help. Keep today. And send to the presenters and see you next meeting."
  }
]
