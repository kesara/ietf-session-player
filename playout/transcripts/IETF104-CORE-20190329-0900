[
  {
    "startTime": "00:01:40",
    "text": "[Music] good morning it is allowed to sit in the front seats even if you haven\u0027t read all the drafts it is encouraging you to sit in the front seats actually it is even if you\u0027re just doing your email you can come sit in the front seat okay so it\u0027s Friday I think by this time most people have read the note well I should mention that this room has a really weird acoustics so the the chairs will probably be wandering around the room trying to find a spot breaker they can understand anything yeah no dwell and all that we have three scheduled blocks on the agenda core applications a resource directory and coral and a new idea from from Gentile if we get to it but we also have accumulated a bit of unscheduled stuff that we will do right after this introduction anything else we need to be doing today anything we should not be doing today okay so let\u0027s Marco isn\u0027t here yet I guess you were encouraged to come to the front not not only other district this last year the lighting isn\u0027t up to snuff anyway let me quickly introduce the topic so we have had second proposal for a congestion control algorithm for code for an advanced foundation control everything and we looked at that and we generally liked it but then we got stuck on IPR declaration which is under data tracker IPR 3 2 to 7 and people looked at that and said there\u0027s not enough information and so we stopped discussing it at ITA 103 and since the statement has been updated and one of us who alerted the mailing list "
  },
  {
    "startTime": "00:04:42",
    "text": "to that fact so the declaration has been updated by a statement about the assertion of that patent claim and the claim owner chose to make the patent available for essential parts of an ITF standard so it\u0027s not for information documents also it\u0027s just for Senate strict documents and something that is needed to do this Senate strike document so far we we have considered handling congestion control algorithms as informational but I think it\u0027s not particularly hard to go for stannis trick yeah and as is customary for this kind of idea declaration there is a reciprocity clause so that the license expires the moment you sue Rahway on on some other patent claim so it\u0027s your classical defensive patent construction so we like unencumbered stuff but the ITF often has been able to work with technology that had this this kind of strings attached to it the procedures say that it\u0027s the job of the working group to decide whether we can continue pursuing this and I don\u0027t want to decide it today I want to get information on whether the working group now things to have sufficient information to make the decision so is there anything missing to make the decision or do we have all information we need now I realize congestion control already is a fringe issue and people who understand patterns are by definition fringe people so maybe a small number of people in this room who even know what what this is about but if you have an opinion on this please stated okay I kind of made my opinion known which is that this is a kind of construction that has been used in other places in the IETF and and has been deemed acceptable so my opinion would be we are in a position to make a decision so we will take this to the list Michael do you want to make a "
  },
  {
    "startTime": "00:07:43",
    "text": "comment yeah mark okay so actually I\u0027m I\u0027m not intending to make a comment on IPR issues but the but in case the working group happens to decide to take this part of this document I\u0027m just wondering how are we able to get enough interest among the people in this working group given that this is primary mechanism and in an essentially conscious tone control where the expertise is basically direct the transport area so in my opinion there should have been more creation with the transport area with cocoa for example as well because it basically in the same area so this is just my slight corn tremor that there is enough interest and energy in this working group to do for this particular document in case yes so the next step would be a working reproduction call the questions which working group should do this work I\u0027m a bit hesitant to say another work neutral through this work because this is really our protocol so far we have done work in this space paid both on the original congestion control in seven two five two and on the other proposal by trying to pull in the ICC RG and the transport area as much as possible and I think that\u0027s just the practice we should continue all right so I\u0027m not proposing that that it\u0027s going to be any other variable just just exactly that but how we kind of collaborate with the other area area so in this case maybe the CPM or PSV so for for cocoa Aleksei even delegated the shepherding the suicide of the shepherding Familia children to the transport ad and I would expect he would do the same thing again when we finished this okay so working or adoption call on the list is next normally I would ask the room whether we should do an adoption but I think you might need some time to weigh this IPR issue so I think this is better than on the list okay where other slides those are gone "
  },
  {
    "startTime": "00:10:55",
    "text": "but you would see anything what are you see it\u0027s acknowledged the promise that the data tracker pages require reloading in weird ways to actually get directly made which we won\u0027t miss dashwood yes yeah okay so far for some slightly the working group we have had a second dispatch discussion about the ad hoc proposal the the underlying situation is that we have adopted DTR SS or mandatory German security scheme six years ago and now we have another security scheme which is called Oscar but that security scheme needs an authenticated key agreement protocol to really cover the same kind of situations that the DTLS environment covers so we have discussed something called ad hoc as one proposal for that and it has also been discussed in other working groups such as ace but it never found an official home and both the security area and the art area have the idea of having dispatch working groups which dispatch work I thought who knew working groups responsive documents true and so on which means that it\u0027s not a solitary decision of an area director how to handle work but there\u0027s actually community input on that and secure speech had an interim meeting and extra meeting just to discuss this a couple of weeks ago and the the ADEs have since "
  },
  {
    "startTime": "00:14:02",
    "text": "taking in the results of that interim meeting and are now proposing to spin up a short-term working group to complete and authenticated Huw agreement protocol using ad hoc as the starting document links are to tow the mailing list messages are on on the slides this is something that that probably fits quite well true to what this workgroup is trying to achieve but of course it would be interesting to to hear whether the people in this room think this is a good way to to handle it this so in the best case I would like to have something like an interim consensus from this room that I can relate to SEC dispatch we like this or no we want to do it in our working group whatever we want to tell them speaking as individual I think this is a good way to go I didn\u0027t do that I think this is a good way to go thank you any other statements and beat the founder stock if you have Oscar I think I talk is something you should like to use actually but if it should be in a narrowly scoped version group or that we should do it in ace I have no opinion okay round 2 da I think it\u0027s very well fitted for LP one network so it\u0027s a very interesting walk okay so that would be the view of the LP one group on akarin I without hats I think it\u0027s a good way to go yep so before we have 10 more plus ones let let me just get a show of hands who thinks this is a good arrangement from the point of view of the covering group only the right side of the room well yeah to the left of the aisle but yeah us a to the right of me and who thinks that this working group should state an opinion that another arrangement might be better okay so I will relay that to the SEC dispatch mailing list as the in room consensus of the car working you understand anything else you want to do under this item okay 1300 yeah it\u0027s a very brief update so we are moving a bit forward on the use of "
  },
  {
    "startTime": "00:17:02",
    "text": "github and I was just wanted to summarize what other groups are using to see where core would like to go basically so in deep for instance they\u0027re using github for issue tracking instead of the mailing list but basically the alpha or the editor needs to curate the list and just choose before every idea meeting what to present or what not to present and so on so they are not using any tagging or anything like that in core we do have some preliminary tagging but it\u0027s not like we have a mandatory well a structure list of tags and then again also we don\u0027t have a lot specific discussed tags to be discussed with the working group or any kind of milestone so there anything like that but maybe we are a bit step ahead on that and then HTTP for instance a bit ahead of us in a sense they have discussed tag they have all the tags based on topics they use milestones and essentially they work everything there so I would like to propose okay that\u0027s to basically track the document life from the very beginning individual submission to working write them RFC everything on github so for those who really like email we could also have email batches it can be easily configured to send even much email batches every couple of weeks or every week or whenever you want we could also if people are happy with that we could assign issues to a specific experts that really know a particular field but that means that they would have to check every now and then also we also could assign we could we could also have milestones on a specific it could be either based on the draft lifetime you know when we do working about option or working on blast call or specific features or sections and I think also the more important one would be to start using tagging for instance we could have the disc a stack if we want to discuss it with the working group and very other tack so some of the stuff we wouldn\u0027t even need to discuss because this editorial a rat our some other way of working and then last this is not supported by the ietf at the moment but you would make sense maybe to consider having our own ITF gitlab servers that we can depend on get have only but yeah so basically and I just finished we will have some trial with some individual submissions and perhaps also with one working already working group adopted document I\u0027m looking for DNA Peaks not just looking in epics and yeah that\u0027s it my comment is on the discussion using it a point one of the things that Martin talks about in the various you know using github and your favorite working group is the working group has to decide where wants sort of active debate to occur whether active debate should occur on the mailing list or in the github issue itself and either one can be done "
  },
  {
    "startTime": "00:20:04",
    "text": "in the working groups you decide often working groups choose to their sites a number of working groups choose to say active you know debate should happen on the mailing list and summary should happen on the github issue that\u0027s actually the policy of teeth and read to be better at actually enforcing at that because I just sent out emails the teeth list this morning basically saying that on one of the issues where I started seeing some discussion and github and so I think that\u0027s a job for this working group to specifically decide that I mean if you\u0027re gonna be using github where do you want arbitrary responses you if you want people to be quoting in line other people\u0027s things where do you want to have that it sounds like you\u0027re proposing to have that in the github issue itself on the mailing list but I wanted to clarify which thing you were actually proposing I\u0027m proposing I mean so today the facto some of the working group items are discussing the github and there is no so much traffic on the mailing list and this really really necessary some consensus but the authors tend to work together like that so I was just wanted to maybe formalize it in some way but of course we cannot force people to do that so we need to Dave that\u0027s nice why this happening before you go away I\u0027m going to ask people here who have experience with other stos that have picked up co-op what their view would be which of the alternatives we have actually would be better for getting participation from those stos the answer may be it doesn\u0027t make a difference because there\u0027s some other obstacle preventing participation or it might be mailing this is better github issues is better so I presume your eyes meet like for an ocf perspective I think it probably wouldn\u0027t make a significant difference to OCF I can say that ocf doesn\u0027t currently use github for issue discussion there\u0027s no split ocf from i/o tivity right and I\u0027ll give you two different answers there just because I\u0027m at the mic ocf uses mailing lists and it uses its own document repository system that\u0027s called copy neither of which is github it may use github for you know data models or something like that but not for the actual discussion io tivity uses the mailing list and github and it does issue tracking on the mailing list it doesn\u0027t have a good issue tracking history I would say but it does have github issues and Falvey active discussion to the extent that there is active discussion as on the mailing list and I think you\u0027re on that list but that\u0027s the OCS perspective I don\u0027t think it would make a significant difference but the history is they don\u0027t haven\u0027t really used issue tracking for the discussion per se if I make Anoma we are also using github for quite some time the transition was kind of painful at the beginning because maybe people didn\u0027t use it we can use both at the moment for issue tracking on the for basically even drafting the specification is done in DTaP some of "
  },
  {
    "startTime": "00:23:05",
    "text": "the other discussions are on the menu list but less and less in my opinion that\u0027s why with them plan yeah bill from Tumkur University I\u0027d like a second what they\u0027ve just said there\u0027s a lot of confusion on how we can actually use github could I propose that we actually come up with a best practices document on the working group because they the guidelines seem to change from working to cookie group and firstly I have faced the same problems getting a discussion going from the mailing list and and passing them into issues it\u0027s not necessarily a trivial thing and being an editor of some documents right now I I have been using the tagging system and I\u0027ve actually discovered that it\u0027s good idea to use github for more than just issue tracking and and it\u0027s a code repository so we\u0027ve got continuous integration going on at the same time github also offers different kinds of insights where you can actually see the activity on different drafts and it\u0027s difficult to know where to draw the line how far we should go into these issues as individual authors or as a working group document authors so I think would be really good if you can get some kind of perspex was talking about all of this so I thought the reason we would like to do the trial I mean these are already discussed with Christian and Christian it so they sorry we want it to be better try out see what is the outcome see if it is actually feasible maybe I can compile later on some document for it but it\u0027s just experimentation at the moment isn\u0027t like we are going to switch everything right now okay but at least to try Jim shot I have two concerns about discussing issues in github the first is I do not know if the IETF policy on archiving of consent of discussions on mailing lists has changed or not the second is I don\u0027t always know that I need to go and follow a new project whenever it starts out so therefore I don\u0027t ever get find out that that discussions are occurring if the discussions are occurring that get up I mean if it is one big project and everything is in the same tracker the not only have to do it once it is not that hard to follow if on the other hand you have a different project for each document that means that all sudden I don\u0027t actually see discussions and that always worries me however we have every document in one project and the issue tracker will be insane you will be a mess of comments from any drafts on any issue and also regarding their storage so the data we had our own gate lab sorry if I came had their own deep lab of course you can dare apply whatever policy that\u0027s another plus for using our own ITF gate lab if it would "
  },
  {
    "startTime": "00:26:07",
    "text": "exist Haidee interrupt the the HTTP Biss working group has handled this by having a separate mailing list set up that an ANA script on github that sends all of this to that mailing list it\u0027s not on the HTTP biz mailing list directly so it doesn\u0027t flood it but you can always subscribe to this mailing list this other mailing list or look at its archives that takes care of the archive problem because it\u0027s all archived in IETF and it takes care of the I gotta go fifteen different projects to go figure out what\u0027s going on it still may not be your cup of tea but at least it addresses those issues and the other thing is that I presume everybody knows there\u0027s a new working group called get to discuss these issues about how we interface with git and you should definitely participate there yeah I will say that the SAC home working group solve this issue by subscribing the IETF mailing list as an observer to all the projects which makes things messy in a different way I realized I\u0027m still new sorry Brendan more in here I realize I\u0027m still a bit new here but this does raise the question of accessibility github is not and has not always been available to everyone and that seems to be one of the core things about the IETF making it available to everyone and github isn\u0027t sometimes it is but not always and we need to be cognizant of that which is another reason why having our own get lab will make a lot of sensors okay we don\u0027t really want to second-guess the work that is going on in the braking group and you might as well wait until they have produced more of a result but the the objective here of this was that maybe as well we should start our own small controlled experiment on this to gain some experience so we can make make a good decision so this is not about completely swapping the model in which we work but setting up an experiment and I think your next slide said something about trying this with an individual submission I was actually going to propose to try this with a resource directory because the now in the working group last fall in the work new blood scholar phase actually there will be a lot of technical issue management that actually is done quite well on github so I would expect that that handing the regular scholar comments on github would be easier that way so that would be my suggestion but I\u0027m certainly interested in hearing what what the main editors think about that I can of course Baker "
  },
  {
    "startTime": "00:29:09",
    "text": "follow all all all and all four Rd but there is tagging already there and we I am already moved replicating the discussion points on the tracker so would be fine for me that was Christian I\u0027m Dave savor the respond the get working group I was there and my understanding is you\u0027re not gonna see a result of that working if that says you must do X right that the working group has a bunch of choices and so I just want to clarify that you shouldn\u0027t wait for some answer to come down right though just here\u0027s a cookbook and your working group choose which of these options work for you and so I don\u0027t think there\u0027s any reason that you have to wait for anything from the get working group if anything they\u0027re just providing for guidance for get newbies but if you\u0027re already using it there\u0027s no reason I think to wait right yeah this is Barry I never intended to imply that I was just encouraging people that if you care and participating person summary yeah I was just interested in the results of the group because having that cookbook would be good and maybe having some tools slightly mahone than than they are right now would also be good but I also think we can start doing this experiment now Peter Hong stock I just wanted to make this down-to-earth survey mark I already have problems being explaining the faces to which the document goes with the normal IETF procedure if you\u0027re going to add in the good of FM even more estates then it becomes very difficult to explain what\u0027s going on so I mean you should be very careful that all this taking follows what goes on in the standard ITF process and that all the others are just alternative and should be used such that it is not to be confused for other people yeah I mean my intention is not to change the IDF process at all say my stages same steps so I think it would be nice to have some some of the HTTP this tooling that that sends summaries of the github activity to the list every Sunday so maybe that\u0027s something we should procure to make sure that there is no disconnect there but I\u0027m also hearing that people would be quite content with having a small limited experiment on the resource directory completion process now and then we can evaluate that and see whether we widen this experiment fine you actually have to run to this speaker to understand what anybody says on the microphones useless not my John Michael Stan Michael are you online so like do you "
  },
  {
    "startTime": "00:32:22",
    "text": "have speaker privileges or do we do this using the queue okay it\u0027s like 1:00 a.m. in California so I\u0027m not playing with Mike Leah so maybe we can just quickly go to to the next option dine link we want it within touch okay Mike is there so let\u0027s go back to can you hear you are under at least five layers of wool blankets but yes we can you okay maybe this is a little better no okay so go ahead and advance the slide okay so we\u0027re going to do which is don\u0027t use a disco and figure out how to handle empty topics topic like time and data lifetimes in some other ways that we\u0027re working out and those are specifically the next slide please an empty topics that the issue is a topic has been created but not published yet so what does the broker return so what what me worked out there is that we\u0027ll have the response wait until there is something published co-active and observe that\u0027s not really a problem you get an AK and and then you know the response don\u0027t have to come back there there will be some time out possibly but will happy a the application layer work that out the publisher can always publish an empty payload there the problem has hubsan only transmits payloads only representations if you will and content format so it doesn\u0027t really know how to construct an empty payload it it means the publisher or the topic creator to do that so that\u0027s we\u0027re going to keep it simple and write that up and depend on things like accept all and nothing to see here sort of an aura multi-part content formats to handle the case more gracefully but even within ml you can just send a bracket bracket and an empty payload and the the subscriber can understand that is there\u0027s nothing there yet so I don\u0027t think there\u0027s any issue that we really need to deal with here other than write this up this way "
  },
  {
    "startTime": "00:35:23",
    "text": "for empty topic right I guess we can probably take questions after I get through explaining all of these there\u0027s no one at the queue now anyway we ready okay next slide please now the lifetime of the topic we just want to use the thing we owe okay so the idea is that we would create a query parameter topic lifetime TLT and you can supply that on creation if you don\u0027t supply that it\u0027s just a topic slip until you remove them basically that when you create a topic the counter begins to count down and every time you published for the topic or repeat the create operation like we do with our D that would refresh the counter to the to the value of course with your doing the recreate operation you can supply a different lifetime value if you want and then when the counter reaches zero the topics removed and that that\u0027s basically the idea that right next slide please okay data lifetime we just wanted to handle with Max age that\u0027s already in place and the default would be to just have the Pope\u0027s a broker not return anything in elapsed 60 second max age on all responses oh that\u0027s not ideal for all situations but it\u0027s a useful default then we want to enable a data lifetime option as well a DLT that when you create a topic you can have a data lifetime default and that would that would set max age unpublish so that would basically allow publishers to have a max age that was different from 60 seconds so if you wanted long live values you could you could use this and also there\u0027s there\u0027s some talk of creating a header option that you know just can be used by push notifications is that the lifetime of the data they\u0027re sending and so that would be an option also but I think when the draft vote will well I\u0027ll show how we conclude later now next slide please yeah so lifetime of topic contents that\u0027s basically what I just said so the idea of there being max age value of 0 the value is still sent and the cash if it\u0027s the cash behavior of the default behavior of is that when Max age of zero the cash can now use the value but but not reuse it I believe it\u0027s the way of the way it looks so if we have a subscriber kind of ending like that same behavior but that would seem to be reasonable like so it\u0027s a client library the client could for "
  },
  {
    "startTime": "00:38:25",
    "text": "example signal that the max age of zero and ask the application not to use the value for example and then a cache that subscribes to a broker could could just use max age the way it\u0027s used to okay so here\u0027s what he concluded that next slide so the proposed profile so I was going to write this stuff up in the draft but it looks like there\u0027s enough here that I didn\u0027t get around to it I wanted to just present what what I\u0027d want to put in so the idea is the first option for empty topic is that the broker won\u0027t respond in topic creators are responsible for publishing empty representations and then we\u0027ll give some examples so this is what I planned it right into the draft right next slide for the topic lifetime and data data lifetime we\u0027ll add the two query options that default if you don\u0027t supply DLT as just to respond without the max age option and that allows the default on all responses to be 60 seconds if DLT is included then the replications are sent with DLT and max age option and then we read and subscribe sometime after a thing has been published with DLT you get a max age equal to a dl t minus the the time basically as as described in RFC 72-52 numbers please I\u0027m excited sorry yeah so if the topic lifetime excluded included the topic will remove be removed anytime there is no published activity or I guess or topic refreshed for a time equal to a topic life sign and when that happens outstanding subscribers and new requesters will be sent oral force if not resource not found so that\u0027s basically how we plan to cover it in the draft questions issues other ideas okay someone getting up yeah I have two comments the first one is could you go to the proposed profile one we have been talking a lot about that up subtopic configuration and I think if we have things like publishing an empty representation for a topic it might say it might make sense to be able to update this representation at a later date so what one idea could be to split the topic into two coop resources one configuration resource which exists for the whole lifetime and then a data resource which is what the publisher has "
  },
  {
    "startTime": "00:41:26",
    "text": "published to and the subscriber subscribe to and then you could simply say you you create the configuration resource and but if it does not have content yet the data resource does not exist yet and it\u0027s created when a publisher publishes for the first time and this would give you this Kurata resource for creating reading updating and deleting topics topic configurations my other comment is I think it was on number two no number three number two sorry the comet is on next age when a publisher hasn\u0027t published for some time like then the broker hasn\u0027t received the publication for 24 hours do we really want to say that I can give you a representation now but it\u0027s very likely that you will get an update like in zero seconds so you shouldn\u0027t even try to catch this and I think we need to distinguish between them data life time and the mechanism of keeping the observation alive and not generate needless traffic just to try to map the data life time into the max age Justin I\u0027m just I think on the topic of of having those empty representations that could be done a lot more smoothly if at as I understand right now when a topic is created all the metadata is is put in there whether it\u0027s I\u0027m part of the link to that that\u0027s created for the topic or as as as registration of as options for the creation and I think that this could be a very this metadata could be a very suitable place to indicate that this topic has some kind of Testament last world tombstone whatsoever um representation that the publisher may use to satisfy observations on that resource which would align nicely with with metadata on topics that on resources that are not topics because such metadata could just as well be expressed about any any other resource and when a client gets that it could look up in the metadata that hey it\u0027s not there but it has a default representation I can pass on you through the application cuz the woman from the floor when I look at this the proposed profile one we seem to be extending the arc HR with long "
  },
  {
    "startTime": "00:44:27",
    "text": "poets now which may be a good on the thing or no not a good thing but I think we should do this very consciously as Klaus mentioned there may be situations where we are having the broker not respond immediately to something maybe more efficient so my ear to form of lung power may actually efficiency improving but this of course could be a situation where a topic has to be created and two days later the first data is published to it and then you would finally get the response to the request you send in so I think we have to consider whether that is an evolution of the architecture that we we actually like the the other observation on the i-th I think it also has already made but I want to repeat it because I want to focus on the architecture right now where it\u0027s that here it\u0027s nowhere anyway if a publish needs to include DLT in a lifetime a query option then this great option of course as part of the UI and by being that it\u0027s also part of the cache key so that publish doesn\u0027t replace any cached instances that might be lying around so having a no cache key get her lifetime option actually is something that might make a lot of sense now adding options also is impacting the architecture so again that\u0027s something that we need to think out think about but it might be useful here and the third observation was already made that maybe having a control resource and the data resource that might be a good thing and if I were designing this from scratch then of course I would make a control resource that actually is a multi-part call that has both some control structure and potentially optionally initial value off of the topic so as I understand currently the kind of control resource is implemented as just using a different content format we\u0027ve I think that doing doing something like that has "
  },
  {
    "startTime": "00:47:27",
    "text": "given us a bit of trouble in the resource tracker as well so having separate resources for metadata and the actual data makes sense and also frees up have subtopics to actually transport link link format or similar data because right now getting the link data on the topic means getting the metadata and getting the and that means you can have actual link formats data on the topic become a stock now something completely different we still in turn intend to use the broker as an epoxy for the slippy nodes it seems to be slowly disappearing I hope you can still look at the requirements we have ready some time ago and make sure that the power can be used as such but again on florrum yes Oh Peter yeah it can still be used for that purpose too there is the read interface exactly for that use case there\u0027s them there\u0027s a subscribing the face and reading the face and the reading the face is the classic use case you are referring to so that\u0027s still possible and in general the theme of this update was that we\u0027re simplifying a lot of things so you could use coop client roughly as such to interact with a a pub/sub program and then when you do more advanced things like five times and such then you\u0027ll have to do a bit more advanced procedures but the basic functionality would be very simple for any bunny like or client through my concern is that it is very much concentrated on using observe and there is an action which this proxy use this mirror server if you like where you just do an increment of the state latest status of a topic is without doing an observe of it or setting the topic yes so we\u0027ll be most talking about that interface which is heavily based on observer there is also the basic 3d interface which is essentially the same this except for one bit you don\u0027t enable observe so but it\u0027s it says that the observer part is slightly more complicated because of this data lifetime issues okay I think we have had some great discussion but not really a conclusion yet and I think marketer can use this and all the pops up authors can use this for generating a next version and proposing a solution to those problems and then the working group can decide "
  },
  {
    "startTime": "00:50:28",
    "text": "whether we\u0027re done with us and no we are not going to get that we are working with sleeping notes Time Inc we are about ten minutes behind schedule we are behind ten minutes behind the end of the segment already so you have to do this in minus ten minutes please okay hello so dine link yeah that\u0027s not very very much to mention we actually managed to finish a fairly big chunk of work already and then at the end of February we had a flurry of activity when we actually had a joint call with the OMA eleven m2m folks and then the the current draft reflects that so there were clarifications that were done we restructured the draft so that we have conditional notification attributes that can be used with general observe requests and then that introduces the whole the whole document and then we change the data types for Eamon and pmax so there we can support fractional second timing previously they were just integer values and also there was a clarification made about when the notifications will be sent but only for LT and GT so right now they they are notifying on all crossings not just notice up or down we also had some discussion with the people from the eleven m2n group about the ban attribute and I don\u0027t really believe it was there anybody in this room from from that meeting because we were also discussing about some alignment with the elaborate m2m documents regarding the description for the different attributes so the consensus from that from that meeting I believe if I remember correctly was that we\u0027ll wait for some information from Delaware em folks on if they if they would like to contribute some text to the document so that\u0027s that\u0027s basically the the major part of it and then the last part was basically about the binding table so we changed the binding table description so that we have a new new attribute value instead of an interface description so that led to a small a small confusion on how we actually do the writing table because we were not in favor of keeping the post operation and this is the old the old example in drop 7 which was about resource collection called B and D which you can manipulate using a post cut or delete but we\u0027re still looking on this a little bit so I think we will get this done fairly fairly soon so right now you discover the the entry point to the running table and then we had we just have get input we\u0027ll have to think about "
  },
  {
    "startTime": "00:53:28",
    "text": "how we do patch and fetch quite soon on that and that\u0027s basically it so the work on the no divisions are completed link bindings are completed so that\u0027s just the partial changes that are needed for the binding table and maybe we get something from the Levitt m2m folks and then we\u0027re ready oh yeah that\u0027s that\u0027s the last light from Christian just analysis I\u0027d like just like to point out that there are there should be a made somewhere around the mailing list with some still aankhon unaddressed concerns about particular binding types that were in comprehensive I could actually give you because they so loud could you keep um so there was a comment on which binding types there are and that this should probably not be written out as a comprehensive list and be open to be open to some scenarios that can fit easily with with what\u0027s written there but just list that is a bit too short or maybe should just go away but there\u0027s a comment on the mailing list at least make sure to follow yeah yeah and I forgot to add one thing that we also included into the document was basically the use of camión because there was a confusion what can you hear me yeah the use of yeah sorry source also the use of be mean to clarify which value should be sent when when teaming expires so that that\u0027s not been clarified in talking also yeah I have one question when I actually think that it should have already been ready now then the binding table just needs a bit of work so discussions microwave we get this done maybe the next two weeks three weeks and then I think it should be well of course we\u0027ve gotta wait with the for why wait and when people also if they want to contribute some text that\u0027s our Hanson moment and they were supposed to contribute to all github issue so the procedure is we wait for the next version we do think two things in parallel which is a chance review and contracting yeah yeah that\u0027s that\u0027s fine that way all right so let\u0027s get this one done I don\u0027t anticipate much I mean it\u0027s fairly stable right now so there\u0027s not much else in there okay next one is I\u0027m not sure I\u0027m gonna be here just right so one of the first drafts that we actually did in in this working group like 2012 was core interfaces and that was an early draft that actually consolidated "
  },
  {
    "startTime": "00:56:28",
    "text": "our ideas about how this was going to work quite well and actually it has been in an influential draft because it has been taken over by other stos who then adapted reg they didn\u0027t just do what we wrote they did something better changed so right now there\u0027s actually no literal adoption of this document just since since there were the few recommendations that kind of have been overtaken by events and we looked at it and decided hmm there is some useful text in there and actually turns out that in particular the text on collections a would fit into a series of small documents that the research group is about to generate so this is non normative text that just describes one way of doing things and that would fit with the rest for design document as a parent document and actually if you look into the Charter the Charter mentioned this document as one place where there will be interaction with the research group so the interaction in this case would be push it over the wall and ask the research group tour to use the good pants so I just wanted to hear the opinion of the room I already asked on the mailing list and I think we had one response to that any other as the people who have been working on core interfaces I think this is a good idea we could so there are basically two paths I mean it\u0027s a very well-written document it\u0027s very small and it\u0027s easy to understand I believe that at least some ideas would fit very well we think two things research group so that\u0027s that\u0027s a good thing and then the other part is probably yeah like you say on the SDS has overtaken so yeah a Peter Thomas talk again I have found this document very useful in the early days when an ad with starfish go up and see how I have the structure documents and how to structure applications and fantastic desk text for that and with some of the additions I think it should be maintained I think we all agree that during in strong subject line so it\u0027s really about throwing it over the wall and getting it published in a slightly different context okay clarify we and we\u0027re not gonna bury it yes make it part of a series of fashion answers yeah good so and I hope you will "
  },
  {
    "startTime": "00:59:29",
    "text": "participate in writing those documents next resource like three and twenty five minutes Dan schedule okay hello and then I\u0027ll try to make it brief so resource directory is an is as of test twenty in working group last course since last Wednesday we are we\u0027ve started to receive comments during the working group last call one of which is an update to the security considerations from class um that should not posing much different difficulties it\u0027s just to help explain basically to give the reader a better impression of of how that would actually of what would be an example of such policies lemon noted appointed outed an outdated reference um where where we are describing how all this might interact with our DT and SSD and gave an example based on probably two year old version of our DD n SSD which doesn\u0027t fully fit with TN SSD so that example would probably just go out and it would it was one way of discovering that is not fully fleshed out could still be added if T an SSD thinks that this is a was all DD if if our DD n SSD thinks that this is something that is needed last but not least I managed to still leave some errors in the examples that are confusing people and thanks for pointing them out um I can fix them so just to summarize we have we\u0027ve had three interrupt events by now and I think I\u0027ve missed two implementations that are work in progress with the last interrupt but the sequence of events shows that ambiguity have found ambiguities and problems that arise from doing it in practice with the first interrupts and with the third we\u0027ve already gone on to experimenting what more we can do what extensions we can use for example using the choral format to express the content of the resource directory which which cows will later follow up on because it um we have we have shown in the interrupt that we can have a registrant register was link format at resource directory and that resource directory would then expose the information in coral to someone doing a lookup and trying to find resources and find out metadata and that did work although of course the format of how we do it imprecise will still change but yeah that\u0027s all at work and I think the the working group last call is in in good progress and by the 17th of our April I hope that we can go on with this um questions so far bill thanks for the good draft that\u0027s uh "
  },
  {
    "startTime": "01:02:30",
    "text": "I was clarified a lot of things and also thanks for the good discussions we had or the hallway meetings that that uncovered some of the example problems but but that\u0027s that\u0027s okay that\u0027s another I sort of clarify one thing regarding um so we were discussing this also with Christine so I just wanted to raise this issue that there is some text in resource directory that says currently the cardinality of the cardinality of what was this nullity of the of the registration base registration to the donation base attribute was one and in future you might have multiple base values and then you refer to the protocol negotiation so I want to clarify that I don\u0027t really mind if you keep that text in but there\u0027s a very high chance that protocol negotiation is not going to have multiple base values so that\u0027s that\u0027s what I wanted to say so we you could have base values but the semantics of what we are trying to do it\u0027s a bit different for bass yeah that should drop me that\u0027s another case of one of those forward references it would probably later be that which we should adapt to the car through the kind of state of the art and possibly move out and possibly remove from the documents absolutely absolutely so yeah just a good indication that we can do it that way okay yep thank you so if there are no more comments I\u0027d like to move to the second part of the Rd slot that is a brief report on what I\u0027ve presented to TQ TRG don\u0027t you stay I\u0027ve previously in Landrum\u0027s and the resource directory application to this group and it was then decided that the benefits with tthe so the the kind of a big picture here is that it is possible with the resource directory to replicate it without doing full application level replication but rather to have the resource direct to have several resource directories meshed up with each other results from that have been incorporated into the resource directory document profile that that allows those kind of interactions and that in my opinion is something that can go on without impeding work here and this is basically mainly to notify that this is going on and tthe from now Peter Peter snook if this document goes out I think some text in the beginning which tells you what the replication is supposed to serve which purpose of this pose of hers is very important yeah because at this moment people have different ideas about applications and they have very different consequences for the protocols you\u0027re going to use I I think the latest version should have text in there that lies out a few of the goals which are mainly not being distributing in order to cope with a great load of requests or registrations "
  },
  {
    "startTime": "01:05:32",
    "text": "read fate and tolerance to failure and I think there was a third one that I just don\u0027t remember out of my head because it probably is a kind of overlap area but um I\u0027ll make sure that the document will outline why it is done in precise groups another thing that was presented over there that leads us basically over to the to the protocol negotiation part again is the is the is the kind of is what I started to call the or d-link project that is trying to integrate the whole vision of how how cryptographic identifiers can be used in order to have your eyes that work all across the internet without necessarily being integrated with the centralized infrastructure that depends on protocol negotiation and alternative transports and the work on especially attractive transports has been taken up again for within within the overlap area between this working group went t to TIG because it turns out that there are many questions that we still need to answer that are not just specify how it works and be done with it especially when it comes to the topics of your royal icing which we try to avoid and having a trust model that allows us to switch transfer transports without getting into all kinds of problems about being able to authenticate that this is actually the this is actually the thing to do so there is this there is a there\u0027s a github repository now in which we are kind of pooling minutes pooling ideas I should probably have put the link in there right if you can follow up with the remaining list so if you\u0027re interested in political negotiation and co-op +80 please let us know please watch that repository because this is something that will eventually become relevant to Corrigan but may in the meantime be processed into TRG just because there\u0027s such a wide variety of of how things could actually go and we don\u0027t a very clear way for what yet but have to do some experimentation as well oh I would like to talk about coral over in the t2 TRG we have been working for some time on the constrained restful application language coral there are now "
  },
  {
    "startTime": "01:08:32",
    "text": "a bunch of internet drafts related to that and the first to the constrained resource identifiers and the constrained rest for application language now coming out of this being a research topic and are getting some interest in being used in core applications and so the idea would be to move these drafts over to Cora and series C power based encoding of your eyes in the same option style that we use in coop you can see one example here um it\u0027s a your eye that you would normally write as co-op codons refresh example.org : and so on and Siri takes the components of the URI apart and then puts it into AC bore array where each component has an option identifier in front of it and you can see the CDL notation here and the idea is that we want to allow constraint devices to perform your eye arithmetic in a small amount of code covering all corner cases and doing that correctly so and this has been developed as part as coral but then extracted into a separate draft because it\u0027s not only useful in coral but could also for example be used in this N and C bar format or in C of wte our insuit manifests for example then coral itself if you\u0027re familiar with link format it\u0027s basically link format on steroids it has a data and induction model for building applications the machines can navigate between resources by following links that we already have the link format but it can also describe operations on resources by submitting forms so essentially the correlate document tells you if you have a quarry representation of a resource what is it that resource what can you do with the resource and how does the resource relate to other resources and it also fixes a bunch of problems that we have an ink format for example link format has is very weird rules for generating the link anchor and it\u0027s not very extensible ending format attributes and coral has comes with the two serialization formats the primary format "
  },
  {
    "startTime": "01:11:32",
    "text": "is again based on C bar so it\u0027s suitable for constraint devices a typical coral document can be expressed in a small amount of bytes and can also be processed by constraint device without taking a lot of additional RAM but because it\u0027s so compact it\u0027s very hard to read for humans so there\u0027s a companion lightweight texture serialization format that is used mostly for giving examples overall these two documents series and coral are so far quite stable at least in on the concept level we might want to do some optimization for example to compress redundant items in Ybor more efficiently we had two meetings this ITF where we got into some details created two coral one was the hackathon where we got to do some hacking on Coral there\u0027s a no apostle for the texture format an encoder of the SIBO format for riot less we created a bunch of examples and look at different use cases and they have some slides on depth upcoming we looked into thing description conversion to coral and also worked on an updated eyes and implementation and on Wednesday we had dedicated site meeting to coral to ours and discuss topics like how could you use series outside of coral some technical disc discussions on comparing series we briefly looked into the conversion between coral and rdf and linked from it and discuss the concept of forms and also i had a bit of high-level discussion are those real hypermedia applications as envisioned by using coral actually feasible and also had some discussions related possible working group adoption and so you know i have very quickly a few examples how how the text form it looks like you have to imagine that those can be expressed in c bar very compactly so what one thing we can do with coil is just use it as a simple replacement for link format it looks like this and this is an example taken from our c 66 90 we had the hackathon one example called Karstens coffee machine which is essentially a collection resource of cute coffee orders so you can create update tree delete coffee orders and this is how it would look like in in coral here\u0027s an example of a thing description convert "
  },
  {
    "startTime": "01:14:33",
    "text": "to coral the original thing description is shown here on the left hand side it\u0027s a bit longer and if you assume that you\u0027re using coop then the finger scription collapses nicely in these to these very few lines of text and as one exercise we extracted some vocabulary from the hip so definition files and for example if you want you could now use the ipso reusable resource definitions inside your kora based applications our conclusion from hackathon and the site meeting was coral rocks and we have tried it for resource discovery and more and there was even a bit of an interrupt a moment when Christians and gems resource directory implementations caught interoperate using coral I have created a github repository with companion material so their drafts themselves are a bit low on the example site and these ideas and we create a github repository and there you can find this EDD R and a B and F grammars the code extracted from the draft test vectors for unit tests and the idea would be to create lots of examples and maybe tutorials and more introduction material inside this github repository instead of putting that into the RFC we also started collecting some open issues on the github repository there are now ten plus open issues and those actually in a state where they would benefit from working group input and that\u0027s no longer just a decision by a single author to resolve those that was my coral and Siri pitch and hopefully less than five minutes thank you I need the other two minutes to ask a question so given that we have reached the state that Klaus has reported is it to the working group adoption here so we have lots of documents of course not all of them I actually something that this group would be working on so the two documents that we seen the candidates for going into the engineering phase are the coward document itself and the Seri document which is needed as the URI "
  },
  {
    "startTime": "01:17:33",
    "text": "representation we use inside coral documents so my question would be are we ready for adopting these yeah I\u0027ve seen one thumbs-up this room is useless for hums so I will show of hands what\u0027s the number you watch so h9 4 so who is against our group adoption of these two documents okay so we will report this as in room consensus and verify the consensus of the neighbors but not do a gradual adoption call that just verify that you consensus we already reached here thank you so the final point on the agenda is new work that Jintao has started on speedy block-wise strength small question about agenda there\u0027s no concern see yes our ddns st has disappeared oh you want to resistant we wrote it well I sent this slide she might it\u0027s okay now about it do you want to quickly say something yes it\u0027s going on very nicely we still want to do some things in to end of July we have separated out all the automatic conversions and for the service tab we have defined an ST parameter which makes things much more clearly and three think we will be done by a year July thank you okay and I think this is important information and apologize for dropping those slides and we are looking forward to seeing this happen actually I didn\u0027t expect to have the opportunity to present this because lonely the working groups very tightly scheduled anyway I create a cup of slice and I always want to keep it very simple this is a speedy speedy co-op lock why transform the problem being the kind not in the current space in the corner see the current is to send continuously requests to the server and using the block option to specify the exact segment then there "
  },
  {
    "startTime": "01:20:33",
    "text": "is expected each time that means we do we do a lot of round trips there and such a design was a reasonable choice since the server can be implemented to be a truly stateless and lightweight but is there some lead and some scenarios that we we can speeding at this for example during the firmware update well a large object a large file is going to below you to the sensor or the the device is going to conduct a critical mission conversation with some server and the other case is there are cases that the the server is actually more capable than their original co-op assumption which means that they can be more stateful in handling these so what we are actually proposing is speeding up blog option called s here and in the speed up option the client can specify the speedy window size there for example five here then the server can send just the five segments to this to the client just you in one conversation as to reply in reply and this it\u0027s a little bit more tricky if because we put is because the client basically know its requirement and its limitation or is constraint and requirement so for example here the client says that means I can receive I can call five packets in one we ten pass but actually interface dividing it to more than five second so the server we are just as in five segments to a server or to descry and each five segments each speedy window the client needs to reply with the ACK and then the server can send more this can you know speed up the conversation as well as keep the kinds as a constraint device there are some more details in the draft and I think they\u0027re more question to be answered for example how to design this probably this is now the best way but I think this is one of the poster boy and that this is just very small fix here we can have block as speedy Apple here that block s means a speedy block option here so that you can the client can inform the server about the speedy window it would like to use yeah mmm that\u0027s it and this is anyway a small fix do you have us any interest or any scenarios that can be I have two things that I want to point your it mean I see the use K I see the use cases I\u0027ve run into them myself occasionally but I "
  },
  {
    "startTime": "01:23:34",
    "text": "think this is this could profit from looking into two pieces of to two areas here first is using n start greater than one which is something that was I think always envisioned to be possible but not really I\u0027m actively worked on recently that would allow the that would kind of simplify the model quite a bit by just sending several requests without waiting for the blocks to come in that would not give you all the efficiency that you are envisioning here but might give sufficient speed ups without making the model any more complicated sort of negotiating that and start a greater than one is okay and if it then turns out that this is still not enough um you may want into what is going on with ultra with non-traditional responses because there comes in all the topic of how will this server even know on which time token to reply etcetera but my gut feeling is that it wouldn\u0027t need to come to this when one looks into and start greater than one for say eighty percent of the applications okay so you are saying there you have MIDI scenario band what\u0027s the solution we just mentioned and start greater than one which would mean that the server is at leisure to keep several to send several messages to the cloud that sorry the client would be at leisure to send several requests at the same time without luck stepping and waiting for each response to arrive that is possible that that that is not if there is no particular definition of how to arrive at those larger and start numbers but if you here that five is a number that works for you that could just as well be a number that you could try out things with and then send resend several requests without waiting for the response and only sent more requests as the responses Strickland so one more question is Easter a solution you just described the document an email I am not aware of any document as lives implementations letter to use and start greater than one but I might easily be wrong and someone more familiar with all the old documents may answer that okay hi did you do some analysis on on the performance improvement you\u0027re you\u0027re getting out of this I think we have done some very simple revocation of these I think it\u0027s very obvious because for example here the DOE regional ways you send each sent for week four five requests for five block items but now you have sent you just an one because there\u0027s only one RTD happening one wrong "
  },
  {
    "startTime": "01:26:35",
    "text": "tree yes but there\u0027s also I don\u0027t know if you maybe you did that already sent this to the transport working group to just see where the transfer they\u0027re a working group because there\u0027s obviously a congestion control issue here you like you pick the number five but I could say I picked the number 1000 and so I\u0027m I\u0027m very fast but I don\u0027t think it\u0027s that easy oh I\u0027m sure it\u0027s not that easy but now I think because we have the coop or what he CP defined already specified by you right and if you are using TCP this is obvious because we have lot of blocks to send and that\u0027s that\u0027s llama a case that history should hinder and TCP country console is so stable and can make an internet very stable hmm say okay so you ambition this to be mostly used with co-op over TCP can we use either for UDP also because we have cocoa a we have to cook co-op congestion control algorithm define in this working group and this can be proved also safe for the conversation over UDP okay so I\u0027m seeing some interest in this and also seeing interest in exploring related approaches for instance with increased and start so I think we should encourage you to continue work on this and maybe also explore the alternatives work with the people who are the ideas in mind and we are looking forward oh thank you thank you very much so we are closing 90 seconds early this time thank you very much for making the time this time and there\u0027s a lot of actions and I probably should have mentioned it has been said before we will have interim meetings and we have large number of working groups that will be coordinating to run a weekly interim meeting in probably at late Wednesday European time early Wednesday u.s. time and I think once Easter the Easter break is over we will continue this and we will have some cost lots in in this repetition of interim meetings and we will continue moving things forward so we can get more documents off our plate now they do that we have added two more which thank you ever nice trip back "
  }
]