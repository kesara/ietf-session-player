[
  {
    "startTime": "00:00:04",
    "text": "okay so this is the second session of the htdp working group and you may notice that we have an additional guest up here say hello Lars hello I guess you have no idea doesn\u0027t know nothing about HTTP so this is a joint meeting of the HTTP and quick working groups and today we\u0027re going to focus just on the HTTP binding for a quick although is as Patrick mentioned earlier we had a bit of an overflow and last session so time permitting we might have another topic towards the end again you may have seen this in the last session but since it\u0027s a new session we should do it these are the IPR terms that we participate in the ITF under this is the famous note well statement if you\u0027re not familiar with it you can find it on your favorite search engine by searching for IETF note well and it\u0027s important because IPR protections and and antitrust protections are why we do standards or a large part of it likewise we have other policies regarding harassment which we take very seriously we want this to be a professional environment so if you feel that you\u0027re being harassed or you see behavior that you\u0027re concerned about we have an Ombuds team which is very hard to pronounce and these folks here are our folks you can reach out to and talk to either via that email address or in person you can also of course talk to us the chairs if you feel comfortable doing that so blue sheets Patrick good to go thank you they\u0027re going around please sign them can we have a volunteer describe this session we haven\u0027t done our homework so we\u0027re appealing to your better nature will someone volunteer whoever doesn\u0027t scribe me to finish the rest of the bubbles Geoff Hodges you are a champion if if you could scrub on etherpad that would be great yes they were okay right and you probably have too much to scrub right away so feel free to get set up well we use the HTTP this jabber room just for those who are confused agenda bash all we have is a discussion of of the HTTP binding we\u0027ve got a presentation from from Mike Bishop the editor or one of the editors and then we\u0027ll probably discuss some of the issues that are related to HTTP as I mentioned if we have time we had one item from the last session which is the HTTP trade discussion that will give for 10 minutes at the end if we have time any agenda "
  },
  {
    "startTime": "00:03:04",
    "text": "Bashan okay so yeah so Mike are you out there there he is fantastic I don\u0027t know do I need to press the button or can you just go ahead I bet I need to press the button let\u0027s find out nope Mike Mirko help okay there we go somehow apparently when I do video it doesn\u0027t automatically bring audio with it can you hear me now we can hear you it\u0027s a little bit indistinct it\u0027s a quite echoey room so if you could just try and speak loudly and distinctly that would help okay so if we can move forward to the next slide I don\u0027t have a way to control that so I imagine if you\u0027re in the room you\u0027re there because you know and care about quick but I will quickly recap why we care about it we quick has a nice property and handshake that you can get the version the crypto and the all agreement all in between 0 \u0026 2 RT T\u0027s and hopefully most of the time that\u0027s 0 TT has some nice retransmission properties where we don\u0027t retransmit things from cancelled streams which is not always true in TCP and most of the frames handle things below where it sheep he cares about mostly we care about the stream frames and how the data gets transferred next slide and this is also handy for a lot of browser and app implementers because if it\u0027s UDP based protocol you can implement it at the a player or at the OS line layer or some combination of the two so you can update it your cadence or you can have something in the OS that gets updated in the abroad way but as some people have pointed out the there are trade-offs that we\u0027re making by bridging letters there and it doesn\u0027t have to be implemented that way and you don\u0027t have to cross layers if you don\u0027t want to that\u0027s all it\u0027s available for you to decide on an implementation specific basis and transport is finding something that we\u0027ve already encountered in HTTP which is that encryption helps to playability that if the middle boxes can\u0027t reach in and try to help what they think you\u0027re doing and they can\u0027t mess up what you\u0027re actually doing and so quick has a lot of things that have been proposed for TCP or sctv improvements that we\u0027d like to take advantage of like "
  },
  {
    "startTime": "00:06:05",
    "text": "say tcp fast open but have not successfully deployed because of these metal box issues next so in terms of what\u0027s changed since we last met in Chicago not a whole lot on the HTTP level most of the work has been on the transport layer and the changes in the HTTP draft are primarily distracting what\u0027s going on in transport quick moved their special stream from one to zero so the control stream moved from three to one for the SUV layer we also had a slight change around how loosely our examples for old service because alt service always gives you a port there\u0027s not actually a designated port for HTTP over quick and the draft had some examples that were UDP port 443 which is what\u0027s currently in deployment but that\u0027s not actually normative to the protocol so I backed that out so if you advance there are a couple key issues that I\u0027d like to kind of frame a little bit if you\u0027ll pardon a slight quick one and then I think most of this time will be for issue discussion and if we want to have some of this discussion as we step through them I think that would be a good way to proceed through the issues sounds good so next there are two key HTTP exchanges that cause a little bit of awkwardness with the current way streams are handled and quick and so there are some proposals for handling each of those the first one is about what happens when you have a push the server is able to initiate a stream it pushes the resource you\u0027re fine but then an HTTP there\u0027s no client response on the push stream there\u0027s nothing for the client to say but because of the stream state machine as it currently stands the client still has to send an empty stream frame closing the stream saying yeah I really have nothing to say both sides already know that there should be a better way around that and there have been a couple proposals the second piece of stream awkwardness is an early response in HTP where the client is sending a body that may go on for a long time but just from the headers the server already knows that it\u0027s gonna 401 403 and doesn\u0027t care about the body it wants the client to effectively stop talking so next slide there\u0027s been a whole host of exactly what these should "
  },
  {
    "startTime": "00:09:05",
    "text": "look like in the current state we have bi-directional streams you send in both directions and the state machine looks a lot like the HT of each u1 where you go from idle to open to half closed and one of two states to fully closed and then the discussion has been if we make those a little bit more unidirectional there\u0027s a proposal where you effectively just have a pair of unidirectional streams and the state in each direction is decoupled from the other and half-closed becomes a shorthand for talking about the state of up here there is a pull request from en that proposes marking a stream when it\u0027s opened as being unidirectional so that it effectively goes from idle to half closed immediately and there\u0027s a pull request from Martin that takes the scram is to fully unidirectional that says there\u0027s a separate stream ID in space in each direction each stream has a very simple life cycle but then if you want bi-directional streams somebody has to handle the correlation either at the quick layer or the application architectural II I kind of like the fully unidirectional approach it does seem to make a lot of people I will say at least nervous because it\u0027s not like TCP but also because there are use cases for bi-directional streams as well and I\u0027ve heard the very reasonable concern that we don\u0027t want everyone to have to rebuild how to do a bi-directional stream so I think part of what we want to do in this session is to we know it when we have the key scenarios that are driving how its GP over quickest of us to work so if we can start the discussion here of what we at the HTP working group want to ask for one quick and I can\u0027t see all that clearly into the room so okay I see at least that Martin yeah I\u0027m like Thompson I\u0027m not sure that I\u0027m really prepared to have this discussion yeah as I understand it there are definitely interactions with CP depending on which one of these options we take but at this point I think we should leave that discussion for the other session where we it\u0027s only a tender there at least it is and the question I think that is reasonable to ask at this point in time is there any requirements that we would have and I don\u0027t think that there are any new "
  },
  {
    "startTime": "00:12:05",
    "text": "requirements exist but I\u0027d like to hear yeah I\u0027m not aware of any new requirements the two that are on the previous slide are already in the quick issues database so I think one way we could look at this is focusing more on the you know single stream versus pairs with streams issue then on the directional versus bidirectional but I\u0027m curious at this point who in the room considers themselves to be a you know I know we don\u0027t have membership but an active participant in HTTP the HTTP working group just raise your hand okay of any of you do any of our interview not participating in the quick group is there anyone here who\u0027s just an HTP but not quick okay just just one of that information Thank You Jenna angrily you just updated my question I was going to suggest that maybe we ask folks here who I think it should be but not too quick let me say something and obviously there aren\u0027t any um you confuse me though with something that he just said this isn\u0027t about two streams versus one stream issue right it I\u0027m assuming that\u0027s a separate thing that we have a separate slot on that mic yeah that\u0027s the next couple so if we want to move on to that that\u0027s fine sure I\u0027m sorry so currently and if everybody\u0027s been following you probably know this the connection control stream and it should be over quick instrum used to be stream three that\u0027s a response to crypto moving from one zero and that carry is session wide information settings and priority frames primarily as well as potentially extensions in the future and currently each request is straddling two quick streams where you have one stream that carries frames which is primarily headers and push promise the other stream carry is the unframed unframed data so that you don\u0027t have additional framing at the HDP layer and if you go forward one slide kind of illustrated the rationale of why we went to two streams in the first place there are two cue reasons one of them is HVAC that HVAC data HVAC assumes that all data has to have been delivered previously in order and reliably because HTTP 2 is over TCP so if you have any HVAC frame that the packet containing that frame gets dropped and the stream gets reset it\u0027s not retransmitted "
  },
  {
    "startTime": "00:15:05",
    "text": "and H pack dies horribly so one reason for having two streams is so that we can say one stream thou shalt never reset and the other stream hopefully curious the bulk of the data so you can reset that freely if you want to the second reason is various people have said that it\u0027s a nice property not to have the the headers of the data frame to strip away and have less overhead but if you go forward once thought we\u0027ve also went into reasons why we might want to go back to one strand and the biggest one there is that quick gives you know ordering guarantees between streams HTTP 2 has a should that the push promise brain should always come ahead of whatever on the main stream references the thing that you\u0027re pushing so that could be the headers frame because you\u0027ve got a reference in a line counter but it could also be a reference to something that is in the body of the resource and there\u0027s currently no way to correctly order the push promise frame on the header stream with something that tons to be mixed to it in the body so if you want to move back to once premium we\u0027re gonna have to fix the vulnerability to loss and header compression so got slides on that later but there are ways to do that as far as the overhead that we save by not having data frames that\u0027s relatively small you\u0027ve got a four byte header and the size of the data frame can be up to 64 K at that point you have to start having multiple data frames but even that we could change the max size of a of a of a frame if we want to and some of the other proposals for how we could fix the ordering and have multiple streams actually still use the data frame on the headers stream that says now you need to go look at this other stream to find a chunk of the body read there and then come back here for the next thing which effectively makes it one stream anyway oh and one thing I missed to say the other piece of the reason why we wanted two streams was so that we could separately flow control headers and body that in HGB 2 there is no flow control 1 headers there\u0027s some disagreement about whether or not that was the right decision but quick originally allowed you to exempt some streams from from flow control and that is and that property has been removed from quick so that\u0027s no longer something that\u0027s splitting into two streams affords us now at the interim there seemed to be pretty strong consensus about moving "
  },
  {
    "startTime": "00:18:05",
    "text": "toward one stream so I\u0027m planning to put up a pull request and probably merge that fairly soon but I would like to hear comments here from the larger working group if anyone thinks that they horrendously bad idea but not in Thompson that was fairly comprehensive thank you Mike I think all of the things all for all of the above reasons and probably a few more I think we should shove these on on one string the the arrangement of two streams the fact that you look on n mod for - you know n mod 4 equals 3 in that mod 4 equal one and everyone former equals 3 is the headers and then one for or equal one is the body and you\u0027ve got to cancel the body and you can\u0027t cancel the headers and it\u0027s just a mess and the the benefit that we\u0027re getting is this questionable anyway the the idea about having synchronization points between streams and and all that sort of businesses is something that just adds more complexity and I think they\u0027re good for and I write it it just it\u0027s kind of unmanageable ultimately and we have a really simple solution we just need to accept that the HVAC cancellation problem will remain until such time as we fix the edge pack think and well that\u0027s the problem of and we should solve that - yeah but my path right now is to force the dynamic table size to zero at which point you can lose all the HVAC frames you want you can reorder them up your Fon compression efficiency stocks but Jenna I ain\u0027t got I generally agree with what Martin said I don\u0027t think the mod 4 is that tricky to do I mean it\u0027s odd for instead of more - but in in I think the debilitating problem for me with two streams instead of one as we have it right now the draft is this the one that\u0027s on this picture it\u0027s the push promise one that seems like a pretty bad blow to that whole proposal and if you have to do any synchronization at all across streams you lost the point of streams it\u0027s not the same abstraction anymore so I am I completely agree that early on way early on when when Mike and I was speaking about this before the draft was even written I think we were talking about data frames as being unnecessary means just because you could even streams you didn\u0027t have to use the HTTP - framing but you\u0027re right in pointing out that of course that doesn\u0027t add that much overhead ultimately it\u0027s and it\u0027s going to be required if you need to insert a "
  },
  {
    "startTime": "00:21:06",
    "text": "push promise in the middle of a body anyways so I\u0027m very much in favor of going towards one stream it\u0027ll be wonderful to have that decision made so that we can do other things last point yes on H pack it\u0027s going to be broken for just a little bit but we are anyways going to try in the quick working group there anyways trying to move towards either Q power call Q cam or one of those proposals we know that that\u0027s what the end goal is and in both of those you can make it work with a single stream with resetting the body so I think I\u0027d be very much in support of going towards one stream so that anger I also wanted to echo my support for one stream proposal I think it also like removes the precedent of interrelationships between streams that like other trans other application transports are designed on this take the example and say that streams are just just you just you can just use the next stream and you don\u0027t need to maintain complex relationships between streams and might in the future simplify multiplexing application transports over this over one quick transport as well we don\u0027t have to preserve certain stream anyone else for the blue sheets put your hand out [Music] Ian sweat Google I also want to say that I I support this change and the main reason that I thought two streams before was a good idea mmm was the whole cancellation issue that obviously you want to be able to cancel the body and you know the fact that before you couldn\u0027t cancel the headers because of you know the compression algorithm and the fact that you\u0027re gonna fix that with with queue back in your new draft or have actually fixed it um pretty much removes the entire reason it from my perspective but all the other reasons are good reasons to do so you should do it okay Mike - empty okay well the echo is pretty bad example all right next next slide sure so just I didn\u0027t hear any concerns about going to two streams yeah that seemed pretty unanimous so I won\u0027t get a pull request in for that hopefully this week thanks Mike so on the note of a Petter compression we currently still use H pack as is in draft four we have a sequence number on the H back frames which requires you to be pretty compressed them and the order they were encoded it\u0027s not anymore head of line blocking than it used to be but it\u0027s no better with ideally liked it to be better so we have two actual proposals on the table and we also have the lock each "
  },
  {
    "startTime": "00:24:07",
    "text": "pack to a zero size dynamic table which as noted it\u0027s kind of drops your compression efficiency but would let you get rid of the sequence number which is eventually going away anyway so that might be a nice thing to switch to if we\u0027re moving to a single stream as just a way to keep the draft in a you could build this state even if we even if we know that that\u0027s going to be replaced so is there anyone who would be opposed to me switching to that and draft five even if we know we\u0027re going to replace it again later speak now okay so I\u0027m food that is part of my pull request so if you go to the next slide the two drafts are both H pack derived and full disclosure Q pack is the one that I wrote I\u0027m trying to present them relatively evenly here Q pack has a new wire format that if you look at it will be very very familiar to you if you have built each pack before but it is not h packs wire format to cram is much closer to H pack and in fact the same compressor could output either one with some it has some additions on the headers frame to communicate additional information q crammed I think the way I would generalize it is the Q crammed requires a lot of things that a Q pack implementation might choose to do so Q pack is more focused on the wire format and lets you manage your trade off between I want to guarantee them there will never be head of line blocking or I want the best efficiency possible and I\u0027m willing to take some risk and I think that\u0027s what Facebook Facebook\u0027s data they had done an implementation of each and run it against some sample header header streams and found that with Q pack you could get some head of line blocking if your implementation chooses to go for a greatest efficiency and the header compression rate matches that they both they both avoid the lost data risk by having one stream carry all the instructions that update the table and doesn\u0027t emit any state for a particular request and then on stream only uses the table to emit headers buck put out an updated draft of Q cram "
  },
  {
    "startTime": "00:27:07",
    "text": "earlier this week and that incorporates that technique I\u0027m sorry the slides don\u0027t reflect that so both of them at this point are reset resilient and Q cram assumes you have some access to pal frames are going to get packed in in the packet that you\u0027re about to send Q pack doesn\u0027t specify that although they\u0027re again I could see an implementation choosing to do that as an optimization so I think they are actually very similar and a lot of respects once you get down to it and I don\u0027t know if at this point we\u0027re ready to actually express a preference as a working group and pick one to move forward or if we want to just sit on H pack with a zero size table for a while let\u0027s see what the room thinks so Madden Thompson I was pleased to see that buck had revised his draft this week and it\u0027s been a bit of time with it there\u0027s a number of things in there that make me sad about that particular proposal to the extent that I think I would very much prefer Q pack and the primary one is that it requires knowledge of your packetization logic at the point that you encode headers and that is hazardous in light of the fact that you might have to send the that data in different packets at some point in the future in case of loss and there\u0027s no treatment of that at all in the draft unfortunately and it I think that\u0027s the the single most brittle part of the whole thing and yes while it doesn\u0027t rely on that I think it relies on that for performance reasons and the recommendation to have that degree of awareness it\u0027s problematic the other thing that I noticed was that it has an eviction race problem and the eviction race problem the way that it resolves that problem is failing it\u0027s like open catch fire if this happens and that to me is problematic for other reasons and we know in H pack that eviction is pretty damn common it happens all the time and particularly in long-lived connections and if you if you set this up for failure then you you\u0027re setting yourself up for failure but by doing it that way so our buck is in the queue I\u0027m gonna try and see if we can make that work so you can reverse by assuming to respond yeah hi can you hear me yes we can okay yeah so I do want to respond on the firaon the first point I think maybe that raft is could be clearer in that "
  },
  {
    "startTime": "00:30:10",
    "text": "the packetization is definitely kind of optional and badly in need of data I\u0027m definitely open to the idea of actually just removing that I think in fact we can get some clarification from Alan but I think in his study it was not fully implemented but Alan can clarify I\u0027m not really convinced I don\u0027t have data yet on how much it moves a needle it could be that it doesn\u0027t move the meter the needle much at all and now I guess I think to what I heard about the original H pack where you know there were smarter proposals and in the end the performance difference wasn\u0027t enough and simplicity sort of ruled the part that does there\u0027s sort of two forms of this packages a ssin or two forms of transport coordination and Q cram the other one is just knowing when data has been act that one is kind of needed but I would argue that that one is not so hairy as as the one of knowing where packet boundaries are so I would hope I think that\u0027s perfectly fine that is like a very reasonable requirement we have a number of other code places in the protocol where knowledge of acknowledgments has such a positive benefit on performance or what have you that I think that the transport API for quick will necessarily have some sort of acknowledgment signals regarding string data I think that\u0027s that\u0027s a that\u0027s a good property I know we have several of those at the transport layer but do we have any others of those at the HTTP layer I can\u0027t think of anything possibly in the hinchik yeah maybe in the handshake actually I\u0027m pretty sure there are it if you a few and they handshake nothing but I could be wrong that was in the sweat so I did want to say speak also to the point about table eviction yeah so that\u0027s another one where I think we really need data I the I went with the nuke this dream option because I think it\u0027s going to be very rare this isn\u0027t any table eviction nukes of stream this is a table eviction that is coincident with a packet drop that happens to affect you know the current header in flight so I really think it\u0027s going to be quite a corner case that said I would also question the basic premise that table eviction is really common and long live connections are very common maybe long live connections are more common with h2 I think a lot of "
  },
  {
    "startTime": "00:33:13",
    "text": "our data suggests that in fact long live connections with quick are fairly fairly rare the you know we have telemetry data on you know the number of streams over the lifetime of a connection and there\u0027s a lot of you know relatively short-lived connections out there and you know in in practice my understanding was until a year ago nobody increased the table beyond the default 4k these days quite a few people raised it to 64 K but it\u0027s extremely rare to go beyond that I I don\u0027t agree that table size and table eviction is actually a first-order issue and we need data this is what I was actually comment that I read the current queue back draft very closely and on a conceptual level I was reasonably happy with it but I had a lot of detailed comments that probably need to be resolved in person so in my opinion it\u0027s it\u0027s certainly far enough away from anything I would want to do that I would not say yes to it at this moment and I would rather just stick with the static you know HVAC and the qqm draft I just haven\u0027t gotten to read the new version yet thank you very much for updating it but I mean I hope by Seattle maybe we\u0027ll be a lot more informed but I think it\u0027s pretty premature to pick a direction at this point and that was my question is are people comfortable delaying a decision about this until the Seattle time frame at least Chennai but I think we should in fact this work on gathering more data as well so I think it\u0027d be very useful to actually have more data and this conversation it\u0027s not just about design niceties it\u0027s actually about performance ultimately all of this is about performance and if you\u0027re able to actually show some numbers about what\u0027s hominin what\u0027s not and what actually gives us better performance if they don\u0027t if they give us equal performance then we can talk about what other things are useful but yeah I\u0027d like to wait to see some numbers okay I just would remind folks that when we get those numbers it\u0027s important that they\u0027re not necessarily specific to one implementation or one deployment we need to encompass the entire web here not just some use of it okay yes I can jump back on the screen here so if we go next slide moving on to other structural things of how it should be in quick interact the so the setting oh hi Jonathan it\u0027s okay hi Jonathan "
  },
  {
    "startTime": "00:36:13",
    "text": "all right so currently HP / quick uses a settings frame just like hep-2 does Jonathan but so we don\u0027t allow any changes to the settings once you\u0027ve sent them so we remove a lot the complexity and machinery of setting Zach there\u0027s been a proposal that we could allow the application layer to stuff a blob into the quick transport settings and handshake which for us would probably just be something serialized that looks a lot like my settings frame and drop it in one of those values so then so then you would need to include settings for any application that you\u0027re offering as part of the handshake now the biggest drawback to that that\u0027s been pointed out is that everything that\u0027s in the client hello which is where the transport settings are is sent in the clear and therefore the entire world would be able to see your settings frame now and the settings defined in the spec there\u0027s nothing terribly sensitive in there so I think that would probably be an okay trade-off but I don\u0027t know what might eventually wind up in there with extensions and other settings and without the ability to send new settings later under cover of crypto I\u0027m not sure if that\u0027s a good trade-off so I wanted to see what one comment on this is it might be possible if we actually have a packet type or a way to define both 0 RTG data and you know unencrypted data client hello data for example in one packet we could put the settings in the zero RTT portion which I think currently already happens because you would send the settings frame on the connection control stream or on stream one as soon as you have 0 13 connection the the issue there is that you don\u0027t have both client and server all the way up front chat hearty back stop I have two kind of questions one is do you think it would be possible for us to find this in a way such that the quick transport settings are then paired with a more generic set of other application settings since clearly at some point quick will have other applications in addition to HTTP 2 and we don\u0027t want to have you know a DNS "
  },
  {
    "startTime": "00:39:15",
    "text": "application or some other later application to have to set no HTTP settings in order to conform of the protocol and second when you say that the client settings are in the clear as a result of this I think that at that point I just made makes it hard to do the analysis of what the impact of those client settings being in the clear is because if all applications are going to do the same thing we need to know what privacy properties of those settings are going to be in order to determine what the implications of them being in the clear would be which kind of trends me towards saying keeping keeping the application settings distinct from the quick settings would be a more appropriate way to go to maintain quick is at its maximum level of flexibility and privacy for for future application Carolla so the combination of the settings are in the clear and the only consent settings one seems particularly unfortunate be a museum no it means if you ever has any want to say that was confidential we have just no way of doing it at all so I guess so I\u0027m Martin smothering defined as it is um generally I probably my intuition as well I mean premiere as the seems like there are two of it to potential advantages to this design one is that might be conception a simpler and the second is that I guess you say get to save a round trip because the client can send his consent his settings in the first round trip I don\u0027t think the second is that is that great an advantage and as Ian says if 3 and 0 or 2d or not that won\u0027t be an issue at all so I think I\u0027m not yet persuaded this is a good change jahmai going to basically relate what I could just said I agree that having the same settings for HTTP 2 and quick have very different result were dead-set having different privacy properties seems like a problem we\u0027d want to avoid and so that\u0027s yeah the potential drawback is pretty significant from where I see it all right so where I think the privacy trade-off is a guide trade-off sorry all right so that sounds like that sounds like a linear direction so if we can update the issue and get hobb I can do that or mark either way great so we can move forward the next "
  },
  {
    "startTime": "00:42:24",
    "text": "slide talking about the error space so we\u0027ve we took it shift in quick to like to divide the airspace into four regions one of which is for the application and those errors show up to both when you close streams and when you close connections there\u0027s been an emerging principle that the transport should never close a Stringham out from underneath and be application layer which would imply that any transport error is fatal to the connection and streams should only close for reasons of the application of the coals and that would potentially let us six and bit so the aerospace but more I want to get into the do we think that that is something that at hjp is their reason that we think the transport would need to close a stream and would we be okay with that or do we want to put as a requirement on quick that the transport should never close something out from underneath us and I assume that we need the ability to close the connection with an error from the application layer which implies that there needs to be some ability for education error that contamination in the connection coroner would be to forbid the transport from closing specific streams it doesn\u0027t know whether those streams contain state that the application depends on in and it doesn\u0027t know that killing them is safe and it cannot know and that means that the error code space for reset stream would be entirely under the control of the application that\u0027s been used do I agree that the application needs the ability to kill the connection with errors of its own so what we would have is connection close would have effectively transport error codes and application error codes and we would be able to distinguish between those two spaces does that make sense to people and I would like to see if we can close on this one I was kind of prepared to talk about this one in the later sessions but since you bring it up I think we should talk about it and kill it but just left okay go ahead Jenna oh wait no puck wants to talk sorry I was just gonna save clearly for the H pad case there\u0027s going to be some some you know global H pack is still has global state and those could have errors which will require closing the connection thanks Jenna Jenna Iyengar the use cases that we have right now at least it seems reasonable for the transport that never "
  },
  {
    "startTime": "00:45:24",
    "text": "have to flow streams on its own anystream erasmus pointing out should cause a connection close better at the transport so I there\u0027s no protocol error and in quick for example for specifically that\u0027s going to cause quick to just close a stream any protocol errors that happen inside equipment cause quick to close the connection separately I\u0027m on the second discussion point whether an application can terminate a connection with error I I\u0027d have to think about it some more but it seems odd for the application to be able to do that here in quick in TCP yes it\u0027s done but in quick given that we expect applications to have a signaling stream it seems reasonable to use that as a way to signal the other side that the applications shutting down and the connection is closed transport part of this quickest close the transfer connection is closed as it normally would be so buck pointed out on the jabber channel that any kind of header compression error currently requires you to avoid the connection which is probably going to be true under whichever scheme we move to and so perhaps we could communicate that on the signaling stream we didn\u0027t get that on the simulator in the table with a connection yeah so so Martin Thompson I think the hazard there is that the connection continued during the processing during that the time that that signaling is happening whereas having a single unified way to say nah this is bad go away and we\u0027re using all of that logic is is an efficiency that we can we can take advantage of I think it is mainly just an efficiency I mean ultimately the same messages are going to be exchanged but having having that transport aware means that now the transport is no longer doing things like we\u0027re transmitting packets and and providing all of the repair mechanics that it has and you know reading from its send buffers and all of those sorts of other things it\u0027s just going to be simply right where we\u0027ve initiated the shutdown now and I think that I think it\u0027s just an efficiency game that\u0027s probably one that\u0027s worth having Jen I am that I actually you\u0027re pointing out is that it\u0027s maybe more than just an efficiency thing and I think you\u0027re right that in this case there\u0027s no urgency at the transport because the transport sees that the application also shut down this particular stream and does nothing and it schedules it with other rights and it could be actually cute way behind other stream rights if things aren\u0027t done right and on the read side again the same thing the transfers happening do so the applications come exactly the applications pending the process data well the application on the other side long ago said please shut "
  },
  {
    "startTime": "00:48:24",
    "text": "down everything so yeah maybe there is a good reason to do this um I was wondering if the conversation we are having here it\u0027s it\u0027s sounds like it should be something that we should either continue or have again in the quick working group but yeah that\u0027s fair enough okay Mike are you still out there did we lose you but I am back fantastic should I go to the next slide yes so this is an interesting one I stole a graphic out of a presentation from a while back about how Firefox does priorities and a number of you a implementations do the priorities by taking idle streams and using them as placeholders quick has a bit of a preference for using streams in order continuously which kind of makes this not work and now that\u0027s less of an issue now that we have the mac stream ID as opposed to max concurrent streams but at the same time you have to assume that the server is going to consider those three that you haven\u0027t started sending on because technically you could and maybe we just say you\u0027re gonna do this then Patrick why don\u0027t you go ahead and respond to what you think he was going to say I mean I was gonna say this is you know sort of always a weird little overlap but the function it provides the grouping function is like really wonderful so is it particularly hard to build sort of a fixed set of slots to do this grouping in explicitly you know into into our new protocol to accomplish the same end but to do it rather than sort of abusing on ustream ids to have a table of grouping grouping orders some mutton Thomson I don\u0027t know if Mike can hear us and that\u0027s unfortunate but one of the things that he said was slightly incorrect the mac stream ID does not allow us to do this because if we start using if we were to allow the use of streams as placeholders then we have to allow for streams not to be opened up in contiguous blocks we have to allow them to remain idle and then we have the possibility of denial of service in the case where you you\u0027ve someone thinks "
  },
  {
    "startTime": "00:51:26",
    "text": "that a stream is being used for just merely as a placeholder but then requests start arriving on it and you\u0027re you\u0027ve got you\u0027ve had a connection open for several hours they\u0027ve been several thousand of these things happening your maximum number is set to something that is based on the on this assumption and now you have a thousand extra streams arriving and that\u0027s just not cool so we need to I think Patrick\u0027s request is perfectly reasonable and we can realize it we make small tweak to the priority frame put another flag in the priority frame header and say well you know the the root of this dependency or the target of this dependency we have Nick Nick two bits is is actually a placeholder and the value in there comes from a different numbering space there\u0027s other ways you can do you can slice this particular thing but I think that\u0027s a reasonable yeah and I mean it closes a little you know deficiency in age too that people don\u0027t like that these these things are unbounded in that way and we could could bounce them in a better way right I I don\u0027t think you actually avoid the unbounded state problem based on this it\u0027s unfortunate but I think fundamentally the priorities system that we have does have this unbalanced a problem inherently and it\u0027s not something that the placeholders allow you to fix sorry I think buck wanted to respond I had a question in response I\u0027ve heard it it articulated a few times that there\u0027s you know some unhappiness with the h2 priority scheme and that maybe HTTP over quick might actually go for something different that for example doesn\u0027t have the unbounded state issues is that like is that are we is it is is the direction to probably stick to the h2 priority scheme or or is there openness to you know it\u0027s changing so so far in the discussions we\u0027ve had to date the feeling that I\u0027ve heard expressed most is that we want to keep as close to h2 as we can to minimize introducing you know more than one change at a time now I think we\u0027ll assess that as we go along but that\u0027s the philosophy that we have in mind overall right now so Munson again from my perspective sticking to that philosophy with the caveat that we might be open to new information that comes along for instance if if people learn that there\u0027s a far better scheme for prioritization that doesn\u0027t have some complexities or maybe we need to add some things to the prior scheme we should be open to that possibility but yeah the amount of work that we have on our plate right now is frankly massive whirring yeah very "
  },
  {
    "startTime": "00:54:27",
    "text": "worrying and let\u0027s not open up too many cans of them at the same time and this is just one of those ones that I think well yeah so it\u0027s maybe not ideal and maybe when we aren\u0027t happy about it but it if we\u0027re going to do it justice we\u0027d have to spend a lot of time on it and I think I\u0027d rather spend that time on the more important issues like getting this damn thing working sure and just for the record I see nodding heads in the room I\u0027d add to that one additional slight thing which is I do sense a strong aversion to using this as an opportunity to try things opportunistically I think we\u0027d need solid data that we were actually making a little better rather than just having another go at it we had a little bit of that in h2 and it burned us a little bit so and and it\u0027s this is again not the last opportunity we\u0027ll have to make changes in HTTP yeah and I think I would add to that that since this is a quick working group document even though a lot of us participate in both working groups if we were to do something that doesn\u0027t directly relate to we have to change this because of how it interacts with quick I would want to see that as something that the HTTP working group did and sent to us and that\u0027s partly why I think a joint meeting like this is the perfect time to discuss if we wanted to do that and it sounds like the answer is currently No oops yes yeah Mike wait Mike were you able to hear or any bit when you get disconnected I\u0027ve heard the bulk of the audio I lost video for most of that time can I move to somewhere with a better Wi-Fi IP mostly we discussed the concept of like a explicit grouping no it\u0027s rather than using Street you ready for the next one yeah so on the note of how we relate to HTTP 2 this is a slide that I had almost verbatim in Chicago and I don\u0027t think we quite reached a resolution there that we have tried to keep this as close in spirit and similarity as weekend HTTP 2 but because of certain traits of quick and how the integration goes almost everything is dive arranged a little bit and I have a section on the spec that describes what the differences are what the similarities are and I\u0027m wondering at what point we actually whether we want to go into this back and say we\u0027re just "
  },
  {
    "startTime": "00:57:27",
    "text": "going to use separate IANA registries and call this a different protocol as opposed to being something that is kind of HTTP - and kind of not was talking with our devs as we reviewed things through here they said more likely there\u0027s a lot of places they could reuse code but it was looking less and less likely that they would be able to use exactly the same code on both sides and likely it would approach as a copy of the htv-2 code and run that over and start adapting that too quick so I\u0027m wondering do we want to reflect that in the document and to what degree so Mike it\u0027s Marc I had thought and maybe it\u0027s just my horrific memory but I had thought that we either agreed to or at least had a strong sense that we were going to do that personally I find the current registry documentation very confusing and I have a strong personal preference for separating them but that\u0027s just me I didn\u0027t think it was as strong but if this room echoes that then great I have a super simple answer anybody else yeah Martin Thompson others may disagree but I I think that at the point that we made that the 10 or 12 decisions that caused us to be ever so subtly different in subtle ways often and none so subtle ways we did actually make a new protocol it\u0027s unfortunate but made a new problem there are some things where extensions to h2 are very easy to port across into into quick and for example the the stuff that we didn\u0027t get to talk about earlier on secondary certificates I think will work perfectly well in this context but I think we need to have at least some sort of explicit signal that someone once has considered the use of extensions or what have you before we just let them work in both protocols I don\u0027t think having something working both protocols is is a feasible plan Arabs grow up um I guess I\u0027m not particularly bit about the Registry\u0027s but I am like and I understand that were in a situations where things don\u0027t working with protocols but I guess when I\u0027m concerned about is designing something where like things have no hope of working with protocols and where everything we design requires new engineering so I guess I\u0027m I think I was a personal push back on this last time um and I guess I\u0027m I\u0027m I like to "
  },
  {
    "startTime": "01:00:28",
    "text": "understand our principles were actually adopting here because I think I saw some were nodding when I just said that and so and so it\u0027s like I guess how do we make sure that that happens so to be clear I mean I think that the intention of keeping close compatibility and and where it\u0027s possible is a very good one it\u0027s just that enforcing that alignment to the registry doesn\u0027t seem to work mm-hmm the question of registry is is fine but echoes echoes core concern is that we don\u0027t end up making it very difficult to to gain these properties because obviously one of the things that we\u0027re trying to preserve here is some sort of seamless reuse of the semantics that were available to us in other versions of the protocol if we create too much of a gulf we end up with the possibility of fracturing between the two of them and that would be a very bad place I would like to see what mike has suggested here which is a transitioning from HTTP to section actually states and principles under which the designers was made simply because that that\u0027s a commitment from us that we will we intend to have this happen and also to have that that as a sort of strong guidance to those people of building things or one of these protocols that they consider the other one when doing so and so we don\u0027t end up win a situation where someone knowing unknowingly builds a product a protocol extension for one or other of the protocols that simply doesn\u0027t work in the other one and we know if we love fracturing in but in various ways because I think that would be very unhealthy for the protocol I think we need to move in one direction as much as possible right so I\u0027m bugs waiting but I just want to insert myself to answer that real quick I agree with that very much so but you know in this maybe this is back to BCC 56 best most people in they extend HTTP are going to be adding headers or or methods or or truly generic artifacts when it\u0027s you know version specific stuff like h2 and HQ frankly that\u0027s probably gonna happen here and and we will have good guidance for that we should write some that down at but I\u0027m not too worried about that so yeah let\u0027s do buckin than you I was just gonna give an example for that guidance section you know for the foreseeable future any large-scale deployment is probably going to want to have fallback and so for the very yin n so that means that some higher level you know applications will go through some interface that goes either direction like either to h2 or HTV over quick and keeping that in mind in terms of compatibility makes a lot of sense yeah I mean I think um I mean like the way Martin framed it um so um I guess I guess I want to give a sample actually I mean I guess with this unfortunate "
  },
  {
    "startTime": "01:03:28",
    "text": "situation we have these things that were designed assuming h2 semantics and now they\u0027re hard to port it to quick but going forward with opportunity pull things that potentially you know or you can take bones can new accounts and so we can be smarter right on and I mean I was thinking earlier the origin frame is an example of something where you might might or might not be be smarter um but we know be sad to have to to origin frame documents right that be like silly so um I guess do you think it\u0027d be possible to perhaps see a PR that did both these things and then we could examine it sure thank you yeah I think I agree with that I think one the same page yeah I\u0027ll be happy to put together a PR or actually there\u0027s an existing one sitting out there I would be happy to update it with more guidance and in particular I think we might even want to have the I Anna even if it\u0027s a separate registry have the guidance feed that you should not allocate the same good point in both registries to vastly different things which is the weaknesses sorry go ahead sorry we can also specify that the experts are shared between the registry know the coordinate just just to make sure we\u0027re on the same page you know what I think about that you know the origin frame good example that document should be one dog you know if existed that would be one document and the INA consideration section would have two registrations and it\u0027s done a more complex you know document that had some protocol implications hopefully you\u0027d have one big section that was the semantics in the core you know artifice syntax and then you\u0027d have a section that\u0027s mapping the stage to which is hopefully very small in a section that\u0027s mapping this to HQ and that\u0027s hopefully small and then you\u0027re done that matches my expectations as well okay great right my expectation would be would be that the ideal would be you just design it not to rely on order between the streams and if it works on HQ almost certainly it\u0027ll work on HP to where you do have work very possibly yes yes because that\u0027s the biggest thing go to my gym but yes you just have to registrations for the exact same frame type okay and there\u0027s one more slide which is something that I don\u0027t necessarily want to know what to get into a discussion of but it\u0027s been on the quick list for a while I just went to plant the seed that I mentioned before that we took out the examples that pointed to UDP port 443 and when I reviewed these internally yesterday one of the questions that came up then was well then what is the port for HTTP over quick and right now the answer is anything old service says it "
  },
  {
    "startTime": "01:06:28",
    "text": "is because there\u0027s actually no going from an HTTP or HTTPS origin the only path to reach it should be over quick right now is the alt service right which means you have to have TCP in embedded in there somehow and we might eventually have a world whether it\u0027s IOT or the far distant future where not every client wants to have TCP we might go the approach of well those clients should just know that the endpoint that they want is quick can be if we can think good for that we might do something like SRV records or old service over DNS but I feel like before we call this completely done we should have some way to reference this thing is on a quick port and I don\u0027t think that just try you to be four four three and assume the TCP and UDP ports are equivalent is quite gonna fly getting quite the queue you\u0027re getting a queue you\u0027ve stepped in something so I I actually kind of like the observation here that we don\u0027t actually have a URI that identifies something a resource that exists that that is reachable only by quick or a resource that sits on something that\u0027s a quick we have on some of it services and I\u0027m actually kind of comfortable with that for the for the moment that may change with time the other thing that I wanted to get up and say is that if that does change with time the definition of URLs in 3986 and the various documents that describe those describe the port number as a number it doesn\u0027t specifically say that it\u0027s a TCP port number it doesn\u0027t specifically say that it\u0027s UDP port number it\u0027s a number and how the protocol interpret number how you are to interpret that number given that it is actually a locator is something that we do have a little bit of leeway in defining but we\u0027d be we\u0027d be sort of pushing on revising or updating 7230 if we if we started down that path but I think we can avoid that doing it what it actually says is that it is a number and view transport is defined by the schema and the scheme registrations for both HTTP and HTTPS say that it\u0027s TCP like I said it would require an update yes I\u0027m going to close the queue just because we do have another topic we\u0027d like to get to and this isn\u0027t I don\u0027t think anything we need to decide right now so please go ahead I said I don\u0027t "
  },
  {
    "startTime": "01:09:29",
    "text": "want to discuss it yeah gen-i and god i yeah i agree that we don\u0027t I don\u0027t think that we need to go updating HTTPS yet it seems like it\u0027s a it\u0027s an interesting it\u0027s certainly an interesting use case where you know that the other endpoint talks quick but not DCP but you don\u0027t know where to talk to them we certainly aren\u0027t in a place where we need to do this yet we\u0027re pretty far away from that world right now yeah air patroller I mean we talked about this actually over the weekend is she meeting there\u0027s a co-op which has a sort of similar set of semantics about you know confusion about the DDP versus TCP in this case it was TLS versus TTLs but it\u0027s the same same generic concept and I think you know the of the IETF meaning dissolution plus at some point probably needed it last month but it doesn\u0027t have it I think it doesn\u0027t need it for this particular use case for awhile I mean it\u0027s just I mean it\u0027s just for technical reasons it obviously has to be the case that the scheme is HTTPS or like completely screwed so um so I mean it may be the case that we need to find someone who\u0027s in the URLs to say actually I mean UDP I was suggesting to large before that would you know make it on the number which was congruent to 4 4 3 mod to the 16 uh-huh but the indicators UDP but in any case I think probably we should punt this until we have a but I mean maybe we can cue up some sort of maybe the IAB and that study the question of like how to indicate for transport semantics in an URL I\u0027m Joyce there\u0027s actually uh Ted Hardy your suggestion to the IAB has been noted by the IV in the form of Martin writing a note a quick points of information to mark I believe I understood that you were working with Vienna to talk to the current registrant of UDP 443 so that it it it\u0027s status was clarified could you give a quick note to the working group on that an update yes so I think the current not owner but what is what is the dredge astern register written area and sent a polite note and was asked for some clarification which I gave and then there were crickets so my understanding the last I heard is that the I ASG is now thinking about a more holistic approach to this issue I actually don\u0027t recall that conversation about a more holistic approach but I agree we should have one and I guess I\u0027d be willing to make sure we do or make sure we start the conversation cool because if you look at the one on ports we have this problem a lot right I\u0027m not I guess I guess my thinking now is that individual um I think we should simply take all the I "
  },
  {
    "startTime": "01:12:29",
    "text": "think we just if we take all the center of all those ports and make them under I usually control sure I had a conversation with and they did assert that ID is G had that power Ted Hardy it is in fact not clear that di use G has that power I had a conversation with the folks at I Anna and it would be very valuable if we could actually run the process that I Anna currently understands to be that it is a release and catch system where the current registrant releases it before it is caught now if there is the case that the registrant is not available due to death then there you know certainly willing to say that there is no possibility for release and that the catch can go forward but if we\u0027re actually gonna say that it proceeds in some other mechanism there is a document we must update and consensus we must achieve before that sure yeah I did have a conversation with Joe touch about that because he was one of the authors and he asserted some things about how that worked that I couldn\u0027t read out the document so it\u0027s at least ambiguous maybe um I recently already signed a couple of ports through IG action but I think I earn a preference is to have some kind of record whether it\u0027s IG action or and so document might be the simplest way which Justin always told of course we want to be reassignment I mean it\u0027s a trivial document yeah we look forward to that document coming from the is gene now the microphones are closed I just saw a volunteer now so Mike was that all you\u0027ve had yep that\u0027s all that\u0027s in my deck and if we had any time I was going to propose me look at the issues list for anything else that people wanted to talk about but I think we would be better served to get back to the HTV topics okay great thank you very much Mike that was really helpful so now it\u0027s 4:35 we have 15 minutes and we had an item in our last session which got punted so now that we have a bit of time we might get back to that Julian are you with us I have a question for the chairs sorry I have a question for the chairs yes the issue of two streams was this one we have the discussion here and is there any I I\u0027d like to see an end to that discussion is that something that we are going to try I believe the outcome was that that we were going to see a poll request and then we confirm that that\u0027s what we want to do on the list as with all of our decisions Thanks Julian Julian rashke Julian you need to use the special link I think or put yourself in queue and I\u0027ll recognize you there is hello no we can hear you okay "
  },
  {
    "startTime": "01:15:30",
    "text": "so this is something that we\u0027ve talked about a bit over the last few months and that we that we came up during the HTTP workshop next slide please so the question is do we want to revise the HTTP 1.1 specs and if we do so what exactly do we want to do so my first slide shows a bit of the history of the specs the blue one is 1.0 the green one is one of one the red one is to zero on a time scale and just shows that there was a very large gap between RFC 2616 and until we got back to work and then it took quite a long time to actually finish this we are now currently having two HTTP specifications one of which the old one containing all of the semantics and the new one HTTP to just containing and you would transport plus a few new features and there\u0027s also the discussion about how HTTP over quick relates to that next slide so why do you do we actually want to update a document that\u0027s because the RFC is that the RFC editor publishers are actually immutable so people keep looking at information that from the time it was published lips immediately becomes updated for some value of outdated the RFC editor collects errata but most people don\u0027t actually find the errata another thing to consider is depending on how much we want to do even if we do only a bit of housekeeping we won\u0027t be done before next year and that would be four years after the publication of the previous spec so it\u0027s time to at least think about this and there\u0027s these carrots in front of us that\u0027s the RFC editor will actually adopt a new publication formats and people will stop talking about IDF documents being unreadable and being from the seventies so I think that it\u0027s worthwhile to try to get more readable "
  },
  {
    "startTime": "01:18:33",
    "text": "document sets out there but once we can explain so there are a few obvious things that we need to do we need to apply the errata where we actually have a few Virata that we don\u0027t have solutions for yet some tricky a B and F problems for instance there are a few references to updates we have a new issue tracker that currently has about 30 issues rest against the wonderful specs and then there\u0027s the issue that the one that one specs currently do not even mention that there\u0027s HTTP to spec so even if we want to respect us to minimal changes we would have to put in a few pointers there to clarify the relation to the HTTP to spec and X light so this is a list of things that have been mentioned in the context of revising the specs one co-author actually wants to reorganize the documents again so we currently have six parts and one could argue that\u0027s less parts would be better also we have the situation that most of the HTTP 1.1 spec essentially is about HTTP in general and the only part of the first spec actually talks about the wire founded of HTTP 1.1 and it would be very nice to be have a clear separation but of course that\u0027s quite a bit of work we also have a few satellite specs that we\u0027ve finished after we were done with this that might be candidates for inclusion into a revision of the HTTP 1.1 spec because they are very small and essentially come fill holes that we left in the spec because we couldn\u0027t actually add new stuff back when we were doing this then there\u0027s the question about how we happy was sitting in the proposed standard spot or do we want to have a full standard ITF process-wise but if we decided that we are probably would be respected and the amount of things we can change our next slide so one obvious thing that we need to do is we need to try to get people back to "
  },
  {
    "startTime": "01:21:35",
    "text": "the report box mmm my current feeling is that people are very focused on http/2 specific things so and that they assume that one of one has done for somewhere you have done and don\u0027t even care about reporting bugs so would be good to get people to have a look at the notes and come up with back records if there\u0027s something wrong and we need to discuss how much we want to do when we want to do it one do we want to finish that before next to after HTTP over quick also depending on what we want to include to the scope we it will organize the order in which we do things very carefully to reduce the amount of divs that we produce so whatever we changed the specs should be very easy to review for readers um and I think there\u0027s another slide at the end I just wanted to point out that although the RFC\u0027s that the RFC editor currently publishes do not include errata information there\u0027s nothing that stops us from publishing better documents ourselves and the machinery to do so us there questions feedback so if I heard you correctly you\u0027re not proposing that we start this work now but just to start thinking about it nope well if everybody says that stop now then we could start no but I think we should take some time to figure out what we actually want to do what when sure so as the newer chair who did not work on the editing the documents for the last bit sound I\u0027m interested if and I realized we did as a changeover between sessions but I\u0027m just interested to see if there\u0027s some enthusiasm amongst this set of contributors for work on this project essentially a business of http/1 one term tray this prime those are all possibilities okay thank you I\u0027ll say personally that I think this work is important and I\u0027d be willing to "
  },
  {
    "startTime": "01:24:36",
    "text": "contribute to it perhaps not as a chair which would put some burden upon you perhaps but I think it on the scope is important I would not want it to be an engagement similar in length to the one we did last time that went on way to all yeah but we had a lot more to do than I think I think if we scope this well it can be much more manageable and we also have the enjoyment of more attention from implementers than we had back then we had to be very careful back then because we needed to be very conservative we have the ability to bounce things off of more people now which i think is very useful and will allow us to be more effective anything else Julie enters that and wrap it up I guess that\u0027s it I mean it\u0027s not surprising that there\u0027s not a lot of enthusiasm because maintenance workers never as exciting as doing new work but that doesn\u0027t mean that\u0027s not informed right and we have to balance the value of that versus you know the cost obviously you have you know a lot of people\u0027s time and attention that\u0027s you know interesting discussion yeah and that\u0027s because that\u0027s why we if we want to do that really to really understand what the scope should be how much we want to change how much we are willing to change and or not to change yeah I mean I think that most of the cost would be on the editors in in that due to the nature of the work it\u0027s maintenance we\u0027re doing some wires - that\u0027s a discussion in the working group it\u0027s probably not in scope but I think maybe we should let it sit for a while personally I plan to gather issues and try and get the issues in good shape as well as get the source in good shape so that if we want to we can start doing some speculative PRS and things like that so it\u0027s a Mountain Thomson I know I know that we actually do have a few issues that have been open we have issues opened in the working group auditory and some of them will require discussion how do you intend to deal with those because if you you said earlier that if it were just maintenance dealing with a rudder and and correcting things that are simply just wrong that\u0027s not something that could be done by anyone at any time they can propose a an individual draft and we can look at and say yes well that\u0027s the same document we\u0027re just these changes thank you very much we\u0027ll take that and publish it but if we\u0027re actually talking about those substantial substantive issues then it "
  },
  {
    "startTime": "01:27:37",
    "text": "does require and write more than more than the investment that so certainly there are some that are gonna require some discussion but I think it\u0027s a manageable set it\u0027s not fifty issues or a hundred issues I mean I guess I\u0027m doing this from from the perspective of the last effort which required so much worry so that was a there was a yes research exactly and as a result of took seven right whatever years is and I don\u0027t want to sign up for that again I\u0027m pretty sure Julian doesn\u0027t want to either [Laughter] that was unglamorous work and also hard so that was hard unglamorous work that was ultimately very valuable and everyone appreciates that and it would good if we continue to capitalize on that work and keep the specs updated and relevant but I\u0027m just trying to balance this against what is a fairly hefty workload we have a lot of work ongoing in this working group it\u0027s pretty active and we\u0027re dealing with this whole quick play out of quick and that\u0027s gonna absolutely and I think this would be like almost a background task for the working group that you know we\u0027re winding down some other things which is good the question is okay you know is this the appropriate time to do that there\u0027s one other factor for me and that\u0027s that you know um there\u0027s a lot of work going on in the browsers in the fetch spec I know people have very different opinions of that spec but they are encountering some you know interesting issues with HTTP that without guidance from us though they\u0027ll answer themselves and so that\u0027s you know something we need to be aware of as well and they\u0027ve been good about raising issues in our rep oh but if we let them sit there for the next five years well I think we deserve to not own that anymore that\u0027s true the scope thing that gets very itchy very fast though because some of those are requests to basically address things that were not addressed so they\u0027re not Parata they\u0027re not these other updates they\u0027re really almost a fork of that protocol and we want to you know make sure that that remains out of scope we\u0027re about to wrap up but I need the this one side of blue sheets circulating does anyone know where it is check the chair next to you it looks like this alright well yeah well then enjoy your cookies thank you for spending your afternoon talking HTTP I know we all wish it could be all week long and let\u0027s see it Thank You Julie "
  },
  {
    "startTime": "01:31:00",
    "text": "you "
  }
]