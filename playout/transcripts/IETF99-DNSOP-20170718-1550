[
  {
    "startTime": "00:01:00",
    "text": "and so widened okay I think we\u0027ll do people a couple more minutes to finish their cookies and file in and so and we\u0027ll get underway in a few minutes run any risk she\u0027s like second if you\u0027re gonna stand there for a long time yeah anything else we did not you have it well I think yeah I think we\u0027re slide that in there himself and I suggested the warned that you might want to have those even though with this is he in this off yet if they have a week\u0027s worth of graphs I can I can slide this in Thursday so you probably good so it\u0027s been noted in the drama room yeah we\u0027re here to fry 1890 so they can take yeah okay okay Mike thank you hey at least I put updated the note well so and I had to do it like all the working groups right no I\u0027m I figure I\u0027ll do them yeah yep all right everybody good "
  },
  {
    "startTime": "00:04:03",
    "text": "afternoon for the last session welcome to Danis op I\u0027m Tim that\u0027s Suzanne and it is I ATF 90 you just you just don\u0027t realize it so you know who we are Joel\u0027s offered to stand up engage a prescriber or we force the former 18 to basically do our bidding so and Paul says is going to be minute so I appreciate that so please make your name at the mic so while we probably know people we may not know everybody I\u0027m always bad about that I well I didn\u0027t get the the ietf right I did update the new well document so this is the new text so hopefully everybody\u0027s taking a little look at it doesn\u0027t seem to be a lot different than the old text yes I\u0027m sorry sir we\u0027re gonna ask you the service I um I\u0027ve since we\u0027ve got some blue sheets going around please fill those in so everybody knows what\u0027s going on how many people we have here how many so we can get a big room like this so the agenda this time we got a three-hour cruise the first two hours is sort of previous work that we\u0027ve been doing the third hour which is on Thursday is what we call the IETF bad ferry work where it\u0027s why a lot of new stuff so so the bad idea ferry will show up on Thursday and sort of drop on some graphs and stuff like that so but mostly it\u0027s updates on current stuff going on quick thing on document updates since the last meeting it\u0027s I feel I feel this is very sad we\u0027ve only got one thing sort of published and we\u0027ve been on a cadence of getting three drafts published I know I know and this is kind of my fault I sort of got busy with work and I get sidetracked and stuff so but we got key tag pushed out we do have a few things actually very close to going out and SEC aggressive use is actually in our 48 and the special use tail a problem statement document that wore us down to a fine green is also an author forty eight as well so and refused any it went through a second working group last call and I basically had kraut Joel who I go to Joey Lynn who I saw at lunch that he is responsible sort of fixing some of the outstanding items so Oliver you\u0027re off the hook on that so they\u0027re pretty minor no so that was his free lunch so Joe raise your hand yep yep we\u0027ll sit down later this week and we\u0027ll get this sort of hashed out so we can move this forward ok so as we said the LTL be also the LTL D is basically now that the problem statements I think we\u0027re ready to try this again and I think it\u0027s ready for a working trip last call the IP six document there\u0027s a bunch of stuff that has to go in there and we\u0027re sort of waiting on me he\u0027s busy it\u0027s ready to go we\u0027re just making sure that we don\u0027t overload "
  },
  {
    "startTime": "00:07:04",
    "text": "people ok do many things at once but we\u0027ll be doing an abbreviated second working group last gal4 IP 6 rd hands and then of course the RPG that wonderful RPG document that sort of caused a lot of you know hullabaloo we\u0027ve worked out all the boilerplate problems and suzanne sent out an email earlier today basically sort of describing that think of it as replace RPG with client subnet in your mind and the work we did with client subnet to you know document what was there make it informational you know yeah we can write about the security things and all the things that we think are bad but we don\u0027t actually change the protocol you know that\u0027s exactly what\u0027s going to go on there so if if it bothered you on some level just you know do a replace on an RPG with clients have net and kind of move forward on that so elsewhere in our gym yes sir oh so I know it\u0027s a very new topic but that\u0027s not what I read from Suzanne\u0027s no two hours ago what I sorry Paul Hoffman so what I read from Suzanne\u0027s note is that the introduction that says we are not talking about whether this is a good idea or a bad idea or whatever is more the case that so even once it comes into working group we don\u0027t get through then start talking about whether we think it\u0027s a good idea or not ok yeah we\u0027re definitely not like a DNS client subnet but more like a we can talk it you know leave the technical stuff aside yet but that we are excluding certain things we\u0027re going to talk about Suzanne is that right I think you\u0027re both right because you know not that we want to spend a lot of a lot of time on it which is why I said ok but the point there was that we resolved the point that was controversial by saying or acknowledging there\u0027s a challenge there that\u0027s not what the document is about the scope of the document in both cases was to say we\u0027re describing the technology as currently built and deployed not going into the surrounding issues this is informational for the purpose of documenting what people are doing yeah and that after that gets published we\u0027re welcome to put out a standards track that you know we go to our hearts content on basically which was the you know so I believe you know that\u0027s currently where where things are going on that ok and yes it does seem it always does seem we\u0027ve sort of gone over it a couple times a few of the things that we have adopted the outer leaf document David he\u0027s made some updates to it I think we\u0027re getting close enough if we have a few more reviews for a working group last call on that it\u0027s actually you know sorting the shape up we need to get back with John about the TCP requirements I know he\u0027s adding some feedback since Chicago and we want to see what that\u0027s going so the and the wire format draft that\u0027s a interesting one because there\u0027s a lot of DNS over transport stuff going on right so we\u0027re actually sitting down with some "
  },
  {
    "startTime": "00:10:04",
    "text": "80s later in the week to sort of discuss all the you know or as I call them DNS / Hoffman you know protocol drafts that are out there you know no offense Paul but just to sort of figure out how we\u0027re sort of you know sort of you know where are we juggling all that sort of stuff right mostly because it\u0027s been adopted and so if we don\u0027t do something with it because it does seem to freak out there we have to have a sort of a good story as to why so and and no response it I think we just you know we\u0027ve had some editorial stuff on that I think we\u0027re technically it\u0027s there it\u0027s just there\u0027s some editorial stuff I think we need to sort of pull together and that\u0027s my bad so one thing we\u0027re thinking about is because things like DNS terminology this is when they\u0027re making changes and they seem small but they\u0027re actually because it\u0027s becoming standards tracked we\u0027re concerned that people aren\u0027t really sort of maybe looking at all the bigger picture sort of thing so we are sort of considering some smaller in terms just for specific topics or graphs you know something like an hour in length we bang on something that people sort of you know bent to their heart\u0027s content and and just basically sort of you know work through some stuff you know interested in some feedback on that if people think that\u0027s crazy or not we just don\u0027t you know we don\u0027t want really long sort of out-of-control ones I think we figure if we can keep them you know sort to the point we can sort of focus on specific things maybe just sort of help us move some stuff forward though the document list of course that\u0027s why working on Paul\u0027s been keeping that up and he\u0027s been really sort of he\u0027s been keeping us on track be less so lately but I think I\u0027m hoping that that\u0027ll sort of sort itself back out so currently today Paul we\u0027re gonna have all talk a little bit that turn ology bit even though he has in slides he\u0027ll just talk a little bit some updates in the capture format which came out of some stuff that came out of the hackathon sort of causes we thought we were close to working group last call but I think some stuff is came up we need a theme that the 50:11 security considerations basically the action item we have is we want to make sure that Wes and Mike hug it out today and we get to the bottom of the baking tension and then I think we\u0027re ready to sort of move forward an update on the a tame draft which people seem very interested in and some people seem very sort of frightened about session signaling which I originally thought we were getting close to working for glass fall I think as the author\u0027s start to dig into it more we realize we\u0027re not there and there\u0027s gonna be some style on us I actually haven\u0027t had a chain I saw the slides at the very last minute having that transfer look at him so well we\u0027ll give details in that and David\u0027s done a bunch of work on the bulk our draft which really freaked a lot of people out the first time it sort of was presented but there is some interesting stuff in there so I think they\u0027ve actually come up with a sort of a very good simplified approach to the problem that looks like we feel is it you know if the group looks for it probably ready for adoption and then we may touch on some sort of the new work with their business two sides of a multi-sided coin "
  },
  {
    "startTime": "00:13:07",
    "text": "as I call it the server stale draft you know this is about you know do you fetch things quickly or do you basically serve stuff out of cash it\u0027s the whole how do you deal when you\u0027re being attacked and you know or you you can\u0027t reach your the authoritative servers to basically get you know updates on your data right though there\u0027s of course different ways to sort of solve it we just want to see you know which way it kind of goes this way or that way sort of thing so that\u0027s really you know what we\u0027ve done on the agenda for this week mostly today so you know so so yeah so that should keep us busy for PR reasons like I said Thursday we\u0027ll do a lot of a lot of the new stuff so you know if you\u0027re looking for sort of the crazy ideas that I always and welcome to sort of what\u0027s listened to so and they\u0027re not even that crazy so that\u0027s just the way it goes there is one thing but you okay Victor go ahead so i\u0027d like to \u0027participate one of them i have some material I\u0027ve contributed to but I also have the UTA session where I\u0027m deeply involved in the STS you know email security thing I\u0027m wondering whether it\u0027s possible to shift the algo negotiation if the author\u0027s are present and ready to the last thing today maybe if that\u0027s a possibility I hope try not to be in two places at the same time yeah that\u0027s a late enough change to be a little bit awkward but we\u0027ll see what we can do you know if we time on that maybe we can you know at least start the conversation and then push it up to Thursday and maybe is another way to put it so Tim this shim on Huck altar of the algorithm in the Commission so unfortunately we\u0027re not ready we\u0027re still working on the slides okay good to know that so and there was one other topic I think you all probably saw it there was a advisory about it was on behind dry soils were about I\u0027m the teasing on durability and so that had come up and there was a discussion a meeting this week with a lot of event with all the vendors so all the major players there for instance is put together one slide I was going to bring that up and we can talk about that but basically it\u0027s it\u0027s something that it sounds like that the vendors are all getting together and sort of work on a update to the document to basically make it a little more explicit sort of thing so we mean go dig this light up and then we can sort of move forward from there apology yeah your spy Creek but um this "
  },
  {
    "startTime": "00:16:18",
    "text": "is just the teasing Oh yep this was just go sit down because I need to take notes okay okay just a quick quiz just a quick thing about the teasing vulnerability you want to say a few words mr. Moore\u0027s former former chair yeah as you know both Moss and bind issued patches to address a teasing vulnerability recently when we got together we found that the vulnerability had the same underlying calls in in both products and we Furr so the dns vendors got together on Sunday we found that a correction is needed to RSC two eight four five versed in the slide there is a the there\u0027s a section in 285 that defines the orders that certain checks should be done to get over this problem we had to change the order so we fill the correction isn\u0027t needed but in addition it became it became clear that 284 5 doesn\u0027t cover all the cases that some clarifications are needed and we\u0027re concerned that if if two experienced vendors make the same mistake then new players may well make that mistake as well so the conclude conclusion of meeting is that we should start work on a piece version of 284 5 just through that just to put in those clarifications and while we\u0027re at it incorporate RSC for 6:35 which contains additional information on t6 hi so I\u0027m Paul Hoffman and I\u0027m not a teasing vulnerability because I don\u0027t interoperate on that um so on the terminology document as you\u0027ve seen there\u0027s been some traffic on the list what it seems to be since the last meeting is we have occasional bursts of here are 20 Corrections or thoughts and such like that and then silence for a month and such like that um I don\u0027t know if that means we\u0027re getting done or if it means that without authors pushing that it\u0027s not interesting enough and so I\u0027m gonna defer to the chairs on figuring out when we\u0027re done we still have we have by the way for those of you who want to know what happens we done we are keeping in the issues list on github and so even if you bring up an issue on the mailing list I will move that over to the to the github issues list if you have a github account it\u0027s better if you do that so that the issue doesn\u0027t look like it came from me but we and so we have a couple of open issues left on that but we have one big open issue and that is waiting on me and sort of like the standard you know dollar sign excuse my day job but one thing that we "
  },
  {
    "startTime": "00:19:21",
    "text": "promise to do when we started the best document is to actually go through the mailing list from original 77 19 and fine you know in during that time we said oh we\u0027ll do that in the best document and there\u0027s a bunch of things that we punch it and have forgotten about and yeah it is so I\u0027m not going to go through the mailing list and so that will probably take me another month or so to start this but the result of that will be some open issues that will be long and hard one of them is like do we talk about resolution versus resolvers and do we fix some of the terminology in in 77 19 we picked some terminology because it had been written up in earlier RFC\u0027s and so we would take the noun instead of the verb and things like that so that will open up a bunch of issues and I hope that this group doesn\u0027t think oh that\u0027s not important because it was important enough the last time where it looked like we were going to thrash and we punch it instead it\u0027s probably still just as important as as two years later so that might happen over the next couple months and yeah hi George from my clinic so I used to collect encyclopedias and I had a pairs encyclopedia from about 1915 that had an article on physics that said at the end dot some recent news from a mr. Einstein in Zurich may change our feelings about certain statements made here and the spirit of this is because I know people who work in the ontology in dictionary space many years it\u0027s never cooked no it is never never cooked and I feel like if you\u0027re not getting the feedback but you\u0027ve actually done a substantive body of work I decide to leave the draft open forever and we just accept it\u0027s a living dog or cut now with open issues and roll abyss space because it\u0027s never going to finish right so I\u0027m not in favor of keeping it open as a draft then the reason is this we\u0027ve been getting a surprising number of documents that have nothing to do with this group referring to RFC 77 19 so so the number of surprising references outside has made me realize people really want an RFC so we should get another one done even if we have to do a third one but yeah and by the way on the on the encyclopedia thing encyclopedias from 1900 to about 1915 are absolutely great if you get a chance to go through them look at articles on things you think you know about what they thought chemistry did was just like really really fun so you know go for that and who knows maybe 77 19 people in 50 years we\u0027ll look back and go that\u0027s not the way the DNS worked but so I do hope that people are still interested enough as we bring up issues especially the ones that we punted on again we didn\u0027t punt because we were bored we punted because they were too controversial and so there\u0027s going to be "
  },
  {
    "startTime": "00:22:21",
    "text": "a couple is coming up in the next couple months Thanks I think that\u0027s it might be that it\u0027s been a little bit difficult to get sustained reviewer attention because this is a long and complex document it\u0027s a little bit intimidating people should go ahead I guess you know not to speak for the authors but it does seem that it would also it would be valuable even if someone doesn\u0027t feel able to take on the entire document to have reviews of particular pieces or by section yet some reviews a part of the document they\u0027re also useful and sort of the other dollar sign argument that people often give is oh if you had a PhD student you know have them do this research if anyone here has PhD students who are doing anything on the DNS especially if they\u0027re one step away and they\u0027re supposed to really understand the DNS even though they\u0027re not working on it by all means have that person do a thorough review of this and open issues those are great people for discovering what we all thought was obvious is not okay and by the way I liked your idea of maybe having a virtual interim yeah I\u0027ll call whatever I think that that might generate you know the encyclopedia readers among us I remember in the first version I\u0027m at the result just a large discussion about various things that we wanted to bike shed on that we put off yeah but now that this is your me standards track and I think we\u0027re gonna go back to these folks like you have and say are you guys actually paying attention to this document make sure you\u0027re using the right terms and stuff and the fact that people are starting to use 77,000 has despite that okay great thank you afternoon old Jim hike Synanon I\u0027m here briefly to give you an update on what\u0027s going on with CDNs for those of yous not come across this so far and CDNs is aimed to be a fast Orage format that permits efficient storage in a space sense of a large packet captures for dns it\u0027s based on C bar it\u0027s and therefore is hoped to be working in restrictive environment with a relatively high overhead and it\u0027s nearly reversible but not quite we don\u0027t store things like TCP stash session details the way basically the way it works is we combine query and responses to into query response pairs collect those into blocks of a few thousand at a time and then abstract the common data from those blocks and we also have optional recording of sections are ours and so forth and it\u0027s not the simplest file format in the world I\u0027ll liebelei I\u0027ll just let that sphere itself on to your eyeballs and move on and now we we presented this status of "
  },
  {
    "startTime": "00:25:22",
    "text": "draft zero one in Chicago since then there\u0027s been a couple of new things happening we issued a draft zero two which was just a minor editorial improvements and correcting an image and then in July we issued the latest version zero three where we\u0027ve added an implementation status into the draft but the big news is that we now have a open source implementation of this available on github it\u0027s C++ and you\u0027re very welcome go and have a look at it multiple implementations would be nice but we\u0027ll also talk about bit more about that in a moment and just one note on the draft we are currently using SVG diagrams in there and we were talking Sara and I were talking to the sect Secretariat earlier and I think my future may may hold some ASCII art right Karen open questions we have now in Chicago we had an open question of what to do about malformed packet recording malformed packets and I\u0027m afraid that question is still open we haven\u0027t really thought too much about it and this includes considering what exactly we mean by a malformed packet it\u0027s the question of packets that are nearly correct where for example you can extract the question from the pack from the query but where there\u0027s something then goes wrong in the rest of the packet what do we do about handling those we would a be aiming to probably record the malformed content in the file optionally if we\u0027re going to do that should we consider trying to compress the raw content and so forth we also have a minor question we\u0027ve specified part of the files specifies the configuration used to capture the data so far we have not made a final decision about how to handle configuration items that were just unknown at the time of the capture but anyway however we\u0027ve also recently received comments on 0-3 which have raised some interesting questions the first one is we have a reference in the draft at the moment two extensions for implementation dependent fields in the data but have no we\u0027re actually described exactly how those extensions are going to work so we need to know around something there and we\u0027ve also had comments about potential use in a scenario where traffic reconstruction is absolutely not required now we\u0027ve been very much developing this from the point of point of view of recording pretty much "
  },
  {
    "startTime": "00:28:22",
    "text": "everything and using it to reconstruct traffic so being confronted with people saying yeah we\u0027d like to use this but actually we don\u0027t really want to bother about recording addresses and so-called subnets would be fine we need to think about this currently we have although we have a lot of optional fields in the in the format we have enough fields than noted as compulsory so that we can do very basic traffic reconstruction so we need to think about this and also the question of what should be the minimal time stamp resolution because again the people who are interested in storage but not necessarily reconstruction and have also raised the possibility of well we don\u0027t really care about time resolution to greater than a second anyway and otherwise we have been having and we will look forward to having we would like to have some more hallway discussions on other use cases and in particular the prospect of using it with DNS tap has been raised recently and I\u0027d like thank Stephan very much for spending his hackathon weekend generating a basic go DNS tap to c.d.s implement at CDNs implementation this raises some further interesting questions in that in DNS tab providing anything is voluntary as far as I can see and so for example Stephan discovered that in fact half the time you don\u0027t you don\u0027t get to discover what the server address was which is one of the items that we currently have as mandatory Plus also DNS tab can supply server internal information such as the Bailiwick and we currently have no provision for recording that and obviously that would be a very good thing if we do so we we need some further discussion on that if there are any DNS tap experts or enthusiasts around we\u0027d love to talk to you which leads us on to the next steps and the next steps are basically some I think some hallway discussions addressing these issues and I think trying to work out a the shortest steps that we need to take to nail this down as something immediately useful and proceed with the draft on that basis alright that\u0027s all I have to say any questions and just "
  },
  {
    "startTime": "00:31:29",
    "text": "because I\u0027m closer than Stefan but it\u0027s one of the things bonds gonna ask about um do you have a reason for making some of these things mandatory looking at it and from this perspective our only reason for making things mandatory was for reconstruction okay thank you and because then if now we\u0027re loosening reconstruction then exactly though if we loosen reconstruction that raises if we loosen reconstruction there\u0027s a question of do we put a marker in the data saying hey you actually haven\u0027t got enough data to reconstruct and prevent it do we just recommend that implementers introduce dummy data of their own when if asked to reconstruct that reconstruct including data that isn\u0027t there but tonight that\u0027s an open question jibley I got the same as what going the smoke is going ahead gentlemen I think you\u0027re all doing great stuff here is there any progress on the IPRA sure that there\u0027s been one talked about the past in anyone that may be getting resolved I think what I can I\u0027d be anything I can tell you about the IPR is that we\u0027re proceeding with the draft because the working group wants us to proceed with the draft as I mentioned we have open sourced the software now that software is it\u0027s an Mozilla Public License but it\u0027s copyright I can and I referral I refer you to the Honorable mr. Mandelson thank you okay that\u0027s me here one thing that was mentioned for the problem of mandatory versus optimal data would be to have two profiles of CDNs one where everything was mandatory on one with a lot of things were optional it would complicate a bit iguana all the semantic description but it would help with all the public it\u0027s not only a dynastic problem in there are many cases where you have only a part of the data you still want to stow it so I tend to think that this idea of two profiles is a white one okay my honestly I only worry about profiles is whether two would end up being enough you know okay we could draw a line between reconstruction and non reconstruction but are there going to be other potential applications where a similar line might exist I I don\u0027t know that\u0027s why I\u0027d like a bit more discussion about potential users first if that makes sense yeah yeah I make sense but of course we cannot see in advance all the possible use and no of course and I think you\u0027re right I think and you know if we don\u0027t come up with something if we don\u0027t come across something very quickly we should proceed on the basis of just the reconstruct or no reconstruct on anyway that current "
  },
  {
    "startTime": "00:34:29",
    "text": "draft I\u0027m not satisfied with a current draft in that respect because many things in the are optional but are not in practice i doesn\u0027t meet thanks that\u0027s the discussion we had about in value zero for the index absence was to say they cannot fund on practicing doesn\u0027t work yes in practice at the moment that that\u0027s that\u0027s a design hangover we\u0027ve we are doing optional data really by other means now and that that\u0027s a lot that needs to be covered right Adams I can and I\u0027m a very heavy user of the Sydney Nash format and the tools that soon as net provider and I\u0027ve got many feature requests on the tools and then maybe a few things on the the capture format itself and with regards to the tool is there a specific mailing list that and I know this is not about developing the standards I\u0027m sorry to ask you this but if there is there a mailing list that that people can go to and discuss these features etc like the proper development yes yes there is at the moment we\u0027re asking people it\u0027s on the it\u0027s on the website I think we\u0027re asking people to use the DNS stats mailing list at the moment that\u0027s actually thank you okay sorry concern yeah the so this is this is code that\u0027s under the dearness stats website and the DNS that\u0027s users mailing list so that\u0027s where to go in first instance or feel free to put issues in the bug tracker on github the comment that was going to make was simply a request for if people genuinely are interested in this dinner stat news case could we just have a little bit of traffic on the list because there\u0027s been nothing there everything\u0027s been off the record so far so if if we can here on the list specific requirements about the additional data that people would like to see captured that would really help us in moving forward to meet that use case ok sounds really good thanks Jim and next yes that would be all right I am where Tucker learns over there ignoring me and we can go on ignore the outline so just as a quick reminder in 5011 the math is sort of complex about how you generate a query interview integral for good reasons it\u0027s not that it\u0027s bad it\u0027s just complex so it involves both a minimum and a maximum there\u0027s that you take the minimum of half the signature validity and half of "
  },
  {
    "startTime": "00:37:30",
    "text": "the tto of the old dns key and 15 days typically the TTL is the shorter of those and then you know if you take that value that you get plus a one-hour value and you take the maximum of either of those to generate how often in 5011 you\u0027re supposed to query for the an update to the keys records so in 50:11 security considerations we\u0027re sort of changing sort of the maximum amount of the minimum amount of time that you must wait while you\u0027re publishing a new key before you can start using exclusively it or it and newer keys and so we called that in an update to the document we call that an add wait time and so the add wait time is now the difference is now the add hold down time which was the original 30-day window that everybody\u0027s more familiar with in 50:11 along with the signature validity period which is the signature expiration - the signature inception plus the query interval that we talked about last time plus the slop so the slop is you know typically what we do in DNS here which is 2 times max TTL so in the end it looks like this and so I bring this up for a couple of reasons we\u0027re gonna get into this in greater detail in a minute but Mike st. John\u0027s gave us a whole bunch of feedback recently and I I tried to get a new document out bytes they failed because he gave so many good suggestions that it took me a while to implement them I\u0027m down to like the last one and then there\u0027s one issue as well they\u0027re actually two so first off issue number one in relocation in fifty eleven in the document that is actually in the draft repository now is wrong thanks Mike for pointing are you here somewhere okay good because we\u0027re supposed to hug it out later apparently so pictures or it didn\u0027t happen you know Mike reminded me that the hold-down time in fifty eleven is thirty days but the removal downtime is just really sort of a suggestion for how long you\u0027re supposed to publish it and how long the validator is supposed to remember that it\u0027s that there was a removal so how long it should actually keep it around and think about it and yeah go ahead Mike you\u0027re gonna sorry the roof this does it exactly this is just the database for the client right actually has nothing to do with now but somewhere else you talk about but there\u0027s there\u0027s two times as good in 30 days so both of those concepts are in the earthing the 30-day the second one is remove is really is removing a subsidiary trust plate and that was and that\u0027s only one of the other places where location is talked about there one more and that doesn\u0027t have any dates scientist so the change I\u0027m making is what I think you\u0027ll be happy with so that rather than having one wait time which the last version the document had now there\u0027s two so there\u0027s an add wait time and a remove wait time "
  },
  {
    "startTime": "00:40:31",
    "text": "and really the only differences is for the remove wait time we knock out the add hold down time which was thirty days before because because relocation does happen the first time you see it there\u0027s still a wait time you still have to you can get replay attacks against you if you don\u0027t wait the signature validity plus these other chumps so it becomes that that\u0027s issue number one that\u0027s functionally resolved unless Mike you know finds a problem with it and I will try and get that out this week sometime issue number two is unresolved but so here\u0027s our here\u0027s just a quick example running through it so from the current KSK and again the timing that I can has put forward there is no reason to panic for I cans 5011 you know supported role of the current KSK which is like underway now the timing actually all works out so these are the values that are in the current KSK relocation related rolling process so the ad hold down time is still 30 days the signature validity for the current KSK is 21 days and the TTL on those keys is 2 days so when we plug in all the math and we do all those same min/max and all that other kind of stuff we end up with and we keep boiling down the math and doing all the division we end up with 56 days that is much shorter than they are planning on waiting for that key to be in place so none of the security considerations we are considering in this draft has any concern over the current key world rolling process and Mike you you were right the math in the appendix that was the exhibit that was in the example had 62.5 days you were right I was wrong thank you and for relocation we delete the 30 days and we leave it at 26 days so the when the KSK is revoked sometime next year it will stay in the zone for a think 7b days roughly so much longer than 26 it\u0027s not going to be a problem so the only dark the only issue left and so all the rest of mike\u0027s comments are handled and you\u0027ll see a longer just post by me about responding to him the only one left is that he and I have this internal debate about whether you should talk about an interval so an add wait time versus a wall clock time and so you know should you specify it as a wall clock according to the signature expiration and to me this is a matter of taste because the reality is that the math has terms in it some of which are wall clock terms and some of which are length terms and so the end result is you know either way you end up having to fuzz one set of numbers or the other so like the add hold down time is 30 days from publication the signature expiration is a wall clock time and the equations could really be structured as either I found more wait terms than I did wall clock terms plus I don\u0027t want to change the document I\u0027ll be honest because I prefer it the other way but because it\u0027s you know like one to one right now if anybody else has an opinion on his site especially now\u0027s "
  },
  {
    "startTime": "00:43:31",
    "text": "the time to stand up and say I\u0027d prefer a wall clock equation let me just ask the question what\u0027s the term of the sum of a wall clock time plus and another it\u0027s a wall clock time yes I know but but see the deal is the deal is is that this equation is very dependent both of these equations is very dependent on when the publisher actually does stuff so there\u0027s actually multiple wall clocks as well because the in this equation one of those signature validities is the real signature of validity in especially in the the query integral one of this one of the intervals is based on sig expiration - sig interval and it\u0027s fixed right so no matter when you publish it the other one the first signature bility the bigger one this is actually dependent on when you actually publish so they\u0027re actually quite different orin orin Kumari just a minor clarification you said things like that we\u0027re adding and Ed wait time and things like that for people who haven\u0027t been following along they might get the impression that we\u0027re changing 50 11 this is just clarifications on how to use it or yes just for those who weren\u0027t you know paying attention as it went by no careful oh just like comment the timers you have are basic to the worst case because the implementations are more aggressive than the formula that is in there yeah unbound checks every day well there you can have a query interval that\u0027s faster than one day - so unknown may have an upper interval of one day sure said so this is entirely based on the math and 50:11 alone if implementations of course do their own thing they shouldn\u0027t be slower than the query interval if they did that they wouldn\u0027t be following 50:11 so if they do stuff faster by only and so this is worse this so my implementation does one day - or yes oh and Wes yeah I think I was talking about 1753 in a sec key timing rollover considerations document and there has a couple the officers are you see them here we didn\u0027t use wall talk we use interval time so that\u0027s just how it sort it\u0027s subjective and I think you can go either way so as I said because already wrote it one way I don\u0027t really feel the urge to rewrite it but if there\u0027s prevailing opinion I will did go through that works alright so unless I hear our opinions either now or on the list I get to pick I guess it sounds like when that\u0027s resolved one way or the other sounds like the discussion could reasonably continue with a working group last call yep yeah so the next slide is exactly that I should have an update out I was hoping by Monday but I failed that so it\u0027ll be out this week sometime I will also release all the comments in response to Mike\u0027s very good set of comments and in on my opinion and I think in Warren\u0027s opinion it\u0027s ready for last call and that towers in Chicago "
  },
  {
    "startTime": "00:46:34",
    "text": "okay thank you so next is a name hello my name is beta Van Dyke I work for Power dienes I\u0027ve been working on the a name draft with Evan hunts if I see Anthony Eden not being a simple so why we\u0027ve all seen scenes own files like this you host your website somewhere ever you don\u0027t host your DNS please cname your website out you cannot see in your apex actually put an IP in there and the whole year from how this IP won\u0027t work you know this is not the only reason to have a name other than the most most obvious popular reason to do this solutions you see right now you put the see them at the apex this kind of works if you don\u0027t do the NSX you use an operator that flattens the cname for you I believe CloudFlare does this you update your zone file from Chrome so you have a name or alias but it\u0027s hidden even from your name server so it\u0027s somewhere in your your provisioning then you have various commercial operators that do alias or a name under one of these names and these are mostly similar implementations but not all identical and none of them interoperate zone transfers and then finally our power deenus has alias which is also quite similar to all these commercial implementations so it is obvious there\u0027s a problem here and there\u0027s obviously one solution okay so this is an example zone file using a name the websites still see names to the CDN and the apex is a named to the CDN you could of course use a name for both butts and trying to show the difference here if you don\u0027t do a query for the the website doc need a BW you get a cname and look closely the website is a cname to the host at the CDN and then you get the a record for the host at the CDN in a name this works differently you get the a name to the CDN then you get the a records again on the original leg this is so that resolvers that are unaware of a name will still get this address still being able to direct the browser to the right side there various concerns have been voiced on the nizam the in a sec is an issue depending on how you set this up you may need online signing there are many ways to do it without but people are concerned "
  },
  {
    "startTime": "00:49:35",
    "text": "about this loops are an issue for a cname you know what\u0027s happening but an a name will be flattened by the resolver in a name point to another a name we imagine there could be undetectable loops there and solar needs to be done another issue his team shall be do IP based or other methods for picking the right data center to point somebody to if the authoritative does the a name resolution for you it will either have to pass on a DNS client subnet etc or you will get bad results the draft proposes for this reason that resolvers do a real lookup of the a name but we\u0027ll have to see if people actually roll it out and final concern on this slide any writer or more of course is that of the TTL because you get you following a name this resolution runs via a resolver and you get the result with a with a limited validity then you pass on this limited validity or do you Cabot\u0027s to some lower or upper bounds etc the next far as I\u0027m concerned now that we are adopted we need some running coat many people have running alienum coat but not exactly according to draft the drafts need some restructuring we have separate sections on authoritative regional / behavior right now but the primary and secondary authoritative behavior is all mixed up in that section and it\u0027s confusing people the draft needs more examples even this presentation has more examples than the drafts and one final thing right now this draft mentions v4 and v6 the EDS client subnet drafts or RC no mention fee for a v6 the xpf draft mentions both I imagine that it might make sense to do something about that make it simpler for if this is ever necessary to create a new address type in DNS without having two updates eight other RFC\u0027s there was it hi this is Andre Caesars Nick hi um personally I find the draft very confusing at the moment because there\u0027s in the alternative name server section you say that the name server should resolve the a name to a and quote a and then there might be might be records that coexist in the zone for a or called a and how do this play together and there\u0027s a lot of other stuff like this for example in the DNS exciting section if you have a key do something if you don\u0027t have a key do something else I "
  },
  {
    "startTime": "00:52:36",
    "text": "think this needs to be simplified you know see from the implementation saya find it very confusing that there\u0027s a lot of maze mites and very different paths how to do one thing so I think this needs to be simplified very much I agree the draft has grown quite organically and we need to fix that yeah Stefan Bosnia I\u0027m going to Paris a grumpy guy because the goal is to I know the user to use the app X in usually visible you don\u0027t if I like the URL but it\u0027s it should be noticed that it\u0027s a qtp specific problem because all the other protocols other way to do it who are DNS indirection and mix SLV it\u0027s Tara so it\u0027s only to fix a weakness a big weakness of a HTTP this being said I agree with a solution it seems the right way but still it\u0027s annoying that we don\u0027t fix it properly by fixing HTTP I know it\u0027s an adoption it would be the best solution it is not the only thing the draft fixes is just the most obvious one but thank you for your support I been wearing it now their lives so first of all I don\u0027t oppose against the drawers but I have a concern it\u0027s not technical per se it\u0027s more a fundamental observation or security or observation that the one who owns the zone and science it might not be the publisher even though you described in the dinner sex section that even though the master is not dynamic signing that there are ways to work around that but still that\u0027s the publishing side and I might be the owner and only signing about the publishing so with offline signing I can sign it and someone else can publish it and with this draft and becoming RFC it\u0027s it has a number of well operational implications or security implications and I would like to ask you advice to write this also down in security considerations good right because more you\u0027re saying right now you can sign off line with me that\u0027s on a USB stick and do it again in a week and now you have to do it every minute yeah yeah and I also might be the owner of zone and sign it but I don\u0027t run any Dennis Dennis well I had and in the scenario that there\u0027s now on lines signing you say well after the TTL the the authorative name server has to resolve the a name sign it and do an extr to the secondary etcetera but still then the I know in many practical situations this is the case but yeah it\u0027s a principal cases its howdy miss AK was once designed and how it\u0027s now being used and I think that\u0027s an important "
  },
  {
    "startTime": "00:55:36",
    "text": "observation it should be at least documented yeah yeah where the draft says of life signing can still be done we are summer stretching the definition of of line yeah yeah thank you yeah I\u0027m John Levine I guess about us I have kind of the same concerns as everybody else on the one hand this is a problem that needs to be solved but I have a hack in my DNS provisioning so I just try to kind of do it on the other hand I am concerned that that I mean I do offline signing I have no intention of doing online signing ever so it needs to work with that and I\u0027m wondering you know maybe we could see if we could do it is something that smells more like cname is like the a and and quad-a records or they just return the original ones from the up from the source like cname does rather than renaming them into your own zone and the other question is I have this vision that we go through this entire process and we finally get it out you know and the day after we publish that somebody says I do boy I do voice over IP why does it do sir why doesn\u0027t it do some records I mean I don\u0027t think I don\u0027t necessarily think we need a huge bitmap of every possible record type but I would you know but I do wonder I mean I understand the main use case the plenty of web servers for you need a part a but I\u0027m just wondering if we\u0027ve looked hard enough to see if there are people doing other services that use other it\u0027s particularly serve an MX that that it\u0027s worth figuring it worth seeing whether we need to sweep them in - yeah yeah we\u0027ve given this some thought and our main concern is that this would take the drafts much farther from what\u0027s out there right now so on my I imagine it all let\u0027s just just you I do MX but as far as I can tell I\u0027m the only one okay Oh countryside I like this drop but I don\u0027t like the idea of authoritative server resolving and online signing everything else I think it\u0027s too complicated to implement this in many many scenarios and I think it would be nice if because I think there it is there but only implicitly that an option that the a name record would be combined with a and quad a record of so-called last resort so the alternative server would do no processing at all it would just add a name record to regular quote al-ansar and in this case the recursive resolver that is capable of a name processing would get some better IP address according to in direction of a name record but normal resolver would get the a records of last resort so we could somehow gradually go towards the is a "
  },
  {
    "startTime": "00:58:38",
    "text": "name solution without the complexity of server-side resolving and signing and so on the draft as it stands allows you to do this yes yes but I think that it should be more explicit there because it I read it I didn\u0027t miss my good hi my name is Andrew Sullivan so I said something along these lines on the list but I feel it more strongly now I\u0027ve heard several people say things like oh it should just or this doesn\u0027t cover my case or it\u0027s too complex and and maybe part of the problem is that the document is insufficiently clear about why this is hard because what we\u0027re trying to do right is is fake a whole bunch of stuff and we\u0027re trying to do it without changing all of the installed base of all of the garbage that has ever been shipped on the internet ever at least another day and and so on and so there\u0027s a whole bunch of of dependencies that you know and and decisions that we\u0027ve made over time um that that maybe maybe some introductory text that I I guess I kind of volunteered to do now that I hear all these people are concerned about it that would would say look here\u0027s the here\u0027s the reason why this is as hard as it is um would help motivate some of the trade-offs and and then we could stop having a discussion about well why don\u0027t you just do this because for instance on Jon\u0027s point that you just made about the MX thing well I I know of at least one implementation or a whole bunch of people would like MX to work fine and the answer is well you can\u0027t because it doesn\u0027t and so they come up with another ant you know they come up with a different hack and that\u0027s the way that it\u0027s been done but there\u0027s a whole bunch of stuff that\u0027s deployed already and the reason it\u0027s deployed that way is because everybody is cheating um in using the eventual consistency of the DNS to convince people that it works so I I think maybe if we if we write some checks that sort of explains that\u0027s where the difficulty is we might we might get a little bit quicker convergence yeah that make sense thing all right okay it doesn\u0027t look like we have anybody else at the moment no and it sounds it\u0027s it sounds like there\u0027s a way forward we\u0027ve got next steps thank you everybody next [Music] "
  },
  {
    "startTime": "01:01:38",
    "text": "okay so I\u0027m gonna walk through an update on session signaling currently this draft is at the O 3 version that came out in July the idea behind the draft and the phrase it\u0027s used currently in the abstract introduction is that this is for managing the properties of long lift sessions for example TCP or TLS in this specific draft we deal with two properties in terms of being able to set session timers and servers being able to indicate to a client retry times for certain operations there are it\u0027s two or three I\u0027m not sure drafts going through DNS service discovery one of them is push which use this mechanism and extend it to do subscription management this draft uses a new format it proposes using a new opcode 6is tend to be assigned in the count sections the draft says that the counts must be 0 therefore there can be no ours within this kind of message and what\u0027s proposed instead is a new theory format which follows directly after the count sections in the payload the biggest point of contention with this is around the use of that new format what I\u0027ve tried to do on this slide is I walk back through the email archive and I just try to gather the arguments that have been made for and against using that new format the proposal to use the TLV one of the ideas behind it is if we\u0027re going to use in your code this is an opportunity to have a clean break from using ours ours have fields in them which for example when they used in opt are once the fields are overloaded you could also argue that they\u0027re redundant so there\u0027s a feeling that the RR format isn\u0027t necessarily the right one to use despite defining a new format here what it also does is because we have an opcode then the set of TVs you have effectively form a new opcode space underneath the new opcode because each of those TVs is completely flexible in how you define the data in it one of the arguments for not using our ours was that there are error cases so you would have to worry about sessions signaling are ours any having normal DNS messages and vice-versa you have to deal with the case where these shouldn\u0027t ever reach a cache because they shouldn\u0027t get there and a range of error scenarios the counter arguments that have been made to say no we should stick with an RR even "
  },
  {
    "startTime": "01:04:38",
    "text": "though we have a new opcode r that passing this within the name service isn\u0027t that\u0027s difficult the issue is the knock-on effect to every element of the DNS ecosystem so once you have a new format like this all the string of tools involved need to be updated so if you have write a string or string to our conversion formats we\u0027ve got to update them you\u0027ve got to update all your logging any capture tools that you have storage formats so this has implications for CDNs for doing this tap etc and any tool that wants to pass a dns message will have to cater for this because at the moment by using our R\u0027s it unknown our arse can still be managed within that framework or you can just extend it by adding a new RR but because this is an entirely new format those tools are going to get tripped up the other argument is around all this error handling and it\u0027s well we\u0027ve already come across that problem with opt our arse so we kind of know how to solve it with this and one I didn\u0027t put on the slide is of course if we\u0027re using this new format we probably need to think about deployment issues because think about issues we ran into just by trying to use a DNS 0 to back that up we did just a little bit of limited memory testing so tom has a test tool which will send a session sickening message using opcode 6 and the new to avi format and we fired that offer a few recursive x\u0027 we found that find an unbound appeared to do the right thing they returned not implemented with an opcode of 6 Open DNS return implemented but the opcode was 0 in the response sorry this was all done over TCP I should say um Google when it got this message it waited a second then it shut the TCP connection we fired it at DK geez not was over over TLS and that immediately shut the connection so this these obviously aren\u0027t blockers but we\u0027re making a list of yeah if we do this with that there are some things that might need to be fixed what isn\u0027t completely clear is whether this is simply the fact that there\u0027s a new opcode there or whether it\u0027s a TLB format or a mixture of both so we can get more digging but it\u0027s not a oh it just works everywhere um so that\u0027s where we got to yesterday when the editors of the draft sat down I had a meeting and what what were the height of that was a few other questions we started thinking about actually using a new format and we took a look at the text in 1035 and the way that that\u0027s written is very much here\u0027s the DNS message or Mac you have counts and have are ours and you can "
  },
  {
    "startTime": "01:07:39",
    "text": "have op codes the text it uses to describe an opcode is it is a 4-bit field that specifies the kind of query in this message it doesn\u0027t say anything more so none of this indicates any expectation choose anything other than the standard message format so it doesn\u0027t explicitly prohibit it but it doesn\u0027t cater for it so one question we have is there any other document that clarifies that great if there is to have that reference I leave mark Andrews is participating remotely I understand he has a strong feeling that there is nothing to prohibit doing this with NOC code but this feels like an area needs clarification because it feels distinctly that if we are going to use a different format then this draft probably updates 10:35 so we\u0027re good to discuss that the other question is we started thinking about the name and what facilities this new york code actually provides so at the moment it\u0027s called session signaling but when we actually looked at how it\u0027s being used in service discovery documents that name is actually a bit misleading so if all you read is this draft in this context the current framing in the current language could easily lead you to believe that this is just specifying a control channel or a channel under which you create a context for regular deines messaging to happen the way it has been used in some of the other drafts is that it is also transporting data inside these TVs for example in the post draft the server actually sends the new updated data back to the client in a server initiated session signaling message in a recent more recent draft which is the relay draft that has this in the latest version it actually has the case where a mdns wire format message is encapsulated inside the data of a TLV that goes as a session signaling message so what what struck is is that the way we\u0027re doing the spec is there is nothing that limits what can go in these TVs and so we just need to be clear about what you\u0027re getting by using this new opcode and so we think we should rename it some to something like just doing a session in other words this is a different way to do dns within the context of a session that you set up with mechanism assuming me detangle all of that there are a handful of issues start standing on the o3 and these are ones that are noted in the document looking at the language they\u0027re the term that session is used very liberally and in the most recent update we\u0027ve realized we are updating 77 66 in this so we need to "
  },
  {
    "startTime": "01:10:42",
    "text": "be clear it in the language I think about what a session is is it a SEM 766 session or is it a session signaling session so that needs some work this version of the draft introduces two timers one which is in an inactivity timer the inactive timer no there is a keepalive timer and I think we need a bit more work to describe the fact that we\u0027re introducing a kind of traffic which is the keepalive message which is special in the sense that it doesn\u0027t reset the inactive timer whereas every other kind of message that sent on this session will do there\u0027s also some questions about ordering the current text in the draft says that the server must act on messages in the order they are received there\u0027s a subtle question is that the order they received or the order they are transmitted and one of the errors this came up in is when we talked about the applicability if this too quick and it\u0027s still not unclear whether it is applicable too quick or not I think it is given some discussions that we had um Christine you want to talk on that now yeah the problem is that when we do things that quick we want to basically process the server to process the message as they are not received and the quick transmission itself doesn\u0027t guarantee that the order in which they\u0027ll receive is the same as the order in which they are transmitted now UDP doesn\u0027t guarantee that either and the the sentence that you have there is kind of weak because most act what does that mean I mean he is putting the message on a queue acting right so I think else when the draft we talk about you must process in order in the sense that these tend to be a lot of the messages in push art you know subscription subscribe and unsubscribe so the desire for this was really that you are trying to process those as you receive them but I take your point it\u0027s slightly ambiguous no it is it is very ambiguous because I mean most of what you will be seed will be queries you will all no no not necessarily think so effectively we have to be very very careful there that we don\u0027t create an artificial constraint that prevents no more processing in it also we have yes your Cheshire from Apple I believe I remember the reason for that which we can debate and may disagree with but the reason was there may be operations that "
  },
  {
    "startTime": "01:13:44",
    "text": "create state the future operations depend on and so the intention of this was if we wanted to support that then the ordering had to be respected or got two ways you can either use the side effect of the transport to get your order or you can have an explicit order in somehow right so that\u0027s the decision we have to make yes because if they are transactions that change the state of the server you have to wonder whether you should have several such transaction in the pipeline or whether on the contrary users just one or maybe in each transaction you have a point of the views one minute there\u0027s a classic sit solutions to sort of use the example that\u0027s are I was using how one of the first clients of this is the DNS push where you can subscribe to be told about change to record or you can unsubscribe if the transport gets those messages out of order and the server receives an unsubscribe for something is never heard about is that an error should it return an error code or should it sit on that and wait for the subscribe to come in that it was canceling and if so how long should it wait for the SUBSCRIBE so I heard from I know of it what you would do there is that I mean suppose that you want to request at the client doesn\u0027t better serve all in a bind you you would say that the the server would actually reject and unsubscribe if he does not seem to subscribe because I know or might even do something nasty but the client should wait until the Sequoias in confirmed to set an unsubscribe so that would be another way of solving the problem and I don\u0027t feel strongly so if the working group can decide which one we\u0027re going to pick that\u0027s fine if we can rely on a transport like TCP to deliver things in order then the client doesn\u0027t have to wait a whole round trip for the confirmation before it can proceed to the next step right it\u0027s not limiting doing one request ping pong and waiting for the act before I get that but what you\u0027re describing is an optimization that says that if the Henderson way it seems are flowing 3d the cost of that optimization is that you\u0027re mandating a sequencing transport yes which has its own cost means it\u0027s also and so so basically you have one design that attempts to gain performance one wave it loses performance the other way it says I don\u0027t think I want to spend a lot of time I mean I it sounds like you prefer something that doesn\u0027t require the transport to deliver things in order like TCP is that like a quick summary of where you stand okay so I\u0027d be interested in hearing "
  },
  {
    "startTime": "01:16:44",
    "text": "other people\u0027s opinion because I really don\u0027t mind it\u0027s one of these it\u0027s tricky decisions where either solution would work perfectly fine and those are the hardest to agree because it goes 5050 yeah it sounds like it needs to be pursued on the mailing list and in the bar so Ted lemon just an additional sort of complexity to that is that so session signaling generally carries state so you definitely want anything that\u0027s sent after a signaling session signaling message to be processed after the session signaling message if you don\u0027t do that the state will not apply to it and that\u0027s bad and then there\u0027s the other case which is where you just happen to have two DNS messages in a TCP connection or a quick connection that are not socially in session signaling mechanism messages and they are sent in a particular order and the question is whether you need to process those messages in a particular order or not so I think there\u0027s actually two different things although in practice you either have ordering or you don\u0027t so maybe it doesn\u0027t matter right I don\u0027t think we address the issue at all of what the ordering of the non session signaling messages I think we\u0027ve restricted it just to the session signaling stuff because that\u0027s what the state is but yeah maybe we need to make statements about that yeah Henry Sullivan the the other thing that I would mention is that there were other uses here that were intended to be just you\u0027ve got this session and now you can reuse it so it\u0027s it\u0027s not it\u0027s not nothing that you know some of these things could be processed at order that that\u0027d be significantly advantage advantageous in other cases so I think I\u0027m increasingly persuaded by Christians argument but it occurred to me and I said this in the jacquard channel that um that we might take a page out of dns updates a book here because it has prerequisites okay right but their specifics is I think yeah I was screaming loudly about the vibe formatting delays so let me scream here basically the proposal if I understood you correctly is using new opcode and new format idea and right so from my perspective it seems like specification which is creating DNS version two over the version one right because the unit version one is just the header which is like without any value no data at all at the end there is something completely unrelated to the previous DNS so maybe it\u0027s time for the clean cut I I\u0027m you know I\u0027m not insisting on the old DMS just you know don\u0027t combine these two together because it doesn\u0027t seem related okay shouldn\u0027t should we let you finish the rest here like much less on the slides and then we can let the bun fight commence yep I think I think the bun fight has already committed so very "
  },
  {
    "startTime": "01:19:49",
    "text": "quickly on through these say just minor things that we need to also take into account we stays in the draft that an impasse proxy should not blindly forward this we don\u0027t actually say what empath proxies should do with it and also in the O 3 version of the draft we explicitly state that name compression is forbidden and it dawned on us that having DNS warm up messages encapsulated inside TVs is in conflict with that so we probably need to revisit it there were a couple of other issues which are noted in the draft but we haven\u0027t come up with a solution for one is the fact that if you don\u0027t have an additional section you can\u0027t do T cig and then you can\u0027t do any easiness zero and the main use case we could see for that we lost with that was being able to pad these messages so a solution was proposed at a padding TLB but it\u0027s not in the o3 so that does need catching up with and there was previously a more fundamental question about does actually every message require a response because it\u0027s which DNS that feels natural but in some of the service discovery cases it feels really redundant and I think the relay draft actually does away with responses in some cases because that\u0027s natural to the message by the last thing to say before we move into discussion is that as I said there are several drafts in service discovery in particular push that depend on its normatively so this is whole up at work so this is something that we it would be really good to get to a resolution quickly on and I\u0027m all open on ideas of how we resolve the tale V versus RR debate that don\u0027t involve rock-paper-scissors all armwrestling or ever but this is one of those cases where I think we have two camps and I\u0027m not sure how we move forward on that say that\u0027s for the working group for - yeah we have a couple minutes yeah we have a couple more minutes because actually we were a little bit ahead of time with that discussion which felt very productive so he didn\u0027t stop but kind of put us back on schedule so we have a couple minutes now and definitely we do need to continue the discussion you know on the list and in the halls because if there\u0027s a relatively quick resolution in these things possible we should do that this is unreasoning I\u0027m actually torn about a new format because for introducing new format I\u0027m not actually concerned about the people who are here because well those are just you know minor glitches and we can fix that but you might be aware of my new crusade the DNS bear violations and I\u0027ve seen a lot of new implementations coming up and people implementing DNS protocol in various languages and stuff like that and those are the people who are generally not here and and those are who "
  },
  {
    "startTime": "01:22:51",
    "text": "when I\u0027m concerned about introducing and you complete a new format because from dos implementation I\u0027ve seen they generally tend to ignore the things that are stable so they might not parse the OP code and stuff like that just ignore it and try too hard this here he is it as a DNS format and in break horribly so that so on one side better on this but on the other hand if we break this earlier it\u0027s might lead to a new development in the DNS protocol like like reinventing some things we did wrong in the past but it leads me to other concerns I have with this sexually the depending stuff and other things like this you dropped all the improvements all the useful improvements we reintroduced DNS and you are implementing this in tre like that keep alive depending and I\u0027m not sure I like this I think I don\u0027t we could end up with a whole bunch of duplication here just because of that kind of thing like oh I\u0027ll do it in TLB as well and you know I never really hated the duplication more than I dislike the new format okay Ted lemon yeah so I mean the duplication issue I think is a real issue but eating a zero sucks I mean it\u0027s it\u0027s really a pain to work with it\u0027s it and and it it\u0027s an hour right it\u0027s not it\u0027s not it\u0027s not not an RR and and that\u0027s that\u0027s circular but but but it\u0027s the whole point of what we\u0027re doing here is to is to represent things that are our arts right yeah yes and no I think I mean well as a keepalive in our are no a encapsulated and DNS message could be an RR no it\u0027s not it can never be in our because it\u0027s a message it contains our ours yes but it\u0027s not in our but we\u0027re not precluding things that could also be our as under this format yeah yeah you could do a stuff in our or in here I mean that\u0027s that\u0027s all point it\u0027s a totally flexible format yeah and and honestly I mean that\u0027s that\u0027s what\u0027s good about it and you know as far as as far as like you know some random device out on the internet crashing or returning a bad result because it gets it first of all is something if something doesn\u0027t look at the opcode and tries to parse that the the payload as right what if something is something yeah that this is a the Stewart\u0027s making the point that the the all of the counts are zero so so you would have to be really broken to actually try to parse the payload of this packet if you didn\u0027t look at the "
  },
  {
    "startTime": "01:25:52",
    "text": "opcode right yeah I just don\u0027t see how that would happen but you know if it didn\u0027t happen it\u0027s actually good news too so to some degree you know well I think blew up I wonder why yeah and you know this is a terrible implementation and yeah it\u0027s it\u0027s vulnerable to just random stuff being thrown at it so it\u0027s not our fault but you could say that you know we\u0027ve also got to accept that then we might hit problems with middleboxes oh yeah don\u0027t like this and we hit horrible deployment issue right but we already have that with a DNS zero so that\u0027s not a difference between we need to continue that particular point on the list and closing in like okay my pound set yeah I\u0027m I\u0027m a little bit ambivalent on the format issue because I it seems to me that the Tobs essentially create a control plane sort of separation of control plane and data plane where we don\u0027t currently have one in a sense mmm not really because there\u0027s nothing that restricts used passing only controlled I - until these yeah and and I like that it it enables all sorts of things solves problems potentially solves problems we currently have using Eden s0 enables all sorts of things that we can\u0027t do currently as a as somebody who implements monitoring and you know log processing and all those things I\u0027m not particularly concerned about the extra work if I\u0027m conceal the messages I will ignore that opcode if I am concerned about them then it doesn\u0027t matter to me whether it\u0027s in our TLB I have to write code to process it anyway so so there\u0027s that I\u0027m a little concerned about the issue of embedding DNS messages in tlvs that seems a little bit odd to me I I remember having a conversation with somebody I think he was in brilliant about about push notifications and how that might work and things and what I said the picture I had in my head and we were having that conversation was a TLB would set up the session set up a lien and and the client could send a DNS query with sunscreen I just make a quick comment because I think you\u0027re mixing up two graphs the push notifications is not what this is talking abut engines on this and it minute the embedding is a different graph it\u0027s the relay notification I separate sorry but in here but Ted lemon be the the the the other draft I\u0027m not at all attached to doing it yeah be perfectly happy to just do session signaling is its own thing and have the other packets be in line yeah so so it\u0027s actually you know if if that\u0027s the if the working group wants to do that I\u0027m totally cool yeah the the I guess yeah it feels to me like sort of a layer violation and and and it and I\u0027m "
  },
  {
    "startTime": "01:28:52",
    "text": "and then I\u0027m concerned about the possibility of things like DNS over HTTP over TLB over DNS like we can up it enables some really weird things that I don\u0027t think we need to embed DNS messages in the TLB itself so Stuart sure sure Apple couple of comments one quick one I want to put a slightly different nuance on what you said at the start Sarah you said that you wrote the session saying and then Tom and I came along and modified it only I know that\u0027s you shaking you know all I wanted to say was that the spirit we approached it was you created this document that define this new container format and we thought we were embracing that in the spirit that you and Ray intended and it\u0027s only recently that we found that you know that we read more into the document that then you intended but it\u0027s what we were actually not trying to we\u0027re not trying to change the document we actually thought we were embracing the spirit of it yeah I think it was a genuine disconnect there and what the expectations were and also there\u0027s there are two very different use cases for this I think and and that\u0027s where have you points differed on this question of tlvs appended on the end versus a pseudo RR I think Ted summed it up very nicely that an idiocy rock record is not a resource record and it\u0027s also not not a resource record and that is the problem you\u0027re you\u0027re cramming this data into slots in a format and giving them different meaning because the the resource record has a TTL and a class but for an opt record they don\u0027t mean that they mean something else and you actually don\u0027t cache an opt record for the time that the TTL says you should cache it for because it doesn\u0027t mean that it means something else and as a result the Wireshark decoder for that record type has to display different labels next to those fields and parse them differently because it may be four bytes but it\u0027s four bytes with a different meaning so I think it\u0027s written illusion to say we could just use an RR and you don\u0027t have to change the code that parses it because things like Wireshark did have to change the code and caches had to know not to cache that record because it\u0027s not actually a record so I think we\u0027re kidding ourselves if we think that just making it look like a red board makes the problem go away yeah I agree it doesn\u0027t make it go away I think it changes its magnitude a little bit but if this is all about the trade-offs here between having the new formats and the impact on all the tools etc and it\u0027s just about weighing up those pros and cons or fancy people I read the first half about Islam for me it\u0027s totally new Potiphar\u0027s is no reason to reuse really "
  },
  {
    "startTime": "01:31:52",
    "text": "we should just get rid of the past oh no on start from scratch and I can\u0027t see which kind of code can we use and for sure we don\u0027t want to reuse the name compression cut fan stance sorry wait sorry cut the line sort of running out of time lesser is very great 30 ok quick um Tom cruson Terry I\u0027m just gonna say I like the TLB format because this stuff is session related and it makes you think about it differently and treat it differently and this separation is I think a good thing thank you this has been really good I hope it\u0027s been helpful to the editors I I think what we\u0027re hearing is slightly tip towards the TLB side oh that\u0027s so my gonna work on the revision yeah and if there are additional issues where you need we need more feedback to get done ish yeah this is actually a good candidate for another for an interim yes and get everybody that\u0027s interested in maybe some of the folks in the SSD or other groups with they\u0027re watching this work also yeah we can do an interim just about resolving the last issues for this also if anybody was in d-pryde this morning I had Daniel Gilmore presenter draft about muxing DNS and HTP over the same port which people were horrified for though many people actually were trying to solve the problem which is not what we were trying to do we were trying to warn people that there are these bad architectural things you can do if you\u0027re not paying attention to stuff right and I think one of the concerns I have in this is we just want to make sure and I think we heard that about you know duplicating stuff and TLB sources are like you know you know are we doing something that\u0027s gonna fund \u0027mentally cause some breakage right or cause something bad to happen as we go down the road and I I\u0027m just you know we should sort of consider that as we\u0027re sort of reading this draft and I think a few people have sort of said that so that was the only thing I wanted to sort of say about that so thanks sir so for those of you who don\u0027t have the context on this bolcar are back in Berlin I believe is when the CenturyLink folks originally brought it to us and it was their first effort with the standards participation process and so it was of their original design but they look for a little IETF help and moving them along and that\u0027s why I jumped on the project for those of you that they don\u0027t have the full context of exactly what the proposal is essentially it\u0027s a way of putting vines dollar generate feature into an RR record that could then be shared in zone transfers in order to dynamically generate records it\u0027s really based a lot of people were "
  },
  {
    "startTime": "01:34:52",
    "text": "under the impression was built around regular expressions but really it\u0027s only based on matching numbers and a quick example here shows you how one record could then generate for example whole bunch of address records or PTR records or what-have-you for this draft the Birgeneau six draft was just published on the 3rd of this month right at the deadline cutoff but because that\u0027s the way we all do things the main goal here was to simplify the draft so a lot of it was changing around to make the language a lot more straightforward this actually had a significant effect on the total page count dropped it by 50% some of that was not just of course from the language clarification but things like taking out a couple features like there was this feature where it tried to modify wildcard semantics essentially to hide the effect that you know to hide the overt evidence that pattern generation wild carding was in effect here this is driven by some operational issues that the folks at centurylink it had where they see for example you may be familiar with mail servers that will try to detect that your reverse address space is you know dynamic dynamically from your pool and therefore shut down your MX connections so they were really trying to avoid that particular issue and it\u0027s still a question that they want to have addressed but at the moment of bulk are doesn\u0027t have any special requirements for trying to hide its existence we also remove some of the octet value restrictions to make it a lot more DNS e that is originally they define patterns is only being in terms and the substitution data that you could use only in terms of the u.s. ASCII character set in particular printable characters and the DNS as we know does not have this particular restriction and so even though it\u0027s unlikely you\u0027re going to want anything other than ussd nonetheless to make it more consistent with the rest of the protocol in now it essentially allows any octet we also there some things were kind of wide open the way it was originally defined you could have any number of references being used for substitution limited to only I suppose by the size of the unsigned short for your entire message length but in practicality you\u0027re going one far fewer than that and so we tried to limit it I think the current number is 32 which would give you every nibble of a ipv6 address so tried to make that a lot more constrained as far as simplifying your implementation might go and then there are a whole bunch of other clarifications that exist in the draft there\u0027s still other ideas that want to be pursued in particular as I mentioned the original design goal included really modeling a lot of dog that dollar generate behavior as far as being able to format the way records looked and the thought there again was "
  },
  {
    "startTime": "01:37:52",
    "text": "that having familiarity you know that people would see that hello this is just like always generate inside a record might help move things along faster but it might be possible to doesn\u0027t dollar generate itself was just a little bit too flexible in what would should be expected out of its format generation there\u0027s also another record in this draft the NPN record which was supposed to help with DNS SEC essentially it gave a DNS SEC like version for these generated pattern names it wouldn\u0027t allow you the full expressiveness of being able to say that this particular pattern would always generate this record especially in the context of trying to hide the bulk record that actually generated it but it turns out that you know as I was trying to write it up and clarify it I was there significant DNS at roll out issues here that really suggests that if you want to use bulk are probably and the DNS Exxon zone you\u0027d probably have to use online signing other ways of dealing with it for example even signing the book our our record and not trying to come up with a special record all of those have big enough hurdles that it doesn\u0027t seem wise to address it for the basic use case that\u0027s desired here and then last but not least another thing that I want to end up talking about and I\u0027m surprised that John Levine I don\u0027t think he mentioned it when he was up the mic a moment ago talking about a name but there\u0027s an issue did you mention it and I just tuned out for a second okay so the issue is essentially that while while some people some famous DNS cognizant I have declared on mailing lists that it is a myth that rolling out in URR is hard that is relatively true when you\u0027re adding an RR that\u0027s just shipping around data that nobody is supposed to look at what the our data is when you\u0027re adding something that actually has semantics on the server you can easily get in the situation where your master is your primary server has this record and then is being transferred to servers you have absolutely no idea how to handle it and now your zones broken so this is a problem that extends beyond bolcar but it\u0027s a problem we really need to be talking about to try and figure out maybe we can use a session signal TLD to say in any event it is it is a genuine issue some text has to be added I don\u0027t think the bulbar itself is going to solve the problem but it\u0027s a wider issue that the working professor consider and that was and we would like to adopt it as a working group document to move forward these others what\u0027s mentioned here I think can easily be done under the auspices of finally being and being this up document yeah we can we have a few minutes for comments and then we can take the call for adoption for the working group yes and I might picking just go fight it up very quickly a name as a gracious fallback "
  },
  {
    "startTime": "01:40:53",
    "text": "behavior for secondaries but sadly I don\u0027t see how you could do this football I mean the DNS SEC validation that requires changed on the result really should be something else I mean because this has value without it and you can deploy it without right follows ready so I haven\u0027t read this in a while but it\u0027s true that is it true that you can see the difference between a bulk generated records and real PTR records no I mean on the on the wire what you get in theory solver would look like just a normal PTR record okay I\u0027ll sit down yeah yeah hi I\u0027m still John Levine yes I have to say that this latest version is much less horrible than the previous version but if that sounds like faint praise it is and I mean I don\u0027t have a book I stole a bunch of issues with it I mean I think there\u0027s a certain mean I think the least bit these records with semantics that secondaries don\u0027t know about problem you know it\u0027s one that I guess when we invented DNS SEC we hoped it would never happen again and and there\u0027s still some possibility for that name this is you know we already a bit in the DNS blacklist world we have we have a stunt server called rbl DNS D that does kind of this stuff okay and nobody has ever asked to have rbl DNS these junk put into the standard DNS spec it to stun server it does one rather peculiar thing and it does it pretty well you know enemy what you have here is now that you sort of do per generalized it you know as far as I can tell this is essentially a way to generate to wallpaper the the v6 reverse address space and I don\u0027t see that as a big enough issue to be worth all of the damage to the DNS or a little bit create Vienna\u0027s cruft that this requires I said like why don\u0027t you guys just bytes not servers and you can use that you know it\u0027s not as nice you know I realize I understand it as operational issues because you like you have multiple secretary you have multiple secondaries with multiple with multiple other providers but I don\u0027t see I don\u0027t see the issue of getting them to to support your stun server as being meaningfully different from getting them to do to put in all this stuff okay and my final thing is for DNS SEC I think youth bite the bullet and say if you do this you have to do online signing you you should do something like CloudFlare is malicious lies too you know and just you know and you know and malicious lies but basically like do the signing like we we know we know ways to sign to sign records that are generated on the fly right you know so do them and don\u0027t you "
  },
  {
    "startTime": "01:43:53",
    "text": "know don\u0027t ask people to to carry your water for you I\u0027m closing my client after Andrew unless somebody is desperate or after Andres under my clan closed okay Andres three I\u0027m John - most of my comment I had just drop the NPN and require online signing but on top of that um the DNS a keys have two bytes specification of the usage so why we why not we think about adding a special type of DNS key just for silent about records yes okay I\u0027ve had a similar thought that you could had a couple of keys in its own one of which is for static signing of you know for a a zone that actually mixed this in two types of data that your static key offline to you could sign everything and then you\u0027d have your one online view that would be the rest yes because then you can use this key T well give to secondaries and you will not be afraid that it\u0027ll sign all the other recourse right or something in this space but the NPN is just the deployment and the implementation is just it will be too complicated yeah and I\u0027m Andrew Sullivan the reason I got up here is because of John\u0027s remark well why don\u0027t you just got these stunt servers why don\u0027t you just go off and do that with your friends the reason that people don\u0027t want to do that is because it\u0027s the same reason that we\u0027re all here in this room this is this is the reason for standardization that we want to be able to work interoperable with various other people on the Internet so um despite the fact that you know somebody who\u0027s probably paid for my presence here would would dearly love to close this all up and you know sew it up nicely so that nobody else can play in this space on the purpose of getting together and standardized standardized things this way is precisely so that we can create more competition have a better ecosystem I think that\u0027s important yeah an awful lot to say that I also think it\u0027s important I mean my own employer who also I did not speak for does have an among the many modes of its authoritative nameserver one that does work on regular expression patterns and so we could perfectly well set this up for a customer who says I want to do this really large zone can you just automatically generate it and step time to transfer you know dozens and dozens of megabytes and zone transfers so we\u0027re already capable of doing that but I believe it\u0027s to our to the overall the industry\u0027s advantage to especially in the wake of some problems that we saw in just the past year to allow for a multi vendor set up and to be able to share features like aiming and by pattern generation of names and so Demetri a speaking for myself I just think that making DNS turing-complete is generally "
  },
  {
    "startTime": "01:46:53",
    "text": "around GUI to go but I just say that putting computational resources to another party is again conceptually wrong so not because I don\u0027t like mine or I don\u0027t like generate I see why people need this but I just think if you take this one step further it would go in the wrong direction so as well point out that the other computational resource part of this is just going to be on the officer my client gets just the record that they asked for oh yeah that\u0027s correct yeah do you want to UM just to get a sense before bringing into the lister okay yeah we\u0027ll take it we\u0027ll take the call for adoption on the list because I suspected the what you\u0027re talking about are some very significant changes from the previous version and I\u0027m not sure people have had a chance to really what\u0027s that a whole week ago Suzanne I know I\u0027m here for you but there\u0027s two more presentations in there on at least somewhere related and I want to make sure we get the both of ya and I\u0027m gonna go really fast on my chair I seem to think that these are more related than either of the graphs authors thing I just want to make sure we get those and so and I will leave it to my think McCune this press presenting his I will be stealing was okay to describe what the salient differences are but in the case of surveil the proposal here is essentially really only meant to cover cases where things are humming along just fine and then the authorities go out to lunch when you\u0027re trying to resolve a name we still we don\u0027t change the semantics of the PTL at all they would still be essentially so we don\u0027t change the immediate semantics of the PTL and that the TTL still defines the maximum time before which you should attempt to refresh however traditionally resolvers have been expunge the record from the cache when they encounter an expired TTL what this says is you know keep it around for a bit longer and the bit longer is defined a little bit later but essentially when you come across authorities so you can\u0027t get an answer from any authority then within a short period of time you should send a response back to the client before the client finds out there\u0027s current recommendation that this should be around 1.8 seconds then your resolver though keeps trying to get it up to whatever it\u0027s normal fetch timeout is in bind used to be 30 seconds I think they\u0027ve cut it down to ten seconds now dippers all reduce different values it\u0027s not really that relevant to the doc other than don\u0027t wait just 1.8 seconds you should keep trying along and in this particular case also negative responses are considered to be a successful refresh if you had your in dub dub dub example.com with an a record and now it\u0027s an X "
  },
  {
    "startTime": "01:49:53",
    "text": "domain the NX domain is a successful refresh that is what you should be serving even if you have to rely on a sir stale answer in the future and then after a number of another period of time which is currently recommended to be days to allow for manual intervention at the authorities for fixing whatever problem is going on with then even over a long holiday weekend eventually then you expunge the data so you\u0027re tapping your cache sizin and everything you know at this point you have a real problem back the way you would have had in that very first period and the goal here is to balance data integrity with resiliency because most of the time in our operational experience the answer that you had before the detail expired is still the answer that\u0027s going to work even after the detail has expired most detail refreshes for us come back with the same answer and so the key here is at least try to get a fresh answer before you decide you\u0027re gonna use the stale answer and then move on it works I wrote a PAC 4x9 back in 2011 it has smooth over a lot of temporary and stability and even prevented several major incidents for us things where you know our web servers would have tried to connect the origin and failed because their provider had come under das attack for example it\u0027s been contributed to ISE now for inclusion in vine 9.12 i don\u0027t know what the current implementation status is but that was my understanding getting a thumbs-up from Vicky and wild bull Bachman Google do have patents that cover this area Wow akhom eyes in particular that was a sign from Zira Cole really spells it out that clearly covers it we have both had our official IPR statements with using the license declaration to be provided later but the code was contributed to is see under the Mozilla public license and so you know even though it\u0027s still technically the will be provided later we expect it just to be freely available and the big questions we have are Warren and I are even not completely in agreement these timers that exist existed because this was what worked in our environment when I originally implemented it but it is worth discussing to see are these the rightness recommendations to make and we would think otherwise it\u0027s pretty straightforward and could move along pretty well and so we\u0027d like to see working group adoption and just push it on through do you have anything to add warrant he had submitted the TTL buzzing yeah phenomenal so this is a huge deviation from what actually the DNS sort of protocol was supposed or doing but my main concern is this is supposedly be standards track and it describes one implementation pretty "
  },
  {
    "startTime": "01:52:53",
    "text": "precisely and the draft notes that are other implementations like unbound and we have one and I think Cisco also has one which might also have IPR on that I think it might be worth actually writing up something more on the requirements I don\u0027t know if you want to do that what to do and what not to do but this is far too specific into the applications and the implementation side I think and I mean I mean definitely not standard strict maybe it\u0027s experimental information well so again with it changing the idea of what the TTL means and what the expected standard behavior would be on the internet I think it is absolutely relevant to being standards track and you know like you say yes this is one particular implementation but I\u0027d also very much welcome feedback on what\u0027s a better way of doing it like how could that change you know what aspect of the requirements would changed under a different implementation well I said there are different ways to achieve that goal by serving cell records and there are different organizations that have done different approaches and this is just one well and yes I would like to understand better what those approaches are and in fact whether they make more sense or not so yeah I guess Warren kumari yeah I mean I don\u0027t think that we\u0027re in any way wedded to this so if other implementations want to describe their implementation you know we can include those as well or something similar you know this is not the best way if you all works better or if you\u0027re willing to describe it and similar I\u0027m not sure working but I think what we need to have here is a sort of description of requirements what to do in the K in in such cases and what not to do and then have implementers sort out how to do or what are we sort of do that and say one word one implementation does it kind of like this more towards an appendix e type thing possibly is not yeah so and to be clear because I\u0027m not exactly sure on my response came across initially but I am in favor of the idea of saying yes lay out what the requirements are and you know I still think it\u0027s useful though to describe them at least one way of achieving the requirements and to the extent that there are other ways of achieving those same requirements I\u0027m happy to describe them as well then I\u0027ll hang another time thank you for bringing this to the dinners over and so you need similar questions about the the IPR and an appreciation of art so OpenDNS also had something like is that included so I actually it was when I was looking for OpenDNS is to see if they had a patent or something is when I found Google\u0027s patent that mentioned Open DNS okay and was unable to find and to be scented there\u0027s a disclosure to make there somebody make it okay and so I come I you said well for us it\u0027s well as we contributed to code we expected will be hello and this also for Google is the same so to be honest I didn\u0027t know about "
  },
  {
    "startTime": "01:55:55",
    "text": "the IPR until David found it and then one of our lawyers sometimes like I can\u0027t really tell if this applies and I don\u0027t really know so you know they filed as much as seems like it could possibly be something that rifice this but it\u0027s sort of off on the sides so obviously I\u0027m not a lawyer I\u0027ve been poking our lawyer to see you know to try and provide more info okay but they\u0027re not hugely interested in actually thank you very much is on rape but wealth upset most of what I wanted to say but for the timers I don\u0027t think that the hard timers are correct in this case even for this implementation I think they should be derived from the original teaching else from record because the the intent is not to serve a record that has a 30-second TTL or for a week it doesn\u0027t seem correct but if it\u0027s a way to have to save and domain under attack that has a TTL of of two weeks for another week that that seems okay so it somehow you should derive those numbers from the from the original TTL that would seem better by the way how to okay to define all happened I\u0027m happy to discuss that on lists but I think that\u0027s actually the exact reverse situation what you want somebody has a long to be TTL they\u0027re unlikely to be under attack for that long that\u0027s going to impact that many people have their record cache where is somebody like a CDN not just to CBN but that has you know very short details it\u0027s easy to make a fun attack that would cover you know lasts long enough to cover even several tto extra periods and giovani aside en it\u0027s great to work I think it\u0027s very interesting also because there\u0027s a current trend a lot of people move in their services to cloud providers and there\u0027s a risk of collateral damage in shared infrastructure so if you have something in place like that we kind of remove all but the long-term let\u0027s say this incentives for attacks the DNS infrastructure so I think it\u0027s good work thank you thank you read the draft review the drought Stephen Morris to talk about opportunistic refresh we\u0027ve taken our beating for considering these drafts related Thanks this is this is a draft written in conjunction with including sivaraman than Shanker right consider considered normal case of events we query for the Horde a wrecker all ww2 calm it stays in our cache TTL the record the record then expires a little bit later "
  },
  {
    "startTime": "01:58:55",
    "text": "we clear we query thrice again it\u0027s not in the cache we have to do an upstream fetch now let\u0027s let\u0027s suppose that before we do these before we do the second query we query for another record from the same zone food comm MX will also make a couple of assumptions here we will assume that with every response we retrieve the serial number of the zone and we will also assume but the serial number of the zone uniquely reflects the contents of the zone in other words if there\u0027s only changes the serial number changes now if the to see if the two serial numbers are the same then we will be entitled to assume that had we queried for www on at the time we queried for the MX record we would have got the same answer oh the FIR serial number nothing to do with whether song has changed or not if you are not using normal zone transfer I can\u0027t my surgery on the fly okay I said that that was an assumption on dealing the bat I\u0027ll deal with that assumption in a couple of slides time now going back if the serial numbers were the same and then with our assumptions we can assume that the zone constants hadn\u0027t haven\u0027t changed had we queried for the same record at the time we query for the MX record we would go we would have got the same data therefore we we are entitled just simply to extend the TTL the record we have - so when we come to query for it at t1 we don\u0027t have to do an upstream fetch so we say that so we saved ourselves a query to the authorities its server so the zone the zone serial information how do we get the zone serie of information we could we could send it along in in needy NS record but the zone already has that information in the form of an SOA results record so the simplest solution seems to be to just add the SOA results record to the to the response uh-huh it\u0027s pretty pretty clear but just to emphasize in order to extend the tto the serial numbers must match we can\u0027t make any assumptions if they different so now how do we let let\u0027s address those two two assumptions that we get there we get the we get the SOA resource record and that\u0027s the that the serial number "
  },
  {
    "startTime": "02:01:57",
    "text": "reflects the zone it said that of a fundamental theorem it\u0027s fundamental theorem of software engineering is that every problem in computer science can be solved by adding another level of indirection and one of the ways British when I was preparing this presentation and looking back over some previous previous RFC\u0027s it occurred to me that a similar thing applies in our in our field of work every DNS protocol problem can be sold by adding another a DNS option and that\u0027s and that\u0027s notwithstanding Ted lemons somewhat negative opinion of them so we have so we have to we have the client had in any DNS option to the query and it\u0027s asking the server to return that SOA resource record if they find that if the point doesn\u0027t need it that was if there\u0027s no option the server that server doesn\u0027t doesn\u0027t add it so we say we\u0027re saving recycling bandwidth the server adds the e DNS option to the response as a guarantee that the zone change is accompanied by a version number change so this is this is an operator this is an operational thing by enabling by enabling this up this option the zone manager is saying that every time my zone changes I will update the serial number so that\u0027s the basic idea we just said we just submitted we just submitted this graph there are questionings issues so the first one is it actually useful it so it\u0027s not going it\u0027s not going to be useful where the where the zone changes frequently it may it may be of limited use in small zones something with just the www record but on the other hand if they\u0027re so if they\u0027re signed something like this means you only need to fetch the DNS key once the second question is should we extend the TTL of NS records this way NS record NS records are special because although at the end although the child is authority for the UN s record the resolver has to go to the parent phone to check if the delegation is still valid and what we were what we want to try and avoid doing is permanently sending NS records and never finding out that the delegation has changed is that serve as easy anis response option really needed because it could be it could be argued that\u0027s simply adding an SOA resource record to the additional section can be interpreted that the server supports that that the survey is saying that the version number changes the serial number changes when the zone changes I did we did we did have a bit we did have a discussion of this I mean might my feeling is that that the the response is "
  },
  {
    "startTime": "02:04:59",
    "text": "needed because otherwise we\u0027re assigning a semantic meaning to the position of an SOA results record in the response which I don\u0027t know I\u0027m just unhappy with a real can of worms is how should we cope with ECS where the respondent where the response coming back depends on subnet so you get it so you get an SOA is it covering everything is it covering the subnet there has been there has been some discussion of that and finally security mattias making on the on the list did did raise the issue that we that we thought about is what happens if an attacker can send back a response and it\u0027s just that this SOA resort just that an SRE resource record in I mean in many came in many cases signatures of value for much longer than than the TTL and so you could pay so you could potentially maybe keep record keep records in a resolver cache way beyond what they should what they should be so that\u0027s um that\u0027s basically it questions yeah we are at time but we can stay so any comments on this and I think the other thing I want to do before people start escaping I thank you for hitting her shouldn\u0027t you several more seconds reviewers I think the next day the primary next step here is we didn\u0027t need people since it is a new draft and since these questions are relevant and irrelevant we will be looking for reviewers for the for the graph to decide whether it\u0027s it\u0027s useful uninteresting and should whether it should be it should have further work from the working group thanks Lena largely markup method I think there was one assumption that you left out which is this can only kick in when you\u0027re talking to an authoritative server yes yes that\u0027s right so so this must not be allowed to happen is that the response must me live happily that\u0027s right it is mentioned in the draft I did hear Aundre um to answer a question if it\u0027s really useful I think the effect will be really marginal hmm because you need a support for the EDS response option laughing you do this to your first question also because we try to minimize the answers and now you are blowing in up again so I think you need a DNS response option and in this case the effect will be only marginal because of deployment yep what am i right Adams I can I absolutely love this idea and I\u0027ll support this I\u0027ll review I\u0027ll keep my responses to every individual and the things here I\u0027ll keep this for the list thank you thank you yeah I\u0027m not entirely sure how to answer whether it\u0027s useful that I think that requires a little more thought but it seems like it "
  },
  {
    "startTime": "02:08:00",
    "text": "might be I\u0027m a little concerned about the notion of extending the TTL on NS records and any DNS SEC material that requires a lot more thought agreed I I have previously got questions from ICANN doing TLD operator moves that well huh how do you plan to deal with in your timing with you know if somebody extends a an honor sig to its its validity period rather than the TTL in my response to that has always been well they can\u0027t and this may change that which potentially causes some problems Thanks or so I thought that it was only me that the bad idea fairy visits but this is really cool are you so one of the things I\u0027m not sure if it\u0027s gonna be all that useful because you need to do another look up into the zone and I\u0027m not sure if the way that lookups happen that happens that often right I don\u0027t look up for dub dub dub and maybe two other things and then possibly not for a long time if it turns out that I\u0027m incorrect and that does happen often you know in some analysis then I think it\u0027s useful I don\u0027t think you should extend the TT of ns just no no I mean it\u0027s um I don\u0027t think you need the e DNS our thing ECS and security who knows I\u0027ll explain offer quick quick quick comment actually I find this interesting and probably useful as well you would have you looked into simulating that\u0027s and not yet I know as you\u0027re actually spent and the second point is as an alternative have you thought about defining any DNS your option that simply returns the sone update times then we can we thought about we thought about the an option return timestamp but the advantage of the SOA are or is that if the zone is signed you\u0027ve got signatures with it okay Jim thanks T fan just as people of Lydia office first of all and maybe be good I get to try and gather some details to where this would ice be exact a tale you cannot Bullis actually benefit caches and the second question which I\u0027ve made it just that the complete blamed freeze for a moment there so no three through election and gather my thoughts again ice a chancre I\u0027m one of the authors listed on the draft although his most Macomb\u0027s idea and Stephen Stephen did all the work so I\u0027m happy to be on the list so in terms of whether it\u0027s useful one idea that we have is that you can actually look at a thaw retain of server logs and you can look it there\u0027s a I\u0027ve identified this a pattern of queries where you can actually look at the queries that you\u0027ve gotten and estimate what benefit you would have gotten so if you have access so I\u0027m gonna go through the doodle data which is a bit tricky because it\u0027s mostly a delegation only domain but we can look at D s records and things like that but if you have access to big authoritative zones then then talk to me and we can figure out a way to actually use some measurements and estimations it may be possible there may be some ways that you can do some estimation on the resolver side but it\u0027s tricky because you don\u0027t have the data which is why we need the drafts so um frozen Jim "
  },
  {
    "startTime": "02:11:00",
    "text": "thanks TV I remember about the poison miss it mother stupid I keep I\u0027ll mention it enemy I hope it using a timestamp rather than relying the source of antics yes you did okay you can you can use this to you can use the timestamp yeah I think I\u0027m thinking see that before the server uses this is the last time I would add is own you could you could do that but if the server\u0027s going if the server\u0027s going to do that why should it not update the serial number when it does so yeah I\u0027m just thinking this data that Oliver was talking about before about people are doing funky things in the sewer records yeah well you might not necessarily guarantee that the Selective changes with his own content changing this equipment of a mech isn\u0027t potentially nomnom so one thing I mean there are servers out there that have no concept of Syria or last sewn up this they are sort of driven from database back-end and have no idea of when the last update was yeah bit I mean this site this idea is completely is completely optional of the client the client will include the internet option in the query the service free to ignore and just don\u0027t return the SOA with resource record okay thank you thank you everyone and if you haven\u0027t signed the blue sheets they\u0027re around here somewhere thanks for your time we do have another session Thursday afternoon for some additional proposed new work but for now we are done thank you very much everybody you "
  }
]