[
  {
    "startTime": "00:01:08",
    "text": "good morning so this is the second half of the call group meeting we had a pretty productive meeting yesterday and already covered some of the items that were on the agenda for today so just to remind people this is an ITF meeting the IPR principles of the ITF apply including the no.12 and this is the original agenda for today and we we are going to move up the deaf you are in item because GRE is only available around 10 o\u0027clock and we already covered two items and we have covered this one but we have to return to it so we will do that any other things we need to change in the agenda okay in that case we\u0027ll jump into cocoa Alice okay good morning everyone my name is Carlos Gomez I\u0027m going to present the current status in the last date of the draft and title co-op simple congestion control advanced also known as cocoa so first of all let\u0027s take a look at the status of the draft the document is currently in working group state submitted to is default publication and the last revision is - 0 3 which incorporates mostly editorial updates and addresses comments by Wesley ID as the TSP our early review and media cooler win who\u0027s the responsibility for this document by the way both reviewers have expressed that the last revision of the document satisfies their comments and then for the next revision we need to address the comments by for additional reviewers that is the reviews from scott Brandner Vincent Rocca and crystal hallmark and in addition there was an additional set of comments received yesterday by Gauri so we need to address all these additional comments later today in the presentation I\u0027ll refer to how we plan or it is our position related with a comment by scott bradley however the other three reviews have been received just a few days ago or even a few hours ago so for those we don\u0027t have slides we\u0027re still processing the comments okay "
  },
  {
    "startTime": "00:04:10",
    "text": "so let\u0027s go quickly through the updating - 0 3 the first update is in section 1 introduction so now we have added the new paragraph there which in its original form was previously in section 5 which is the section that focuses on mom\u0027s and now it has been adapted made a bit more general and it provides an overview on what cocoa does we explained that cocoa computes the RTO based on weak or strong our titties because we use weaker titties in addition to strong art it is the reaction of cocoa to congestion is by using a low ascending grade and specifically for moms the sending rate is limited to one message per RTO per destination end point which is more conservative if everything works as expected then what is stated in RFC 76 41 which would define a limit of one message per RTD per destination end point then in section 3 we have added details on the scenario square cocoa has been found to perform well we explained that these scenarios comprise latencies that range from milliseconds to up to peaks of dozens of seconds there\u0027s an additional comment by Jaime which is that we we might need to detail a bit more which reference contributes to what within this range also scenarios used in evaluations comprise single hop and multi hub network topologies and link technologies that have been used in a variance comprised 15.4 GPRS UMTS and Wi-Fi also we\u0027ve added that cocoa is expected to work suitably across the general internet so not only within the limits of a constraint node Network then in section 4 the 2 which is the one that defines the algorithm for the RTO we have added an explanation for the default weight values used for the strong and weak RTO estimators basically we have found that these work well in evaluations that are referenced in Appendix A of the document and also in for the two that one we\u0027ve added an exclusive note on the fact that the variable back of factor used in cocoa replaces the simple exponential back-off that has been traditionally used in TCP and also in in default co-op then in Section 4.3 we explained that the state of RTO estimators for an endpoint should be kept long enough and now we provide the motivation for this the idea is we want to avoid frequent returns to inappropriate initial values of the algorithm and also we write that for the fault parameters in coop it is recommended to keep such a state for at least 255 seconds so well this was a must not a recommendation in the row two so this is possibly the only technical update in in zero three and also now we "
  },
  {
    "startTime": "00:07:12",
    "text": "make explicit the relationship between this time at least 255 seconds and the parameters of coop that are in use especially in particular those that are relevant are those in section 4.8 of RFC 72-52 and it is anyway this time the time during which we need to keep the state for the RTO estimator and it\u0027s to scale with those parameters and also we have made a number of minor editorial updates throughout the document so for the next revision we have several comments let\u0027s mention before so on Scott Brown was common he has only one comment which is that the draft makes no reference to RFC 50-33 which is a document that provides guidelines for specifying new congestion control algorithms for the internet however we can arc that we have actually taken into account such guidance when designing cocoa and this light and the next one show which are the different guidelines in 1533 and which is our position on that Carlos before you go into the details on that maybe we can use of the adult supervision that the transport area has provided for us today very fair analysis here and maybe you can comment on the mic but we are doing hi I\u0027m Corey fairest aha that\u0027s good an amplified okay so I\u0027m I\u0027m coming at this just parachuting into the room so my initial response was just to provide some comments as I read through it on the five oh three three I think this guidance is mainly meant for transport protocols like the ones that are listed TCP ICT PD TCP zoom lis quick and other transport protocols the transport I see here looks a bit more like what\u0027s described in RFC 808 five in other words it\u0027s a timer based lockstep retransmission method so maybe some of these checklists do not apply and you could say this but and point number one does apply you still shouldn\u0027t impact standard transports so if there\u0027s anything that happens here that could "
  },
  {
    "startTime": "00:10:12",
    "text": "appear on the internet and could stop TCP behaving in the way it normally does then I think you have to consider that so I think you probably need some sentence that addresses this but I\u0027m not sure all of five oh three three applies thank you sure like maybe just quickly so well in 1533 there are nine guidelines and you can see for each one of them we have the lowest level ballot which indicates our position on how Coco or the design of Coco has taken them into consideration so the first is about deviations from congestion control principles the in 2019 for Team need to be motivated however we believe we have cocoa design is aligned with those congestion control principles then for guideline one we believe cocoa has no negative impact on existing protocols such as TCP although we may want to discuss something later with the second presentation in this lot then cocoa has been designed for difficult environments in terms of what 50-33 defines for this term then also a range of environments have been evaluated as has been shown before also we believe cocoa protects against congestion collapse because of the values used for the variable backup factor when retries are needed we have evaluated fairness of the new congestion control mechanism and we have found it is high especially thanks to how the variable backup factor compensates and possible potential issues in terms of fairness in some topologies then we have considered situation where there may be performance issues with misbehaving nodes we have text on that in the security consideration section and in that case when nodes may want to drop packets to decrease performance we explained that the weak estimator may help recovering from such situation also we have evaluated situations like in guideline 7 where there is some sudden event for example a number of sensors that many of them detect some event at the same time and want to communicate such detection leading to temporary congestion and we found that cocoa helps restoring normal Network State quickly and the last guideline is about incremental deployment and we believe that cocoa runs correctly in current constrained node Network scenarios and also in scenarios where a constrained node communicates with a not so constrained device possibly as cloud infrastructure for example ok so the doll from I said and initial comments or questions okay "
  },
  {
    "startTime": "00:13:19",
    "text": "so if there are no further comments on this we have some some new results that Marku hooyo is going to present she\u0027s go ahead okay do you mean Oh so this joint work with my team ilpo Eva Laura together with our chain so just an understudy that we are using is we use a varying number of IOT devices to increase the load so the congestion in the first place and we run of a constraint photonic link so the only second uplink 60 kilo bits per second traffic time little bit over 600 milliseconds so this kind of our emulates an NB IOT like environment but we don\u0027t say that is in the IOT environment so good enough to see the the effects and from the router to the fixed host we have a random delay between 103 10 and 20 milliseconds and is the fast links also it\u0027s not kind of fun affecting the so deep and affecting the air traffic in any other way on the router we have Warren Buffett sighs use water in buffer sizes for recommended PDP size to two thousand five hundred bytes kind of a small buffer and then increasing sizes for the voters and then we have the has we called infinite buffer so it\u0027s not of course infinite but is large enough so that there are there will be no packet losses with year that we give we implemented the client of serial using lip code so actually for the default course also you have 72-52 implementation we used here as it was implemented in there we added some some bug fixes but that\u0027s all coca was implemented with the product person or one as well as TF o three because we noticed that errors of change in the variable back of factor from 1 0 1 0 1 2 0 2 so he wanted to experiment that as well for the default carbon KOCO be modified to max retransmitted trend it is just to see that there are no boards for for any of the exchanges or the max retransmitted for is defined sisters could make sure that our test run put all the way to the end and we get occurred the results that are kind of a comparable 32 seconds for Kauravas "
  },
  {
    "startTime": "00:16:24",
    "text": "specified as as as specified was used for the max RTO to the default coffee we use 60 seconds so because otherwise in some cases the AB the RT or fires very high and it\u0027s it\u0027s kind of our take those tests would take very long time the implemented copper TCP has per craft 0 9 and and it equals only the necessary featured features kind of had to run the test and we use the Linux TCP but we modified that so that we don\u0027t use any of the fancy features so he uses new Reno so we disable sac cubic times have a party or all this experiment of this is TCP rock and so on more about the delay act time to be constant 200 milliseconds and then we also for the retry counts for tctv we we\u0027ve modified them to high enough so that none of the TCP connections water port okay for the workload we use a small request like request/response exchanges so that they fit into a single crop message and then we increase the load by using one client all the way up to 400 clients so this gives the kind of a increasing trend in the of workload and at the same time of course the congestion so it would put the system in a realist stress with this higher number of the of clients or client server pairs I read use two types of workloads continuous clients where those clients they exchanged 50 requests responds exchange changes and for TCP TCP connection is pre-established so the three-way handshake doesn\u0027t affect measurement so we can compare the the TCP with the other two so the default open D and then we have the random clients which emulate short-lived clients so they\u0027re each short-lived random client exchanges random number from 1 to 10 let\u0027s exchanges and then each client start immediately and it changes yet another 1 to 10 and the 50 exchanges are completely sorted so this is kind of a we can compare the results with the random and the continues playing in this sense the difference of course being there that now another system is putting all these those clients are put in more tests because the retransmission time sorry need us for each random client and the same for the TCP a TCP connection is is all communities EP connection is open for each new random client ok do the test result so here we have the results for one and ten clients so this just provide a baseline sort of full completion time so how long it does takes to complete these 50 exchanges it "
  },
  {
    "startTime": "00:19:25",
    "text": "takes something like roughly 33 seconds in all cases except BT coop or TCP with the random clients where of course because TCP needs to kind of establish a mini connection every now and then that that gives the the overhead so those DCP completion times are over 40 seconds and then if you look at the 50 clients case now the for completion times increase to about 60 seconds it is mostly because of the queuing delay so here we have more load but still not quite contrasting the late B to exception that the TCP which has a larger header it means that the less ezp packets fit in the router prefer sort of TCP has a little bit more lost things compared to their default co-op and copper which has just a few few losses in there that source India left hand side to County and should be two continuous clients the TCP has a little bit higher for completion time and then over on the right hand side because of the TCP connections are created those there is this clear difference there of course okay then 100 clients and now something starts to happen if you look at the the what now happens is that when we increase the close now another system becomes congested and with the infinite buffer or when when we increase the size of the buffer of cost more queuing delay occurs and now because of the queuing delay the RTD is increased over 2.5 seconds this means that now when we are using the initial RTO of with with default Kokua from from 2 to 3 seconds know this in easier returns of Santos retransmission timer starts to happen and Coco and DCP they handle this just fine because they adjust the time and so in the early stages they they need to retransmit a few times but then they adjust the timer run and everything is fine but with the default cop it each time when we transmit it back backs off which is fine so that\u0027s it needs to do but then for the next exchange it restores the initial timeout and does it again retransmits and again and again and if you look at the number of free transmissions we will see that for 50 exchanges it needs basically retransmit every every every request once so it does the double the work and now this is the first sign of the consistent collapse so there is no kind of a fine "
  },
  {
    "startTime": "00:22:27",
    "text": "line then we have a congestion collapse the conscious collapse is basically defined that the if we increase the load and the useful work of the system then decreases then we have signs of the congestion collapse and that\u0027s what we will see with the people of Hogan we further increase that the log so with the 200 clients if you look at the infinite buffers what happens there that happens with the with the default cop it gets slower and slower but if you look at the small buffer on the left and so it\u0027s both ball vitia it with the continues clients there you can see that the pitiful or complete sometimes there is some difference between TCP and and and default command Coco so basically they are pretty much the same but but there is much more variation with TCP and this is because TCP does the full TCP compatible back off it means that some of the clients they wait for longer they back off for a longer time while the others can proceed and and but but this is different from what happens with the default because they both Coco and before co-op they have the same problem that they restore for the next exchange do you have the retransmit time if you look at the the the number of retransmissions there is a clear difference with TCP is also small buffer 2500 fight with MIDI circled the TCP and then the default and Coco this means that now is not visible in the whole completion time because all these unnecessary retransmission or sorry too aggressive to three transmissions that default government KOCO do they are dropped in the in the router so they so then they kind of a so-called undelivered three transmissions which is a second type of a sign of the congestion collapse because these undelivered retransmit a affects the network before the bottleneck and if we have too much of tolls then we may have a congestion collapse somewhere else okay and now if we increase then the the load to the 400 clients that is the price that we are offering we will see that the default cop of course has to you still have the problem but interestingly what happens now is that the that the Kokua also starts to collapse with the continuous clients not as badly as the default call and with the random class on the right-hand side Kokua collapses as well and what is more interesting is that the diversion all three is worse than the apt and they\u0027re all one and why this happens if you look at the number of "
  },
  {
    "startTime": "00:25:27",
    "text": "retransmissions this shows up there if you look at the left hand side first the continuous clients be to infinite buffer there we have a see that that those Kokua version three has much much more retransmissions 10t version one and the but not that much as the default cop has and what happens there is that bit more than a half of the clients they are not able to adjust a timer because now the raw drip type is so high that that you are in the first round which they are not even able to get the the week sample and why they don\u0027t get we example of it to all three but to get it to over one is referenced that at the back the water go back of that was changed the original definition was that that we look at the RTO estimate and compare whether it is above three seconds then we then we use the back row factor 0.5 and if it\u0027s below 3 seconds we use the binary exponential and now what happens there for those clients that get the the sample and are able to adjust the day timers they practically use for the first retransmission they double the timer but for the next one they don\u0027t anymore while within India or one they continue a bit to initial timer using the doubling so which is more conservative this is one difference and then there is another difference and this relates to the aging so anything is defined that if there is no update to timer for four times the current RTO value then we age and it is different that if the RTO value is over three seconds as as here it is then we take the timer the returns from timeout value down towards the initial values which is exactly the wrong thing here because now our delay is increasing we should be kind of increasing the value not decreasing the value and then the third thing that affects is that the Coco is that it has two upper part of 32 seconds for the app for the timer and in this case actually especially when we are backing off our time I should be good for being or even beyond 32 seconds all right so these are the our results and it seems to me that the protocol actions are needed so with 72-52 P because we don\u0027t in play I employ a full backup that is TCP compatible so it means that we are restoring the earth the tools occurs initial RTO for the "
  },
  {
    "startTime": "00:28:29",
    "text": "next exchange this is the basic problem with default the Coco has the same with the difference of course that it is not restoring the initial audio value but the current RTO estimate and the current RTO estimate in some cases not it not enough as we as we saw and with the RTO estimate larger than three we are kind of applying these eighteen pliantly the decrease RT as as we saw in some cases this is not a good thing it is kind of a justified there in the in the in the aqua craft that that in idle P after idle period is a good thing it might be a good thing but not always so so this this calls for update as well and then also this upper point of 32 seconds for RT Otis is actually in conflict with the aircraft idft CPM RTO consideration so these of general considerations for the for the primary mechanisms that that we should use in the internet so the action suppose I think what we need is to edit here pourquoi drafted it that should be easy because we can address it and but then for the 72-52 we need needin seems things that we are needing an update so we could write a short ID that updates that should be easy thing to do it\u0027s not just a cheese maybe and for the cocoa then we should reconsider this 18 at the RTO values larger than three and as well as we should reconsider this upper part of 32,000 which actually now after the change in the in the version all three it doesn\u0027t apply in any other case anymore except when the art your value is about seven seconds roughly about seven seconds we it never reads that or it will be too much very transmittal for okay thank you so you can go back to the slide with the meter on it with one previous slide pic so just pro tip never put a thank you in a slide at the end of presentation because that\u0027s not what we are discussing okay so I would like to make several points here one about default co-op which I think we should lay dressed quickly of course we know that there is no state kept there and inquire but if you if you think this change needs to be made you will have to make it for TCP too because this appears exactly the same problem that when you easy to use that TCP know these DCP DCP backs backs off and then it doesn\u0027t restore the RTO value but it keeps the "
  },
  {
    "startTime": "00:31:29",
    "text": "exponential effect of value until you get an acknowledgement without retransmit search so when you send a news new segment and get an acknowledgement for that without retransmit only after that this disease sixty to ninety to ninety eight before it\u0027s not said if I open a new TCP connection I get new state right and that\u0027s exactly what happens with co-op here so we all we all have experienced the congestion collapse that you get when the network is not even fast enough to open the TCP connection because this B has exactly the same problem problem here now you don\u0027t because because because we see here these for the random clients TCP is open and UTC comes every now and then what happens that your ignorance and your sin you have a timer right yes and then if the delay is too much then you you retransmit bit to be tobacco factor and after a while you get to see knock right and then for the next segment you kill is higher and you won\u0027t we transmit anymore you never get there when you experience the kill I just described you will get it if you retransmitted long enough meaning that that your retries are not too long and and today what the TCP uses as a default is high enough for I would say almost all foreseen gratify environments you so you\u0027re comparing the case where TCP keeps State for the connection and curve of course does not keep its default coop is not giving any state right so what that\u0027s a prop that\u0027s the problem no yeah yes incongruous the fix for that yeah okay then Denton if we are not keeping any state then the initial RT of two seconds is way too low for your specific experiment center yes no in general that that\u0027s also there in the in the in the you repeat guidelines it says at least three seconds okay yeah okay so yeah between two and a half and three seconds difference I understand that with some of the constraint devices you do not necessarily you are not able to keep the state but that\u0027s not the whole story what what we should say there in India in in the spec is that if you if it\u0027s possible you should keep the stage and and for most devices or at least a large number of devices this should be okay today so the in the minimization that we should be thinking is the recommendation that we should be making is if you can "
  },
  {
    "startTime": "00:34:30",
    "text": "keep this state do cocoa okay fine yeah and in a polka you should do the same as the TCP doesn\u0027t apparently it does not do that right I just wanted to leave the rest is the the the suggestion that we have to change them to 52 because I don\u0027t think we have to and I think what we what we need to do it we need to reconsider at least what is the initial RTO value which is given now as a two seconds that should be religions between two and three seconds maybe two and three but still below three yes on the average 2.5 yes I\u0027m not sure that it\u0027s going to break the internet with respect to Koko I think there are a number of really useful observations here one thing is the 32 seconds that is the upper bound for the RTO in in Koko really is based on the default parameters so if you have makes retransmit of five this is exactly what you should use as your your upper body while if you have a much larger makes retransmit then you also should change you up about and that\u0027s something that we definitely missed when when defining Koko so this this should be a suitable it depends on mix retransmit so that\u0027s one important observation here the other what but but even with the current parameters the the if you have four great transmissions it goes above 32 seconds if you\u0027re in if if your RTO estimate value is more than seven seconds and in although or one version it happens also bit with this with two seconds initial arthéon yes yeah okay so maybe the the the the function that we need to define for the that is based on next reference but won\u0027t yield exactly 32 4 even for the current value of current default video of next retransmit so let\u0027s discuss that I think that at one point we can take home the other one is the aging the the point is that the the number 32 should depend on monthly transmit and that may be the number 32 also isn\u0027t right for the default value of lots of you transmit so I did follow me could you read yes so the observation is that the number 32 is the upper bound for the RTO should depend on Max retransmit and that "
  },
  {
    "startTime": "00:37:36",
    "text": "also may be the the very Oh 32 for the default value of max retransmit is not sufficient hmm okay so the other thing is the aging issue and I think that that\u0027s really interesting because your simulation is based on a situation where you essentially have continuous conditions for the whole time of the simulation now aging was not designed to handle continuous conditions but it was designed to handle bursts so if we have a burst in the network we want to go back to a relatively normal situation quickly and that the the problem with not having aging is that random losses make your your reaction it can make your reaction time very high when you don\u0027t have some form of aging so it\u0027s seeing fundamentally the the idea of aging is right and from a deployment perspective nobody in their right mind would deploy cocoa if we didn\u0027t have aging because some random losses for a quick burst would turn your implementation into a very sluggish what so we have to have some form of aging I understand the basis for that but but the message is that that in some settings like with the high delay it\u0027s it\u0027s it provides the wrong result because because if you have more to retransmits this currently that aging comes into the play and decreases the RTO value and in some cases if you\u0027re littering value is more closer to three seconds what happens is that that that your primer age before you get the week sample so with the second retransmit that is also a portion that happens in our tests as well and this is not a good thing that you first aged the value and then you get the sample and you will recalculate with this age value okay so I think we have interesting misunderstanding it aging is supposed to be used when you are idle yes that was for understanding it with oh one person and that\u0027s why we we first didn\u0027t even implement aging then we implemented but with all three it has two examples for the aging the example especially for the below one second case exactly saw that "
  },
  {
    "startTime": "00:40:36",
    "text": "that you are in you are you re transmitting it it kind of a takes their takes it takes it up and it doesn\u0027t mention anything that that it is should be used only when you are idle when when about three seconds so this it should be clarified at least in this case Oh Marie exactly what your process so doing the aging algorithm while you are still you transmitting that is that will lead to problems I agree with that so we have to clarify that yeah I either case also I think four times RT all or a high values that that probably is too short period because if you think about that that your current RT value whatever your network set up is your RTO value is about three seconds so slightly about three seconds it means that that you will age it in 12 seconds or a bit more than 12 seconds right and now it might be that your big changes are started that that they happen every 15 seconds and if you get congested you have a persistent consciousness just because of these features of the default coop it does not necessarily go away within 15 seconds so it is not necessarily good idea to age the value in such a case even though I admit that in a wireless case where you have Wireless closely this is the heart problem we don\u0027t we have had this problem with TCP and there is no solution and the best solution there is is to try to get the the the samples as often as you can and in that sense kind of a fee we example it may be a good idea but the problem is there that that you use the app you have to use this ambitious samples with retransmissions which actually give you a very high value it\u0027s better than nothing but the it\u0027s still problematic here what the problem is hard yeah I agree that this is hard and so one thing that we discussed this was aging maybe should be more tunable but of course that just throws over the problem into the core of the poor guy who has to configure everything and we know how well that works if I say that the one thing that is important so we have this performance probability with the wireless for sure yes but the congestion is the thing that we need to deal first we need to ensure that we are safe on that side and then we can do whatever modifications with to handle the other the wireless losses better that is kind of a basic guideline that we should have there right but we also have to have a protocol that\u0027s actually deployable so we we have too little information that\u0027s the whole problem and we are trying to run an estimator that does something reasonably useful and we "
  },
  {
    "startTime": "00:43:39",
    "text": "know we in a network that just doesn\u0027t give you replies you don\u0027t get enough information to actually always react in a sensible way so again I think what we need to take home here is that first of all it needs to be made very clear that aging is only used in in idle periods and I would be interesting interested to see your numbers when you actually implement it that way do you think your one numbers are representative of that so if you you implement aging the way that the authors intended which is that aging only applies when when you\u0027re idle so that is pretty much the results that where we implemented all or one without aging okay so it still has this problem with the random clients and had a high high enough world so it is that\u0027s discount but it not what a major cause for disease is this this the not retaining the fact of RT or value that\u0027s the main cost that if we fix that then then then then I think these aging and the and this upper bound of 32-second stay there they have a role there but but but we mostly fix everything if we do that then we need to reconsider whether whether some other modification and and what actually is what of those are needed your sense two major major cost right so what I saw there is this that just is because of aging like we need now implemented it it kind of takes these problems or this this process of you just a little bit earlier but finally they occur just because of if we don\u0027t retain this back of our T about this is the main main reason for the problems yeah and I think we have to look in exactly in to why that is not happening in in your situation because the the the current are gos image contains back off information and maybe we have to look into this a little bit more in detail but probably can\u0027t do this at the microphone right now yeah but thank you that this was really useful and I think it really shows that there are limits of the default co-op congestion control and there are also limits we are the parameter set that we have defined for cocoa works well and we probably want to update it based based on that information in one of the orders "
  },
  {
    "startTime": "00:46:39",
    "text": "so so one thing that wasn\u0027t on the slides but it\u0027s interesting related to this congestion collapse that actually even for this 400 clients the actual art it is on is something like 10 to 15 seconds depending on whether you have continuous or random coin so it\u0027s still clearly below this even this 32 seconds if the congestion control would work well enough so that it would prevent these collapse but now now as the consistent control causes the collapse to happen the actual art RTT rises rise is much higher so you have this unnecessary transmissions which consume some of the capacity but not only that they also increase the RTT much much beyond what it could be so so if you have just one one request reply per client which is not always possible with random clients because there is the status or okay I lost but but for continuous client you can always have this that you have just one one request reply there and with that that even with 400 clients it\u0027s slightly more than 10 seconds the actual RTT so if if we can prevent the collapse the RTT also will will be much lower lower so so this MUX RTO is not so significant any any more so so this case is not sort of pushing pushing the load beyond 32 seconds but because of the collapse there are articles that are yes every every every request was retransmitted at least four times which means that the useful work that the system must do it was less than 10 20 20 percent of the capacity can you go back to the 400 bridge I can\u0027t call okay so which one so you do have numbers for Koko version of one there which I think implementing the the aging closer to what we actually had in mind what means anything actually is implemented the same in both cases so this this Koko without aging it is just an it simply doesn\u0027t do this so in in that in that sense in these experiments it is equal to the case that if you apply aging only with idle periods okay so it never happens but as we can see with the "
  },
  {
    "startTime": "00:49:40",
    "text": "random clients with infinite poverty there is also are the same so we still have this every segment is every request is free transmitted at Li four times more or less four times all so on only 20% useful work that the system does there and if you increase the the load further to the 800 clients did then this is cause for kind of a more or less double this is so then then only 10 percent then finally there will be very little forward progress or or useful work in the system okay so the the anomaly in the left graph would be fixed by by making more clear and the document that aging is only to be used in the period and on the right side we still have a problem if we if we keep the pact of value for the next three questions and the problem should call more or less away okay so with the default curve we are not able to do that if I understood yeah but after all it is only one it\u0027s only one variable so I would say that many systems can afford it so I think we should recommend a little bit more than what you said but you don\u0027t necessarily need to do implement coop but but you can add one variable fault what maybe I should keep the timer value then you also have to add a decaying mechanism they are no oh you don\u0027t need to have any chemicals EP doesn\u0027t have that you want to say stay at the safe side that\u0027s that\u0027s all you need really anticipate starts at three again so let\u0027s let\u0027s not go into this is custom idea I know but but we need to be safely to understand first and then tend to think about the wireless losses after we have okay unfortunately time doesn\u0027t download we have a resource for the wireless case as well as for comparing these there is no chromatic there are such differences between the cases but the beam that we publish this shortly of the don\u0027t have this here right now for Carlos Gomez so I was wondering just a couple of minor details and by the way thanks for all this work it\u0027s really helpful um is it possible that when you mention zero one it is not right draft IETF core Coco zero one but instead it\u0027s draft Boorman no it\u0027s and the working group draft and yes because I think you mentioned that the behavior we implement it\u0027s right we just we\u0027re completing to implement this event event the old to draft came out so that\u0027s why we implement it that one and then we later implement it all three "
  },
  {
    "startTime": "00:52:40",
    "text": "which does not have any chases technical change in that sense [Music] okay the resourceful with the frequency of transition saying that how many retransmissions each of the exchanges that we did needed Sottero meaning that that no retransmissions 1 1/4 e trans and so on as if he used on the right-hand side in those cases the that client could fail because they because because this this exchange would be aborted and he won\u0027t get the result for that and in that sense kind of up for that client results would not be comparable with the others that so just to make them comparable we had this and as we can see that there is there are some retransmit of beyond for for retransmissions it is something less than in all cases less than 5 percent of the cases so this is also a question that we could raise that that if the Marx retransmit of 4 is the best value whether it should be a little bit higher or alternatively should be kind of fun actually use tobacco factor such that it depends on the maximum retransmits if the lower number of free drugs will be all all then we should use kind of a higher back of factor to ensure that we can get all the transfer kind of get yet get rid of the the the the conscious tone during the period that we have well but yeah this is just another discussion maybe not got something to discuss right now here you have a and so so if if we wouldn\u0027t have not changed it marks at "
  },
  {
    "startTime": "00:55:41",
    "text": "least as we would have this offer at load as would have varied depending on how many of those clients fail fail so because of that we couldn\u0027t have compared those cases so well because this these are sort of random effects one of the clients might might my to more more of the bat of Stan some some other so so the number of clients which are able to complete successfully would have worried if he would have not increased this much retransmit so this is just to make that test test to be useful useful of course it would be possible to run run with these packs we transmit four four four and then some some of them fail but and then you have this issue that that they offered world would have not been the same between different congestion controls so so it\u0027s harder than then comparator for completion times and whatever I I think I understand this reason but anyway I think it might also be interesting to to run the evolutions also for max retransmits that for it wouldn\u0027t change the final outcome cause it\u0027s just a setup that PFP are running a certain number of clients I had these fifty exchanges he could have the exactly the same load with with larger number of clients that are maybe exchanging every ten seconds or whatever it\u0027s just a bit based on what is that no amount of offer at all so how many clients you have you have you will have it exactly the same result it doesn\u0027t matter kind of find that sense yes we have about three minutes left for the topic so Gauri if you want to give you impression Gauri first I just like to kind of come back at the end and first of all I found that Miss Christian really really helpful and when I point to Scott Bradley\u0027s document and I talked about DCP I\u0027m talking about it fluor TCP flows you shouldn\u0027t directly compare one TCP syn with one other packet so you need to talk about it in this way talk about the effect of congestion collapse in the network so congestion collapse is more important I think than performance for the network in doing that I have some concerns which I think you should look at which is this idle time I don\u0027t think you can reset RT t without really seriously considering that in the presence of failures so what I think we talked about that but I I think that has to be talked about more either has to be really discussed in the draft or you have to address the issue and if you then expand the back off appropriately I think you can have a document that actually satisfies the congestion collapse conditions so please continue to work please think on this topic "
  },
  {
    "startTime": "00:58:42",
    "text": "because I think most the documents okay but this particular bit does need more work thank you since you have a bit of time it\u0027s not quite three minutes one minute yes good Zack Shelby from armed um Mattias and I did some work years ago on coop at scale and one thing that concerns me is that our we do we have the right use case in mind here when we\u0027re doing measurements and research around the scenario were worried about and what I see happening in the industry right now is coops being used in quite a centralized way yes we have some kind of local communication and Gateway things over wireless happening but actually we have very large cloud providers and operators collecting data from hundreds of thousands and now scaling into millions of devices into centralized cloud platforms so this is big data data collection in practice how do you guys in your in your simulation work looking at congestion control looked at that kind of scenario one server communicating with very large numbers of low performance you know low bandwidth devices but there\u0027s just lots of them right so basically as a know now it depends on variable domain ease so how your server commonly or your pack and communicates with all these devices so what is there is how many parts there are how many routers there are all what matter is is the bottleneck where the bottleneck is and what is to offer cloud over that particular permit and that\u0027s what we are emulating here we can for the con system control point of view we can kind of make the system more simpler to test how to consistent gonna actually works just to have the photonic or in some cases more than one Potomac and then then you offer the certain amount of load there and that\u0027s it simple as that okay I think I think for that we probably need to do a little brainstorming with um some of the operators in the room some of the LP land providers like where these bottlenecks might be showing up where he might have fairness problems with TCP traffic like but I can\u0027t answer that off the top of my head what where those might be but just to make sure that what we\u0027re doing is real from from an industry perspective thank you so we essentially consumed most of the sector "
  },
  {
    "startTime": "01:01:43",
    "text": "we have we had gained on Monday so the next one on the agenda is Gary you with a few oil okay so I\u0027m here to give a short update on this draft and also have a couple requests and and questions for you guys to try and answer so I mean just to set the stage in case you haven\u0027t been in the room before when this being discussed debut our ends are our namespace for hardware device identifiers we support MAC addresses eui-64 addresses 1-wire addresses and also sort of a free-form organizational device identifier if anybody has those at the bottom there\u0027s one example your dev Mac something something pretty simple and just before the deadline I posted a zero zero for the working group version of this this draft and then earlier this week published zero one version the zero zero basically was just a copy of the old draft but but some typos was fixed in there in the a BNF and and then zero one actually updated the you are and registration template because they\u0027ve updated that to where there\u0027s new RFC RC 81 41 I think it says what how to register you are ends from now on or from that point onwards and we\u0027ve updated that and that that sort of textual affair lots change and also had answer more questions than then I had answered before and that\u0027s that\u0027s the usual year a good thing that you I mean that the new template actually forces you think through more cases than than the old one so you\u0027ll see some of the findings actually there so I have a couple requests and questions one is that can people read the new template they disappeared on Monday so I appreciate feedback it\u0027s new text so take a look at that and also given that there was a few more questions to answer there were some that I didn\u0027t actually know how to answer and one of them is that the new template asks us to specify how the particular u RN type deals with Q R or F components in you are and then you are ends and I wasn\u0027t really sure about this so for the moment that is fraught that they\u0027re not used I\u0027m not quite sure if that\u0027s the right answer it would appreciate feedback and that so so that\u0027s sort of the basic of of this this "
  },
  {
    "startTime": "01:04:45",
    "text": "you are in typed in there\u0027s two classes or two items of another type that I\u0027m or we\u0027re wondering about and those relate to possibly adding new new branches under under the dev URM so the first one is something that we had discussed briefly in in previous slides if I think adding device ID specified in 1m 2m and light weight m2m groups and and I think we just basically agreed that would be a sensible thing to do if that\u0027s what would you still think and that\u0027s great but since I\u0027m not personally working in those groups maybe there would be somebody who\u0027d be kind enough to send me some text that we should actually add because we actually have to specify the syntax in in detail and then the there was a discussion mattias cots and I see myself discussed a little bit during the hackathon about possibly adding web of things identify side-effects and schemes that he\u0027s developing and this sort of would seem to possibly fall under the Devi Warren\u0027s but could also be separate thing I remember the Devi Warren\u0027s are not the only way of identifying devices you can still use uu IDs you can still use you know regular URL C then and and so on and so forth so Orry main on person support so the viewers that sort of the catch-all of the you know things that we missed or I have not defined before we can add more but we can also do separate and in in this web of things scheme I think the it would seem at least that that that\u0027s that\u0027s the thing where you have to define the salient the next step is to define the semantics of that house how they get allocated underneath this this high-level branch of the tree and then go from there I am great recommended that\u0027s probably a separate draft so that\u0027s it really so you know feedback on the template answer to my question on the different components that could or could not be used in in the URL and then what to do about this additional things I think material approach is that if I don\u0027t get text or you know clarity on on some additional thing then my inclination would be to publish the try and publish that the RFC because you can always possible to add more branches to under the viewer and later also so that\u0027s it looking feedback can you write me is UUID already one of types I\u0027m sorry I didn\u0027t quite sure he so my name is Dave Sierra the question "
  },
  {
    "startTime": "01:07:47",
    "text": "is can you remind me is UUID already one of the types no that that\u0027s a separate you are in tight you just use the UUID : or whatever instead of a you are n : right and that\u0027s why it\u0027s out of there yeah yeah so so my point was that there\u0027s other you are n types that you can also use to identify scheme yeah so there\u0027s you are n in the general sense there\u0027s you are running the scheme name sense yeah hi I\u0027m Badou from Nokia so this third bullet about decision and text unclear like what is expected from lightweight him to him but what we have done is I believe with 1.1 release right now what we are working in OMA we assume the you are ends and URLs are basically I understand it\u0027s all under uri so lightweight m2m could do a uri meaning anything under the sub set can be a device ID that\u0027s what we have update updated it\u0027s still wrapped so it\u0027s unclear like how to handle it okay so I I\u0027m not very well aware of the details of what you guys are doing so that might be a you know maybe you\u0027re offline thing for us to look into I would fully understand what\u0027s going on there and and maybe it\u0027s the case that we don\u0027t need to do anything I\u0027m just basically standing here saying that if you if anybody has a burning need to add things these urin types that not would be a good time to say yes please add and then give me text otherwise we\u0027ll move ahead I don\u0027t see a lot of screaming or requests or more answers so thank you very much for the update so in the meanwhile the next one I believe he\u0027s the this one is done is a second haven\u0027t seen hasn\u0027t seen the presentation on resource directory yesterday my name is custard answers and I will present be presenting the latest state of the echo and request tag the Lyon request tech document that young john and i am working on so i\u0027m just brief context what this does is address provide solutions to some "
  },
  {
    "startTime": "01:10:47",
    "text": "to some security issues that were found with with basic co-op mechanisms and the and the DTLS bindings that also show up another security repres what happens if if packages get get delayed for only a long time by anniversary and this document provides some salute some solutions to that there is in parallel to it document that that outlines all the attacks that is being updated constantly but this should be concise and and provide everything that\u0027s needed for example for a score to to solve those issues and to also solve those issues with with other security bindings so what happens since since the last meeting is that token processing was added this would now update RFC seven to five to because the as dps tokens were described to work over I would ETLs those could result in responses being matched to requests that they don\u0027t belong to so this is one of the updates that the second update is that the the whole echo section was a bit shuffled around to be a little more easily and the third part is that the request tech option which originally had quite a bit of tips on how this interacts with lock wise and assembly of options can be much easier provided that the understanding that we\u0027ve come to develop of how block wise is intended to work is correct now we\u0027ve discussed this with various people in the working group already during the during of the last few days and it probably that understanding is probably correct and that means that the option is just what has been suggested in RFC 7 9 5 9 as if you want to do kind of sort of simultaneous block-wise operations just add an option that is safe to forward and part of the cache key now request tag will be exactly that option and it won\u0027t need any normative text on how it is used server-side because this is just how it can work with lockwise anyway and the text we were having there is how do you apply this in if you\u0027re a client and it matters to you that your blocks aren\u0027t shuffle around this in the in the current draft version this is only being hinted at because it as I said it is in under active development and there will be an updated version roughly at the end of the week or shortly after that which "
  },
  {
    "startTime": "01:13:47",
    "text": "will be a bit shorter and if you if you have anything if you have any opinion of whether they will this can work that way by saying that block wise operates on cache key data and if it\u0027s part of the cache key the the blocks are safe if you have any opinion on that please voice it now because the results of this will probably go also into into likely the implementation guide cannons and basically um clarify what was intended with our C seven nine five nine if someone has divergent opinions of that place after them because otherwise we will proceed on with working on that the normative part will be this option there is no semantics will largely be to the server this option has no semantics yeah and of course we would still want to keep the informative part why we\u0027re defining this thing and also it\u0027s a probably good idea to have a common understanding in the community which option you use for sending something that doesn\u0027t have any semantics because you want to to keep the block requests together so I think it\u0027s just anything outer moving over some materials not really actually a big change but as soon as that new version is at I had asked you to review it so it can proceed easily because it\u0027s basically just fixing stuff that is already well I\u0027m sorry can we see a few hands of people who would like to review this Jim Klassen I can\u0027t see you Julian Francesca Michael okay that should be enough icon so I think that the timeline of this should be we shouldn\u0027t be sitting for too long on it because it solves some some real problems so yeah next version reviews window glass call ship it thank you so we are back to our favorite item we started that discussion yesterday afternoon and we still have to finish the discussion and I thought my discussion contribution here on this slide and and everybody has had a chance to think about the pending issue during the last 20 hours or so so I would love to hear other views on this subject how "
  },
  {
    "startTime": "01:16:47",
    "text": "should we handle this in general and how do we handle specifically the pending requirement that comes from the est document so anybody have an opinion on this one person is getting up one person is leaving the room no was a long way mattias covered siemens so what I see from the two proposals are two different strategies one is to handle it explicitly as part of the states of the state machine and the other one is basically the mechanics of the state machine that we want to define so the proposal having a new response codes and so on this is more on a mental level so there it\u0027s basically some basic implementation that has to deal with that you do not have to think about it in your application there may be proposal is more okay you have to design your applications following this state machine thoughts kind of the hypermedia way how to do this and have it explicit in your application so a question is are all applications yeah recommended to follow this approach of course it\u0027s something you would like to see but maybe goes a bit too far if we kind of make them all do this and use the media types as they should be if you have a lot of proposals yet that use coop in a more simple way that use what is defined there and they don\u0027t put so much thought into how to design a hyper media driven application meaning these thinking about what are the states of the state machine and so on what is the right media type to use and and so on I think in particular for this pops up draft a nicer solution for that would be to have it in on the meta level so meaning the new response code because pops up yeah people who we want to adapt that bond think in this hyper media terms so these are my thoughts on this so it\u0027s I see it\u0027s it\u0027s two different strategies how to solve this one is on the meta level having it how state machines can be defined using coop and the other one is okay you have to model this with the means coop gives you directly in the state machine of your application that would be the the may be version or proposal yes but no what position do you take on this so I don\u0027t have a strong one as I said so it depends on the applications on the one hand side it would be nice if more applications would follow the hypermedia driven approach would be good to have "
  },
  {
    "startTime": "01:19:49",
    "text": "something there but then if I look at the case of pops up where we want to have people at least move let\u0027s say from mqtt to to co-op pops up where we have some more metadata on what is the content sent around we have more features for interoperability and then let\u0027s make it easy for them and then I think this response code solution is a nicer one there are cases for both that that\u0027s kind of the main message so so I see both solutions they are valid but it\u0027s two different domains where they are valid and so I haven\u0027t thought a lot about the ESD use case but I think they had a similar case it\u0027s it\u0027s not people designing hyper media driven applications but it\u0027s they\u0027re using the coop protocol and they look ok what are the mechanics of this protocol and how does it met to my problem and so it\u0027s I think the same bin is this pops up yeah where they\u0027ve just want to have some mechanics on the metal level of the protocol and define what it needs to be done Peter fan of stock because it\u0027s my turn I think to say actually I agree completely with Matias about if you have a response code it is a more general nature than when you use the media format the media format actually is for an ex-client which talks to a server and they are part of one application so they know about what things are going and there\u0027s no need to export all this knowledge about what the media format means well in the other case when you don\u0027t have a more general service well you have the response code I think it can be used also the other applications you should like to try a response code I understand that there are problems because there may be proxies which do not understand it and do who the values Achebe\u0027s and on the other side it might be that he have a client who gets a response back who doesn\u0027t understand it I think that it depends very much on the type of a response code that you do and the kind of consequences which are passed to this return it should actually help the working group decide if Irma likes to keep this response code and introduce it or not yep you can transfer to this or can i okay Alexandre proof so I\u0027d like to see like a one use case or an application that will say no how does this map and why do we do this so it seems to me like it\u0027s a pretty meta approach and like yes we could do it and yes but what it will serve for like one specific use case you want to see okay well we solve this problem and and then we can say yes it\u0027s interesting or or maybe not Michael Koster smartthings excuse my voice I yeah I agree with the "
  },
  {
    "startTime": "01:22:52",
    "text": "the idea that this is more application oriented and the idea of a response code status code is more transfer layer so you know pub/sub I agree that pub/sub just transfers representation so we really probably can\u0027t try to synthesize media types in pub/sub in terms of the other use case they don\u0027t have much to say but I think I\u0027d like to see a little more discussion on what\u0027s wrong with response codes okay customer from the floor I\u0027m a computer scientist and I think good computer scientists are fundamentally lazy so applying this principle here should we have this kind of discussion each time somebody comes up with an application if we can come up with a couple of response codes that we really think add something to the ecosystem in a general sense I would be really happy to embrace them but the the to response codes that the two applications that have been discussed here so far those are just specific things and we do believe we shall guide application developers to defining media types for their application states so yeah on one hand I agree with my peers maybe to the level of saying yes there is a decision to be made but I would prefer to only have response codes for things that actually are somewhat Universal now to the question what\u0027s bad about a response code that\u0027s in general and nothing is bad about a response code so for instance we can add four eggs eggs and five xx response code as soon as we understand what we\u0027re trying to do and and we will do that for too many messages a success response code has a bit more baggage to it because we are assuming that the the co-op layer knows how to handle this response code so things like like proxies but also the the coop layers the caching layer in a client implementation has to know about the response code and what I really don\u0027t want to get is a situation in which somebody cannot get the application going because their co-op layer they call it library or the the "
  },
  {
    "startTime": "01:25:54",
    "text": "proxy that they are using hasn\u0027t defined that response code yet so that\u0027s really a bad situation where to make a deployment you actually have multiple entities to agree that it\u0027s a good idea to do that deployment we generally try to avoid that so that\u0027s why I generally think we should guide application developers to words solving this with the means that co-op has already available and and one of these means is media hubs now on the general question of having a resource and that resource isn\u0027t currently quite in a state to provide useful information I think one property of this situation is that the the application probably wants to say something about the characteristics of this state of not yet having useful information so in some cases it may want to say come here again in 30 minutes in some cases it may want to say Oh nobody has submitted anything to this topic yet but here\u0027s a default value and so on so this is a fundamentally application-specific and calls for an application specific media type already so I don\u0027t think it\u0027s a lot of onus on an application developer to to develop that media type and the final observation one problem we ran into when looking at the pub/sub case is that observe currently requires all the notifications in a stream of responses to have the same content format that may have been a mistake so yeah maybe we want to fix that mistake but maybe people don\u0027t agree it\u0027s a mistake so I\u0027m interested as a cue you didn\u0027t have or that was already okay yes oh so I came a bit late to this discussion so so I discussed a bit during the hackathon what is the issue there so for the pop stop use case it is exactly what custom just mentioned to me yeah at first glance it feels like okay this is kind of a strong correction of our changed in the observe RFC maybe then having something more drastic let\u0027s say like a response code that can fix that might be the right direction because there were some thoughts why it should be the same media content format "
  },
  {
    "startTime": "01:28:57",
    "text": "during an observation I think that\u0027s that\u0027s something you should think about so that the main point is it\u0027s connected to a lot of other decisions that that have been made and now that more and more applications pop up we actually get more evidence what would have been maybe that the right decision with response codes it\u0027s a bit similar to to the the methods so we we originally stuck to to a minimal set then it turned out yeah actually these additional methods a good idea they have optimizing their days source particular use cases especially if you look at fetch and for the response code so for instance there\u0027s also still this gap what if you just want to say yes this was processed correctly the resource state didn\u0027t change so it\u0027s not a change there\u0027s no content to return there\u0027s also still a gap and it\u0027s it\u0027s like the workarounds that we had let\u0027s say in HTTP when there was no fetch method to to send a post and everything was a bit yeah sloppy let\u0027s say because they are there was a gap in the specification so I think with the evidence that we have maybe we can collect more of these use cases where everyone has a problem to pick the right solution from from the their RFC\u0027s and and think rethink what are the response codes that that we need so again it\u0027s it\u0027s a it\u0027s connected to many issues actually so it\u0027s not really okay but do we need to solve this EST or this particular pop sub problem but maunder the overall design space so the the way that you describe meant yes the the new response code actually would have semantics that are quite similar to 205 except that the the what you get back is not the content but some some meta information about that content it\u0027s it\u0027s so so this isn\u0027t fully figured out so it\u0027s a I started thinking about this during the hackathon so the the the one thing about this response code in question here it tells you okay there\u0027s this resource everything is fine but there is no content so it\u0027s kind of this HTTP 200 for no content and something similar was missing in these cases where you sent opposed to to process something and you don\u0027t change resource state there\u0027s also kind of no content to deliver it but that is more like a 200 ok a generic okay I process this correctly and maybe the to zero zero is too generic for for saying that maybe it\u0027s the same thing that we need it\u0027s some two something something no content that would feel soft to these two issues the two or for the HTTP two of who actually has even though it\u0027s described "
  },
  {
    "startTime": "01:31:57",
    "text": "as no content has a slightly different semantics which is the previous content you already got for this is still valid and you don\u0027t have to update it it\u0027s really weird that this thing is called no content so I\u0027m not sure we can draw a parallel to HTTP here but maybe that\u0027s one question that we should try to decide for this this new response code what what does it mean about the actual content behind that resource that may already be cached such that replaced or is it still valid like in the HTTP to or for case at just an observer observation here so the tool for I think was also returned if you change something because HTTP doesn\u0027t have to explicit changed response code and so on so this is originally already this this problem okay I don\u0027t really have the right thing to pick from there\u0027s the general confusion from from the name of the response code to the actual semantics and we I think are stuck in the same problem here but with the expectation that coop is for machine to machine so we have to be way more explicit about all this yeah so I would propose that we define a new response code not what you wanted and that is used for for representations that come back that are not what was originally requested but that how somehow are useful in the application to make progress in successful yes successful not what you wanted not cacheable I think that\u0027s a significant observation you and may have a different content form it keeps the observation alive Michael Koster smartthings yeah on further reading the 204 does an HTTP does instruct the client to use the previous value so that would not be appropriate for the pub/sub case the same semantics we do need something a little different the I believe the other one was more analogous to 202 accepted which says something like I might process this later or I might not he and I to or to accepted as used in some IOT api\u0027s for ghosts go go deal with this some other way like for example one one API uses that to indicate that you\u0027re supposed to go get your asynchronous notifications somewhere else so you do an HTTP thing that says hey like I want "
  },
  {
    "startTime": "01:34:59",
    "text": "to observe but it says it gives you back a 202 and it says here\u0027s where you go observe this thing that\u0027s that\u0027s it\u0027s not a redirect but it\u0027s a I processing this but yeah you have to get your answer somewhere else I\u0027m gonna sure if that\u0027s exactly what computers use cases either but I think what what you said is I kind of agree with that that\u0027s really what the semantics of what we want to say for pub/sub is it\u0027s not what you wanted in a general case so doing that would cover pub 7 as well as maybe some other general cases article on Erickson I think we need a response code but maybe the one who suggests is something generic ok yeah here\u0027s more information how to go forward maybe that is actually the right solution here so instead of having three new success coach of having one that is relatively future proof I think that would be solving the pub sub case and most like the SDKs - so I would think make sense to explore that so I think what Michael just said is interesting there are cases out there that we could look at and particular ot cases out there and maybe we should spend a couple of days of collecting these cases so if you have a pointer to the API so other people can can look at that as well that would be useful thing to take to the list so for once I think take to the list is exactly the right thing but we have a couple of days at this ITF so we can continue discussing this but it seems to me we are kind of converging on something great so let\u0027s jump into pops-up itself yeah yep okay I\u0027m gonna just go through all three of these since they\u0027re all in order I just made one set of slides for the whole thing pub/sub we did not as get as much work as we hoped done but we made some incremental progress you can look at this screening folder oh thanks so what we want to do is split out these response codes into separate drafts so that that there\u0027s no dependency or impact and we\u0027re going to need to reach both or we\u0027re creating a dependency but we don\u0027t want them internal in the draft we want them to be as as Carson said general purpose for you know for everyone to use so we like to just refer to those whatever the note content one that\u0027s the TBD too many requests seems to be less controversial so that shouldn\u0027t be a problem now that we have a really clear idea of how observant groups and multicast and different sort of security considerations are at least a better idea than we had a year ago we\u0027re ready "
  },
  {
    "startTime": "01:38:00",
    "text": "to put some specific stuff into the security considerations for OS core and there are some more issues and comments that we need to address it\u0027s a really good issues really some sort of unspecified cases like we have a hub sub resource that\u0027s a resource type that works sort of like the Rd resource type does where you that\u0027s where you sort of access the functions and queries and stuff and question is do all the topics sort of show up under that in the tree or do they sort of are they able to be sort of created just anywhere conditional notification it seems like conditional notification and pub/sub or two patterns that really need to be used together even though we don\u0027t really have the numeric stuff we have P min and P max that would be really good for controlling you know the flow of data a proactive way instead of depending on four to nine when things go wrong so we\u0027d like to look at that and also dine link just to be able to use dynamic with pubs up how do you use that with a broker do we create a binding table on the broker or do we have a way of putting linked findings with associating with topics in the tree so that needs to be that needs to be work and also there are some questions around how topic discoveries work with topic trees when you create things with a number of levels all at once are there intermediate nodes created and we need to be clear about that and there may be a couple of other small issues but I think this is the flavor of what\u0027s left to kneel down before before we\u0027re done so that bit of work left to be done we\u0027d like to schedule an interim meeting so that we can be ready for last call by the next IETF it\u0027s basically how we\u0027d like to proceed so sort of do a one big final course sort of the way we did with Rd to just get everything in and get it done before then as a deadline for IETF one or two now that raises an interesting question we have been using but you\u0027re in terms in the corporate group a lot previously but not recently and we may want to get back into the habit of having some now what would be the right time for an interim meeting that finishes what\u0027s up that\u0027s a good question it kind of feels like it like next month sometime or April or May right are you sure that you can do this in one month well maybe so when is it well the IETF is July yeah so okay deej in the mid the mid point would be sometime in May right that\u0027s and we also could go for two interim meetings and then one would be early May and June "
  },
  {
    "startTime": "01:41:00",
    "text": "or something like that at this point it doesn\u0027t feel like we have that much worry yeah but I could be surprised okay so we don\u0027t have to do the scheduling no but maybe we can take on that we want to have something in prove me it\u0027s an interim meeting these for this and maybe for a few other things like I think maybe even as with some of the others too that we want to continue to wake and earlier is probably better because we really kind of have an idea of the scope now but if we get some more working group review and some more comments the scope may get larger so please if anyone really cares now\u0027s the time to do the review so who has a red version of the pub/sub document almost twenty hands and who is willing to contribute a review of the document Jim I see a hand but I can\u0027t see the person behind that Thank You Chester and two for truth better than nothing are you thinking discussion yes okay great Michael before we go forward if we have time it would be good to discuss the point like by the way this sorry Carolyn discussed the point where do we want our topic trees trees land do we always want to have under the API resource or would we like to have it\u0027ll be anywhere so that\u0027s that first bullet over here yeah I can see arguments either way we couldn\u0027t really conclude like what is the right way to go here or does anyone even care is this something green we need to prescribe given that it\u0027s all linked together in the in the perhaps a broker anyway no there\u0027s a link to everything and you know it\u0027s there\u0027s no it doesn\u0027t really break anything so the leaning toward yeah you can put starts with slash URI if you want or you can put a relative URI when you create a topic and it\u0027ll do the right thing because those are all well-known errands so then the broker would just deny requests that are not compatible or whatever what is its use I think that\u0027s one way we can describe it if we don\u0027t have want to have any normative text on the drafts on that anyway that\u0027s okay well we\u0027ll need to add description of what happens it\u0027s an ambiguous right now okay other questions comments so um I\u0027m "
  },
  {
    "startTime": "01:44:07",
    "text": "gonna talk about interfaces in dine link now which which are also pretty close in our opinion so the interface is draft is really just informational we define some some link attributes if\u0027 and it interfaces draft basically as some high-level guidance about what this eye off attribute is about and you can use it to say this thing is the sensor this thing\u0027s an actuator this thing is a collection that has stuff in it it\u0027s basically an application layer tag that\u0027s that tells you how to process the resource so originally other stos noted notably osya for using interface and there examples are a lot different from ours there was an idea that we would try to show at OS ocf is doing in our draft but i think we\u0027ve decided not to do that and to keep with our original examples at least that\u0027s what we proposed you can go look at the ocf spec if you want to see how ocf uses interfaces and I don\u0027t really see a lot of value in duplicating all that in our IETF spec it won\u0027t be normative maybe maybe we if it\u0027s really if people feel strongly about it we could bring in a couple of examples but we should show different ways of doing it if anything and not not try to imply that there\u0027s only one way to use the interfaces target attribute look what\u0027s happening someone coming to the mic on mediate Oh No all right so that might be a little controversial but that\u0027s done in the and in a reason to simplify things and also we\u0027re going to use CIN ml so it\u0027s sort of like the examples are going to be more sentimental examples that show content that\u0027s according to another IETF draft which seems to be a little more consistent than bringing in stuff from an external sto and we have some remaining issues to close but not too much so we want to do the same thing here and address all those comments and issues before the next and prepare for working good last call you know we may or may not be prepared by then but we want to prepare for that at IETF one or two so you want to prepare at IU TF what a tool do you want to have the last code we won\u0027t have the last call at I e TF 102 yes but we want to be prepared to do that I guess okay yes I guess it\u0027s just a little a little less certain that we\u0027ll have everything done versus pub/sub where we really sort of feel like we need to tie it up but that\u0027s because that you know I guess we were just not quite sure about the state of that draft relative to the other ones right instead am i representing this correctly bill is Bill silver Rajan has been doing a lot of the work on this draft lately and but we\u0027re we\u0027re all "
  },
  {
    "startTime": "01:47:08",
    "text": "pulling together here okay so dine link don\u0027t link is a little more going on with it but probably a little less work to do we really kind of understand the scope of how we want to finish dine link there are two components in the dining draft there\u0027s dynamic links that define it sort of uses a link to define an asynchronous data transfer from one resource to another so when when this thing generates something that needs to be updated then it causes the transfer to happen the other thing in the draft is conditional notification parameters which basically we call them observe attributes in some other areas and and basically they they control the notification behavior so it\u0027s sort of the timing and how much the value needs to change and and things like that know that the conditional notification parameters could be included in the dynamic link so that\u0027s really one way to use them you put them in the dynamic link and that that defines the the parameters of the notification Lakes out how how frequently and how much change they can also be applied to a resource instance and be stored in a resource instance along with the resource to have sort of a global notification behavior for that resource and they can also be the third way that we\u0027ve looked at is uh applied to an observation instance - I guess I lost the rest of the sentence but basically each observe can have its own set of parameters as well that you plug in with query parameters on the get so we want to make sure we define all those three ways of using parameters really clearly I think it\u0027s probably already there but mainly we want to put the draft into two sections have the dynamic links in one section than the observed parameters in the other and then there\u0027s the thing about a binding table which is how you might organize things on a server but they don\u0027t all have to be organized that way so that\u0027s optional so we kind of know what we want to do with it we have one thing that we\u0027re adding and that is another notification attribute we\u0027ve looked at a lot of different notification attributes to have a lot of different you know tunable behavior and what-have-you and the one that seemed to really stand out as being consistently you know people say why didn\u0027t you do it this way is to have the notification happen within a certain signal range value range and not when you\u0027re outside of that value range and this was a really popular this is uh mmm in working with lightweight m2m originally a lot of the folks thought that that\u0027s what LT + GT were for was to say you can only notify when you\u0027re between LT and GT or or outside limits or whatever you know they want they wanted to have the endpoint be quiet when nothing was happening and only do notification "
  },
  {
    "startTime": "01:50:09",
    "text": "when something unusual is happening so we\u0027re adding the band attribute to modify the behavior of LT and GT to be this notify within band so if you use LT and GT in that band has a boolean flag then you get the SPECIAL behavior on those if you don\u0027t you just get notifications when LT and GT are crossed as a limit sort of a crossing limit behavior and then finally we decided not to rename LT even though resourcedirectory uses LT as lifetime we don\u0027t see any significant conflict there so we\u0027d like to keep this as LT and take care can you clarify when you\u0027re actually using it as a band pass can you say only notify when you\u0027re outside the race yes you just make L T greater than GT okay so you allow both yeah within this and band exclusive and exclusive is maybe the usual case yeah because your example there with the and there implies that it\u0027s only when it\u0027s in between the two right instead of on the two extremes right and so greater than GT and less than is silent in the normal range and be signaled only when it\u0027s outside normal range then that\u0027s actually the opposite of that example right so you\u0027re saying I\u0027ll both that\u0027s right GT is normally the lower one if you want in band when GT is the upper one if you want out a bit right so whether it\u0027s an Andrew and or depends on whether GT or LT values are higher versus lower right that\u0027s how you switch exactly that\u0027s and we\u0027ll we\u0027ll clarify that in the in the draft well we probably need some examples there to show some ASCII art that I signed up to create a little ASCII art to illustrate those and on the roadmap the last changes are scope we want to you know do these through these three things security considerations we didn\u0027t really talk a lot about that but when you have a dynamic link there\u0027s sort of an implication that there\u0027s some client functionality there that has to process the link to do the output you know to generate a transaction and that has a lot of security implications like was doing and what\u0027s the subject if you have a CLS where does you know so I think it\u0027s out of scope for the draft but it\u0027s definitely means to be brought up as a security consideration and needs to be resolved in any real system that uses these right and we want to also have working group last call it the next IETF so I say prepare but it means prepare to have everything ready so that we can ask for last call if that seems to make sense good so I forgot to ask the question for interfaces but I\u0027m going to ask it for downlink first who has read a recent version of the dime link document Christiaan and one hand behind callus I "
  },
  {
    "startTime": "01:53:13",
    "text": "think modern and who would be willing to contribute a review Christian and Christian okay and and Ari thank you and on the subject of the interfaces document who has read recent version Christian and zag so he probably should reserve the first row for Christian because he has read all the raft and and who would be willing to have it contribute a review of interfaces just yawn it\u0027s always a bit harder to get people to review information a document so we know that but it\u0027s probably still worth finishing this work okay I think next bill [Music] okay yeah all right so we\u0027ll start with protocol negotiation fist so there are two two drafts right now that that are separated for alternative transports one one is for describing where the transport information should be residing the URI and the other one is for discovering alternative transport endpoints so protocol negotiation is about about doing the second part bit of context so the the document aims at talking about notes that have multiple transports and then they wish to allow for every question response to use some or all of these transports so we started with thinking only about other server models but then recent discussions also showed that that per resource models are useful and then also the the drive evolve so initially we went with the core result directory only model and then right now we also have a model where you can directly query the origin servers for the available transports okay current status so in be on drugs 0-8 we did not introduce anything new we clarified some of the parameters based on reviews that we received and also thanks to Christian for doing good work on the resource directory so from that we were able to do a lot more we have the DOL other locations attribute that allows multiple base you arise and to align it with the way ocf does it and then we have the eighty and TT parameters which are also repeatable that you do the same thing with the "
  },
  {
    "startTime": "01:56:13",
    "text": "resource directory so there was a request to provide more complex examples and that was incorporated with the current draft and then there\u0027s some example usage that was updated with the way resource directory structure right now that\u0027s basically it so next steps we have are so one thing that I omitted in this slide is basically that we we have a huge section that we need to consider for security security consideration space a really important part in this area so something that I\u0027ve neglected putting the slides but anyway we\u0027re still looking to see if there are other mechanisms that we can use in terms of the in terms of allowing the clients of a discovery faltering transports and always looking and seeing some of the suggestions actually came from the courier discussions that we had and some came from the from the the reviews and these were some methods that we think we were going forward we\u0027ll try to evaluate them and see if there are any of them have any any viable ways of doing that so for example using using music fetch to provide a payload when you do a request and then retrieving the list of transferring points or then using a well known location for cycloid metadata or then doing what we do in deine links with the writing-table entry so in that sense that basically we can just use a resource of resource collection in them try to add or delete web links that tell what the locations of the of the endpoints are that\u0027s it I think okay so who has read a recent version of this document Christian has no surprise yeah I think a few other people have but I\u0027m afraid to put up there because they I might ask them to put in a review so I think these two documents there are currently two separate documents but maybe we want to revisit that at some point so maybe we can go into the other document quickly and then there\u0027s this someone the other documents even easier since this this work this is currently my opinion it\u0027s completed so we need just a it\u0027s actually from the point of view of language and to him since we have now multiple transport say I believe the protocol negotiation one could be also useful we are finishing one to one maybe on one or two it could be something discussed I don\u0027t know what pad or sack or harness eg he\u0027s in the room would think but it sounds like a useful feature yeah I\u0027ll be happy to get some text to look at examples of how ocf for "
  },
  {
    "startTime": "01:59:14",
    "text": "me okay so coming back to the second slide set alternate transports was originally we look at the word to see and this was this was at the point when we had not yet done RFC a three to three and and there were jobs emerging looking at our core was being used other or other transports than UDP so we wanted to figure out how if you if you wish to if you wish to expose the transfer endpoint in the URI how do you do it so that the work of the work took a while and and we discovered that when you look at all the URI components you can\u0027t put it in the query the part of the authority and certainly not the fragment and with the requirements that we had it the only place that left to do that was in the URI scheme so the draft basically just crystallizes that point tells you the design decisions that drove the decision that currently is being used by RFC a tree to tree to the core TCP and WebSockets information in the URI scheme so the the current current drop 11 is just a small Delta yeah that\u0027s basically so it seems to me this disruptions in a weird state because the documents analysis that led to obviously a three to three being what it is but yeah how are we going to use this analysis next so one one thing that that we left unfinished when we completed h.323 was how do you actually do your head scheme that is open with respect to the transport being done and we kind of have an unpaid IOU with an approach on this one because we agreed with him that that we should have such a URI scheme as well but we haven\u0027t really done the work on that yet and I think the protocol negotiation draft certainly will go into that in some form this will go into that in some form but also we probably want to specifically define what what such an URL scheme with which has been referred "
  },
  {
    "startTime": "02:02:16",
    "text": "to as co-op plus 80 some people how that and how such a URL scheme would work in practice now dave is going to remind us that ocf already has such a scheme which which is specific to their way ocf is naming endpoints and maybe that is also something that we also have to take into consideration when doing something like more general co-op +80 scheme so I think we have we have two nice pieces of raw material here and we have an unfinished unpaid check and we take it from here what Carson said I was going to say and then to extend on that I\u0027d say my comment is not entirely specific to ocf although you\u0027re correct that that is sort of that the main case that we know of today that\u0027s making use of of co-op and so on but I would say anytime that you have an organization or a vendor or whatever that makes use of co-op but potentially makes use of transports besides co-op then such an organization would probably never use a co-op - 80 they need something that wasn\u0027t co-op specific like OC f : isn\u0027t collab specific you can have EPS that are you know couette plus d CPE HTP something else it isn\u0027t invented yet or whatever because it\u0027s an agnostic higher lira that you can resolve any transport and so when you\u0027re talking about transports whether you\u0027re talking about transports under co-op or whether you\u0027re talking about transports that include Co AB and there\u0027s other things you know ATP or you know what have you that\u0027s in parallel to that that some higher level protocol might run over all that\u0027s part of the larger protocol negotiation or endpoint discovery problem ocf discover is that by having a higher layer that is not a co-op specific layer krytus your state generic research layer right and so that\u0027s something we should take into account when trying to figure out what the scope of these things is and to what extent we\u0027re gonna go to co-op +80 is anybody going to use it and if so how right that\u0027s what\u0027s what we should know because right now ocf would never use that right and we should do it too so that somebody would actually use it and if our customers and ocf we should figure out what the requirements are and how they\u0027re up to so me that would actually use it so let me throw this from it we rename this your ice cumin to rest : sesh - now you know what the implications when you say this scheme you mean the co-op +80 scheme yes yeah yeah that\u0027s exactly the sort of thing that I\u0027m arguing for is to say if you do that and then you can use you know whether it\u0027s you know oh well or whatever which can point to things which may or may not start with co-op plus okay "
  },
  {
    "startTime": "02:05:16",
    "text": "because you don\u0027t if you don\u0027t constrain it to that so that it could be extended in the future if something else comes along then yes that\u0027s exactly what I\u0027m arguing for yeah okay and then you\u0027re basically covering the ocf use case and that depends on you know what the rest of the syntax says which you mention you know what\u0027s the right way that you\u0027re naming things and so on and what you\u0027re naming things along the lines of what URI presented or something else right right Michael not at the Mike Michael Koster that\u0027s a generalization of the pattern so I actually just want to sit down [Laughter] it should be let that shake yeah so what David\u0027s providing us that we have a joint meeting on Friday between OCF w3c web of things and and Teatro TRG so that would definitely something that we want to coordinate so who can write the draft so we can look at it on Friday yeah so I think that the most critical issue is one that has for a long time which is important aiming and I think we finally have to buy the world on this one and agree what what we want to do there so can we count on you and helping us with that okay so I take it that we just have transmogrified this set of two documents into a slightly larger work item which is again an unpaid check that we still have with Roche and also something that I think the community really could use so let\u0027s take this discussion offline and make some progress there okay thank you okay so we finally have arrived at the flexible time part of the meeting and right now the the only side said I have is about OPC UA you\u0027re on do you want to say anything about the timescale thing nothing nothing you do report okay so where are we with timescale do we want to have working group adoption what are the next steps there it\u0027s not to talk I witness I would like to have a fucking quorum but it\u0027s a working group but have to put comment "
  },
  {
    "startTime": "02:08:16",
    "text": "and Angie\u0027s draft so the goal was to to have some when you send a mess request then to say how long you can keep it in in the server so when you are very slow devices could be very important but we need feedback from the from the group from this ok so who else is interested in in this option ok I\u0027ll be happy when people raising their hand so yeah we know who you are good yeah so so maybe we should take this offline and maybe use a break at some point and discuss how to make progress with this okay so that was timescale segment and now let\u0027s go to the OPC UA segment there are seven names on this slide I don\u0027t know who is actually going to present this so we had a presentation on this last time and there was some pretty good feedback from the working group ok thank ok this is jr. and Jeff name is OPC ua message transmission has over crop we have presented eight had last meeting and the way updated this new version three we made some Evo changes according to the last meeting commands especially adding some use cases so whereas our means this version and forest was resource constraint industrial scenarios if we want to use OPC a to consolidate different types of data and protocols into a unified information model as well as using web service HTTP is not a good choice because it\u0027s too you\u0027ll sink Rob instead of HTTP good better choice because it can achieve lightweight communication the first use cases was based on this and we only needed to change OPC a client and Savior to support a sway the second use case a use case is using crop tool HTTP proxy it\u0027s no necessary to change OPC UA client with developing of the cloud technology the factories data\u0027s can be uploaded to the cloud for fodder precisely and many cloths api\u0027s could support OPC we and a cop so obviously over crop can light few divorces - - like the few devices to use wet use "
  },
  {
    "startTime": "02:11:22",
    "text": "cloth api\u0027s directly and quickly the others the other change we consolidate to transmission schemes the proxy for PCO a crop and the directors machine into one to realize better transmission performance due to the expert membership of OPC foundation we have not contacted with OPC foundation working group yet and in the few weeks we will contact with them for faster feedback and we will implement the transmission scheme mentioned above over a resonable architecture we think the combination of OPC area and the crop is meaningful so we wish to get more feedback thank you and in command I\u0027ll question [Music] Dave Taylor so yeah I agree your next step should be to go to the OPC foundation get reviewed there as we talked about last IETF cos yes I think it\u0027s just informational to us that this work really belongs if they accept it and the OPC foundation not here right because it\u0027s on top of us it\u0027s a user of us and so they would be the ones to do the findings from OPC UA to various things within that my comments are our sort of technical comments or questions that are would might be more appropriate in that for them than this one but I\u0027m happy to give them to you now since I\u0027m here and I\u0027m not there which my understanding is that the only trance although the OPC UA defines like three or four different transports which you have the good picture in the in the draft the only one that\u0027s actually used is not HTTP it\u0027s the one that\u0027s TCP and here you mentioned Co app and I don\u0027t remember if in the draft you talked about coop versus over UDP versus coop TCP but for the cloud it seems like you care about the coop TCP thing and so I guess that\u0027s part of a question here is you assume it\u0027s co-op TCP because you care about congestion control across the Internet to the cloud and the second question would be have you compared the compression that you get from you know co-op and sea bore against the UA binaries compression when using the OPC UA TCP and is it comfortable is it significantly better or whatever so that would be my questions yes thank you Dave good so I think we continue to be interested in finding out what what other organizations might be using our "
  },
  {
    "startTime": "02:14:26",
    "text": "protocol and what influence this has on further design decisions so I would encourage you to bring back your work to us again but as Dave said we would be good to know what obviously foundation thinks about this and it also would be good to have some some numbers like like the message sizes the compression that okay thank you very much so we are 15 minutes ahead of schedule and we\u0027re done with our agenda so we can have a brief open mic session and then go to early lunch so is there anything that anybody wants to say at this point in time yes Dave asked who is going to be at the ocf w3c tthe meeting on Friday 6:00 will be what about remote participation do you have that ability I mean on the mailing list on core maybe you guys could send some information on how to join yeah it has been sent to the research group make a list and Bill just Oregon and I also sent on the core main list a remote part space and details so they are all in the github and core list and in the archie list thank you thank you okay anything else then thank you and see you I\u0027m not real or at the interim before that all right give up they transport sideways with you mom no it was good yes I\u0027m waiting for them too they are almost done but I was interrupted by the start of this meeting "
  }
]