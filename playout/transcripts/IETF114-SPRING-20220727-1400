[
  {
    "startTime": "00:00:08",
    "text": "hello i have been disconnected anyone hearing me yeah we can hear you okay but we can't hear the room now so maybe we need to to wait for some some time yeah thank you uh they broke it all over again yeah all right hello bruno can you let will the system let you share your slides again uh yes we got disconnected from the room at least yep um it says your sharing is getting started uh waiting for it there you need to back up to the beginning we didn't hear and the room didn't hear any of what you said okay so this is um 114 spring working group association is being recorded hopefully uh ghost audio and on video this is the usual noteworld we'll skip it for a second of time um [Music] i'll try to to be short this is a hybrid meetings so if you are in person you need to sign in uh using mytheco and you you need also to use mytheco to join the mic queue"
  },
  {
    "startTime": "00:02:01",
    "text": "and very importantly you need to to wear mask anytime and if your remote nothing changed please make sure your audio and video are switched off to avoid noise and uh [Music] minutes they are collaborative shooting is the main minute taker but you can help especially if you if you have comments you can check your name and comments in live this is the agenda for for today we are full agenda so we're already 20 minutes late so please stick to your allocated time which include both presentations and comments otherwise we may we may catch your presentation if people have commented on their gender you can i can go to the mic the time of document status we have two documents publish limited to isg for publication first is the past segment in mps based segment routing network and second is the integration of network service better and segment routing for service functions training and finally we have one new rfc which is a segmented policy architecture it's a important milestone for for spring so thank you to the authors the working group the shepherd the eddy on the isg and that's all for the chairs we can now move to a christian or circuit style segmenting policies before we start just uh we've been asked to remind people that it is a requirement having masks on in the room so if you haven't got them on please do"
  },
  {
    "startTime": "00:04:00",
    "text": "so thank you okay joel do you want me to share the slides so it's okay for you i'll share the slides right now bruno you need to release things and i will start sharing the slides okay our first presenter yes christian go ahead um i will give you you have slide control okay thank you uh hello everybody this is christian schmutzer i'm presenting uh as a representative of all the authors on the draft and i will be talking about the circuit style segment routing policies um sorry i'm not sure if i can actually advance the slides what i can't [Music] okay sorry we'll take control back and uh just just prompt us when you need to change slides sure okay okay so thanks the motivation for circuit cell segment routing policies is to allow operators to run a single network that not only carries what we call connection-less services which is classical ipvpn services or layer 2 vpn services in conjunction with more transport oriented or connection oriented point of point services uh often called private lines or um you know in essence wise uh if you will"
  },
  {
    "startTime": "00:06:02",
    "text": "um now what circuit style segment routing policies are adding on is from a underlay transport we addressing additional requirements first of all to have traffic engineered paths which are persistent meaning they are not changing because of traffic load or topology changes they only shall change when the operator is requesting the path to change we're looking at strict pain with commitments and end-to-end path protection to achieve you know very quick failure recovery and the famous sub 50 millisecond target as well as restoration to handle multiple failures and along with that of course path oem which is very important to understand the liveness of a path and understand when somebody needs to switch next slide so how do we address those requirements and what are the characteristics of segment route circuit style segment routing policies first of all we have a centralized path computation element in the picture that is responsible to get the path requests and part of the path request is of course the requested bandwidth and the path computation element will make sure that we have bandwidth management for all the links and this is important because in a segment routing network you don't have any rsvp that normally would have done that job for us we're forming bi-directional constructs that which are co-routed by associating a forward and reverse segment routing policy together and the persistent paths we are what we are creating by using strict tops of a list of strict types of unprotected json specifics unprotected jssits are important because we have path protection and we don't want any ti lfa for example to kick in as mentioned the path computation element shall not reoptimize the path"
  },
  {
    "startTime": "00:08:00",
    "text": "only when the operator is requesting that and that's a behavior that is commonly uh requested and known in the tdm world aka solid stage or otn uh we are using multiple candidate paths uh now we're going to program two of them to install um you know a protection scheme and there can be a third one if restoration is required as well and stamp is used to do loopback liveness detection or observation if you will and performance measurement next slide how are we creating uh circuit style segment rounding policies before we can create them a few uh words on the topology uh the topology is um you know every link has to be configured with unprotected adjacency sits and they should be persistent across router reloads which generally is done if you configure them manually and explicitly the topology will be known by the pce via igp or vgpls extensions the path computation element will have to ban with configured for uh that is available for all the circuit style segment routing policies for on each link and there are pair hop behavior guaranteed uh you know guarantees you know assumed or required so that the provision bandwidth on the link can be at all time assured to be available for circuit circuit style second route the endpoints of the policy um are acting as pcc and will delegate the path computation to the pce um the draft is outlining a bunch of um you know attributes or information that will be included in the candidate path request uh important is for example the the c bit in the bidirectional association object to a force co-routing we also have some um you know some bits in the lsb a object to uh um"
  },
  {
    "startTime": "00:10:01",
    "text": "to enforce no local protection but there is a dedicated draft for that will cover that and it is being discussed in the pce working group um and we are using multiple candidates for protection i mentioned that the path computation element is uh is responsible for configuring or computing working in the protect path uh in a disjoint manner and we're using the disjoint association for that uh and so on so forth next slide next slide i'm going quite quick because i wanted to share the updates and the progress we made we have done our first presentation at iitf 113 in the pc working group we got quite a lot of input in the meeting as well as after that and we received you know a lot of review comments which already got incorporated the document changes are mostly around clarifying the role of the pce and the stateful pc we added a section about how to deal with the maximum segment depth limitations that may arise and we overall cleaned up or reshuffled the the sections so that uh to to get a better structure and readability of the draft and speaking of the draft uh one of the feedback was that the draft is probably more uh better suited in the spring working group and that's why we renamed the spring working group and we're presenting it here in the final slide we would like to get more comments and and feedback this is always welcome um we think that we got already the document in a pretty good state and that's why we would uh suggest uh the the working group to uh to uh do an adoption call so that that this draft may be uh adopted by this working group thank you very much"
  },
  {
    "startTime": "00:12:00",
    "text": "thanks christian uh nitsan you were on thecube but you dropped off um i don't know if you want to jump back on or whether do you have a question or not okay i'll assume not uh please go ahead oh wait a minute uh nitzan go ahead one issue is that i'm not sure about how do we ensure uh protection uh with resource allocation uh and um bidirectional thing i mean it seems to be addressed but i'm not sure exactly how uh i'd appreciate any elaboration on those issues so maybe to to cover the the um the core the bi-directional so we we're going to use the bi-directional association to signal from both end points to the pc that those two sr policies belong to together and then it's the the job of the pc to basically perform the path computation so that those both sr policies that are indicated to belong together are co-routed in a bi-direction are routed in a bi-directional and co-routed manner uh which i think is something that um um you know it's it's is already quite well defined with piece of extensions um the protection uh maybe i was going a little quick right so we have two candidate paths that working at the protect they will be signaled each as a request and each having a bandwidth uh you know requested as well so when the the pc is doing the computation and manages the allocations of all the path computation requests in the topology it will allocate both the working and the protect band so whenever we need to switch the protect uh path is pre-programmed and already and has the bandwidth um you know assumed or allocated from the pc perspective"
  },
  {
    "startTime": "00:14:02",
    "text": "uh robin go ahead robin please go ahead can you hear me yes we can hear you okay uh in fact several years ago the similar work like oem protection and the bi-directional sr paths have been taken into account so the work of sr pass segment has been developed so in my opinion i think this work has much relation with the existing past segment work i wish the work can be taken into account this in this draft and also can do some of the combination work with the past segment yeah i think this is um this is a a fair comment the our draft i think is mostly focusing on on the the overall solution how the corroded and bi-directional computation and this and the paths are getting established you know establishing an end-to-end path segment as part of that um you know i think fits in the picture so we definitely can we can we can talk about how uh how those two work items are are you know aligning okay all right dhruv please go ahead my one query is like even in this presentation as well as in the draft uh the pc is used extensively is"
  },
  {
    "startTime": "00:16:04",
    "text": "uh okay we're gonna have to move on uh um in the interest of time because we were late starting so let's uh move to the next presentation and any other questions please take to the mailing slice list yeah is it on there we go hello uh hi my name is gion mishra i'm with verizon and i will be presenting uh srpmtu for sr policy on behalf of the co-authors thank you next slide so some history as to how this draft came about and came into the spring working group so during the adoption of draft pce psep uh with uh shipping a need for the spring a need for a spring document was requested and confirmed by both the pce and spring workgroup chairs uh so with that a and i during that discussion of the adoption during that adoption call an idr document um for sr policy path mtu adoption this this topic had as well had come up in april of 2020 a discussion was brought up by keith and taluer uh that the concept of path mtu for sr policy and its applicability should be first defined in the spring working group should be the first to find in the spring working group before we introduce the signaling aspect into the into bgp so as a result of the pc mtu extension adoption call uh for pete for psep of path mtu extension"
  },
  {
    "startTime": "00:18:01",
    "text": "was to maintain basically only protocol extensions that was also as well requested for the idr draft to just really maintain just the protocol extension details while the sr policy path mtu definition and framework was to be developed in the spring working group as a standards track document to ensure interventor interoperability related to sr path mtu concept and computation details this topic came up as a critical issue to be addressed during the idr work adoption as i mentioned in 2020 and then and then the second time again during the psap extension for pat mtu due to the criticality of solving this topic and related related to handling of fragmentation and fragmentation issues that could happen with an sr policy next slide yep thank you so ssr policy uh so an overview here so the motivation of handling the sr policy path mtu so we got fragmentation avoidance by the sr head end to be aware of the sr path mtu associated with the sr policies sr paths and policies the ability to generate an icm message at the head end if they're if fragmentation is required and then follow correct fragmentation procedures to ensure interoperability between implementations and the ability for the sr policy as as a path competition constraint to be added in a distributed model directly to the sr policy in cli or i'm in a centralized controller method with a pcsdn controller as a cons as a constraint that could be pushed down by the pce to the head end source node next slide so sr policy uh definition for sr policy srp sorry pmtu definition for sr policy so basically a valid candidate path is selected as the active path and once"
  },
  {
    "startTime": "00:20:01",
    "text": "determined to be the best path for the sr policy it could build the dynamics explicit composite set of segment lists or composite canada path container grouping of the sr policy so so with that definition srpmtu for a segment list is defined as the minimum link mtu of all the links in the path from the source to destination srpm to you for candidate path is the same as the sr policy same as srpm2 of a segment list for an explicit or dynamic is expressed as a set of segment segment lists and the srpmtu of the candidate path as defined as a minimum srpmt of all segment lists in this set for for composite is the minimum srpmt of all constituent sr policies of the composite candidate path and finally the srpmtu on that sr policy is defined as the srpm of the selected active candidate path next slide so here just depicting kind of the sr policy for a pmtu framework so in this example we're showing an sdn controller we have a path these so the sr uh piece the uh centralized controller would basically push down via pc the pce to pcc to the uh sr source node the a constraint so it'd be an s it would be an srpm2 constraint that we're pushing down from the controller to these a head-end source node and that's with the bgpsr policy so when that gets pushed it would it would it would uh add that constraint into the policy to prevent fragmentation as well as part of that uh framework the link mtu collection would be would be done via bgpls next slide so the framework of sr policy for p for srpmt for sr policy so with that framework uh the srpm2 path computation and how that would work for the variety"
  },
  {
    "startTime": "00:22:00",
    "text": "of different paths so a loose te path would be the minimum srpm2 of all ecmps between the two adjacent and two nodes between uh ingress source node and egress destination node node sid along an srt path so that's basically the node node sid uh ecm ps so the next one is a strict patch so this here it's a minimum link empty of all links along the strict srt path and then mix to the minimum sr pmt of all ucmps between the two two node sids and the link mtu of all the link mtu of all links along the path indicated in the adjacency sid and then binding city path is is the srpm2 of the binding path is the same as the sr policy except that it includes the associated encapsulation overhead of for srv6 with the outer ipv6 header nsrh and srm pls sids sid list that's pushed onto the stack for tlfti lfa the srpm2 of the repair path at the plr node to the merge point is computed by the controller which updates the head end with the new srp mtu so in that bypass loop if there is a different mtu than the uh then the primary path that that that path computation for the bypass loop is actually is is is sent back to the uh ti to the head end node for the bypass loop next slide so this shows an example of kind of how this would work so so with this is an example of a sr policy for loose path you with the node sid so you have the node sit on the ingress and egress pe and here we have an ecmp so so to keep in mind that we're looking at so this could be an n-way ecmp you have many ecmp that are that are there with the uh prefix sid prefix node said so now here it's the lowest the the lowest pm2 of all the pads of"
  },
  {
    "startTime": "00:24:00",
    "text": "all the ecmps so if you see the path from left to right it's got an m2 of 2000 but then you see the bypass loop has an mtu 1500 so as as with with the uh computation it would be the lowest so here the lowest would be that bypass loop 1500. so now here the controller would basically push down the constraint of 1500 down to the sr pulse sr sr head end head end node for the sr policy next slide so this example is a strict policy example uh with the adjacency sids and in this example what we're what i'm depicting here is if you see if it's similar to the last slide so in the the path along from left to right you see an mt of 2000 with the adjacency sids and then along the bypass loops you see a um a nmt of 1500. so in this example what we're trying to do is we're trying to but so normally the path mtu would take as as mentioned in the previous slide the low the lowest uh lowest path mtu so in this case the lowest path mtu would be the bypass path the triangle path along the bottom 1500 so that would that would be normal standard computation when the path mq's is is computed so now what we're doing here is we want to take the actual the higher mtu so we want to take that 2000 pounds from that ingress pe to the egress pe so in this case what we're doing is we're actually pushing a uh a constraint a path mtu constraint of 1800 from the controller to the sr policy on the head and source node and we're pushing down 1800 so since that is our constraint that we won as a minimum and that actually forces that green line so now we're actually instead of taking the default uh path m2 using the lowest which is the triangle path now we're actually with that new constraint we're actually taking that green line path from left to right next slide so this example is the loose so it's a similar topology so we got left to right we got 2000 and then we have the uh"
  },
  {
    "startTime": "00:26:02",
    "text": "triangle path 1500 along the uh low the other path and this is here is example of a mix so you got prefixed so you you take the prefix sid in the segment list you're you're taking you have the prefix sid so that's your first sid in the si the active sit in the sit list and then you have then you have an adjacency sid that you take along the path to get to the uh egress destination so in this in this case what would happen from left to right you have the uh you have the two-way ecmp here left to right you got 2000 and then on the bottom triangle path you got 1500 so it's the lowest lowest of of the path mtu along all the paths and this case is 1500 so the the the controller would basically push down that constraint to 1500 down to the sr policy at the head and source okay uh let's let's go down to the last we will if did you have time for just one more go up one slide you one more slide okay thank you so what i would like to ask the work group is if we could if folks could review the draft and we just want to get feedback there's some there are there are some critical components that we would like to get feedback from these spring working group experts the three three topics that that we bulleted uh with the uh you know with with the authors co-authors on on you know as that we had discussed one the first one that we want to get feedback on from the spring working group experts is the ti lfa srpm2 ti lfa computation and fragmentation caveats so just to make sure we didn't miss anything you want to make sure that we we're really on target and so we really want to get get feedback from the experts the next one is the srpmq srv6 source node encapsulation fragmentation caveats and the last one is srpm2 bindingsid path computation caveats so much appreciated and if you know and we'll take this to the workgroup mailing list and uh and i"
  },
  {
    "startTime": "00:28:01",
    "text": "really appreciate the feedback yeah i'm really sorry we don't have time for questions but we're really short of time this time and we want to let things keep moving so thank you very much and the next presenter will be up in a moment thank you so this is the connection oriented path in srv6 i'm not sure who's presenting this and zhang ping so go ahead and this is about the motivation uh we think that uh the exact uh name should be the connection only the whole backhoe switching pass in the sr6 the whole pipe hope switching is just the way that the traditional amps start on its node in which the label is locally allocated and slapped on each node as we know that at r6 packet can contain a hole or partial nodes to do the strict or loose source rooting thus fewer status on each node would be needed however if we need a strict t pass in the network we need to put each node state in every packet tyler which is not very convenient next page please and the uh for the connection oriented strictly"
  },
  {
    "startTime": "00:30:00",
    "text": "passed in s56 we can we have several options the first is we we still put every node state into the package header but if the path is long the packet header will be large optionally we can also compress the c list the second option we can support both have our v6 and i'm pairs but it is complicated and with this document many talks about the third option we want to try to support her back home switching advice 6 network we think the benefits is that it is based on the uniform srv6 network programming platform and we also think that the platform can support many network characteristics and reduce number of protocols in the network and we have two graphs and the first one is about option one and uh the packet heidel pipes need to contain each node seed and in option 3 we perhaps have only one node seed in the packet header we also add some explanation here we think that we do currently we do not need to manage this kind of or correct oriented uh parts in the as fast in the network next page please for the uh for the folding on the display uh we introduced a new set of seeds uh on the data it is easy to replace the label in mpls with the seed in advance 6 in this document we call it a endpoint x cup d function it should be supposed on each node and contains a argument similar to a label"
  },
  {
    "startTime": "00:32:01",
    "text": "uh this is a graph we can see that on each node the packet header uh the destination in the packet header is changed is similar to the label swap and we have we have we need these nodes to support the label mapping in a seed format next page please on the different it is simple to introduce new cs to replace the [Music] label in mpls but on the control plan we also have two options the first option perhaps we can use a pce server to connect to each node and communicate the label labels uh for the past uh and under the document that we also introduced another option uh is to simulate the procedure or svpt mpls by using new uh control plan c's in n56 we call it and they are independent corpse c function which is also needed to be supported on each node and the content data paths contains an argument similar to a label uh and the id step we think that the legal zero is special it is used for the confirm the path we have the the graph and the node one is a hidden and the node file is the endpoint the first node one will send a packet containing the uh the end point code c function with the label zero and it is sent from one two three four five to confirm the path and the note file will enter a"
  },
  {
    "startTime": "00:34:02",
    "text": "packet similar to uh next page please and we in this page we introduced the steps or as hebrews in the past the first step is we we need the hidden standard packet to know for node one to know the file and it contains all the nodes seeds and each downstream node will respond a table in the package returned to the node one and they can establish this mapping table but it is in the sealed format next page please i think this is the last page and thanks for listening welcome for comments and our contributions thank you any question there any questions from the room there's none on the cube okay we're moving on then thank you thank you okay go ahead you song hello yeah we can hear you please go ahead yeah okay thank you uh hello everyone uh i'm yuzun leo from channel mobile uh today i will introduce uh rprd uh for the network slicing in src segment this is the first presentation of this draft next page"
  },
  {
    "startTime": "00:36:01",
    "text": "please next slide and firstly i'll introduce the background and as we know a network slicing partition a physical network into multiple isolated logical networks network slides associated with the spatial specific network resources called the nrp an rpid is used to identify the nrp during the package forwarding and it can be carried in the pack packet and like in i like the picture the router can use the rpid to determine the rrp and for the package uh like an rpid eco2 uh the router will use the green line to forward the packet so uh in this chapter we propose a ambassador for the for the uh nrp id uh in the sixth segment so that's the page please okay uh uh this master to uh encoding an rpid in a 76 segment so uh yes i succeed we have uh three parts of that locator function argument and in the either 6t mode the segments of the intermediate endpoint along the six parts are usually the end or and.x type segment so we can and the argument field of this type segment are not defined"
  },
  {
    "startTime": "00:38:02",
    "text": "so we can use this uh this field uh to uh carry the nrp id so the seedless in the rsrh every segment can carry the same or different rpids which can remain by the controller of the cri so next okay please uh because uh for the in the srv6 parts uh the srv6 endpoint can look up the local seed table to extract the argument field to get the rpid but in other nodes like the non srv6 node even the node cannot support the israel 6 only supports ipv6 so we need a table to uh get the nrp id from the destination address so we uh we should uh create and look up the slice prefix table here so with the static configuration mode of the dynamic advertising mode that means from the controller or the cri to the router or or from the bbp rs or the lgp to other nodes of the controller and the protocol can extensions will be provided in future versions or separate drafts so this is the basic uh mechanism"
  },
  {
    "startTime": "00:40:02",
    "text": "so a slice prefix includes the prefix should be matched and the the second part in the encoding position in segment we can uh get where we can get the an rpid so that's the page please so this is the uh rspt that uh we we will build the local slice prefix table in every node along the sr6 parts for the head end of the sra 6 we will write the rpid into the segment and in for the intermediate nodes we'll get the nrp id from the destination address uh if the nodes are not the it's not the uh srv6 and the honda like the example in in the slide for the p1 and the p3 they have a different slice prefix and every uh each prefix has a different position of the rpid and if if the destination adjust match the slice prefix it can get the nrp id position and it can extract the rpid from the destination address okay next page please this is the example for uh this mechanism so we assume that we have a two rps"
  },
  {
    "startTime": "00:42:00",
    "text": "and rp1 guarantees the 100 megabits band device and the rp2 guaranteeing 200 megabits pen wise so we dedicated the the queues for the airy router to guarantee in the bad ones so uh we have a sra 6 policy on p1 including the segment for the p1 and seed and the p3 and the seed and for the p1 as the head end it will determine the nrp and it will uh carry the nrp id2 uh to the p1 and the seed and the p3 and speed and in the in caps with the srh and the ipv6 header and the uh sorry i'm not finished and for the endpoint the p1 and the p3 it can extract the rpid adjuster from the local seed table and for the p2 it's just a transient node so it must look up the rspt to get the nrp id position to extract the nrp id and decide how to uh uh forward the package with the queue so that's that's all uh we are seeking uh the feedback from the working group any questions uh comments and welcome thank you i'll ask one question this is joel halpern"
  },
  {
    "startTime": "00:44:01",
    "text": "as a participant i'm in looking at this material i think i understand the general driver and actually like it but the material needs to be much clearer about whether you are requiring strict paths expecting strict paths or expecting intermediate nodes which are not addressed to extract these arg bits from the current sid and and handle them which would be an unusual requirement so we need to be very clear i'm not telling you what the right answer is but we need to be very clear about what we're doing okay other questions on the queue okay thank you i didn't get my name on the list but darren duke cisco systems quick question is is this a hop by hop every sr and non sr node does this stuff i was asking okay now iso 6 node it should get the rpid from the rspt so uh thank you okay thank you son john wade uh do you want to uh go ahead uh hello can you hear me yes we can uh okay hello everyone my name is jaiway mao i'm glad to introduce this new draft for you generalized arguments of srv6 segment next slide please"
  },
  {
    "startTime": "00:46:06",
    "text": "here is the background and motivation in these years some new features are created include network slicing ion alternate marking apn6 then net and so on the instructions or commands of these new features can be processed and all nodes along an sr path or some endpoint of an sr pass that means the ipv6 callback hub options header the destination options header or the srhtlv may be used to carry the instructions or commands however the usage of the options or trvs will cause two issues first you will make the packet header longer that will reduce transmission efficiency and it will make make the forwarding processing complex they will affect a forwarding performance besides in the solution of srv6 c6 compression with next flavor if all the c seed of the seed list can be put in the ipv6 destination address field of a package there is no srh or the doh which is before the srh here in the package after the compression that means we will have no space to carry the instructions next slides please [Music] so in order to address these challenges we propose this draft to use the arguments of the srv6 seat to carry those instructions using the arguments we will gain this benefit first we can reduce the transmission overhead because it will reduce the needed space of ipv6 extension header or sih tlv next we can get better forwarding performance because the i the the srv6"
  },
  {
    "startTime": "00:48:03",
    "text": "arguments can be read and processed as a part of ipv6 address that means it can avoid to process the extension header or srhtlv behind the basic ipv6 header finally we may unify and simplify the package processing because the instructions for the srv6 and the new features can be put together in the arguments part in addition we noticed that there are several kinds of arguments for the srv6nc and endo x seed which need to be compatible for example the srv6 cc compression solution use arguments to carry multiple c seats cl field or both of them next slides please [Music] okay in this draft we propose the generalized arguments it makes the srv6 arguments structured and generalized and allocates spaces to encode the instructions of multiple new features and srv6 seed this draft specifies two methods to use the generalized arguments the first method is template we we configure a template to network devices then the devices read and process the content of the arguments according to the template for example if the argument has the total length of their bits we can define b0 to bx stores the instructions of feature a bit x to bit y stores that of bishop b and bit y to be z stores that of feature c next slide please the second method is called bitmap the this draft defines a bms structure"
  },
  {
    "startTime": "00:50:02",
    "text": "in the arguments it is used as an indicator each bit in the beam map indicates whether the instructions of a specific feature exist and are valid in this method the generalized arguments have two possible formats corresponding to msb and lsb next slide please moreover this draft also considers how to interact with srv6 cc compression solution as for the next as for the next flavor or the next and replace flavor it is required to shift the sea seed in the srv6 seed so the c seeds can be placed in the generalized arguments and need to be placed from the most significant bit while shifting the multiple cc's the remaining parts of the generalized arguments should not be shifted next slides please so finally we believe there are something to be discussed and clearly defined in the next step for example which bit in the bin map corresponds to which feature and what instructions or fields of the specific feature need to be carried in the generalized arguments and how long is the space of arguments that we need to allocate for a specific feature at the end we'll come to give us some advice online only the mailing list or join us to make some contributions many things that's all thank you thanks jim generally um i have a question myself as an individual contributor um before i go to the queue it's not obvious to me anyway what these uh features that you talk about are"
  },
  {
    "startTime": "00:52:01",
    "text": "you you're kind of indicating that it's a feature but presumably there's going to be more data so for example you talk about network slicing why do you need to indicate that feature when you're going to need more information than that to actually be able to do anything you don't need to answer that now but something to consider um the other thing to consider is potentially giving some example how the compression would actually work with this so my concern would be for something like the next um flavor and if i've already used up all the bits for for that how i'm going to be able to do that so so just some things to consider um kitan do you want to go ahead uh thanks for your comment uh in the draft we have defined a new flavor to indicate that the argument part is needed to be processed as a generalized argument uh it's named as a structural argument flavor now uh this point is no shown in the slides for time reason uh thanks for your mention and about how to interact with the srv6 compression uh is shown in the above page okay katan go ahead okay uh so i have a concern with this notion of uh generalized arguments uh because uh there isn't anything of that nature uh based uh for rfc 8986 the network programming whether whether a sid has an argument or not or whether it is valid or not is determined by the srv6 endpoint behavior definition of that side so if there is if anyone wants to use arguments in a seed uh said"
  },
  {
    "startTime": "00:54:02",
    "text": "there has to be a endpoint behavior definition which should precisely say what the arguments are or how it is to be processed so i think uh maybe i'm missing something uh very fundamental or basic here okay thanks for your questions like there isn't anything like a generalized arguments for that may be applicable for our srv succeeds basically uh okay uh i guess you are you are a question about the how to know to process the arguments as and generalized arguments in this draft we don't define as a new behavior for this we define a flavor to identify this srv6 seed is carried on generalized arguments and and it is needed to be parsed sure so you need to define i mean behavior flavor is like i mean i don't want to go into it you would need to define a new code point let me say that uh for for set behavior slash flavor that is going to use generalized arguments they do not apply to existing ones that are defined and uh let's say today we can discuss further on the list perhaps if you have any queries um uh okay okay thank you greg please go ahead thank you uh greg mursky erickson i i think that my comment is in continuation of jim common because it's not clear whether this argument really defines the behavior or capability advertisement what's not clear in particular is uh how that net is relevant to this so basically what you expect if this uh argument indicates that that net is it support of"
  },
  {
    "startTime": "00:56:00",
    "text": "that net and what's else okay thank you that's great okay thanks for your question uh we just defined a general a general space for the multiple or the many features so the dead net or the network slicing or the api 6 is just a structure instruction example feature for this and and whether it is fit uh it is suitable to put their net here and we can discuss uh further thank you robin please go ahead okay i this is a quick reply about this about this the questions uh in fact this the arguments should be uh processed in the local node but because the instruction to be processed by the specified segment there can be multiple arguments for different features so we need a template we all need a structure the arguments to be defined for this purpose but we ask this these comments we should refine this draft to explain the use case more okay [Music] thanks robin okay uh fan please go ahead hi um this is faryang from huawei and on behalf of the other courses i present this redundancy policy for preventive protection next please yeah here's some background of the redundancy protection and it is a generalized protection mechanism that um and and used in used in the context of"
  },
  {
    "startTime": "00:58:02",
    "text": "of the segment routing paradigm and it it replicates the service package on the redundancy note uh yeah shown in the in the figure it replicates the service packet on the redundancy node and transmit the copies of the service packets uh from different uh destroyed paths and transmit the first correct and illuminate the redundancy packet as the merging node and to to be clarified it the the redundancy protection is triggered is inspired by the then that packet replication illumination and ordering functions but it it is extended to provide provide production protection functions to sr to segment routing and uh here many will use to uh draft to introduce this uh mechanism the first draft is was adopted by spring last year introduced the redundancy seed and merging seed in data plane and to specify the endpoint behavior and this draft introduced the redundancy policy in control plan to instruct the instructor multiple redundancy forwarding pass from controller to the redundancy node next so what is the redundancy redundancy policy it is defined as a variant of the sr policy and with minimum changes so it inherits the the main structure and the most attribute uh from of the sr policy and the function is to instruct the replication of the server's packet and assign the multiple redundancy forwarding pass so um we actually we specify it in um"
  },
  {
    "startTime": "01:00:00",
    "text": "there are actually it works in two scenarios and and the scenario is shown in the in the two figures below um the main difference between the two scenarios is that whether the the redundancy whether the head end of the head and node of the sr domain is the redundancy node or not so it did it if it is the if the head-end notice the redundancy node it means that there's no necessary to use the uh redundancy seat at the at the header so that it did so it determines the whether we used to identify seed or not next um in this picture in this page that we used uh an example to explain the structure and the behaviors of the radiances node and uh in the figure on the right there are three um folding paths between the arnold and m note so we use the first two blue um first two um forwarding paths in blue as the redundancy note as the redundancy path so they are they are the seed list one as they list two in the first candidate passive one and the last uh the last the third folding pass in ring and is a is described in the second candidate past cp2 as these list three so in this redundancy policy that will introduce a new optional uh attribute at the candidate pass level so it uh so if we use the the head attribute is for the flag so we define one flag the redundancy flag to indicate the type of the candidate pass is used for redundancy forwarding so uh come back to the example here that if um uh when the with the first candidate pass cp1 is selected as the uh best valid uh"
  },
  {
    "startTime": "01:02:01",
    "text": "uh can they pass for this redundancy policy and this um all the syllabus are used for all these lists in this um candid pass are used for the redundancy forwarding and not for the for the load balancing functions so at the same time the weight of these list is not applicable and next yeah as we've shown that in the in the scenarios that there are the this um redundancy policy can be optionally associated with the bounty seed and actually the body seeds should be the redemptive seed so and it is it is defined as optionally as optional and next please uh here i list several um separate draft and and as a other actions that to make this function make this mechanism complete and um yeah i will also present the bgp and pcep extensions in the following working group sessions next yeah the the next steps that we mainly want to uh have the discussion on the melody stored on the on the meeting to define the solution and also keep the keep in line with the sr policy if necessary and the further uh possible discussion on the alternative solutions um people may want to discuss whether why not use the use multiple candidate paths for the for the redundancy forwarding forwarding pass and we're happy to receive and comments and"
  },
  {
    "startTime": "01:04:00",
    "text": "suggestions and thank you thank you fam we have a couple of questions on the queue mike uh please go ahead this is mike from cisco systems i just want to make a comment that i think it's it would be better if you replicate the packets across candidate paths rather than across segment lists because uh if you replicate it across the center yeah yeah i think the load balancing of the sr policy so you can't uh you know have load balancing anymore and like you say the weight is not applicable right so the weight is there for load balancing so it's perfectly possible to do what you're saying uh if you replicate across the candidate paths rather than uh segmentalists that's all thanks yeah thank you for the comments actually i we will think about the which one is which solution would be better or will be more um uh more suitable for for uh for different uh scenarios but we can move to sili to have more discussion yeah israel please go ahead israel please go ahead you're on thecube can can everyone hear me yes we can now yeah israel at t uh in in the material you mentioned a binding sit you also mentioned something referred to as a redundancy uh binding set however what wasn't clear is if the redundancy uh it takes all of the semantics of a standard binding set or if the standard bindings it can also function as a redundancy uh sid can you clarify that"
  },
  {
    "startTime": "01:06:02",
    "text": "yeah the redundancy seed um that we defined in the previous in in the first draft and it is uh we we defined it as a as a variant of the of the bunking seed um i think it takes uh issue takes all the all the functions from the all the semantics from the pounding seed but uh add more uh functions like the replication of the packet to this new spending seat yeah but but if you have the after any doubts about the semantics if if the semantics is correct or not we can have further discussion so far i think he it inhabits it has the same okay thank you uh greg yes go ahead okay uh greg mursky erickson um one question i have and then probably a recommendation so the merge function works on packet by packet basis or flow basis yeah yeah the margin for the merging function that we define as uh as a merging seed so i suppose it should be a percent packet by packet okay um so uh in this case it looks very similar to the uh prior functionality defined in the depthnet so packet replication elimination and order preservation and so i think that you might consider it presenting it and sharing with the debt networking group at some point thank you yeah thank you actually we have the previous discussion about the relationship between the uh between here and then that so uh if the people still have the doubts or have not clarified we"
  },
  {
    "startTime": "01:08:00",
    "text": "will clarify it in in future and found the on the mailing list and the draft thank you thank you fan uh you song uh you're up please go ahead hi uh thank you can you hear me well yes we can oh thanks jim uh hi this is josue and i will introduce our work about segment routine for newhamster.net next slide please uh this page i just want to show a very brief introduction to uh the audience what is that net uh actually based on the definition erc 8655 there are three key features for the net cues one of them is upon the latency and bonded variation uh that means there will be minimal and maximum end to end latency from source to destination and also zero packet loss which means there there will be uh zero delay when packet switch when past switching and also upper upper bound on out of order packet delivery and the reordering function will uh will do its work to make the the packet in order again so all these features will be achieved by three technologies as resource allocation service protection and explicit routines the existing technologies can be reused or new functionalities or technologies can be introduced to achieve the standard qs functions or sla guarantees this document is to provide solutions for boundary latency with segment routing"
  },
  {
    "startTime": "01:10:00",
    "text": "for that net next slide please uh actually as we all know uh sr mps and sr6 is able to provide explicit routine with which is also requested by that net and for the convenience of uh presentation i just take srs6 and as an example and srmprc is very similar um with source routing it could steer that then airflows go through the network according to an explicit routine by second releasing srh but only explicit routine is not enough for guaranteed bonded latency so what's more next slide please what we are proposing is srv6 extensions should be defined to provide explicit routine and upon the latency um the the basic idea is very simple if we just indicate a explicit routine along the past if we can guarantee the boundary latency for each half inside of the path the end-to-end latency can be guaranteed so here we we just use network programming provided by sr6 which can give packet instructions in every node along the path to guarantee the bonding latency so what kind of instructions is requested in this case next slide please uh here i just referred to another document we have another document called upon the linus information which is introduced uh for body latency function the the document will be presented in the networking group the basic idea is very simple uh we just want to avoid"
  },
  {
    "startTime": "01:12:02",
    "text": "implementations for guaranteed on the latency we just define a concept a general concept of under latency information which have uh eight we defined in existing version eight body latency information types and we then cover most of the cases we have met the mechanisms to guarantee bonding latency and also the the boundary latency information value is specified uh value of of bli to provide guidance for packet processing with the meaning of a particular bi type as i have mentioned the the eight one of the eight type in the table in the right hand so the information pair bi type and the blf value should be indicated by srv6 data plan to provide a boundary latency next slide please i notice as greg is in the queue do you want to ask now or after i finish the presentation go ahead greg okay thank you uh greg murray erickson so uh can you clarify uh when you say guarantee what particular technique you use to guarantee the latency or jitter or any performance behave metric value uh i think here we will try to go along with the definition internet because then that internet queues the terminologies of guarantee in my understanding is to provide an expected bounded latency which means that we know the maximum bandwidth and the the minimum bandwidth uh from the source to destination uh you're right so the in that net i think that there is no uh discussion of guarantee uh the mechanisms discussed"
  },
  {
    "startTime": "01:14:02",
    "text": "tsn or priof improve or reduce certain behaviors but they provide no guarantee actually if there is only only time division multiplexing um can provide the guarantee in a packet multiplexing i believe that we have no guarantees if there is no guarantee there is no meaning to mention that we can expect a particular value of the maximum or minimum of the latency i believe the detailed definitions of these are said to be det net this clearly will not advance until the dependent.net stuff is adopted and so we'll leave it to det net to debate the exact way to describe these various properties because it's their space the only question for spring would be how to indicate that net properties in a spring segment list okay all right you may continue yeah thank you thank you joy i i agree i think the the the definition of the terminology or the meaning of uh the terminology we can leave it to that net and this page i just want to if we want to summary the the ideas from the previous slides uh bundy latency information is used to uh to guide forwarding in the network device which could be initiated in srv6 data plan for example also similar as a mps sr data plan with the characteristics of segment routing the boundary latency information could be coupled with the explicit pass to provide the latency guarantee in each hub or both it can be node or adjacency"
  },
  {
    "startTime": "01:16:00",
    "text": "indicated by the segment list in order to achieve this we in this documentary we've introduced two new variations of uh ndo and dot x seed uh they are defined for that net boundary latency uh which are called and dot x l and n dot x bli uh the difference uh main difference of these two cs is whether to carry bis ex implicitly in the encapsulation for uh and dot x blc uh it has two meanings one is uh to identify an interface or link just like the normal or the json c the second meaning is to identify the information pair of bli type and the br value on the interface uh or linked to guaranteed funding latency so there will be a multiple and dot x blcs for one adjacency in order to differentiate different bi type and the br value to guide the packet forwarding and another variation is and doltech's bli seed it also has two meanings the one the first one is to identify uh interface or link uh as the norm of the tcc seed and uh second is to identify the vi type to guarantee boundary latency uh in this case the the bli value will be carried in the encapsulation of the srv6 packet now there are three possible options have already been defined in this document uh the first one is the arguments in the ant dot effects and the second one is srh tlv for bi uh will be used together with endodontics vli seed and"
  },
  {
    "startTime": "01:18:04",
    "text": "you just yeah we just lost you son yes we just lost you briefly there you song how about okay you're back go ahead okay okay thank you i just finished uh there are three possible options to carrying the the bi information value and what is the next uh we we would like to collect the comments from spring and attendance like joy has already mentioned uh the maybe the definition of mechanisms should be left to the net about how to uh how to make srv6 and srmps to support this function should be left to spring and we would like to collect feedback from both working group and also we would like to seek more corporations with people who are interested in this work thank you thank you any questions from the room there's no questions on the queue okay we'll uh move on to the next presentation okay how how lee please go ahead hear me uh can you hear me yes we can okay uh first page please uh hi uh this is the ho from it's rizzy and i'm going to present at least two drafts on behalf of the authors and these two jobs are all about extension of bgpsr policy this page is the motivation for segment"
  },
  {
    "startTime": "01:20:03",
    "text": "leads list identifier we know the draft segment relating to policy defined as a policy to distribute as a policy to the hand and node there are policy name and candidate pass name to identify the policy and candidate parts respectively for seminal segment list there is no id or name in sr policy so in some scenarios it is inconvenient to do some process about someone list one case is the reporting statistic from head and node to controller normally hidden can collect a forwarding statistic account based on signal list one report the control controller patent has reported static with the whole signal list and the controller has to compile the seed one by one to identify which segment list is reported and another case is distributing configuration it is from controller to hidden node in addition to distributing policy through bcp as a policy the controller also distributed configuration uh through that that conf our procedure is similar the whole segment list has to be carried in these cases identifier or segment list may be helpful next slide please yes this is uh okay thanks this draft hopes to add the second list identifier in bgpsr policy and identifier could be a id or a name next slide so displayed uh two uh subtlety are"
  },
  {
    "startTime": "01:22:03",
    "text": "defined and the left subject away special file identifier second list buy uh four octaves number uh the right sub here we specify latin fear of a second list by a simple logic name at least two subtlety are optional and it must not appear more than once inside the same listed subject uh maybe just need to keep one on them we can update jobs according to feedback working group next slide and this is another draft about the head and behavior we know there are multiple ways to steer packet flow into a 76 policy for binances during multiple behavior have been defined the multiple sf6 uh yet banning seed with different behavior could be encoded in the same six policy it can perform corresponding behavior of 68 with a 76 banning seed but for us doing well hannah behavior is not specified by bgp as a policy next page uh hal lee before you move on um chung li do you want to ask your question because i presume it's on the previous uh um okay document that was described so chungli please go ahead yeah yeah thank you jim money from huawei so uh yeah it's firstly it's really happy to see the people uh also also thinking in the similar way actually we have some draft to propose some like second list id ident identifier or plus segment something like this already so we can discuss further to see how to cooperate together to avoid multi redundant uh draft in the itf thank you okay thank you"
  },
  {
    "startTime": "01:24:02",
    "text": "and ketan is your question do you want to take your question now or or is it on this uh this other document here no this is a what go go ahead then go ahead catan wait for uh the present uh presentation to get over okay fine um how lee please uh continue okay please the next slide please yeah uh this draft uh hopes to add a handy behavior in bgp as a policy and the head-end behavior is only for srv6 uh next slide please okay the two subtlety are defined for distribute distributing some six policy and the labs subject will specify the behavior for layer three traffic for behavior as defined the right subjects verified behavior for layer two traffic and two behavior are defined uh these two subtitles are optional and must not be a more than once in the as a policy encoding yeah next slide okay let's all okay uh so couple of uh uh clarification and one question uh the clarification is that sr policy yang model does have a name for a segment list and i think uh that should normally be sufficient so i would suggest that you know uh that's something to be looked at the second point is there were feedback here on the bgp sr policy and i would not much rather prefer and i'm speaking as a co-author there i would much rather prefer that such"
  },
  {
    "startTime": "01:26:00",
    "text": "feedback is given on the idr list so that you know we still have a chance to make any changes or you know address any comments rather than bringing new documents so i believe that we have the necessary things there to address this and you know basic behaviors but if you think that it is not please comment on the idr list thank you thank you okay thank you just pulling up the next presentation okay uh please go ahead hello can you help me yes we can okay this is myself along with the ninja will be presenting this draft on problem statement for introducing intent away routing using color next slide please uh so some background on this draft we had a seamless smart problem statement in spring working group and another draft bgp card statement in a best working group so the as the problem statement documents were addressing the same use cases the chairs suggested us to merge this document so the authors from a subset of authors from both the draft work to produce a merged document so this is the first version of the merge document that we have posted next slide please"
  },
  {
    "startTime": "01:28:17",
    "text": "go ahead we're not here in charlotte dj are you there hey uh hey jim can you hear me yeah do you want to take over because we're not here in um sure sure um so yeah so the problem statement uh is you know focused on uh defining requirements uh and of course use cases for uh you know building intent aware paths across multiple domains uh and again focused on our distributed routing solution uh primarily on bgp given bgp is the you know inter domain protocol and many of these networks that are being targeted of course the requirements are general so they could apply to other solutions as well next slide please next slide yeah thanks um so in general why you know focus on bgp uh you know clearly today bgplu is used in many seamless mpls as well as you know uh some multi-year deployments so because operators have operational familiarity uh so some of them expect the you know an incremental solution uh that they can deploy in you know of bgplu um there is an expectation that you know with the you know familiarity with bgp uh it would support uh you know a higher scale than what they are deployed currently and um there is the familiarity with the uh you know the the sort of the trust model"
  },
  {
    "startTime": "01:30:00",
    "text": "when you if you have to go across different uh bgp domains mostly in terms of appearing policies uh next slide please so um so as shraddha said this is a you know merged document so what we've managed to do is uh put together some sections that uh you know with the content uh that we uh would like to see so some of these sections they're broadly divided into two uh you know areas one is um look at some of the typical deployment scenarios uh you know explain some of the use cases so that's uh you know like the first set of sections uh next slide please um and then uh given that uh there is already a set of solutions uh including you know uh you know the srt solution that's been standardized and deployed you know by the spring working group and supported by multiple implementations the there is a section that defines uh an intent aware routing framework uh introducing some of the you know the the base constructs the concepts and how existing solutions work so this is meant to be used as a reference for some of the you know detailed requirements in the subsequent sections next slide please um then we go into uh some details uh you know in terms of the technical requirements again it's uh broken up into different categories there's a section on the intent requirements currently what we have are the transport network requirements specified um in general the the sections that you see underlined are ones that are placeholders you know specifically the vpn uh layer"
  },
  {
    "startTime": "01:32:02",
    "text": "intent requirements the oem requirements as well as the multicast intent requirements the co-authors and editors you know have not yet managed to you know discuss and review the content in you know those sections so but we will address them in subsequent uh versions um in terms of the the other you know requirements we have the steering requirements we have deployment requirements that go into uh you know different topologies different transport types that are you know that need to be supported um a variety of interworking and color you know mapping uh scenarios are also described and then we have uh scalability as uh you know section network availability requirements and finally given that you know the primary target here is bgp there is a section on uh you know bgp protocol requirements as well next slide please um yeah so i don't know how much time we have in general what we've done with the network intent requirements this is not an exhaustive list but there's a you know a number of commonly seen you know scenarios so we've provided uh you know a description of those scenarios with reference topologies and flows uh the uh the idea being you know it will be used as a reference for various solutions uh next slide please again when it comes to steering we start with the baseline that uh you know existing solutions like srt you know support uh we've added some more detail on fallback uh in terms of you know things like ordered fallback across multiple you know intents uh you know the granularity of fallback schemes and so on um and of course you know the the requirement for steering to be supported for all uh services uh next slide please"
  },
  {
    "startTime": "01:34:08",
    "text": "uh again in terms of scalability uh we you know provided some data on you know the target uh scale uh you know and then some analysis on what that entails uh for existing you know designs what are some of the constraints that need to be uh you know taken into account uh and then uh in terms of requirements we focus on two broad requirements one is uh you know to scale the mpls data plane you know the need for uh in hierarchy uh and then also to reduce the control plane you know uh state as well as data plane state uh the need for a subscription based pull model next slide please um so we have gotten some you know good feedback already after publishing this uh first you know zero zero version uh we do request uh you know more folks to review and provide uh your comments thanks to the ones who have already done that and uh thanks also to joel and jyotaro for you know guiding the the merge effort um you know given the time we spent on this and the you know the content and the quality of the document we think it's in a good shape to be adopted by the working group so we request the working group to you know do that thank you thanks dj um you mentioned about working group adoption so um if the document gets adopted then the chairs obviously want to see that front page cleaned up um preferably with editors and everybody else moved into contributors but i'm sure you're aware of that but the sooner that's done obviously the better so if you could take that to your co-authors that would"
  },
  {
    "startTime": "01:36:00",
    "text": "be uh um sounds good thankful from the chairs and the other thing i will just remind all the participants is that the technical work on how the heck to do whatever it is that meets these requirements is in the idr working group not the spring working group you please do go to the idr working group and participate in the discussions there okay we'll go on to the next presentation which i need to briefly introduce okay we are pressed for time this is a brief presentation on the on one of the proposals for encoding changes to the mpls header this is an active topic being discussed in the mpls working group there are multiple proposals what we have here is one of them to give you an idea of what's going on in this space uh hi everyone my name is rakesh gandhi and presenting the m a encoding for everything that's above the bottom of the stack on behalf of the authors listed and next slide please so agenda we won't go through a lot of details about the encoding and bits and pieces but we'll show the salient features of the the encoding next slide please so many thanks to the open design team between pulse and net and mpls there's a lot of work done there for the requirements framework and use cases so this is basically leveraging the work to provide the encoding formats next like this so basically in the encoding we need two things one is the present indicators so there is an m a lab label we call it"
  },
  {
    "startTime": "01:38:02",
    "text": "the indicator for the network accent sub stack and the flags that says there is a in stack or post stack and basically um the second part is the network accents the flags or pop quotes that says that this action needs to be performed next slide please so uh the encoding basically uh there is a label uh this is a base special purpose label that's an indicator and the next lse has the encoding flags in the tc and ttl fields that has a length and the present indicators and there is a flag based network action defined in the second llc next slide please so this is more details about the flag based network actions and next slide please and this one is an encoding that shows the opcode-based network accents it can contain the ancillary data that is used to execute the network accents associated with the opcode there are other fields like the scope and the length also part of the same lse so this makes it a hardware parser friendly next slide please so this is just an example of uh if network action needs to be performed a flag is assigned by inf uh that this flag is to do that network action next slide please uh if there are more than 19 flags required it can be easily extended next like this uh this is the one where opcode10 is assigned to perform some action uh with his data and next slide please so this is an example where if you need to have more than 20 bits of data for"
  },
  {
    "startTime": "01:40:01",
    "text": "the top code it can be easily extended as well next slide please uh it can be encoded with the flag base and of course network actions in the same network substract in the same packet and next slide please again uh it's flexible enough to carry multiple opcode based network actions and end cap node can put the network actions in a certain desired order this is an important characteristic of the encoding next slide please so that the encoding is backwards compatible um obviously that the capability needs to be signaled that node is capable of uh m a processing the acmp is not adversely affected um it does not alias with an existing reserve label so it will not cause an issue in the legacy network the penalty mode ttl propagation will not cut up the m a because we we're leaving the tt ttl and tc fields uh uh as is um and it can coexist with the gsch and other current encodings and next like this so it is aligned with the mna framework and requirements for in stack and posttech it's flexible you can put the action in the desired order it can be easily extended for various use cases we have worked with multiple vendors the encoding is hardware parcel friendly uh because of the fact that the opcode the data the scope the flags the land everything is in one lse uh so it can execute the instruction quite easily in hardware"
  },
  {
    "startTime": "01:42:00",
    "text": "it is msd efficient because you can take advantage of the various encoding formats backwards compatible we make sure it's backwards compatible and ecmp friendly as well next slide please so uh welcome your uh comments and feedbacks um there is very strong interest from multiple vendors and operators and we have requested working group adoption in the mpls working group thank you thank you very much my thanks to all of the presenters who were expeditious and helped us make up the time we lost to do technical issues and the fact we've even squeezed in a few comments i really prefer discussion but we have what we have so thank you very much for your time we'll see you on the mailing list where the work actually gets done please engage i'll take a minute and then i'll be walking around"
  }
]
