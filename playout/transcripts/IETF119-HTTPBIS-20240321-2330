[
  {
    "startTime": "00:00:00",
    "text": "Just double check that it didn't Yeah. It won't. I I, yeah, found the Good. Good. Thank you. I'm gonna get a coffee we're just about Yeah. Let me just make sure that I didn't see I'll go and get this even out well and then It's Rainbrook. Docs. Trig You ready to do that? I'm gonna share that you sharing it? No. I I was just trying to see because the need these ones are not yes, Okay. 6 from Okay. Folks, Oh, we really need to eat the mic this time. Okay. We're gonna get started in just a second. You good? Okay. Okay. Well, Welcome everyone. This is the 2nd session of HTTP. It's later in the week. So, hopefully, you got some coffee outside. Let's get into it are, first off, as always, this as you see on the screen, if you can read it, is the note well? If you're not familiar with this, take a look, on your favorite search engine for IATF note well, and you'll find it. It's the terms and conditions, that we participate here under, which are are very important to us. It's important that you understand this. It covers things like, competition law"
  },
  {
    "startTime": "00:02:01",
    "text": "Believe it or not, standards organizations, one of the primary reasons is just to allow competitors to talk to each other. So understanding this is really to your benefit. It's also handling things like behavior, making sure that we don't treat each other badly. And so, have a look at it if you're not familiar with it. We we take these things serious If you have any questions, p please feel free to talk to Tommy or or any other leadership folks. Our agenda for today. There we go. So, we need someone to take notes. Do we have any volunteers We really do need to have a record of what We do here for our own purposes as well as aforementioned legal purposes. Eric, that's fantastic. If if if folks can give give him a hand while he's at the mic, Thank you so much, and thank you Ted as well. The blue sheets are now automatic. You need to, scan these QR codes that you see plastered all over everywhere. To note your tenants here. And, also, if you want to speak in in at the microphone or remotely, this is how we know, that you want to speak. Please do sign in on those with your data tracker account? Today, we're gonna we have a pretty packed agenda. We've got 2 hours And we have templated connect TCP. And then another, presentation from Ben, security considerations for optimistic use of HTTP upgrade. Then I'm gonna talk briefly about retrofit structured fields and then cash groups. Patrick is gonna talk about compression dictionary transport. Those are all active drafts, things that we've adopted, and we're working on. After that, we've we've got some other presentations that the working group is not working on including HTTP 3 on streams. From Kazuko. Kazuho. We don't have your name on that one, but that's also from Kazuho, I believe."
  },
  {
    "startTime": "00:04:00",
    "text": "And reverse HTTP tunnels. The first of those is is, had some discussion earlier in quick, and now we're talking about the HTTP part of then we're gonna talk about window sizing for Z Standard Content And Coating. And finally, some some discussion about best practices for link local connectivity. In your database protocols. Any agenda bashing. Alright. Let's get right into it then. Ben, Tampa to connect TCP. Are you out there? Yes, you are. I'll, give up a Great. Okay. Packed a short short time window. Let's get started. So, quick reminder, this is the thing we're talking about. It's this thing that's like connect but more like the mask style it involves some kind of URI template So when you are saying I want a TCP socket, to this host and port That information goes in the query parameters. And in HTTP 2 and HTTP 3, this is extended connect. But in HTTP 1.1, there's some kind of tricky use of upgrade, which is exactly the same as mask. Since the last time we talked about this here, there has been a new draft with a bunch of changes. So we added a Some people ask for a default template. So we added that with some text that says you only use the default template if plain connect fails, so, like, we try to use old, good old fashioned connect, But if that is failing in a suspicious way. You could try using this with the default template instead. There's, we settled on Dub, Dub, authenticate as the relevant authentication header, For this, For this purpose, And, relatedly, there's some text now about the fact that HTTP connect proxies don't, well, don't exactly have a clear origin, but"
  },
  {
    "startTime": "00:06:01",
    "text": "Templated TCP proxies have an unambiguous origin And so all the origin scoped headers apply as usual. And, we added a security consideration section. Okay. So this document started a working group last call, and there were flurry of issues. Thank you for everybody for actually reading the draft in Your last call, some of those have were editorial issues or other things we were able to quickly reach agreement on and clean up, but there are 3 issues that I want to talk about right now right now. First one TCP port. So draft 2, says that you can take All these different kinds of template driven things that we now have proxies, UDP proxies, IP proxies, and more other stuff. And you can just kinda squish it all together into one big template And then just by looking at the template, you can see what it supports. You can see from the variables it turns out there are a couple of problems with this. One is that the connect IP specification doesn't actually require that proxy, to support the some any of the variables Literally, a bare any bare URI is potentially a connect IP proxy. You don't have any information. So there's so you can't derive that information from the string itself. And also just sort of more abstractly nothing in any of these specifications exactly forbids you to say like, oh, I just decided to put in an IP proto parameter into my URI template, but that's not because I support connect IP. I just like, putting an IP product variable which seems really weird to me, but anyway, there's it's not explicitly forbidden. So There was a proposed change here, which is to say forget about all this. Use, instead of using TCP port, which makes this, support for connect TCP uniquely identifiable"
  },
  {
    "startTime": "00:08:00",
    "text": "just use target port the same as mask. UDP. And then that means if you're a client and you get one of these things and you don't know exactly what it supports then you would have to either prove it or you would have to know somehow out of band. And so that's The proposed text there for this change. The alternative to this I think would be to define this concept of a multi protocol proxy template, an explicit way, probably create an IANA registry for, like, the things that can be part of such a multi protocol plate and the variables that identify. Tommy, Hi. So just speaking purely as an individual from right here, As you're aware, we have the discussion and the document recently adopted in intera for that discovering essentially, like, getting a JSON file of the configuration of the different proxies you support. And so that is one way to disambiguate things because, like, if you get a, a, a, proxy URL, then you're, like, don't know what this is. You could always ask it for That file and say, my connect IP you're right is this. Am I connected UDP? You're right. Is that? And then that would help tell you so, I don't I don't I'm not suggesting that we point to that from this document, but overall that is a solution space, like, the separate usage indication. So we have Yeah. My understanding is that that's limited to provisioning domains. But to to technically, every So the the the the document within interiors saying that every proxy, has its implicit own provisioning domain. You just ask it for a particular well known URL. Your eye, the well known PVD, and then it can tell you what proxies, specific protocols it has. Anyway, we can take that 7 okay. So Yeah. So I have I'm personally neutral on this On this question, I would like us"
  },
  {
    "startTime": "00:10:01",
    "text": "right now, I think probing is pretty ugly. I really, like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like find this quite unfortunate the usage indication that you have to access via the proxy is also a little weird like, I have a proxy, but I don't actually know what protocols it support. Let's hope it supports TCP and try to use it over TCP to fetch something to find out I don't know. But, Anyway, so that's seeking input on that. Let's move on. Okay. Another topic that, that was discussed on the list the question of happy eyeballs and target host lists? So in draft 02, the proposal tries to do A little bit better for happy eyeballs then classic connect. Classic connect says, you can choose a host or an IP address. But then if you wanna do happy eyeballs, you have to make multiple independent connect requests, for these different families. You have to essentially run hap drive happy eyeballs all the way from the client side. If you wanna do this. It's there's basically a lot of overhead you're you're setting up and then tearing down entire unnecessary TCP connections much of the time. A way that would not happen with normal happy eyeballs. And also the same thing applies even within the absence of happy eyeballs to just multi IP fail DNS Resolution normally returns a collection of IP addresses, And if one of those is down, you expect your your T SP client to basically transparently failover between them. And all of that logic has to be driven from the client side, unless we can pass list. To the server. And so that's what draft 2 and prior drafts of in this line propose. But there was some concern that this is too complicated And so there was a proposal to drop this feature and add it as an extension. But we don't have an extension mechanism. I have so I have no idea. How to add it as an extension."
  },
  {
    "startTime": "00:12:05",
    "text": "Except maybe again through some kind of probing, but I really don't even know how to do the probing. It's it's pretty So it's, it's not clear to me how that would So my preferred alternative is to keep this in think it's that hard to implement on the server and we can thing we can do compared to draft O 2 is to simplify the syntax. So it's just a common separated list of IPs. And we don't hit. And we only need level 3 templates. We don't need level 4 URI templates, which are a little more complicated. Hi. So, again, as an individual, I I'm just gonna have a lot of opinions here. I apologize. I I'm definitely in the camp of dropping this from it. As far as I know, this is not not something Anyone has a lot of experience with. And I would like to see any mechanisms we have here be parallel across the various proxy methods, as you point out, connect UDP Might not. Work with happy eyeballs in all cases, but we also have variants that are aware of quick and, like, I I definitely have done happy eyeballs with UDP. It definitely can work. There's a chance that we may be having a happy eyeballs related working group spinning up that this could totally be discussed in So I I I would go for dropping the feature, and then as far as extensions, we do have the ability to add other headers And as we'll talk about in the next slide, there's possibilities for using capsules, here And I'd like to find a generic solution that would work not just for connect TCP. Okay. I don't actually think you can do this with capsules, but we can talk about that. Some time late late"
  },
  {
    "startTime": "00:14:00",
    "text": "Eric. Ericaneer. Yeah. Hello. Just a note that we're talking about happy eyeballs and UDP and all that stuff. Like, I think the text that says treated as if you got it back from an A or a quad inquiry works equally well for UDP. And if that doesn't give you a massive level of excitement because you're not doing quick, then that's the same as just made a regular DNS query, So, like, I don't think we should over rotate on that. I think we should focus on we make this consistent across all the different places? Okay, Johnson. Trump modem, Kepler. I haven't followed this at all, but just just Why why can't you in this case, Send, a URL to the server and let it handle happy eyeballs, DNS, TCP UDP everything. Everything. Everything. Everything. Everything. Everything. Yes. You can pass in this case, it would be a host name. To the to the server, which it will resolve. And then, yes, that that is uncontroversial. That is the same as The question is if for some reason the client needs to do its own DNS resolution, IP addresses aren't coming through DNS Can you give the server exactly that same information that it would have gotten through DNS resolution? Effectively say, I'm the client. I did the DNS resolution. Here's the answer. Do whatever you would have done if you've done it yourself. Because DNS resolution produces a collection of IP addresses. Thank you. Okay. We're out of time. So I will I'll I'll leave it to the chairs to decide, but so there's also a proposal to use capsules my preference is to say that this can be done at a later date if needed, there's is, as far as I can tell, no advantage to declaring that we're doing this right I'm so sorry. Just jumping in very quickly here. My main con I'm okay with leaving it"
  },
  {
    "startTime": "00:16:01",
    "text": "for a later thing, although I would like to do that like, quickly, and I'm happy to work on that, but I I'm concerned that if we do not mention the capsule protocol at hall. That we could have implementations Yep. That set it and have a different interpretation. So we may want to, like, prohibit the use of it until you have It defines somewhere else? Because we don't want people to just say like, hey. I have my connect UDP. Gonna say a capsule protocol over here, and now they actually don't do it correctly. Okay. Think that's totally reasonable. Tommy, if we don't, tell people that it's a capsule protocol, then it's not And then you've effectively prohibited that, anyway. I think that's the default. It is general We can put in a non normative reminder about that. Yeah. I would I I wouldn't bother. We're also not transporting elephants. We're transporting bytes. And that should be clear. Yeah. Oh, David's Ganazi. One of the 2 capsule enthusiasts in the room. Lucas just walked in, Ben. So I think it could be cool to use capsule for this. But I don't think the maybe use capsule as viable at all. In particular, when we designed the capsule protocol header, We always decided that it meant Nothing. Nothing. It is not you don't have to send it, which is a decision I wasn't happy with, but that's what the consensus was. And so you can't use it for any kind of negotiation, unfortunately. So I think our only 2 options here are either to say This doesn't use capsules, and it's kinda like regular connect. Or it uses capsules all the time, and we introduce a data capsule. I'm"
  },
  {
    "startTime": "00:18:00",
    "text": "Or or you can negotiate with another header. That's right. Okay. I that was from Martin Thompson. I lean towards maybe making this capsule. That's what we're doing with the new things. Having implemented capsule parsers, like it's trivial. But I don't feel too strongly. I just don't want us to negotiate with this. Yeah. Mike Bishop. Two comments here. First off, Do we actually have a use case for capsules with this? Because if we Don't, and we can't envision 1, then let's not build it until we do. And 2nd off, Martin, I admire your optimism that you were able to go all the way through quick drafts. Without Giving up on the we shouldn't say the obvious. We've had a lot of obvious stuff in there. Okay. Where where having great discussion, but we are over time on this draft. So it sounds like, we we need a little this discussion bit of maybe on confirm those things and and a new draft bin. Yeah. Can Thanks for that. one? So you're also next. Do we wanna go ahead and switch to that Okay? So sort of related? But this is about HTTP upgrade, it should give you 1.1 Upgrade. In general, this is a recently adopted Draft. Draft. It is It has no changes yet from the pre adoption text. But there are some proposed changes and some topics that have been discussed in I was Mentioned. So The current draft only makes recommendations to standards authors. Says, if you are defining a new upgrade token. Here are some things that you should keep in mind."
  },
  {
    "startTime": "00:20:02",
    "text": "In practice, those recommendations to Standards authors in turn are things that they should probably tell client to mostly. But there's a proposal that actually, maybe this draft could tell something directly server implementers right now of existing tokens And the proposal is If there's a failed upgrade So if if you have a request with an upgrade header and you don't accept the upgrade Then you should close the connection, I guess, after replying with a non upgraded response. And this prevents and and also, crucially, before reading the next request on that socket. So this basically the whole category of issues that are being discussed here. And it's compatible? Within with any existing upgrade token. So very cool suggestion. But it does slow down basically anything that has an upgrade, reject, retry sequence And that's actually a pretty common sequence. For anything that uses HTTP authentication, maybe I'll just charge ahead. Another suggestion that came up was To say, upgrade tokens should Never have a body. A little unclear, This is my best interpretation of what this suggestion is about. It's it I think it's really about gateways saying Like, if you're before you talk to that back end server, you've got an upgrade header and a body then you can just drop that upgrade header. And There were some concerns about basically confused back ends here, But also this would be incompatible with some of the Like,"
  },
  {
    "startTime": "00:22:00",
    "text": "Welder, long tail, sort of unimplemented existing uses of upgrade and potentially future creative uses of Okay. And the third thing that I wanted to talk about was status of upgrade HTTP 2.0.0 the bottom line here is it seems like This is not actually a thing. The documents aren't very clear about it. And I think we should probably delete it from the IANA registry. And while we're at it, we probably also delete upgraded TLS, which is also like sensibly defined, but not actually Okay. Question. It's not a direct question about this. So I I can let you get to the end of the slides unless you're already done. That's the end of the flight. Okay. So know this is focused on Connect. But, I had a case I was speaking to someone who was seeing, like, an issue on this for just a plain old, I'll make a H1 request. To a server that I can failed to connect to and then What do I do? Do I accept the remainder of the incoming client's stream to, like, dispatch more requests and answer was no. I'm just gonna close the connection because I can't like, this whole thing is completely blown. So Yeah. It wasn't an upgrade. It was literally a post or whatever, like, I Is that already covered in the HTTP specs or not? It it was it was malformed No. It was, like, you would make a request to a reverse proxy, and it would try to pass that to one of its configured Upstreams, which wasn't there. When it would return its server error, but then it couldn't safely process the remainder of anything on that connection. So it The safest Why not? Because we would maybe read the the post request body is the next request to be made and forward that somewhere. That should be unambiguous. Thomas. From the from the gateway's perspective."
  },
  {
    "startTime": "00:24:01",
    "text": "Maybe. I don't know. I'm I believe a gateway can can like, read and process an entire post request. Amazon. I'd love to talk to you about that after the session maybe. I I think in this case, I had, like, no content length, and it was a was too risky. So the safest thing was just Fail. If know. there's if there's no message, let me But we can point to parts of the spectrum. Sorry sorry to confuse this. It just friend to mind as as we're talking to this, and it happened, like, in the last 2 weeks. So Thanks. Thanks. Okay, Ben. Did you have anything else on that spec? Those are the only issues I wanted to mention. So you know, I'd like to Get some more input about these topics so that I know what to do with next iteration of this draft Sure. Please please engage. Right. Thank you very much. But any more comments on that? Okay. I feel like I have to re really close to this mic. No. That's better. Okay. Wow. Okay. Next up, I've got, retrofit and then cash groups. Both should be very brief. Let me try to share a screen here. No. Not chair slides. Well, I I need to stay here, though. So I'll just Hello? 1, Is it? Yes. Good evening. Okay. We've got this one up, and I will make it more legible."
  },
  {
    "startTime": "00:26:04",
    "text": "So first of all, retrofit fields, this spec we have been lightly parking for a little while while we got SF Best done. Excuse me. And SFbis is almost done. It's in in, final ISG stages. So, we're gonna return back to this and for me, there there are a few issues here to work through, which I won't go through today. But, the thing that that caused us to park it was that this is a very abstract specification. It's talking about fields. And we don't we we have use cases in mind but they're not in this spec. And I think that there's a little discomfort that we're not entirely sure what the sharp edges are on these until we use them in anger. So I'm I'm starting to think about how we can do that and and get some experience with these before we actually publish it. So if anybody wants to talk about that in the background, I'm very happy to do so, but this is really just the status update that that we're gonna start. Trying to get this one moving again. Now that SFbis is done, And any discussion comment on this draft? Otherwise, we can move on. Martin. Yeah. I'm I'm kinda curious as to whether you have any thoughts about what what getting moving looks like. Firm thoughts? No. Half baked thoughts, talk all day. Alright. Yeah. Okay. Yeah. So thinking then Yes. Wonderful. We're still in the thinking phase. Yeah. Yeah. And then, you know, when I talk to people about this, I think a lot of people nod their heads and say, yes, that is a very intuitive, natural, and and wonderful thing to do potentially. But we have to get it right if we're gonna do And that's the tricky part here. And I for the record, Martin Thompson is nodding. So unless there's more discussion on that, I'll I'll just move on to cash groups."
  },
  {
    "startTime": "00:28:05",
    "text": "So cash groups, this is a specification to, standardize what is a fairly common behavior at least in intermediary caches which is, allowing the origin server to tag different responses to, tie them together so that you can do things like invalidate them together. As as a group. And that turns out to be a very useful thing to do, for for the origin server or for the resources on And, this is a fairly straight forward spec because there is implementation experience with the con the concept I think my issues right now are 2 things. One, what the details of of of required support are in in terms of how many labels should you support for each response and so forth and so on. And, I did a little digging around the documentation of the folks who have implemented this at least the CDNs, and they seem to converge reasonably well. There's a proposal in there and take a look at it. I'll probably write some text for this pretty soon. And the other was that there's a very, thought experiment y kind of, feature in the draft. Which is if you group a bunch of of of resources or or sorry, representations in a cash, and one of them is revalidated. It might be interesting to assume that all the other stored responses in the cash with that group are also revalidated at that same time. So they kinda go together as a flight. And that has some very interesting properties, but it's also extremely speculative. So I'm thinking of because we don't really have any implementation experience with this at all or any any any measure of demand. It's just really interesting to think about. But that kind of says to me, well, maybe we need to that we have an extension mechanism so that future uses like this can be lumped on to cash groups. And so I wanna Other than those 2 issues, I think this spec is almost ready for working group last call."
  },
  {
    "startTime": "00:30:00",
    "text": "So if if folks have any comments or thoughts, I have talked to various for implementers about this. There is some, interest in this I think they're just waiting for the spec to to settle down. Do you wanna change the name of this of the specification. If you're not gonna do the revalidation thing, see David's discussion of bike shedding on Tuesday. This the the current name is a little bit of a compromise because the different vendors call this different thing and I didn't wanna favor any one vendor. So with that constraint in mind, I'm open to new names. Yeah. I mean, if it if the sole purpose of it now, at least is invalidation. Then then that might be something that you could Good work in there. Just so so it's clear. I think there's But So to to be honest, no vendor currently refers to invalidation in the name of the on the wire artifact. It's always something like Here's a tag or here's a, you know sure. Sure. And then it seems intuitive to the user. that that So so Yeah. But here, we're we're talking about names. I'm I'm very happy to be talking about names on this draft. Any any other feedback, feedback, feedback, Otherwise, we can steal some time. Okay. Let's move. So next up, we have compression Transport, Patrick? Are you there? You are. Fantastic. Yes. Alright. And, Patrick, do you wanna share your own slides? You can To click the share You go. can click the share slides button, and I can create your permission. Okay. Here we It's just Alrighty. So quick update brief overview for anyone not aware of the compression dictionaries. Allows for negotiating any response to be used as a compression dictionary for content encoding for"
  },
  {
    "startTime": "00:32:02",
    "text": "future fetches or future requests There's an HTML bit that allows for side loading, dictionaries if they weren't going to be fetched as normal part of operation that's not part of the spec. Then at some point in the time later, browsers advertise the available dictionary they have that best matches the request they are about to make, and the or and as well as the encodings that it supports, and they can tag the Naries now, with an ID. And the server, if it chooses to use the dictionary, specifies which dictionary it used and what content encoding it chose to use. Updates, Chrome 123, which is rolling out literally as we speak. Has all of the changes in draft 3 in a new origin trial for compression dictionary v 2. The original origin trial that we were running up until this release was pre HTTP biz adoption. So there's a fair number of changes that are included in the current origin trial. We're hopeful that this is the last origin trial, to sort of get our feet wet and make sure it's actually working the way we think people want to use it. And there is a new draft, that was sent out, just shortly for things got locked down. There are 2 bits that are sort of tangential to the IETF side of things that are, what WG specific the HTML tags that I mentioned for fetching or triggering effect of a dictionary, needs to get added to the HTML spec. And the fetch integration with the course processing model of browsers, just needs be flushed out and the the fetch spec for what WG. But the core of the protocol and everything else is owned by the IETF side of things."
  },
  {
    "startTime": "00:34:04",
    "text": "And the explainer and everything else will be moved over shortly. The changes that have been done in the 03 draft since the previous time we talked, The server now has to send a content dictionary response header with the hash of the dictionary it actually used, rather than just assuming, a match with the request, header the advertised dictionary from the client. So now it's more explicit The dictionary hashes are now, binary or byte stream. So, basically, base 64 encoded instead of a hex string, dictionary specific time to lives have been removed, and now a uses the resource expiration time plus stale while revalidate time, of the dictionary resource self as the the time that the dictionary is valid to be used as a dictionary for. Match instead of its own custom, wild card pattern matching thing is now a URL pattern the match destination match desk, is now a list so you can match document plus script plus style plus iframe if you want. As far as fetched or request destinations. And there is now an ID that if the Dictionaryry response includes an ID with it. It will be echoed as specified as sent. In future requests where that dictionary is being used. So intermediaries or the origin, can key off of the ID and instead of having to look it up by dictionary hash. The open issues that were live at the time that the slides got locked in."
  },
  {
    "startTime": "00:36:04",
    "text": "Kind of an old one, or these are all fairly old. Question if we should split in two documents, I think enough has been changing in all parts of the document that is probably best to just keep it as one document. And just keep running it as experimental until we're sure it's the way we want it to be. It's flexible enough I don't think that'll lock us into anything that we can't add to later if we wanted to. There's some concern about the match, pattern allowing for users to must be same origin as the request. Unfortunately, Earl pattern doesn't have a string based constructor that allows for excluding or Not allowing origins to be included. They don't have to be there. It's encouraged that they not be there because it's a waste of bites but we don't have an enforcement mechanism, to prevent it. And then there's just a a placeholder to make sure the ZsDC stuff that the Edge team rolled out, that's Bing Microsoft edge specific, that their use cases are met with work, and we've been talking to the team. And so far, it looks like it, but I've been keeping this placeholder open until ZsDCH can be rolled back and unshipped. And then there were, few issues that came since that are probably more interesting. So there's a request that we specify a single compression algorithm instead of allowing both Z standard and Broadly, so that for adoption reasons, we don't have to have clients implementing everything if they want to be able to, support arbitrary, origins"
  },
  {
    "startTime": "00:38:00",
    "text": "Then that will lead to some question about which algorithm, which feels like it's gonna be an interesting discussion, but there are benefits to both the issue is in the repository so we can discuss it there. We need to, be explicit about the window sizes that we support for the compression algorithms that we do take up. Nydia will be here talking later about the z standard stuff. That's specific to Z standard encoding that's not dictionary inclusive. The dictionaries have a special sort of edge case that For Z standard at least the compression windows, need to be larger than the size of the dictionary otherwise by the time you they treat the dictionary as sort of cursor as part of the compression window. And if the dictionary if the compression window is not larger than the dictionary, there's a good chance you watch actually won't be able to do Delta encoding. And so if we support Z standard, for dictionary compression, We need to support fairly large compression windows. Probably on the order of a 128 megabytes, which is what the the default for the CLI is for Z standard. Broadly, I don't believe has the same issue. The dictionary is always available to the compressor and decompressor and still works with the 16 meg default window. And then the the final sort of open question is if the match pattern should be a single pattern, or if we should allow for a list of match patterns, allow for a dictionary to to perhaps reference, like, a script location as well as itself, as separate patterns. So it can be used as a dictionary to upgrade itself. And, some edge cases. It feels like that's something we can probably extend later but it's worth discussing and the dictionary matching requires a linear search through all of the available dictionaries anyway,"
  },
  {
    "startTime": "00:40:00",
    "text": "because there's no way to a hash lookup, a pattern. And so Adding it as a a list doesn't really change that. Some other questions. When we changed the origin trial in Chrome to move to the latest spec there has been some pushback about moving, to the byte stream format for the available dictionary hashes. I don't know that it's a deal breaker. It's just there has been some friction of using the base 64 hashes instead of hex strings just because they're not file systems safe. That said, people probably want to be doing more processing to make sure that the URLs and hashes are safe rather than just mapping them directly to the file system. So the added processing step might be a good thing, to make them be more intentional about it. And that was all of the updates and questions I had. Great. Thank you, Patrick. Great. Thank you, Patrick. Any discussion, any questions on this spec it it's great to see progress here. I think everyone's very excited about this one. I will say the origin trial feedback we've gotten so far has all been very, very positive. With some fairly large savings being seen in production for, at least like, a JavaScript use case that I know of. Awesome. Lucas. Yeah. Just just a thought on the the the last point, the byte string. This is text string stuff. Like, 2. Who's using file systems now these days with, like, cloud object storage"
  },
  {
    "startTime": "00:42:02",
    "text": "Like, I don't stuff. So just I don't know anything about this just to agree. what So it's it's more that could have been done before 4 is the Request header of the available dictionary could have been tacked on directly onto the URL. And tried as a request, basically using edge functions that are already available. And then if the origin just added the hash to the end of the file name, It would just work, with minimal processing. Even for objects stored in the cloud, for example. I I just wonder how how often it is that, you know, a server receiving require for a path has to go through a bunch of remapping into whatever their object storage IDs are. I I have no no understanding, but maybe that's just, really easy operation that people already are doing. I mean, it's fundamentally very similar to storing dotgz pre zipped Right? files for g files. In this case, it would just be dot hash. Martin. So, I know this is not implementation deployment report but I'm I'm very curious about about about the split between the the the use of this for deltas and the use of this for have an arbitrary dictionary that's gonna match a bunch of resources and I'm I'm gonna use it there, the the use as dictionary case. Because I see the the form of being relatively straightforward to implement. And the ladder is being far more complex. This is the matching stuff. And when you when you said, oh, you have to do a linear search through all the all the patterns in order to find something that"
  },
  {
    "startTime": "00:44:02",
    "text": "rang alarm bells for me. I I I don't know how scalable this will end up being on on the client side, it has to do the linear search So if you have if you're not using match desk for destination match for, like, document or script or whatever. And let's say you just have match all requests And then you have a 10 dictionaries on on an origin, for example, each one would have their own pattern. There's no way given a request to have a look up for patterns, without looking through each pattern, for example. Right? And so you're kinda limited to the global number of patterns that you're going to have on an origin that the more that you add when you get into the, like, if you have thousands dictionaries on a given origin and you're having to do a linear search across all thousands. That could start to become a problem. We have a solution for that problem because that sounds like a real problem. Not really. I mean, You could probably do things on the client side to optimize if you have prefixes for all of the paths and the paths are all relative and your patterns, you could do something a little faster But, but, given its It's very similar to the service worker, sort of pattern matching where if you allow arbitrary patterns and it's not just a prefix. It's hard to be more optimal than that. Okay. I think And applies it to both both the Delta Compression and the dynamic case because both need to run the pattern matching, because even the delta compression, it's one URL to a different URL. Okay. Okay. What? We we probably need to talk about this a little bit. Because that sounds like kind of a denial of service vector. To my. I mean,"
  },
  {
    "startTime": "00:46:01",
    "text": "As far as the denial of service vector, it would be an origin denial of servicing itself because only an origin can set dictionaries for that origin, That said, a given origin can have thousands of product teams that don't talk to each other. The client's still doing the work. The client's doing the work when fetching requests Right? from that origin. So it it only looks at the subset of dictionaries that came from that given origin. And to be fair, it's scoped by sight. So the the site and origin combined. As far as, partitioning for the dictionaries. Martin, I'm wondering if you wanna maybe have a think about that. And think there's something there open an issue, Okay. Have to think about it. Any other discussion, we're actually doing pretty well on time. So if if there are any more things we wanna talk about here, We've got the time. I'm not seeing it. So thank you, Patrick. That that's a great update. It sounds like we're making good progress. Awesome. Thanks. I am. And and I look forward to seeing more of the results as as you guys are doing some deployment. Kazuo is next. You've got slots for that. Right? Yeah. Yeah. You know, do you wanna present your own slides around me to Okay. So this is the HTTP 3 on streams. Thank you so We have the discussion at the quick working group, and reflecting that we have added more slides, more information, the feedbacks. So thank you for all of them. And this time, I'm presenting with"
  },
  {
    "startTime": "00:48:02",
    "text": "Call presenting with Luca so I have left me to speak. Next space? So let's recap. Quick is that huge success has We know. And we are seeing broad adoption. Next, please. And the TCP continues to be used at least as a fall, but And there are so many examples. HTTP tool being the most prominent, ma'am, but mock wave transport mask, DNS, there are all the or the other prop protocols that are built on quick and to get TCP. Next space. And it should be 3 projects. Will continue to to want a TCP format. Yes. So, you know, any math enthus us in the room will be familiar with the various protocols we support tunneling over HTTP. Some of those really benefit from datagram is properly unreliable. Flows. Other things just wanna do loads of multiplex. And so to be able to have one connection to your proxy, and, shovel out a different stuff over it. So the features of quick unreliable streams that don't block each other and and and sorry, stream reliable streams that don't block each other and data grams. Makes sense to start a mass proxy using quick and HB3. But we know some users can't use such services for whatever reasons, whether it be a network issue or something else, and they wanna increase their reachability or their availability. So a fallback option is needed. You didn't start with that. You start with picking out the biggest population of users with the biggest benefit at performance and everything that quick can offer. For a kind of an alternative mode, performance regressions are acceptable. It's often better to be able to reach something even if it's slow bit annoying than having complete avail service availability outages. So from that point on, you would look to maybe add a TCP fallback option."
  },
  {
    "startTime": "00:50:02",
    "text": "The natural one because of the way we design mask would be to fall back to HTTP 2. But for a, say, like, a new project that I'm familiar with, that is a completely entirely different software library, a different stack effectively. You're talking TCP, the interactions with your library and its system dependencies or not and your optimizations etcetera. You might have already done that if you're not working on a greenfield project. That's a solved problem, but for for for people who are trying to ship something new, having now to import, a whole load of dependencies legacy problems. The things that are wrong with quick. So nothing wrong with quick. For the incident. Things that are wrong. So I think on the next slide, So it gets more specific about these things. I like because they were to this one, and then I'll go into a few more things I hate with hate should be too. Right. So this is the list of all the pile that we have on Both HTTP to manage. Sorry. On HTTP to we have pack and only chips where we have coupons. So they had a conversion. It's different. Priorologies are applied differently and mask has Datagrams on sugar free, but on sugar, you have to always use CAP So there are 2 ways of sending things. And web transport has essentially ported the quick features onto HTTP 2. And we, as we develop new protocols for quick, and having the knee to to to support TCP as well. We have to do all of those all those repeated work once again and again. Next slide, please. So one of the things I really hate with H2 is that concurrency is really broken. We had a a really fun summer just post IETF in San Francisco. Dealing with this, not just we use cloud flag, but many other cloud operators and anyone effectively nearly every"
  },
  {
    "startTime": "00:52:02",
    "text": "No. That's a lot, actually. There were a number of implementations that were affected, and there were a number that went But effectively, what that highlighted is Just a brokenness with the design that we had fixed with quick Right? We we came up with something better, a way to vend stream concurrency, that avoids all of this So the problem that we had is that, by default, HP 2 allows unlimited concurrency. If you don't receive a settings frame that states a different value, this is as a client. Right? You're gonna be opening request streams. In fact, be allowed to open any number, and that creates work and resource commitments on the server side. No clients that are well behaved, as stupid enough to try doing that. They limit themselves to a 100, and 100 is like the value of ours. Probably sensible provide least a 100 streams. And that's what they picked because they the implement specs by example, not by the the requirement tax in them. What this means is that any server picking less than a 100, breaks the assumption that the client made. But but in my experience, clients sometimes just don't wait for settings and just yolo. And and and what doesn't cause a connection error in H2. In H3, it would. If you blew currency limit because it's designed well, you would close the connection. But in h 2, you just reset the stream carry on. And maybe then you go, oh, you research too many. It looks dodgy. But that's adding heuristics and kind of I don't know. Stuff stuff that isn't in the back about behaviors, goes as interrupt issues and wastes time with people. And the rapid reset attack specifically isn't even anything to do with concurrency limits. You could set 1 and you could still rapidly reset for infinity. As a client by just sending two frames in succession, like taking five bytes and repeat that hundreds of times per single packet."
  },
  {
    "startTime": "00:54:01",
    "text": "Was discussed back in Prague. I presented at UFMRG. If you're more interested in going to the details, we had a side meeting too, and we discussed some of the possible options at actually fixing this properly. Everyone's got a lid on it now. They they address the resource allocation problems related specifically to the rapid reset problem? Or they should have. If not, they're probably offline. But, like, we can't fix this real, like, Being conservative with the number of streams that you can allow a new client present on you. So everyone's stuck effectively. If they want support and interrupt, we're having to support a 100 connect as I request. So to try and fix this, not on top of similar draft to back port the quick model for stream concurrency back to to HP 2. We discussed this in the side meeting. Takeaway from that was there wasn't that much appetite for it. Know, if there was, we probably would have been having an adoption call right now, and people would have been actively implementing it or whatever. Part of that was, you know, it's an extension. So, yeah, sure. Great. The good guys are gonna it. at the extension, and and the people who don't care will just ignore That adds, kind of fragmentation already to the to the what you can do with H2. So if you go on to the next slide, the activation energy, right, if you're gonna if you are gonna open up the bonnet on your card to change the oil, might wanna do things like change air filter and other stuff. Right? You're gonna you're gonna do more work. And therefore, it might be more attractive to people or if we were to bundle a list of changes to fix the rest of the stuff we don't like with H2 to address a known security availability problem that was rapid reset. What would you wanna do? What is your wish list of of stuff to fix. So I went away and wrote something called hb2plusplus as a spec, which was my personal one."
  },
  {
    "startTime": "00:56:00",
    "text": "Mark suggested I opened an issue on the HP repo to turn that into a list of not not requirements, but things that person I would like go and visit that. And this is just a summary of those things. So the first one, bad is stream concurrency control. Yep. remove server push. Alright. You know, this has been a long thing in in the IETF be that's never feasible. But that's something I would like to do because it's code that's just wasted. Forities has already been mentioned. We've deprecated that. Guess what? That's a setting. That's an extension. That's something you need to support both with now. Already in H2. We have things related to the extended connect. If you remember, we had a WebSockets discovery session, presented ideas how we fix that. Again, not much appetite just to point fix that one. That suck. Whatever. We have this this kind of H2 specific encoding of values, which means that frame service certain size. They're smaller than the frames you can have in htp3. By virtue of quick. So we end up with an impedance between those two things. Any proxy that's trying to convert between stuff. Now has to do something, and that that conversion isn't specified anywhere. It becomes an implementation matter. That leads on to point 9, which If you need to send really large headers, you have to send continuation frames. And that suck. So, Just remove those 2 because you can just have a larger frame. There's flags. We have these flags on every frame and they're never used by anyone except for very specific cases, not used by any extensions, blah blah blah. This whole the stuff like, you can see it goes off the bottom of the slides. So we're going to the next slide. Do you wanna speak to this phone, Kuzu? Alright. Right. So some people might think that now that we're down with all the stuff that we want to do with H2, maybe just we can keep it to running our own, but"
  },
  {
    "startTime": "00:58:00",
    "text": "the truth is that people still keep up keep coming up with new ideas to extend a GP. And then we have to extend the GV to an issue 3. Think about 600 subjects, you know, adapted it. Last I at last idea, and it's going to extend HTTP to once again. And there's also about extending changing the static Compression Table, and it applies to its pack and q pack. So we are still doing those kind of things. And moreover, these complexities being added is an additional part I mean, supporting them in the media requires additional logic because you then have to convert the HTTP 2 version of web transport or whatever to HTTP 3. You have to do that for mask. So each extension being added is a requires a new conversion logic, to be added to the intermediate. So it's just a pain to have H2 and H3 being a continuously extending in different ways. 5, please. Oh, no. Right. So then that raise us. I mean, that All those, all these recognitions, raise the question. So TCP UDP supports both ipv5 you write one code, and it works on both. So the question is, like, can we do the same for quick support quick on top of UDP and DCB and write once Right? Cold once. I'm from it. Run it everywhere. Next space. Right. So that's where I click on stream scheme. This the idea is to backboard a quick API contract. Or specify the quick strings onto TCP and run everything only 2 to 3. Next please. So if you're gonna look at trying to provide a way to express quick over reliable streams, that provides capability layer that Casero was talking about. And and what I wanted to do is take my wish list of stuff,"
  },
  {
    "startTime": "01:00:00",
    "text": "that, you know, everything I hate with H2 is red and says, no. Like, we can't actually get better stream concurrency with H2 Realistic we can't have no priorities without it being extensions. So it's unrealistic. We can't change the way that settings interactions occur. There's there's a number of things you you just really, really hard to fix. So HP 2.1. The chest hate me for saying that. I saw the look of disgust inside of my eye, but you know, is there enough energy in the room to try and iterate hate 2 to keep some of its binary wire format but change some things. So it's similar but incompatible. Maybe, you know, we'd have to go through and discuss each of these points 1 by 1 and go through and I'm opinionated, and not not to take A long time. And that's fine. That's consensus building. But to the point because it was just made, that would add yet another vision of that we would need to translate everything between, which sounds like really painful. But if we look at what the features are that I like, and I want. They're already there in HB3 by and large. They're just it would just come for free. Apart from removing silver push, I lost that by all in Mandating Connect. It didn't exist. But maybe there's something we could do clever without. I don't know. And so if we were to try and consider what hb3 over quick on streams provides. It's everything that HB3 already it's not even that it's, compatible from an implementation active that you could tweak a few things, pick this up and drop it in. It's that feature by feature all of the mistakes we made in the past or that we've come to realize a of the sharp edges of to are already fixed. I don't wanna waste time trying to relitigate some of those choices we made. That might be different. It might require even more work and implementation to a good bit between the two. Next slide. Right. So what should be our goals or non goals? I we think that the goal should be to eliminate the need to develop new things on top of 2"
  },
  {
    "startTime": "01:02:03",
    "text": "proof profiles, as I said, and to run a modified HDV3 on top of quick on streams and to eliminate a need to deploy 2 HTTP versions. And that could come immediately when you control both both sides. I mean, if you own your own client, and it's only the one that you are talking to Then you can just use quick on streams and just use HTTP free. You don't you no longer need it should be due as a fallback. And the other goal is that we want to reuse existing quick HTTP 3 implementation. That's by doing so, we reduce the work or the attack surface, even though we create a new variant. And the final bullet point is that for people who want to optimize for the underlying under underlying transport, we could always expose a the properties like, oh, this is a reliable trial or or this is like TCP. And then those applications can optimize. And on the other hand, the non goal have been that we don't want to spend optimized sync TCP, all optimizing quick frames because quick roll over UDP works in most cases and we'll be able to or we know that it performs better. So click on streams is solely a fallback. Next, please. So the design of graph 00 looks like this. We have a new open for HTTP 3 on street. So I maybe it could be a street. I don't know, but Let's keep it. Let's keep it in the back And we send a minimal set of quick real frames on top tcp until us directly, and they are only stream related or datagram frames. There are no act frames because that's, implicit. There's no connection idea of those things because the connection is managed by TCP. And the transport parameters are exchanged using the first frame called US transport parameters,"
  },
  {
    "startTime": "01:04:00",
    "text": "And the minimum maximum frame size is 16 kilobytes. I mean, for example, you can send stream frames of larger 16 kilobytes because That's the equal size of the heels. And for what's left, I was able to create a POC working for quickly, our quick stack. In half a day. And it took another half day to use that in the h 2hv3stack. So it's I it's it's only depends on each person or each step, but me, it was very trivial to implement HTTP 3 on streams. Next please. So people have raised concerns, and I think they are valid. So let's go one by one. Oh, the first question that I want to discuss is that their application layer protocol is going to suffer if they are assuming UDP because it's quick and then get TCP. I think that's a valid concern, but the compliment is that for at least for HTTP, We know how to mod multiplex and write efficient protocol because we have experience in HTTP 2. It's only about moving the multiplexing layer from using HTTP two frames to quick frame. So we have that experience. Things might be a bit different if the protocol to be run on top of pick is different, but As we said, we could expose flags much like when transport intends to do press whatever HTTP 2 intents. So that's all we already have the design that we think we work in the white transport working group to handle this problem. And regarding the performance versus HTTP 2, basically, it's about just about changing the frames you being used for multiplexing. So we expect that the performance will be comparable to HTTP 2. And the next question, next one so is that, yet another having a yet another way of doing HTTP is adding Compressed day, and exposing us to new security issues. But as I said,"
  },
  {
    "startTime": "01:06:01",
    "text": "we can reuse our quick stack. We can reuse it our HTTP 3 stack. So It's not like having an entirely new set all stacks that you have to deal individually So I probably agree that the additional attack surface. So additional complex is not that bad. And if we consider the fact that we no longer need to extend HTTP 2 differently, we are reducing the attack surface at the same time. So it's unbiased. I mean, people might have different opinions regarding how they are biased, but It's not just a one side game. And to the next point, the people argue that providing a fallback providing a good fallback reduces the pressure from us pushing people to the quick site. Or the UDP side. But I mean, it's it's fine because I I agree with that, but we actually creating fallbacks on DCB. So I think we just would rather just accept the The reality and do this because it reduces our pain. And one thing to mention is that quick on streams. It's never going to be as performant as quick. So they'll be always incentive to move too quick, and I think that's a good thing. So I think this is my final slide. So Right. Oh. The other slide is going back to the Alright. So next please. Yeah. Yes. But the the yep. Okay. Thank you. Questions? Great. Thank you. So we we have a queue building, we have a reasonable amount of time to discuss it. I'd say a good 15 minutes. So first up, yaroslav. Hi. I, that's very, very interesting brief proposal. I think that although it's unlikely to achieve its goal of allowing application applications to run solely on HTTP 3 stack today."
  },
  {
    "startTime": "01:08:00",
    "text": "Majority of enterprises block UTP 443, not because they don't know better, but because they are proxy firewall and firewalls and other, enterprise things that do, web filtering that performed less money in the middle are not capable. Of processing, quick. So they block it to force things back into TCP based HTTP that they can inspect and intercept. Now if you're introducing a new way to send HTTP with new AOPM. Then guess what? Those things will still not allow that a LPN to come through And so to retain service availability for those networks would have still to support both versions for HTTP 3. And, HTTP 2 or HTTP 2, point 1. So with that, I'm not sure if this proposal will solve a quick adoption, challenge. Thanks, Sarah's love. And and I'm not gonna disagree with you there. But to to respond specifically, if if we take my would call it bucket list because I think Janice, China said we'd never solve this in our lifetimes but may maybe I could before I die. Like, If we change the wire image of H2 to some of the stuff I'm talking. Like, that would be different. And such metal boxes wouldn't support that either. So I don't wanna I don't wanna exist in a world where we're not allowed to iterate everyone, hate 2. We have extensions. We're literally adopting new work to keep iterating on H2. But if we're stuck with all the broken stuff, that's not great. Like, so whether it's h two that is called h two in a bit, and it looks like quick or it's h 3, and it goes over TCP. Those boxes, I'm just gonna break the internet if they continue to block stuff because they're too lazy to get with it. Right. And we have we have a That's if they don't"
  },
  {
    "startTime": "01:10:00",
    "text": "Do they support H2 today? If they did, they realize the benefits of doing some work to allow it. If they don't, they're blocking it already and it's not a problem I'm aware of middle boxes that have added support for intersect in Quicken H 3 Great. Some don't. That's complete within that remit. So I just My my concern is it's a completely valid point, but it's unrelated to some of the other quick blocking concerns that we've had before. Okay. What I'm trying to say is that even if you if you deliver this proposal, then the number one goal that don't have to maintain two's tax is unlikely to be accomplished in near future. And if we focus efforts on making shining, great unique applications that show fantastic performance benefits and all other great things about, the that depend on corporate HTTP 3, that might push for faster click adoption. Sure. Like, like, like, as I said, I'm I'm aware of middle box that are already adopted support for quick wire image. And it to me, it seems more likely that, fixing H2 with the same wire image would be a fast the path to deployment than creating yet another wire image and waiting for those folks to catch up that's just my personal opinion. So let let's try and get through the queue. I don't know. Yeah. I think we have to resolve everyone. Cool. Alright. So me, Paul, is speaking as an individual, so so Even like before this, I've been thinking a lot about how to let clients who have UDP blocked locally still access, quick and UDP generally. The comment I wanna make is about, like, how we about this, and it actually relates to some of the stuff on the chat about saying, oh, this is not quick, etcetera. I I'd like to maybe challenge us to think of it a different way to think of it more Like, up, up, proxy. Like, we're just gonna run quick over a TCP based proxy or, like, a tunnel in order to you know, bypass the thing that is blocking quick."
  },
  {
    "startTime": "01:12:03",
    "text": "Because that's actually something you can do today, and I actually that's how we're currently doing it, you know, we can run, connect to UDP, on an H2 proxy and, like, it has inefficiencies, Absolutely. But it lets you do this. It actually lets you access the thing. And then you could, you know, very simply just say, hey. Next to my you, like, My main server just offers some essentially legacy translation proxy. As a way to have everything end to end actually be H3. And, you know, we earlier said that for these cases, we are always going to be accepting some performance regressions. So maybe it's, easier to approach this by saying the the the model that actually already works is that we can run this over proxy, and then we wanna figure out ways to decrease the level of performance regression of teaching quick Hey. If I if I tell quick that on this path, you have a reliable substrate, turn off your level of hacking. If you have an already encrypted substrate, figure out how to turn that off as ways to reduce the harm of performance regressions, but you still have like a baseline that actually works even without that. I think one of the benefits of doing that approach is that allows us to still get you know, end to end quick where we can actually do migration and multipath, such that if we have a session with age 3 or whatever it is to the other side. Which, you know, it could be some other quick thing that's on h three. Maybe I start on a network that's blocking UDP, and I have to do this thick translation over TCP, but then I can migrate and have another path the same session that's on a different link. And I don't think that's possible if we think of this as a that is quick on streams and is not compatible with end to end quick. Okay. I'm up next. Again, speaking as me. So, Mark, not him. I like this proposal. We talked about it a lot the other day, Lucas. I think inter it has a lot of merit in terms of"
  },
  {
    "startTime": "01:14:02",
    "text": "simplifying the stack and unblocking us from doing work in the future and and and and reducing the complexity of of how all this interacts My my observation, though, is that Seems like most of the benefits that it brings accrue to implementers and the specifiers and to most deployment there's not a strong reason to adopt this. And so, you know, experience has shown that that when when there's not a strong reason greater protocol. People don't upgrade. And so I think we have to conclude that there gonna be a lot of HTTP 2 deployments out there once we do this. And so that makes me concerned that we could be in a world that is is more bifurcated where there's common HTTP 2 deployments and we're really paying attention to those because all the shiny new stuff is on this. And and that makes me a little uncomfortable. Because frankly, a lot of the, you know, attention of of of what we're doing on top of HTTP with things like mask, and I know people are very enthusiastic about that. There he is. You know, those are used by a very small set of on the internet. Right now in terms of deployment, and the the the larger deployments are more vanilla. And and maybe they're okay to just sit there, and maybe they're getting all the value they need. But we still need to pay them attention, I think. And so that's center of my concern around this is we need to think carefully about how this is gonna play out in deployment I think you are the slums concern came to that a little bit. You know, you know, because for better or worse, those people are deployments too. I'm just to respond to that specific point about deployment, it's it's it's it's it's it's non trivial to, create a way to speak quick. Right, and have this scalable and robust, we have things like low balancing specs, on rooting you to be like, there's a lot of work beyond, turning it on So, Being able to focus the feature set on, say, 3 and make that"
  },
  {
    "startTime": "01:16:02",
    "text": "easily deployable for such services where they can just We use that TLS and TCP infrastructure seems of the benefit to me at least. So so as a respond to your response, I agree. And I think that is one possible future, and so I'm super interested in things like is somebody gonna do the Apache module for this, for example. And is it gonna get that deployment where I can deploy it on my little tiny $5 a month cloud server, then I think that's much more interesting if there's natural upgrade path. But we shouldn't assume that that code's gonna get written, and those people are gonna do those upgrades. Yeah. Alan Findell Mehta. Thank you guys for, bringing this work. I think it's really interesting, and I'm really in support. Think even just taking a step back, I think the quick on streams, Protocol is it's a very valuable protocol that has a lot of use cases, even if you don't think about what it could mean for HTTP. So There's not currently a generic multiplex protocol that runs over TCP. HTTP 2 is the, like, the next closest thing, and it really really doesn't meet the mark. You know, for example, we have an RPC system internally, which runs over TCP. And it uses multiplexing, but it has its own transport stack. If click on streams was available, we would use that and have only one active support. So I think there's a lot of use cases for this protocol. That go beyond what people are maybe thinking about here So Also, like, we've basically decided that what the a modern transport interface looks like, and it looks like the interface to quit. That's what we built in web transport. And if you look at web transport over HB2, it basically is this. It's just less efficient. So, again, I'm just I'm I'm supportive of this work and I I think that the possibility, like, know it's not possible for everyone to remove HTTP 2 support, but I think it would be likely that"
  },
  {
    "startTime": "01:18:02",
    "text": "we would probably we've met, I would probably remove HTTP 2 support if we move to this. I'm gonna be cutting the queue in 30 seconds. So This is your warning. That number is Yeah. I think it was on slide 6 that you you talked about. Retrofitting, Quick flow control. H2. And, You sort of observed a couple things about why that didn't work out. And and one of them was that there just wasn't enough interest. And I'm concerned that this is adding code to solve a problem of having too much code. And without an incentive to upgrade where in this really awkward position. Right? So okay. So Meta upgrades. Great. That's great for Meta. But there's a lot of lot more people using the the protocol than than them. If those other people don't have time to to invest in the development of an entirely new stack, then we're in a situation where we have more fracturing in the ecosystem, not more. And those of us kinda stuck in the middle, just have way more code to maintain, and we're in a situation where we still have to keep keep keep HTTP 2, alive. We gotta keep this new thing alive, and we gotta http 11. On life support as well, and Some of us have 0.9 kicking around somewhere as well. So Adding more stuff to the pile, is, is not necessarily something I'm enthusiastic about, and this is this is why it's it's difficult for me to say this because I like the design. I like the idea. I like the the the sort of promise that this has. But I don't think until we have more reason to do it."
  },
  {
    "startTime": "01:20:03",
    "text": "This is this is something we should be pursuing. And I think we were talking about an HTTP 4, there was some new thing that we wanted to do over TCP then fine. You know, this is a great basis for that sort of design work. Maybe the mock people wanna fall back pretty and that's enough justification to do something along these lines. But Wayne wouldn't necessarily do it for I should repay at that point. And that's the sort of thinking that I think we need we need to be looking at here. Much along with same lines as Mark was talking about, and Garrett Love and and others. This is This is like, a a great idea, but the great idea has a huge activation energy. And I wanna make sure that we can justify that. Hello? Denton. Yeah. The battery is going down. Oh, here. You this is fantastic. I still want people to hear you. Be even briefer. No, I think this all hinges on what the delta is. If if it takes you half a day to to kinda put in a a mode. I mean, I think it would be interesting for us to see this precise And and if it the answer is no, then be good. David's Ganazi quick enthusiasts. So plus one to everything, MT said. I I I was much more opposed to this in the quick session. And then we had lunch and now I I kinda understand better. And I think I've kinda distilled or disagreement to fundamental assumptions. Which are if if This allows you to get rid of HTTP 2, then it makes a lot of sense. If you control your client app and your server, you switch from this and then you forget about be 2. This makes your lives better. But if you're a browser, or a cloud provider,"
  },
  {
    "startTime": "01:22:01",
    "text": "gonna need to keep HTTP 2 support pretty much forever. And this adds something on that list. Another assumption is if you think that there will be a lot of folks building new protocols over quick. In the near future. I don't know if that's true because as opposed to people building new protocols over HTTP Symantics. Even over web transport. Gives you that in direction layer for almost free. So Totally see, What I think will be the hard might be the hard part for you is incentives, incentives, because for this to be useful to A CDN, you need browsers to implement it, but it doesn't seem to be solving a problem for browsers. So I'm not saying this is an official position of any browser, but we'd have to talk through what helps what the browser gets out of it. what So I I'm gonna interject quickly. You know, how I said we had plenty of time. This is obviously something that we're not gonna resolve today. So let's keep the comments brief, keep the discussion going, but let's let's get to the queue. Pretty briskly. Sounds good. Eric Kaniere, Apple. I did start out very dubious about this in quick, and we've since had some good conversations that are starting to change my mind. I think tunneling quick is really nice, but you still need to be better than H2 in order to get So I love the idea that migration and multipath could be happy. And that would be an awesome thing. But I think we need to not say, oh, these are gonna be people who are already in this really, really sad bucket and so we should just make it they're just gonna keep using H2, and then we're gonna have the same pressure to build stuff over H2. Right now, we're showing about 4% of connections are in that bucket, which is close to a hundred million people give or take. So that's not nobody. Other than that, just development of a whole new stack here is an interesting question because my mind, the real thing that makes or breaks this is, do we think we're gonna have to invest in H2 anyway?"
  },
  {
    "startTime": "01:24:02",
    "text": "If we think that in order to fix rapid reset and everything else, gonna have to do a bunch work in H2 then we might as well do some other work now so that we don't have to keep having that long tail and h two is always gonna be around, and we'll always have to have it. If we don't think that we're gonna need to do that and H2 is already dead and we can ignore it, then then this conversation is moot. Also, what are we doing in mock and wood transport and everywhere else we're not ignoring it? since Car. Carl to the MacRitz. I think I'm very sympathetic problem here. I think it's a lot more compelling for the case where you have a like like like like non general purpose HPU web browser case where you have like a new protocol, that's talking directly from client to server. You just want something that works in a case where, like, udpizza is blocked on the network. The case where you have, like, a middle box that's blocking things, like, I'm not sure there's that compelling use case because of a middle box is going to, like, upgrade to support this, it'd probably be fine to sporting quick. The One thing I wanna add as well as, I think there's kind of a similar problem at the TLS layer where someone, builds out a quick stack that they're using for most of their traffic with really nice features, like, requiring Chills 1.3. Then they have a fallback stack that uses something completely other implementation. That doesn't have those properties. Might even support, like, TLS from what I know because people are caring about that. It makes it really difficult to, you know, make an argument for the security properties. So I think we should be careful that we don't like TLS layer as, like, That part is still different. And find ways to encourage or mandate using the same exact TLS stack west west the minimal set of differences that you can have like, like, Make this up. I feel like we really should learned some lessons from the last time we successfully depreciated an HGP version."
  },
  {
    "startTime": "01:26:08",
    "text": "Like, as mentioned, we still have 0.9 around a little bit of it. I I love the idea of this. Fair, A brand new protocol, that is gonna build over quick, but knows they needed TCP fallback. I would love there to be a doc in the transport area that we should say, okay, just shim this in. Keep the same interface. You have your TCV callback. I'm very hesitant about trying to put HTTP over this. Because I feel like As Hopefully, we get like 90 90 plus percent code we use. And just branch between the the different paths that we already have to support this. But I'm I'm concerned that may not be the case as you try and iron out the edge conditions that you would need for shipping and not just a proof concept. So I see some promise here. I'm not sure that HDIP is the first place to do this. That Ted Hardy. It's really hard to follow somebody as brutal as that. That was scary. Could Could you could you show slide 10, please? I actually, agree with Mike on one thing. And that is that I think if you take this as a what if there were a transport protocol with the understanding that it's not a new transport. It has to run over one of the ones that gets through firewalls. But it could run over either 1 UDP or TCP and have similar care roostrics that that would in fact get you a critical piece to getting here. My concern at the moment is you have HTTP 3 or a new protocol called X running on top of these things, where they don't give you the same things when run over UDP. And and and and and and"
  },
  {
    "startTime": "01:28:01",
    "text": "TCP TLS. They're they're just sufficiently different below the API of HTTP 3, that I don't think you're gonna successfully unify them at the API without doing some like he's talking about and having a shim. I think, Tommy Shim, is cheap and easy, and it works today. If you absolutely need something, you you run a unbox protocol, an unbox proxy that lets you run connect UDP and the the delta between how well that's gonna do and the activation energy to get what Mike talking about. Is enormous. Realistically, we should live in an an internet. We're introducing a new transport is doesn't have to run over UDP or TCP that's not the internet we've run-in for a very, very long time. We have to deal with the ossification we've got. And I'm very concerned that if you try and run what you want to run. With with sufficiently different behaviors for TCP in order to to avoid this API problem that the Ossified internet is just gonna kill you anyway. You you you're running on top of TCP, but not in a TCP like way. And that's gonna result in you getting killed. Now that's it's speculative. Right? It's it's speculative, like like, guessing when people are gonna stop blocking UDP it's not really worth going down there, but I just wanted to articulate that I think the problem you actually are trying to deal with is the problem of how do I deploy a new transport on the internet. And, well, we don't have deprecation experience for HTTP, we do have experience that says if you want a new transport on the internet, you run it over UDP. Tech tech. Can I ask you a clarification question about using t but not using it in the way that people are familiar with? What can you just expand on that? So if if you're running a, a proxy that's, Not a sorry. If you're running a firewall that's not a simple block this port"
  },
  {
    "startTime": "01:30:00",
    "text": "firewall, but is doing packet train analysis or more advanced things. Something that looks sufficiently different from known traffic for a protocol will get blocked, even if it's on a known port, because it doesn't have say, this this is going to an HTTP port, but it's not doing request response in a way that the the firewall is gonna recognize as appropriate. So if you get far enough out side the window to get where you are here. I worry those boxes which are what have occupied us into this problem are just gonna start cutting you off anyway. And I I don't have evidence to show you that that would happen, but it does completely agree with that, and I think that's what prevents us from being able to extend or enhance the H2 wire image and fix any of this So I think were agreed. What laptop. Laptop. Laptop, Alex. Alex. This work. Alex Nejovsky, Google. I have a few thoughts here, but I'm going to allied most of them. My first thought is that if we take it as sort of granted that quick on stream is going to make it out there because there are protocols, like, we've been discussing in this week, like SSH 3, which some people think shouldn't be based on top of an HTTP semantics, but probably still wants a piece of the fallback. That clearly is a way to do this. And if that gets adoption, then we sort of find ourselves here in the group in a really funny position of cool. The underlying substrate, which makes this possible, already going to exist. Going to stop someone from defining the ALPN to make this work and have it work? Like, I think one of the things that we've been discussing in hallway sessions about this area of things is that a key metric for success for HTTP 3 on quick on streams would be if it's almost trivial for users of H2 to migrate. And think that also changes the calculus. So while I'm totally happy we might walk away with this issue, but they not yet, let's maybe get some deployment data. I think that we shouldn't necessarily close the door on this discussion if we do in not get the data to show, but, a, this works and, b, is as easy as we think it's going to be."
  },
  {
    "startTime": "01:32:00",
    "text": "Because a lot of the things that we've been talking about here are there are real concerns, but they're all hypothetical. And I don't wanna say that any of them are not real, but I do wanna the deployment data to know if we have to care and how much. Okay. Thank you. And and and and and Thank you, Kuzujo and and Lucas. So chair head on. I I think this is a bigger discussion in in a couple of different ways. One is is that, We know, has we've never done a new version of HTTP without a bigger community discussion. I don't think we can just do a call for adoption on this tomorrow, and see how she goes. You know? I don't know that that requires a boss. We'll we'll talk to our ADs and so forth, but there needs to be more of a hurdle than just know, normal adoption for this for the working group. And and second, I think this is part of a bigger discussion about how we maintain and evolve protocol. There there's a lot of you know, this is one way we could do that, but I think there are a lot of different aspects this that we as a community would really benefit from having more discussion of. The back of my mind, I'm thinking maybe there's a a bigger discussion at the HP workshop about that issue because we have more implementers in that room, and that might be helpful. So thank you very, very much. I just wanna say we had a side meeting this week. We had a great discussion in We've got another one here. I really wanna thank everyone for their different opinions. And the way we had a really respectful conversation on that but thank you. K. Alright. Alright. Thank you. Kazuko. Yep. Once again. And, sorry, we are we can we compress on time if possible? Yes. Thank you. Let's Oh, no. No. Yes. No. It's creating materials. Due to tracker issues. Now? Yeah. Is it was in the other session? Or or probably it wasn't synchronized? Is showing on status, but it's not allowing me to share. That's what Click refresh documents, maybe? I did."
  },
  {
    "startTime": "01:34:00",
    "text": "Can you can you get it and then project from your screen maybe? Yes. We'll we'll we'll be at the end of the session by the time we'll resolve it, I'm afraid. That's the problem. Rich. Rich, you have the slides? Why is are you in the room? Oh, you have you have trying to see if there was and Thank you. Pile. No. there. That's not Yeah. Yeah. Let me, that was, that was And we get I love it. Well, we should talk about that. I'm not an I'm the full client. Yeah. Yeah. Yeah. Yeah. So I can't Okay. And where can I find the isn't the material? So if you go into a folder, it knows it's there. Okay? No. Refresh. Nope. I guess that if you want. Can you just speak to him? Okay. Go ahead and start. Right. So this is a proposal about doing the reverse HTTP thing. So typically, HTTP clients connect to HTTP servers. But sometimes there's a firewall in front of the HTTP server that blocks HTTP clients from connecting to the HTTP server. And in those deployments, we often use something called reverse tunneling or reverse HP that lets the AGV server connect to the HD client at the TCP level, and then let the client center requests. So it's the connection is going in reverse direction. And it's called reverse HTTP or reverse to 9. In the previous, I guess."
  },
  {
    "startTime": "01:36:01",
    "text": "Session, been short, presented their way of, doing this. And it was based on TLS. Basically, they should be server connected to the HP client using a using to this, and it uses a special open to indicate that the connection is going in reverse. Honest. Next mix. 4 Maybe 3 or down. Yeah. This one. Thank you. Wonderful. Thanks so much. So and the auth Oh, and the the It should be service against key is provided as a client cert to the HDB should be client. And once the handshakes are modified HDB is used, with the TCP server being the HTTP client. Next, please. Oh, okay. Yep. Up. Up. Up, up. Yeah. Thank This one. Thank you. So, there there were some feedback from IDF in the previous meeting. And what was the some people, I mean, me had, the distaste against exchanging the tonal parameters using TLS handshake because it seemed to me like it's too inflexible. Especially for the large CDM deployments because the identity or the scope of that of each tunnel is being is com is communicated using the S and I or the cert. Or the origin frame, and it's it was considered too inflexible. And the other and desired that was raised was that we want to tunnel something other than HTTP as well. Next space. So this is the new proposal that I have they help me, phrase out my things. But, unfortunately, I couldn't we can come up with a converged proposal. It's"
  },
  {
    "startTime": "01:38:02",
    "text": "the fault is on me, having the desire to have one specific way. So 40s entirely on me. And this is the new problem. New protocol. So, basically, the ideas to use HTTP to establish reverse terminal instead of using TLS. We use extended connect. Next place. So first, the HTTP server instance that you also handshake and an ordinary open is used. It should be serviced. Don't need to authentic as themselves using using tier certificates. They are it could use basic auth, for example, next place. And once the collection is established, there should be service sends a extended connect request, for the sake of reality I'm using HV 1.1. So as you can see, this and there's the upgrade token that says Do the HTTP reverse direction, and in this example, we are using basic authentication. And then as your client says, Hey, I'm ready to switch the protocols, and then that you guys start seeing the request to the server please. next And lots of their U verse on this is published HTTP request just flows as is. Next space. So why is Xfinity? It provides us a flexibility. So we call the discussion about connectivity. The full point was that the traditional connect method uses the host name and the port of the proxy as well as if it uses TLS. And it has caused it to inflexible. We decided to make connectivity because it uses URI. As the end as a way of specifying in the endpoint. It's the same. So, and the other argument, for example, with by using URI, we could create reverse service that's only responsible for handling a specific consulate, for example, it could be a specific domain. It be a specific user, it could be anything. And It's also the case that once we move to HTTP based design, we can use any authentication scheme. And it It makes integrating this to a"
  },
  {
    "startTime": "01:40:02",
    "text": "existing infrastructure is so much easier because a CDN is example, they already have HTTP based APS that they provide to their customer. We can just integrate this into our existing infrastructure because extended connect is also HTTP And we also be and because we build on top of HDPCSomatic, it makes us Easier to default. Next base? So the question is We use extended collect. To create a tunnel and then exchange HTTPS request, which HTTP function is being used. Next, please? There are 2 options, actually. One is to use TLS on top of this one, but the downside is that there's double encryption. And the other option that we prefer is to use the shipping version being used. And there's also already a standard for sending their opens, but there's no one for selecting the open. So the client so the client sends H2OI try and the the the client's then selected out all business. Next please. And this is really easy to implement, and the performance is guaranteed. Because In the HP proxy, we want the We can simply accept the reverse connect request using H1. And once we send 101 switching profiles, we can just Move the connection state. TCP level, I'm also the connection state to the but can collection for the proxy? And then, you know, we we we are back to the ordinary job of running the request through the tunnel, and we already have the highly optimized, but so this is very easy to implement and the Thomas is guaranteed. Next, please. So the next question was, like, What about HTTP 3? Do you want to support it? Yes. Want to support it, we can support it easily because we know how to forward UDP data rest. On then established on it. We we are doing that in masks. It's easy. Next about the TCP relay, next page."
  },
  {
    "startTime": "01:42:04",
    "text": "Right? So we could use this for doing TCP well. So let's say that that Oh, let's say that the HTTP server wants to listen for this address, 0.0.0.0.0. 25. It says the extended current request and next page. And then the HP client sends 100 continue indicating that it is waiting for incoming connections. Next base. And what's the HTTP client acting as a TCP accepts a new connection. It can send a one on one searching for holes with the whole other data saying that Hi, Gabrioters is this. Next, please. So this is This semantics is like accept. You you use one tonal for 1, TCP connection being read, but there's only an alternative in which we can use the bind semantics. And it will be like creating a tonal, creating a multiple multiplex tonal of a and it's free. And using that to forward each incoming connection. Next, please. So for me, the questions are that's the desired quirk. I think this fair amount of interest in doing this kind of thing. So the question is about the design. And the next question I have is Do we want support history, or do we need to support it now And the final question is, do we need the TCP value mode? Personally, I'm not that interested, but maybe people have old ps. Thank you. Thank you, Kazuko, and thank you for doing that so so quickly. We we do have 2 more presentations scheduled, and and we're definitely gonna run out of time. So I just ask people, right now, are there any immediate in terms of, like, almost a dispatch style, yeah, should we should be looking at working at this area I have concerns without going too deep into them. Do we have any immediate reactions? Okay. Go ahead, Martin."
  },
  {
    "startTime": "01:44:01",
    "text": "I'll be brief. I think you need to think about the security model a lot. As a browser, I don't think I could implement this without a lot more work and the security model is kinda key. Let's check Martin? I'm definitely interested in this. I have to admit I don't and don't quite understand how it works in Hupp3, and I'm wondering if we can use by directional strength in the other direction, but the interest time, like, at let's discuss this later, Okay. And, and then, Hey, So, this this proposal is is basically like a TCP1st version of this. And I I think basically that's backwards, we should basically start with HTTP 3. And I think that will sort of give us the right design and then just like the previous presentation, we can try to to to come back from that to something that works. For anticipated dispatch wise, I think, we should put together some kind of joint proposal eventually and, I I think the HTTP working group is is going to have to be involved. But, might not be the right home. Okay. Right. Alright. Thank you. It it sounds like there's need to be more discussion, it sounds like. Yeah. Perhaps side meetings are yeah. So I think Nidi's next Nidi, do you wanna Present your own gap. Great. Thank you. Is Cool. 1. Okay. Hi, everyone. I'm Nedi from Google, and I'll be talking about window sizes for 100 content coding? Recently worked on shipping support for a z sander content coding in Chromium, and came across a few issues, which is what prompted this draft. I'll keep this very short as the draft is also very short. From Yes."
  },
  {
    "startTime": "01:46:04",
    "text": "To get some quick background out of the way so you standard is a data compression scheme designed by Meta 3 years ago. It's a fast losses compression algorithm. It provides higher compression ratios than gzip lower CPU costs than Broadly, So as the diagram shows, the window size indicates the longest back reference that the encoder will emit and provides a guarantee about the minimum Memory buffer required to encompass a frame. Which is important for decoder to allocate enough memory. In general, larger window size values tend to improve compression ratios but this is up to cost of increased memory usage. To prevent unreasonable, usage of memory decoders are allowed to reject a compressed frame that requests the memory size beyond the decoder supported limit. So the r had some tax recommending decoders to support window sizes up to 8 megabytes, but this is merely a recommendation. So looking at some of the different tools that supports this standard content encoding. The CLI uses up to 8 megabytes by default, and it can be increased to 128, depending on the flags, Chromium, which recently shipped support in M123 up to 8 megabytes and curl, accepts up to 128 by default. So because there's different defaults being used here, we have seen small number of interoperability issues already manifesting in the wild. A few developers have filed bugs because their compressed content doesn't decompress properly on Chromium. But, which does follow the recommendation. But when they use curl, it de presses normally so that causes confusion. The proposal is to change the recommendation for 8 megabytes to be an explicit requirement for the HP content coding took in the standard to mean that the compressed content uses a window size of not more than 8 megabytes So the text we looked at before would be replaced with something like this. I'd love to hear any feedback about the number we've chosen or anything else as well."
  },
  {
    "startTime": "01:48:03",
    "text": "And as I mentioned, we have A small but non zero number of interoperability issues in the wild so far, so we'd like standardized on a single window size limit before the usage becomes more widespread. We had some discussion on the illness, and I'm happy to have them get choose as well. But if we think this is the bright approach, and this is a really minimal draft. I'm wondering if this is a good starting point for adoption. Great. Thank you very much. So, again, we're time constraints. So let focus on whether we should be working important. Yeah. Ma'am Thompson, I think we should go straight to working group last call with this one. It's so small. We should just do it. And that It was just a bug. And so, we should we should Thank these fine people for fixing the bug for us and and make sure there's an ROC promptly. Thank you. Eric. Eric. Eric. Eric, can you or Apple? I would actually second that. Yeah. I would say, thank you for doing as we're looking at implementing these standard for Safari and Apple platforms, there's no way we're gonna use 128 megs. We just can't. we need a smaller number, somewhere in 4 to 8 So the Meg works. 8 megs is what everybody else seems to be happy with. That also works for us. So please ship it. Alright. It it sounds like we know what we need to do next then. Time s you very much, Nidi. That was very Okay. Okay. And and finally, we have, presentation that is, talking about it here because it's very close to the implementer here. It's not clear whether we'd adopt something in this working group but we wanted to talk about it here. So, David, go ahead. Thanks. Hopefully, the slides work. Oh, okay. Alright. Hi, everyone. So This presentation is going to be,"
  },
  {
    "startTime": "01:50:04",
    "text": "about a topic that got a little bit controversial over the last year of IPV 6 link local addresses in your eyes. And My main goal here is to kinda go through the history of, like, what happened because I think because this topic stretches between HTTP and ipv6, Not everyone had the full picture. And so I wanna kinda tell the history and then have a proposal for going forward. But it is Friday, And this is the last talk of the session. And I didn't have time to make slides. So I asked Geminiai to make slides for me. So But this is what happens when slides are submitted very late in the process. You got Now? Yes. Alright. They're still figuring out the slides. There was kind of a warning at the bottom of the page about in it possible inaccuracies in the results? I didn't have time to check them. So there might be some things wrong there. But please don't take the slides as me saying that like, the topic is light. There was some real things that we need to address. But Yeah. Just Working on it. We're working on it. No. Probably there were now. HTML Don't open it up, but it's more fun if I do it in order. anymore, So, though. just I think you need to start talking talk Alright. Alright. So Quick, quick primer on ipv6 because not everyone in HTTP biz, knows all the intricate details of ipv6."
  },
  {
    "startTime": "01:52:02",
    "text": "So has longer addresses that have colons in them, that great and all. But in particular, ipv6 link local addresses, have an interesting property that they have a scope identifier. So that's a name that's slightly unclear, but conceptually what it is is an interface identifier. So if you have a machine that has multiple interfaces, say your phone with cell and Wi Fi, Then who? Yes. Alright. IP. This is what an ipv6 address looks like. Can can you make it a bit bigger? Or or do we Oh, it's Ted. Thanks, Ted. Ted, can you make it a bit bigger? The single flight It's alright. So, And, you put the scope identifier kind of at the end of the address. So But the issue is that URIs don't have a way to encode the end of the address. Which is the percent and 0 there, which is kind of the the inter interface name for for yours. And then the issue is you need to pass that into the socket when you call connect later. Next slide, please. So let's talk about use cases. This draft is like generic to all of your eye based protocols, but I'm just kinda gonna speak about browsers that's what we're most familiar with here, and it's a good example. So I have this friend that goes camping with his printer. I don't know why. But, There's no router out there when we're camping. And so you plug your machine. You use you know, your lightning bolt cable to plug into your printer and you wanna be able to print. And you know, that also applies to any case where you have 2 phones talking to each other. Born, you're outside of a home. And that's kind of what I wanna focus on is having cases like this work in a browser and then more generically. Next slide, please. So this works today for ping. So"
  },
  {
    "startTime": "01:54:03",
    "text": "You just type ping in your address. Get out our info. Handles that properly. It gets the, zone identifier, enter your struct socket or IN6, and you can computer on the other side. I love that when you ask for computers in Google's AI, you get something that looks like another brand I know. Next slide, please. So, we realized that there was a problem, put the best ATF minds on solving it, and they had a great idea, which was why don't we put the zone identifier into the URI? Next slide, please. So this was back in 2012 2013 and led to the of the esteemed RFC 6874. It happened in the 6 man working group, and course, because this is IETF and you can't have nice things. We ended up with percent 25 down there because we presented coded the percent sign. Great. Gorgeous. Next slide, please. The issue is kind of the that RFC was Kinda written from the aspect of ping And, like, for being this just works. It's really easy when you you just get a host you get a string. You Pass up to get our info. You pass it to the socket. Browsers are much more complex. So this room knows quite a bit about that So they work on the origin model, which contains the host name, and then do a whole bunch of stuff with the origin. There's cores, which is complicated security stuff. The it interacts with the HTTP cache. It's also in links. And Importantly, it is sent over the wire. And so now we have this problem where this zone identifier has only local meeting to the host is entangled in all these things where in some cases it makes perfect sense to have it in summit doesn't. So implementing this in the browser becomes way more tricky than it does in ping. And"
  },
  {
    "startTime": "01:56:00",
    "text": "not even clear if you can really get it to work nicely. Next slide. So the because of this, the implementation of this RFC was somewhat limited. I'm told an old version of IE, actually, so reported this, but that was a I am told that was a bug. They didn't do it intentionally. And, as you recognize the cups protocol, wanted to do this. And but they went to have a different format from an earlier draft And this part is actually not AI generated. This is a real thing. Gorgeous. Alright. Next slide. So but why is this all super complicated? There are 2 URI specifications. So the one on the left here as you can clearly see is RC3986. Which was developed by the ATF awhile back. And that's the one that was updated by 6874 that we just talked about. And on the Right. You clearly have the what working group URLs living specification. The I won't go into detail of why that happened, but the what were you forked the IETF spec and had their own And to this day, this is the one that browsers use. So you kind of have a weird situation where the one on the left is affordative for many URIs, but not at all on the web. And this one is there. And there was a request to add, go by as one of the identifiers to the what working group URLs back. And due to the reasons I kinda alluded to earlier was deemed kinda too complicated and with security risks. So they explicitly decided not to do it and added a line to their spec saying we intentionally don't allow these. Next slide, please. So, quickly, 2 more proposals that happened in this space. So, the one on the left is draft RC,"
  },
  {
    "startTime": "01:58:01",
    "text": "sick I'm remit for getting the number, the one that we did before biz, where folks were trying to solve the problems from the older one, like it wasn't percent 25. It always sent about sending it over the wire. But, similarly, it didn't fully address all of the browser concerns. And That was kinda realized a bit late in the game, when it went through, like, ATF last call and got review from the HTTP working group. And as of yesterday, the responsible, AD like, mark kind of this document as, I think, abandoned is the term. And Brian Carpenter has a new proposal on the right that focuses on user interfaces, where his idea was, let's not try to add it the URI and instead require that any application that makes use of a ipv6 addresses directly allows zone identifiers but he does mention that this doesn't really work for browsers because Next slide, please. Alright. So what are the what am I proposing here. So first, I think we take RFC 6874 and we obsolete it. It was a reasonable attempt, but, like, it hasn't been implemented, and I think we can just Market as historic. Next slide, please. But then going back to what we're trying to do, we're trying to have connectivity, local only connectivity work. That's kind of the goal. These two devices should be able to communicate without requiring some sure. Like, a router or anything. Next slide, please. But luckily, the folks of ITS have had great ideas. So We have this concept called MDNS where similar to how ipv6 allows you to have link local addresses, without any infrastructure, allows you to get uses multicast DNS. To exchange and to be able to discover the IP address."
  },
  {
    "startTime": "02:00:00",
    "text": "Next slide, please. Yeah. If you wanna go even more printer galaxy brain, it's important to there's a note in there about how the name should be unique. And that way, you can avoid collisions making your really easy. And that gives you a nice property because, like, if you you base your name on, like, the serial number of your printer, you can put a QR code on it that you scan with any device and boom. You're inside the web page for it. Great, easy. Yeah. Yeah. Yep. Next slide, please. I think we're close to done. Of course, web security is hard, and this is what it looks like. So For all this to work well, like, all of this is completely insecure, and that's kind of a known fact. Same as, you know, web browsing to 1918 space. Have some consideration to document. There are some proposals for fixing this. They're not I I'm considering an out of scope for this document. I'm just trying to resolve kind of a specific issue being able to communicate with these devices. So the idea becomes instead of focusing on my PV6 link local addresses and you're putting those in your browser, we say Like, have your device that you're trying to talk to, like, your printer, advertise its name, we could just put that in the browser. That actually works today. The browsers don't need to do anything about it because that's handled by the DNS library. Underneath in the OS. Next slide, please. Alright. And that's all I have. Does anyone have any questions? Okay. So, we're actually at time. For the working group's benefit, I think, you know, we're not considering adopting anything here right now. This is more of a, a nature of a community discussion. If you'd like to participating in that discussion, please stay in the room. I think we can go over time. And I'd ask, especially the HTTP folks, I think it'd be great if you're part of that discussion, but you know, we're not gonna do any official work from this point onwards. So let's have the a bit of a discussion now within a reasonable amount of time. So Torless, first. Thanks. Thank you very much for the work. So, yeah, I'm I'm I'm all for, you know, users have to know about ipv6addresses"
  },
  {
    "startTime": "02:02:04",
    "text": "that's one of the reason why, hopefully, you know, an ipv6 network administrator gets a little bit more money than a user, to have to deal with this stuff. When DNS isn't working, even, including that. And those network administrators also love to use browsers for that because often there isn't anything else. So, I don't think we should retire 6874. Showed 4 users, you know, so you proceeded in terms of a better and I think we've seen some evidence in talking to people that browsers don't always support the dot local MDNS lookup. So if if we figure out where to best do that work. Hope that guy over there has a better idea. Then we should certainly make that, you know, very much mandatory for browsers, but that may not even be IETF after you've educated us that there are the standards buddy that may be more important in that respect. When it comes to where then is a 6874 relevant, Yep. Network operators, but I also think in any form of, APIs that use rest confident any other forms of URLs. And then for, you know, The biggest problem, of course, right, it would be lovely to figure out if if there is any particular better way you know, to fix that origin problem, for something like these zone identifiers. I mean, there is, they already I think in what WG work for the problem of non global, addresses. Anyhow, and, that stuff is, I think, not including the fact of of trying to figure out if there are actually, you know, different zone instances, let's say, the the usual RFC-nineteen 18 address Right? 192, 16811 is my route, right, change my SSID. I have the same IP address. And why the heck am I seeing all the graphic from another router, on on this router. Right? So this isn't addicted to these, ipv6 addresses. We have the problem in other spaces as well. So for whatever, you know, you folks in what we g or so are doing,"
  },
  {
    "startTime": "02:04:01",
    "text": "I, I think we should be happy to help figuring out the right thing to do. And in include those zoned addresses in there, even if it means, well, it's hard but but but but doesn't mean it has to be, you know, standardized and adopted, but what is the right way to to deal with these addresses, right? But, yeah, they shouldn't be used by users. Right? So please don't take them to the camping ground. Thank you, Thomas. Stewart. Thank you. I know we're over time, so I'll I'll be brief. I stood up because I have a request for everyone in this room to see if you think this is a useful problem. And if so, give us some guidance on how to solve it. I'll quickly start David made a little private joke. I go to Burning Man, one of my contributions is I take a wireless battery powered dye sublimation printer that makes it all 4 by 6 inch postcards, and anybody's got a pitch on their phone or their camera can come up and make a postcard, which they can mail to family and friends. There is actually a post office at Burning Man, It is the only US ZIP code that only exists for 1 week a year. And about 10 years ago, I was doing some stuff at home and it's very common for home gateways and printers and things to have a little embedded web server and that is the universal UI So you don't have to install an iPhone app or an Android app, Any platform that has a web browser can connect to my laser printer over the network and see the in glove also, you know, when it's time to buy a new toner cartridge And this to me seems very natural and good, I really don't want to have 20 different apps on my phone all the devices in my home. I'd rather just have one app, the web browser. And I can type 192, 168, something something to connect to my printer, and that works. Or or link local 190 169254. But when I tried to do it with v 6, cave an hour. So I talked to the browser team at Apple and said, oh, you need support the percent interface on the end of link local And they said, oh, yeah. That's a reasonable idea, but"
  },
  {
    "startTime": "02:06:01",
    "text": "I thought it was just a bug fix, and they said, But there is an act in RFC that says Like, are you supposed to present and code the percent or not? And that's ambiguous. And and we don't want to just do our own thing and be different from else. So Tell us again with us in RFC. So I thought, oh, well, that's really easy. It's just a bug fix. Right? That'll be uncontroversial, and I I worked with Bob. And and we've made an RFC. I didn't like the stethoscope the stethoscope and the percent, but agreement is better than, you know, you don't always get what you want, but at least if we all agree, I thought that was done, and I went back to the browser team at Haplin. They said, No. No. And I said, No. But you just said the problem was lack of an RFC, and we did that. And they said, no. We're not doing it anyway. And that was when I went I don't understand what's going on here because this seems like a reasonable request I just wanna check the ink levels on my printer. I am learning more about the enormous complexity inside a web browser that is not same as an SSH client or something Now David has proposed, I think, a really good idea which is Let's use dotlocal multicast DNS. And I would hesitate to propose that myself because that seems a little bit self serving. But But after 10 years of sort of trying to push this rock uphill, I think I really relaxively admit, but you know, maybe that is the right way to do this. So One way or another, I think using the web browser For local communication, it is not just for buying shoes from Amazon. I think the web browser has much broader use than that. And I wanna be able to use it within my home communicate with devices as easily as I use it to communicate with something on the other side of the planet. Awesome. Thank you, Stewart. Ted Hardy, basically, from a dispatch point of view, I think this needs to go to a either a BAF or a short working group"
  },
  {
    "startTime": "02:08:03",
    "text": "because it turns out there are people who use the current syntax, and they use the current syntax for addressing specific interfaces in network management and other context so you can't deprecate it and identifying when it is that you can and can't use it needs at least a document and not the hallucinations of Gemini, although they were very amusing. And just to be clear, there's a draft. I guess we skip the first slide with the hiccups. Yeah, so the, I do think that this needs some actual work to say, in this particular context, because of these things, this is no longer permitted and basically align the URI What working group spec with ours with an applicability statement and in other it is permitted and why. But I think It can't be done here because you have to balance the different use cases and some of them are outside this work Okay. We we are now back of the room tapping their watches meaningfully. getting people in the So, we're gonna go through the queue very quickly, Ben. Hi. I wanna solve this. I'm very excited see energy about solving this. I think this draft is extremely insecure and is basically like 1,000,000 different kinds of exploit waiting to happen. It is less secure than insecure HTTP. And I I really think that It's pretty scary. But I really wanna solve it. And I think that I wanna live in a world where I can scan a QR code off of an IOT device, and connect to it. Securly over the local network based on key material that was in that QR code. And I wanna be able to get just like a totally human readable, no garbage, domain name, for a thing that's on my network and connect to it and have some kind of tofu thing happens where, like, I've approved it and if it's keying changes, get a big scary warning. I think that both of those things are within our capabilities, and world needs them, and we should do"
  },
  {
    "startTime": "02:10:00",
    "text": "Thanks, Ben. And for what it's worth, I would love to solve security problem, but I'm not sol signing up to do it myself. Go you didn't. ahead, Just Bob. Bob, to reiterate. At least I think there's a a real need for this. We're also seeing it in ipv6 environments where there is no V for There is very little user interface. And they've had to do some really nasty hacks to get around this problem so There is a real user need for this. In, you know, you know, you know, you know, Zaro. We live for a long time because things could fall back to before, but that's changing quickly. So, So we really I don't care too much how it saw, but we need a solution. Right. Thanks. And and I'll just say very quickly. I I do hear a lot of people saying that they want user needs to be solved here, and I think that's where we're seeing good convergence, which I'm very happy about. The the the solution though needs to to to realize that you know, it's not just an address on the network. It's used in in in in the web stack as as part of identity. And that loops in all these other parts of things that causes such complication So we need to be very careful that, and it needs to be whole of IETF. We need to involve the implementers. And and maybe what working group do. So, yeah, there's some I agree with Ted. Something else is needed here. Finally, Martin, very quickly. Hello. Can you hear me? Weekends. Yes. I I'm not sure. I I just had to switch I wasn't connected all the time, so maybe this had been said before, I think there are quite a lot of, Well, you use a problems that can should be solved but I would like to say something that I send said 1 year ago in Yokohama in a a close meeting with, I think, it was Bob. And, Brian and, And 2 of the other people which is that the fact that you can"
  },
  {
    "startTime": "02:12:02",
    "text": "configure an IP for With a bowser, is not something that the thousand people Did because they thought it's a good thing. It is just something that they owe to people This cover that you can do with a browser and they did it. And so, It works. But There there's the bounds of people are the bounds are ecosystem isn't really that keen on these very special for them, from there, point of view, raised special use cases that, cost them a lot of, of kind of special And, considerations and so on. So, That's that's a point that is very important that the IPs we six people should understand. Thank you. Great. Thank you very much, Martin. And with that, we we need to close. And I believe we need to vacate the room relatively quickly. Yep. Thank you. Yes, sir. Your charter is approved. Ted, thank you. 3 I'll reach out afterwards, Ted. Probably right before. On our store."
  }
]
