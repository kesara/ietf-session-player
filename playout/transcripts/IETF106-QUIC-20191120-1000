[
  {
    "startTime": "00:00:15",
    "text": "okay let\u0027s get started this is quick and this is our sessions second session for the week if someone come in the back door could possibly close it that it\u0027d be really appreciated thank you or we can get the next person to close it okay this is the note well good morning by the way this is the note well hopefully you\u0027re all familiar with it if you\u0027re not you can find it using your favorite search engine by searching for ietf note well it\u0027s the terms under which we participate regarding things like intellectual property but also regarding things like our behavior in the room and on the mailing lists and in the hallways and other ietf uShip places so please take a look please learn more about it if you have any questions we\u0027d love to chat with you either myself Lara\u0027s when he\u0027s here he sends his regards or other ITF leadership blue sheets are circulating one on each side please sign those as they combine can we have some volunteers or a volunteer for scribing two hours for which you will be eternally thanked it\u0027s amazing how quiet the room can become I won\u0027t ask Ted Hardy because he\u0027s done so much service in the past are you volunteering Ted your service to the community is is above and beyond thank you Thank You Ted can are you gonna use the ether pad Ted or the Google Doc ether pad if folks could help Ted out on the ether pad if you\u0027re not actually helping Ted out maybe refrain from getting on to it because it doesn\u0027t like lots of people at the same time that would be appreciated can someone volunteer to jabber scribe is significantly easier to ask Thank You dkg once again we\u0027re not entirely sure the bridge from jabber to slack is working so please bias towards jabber agenda bashing our agenda today we\u0027re gonna continue discussion of the issues I think we\u0027re in a place where we can discuss just the HTTP and recovery issues today we have Becker interrupts yeah we have one remaining transport issue slash pull request that we didn\u0027t process yesterday I heard one remaining transport issue and then I heard a lot of ekor huh can you that we didn\u0027t part that we didn\u0027t process yesterday which one pull request three one two oh okay "
  },
  {
    "startTime": "00:03:15",
    "text": "I start with I wanted Rudy tag : J\u0027s I would it be possible to add in agenda bash the swapping of datagrams and version negotiation they do to some people tried to sneak to a different meeting well first of all we\u0027re not sure when that\u0027s going to start it depends on when how much the issue discussion totally understand and we\u0027ve already agenda bash yesterday that getting version negotiation before the other two was important so Mike and still remains is there reason not time fie it was just a question yes you know any objection to that I think that\u0027d be fine I think well time okay any other agenda bash sorry I didn\u0027t even finish the agenda so we had finished talking about issues including that talk about extension documents apparently talk about datagrams first then verse negotiation then load balancers we end up with planning any other agenda bashing Provine sorry yeah the acoustics in this room are horrific so everyone needs to speak very close to the mic and very distinctly praveen agenda I think like the planning discussion should be moved up front one of the discussion with implementers has been a request for like a quiet period where we could get some deployment experience so I think planning moving it upfront would be very useful any objection to that okay Jonah if you could I take a couple of minutes to talk about the quick intrapreneur as time permits sorry can we put that at the end desires time permits that\u0027s fine with me okay okay any other agenda bashing okay that\u0027s probably the most lively agenda bash we\u0027ve had ever so let\u0027s execute on that planning we\u0027re going to talk about extensions and other documents later on today and so Lara\u0027s and I and the area directors have been having a number of chats about how we\u0027re gonna go into the next phase of this work as as we\u0027ve discussed we currently have a co-op for consensus on getting the recovery and HTTP documents into the late stage process we are as you can see winnowing down the issues lists on all of the drafts so there are very few left and the anticipation as we\u0027ve discussed and tried to Telegraph number of times is that the drafts are going to settle down from a technical standpoint of the bits on the wire but we will enter a period where we think we understand yes mr. chair sue B does I "
  },
  {
    "startTime": "00:06:16",
    "text": "think it is Winston or Thursday I\u0027m sorry I can\u0027t hear you today\u0027s Winston or Thursday your site thank you for that if only every issue were so easy to solve this is what I get for chairing more than one working group and reusing slides right so good morning I will point out I\u0027ve only had one coffee this morning and for someone where I\u0027m from that\u0027s not any at all so we\u0027re hoping that the drafts will settle down from a technical standpoint we also anticipate the editors taking that time to do some fairly substantial reworking of the documents from an editorial standpoint to make sure they\u0027re communicating clearly not changing the technical content but changing how it\u0027s presented so that it is readable and and usable by people who haven\u0027t participated in this process at the same time we feel that implementers are going to need some time to digest everything that\u0027s happened to work on their implementations to do interrupt work and also to get some deployment experience that\u0027s something that people want to see very much before we ship the RFC\u0027s to make sure that this thing actually works in the wild and so the tentative plan going forward is is that once we get the documents into a good shape and we close these issues we\u0027ll go to a working group last call hopefully before the end of the year and and as a way to notify the greater community that we think were technically done however we\u0027re not going to request them to become our FCS for some time after that and and very roughly speaking that\u0027s something like the middle of next year because we want to get that experience give the editors a chance to work in the documents a bit to get deployment experience so it may not be our last working group last call on these and I know that that that dissonance is is harsh for some but but it is a what we think will be our working group last call because of that we\u0027re gonna have some capacity in the working group for discussing other things and so we\u0027re talking about how we can start the discussion of extensions to quit v1 and whether we start the discussion of any potential quick v2 and also discussion of new application bindings to quick and in discussion amongst the chairs and the area directors we think that the best approach is for this working group to start discussing extensions in a limited way we don\u0027t want to have a flood of them come at us all at once but to start a few discussions and and and and that\u0027s why we\u0027re starting to have things like discussion of load balancers and datagrams verse negotiation is is is the "
  },
  {
    "startTime": "00:09:17",
    "text": "third one I want to talk about there and at the same time you know there are other folks who want to do new applications on top of quick and and our bias is to not do those in this working group but instead to talk about new venues for those or reusing existing venues so for example there\u0027s AB off I think later today about web transport and that\u0027s a potentially working group forming buff I believe no not quite yet but one may appear afterwards at some point and but but we wouldn\u0027t want to do that work in this working group for is the important thing to convey so I think that\u0027s where we\u0027re at we have an interim scheduled in Zurich the anticipation is is that there\u0027s an intervention or experience hopefully on those working group last call documents we\u0027ll have some discussion of any remaining issues that we need to but we\u0027ll also have some time to talk about these extensions any any discussion of this Christian yeah I mean I like the idea of stabilizing the protocol before publishing the RFC and having some time to test and verify however if you delay pushing the document for publication at the same time you\u0027re also pushing the IDF review pushing the idea of review yes I mean that so basically if you\u0027re not doing the ietf last call you are not getting the feedback from people who are actually in the working group and so that creates an uncertainty about the duration of its own ITF last call later on and I\u0027m a bit concerned about that and I\u0027d like to find a way to mitigate that okay I think that\u0027s a reasonable concern to have I\u0027d be interested hear what other people think about it pravin I do like the idea of going to a sort of semi-formal working group last call so I think that\u0027s a good idea what I would like is something more concrete in terms of a draft number that we are targeting to close of the remaining issues such that implementations can deploy and stabilize on it I think working group coming out and saying something formal would be useful instead of having a vague date waste deadline like target a particular draft where we say hey we\u0027re gonna freeze this for a little while so that people can deploy I think that would be very very useful and regarding IETF process I think that can go on in parallel like if you find any major issues from deployment we can come back and like fix those but I think like having a very stable draft formally declared would be very very useful the saman Thompson I think based on the issue list that we have in front of us and the discussion that we had here earlier this week the next version of the draft might be that one that prevents looking for I\u0027m not 100% confident about that but I think we should certainly try to make that the "
  },
  {
    "startTime": "00:12:18",
    "text": "case we have a long time between now and the interim meeting and I think the editors are pretty firmly committed to nailing all of those issues most of them have pull requests against them already so I think we\u0027re we\u0027re in pretty good shape for that one as for Christians concern I think we have a fairly simple answer to that one the ITF review is largely based on Directorate reviewing in the modern day and so simply going to each of the directorates now and asking for review which is a practice that most of the directorates already support for various things is sufficient and will get us some wider review and I would I would say that the the steps that I would like to see happen we finish the next draft we do a working group last call on that and then after that finishes the chairs talk to the various directorates and ask for those reviews to happen and that will happen during our idle period and we can deal with the issues as they come in but I suspect what\u0027s going to happen there is that we will have 25 and then a 26 will contain a whole bunch of editorial changes based on review and working good last call and feedback and 27 will be Directorate feedback and then we\u0027ll sit on that but 25 and 27 should be functionally identical if we\u0027re if we\u0027re changing something there then that\u0027s a pretty high-energy event that\u0027s maybe optimistic but that\u0027s the that\u0027s the sort of thing that I would like to see happen yeah but I mean at the same time you cannot expect to have review for a bunch of directorates and change nothing so it may will be that there is some substantial change when you don\u0027t know that sorry Brian before you speak can you raise the microphone I think it would benefit everyone thank you hi Brian Trammell yeah I basically came up here to see what Martin said I\u0027ll expand on that very slightly there\u0027s even a button in the data tracker no I think to request director review review from a director up on a certain thing there is yeah so I mean you just click the button if there\u0027s further like I think that gets us exactly what we want if there is further lake-like discomfort that maybe the entire community like if there are there are like whole areas that aren\u0027t in this room so like maybe there are people only won\u0027t write a review I know that we do not generally use IETF at IETF dot org for Nicolle discussion but there is a mailing list that we can say hi by the way you know maybe you\u0027ve heard we\u0027re like replacing TCP with TCP - um sorry yeah yeah it\u0027s like last call coming up great like so last call preview can we actually send that to last call at IETF that org I mean we can also send it to ya I mean yes it\u0027s like almost last call that\u0027s like you know preview of last call please start reading the document "
  },
  {
    "startTime": "00:15:18",
    "text": "now it\u0027s big and important yeah so I mean like we have we have like I think we have a lot of options here to pipeline this and I think what like what I\u0027m hearing is that everyone here is interested in pipelining it and I think that\u0027s a good idea hi this is Sean Turner just driving the point home we\u0027ve kind of had some running code we did with TLS 1.3 I don\u0027t know that we did it perfectly but you can tell the ADEs the ADEs talk you can request the early reviews you can send the messages to everybody you can Twitter it you can be like look this is coming if you want your chance here\u0027s the github repo knock yourself out I mean there are ways that we can do this I do not think we should try to get it top try to let the arts you go early because we\u0027re gonna end up changing it anyway so we know that right there\u0027s like an N DSS conference in January so like stuff can pop up so my theory is just do your plan where\u0027s - what Sean said do you know - do other things and people will still show up at the last minute so you don\u0027t like it the I think that running code as well I think this generally seems like a solid plan um the I\u0027m probably the person who thinks that calling it last call when we know it\u0027s like not the last call is pretty silly um but you know what it\u0027s not a bike shed thanks David um and the reasons that a bike shed is that often there\u0027s a presumption we do or last call that if issues not raised in the last call then they\u0027re out of order when they\u0027re raised later and um and so on the I think praveen\u0027s entirely right that it\u0027s good to have a last call let\u0027s try to flush out as many of these as we can and like they\u0027ll spend sometime sometime you know doing um you know doing testing and doing some errant ation and that will know that turn up some things about the change and those issues will obviously be in order but what also needs to be an order is upon reflection having looked at this longer not from data but from looking this longer there are things which are not good we can start changing them my point is those are still in order at that point in the process where they would not be in order ordinarily if like you were sitting there working group for two years with the last call and like you aged it like it ITF I was called people think you were a jerk and so I\u0027m just that dust but that\u0027s the reason that\u0027s the reason you\u0027re hearing resistance from the last call david\u0027s Kazi google just want to quickly say this is a good plan i like it especially from our implementation side of things it the past couple years have really felt like running after a moving target because we\u0027re like we have quick oh they changed the header format all right run change that oh they change this and it\u0027s we\u0027re almost there now and so this quiet period is gonna allow us to actually catch the target and actually put it in production and get numbers that we\u0027ll share with the group so I think this is a great button that\u0027ll be great Jenna and got a clarification question I\u0027ll be talking about last call for all the documents I would talk about some of them but once again you\u0027re reading my mind I was going to bring up when you "
  },
  {
    "startTime": "00:18:19",
    "text": "when the cue drained I in place it in these discussions I think that everyone\u0027s assuming I I think but I want to confirm is that we\u0027re gonna do all four documents at the same time I really all five documents at the same time I do you dispute that I think that\u0027s all right okay I just want to I just want to point out that we\u0027ve not yet moved it just in terms of process we\u0027ve not even move those ones HTP and recovery documents to the late-stage process but sure and and and that\u0027s something we\u0027re gonna talk about briefly today but there\u0027s already a call for consensus up for that and of course that that\u0027s an internal process it\u0027s an external facing process so the other documents we haven\u0027t talked about very much at all or the ops and management documents we do need to start talking about those more yeah so mutton told some was going to talk about those two specifically this quiet period will allow them to catch up as well because there\u0027s like like those people implementing chasing the moving target has been difficult for those documents and I think it\u0027s probably a good idea to to allow that to sell it might be then that we can publish all seven documents at the same time which would be a really nice thing to be able to do so we all understand the plan the plan will meet battle and we\u0027ll have some fun yes planning is important one of the important takeaways that people should have here is is that if you do think you have an extension that\u0027s generic not specific to an application you\u0027d like to propose for quick write a draft bring to our attention we\u0027ll reserve time for it if it sees some discussion on the list we\u0027ll think about whether we want to adopt it and then we\u0027re going to start that mechanism going but this working group will we think be the locus of that and one thing I should mention I\u0027ll put a meal email on the list shortly if we do do that and I think this is from talking the area directors the direction we want to go in we\u0027re going to need to make a charter change our charter currently says thou shalt not work on a datagram extension woops so we need a slight chart okay that\u0027s not them that\u0027s me we\u0027ll need a slight Charter change to enable us to work on on those extensions we\u0027ll put a proposal out for comment the area directors will change the Charter do that do whatever they need to do and we\u0027ll move forward there are other parts of the Charter we can change but we\u0027re not gonna think we\u0027re gonna try and do that quite yet so let\u0027s talk about issues occur you said there was one remaining issue from Transport what if she never was that um I can talk to that one okay so as the author of the PR for it so the sorry what\u0027s the issue number sorry Iker says thirty one twenty "
  },
  {
    "startTime": "00:21:22",
    "text": "okay alright so this is the PR and I guess the issue is thirty fourteen okay so let me summarize this so first thanks Kazuo for finding this issue in short most packets in quick are encrypted and in particular their integrity protected and what this kind of a slight side effect so the crypto but what it also means is that if you get a random bit flip on the network it\u0027s the same as an attack but we detect it and we drop the packet one exception though is retry packets those on Mike initial don\u0027t have any kind of protection and if the retry token gets a bit flip on it we don\u0027t notice especially if the UDP checksum is disabled that\u0027s particularly bad if that because if the retry token is invalid the server will reply with a second retry and according to the spec the client must not like do that dance the second time so then the connection is dead in the water so the quick and simple fix that we agreed to in cupertino was to add an integrity tag at the end so if there\u0027s any kind of error on that we detected and we drop the packet then if you switch over to my PR the proposal is to do exactly that it also has a slight thing where it uses a pseudo header similar to how TCP computes its checksum so that some fields don\u0027t need to be sent over the wire anymore they\u0027re just added as part of the checksum and in particular the original destination connection ID and that\u0027s really all there is to it that a1 one more last point was we were wondering what hash algorithm or slash checksum to use here and in order to not add any dependency on the protocol we decided to use GMAC cuz everyone already has an Aes GCM implementation for initial packets so yep right there perfect we just reuse a a das GCM 128 the key was initially zero but I could rightfully pointed out that it might be nicer to have one that changes and then a Martin Thompson had the good idea to just reuse the initial salt from okay well then get in line to say that and so we use that key so that way it\u0027s the same for all the time the nonce is just zero there\u0027s no plain Tex and this gives us and the associate data is this entire pseudo header and that gives us a checksum and that really "
  },
  {
    "startTime": "00:24:22",
    "text": "authoress to it right so um I guess two points plus listed there for the first point first on quick graphically which I mean I know this is a fine point we shouldn\u0027t use the initial assault as the key we should take the right we should Katie has something off the initial assault I understand like this is not like like I\u0027m going hands vigorously about like how is it really secure anyway but um nevertheless a good practice on the more substantive a acetal nodding so that\u0027s fine that\u0027s it cause it it\u0027s a constant any case on the on the issue that I think that Dave and I were forth on is whether any of this material should be encrypted in particular the retried token be encrypted and so as I I think I think my claim is that encrypting it has the nice property that like two centuries there is any structure each I took in France ossification um Martin\u0027s counter-argument I believe is that recall was that on wait what so I think they\u0027re two arguments while you might want there\u0027s one or why you might not want to do it which is it costs the cost in AES or operation or two for the GCM computation further for the AAS computation on the the martin counters i believe with this will be a fixed fixed mask so you can just X or the fixed mask which and so this is there\u0027s no performance there\u0027s no performance consequence really the I have two ways there are two the most there\u0027s some benefit um um because it means it means it\u0027s quite a bit more work for like for someone doesn\u0027t in the draft to see the structure of data on the on because all you\u0027re getting because you\u0027re getting X or something unknown on now I where I was going to say is um there\u0027s actually two ways you go here one way it all three ways one way is the current thing we recycle it at all the second way is the fixed AES key with a fixed mask which turns into fixed masks so you can on which has additional advantage by the way that it means you don\u0027t like redo it means you can use exactly the same computations you ordinarily would do for backup reduction on the on one more thing that\u0027s worth adding is that if you were willing to accept the AES operation um then you could use either disconnection IDs the nonce I mean you would not have a face mask anymore sorry you could use either of these connection IDs as a nonce and then you would not have on you\u0027ll not have the fixed on computation but you also have a better off occasion offense so it\u0027s can Aussie Google a lot of these I get that you have really good instincts about cryptography and that QE use is bad and a big red flag that should just make your knee twitch but when the key is public in the spec implications are a lot less interesting and therefore like this really becomes a beauty contest I in my personal opinion the thing you\u0027re trying to encrypt is the retry token which the server "
  },
  {
    "startTime": "00:27:23",
    "text": "encrypts with an actual key that is not public so maybe we just need to say that the shark of structure should not be visible we already say that the retry token must be distinguishable from a new token for example the there are we could have built this similar to initial meaning that you do in HK DF based on the connection IDs and that\u0027s is better for ossification Nick banks was scared of that because he thinks that we\u0027ll have really bad performance Beck\u0027s on his box that sends the retry as Google I don\u0027t think we care much but that\u0027s a reasonable thing at the end of the day ossification of Paulo bites that are already encrypted is not something I worry about so from my perspective this is a bike shed we really need the token sorry we really need the integrators check at the end but what we use for the key and if we put the token is a complete bike shed I\u0027m totally in favor of flipping a coin and being done with this and I\u0027m gonna cut the queue Praveen I just had a clarification question so UDP checksum is only man optional for ipv4 because it\u0027s protected by the activity for checksum on ipv6 it\u0027s mandatory so my question was are we trying to get protection for the packet beyond what is provided by the IP or UDP checksum here I\u0027m just trying to understand why we need to do this there it\u0027s crazy you as a client application you do not know what IP version your packet Walker over even if the socket you\u0027re using is ipv4 ipv6 you could have a nat64 in the network there are a bunch of NAT sticks force today or if they see an ipv6 packet with a checks party time with a checksum they will rewrite it to v4 and clear the checksum so there are cases where like you will not get it and you have zero control over that from the application so I think there\u0027s really a use here on our court on that I just wanted to clarify I just wanted to clarify on slash respond to point David just made it Jeff one very common way you can start tokens like this is to have a header which to the my header I was indicate sure thank you but unique is the key or the token version followed by a followed by separate text so it\u0027s true if the cipher text itself is white is it just random but often there\u0027s a header which is not chris was just commenting on something earlier particularly what David was saying with respect to the key being public and what Eckert was trying to "
  },
  {
    "startTime": "00:30:25",
    "text": "encourage us to do earlier domain separation is a good thing for graphically speaking we should derive a key from this pixel and use it let\u0027s do that [Music] whether or not it\u0027s encrypted I don\u0027t have a strong preference on that so maybe that\u0027s the bike shed so mum Thompson I wanted to ask the question whether anyone thought this was critical in some way I don\u0027t I don\u0027t see any indication that people think that this is this is a hole worth dying on it\u0027s just that we have a preference from some people not to have it encrypted and preference from others that it be encrypted um one of the the key observations here is that we don\u0027t want to run HK DF and we don\u0027t want to install the different AES key because both of those operations are expensive enough to show up in the test and Nick had some pretty good numbers on what a cost to send retries with the full HK DF plus a yes key installation all those sorts of things so I think we have agreement on that but ecers point about the three points in the spectrum that we\u0027re discussing is I think probably what we need to look at and that is just the integrity tag the fixed key encryption with the way that just just adding encryption in in the way that Davis described and the third option being used something from the original message for instance the destination connection ID the first eight bytes there off for instance as the as a nonce so that you get a different output depending a different mask for the token and so I think if we I suggest that we just do a beauty contest on those and see what people think because I don\u0027t think anyone\u0027s particularly concerned about one versus the other here oh yeah that\u0027s that\u0027s a that\u0027s a good question does everyone think they understand the three options so it\u0027s basically no encryption encryption with a with a fixed nonce or encryption with a varying nonce based on the destination connection ID everyone who seems to be engaged in this discussion understands colloquy regarding other three options that Martin Thomson mention I think between the first two options and the preference would be to go for just doing GMAC compared to a doing X or the reason is that I mean endpoints can retain a pre-generated X okay for one inch of salt but if we are going to have multiple salt based on the versions then it becomes increasingly difficult to pre generate all the xor patterns for each "
  },
  {
    "startTime": "00:33:27",
    "text": "draft therefore i regarding the first options i think the first one mixed losses so so martin the the queue is closed okay this is a clarification question because i realized that from empties discussion I don\u0027t understand so you you did comment about Nick banks having these legitimate objections to encryption and then you presented two options that were encrypted and I\u0027m confused so the the the thesis here is that the that the costs involved in Nick\u0027s experiments yes the cost involved in those experiments was largely to due to the fact that you have to run H KDF a very a number of times in order to get the keys and you have to install the AES case whether when when you get a new AES key you have to run a number of operations in order to get it in the state that you can use it and so those costs tend to dominate in these things but the thesis is that running the AAS operation to XOR those bits is very very cheap and when you\u0027re talking about using AES GCM it\u0027s basically cost nothing because you have to touch those bits anyway to get the cheap GMAC and so that\u0027s the thesis that were operating on here you know there is a cost but I would suggest that it\u0027s very hard to measure that because of the way that this all works so Janna do you have a question of clarification or a point of clarification question as long as it\u0027s a question it is a question this is just piggybacking on exactly this conversation because I was confused as well we had agreed to something in Cupertino does this effectively mean that the agreement remains the same okay so it sounds like this isn\u0027t quite ready to go do you think it\u0027ll be her useful to have a hum to distinguish between those three I thought you did or already understood that yes I want to understand from this this room yes I pay your C because this could drag on if we take this to the list because it\u0027s one of those ones where it doesn\u0027t really matter but we could yeah it\u0027s gossip forever right but we\u0027re not going to close it today so any chance we could have a home on those that\u0027s where I\u0027m going yes thank you we\u0027re gonna hum we have three options the first is no encryption the second is encryption with a static nonce and the third is encryption with a nonce dependent upon the destination connection ID correct so hum for all three if you don\u0027t care or come for none can can ask clarification question so the first is the status quo is that correct and the second oh as first isn\u0027t quite basically what we do for initial "
  },
  {
    "startTime": "00:36:30",
    "text": "encryption right okay this is actually making worry about this home a little bit the first was in the pr2 all these fix the problem because you all have found the point one the different there\u0027s different like colors I\u0027m like fixing work as you all have found the first of us in the PR which is to say just integrity check nothing is encrypted the second is that an integrity check plus things are encrypted but with this completely fixed key so that basically the basically the encryption is the same the same plain text will be encrypted the same way every time the third option is on the third option is an integrity check plus a form of encryption and so that you will with system with a fixed key but with a diversifying nonce so that the same plane is will be encrypted differently each time there was that those are the three options it\u0027s just a process suggestion I have the impression that the second option is kind of really weird so I would like to be first her on eliminating the second option because he doesn\u0027t bring anything in sorry what was that I first suggested it but then my rows with a nonce thing I decided I decided like the third option better stuff so then the options are no encryption or encryption with a nonce based upon the destination connection I do maybe we skip the hum on the second one let\u0027s talk about the first and then turn that in the last so let\u0027s let\u0027s let\u0027s try that unless they won\u0027t feel struggling otherwise no okay has anyone contacted the Secretariat about the lights okay I like to see you so if you believe we should have no encryption please hum now and if you believe we should have encryption with a nonce based upon the destination connection ID please come now it\u0027s about even the second one was maybe slightly louder but I think that was due to maybe one person who\u0027s really good at this this is DK GG i prescribed reporting - hums for no and and one hum for the encryption okay so this is this is does does I guess I\u0027d be interested to hear if anyone believes that it\u0027s great there\u0027s a critical distinction here whether you know we need to faceplant on this for a technical reason or this is just a beauty contest yeah so Jenna and God I\u0027m gonna suggest maybe just asking the room of people can live with either solution and have skin Ozzie actually decide based on whatever feedback he gets on the PR and move forward but he\u0027s written the PR Martin wants to cause we\u0027ve we\u0027ve said this in "
  },
  {
    "startTime": "00:39:31",
    "text": "several ways now it\u0027s a beauty contest echo said it\u0027s different colors but you didn\u0027t use the work by would bite shit but I\u0027m suggesting that this is a bike shit and that we move on that\u0027s what I do so our tactical difference is difference value like I mean it\u0027s just a matter of what how you judge those but basically there\u0027s a question of do you judge put the performance cost of the EES versus the somewhat improved cost of the obfuscation of of the aggression that\u0027s like that\u0027s what you\u0027re but George okay the cue is still cut I\u0027m not really wanting to spend much more time on this right so you have something short Ian I I had a suggestion that originally the reason we went for the first option at least the interim was due to Nick\u0027s bank\u0027s feedback about the CPU cost can we get some feedback on whether like this is actually a blocker for deploying quick or just like kind of painful or something yeah I mean Praveen the best person I can think of channeling it but but if otherwise I don\u0027t really care but I\u0027m trying to you know but can you answer that I think like deployment ways yeah if crypto will add cost right so the question here is if you\u0027re only looking for integrity check play then it seems overkill to me to like go crypto so I have a strong preference for the Nugget option sorry I have a strong preference for the no crypto finalcut oh that\u0027s very hard to tell because it will need to be deployed and measured right so the only I rough measurements okay so you do have a strong preference that\u0027s actually good to hear if we just say no crypto is anybody gonna lie down on the right about that sorry no encryption yeah yeah so Martin Thompson that that assertion is based on an assumption that this is expensive and we don\u0027t have those numbers Nick produced numbers for the other thing which was definitely much more expensive but I don\u0027t think we we can say based on just a yes crypto is more expensive when we were running G hash so running AES alongside that may not cost anything noticeable I don\u0027t I don\u0027t know what what the cost would be let\u0027s take the discussion of the issue then okay I can at least bond her to write up the things that people can see them from them in case anybody\u0027s confused okay yeah I mean if we are strictly speaking about the norms and not to be computing the key then my number says that you can do that at something like 28 a second on on CPU like okay so I keep on saying let\u0027s move on and yet the my client still keeps on fizzle sorry process question as owner of the issue and writer of the PR what I\u0027m really my opinion is on this is irrelevant what I\u0027m getting from the room is that some people assume that it\u0027s one is better because they think something is cheap some people assume that the other is better because they think something is expensive no one\u0027s willing to like lay down the road and kicking and screaming on this if we take it to the list people will take their "
  },
  {
    "startTime": "00:42:32",
    "text": "keep giving more arguments and more opinions and a willl a go on and on I think that I would really prefer for this to be a coin toss here and now so then I can we can versus PR and I can move on with my life if someone actually runs those numbers and has further input down the line to the working group that\u0027s that can ward things and that can ward changes to just about anything in the protocol but for now in our current knowledge in our current state let\u0027s do a coin flip so we can move on so so here\u0027s the thing about coin flips we did four and http2 and if I remember correctly two of them didn\u0027t turn out so well in the long run those are pretty regular odds for them the odds but so what I\u0027m saying is the only thing that could make us make a informed decision is some new data and what can we open this if and when some people cope with do data but I have a very strong intuition that people will come up with a pinion z-- not data so so David let me ask you this as the author the PR have you heard anything in the room today that will make you change that PR not yet but if the coin falls on that side I can change the PR okay the editor is do you still believe that this is proposed already you just wouldn\u0027t flip a coin we haven\u0027t flipped a coin yet for quick um if you look at the list on the PR there\u0027s a bunch of approvals at the same time there\u0027s been a discussion that just happened here and this is exactly coin flip territory I don\u0027t think that you\u0027re gonna find resolution there yes it is propose already based on what we had earlier and now this is there\u0027s more discussion now that\u0027s causing people to maybe think that we could do something slightly different but it was proposed already we can always open it again later as David says if we have data but at this point we are speculating so I\u0027m saying that we should either merge it as it is or do a coin flip but either way so I should finish it I\u0027m sure I didn\u0027t get that I\u0027m sorry I\u0027m saying that we should merge it as it is or do a coin flip and decide which way we are going if Mark isn\u0027t gonna stop me I\u0027ll come here repair toupee own you just need upset the speakers aren\u0027t as loud up here so I can\u0027t hear a lot of what you\u0027re saying we did a hum for what people like we can also discriminate a little more by doing a hum for what people don\u0027t like if you care I perfectly fine with the coin flip myself well the question that I want to ask is is that this is proposal ready we can do a call for consensus on this in the next batch this is already so this had a call for consensus and Ecker raised a point "
  },
  {
    "startTime": "00:45:34",
    "text": "on that saying we\u0027re saying what I said in the rules is the one that he am so Acker has any of this change of mind all right Mike Bishop if I can offer a suggestion as a previous comment noted the distinction between these two one clearly offers a little bit of benefit and there\u0027s question about what the cost is would anyone volunteer to get the didn\u0027t get the data on the cost and see if there actually is a difference okay so if we accept Christians data that this can be done at what 20 gigs three gigs a second that seems it\u0027s very simple I mean if we do a regular AES encryption on packets we have a different nonce for every packet and on the measurement we weren\u0027t at our 20 gigs on the CPU in the window stack so that\u0027s I think we should move on pravin one more one last comment like this is like a DOS attack scenario right so we\u0027re talking about system already under stress so any solution that puts even more burden on the system in generate the retry is I think like not ideal okay let\u0027s take it back to discussion I don\u0027t think we\u0027re gonna make any more progress right now thank you yeah our scribe is reminding us to say our names when we\u0027re speaking so let\u0027s move on to the other documents let\u0027s start with recovery I think so recovery editors we have six open issues are there any that you need to get some input from the working group on and you want to discuss yes definitely the second one and possibly the third I think there\u0027s the - I won I have a highlight at the end that I think is the question at least I want guidance on this actually mostly comes down to pseudocode oh yeah for the working group proposed PR attempts to include a mechanism to limit Steven to increase during slow start we\u0027re not pacing by itself this does not actually fully guarantee the must that we have in another normative section my opinion is I would rather not add pseudocode for cases that we don\u0027t recommend we say you should pace packets if possible and you may not and if you do not then you need "
  },
  {
    "startTime": "00:48:36",
    "text": "to limit bursts but if people would like pseudo code for maze as well as shoulds then we need to kind of revisit that and expand the pseudocode quite substantially so this is not actually a normative issue but I\u0027d like some guidelines on like what is the expectation of the pseudocode doesn\u0027t need to like cover all the things you may do for example there\u0027s no texture no pseudocode right now around detecting packet reordering and increasing the pakery ordering threshold as a result of every rank and that\u0027s another one that I can see adding but it\u0027s fairly complex and so it\u0027s a fair bit of work yeah sorry ian\u0027s what Google said that but I\u0027d like some guidelines here is really what I\u0027m asking for not only about this PR but about going forward and I think we\u0027ll hear from vidi next go ahead oh we lost her actually did we lose me that go no okay we\u0027ll wait to hear back so ah fantastic know me deco we seem to be having some troubles go ahead John alright let\u0027s try one more time no that\u0027s not good go ahead Jenna Jenna younger so I\u0027ll make just a couple of notes the pseudo-code lives in the appendix that\u0027s by design the reason it\u0027s in the appendix is because it doesn\u0027t have any normative status the text is normative the pseudocode is merely a guidance to implementers about how to implement the text that\u0027s already in the draft and to the extent that we want to add stuff or not add stuff there that\u0027s really up to us it\u0027s all guidance in there anyways so if there is an implementer who\u0027s asking for how to do this which happens to be the case I don\u0027t see any reason to not add it at the same time I don\u0027t have a strong opinion on this I personally am of the opinion that we should be we should be pacing but that\u0027s my personal opinion not the working groups okay today I\u0027m going to try one more time and if this time doesn\u0027t work why don\u0027t you give your input through jabber and we\u0027ll jabber relay it to the room now Oh Jabbar please Vinnie sorry about that go ahead Eric Kinnear so I think it does say that we should be pacing and so it feels as though we should have a copy of "
  },
  {
    "startTime": "00:51:37",
    "text": "the pseudocode which is kind of the main like this is what you are expected to do and to John\u0027s point if there is an implementation or a group of implementations where we know that there\u0027s kind of another branch that can be taken in terms of what the implementation is doing it seems fine to have a section in the pseudocode for here is kind of the alternative but I would suggest that that be a separate section so that there is a clean copy of and I yes but basically there should be a clean copy of the pseudocode for if you are an implementer and you just read through the pseudocode and you do that thing you\u0027re following the main recommendations of the draft and where we have a place in the draft like this where we\u0027ve kind of said if you aren\u0027t following the main recommendations you must do this other stuff it seems fine to have pseudocode for that but it\u0027d be nice to have that have a distinction gori gori fair has look at a good thing at the back cuz I would agree with what we just said and in this case we have 496 always some pseudocode it for another protocol to kind of build on anyway so let\u0027s keep the main path really clean on the shoulds and if you want to do the must other and that\u0027s fine but there is already a reference to how to do it on this one alright Andrew McGregor I kind of agree what people are saying about the pseudocode but we should keep this documentation because it\u0027s entirely possible that an implementation may have spacing support that isn\u0027t always functional and then need to know what\u0027s do what to do in we need to know what to do when it\u0027s not working repair to pay on Google this seems editorial sorry yeah yeah old habits die hard no longer at Google thank you very much Daniel Kahn Gilmore relating for video as Jonathan said the pseudocode is a reference for implementations which don\u0027t implement pacing this would provide completeness to the pseudocode for increasing congestion windows okay so editors does that give you the input that you need it sounds like there\u0027s general support for having something here I think we can figure this out this is again like I said it doesn\u0027t have a normative effect so I don\u0027t see any reason why the working group really Mesa spend a lot of time on this but it was valuable to hear input about what people think this should so good should reflect it\u0027s clear to me that the working group is split and not so different away as Jenna and I so yeah I think I think this is useful like we can keep going pravin did want to note that there were a few issues that didn\u0027t get a design "
  },
  {
    "startTime": "00:54:37",
    "text": "tag yet because we are in this limbo where I\u0027m not really sure we\u0027re in the late stage process and I haven\u0027t tagged thing is designed so you might want to go through and see if there are things that aren\u0027t tagged it with either editorial or design that also might deserve discussion and if anyone knows where my badges then that\u0027d be cool thanks my name is Ian\u0027s but maybe you could filter on not editorial instead of any others you want to discuss editors or anyone else just for context I think we have about let\u0027s call it 20 minutes before we need to start the other discussions so for this end for HTTP a couple of issues here you can see those ones right there which make out of C 69 28 normative and can be make a nominative reference to 80 85 this is worth noting because we are changing something or there\u0027s a proposal to change something here that we had agreed upon earlier to not do we had agreed earlier in this working group that we wouldn\u0027t have normative reference to two normative references to TCP RFC\u0027s for the mechanisms that we use here however Gauri has noted that in his review that we don\u0027t have any strong basis outside of these references for some constants that we use for example we use the 69 28 value of initial initial window of 10 the basis for that is our fc-69 28 which is a tcp RFC similarly we use reordering threshold of 3 that is again I can\u0027t remember which one that is so that\u0027s one issue that\u0027s the first one 30 to 45 so there\u0027s a there\u0027s a suggestion and a proposal in a PR there now to make that RFC normative it seems completely reasonable the argument is that 6 928 even though it was written written for TCP the only discussion there is about the size of the initial window and to the extent that the size of the initial window matters it doesn\u0027t matter what the protocol any uses it\u0027s about a network load so we should be able to use that RFC directly and use that as the basis for making our decision I won\u0027t talk about 80-85 as well but I let it finish 6 9 20 at first so you know I guess the question is does anybody does that cause anyone heartburn uh yeah I I\u0027m motivated making that normative it is exp status but I think it\u0027s a useful document to be normative for this one so there\u0027s actually so that raises an interesting issue which we may have to "
  },
  {
    "startTime": "00:57:38",
    "text": "deal with later on which is that this is a standards track document and 69 28 is well it\u0027s a standard strack document but it\u0027s experimental so we\u0027ll be putting a dependency on that maybe that\u0027s alright I\u0027m happy to figure it out later on if folks have concerns about that get to the key to the mic 1 Martin Duke I don\u0027t understand what\u0027s the difference between having a normative references you 9:28 or just saying the initial window must or should whatever be 3 in the quick document just saying the reason why is over here if you care well okay that\u0027s interesting but then is quick experimental status and and how are you going to justify this choice I mean someone\u0027s already done this made this choice if you make it normative then that choice is okay for me here\u0027s the microphone please yeah that seems like a great solution right um I mean I thought I was that soon as a great solution um you know the the purpose of the text is to explain what the Hector doing and like pointing their document explains if it\u0027s not a normative reference it\u0027s like it\u0027s just like citing a paper you say we said it this value and go read this paper to find out why so so Cory is it your is it your contention that we should not have the normative so I mean I like how the documents are arranged I think is is secondary like the question is should the should we have a normative reference on what the initial window is or not I think we should and I think that\u0027s what I would advocate here if the ad finally decides it\u0027s a downdraft that they don\u0027t want to put up with then they can take it back but I think we should have it as a normative that reference because it is the basis on which this decision is being made but I don\u0027t think that\u0027s most people\u0027s understanding with it we take the pacing requirement that goes with it and if that pace and requirements removed then this document could be changed or you\u0027re saying just going to dependently do the experiment you clear that as an experiment going to do here I mean so what normal requirement means is you have to understand in order to understand the specification you\u0027re reading you have to read the other thing and but what I\u0027m not gonna agree anything right now because the I understand the specification perfectly well it\u0027s got a number in it the numbers there the the an informational reference means that you may want to read this in order to understand but background or other information but I don\u0027t like the number sufficient to put the specification and "
  },
  {
    "startTime": "01:00:39",
    "text": "so like like if you look like like any random like like crypto like bit using thing it\u0027s like for like references but like paper isn\u0027t like in like trying to plate SNP and use this security in those things and they\u0027re all and like I\u0027m like he\u0027s very hard understand that the technical choices we\u0027ve made like like like in and you know in these protocols that are reading those papers but you don\u0027t need to and that\u0027s why they\u0027re informative references and it\u0027s the same and so they said to which the reason that you recent is this is the background for this number is chosen as informative reference okay I see lots of nodding heads so let\u0027s keep it brief I don\u0027t want to spend too much time on this gory one last word and yeah like no we should figure out what we want to do yeah yeah yeah let\u0027s take this offline I think but we\u0027ve heard from a bunch of people editors any others on recovery so there\u0027s a similar slightly different but question on 80 85 so 80 85 is the UDP guidelines RFC I can\u0027t remember the exact title but it\u0027s basically about Europe eBay\u0027s protocols and they\u0027re specifically targeting the conditional control behavior the question here was should we have a normative reference to that RFC in recovery draft given that we talked about congestion control but we also do allow but does the does the issue that was raised so yeah so there\u0027s a PR that there\u0027s a PR that that fixes this but it also has changes 80-85 to nominator now this is not a tcp RFC so this doesn\u0027t go against anything we\u0027ve agreed on in the past I think this is reasonable I also think this is reasonable although if we if our position is that we just don\u0027t want normative references in this doc then obviously we shouldn\u0027t do this but I think this is a much more reasonable choice for every any comment on that yeah so sometimes I\u0027m I think the PR is fine this issue was sadly worded we don\u0027t take normative references unless we have a reason to take a normative reference the bug that we had in here was that we had a specification that defined a congestion control algorithm that did not that was optional effectively but did we did not have a requirement to say that if you do quick you need to have some form of congestion control mechanism and that is what 80-85 provides for us and that is what we\u0027re depending on it for and this PR fixes their problem anything else editors if people have "
  },
  {
    "startTime": "01:03:50",
    "text": "time now right now if they care about the hen handshake deadlock prevention stuff I would request that they take a look at 31 61 and the attached PR and give me feedback as to whether I should just close it with no action or not but we don\u0027t need to discuss it now but I asked for a review just cuz I think only three people or two people have looked at it and then the other issue is I think Praveen had one or two issues that is there anything critically do you want to discuss Praveen yeah billion I I just opened few recently so I would request the editors to review them and there are other folks as well there\u0027s at least seems to be one safety should that I found in the AB Limited case and there is two deviations from TCP calculations for a certain time so we should reconcile those okay so same question for HTTP what issues do we want to discuss so probably the most thorny one we already discussed we\u0027ve got a couple that are assigned some with outstanding PRS so I think the main one that I\u0027d like to see working group feedback on today is 30 to 65 so this one is notable and that it\u0027s requesting something that is kind of new to HTTP and kind of not so basically in each one you have headers before the body you have trailers after the body and if you\u0027re doing chunks you have chunk extensions trying to sort out which are their own thing in h2 we don\u0027t have chunky extensions but you can send headers you can send trailers this is a request that we remove the restriction that there only be trailers after the body and say that you can send trailers at any point after the body has started and they\u0027re all just trailers they can arrive any time that\u0027s a little bit of a change I don\u0027t think it\u0027s breaking anything I don\u0027t think it\u0027s required by our Charter so I just like to get feedback about whether we want that or not because you have the whole guy thing this proposal by itself is a sensible thing though I wonder if the quick working group is expected next decision so I think it might actually be a good idea to raise this topic as an HTTP working group issue and then discuss this as an extension to http 2 and HTTP 3 so with various chair hats on I think we do need to go and at least highlight this in the HP working group and make sure that there\u0027s comfort there there are folks like Julian who aren\u0027t following this as "
  },
  {
    "startTime": "01:06:53",
    "text": "closely over there I have a personal response but I\u0027ll let the queue drain go ahead that\u0027s her McManus on its face this is perfectly reasonable this was perfectly reasonable also in each one and as I recall we didn\u0027t add a hook for it into h2 because it was never used and given the no-one\u0027s clamoring for it this time I can you speak up just a tiny bit and given that there\u0027s no strong use case presented here I think we ought to really let that decision ride so so Mountain Thomson we more or less signed on with the contract of porting the h2 cymatics across which were very clear about where trailers can appear this is kind of cool idea though so but I I think that the request here needs to come from the air should he be working heard Luke\u0027s party I\u0027m just reading this description I wasn\u0027t sure if Roy\u0027s request put in scope any idea of this kind of behavior for server push or they pushed response push request from server to client so I think there is something to keep in mind and I might do that so how would that affect push is is the feature request here applicable to pushed requests ie is only capability to add trailers to pushed requests so if the answer\u0027s no then that\u0027s a constraint of this which is already there but should be kept in mind ok um mr. Roy fielding to answer that Lucas\u0027s question I I\u0027m not aware of any tie to push I would say responses I don\u0027t think it\u0027s requests be close to the mic place on the I don\u0027t think there\u0027s any place I\u0027m not aware of any connection to push responses that would require a trailer but then I would I don\u0027t have all that much experience using push responses that lasts for more than a single frame in this I wanted I wanted to came with Micra for it to point out that when we discussed HTTP to a lot of emphasis was made is that we do all these things in the next version of hb2 as soon as this working group started folks said well we\u0027re not going to do another working group hp-2 so guess what quic is a CPU version 2 and if we do not act responsibly when we have needs within the protocol just because of the chartering discussion the Charter must change because it\u0027s taking over a protocol that\u0027s very important to the internet and we can\u0027t have continuing 7-year blocks of time that cannot adjust "
  },
  {
    "startTime": "01:09:55",
    "text": "the basic protocol because the working group that\u0027s working on the next version it doesn\u0027t want to address changes that might have come up for the previous version ok I just don\u0027t so if you have a proposal for a charter change well I mean my right my suggestion is that this is within the scope of the Charter because it refers to http semantics I don\u0027t think anyone\u0027s disputing that it on charter scope right now so so keep your powder dry I\u0027m gonna cut the cue but go ahead David skin Ozzy Google Chrome if there was a use for this someone would have built it as an extension to HTTP too often like when there is a use case for something people build it so that I get that that\u0027s not entirely true come because sometimes the people who build it or not the same people who write the stacks but very often you\u0027ll hear at them clamoring that they want a new feature and especially when a feature can be trivially implemented as an extension there would have been some movement there I would much rather see this as an extension and if look like we\u0027ve been doing with like gos 1:3 and htv-3 popular extensions get ported into the next version of the protocol this is not a population of h2 that warrants putting into h3 so I would and on top of that this would require some work which I\u0027d rather not have to do so I strongly encourage this to become an extension and if it gets widely used then we can add it to the next revision Victor the keys cut Martin Duke I have no technical opinion this at all but I think if we are going to mess with hb2 in ways they\u0027re not immediately germane to quick I think we should you have DHT to be working group give us guidance and as long as it doesn\u0027t influence the the schedule we can try to bring it in and that\u0027s kind of it Mike\u0027s prerogative and I\u0027d rather not waste more time discussing the technical merits of that in this forum with people who don\u0027t know what they\u0027re well people like me who don\u0027t know what they\u0027re talking about Thanks so I think we\u0027re hearing you know that the impetus for this has to come from the HTTP working group and I think from from a charter standpoint you know we\u0027re chartered I think to allow the semantics of HTTP to that\u0027s been a problematic phrase in the Charter for a while because really the semantics of http/2 are driven by the generic semantics of HTTP and so this is probably an HTTP core issue if those semantics are excuse me clarified in HTTP core we can choose to bubble those into HTTP three and that would be the path I think that would be most sensible for this I think personally I agree with Martin this is this is pretty cool I think a lot of people can imagine use "
  },
  {
    "startTime": "01:12:57",
    "text": "cases for this if we\u0027re commonly available what I like about it is that it\u0027s backwards compatible with existing api\u0027s you know it\u0027s there\u0027s one thing about the wire serialization and decoding the frames and everything but there\u0027s another thing about how do I bubble this up to applications and if my API doesn\u0027t support having trailers in the middle I can just collect them and then make them available at the end if the trailer supports normal trailers the API supports normal trailers so I think it\u0027s deployable but let\u0027s have the discussion in the HT working group Roy maybe perhaps you could open an issue on core and we can discuss it even tomorrow and then see where that goes make sense okay sorry an issue in yes an issue in core place HTTP core thank you I assume that\u0027s what you mean by the other group we\u0027re not gonna blow third group into this all right okay good like any other HTTP issues you want to discuss now I think most of the others have pending resolutions or at least assignments so if you have an issue assigned to you please make progress on that PR I would appreciate it and otherwise I think we might be better served by giving the other presentations so I didn\u0027t catch that we might be better served by the other presentations okay so one more thing before we go to those we have an open call for consensus on taking the recovery and HP documents to the late-stage process from talking to folks I think we\u0027re pretty much ready to do that believe that open a little bit longer for any other further feedback on the mailing list and then we\u0027ll we\u0027ll make the transition for those okay so what ordering did we decide upon we decided on pun datagrams first sorry um it\u0027s not gonna do you any good sorry yeah one moment I\u0027m not gonna put random USB things in my laptop nice try [Music] go ahead Eric all right we\u0027re gonna try to keep this decently short because it\u0027s fairly straightforward and we\u0027ve got a lot of other good stuff to do so I\u0027m gonna try to get through all the slides and then we\u0027ll talk a little bit at the end of that so we\u0027ve talked about this before and we\u0027ve had some side meetings and other things in which many of you have engaged so thank you for that but I\u0027m Eric Kinnear in the middle of this slide and let\u0027s talk datagrams so in some of the side meetings and the other conversations that we\u0027ve been having we\u0027ve learned a very long list of use "
  },
  {
    "startTime": "01:15:58",
    "text": "cases where people think that they would like to use datagrams to support unreliable data transmission and I put a couple on this slide but there\u0027s really way more and really the the thing that seems to shine and come out from all these are our applications that would like to have a reliable control stream or some sort of negotiation and and reliable transmission of information between the two endpoints to coordinate some other transmission which can then be unreliable we also notice here that quick provides functionality beyond what you just get over DTLS and UDP a lot of that being the multiplexing of these streams and the last reason we really wanted to do this was because it\u0027s a very straightforward extension that makes sure that we can kind of grease and use the extension mechanism and make sure that it\u0027s working next slide please so we want datagrams in quick as opposed to just dt OS or somewhere else because we want to be able to share that same handshake and authentication context that you\u0027re using for your reliable stream data in your existing communication with some other endpoint for unreliable data as well along with using that handshake etc etc comes with the fact that quick generally is going to work pretty well for that for example DTLS retransmits handshake packets on a fixed timer and quick is going to be using the full mechanisms of quick to get packets to the other side and there\u0027s also a bunch of other quick features that are really nice so things like transport parameters and the ability to negotiate things upfront having acknowledgments of this Datagram data so even if it\u0027s not retransmitted you can tell whether or not it got there and potentially adjust your sending rate or or make other choices based on that information and you can also multiplex additional content over the same transport so you have the ability to sit there and and have your control stream have some other content going and bring up multiple different streams worth of data one of which is this unreliable Datagram next please the design has simplified greatly since we first started talking about it so thank you all for your feedback there\u0027s now two frame identifiers and it\u0027s really just the the last bit there determines whether or not there\u0027s a length field present so if there\u0027s a link field present to you have a Datagram frame followed by the length of that Datagram frame and then whatever data you want and if it\u0027s not present then it extends to the end of the packet so you can skip that extra overhead for those of us who are super concerned about overhead which starts to actually matter when you start talking about tunneling and doing some other things it\u0027s a negotiated via the max Datagram frame size transport parameter which helps a lot when you\u0027re looking at things like PLP MTU D next slide please so in terms of the details that we\u0027ve hammered out since we started talking about this Datagram frames are act eliciting they are not retransmitted ping is the same way but in at least our "
  },
  {
    "startTime": "01:18:58",
    "text": "implementation we discovered we\u0027d made some interesting assumptions about what a Calissa ting meant in terms of recovery and congestion control so we need to make sure that we have the distinction between frames that are not retransmitted and frames that are separately from frames that are act versus not they also do not contribute to flow control limits however they are congestion controlled so you\u0027ve got your congestion control getting your pipe of data to the other side of your connection but there is no sane way to do flow control here so we took that out flow IDs are also gone thank you for your lovely feedback however they didn\u0027t go super far david has written up a draft that adds flow IDs into the HT p3 datagrams which can live on top of this so it\u0027s pretty much exactly the same but it solves a lot of thief low ID questions so please take a look at that document and go there and the other thing that\u0027s noted in here is that max Datagram frame size can be stored and used in gr rtt requests etcetera etcetera next slide please we were really really happy to see that at the hackathon we actually got some inter up on here and there are several more implementations even since I wrote the slide that I know I\u0027ve been looking at adding Datagram support because it should be pretty quick but we\u0027ve got several that that are already doing it and also thank you folks for the Wireshark toast sector tea screenshot oh that\u0027s pretty fun you have a little data gram thing and then there\u0027s a blob that currently says quack so yeah so it so far the feedback from from implementers has been that it\u0027s not super difficult to add support for this frame type there have been some really good discussions around API and how you let an application know that something was probably lost or certainly act so those are good things to keep in mind but don\u0027t actually affect the on the wire bits at all next slide please so that brings us to the end of our hopefully short set of slides so thoughts feelings and the other thing we were looking for this time was to potentially talk about a call for adoption sure so so just to be clear you\u0027re suggesting and call for adoption just for the quick diagram document not the HTTP three bonding correct right there\u0027s an interesting question there that when we do get to the HTTP binding whether that\u0027s done here or in the HTTP working group because our intention has been to hand off h3 to them after we\u0027re done exactly yeah Mike Mike Bishop this is not a question directly on datagrams but something that datagrams brings up I noticed that you reserved two adjacent frame types so that you could embed a flag and the type just like the the inspect frames do do our new reservation policies that require random assignment for that good question I think we just changed the registration policies for well okay we own we discussed in cupertino and we have a PR and part of the guidance and that is that I Anna is "
  },
  {
    "startTime": "01:21:59",
    "text": "that we randomly allocate that\u0027s not are you allowed to randomly allocate to adjacent points under the current text or a block of registration facts in language around that as someone who\u0027s worked with Martin on that PR it doesn\u0027t quite say that so we should just add text to allow it because that makes a whole lot of sense if you\u0027re right I think was next victor was silly of google we use data chrome frame currently in production so I fully support working group taking on such work Roberta pay on Facebook I\u0027m certain that we\u0027re gonna adopt this pretty much and that\u0027s a little scary for me because I worry about the fact that it\u0027s going to be interesting at proxies especially without flow control so I think there\u0027s a lot of hidden problems here that we\u0027ve suffered through in the past again I\u0027m sure we\u0027re going to adopt this and I bet people are going to figure this out which I guess is a good thing because then we can replace it with something better but it might be a good idea to at least put some text in about the fact that intermediaries with no flow control is a recipe for fun so folks folks the q1 thing that I\u0027d like to hear about is timing in terms of whether you think it\u0027s important to adopt this now or whether it\u0027s important to wait if you think we should adopt it yeah crystal and I think we should adopt it\u0027s good work I\u0027ve no opinion on timing I guess that\u0027s for other people who care more about this I just want to say that they\u0027re interesting security implications that come from this particular extension as a Waterdown example of something that might go wrong imagine an application is using a Datagram frame to send a very secret specific sensitive message like fire the missile and you have an attacker who\u0027s like randomly dropping back it\u0027s um waiting to see whether or not things are retransmitted the fact that these are not retransmitted leaks a bit of information and like how that affects you know quick security posture is sort of not clear I\u0027ve been talking with Kenny Patterson about this particular issue don\u0027t know if it\u0027s a big deal but like something to keep in mind and maybe birthday acknowledgement at some point in the draft but ya know send it to be transmitted but quickly jump in as a author of the document Chris would you be willing to file an issue discussing this problem against our github please yeah of course okay I\u0027m going to close the queue very soon I think Moses and I think this is important work to do now especially because I think it\u0027s gonna surface things that need to be fixed in other drafts especially recovery presumably a big user of this will be media "
  },
  {
    "startTime": "01:24:59",
    "text": "applications and flow control and congestion control sections of recovery and even this draft are they need a lot of work you know there are a lot of conflicting and country things and and and it needs to go broader than just this group there\u0027s other groups in other areas that need to weigh in on this too so I think it needs to be done now sooner than later Martin Duke f5 um very exciting and I think are important work my only concern is bandwidth I think there are a few what we\u0027re starting to punt things into extensions that we really really need soon after v1 ships to make quick work properly like version greasing like maybe this version Association thing etc and I think we can probably walk into a gum at the same time but I would like to I think there\u0027s a lot of key resources that need to commit to support to work through all these things simultaneously hi Colin Perkins I think as a minimal Datagram extension this is a very reasonable thing and I think we should adopt it before we finalize it I would be interested to see how people are using datagrams and what people are building on top of it we may find that a slightly less minimal Datagram extension turns out to be a more appropriate design once we have a little more experience flow IDs being the obvious thing in that space thank you the queues closed after Jana and yes you can clearly build one on top of the other if everyone is using a flow ID if it turns out that everyone using datagrams wants a flow ID we should probably just build this into the Datagram Lucas pardhu I support adoption of this document I think that although the design of the frame itself is fairly simple as many issues in terms of how we use this thing and that having a venue to to bring in people to discuss those and actually capture that information is really important yeah I think we should drop this now I don\u0027t think there\u0027s any reason to wait and I appreciate all the simplifications that have got to do it because that makes it much clearer to reason about and gives me a lot more confidence that they\u0027re not gonna screw this up and who are you sorry that was Ian thank you I am Brian we are we are both from Google although entirely different parts of the company uh yeah actually I basically came up to say what Mo\u0027s ed and then what Ian said and then what Lucas said so do it do it now gen-i and god I support adoption of this document but I\u0027ll it is it is a bit of a fur gun like Roberto says but I think it\u0027s an obvious foot gun we all knew this was coming that said I will I will say this one point which is that I think this is useful in other way people are already implementing it so we actually get to exercise the extension mechanism and I think that\u0027s super useful that we "
  },
  {
    "startTime": "01:28:01",
    "text": "don\u0027t need to prioritize this because the functions here aren\u0027t critical I think Martin Duke was right that we have other things but this one is useful because it actually allows us to implement an exercise that okay I think that\u0027s all good input thank you very much Eric I\u0027ll talk to Lars we\u0027ll talk to our directors and we\u0027ll likely see a call for adoption soon but we do need to consider the Charter aspect to this as discussed thank you next up where were we version ago she ation good morning everyone my name is David skinned Ozzy I work at Google and I\u0027m here to talk about quick version negotiation so this draft is joint work by our horse calling myself next slide please so first point wait a minute what are we talking about doesn\u0027t quick already have first negotiation so the yes to some extent the quicken variants define a version negotiation packet it uses version zero and it sends a bunch of versions in quick v1 so the quick transport draft it says if you receive one of those to fail the connection report back up to the application that quick is broken we cannot use quick because the server doesn\u0027t support this version that\u0027s fine when all were the only version in the world is version 1 because if the server doesn\u0027t support it then you\u0027re dead in the water but what if another version were to come about the client could in theory just get that back and reconnect with that version if it supports it - problem if you just do that in AV you could expose yourself to a downgrade attack what if an attacker sent that packet and because the client supports version 1 and 2 and it turns out that one is no longer safe because we found a really bad bug in we don\u0027t want an attacker to force you to use one even though both the client and service support - that\u0027s the main thing another point is the whole main premise of quicks existence in the first place is to be fast - like allow us to actually send the request to the server in a few hour around trips as possible so spending a round trip is a deal-breaker especially for browsers so if we were for example to say like we have quick v1 and then "
  },
  {
    "startTime": "01:31:02",
    "text": "quick v2 comes around some of the servers will support one and some of them will support one and - the browser can\u0027t just go to - and then in the case where some servers don\u0027t support it spend a road trip - then go to one that\u0027s too expensive and that\u0027s a complete deal-breaker so what do we do next slide please so if going back a year but I know we\u0027ve been doing this for too long I don\u0027t remember when we did what at some point we had this as part of the spec the original transport parameters code had support for downward prevention and the way it worked is the server would just send all its versions and the client would say wait a minute I or originally sent you this version and now you\u0027re telling me that we switch to something else but you support it the first one in the first place what the hell that must be an attack abort but someone at the time I\u0027ve forgotten who pointed out that if you have multiple servers as in you talk to a first one it tells you now I don\u0027t support this version negotiation you try again and you land on a different server because you got load-balanced and they don\u0027t have the exact same set of versions then you can end up in a situation where for the client it looks like a downgrade attack when in reality you just hit two different servers that are both equally trusted and both have the private keys for the TLS sir so that\u0027s bad both in the multi CDN case but also if you\u0027re just in your own network in currently deploying your software and so there\u0027ll be a period of time where the new version is hit here but not there so at the time we were starting to argue about how to fix this and as with all the problems that are a lot of the problems that aren\u0027t blocking for quick view on we said okay blunt this out we don\u0027t need it we want to focus on getting quick view on in we can always build this as an extension later this is that extension it comes with two main goals solving the downgrade prevention problem but also this spending an RTT problem it allows us to deploy quick v2 on the Internet in a way that both the client and server use it without the deal breaking spend of an RTT next slide please in order to do that we this draft introduces a concept which is compatible versions the idea there being that if quickly two ends up looking very much like quick view on let\u0027s say for example a quick v2 is quick v1 plus the Datagram frame that wouldn\u0027t change much for HTTP 3 so you could say these versions are very similar would be great if we didn\u0027t spend the RTT so we define compatible versions as when the server receives the client floors flight so in quick view 1 that\u0027s the initial containing the client hello if it can understand that and map that to a v2 or version B as I put it "
  },
  {
    "startTime": "01:34:03",
    "text": "here first flight then they\u0027re compatible so they make mechanism is the client sends the first flight of the version it thinks that is most likely to be supported so for example if v2 just came out that would be v1 and the server and the client says oh by the way I also support me to which I know is compatible with you want and then the server says oh I support that too let me convert your initial to whatever a first flight in is in v2 and run with that so then you the initial that the server responds with is now a v2 initial pretty simple we just need to make sure that we don\u0027t allow downgrade attacks or foot guns next slide please so how do we do this and as with most extensions it\u0027s a transport parameter so the transport parameter contains different things on client and server on the client Ted do you want me to go through the slides or is it for now I have a question at the end okay so the just return on the client contains a few things the first one is the currently attempted version so that\u0027s redundant from the version that is in the long headers of that initial but what it means is that version lands in the TRC schedule and if we\u0027ve learned anything from the history of TLS is that if things are not in the key schedule then you can end up with some really funky attacks where someone swaps it and you don\u0027t realize it so we put that in there that way it prevents an attack where your attacker is just swapping over that version you also add your previously attempted version meaning if I tried a got a version negotiation and tried B when I\u0027m trying be the I\u0027ll say here that oh I tried a originally by the way and I send a copy of this verse negotiation packet I got from the server and just a payload which is just a list of versions that were in the version negotiation packet so the idea there is on the server when you get that you can check if that you if in response this previously attempted version you could have potentially sent this VN packet and the client sends one last thing which is the list of compatible versions that the server could in in-band switch to if it supported them next slide please from the service perspective the first thing is the negotiated version so similar that\u0027s also the version that\u0027s going to be on long headers but that way we landed in the key schedule and then the supported versions list so the idea there is if there are incompatible version in particular especially let\u0027s see version 3 is not compatible you can tell the client hey by the way for next time I support this so the client can cache that if it wants the same way today we cache things based on all service for example next slide so how does this work for downgrade if the attacker is tampering with the version in the long headers though "
  },
  {
    "startTime": "01:37:04",
    "text": "the first part in the transport prior won\u0027t match so the TRC schedule will fall over and the way quick is defined you have a bunch of versions in a bunch of long headers but the first one you get is what you establish on that connection so if it changes after that you drop them on the floor so you have that strong map in here and then if an attacker forges a virgin negotiation packet so it\u0027s a clarification yes you have a client and server have to check these things match you know in order for things to fall over it\u0027s not just a not just that the handshake pulls over automatically sorry that is what I meant the server like both sides upon receiving stuff need to make sure that they match agreed and so if an attacker forges this a great one the list of things like because those are there it can say wait the server can say wait a minute I would have never sent you this the end packet because I know all my servers support this version that\u0027s bad and if the server deployment has different banks where knows like over here I support one and two and over here I only support one then I can say yeah it\u0027s possible that I sent you over negotiation for just one cuz I know I own some servers that do that and also if you\u0027re in the multi CDN use case if you know what the other CDN versions you can do that here next slide quick question Mike bishop if somebody tampered with the version isn\u0027t that part of the ad the packet would just felt worse yeah Bondish initial packets the initial backers can be rewritten all right so the mechanism is pretty simple the draft tries to describe that the draft originally only did compatible versions and kind of a few weeks ago before the deadline we kind of rushed in to add the downgrade prevention and so it makes the draft really clunky to read so that\u0027s on me I think we need to work a lot on the framing and refactor it to make it a lot more sensical but I think the mekka mechanism is correct so what if folks think especially there are cases like the ossification work that Kazuo proposed that might require version negotiation so I think it would be nice to have this in the working group it to progress it okay I can see a lot of people want to talk about this we have about five minutes so I would suggest that we focus on is this an area that the working group thinks it needs an extension in is this a reasonable starting point for that extension knowing that it can change and do we need to do it now or do we need to wait and questions of clarification if you need them to answer the previous questions please go Ted 10:30 my clarification question actually relates to the discussion we had yesterday with a LPN we can\u0027t hear you Ted okay I wanted to ask the relationship between this and the discussion we had yesterday about potentially using a LPN with full-stack as opposed to just the particular "
  },
  {
    "startTime": "01:40:06",
    "text": "application layer if we do a LPN with full-stack does that obviate the use of this okay thank you so to basically this version negotiation mechanism is for the transport layer and if you don\u0027t speak this you don\u0027t understand the client version at the transfer layer you won\u0027t be able to parse the LPN so there\u0027s still a need for this repair to pay own I did not see a clear discussion of what happens in the zero RTT case with us and zero are ITT being the thing that is now fun and providing a lot of value I think that would be great to answer Marc\u0027s things the first answer is yes and to give a ten second answers your TT is a perversion specific concept so if you don\u0027t understand that version there but that is a good point we need to add more text if you do four compatible versions there\u0027s going to be work to figure that out if we do not figure that out it will be difficult to upgrade because you will suffer performance penalties that you wouldn\u0027t otherwise good point cattle Hawks thank you hope presenting in the draft I think this is an important work on the other hand I wonder if there\u0027s immediate need for this to be adopted due to two reasons one is that for something like datagrams can be negotiated using a future and my decided that we only need a version number change when the pockets the critics putter pockets that\u0027s being exchanged during the handshake changes the second reason is that for something like version something like version aliasing we need a different kind of downgrade protection for example the proposal that we had using a new token frame was to use the value of the token to see if a down gray should be prevented so this one doesn\u0027t address the old cases where downgrade should be prevented so that\u0027s one of the reasons I kind of wonder if we can park this until we have a something and do we have a new quick version that actually uses a different country chimerism I\u0027m gonna close the queue after Roy and Martin do better up not in Thompson I think we need an answer to this one before we start working on the version 2 I somewhat disagree with Kazuo though I recognize the points of valid this document needs a lot of editorial work I provided that feedback I think there\u0027s different ways to spell it but the basic framework of what David described which is to have the incompatible and compatible upgrades is quite valuable and so I think we should adopt it now and treat it like the other extensions I don\u0027t think we need to block quickly one on this being complete but I do think we need to be working on this so that we have a story "
  },
  {
    "startTime": "01:43:07",
    "text": "for when we do have quick v2 and we have a design it\u0027s good enough take it well this makes in the right place for us Eric rajala I\u0027m one of the authors I think we\u0027ve traded out this I frankly have some misgivings are at the incompatible negotiation but we can fight that out in the working group but I think like having that like like having a good item to sort to work on negotiation I think like we should do and we can figure out the details later or this is good a good video start you but Google yes I also think we should adopt this though if if it turns out that you know due to the editorial work it\u0027s easier to do so sometime between now and the next ITF in a few months that\u0027s that\u0027s fine but I think sometime in the next you know three to six months we should be doing this in this working group Roy fielding Adobe I I\u0027d like to get a little bit back to the HTTP 1.1 or 1 versioning scheme that has the ability to send optimistically minor version changes that are compatible so is there a way to do that in this scheme and other than that I would also approve adopting so just a ten-second answer so currently quick track at the transport layer doesn\u0027t have a concept of minor versions but maybe the compatible versions is that so we\u0027d have to maybe that\u0027s there\u0027s a mapping layer the let\u0027s take it offline bring that to this because I think that\u0027s an interesting point okay thank you very much David we\u0027ll where we\u0027re going from here I\u0027ll chat with Lars we\u0027ll check with the aero directors it\u0027s definitely on the list Thanks thank you come on morning everybody home martin duke one of these your suspects just to see how much didn\u0027t you talk about it can I see a show of hands who\u0027s read the draft okay about half the two thirds good next slide so this is a about a lot of things but it is mostly about allowing servers and load balancers owned or implemented by different entities to work together basically you want load balancers to work off connection ID rather than four tuples that you don\u0027t break not rebinding resilience and so on and so the ideally for a low state load balancer the connection idea should contain the server ID mapping and so this is just basically proposing several standardized methods of encoding the server ID mapping in the connection ID so that the load balancer can understand a packet and or understand the routing of a pack get to the correct server next slide okay this is turned out to be a useful vehicle for several other problems for instance there\u0027s interest in having essentially the quick equivalent of sink the offload which is which I\u0027ve decided to call retry services so there Nick banks I\u0027d "
  },
  {
    "startTime": "01:46:10",
    "text": "co-author akin for the scheme on how to do that so that\u0027s also in the draft and then also there is interest in eventual Hardware crypto offload for quick and after some conversation of Intel I was certainly convinced that that that would very much benefit from somehow encoding the length of the CID inside the CID and so if you are trying to use those services to provide standard way to do so so we can use ones you know a fixed number of chips that to solve that problem next slide please so basically you know the the underlying value the value statement and quick is that if middleboxes try to mess with the connection it kills the connection and this is amending that that attitude to instead say that the server must explicitly consent this sort of quote-unquote contribution that the middle box is making next slide this is fairly clear from the draft but I do want to highlight this point and a lot of conversations about security it\u0027s a very much a binary thing where something is secure or it is not the point of a lot of these server ID and coding algorithms is to is to hide the fact that a connection that two connection IDs that belong to the same connection are going to the same server however this mechanism has limited ability to solve that problem in this extreme when you one client connected to your server pool you are linkable no matter what the C IDs do next slide conversely if you have approaching infinity clients per server then you\u0027re about as on linkable you could be regardless of how clumsy your scheme is next slide let\u0027s get next slide okay so the first part of this draft is basically just providing some common configuration and what to do given that configuration that is it\u0027s describing some algorithms there are basically three bits to this one is one is what method you\u0027re using to encode the original that\u0027s the issue connection ID in a retry token to allow these retry services a second thing is whether or not using the CID length encoding and then the third thing is what algorithm you\u0027re using to encode the server ID in the connection ID next slide and then there\u0027s more stuff there for that\u0027s parameter specific to each of those algorithms now so again the first part of this configuration then the second part is well how does the configuration get around the draft definitely enables you to go ahead and use whatever existing config distribution infrastructure you have that is probably encouraged however for people who don\u0027t have that there is a very simple in-band protocol it is the overriding design principles or one to be very simple and two to look sort of like quick because the one thing can guarantee about a path we\u0027ve seen a little balancer and the pic server is that it it bits quick next slide I\u0027ve gotten robust and diverse feedback about "
  },
  {
    "startTime": "01:49:12",
    "text": "that in configuration and you can see some of it I have no particular love for what I wrote down there and if the working group as a whole kind of gave me a solid message to go with one of these three one of these four options I would be happy to do so with two caveats number one find something needs to be used this number one and number two I do want to talk a little bit of putting in a different draft so there is of course the general problem of proxy to server communication in TCP we have the proxy protocol that does not work in quick for a variety of reasons there\u0027s some desire to maybe find a solution for quick and I would be happy to have this fall in with that effort but that effort does not currently exist next slide some other discussion points so one thing is one unfortunate property of all of us is that server infrastructures are deciding whether or not clients are linkable when fundamentally that is something that affects the client most of all and would be great to have a way to communicate somehow with clients how linkable they would be if they attempted to migrate and then clients could make the decision as to whether they wanted to go ahead migrators tear down the connection start over the whole new connection should they change IP address so you could do something good transport foreigner particularly if something like quick OB was was a you know a standard a reference point on what was a Lincoln Bowl what was not so I would appreciate feedback on that and maybe there should be a quick extension second issue retry services are they are course version specific because retry packets are version specific all the other stuff is based on connection ID connection ID is part of the invariance - a link field which probably will not have a problem so do we really want to have things that are quick version specific and not version specific in same draft if we rev quick that might just be an editorial pain without waiting deep into the algorithms for people who weren\u0027t reading it there are some some of these methods involve encryption and some of them don\u0027t there\u0027s one that is sort of an obfuscation algorithm that attempts to do some mathematical operations to make the server ID less obvious a lot of people will say I\u0027ve heard from a lot of people that that don\u0027t see that it\u0027s clear that that\u0027s cheaper than just doing crypto on the other hand I\u0027ve heard some pushback from others that that they would really I see didn\u0027t see a an option like this and this okay this actually kind of moves on to the second point which is I think we\u0027ve struggled a little bit to get really robust engagement with a lot of the low state load balancer vendors particularly in the cloud environment Nick my co-author has talked a little bit with the Azure people and and frankly a lot of it is what one obstacles to get through the initial reaction of this sounds like a "
  },
  {
    "startTime": "01:52:12",
    "text": "pain can you change quick so we don\u0027t have to do anything which is probably not a realistic view of things so um you know really it\u0027s what are people will you know this this room is essentially the community of pic server implementer so obviously your feedback is quite important it\u0027d really be nice to do I\u0027m still trying to work to try to feedback from the other end of this of this communication to answer some of the questions like the third one I have on this slide next please so I would like to move for adoption there were a few fairly minor issues that are open on my private github but ultimately I don\u0027t make move forward on these on these larger questions without larger broader working group input and these algorithms are not that complicated I\u0027ve already played with implementing them that was at most you know hundred lines of code to do one of these algorithms if we really nice to start interrupting with them I would hope to maybe do that as soon as Vancouver and definitely there\u0027s some there\u0027s an opportunity for somebody to help help me set that up and define that yeah and that\u0027s it okay Thank You Martin so again we only have a few minutes to discuss I\u0027d like people to focus on is this appropriate for this working group is this the right time is this the right starting point and especially I\u0027ve heard a question of whether it\u0027s appropriate to do this in the quick working group or elsewhere so if you can speak to that that\u0027d be interesting please go to some on Thompson viewpoints I like the model I like the way you\u0027re framing this I don\u0027t like the protocol but we can talk about that I\u0027d probably like to see that separated I don\u0027t want to see any ghetto crypto in any of the things we produce here I would prefer that we have where time limited let\u0027s move on so I\u0027d like us to look pretty seriously that sort of thing one of the things this looks a lot like is the sort of work that happens in the in the ops area in this organization and I predict that we\u0027ll have some young people looking at this one I don\u0027t know how you want to manage that but expressing these as yang models is something that I I suspect will happen whether you like it or not I\u0027m open to using it yang model to express the configuration I actually cracked open the RFC for that and solves 172 pages and then thought maybe I could get someone to do you hang a lot of for a fee yes I don\u0027t think it matters how it\u0027s spelled so much as that what the contents of the model are so let\u0027s concentrate on getting the models right and then we can talk about how to how to spell it okay let\u0027s not go too deep keep the comments brief please pretty Praveen I think the graph is great especially like the fact that we are giving options that are incrementally deployable instead of going to like a really expensive solution it provides multiple solutions on the way there and I think this extension of the three we talked about is the most important because it directly affects quick wave and deployment and like data centers in the cloud so in terms of adoption I think it\u0027s the most important and they\u0027re already talking with like third party "
  },
  {
    "startTime": "01:55:12",
    "text": "load balancers about this so I think it\u0027s very timely and very very important make a livin so I think Martin mostly said what I what I wanted to say I think it\u0027s it\u0027s good that you put like the different parts apart and like as much as I would get because he\u0027s belong together I think it\u0027s like easier to rip them apart I\u0027m especially uneasy about like defining a completely new protocol here for configuration I think what could be in scope here is like the configuration it solved the yang model and the algorithms for sure because we have an open issue on that one in the manageability Draft and I don\u0027t care if it\u0027s in that draft or if it\u0027s separate draft but I think it\u0027s very much in scope and I just wanted to add that there is ongoing efforts about proxying in general so that could could fit and we\u0027re moving on and we probably will propose some more work at the next meeting so that\u0027s that\u0027s in process and we should sync up a little bit more tell me poly Apple yeah so we should adopt it we should adopt it now and I agree that we should split out that other work but the protocol work for the protocol work yeah you leave the definition of the quick bits here I think that\u0027s all you should do and kind of find them maybe another home for that part Eric Kinnear keeping things quick what tommy said but I\u0027d also like to say yes we should also adopt this because we as people trying to deploy things at scale on the server side it will be very helpful to have guidance in this area and I think that\u0027s going to be instrumental in in making a quick that that many people can deploy as opposed to a few people can deploy equations gave Verizon media Yahoo eeveelutions gave Verizon media Yahoo EdgeCast very close to the microphone please so I think this is great work thank you really fantastic to actually define every way of doing it we absolutely should adopt this we this is one of those things that\u0027s missing from being able to actually go large-scale deploy I agree that the protocol actually probably should be split out because some of us will just want to express this as yang\u0027s some people want to express this as JSON other people want to do in band different people and they do different things but ultimately I hate to use there was an example but how we exchange the bits this day and age really doesn\u0027t matter for configuration so just define a semantics and everybody else will figure out how to encode it but the actual algorithms that\u0027s what\u0027s more critical and that requires Interop and that\u0027s that\u0027s awesome what you\u0027ve done so absolutely we should adopt us thank you one more remote should be adopted okay "
  },
  {
    "startTime": "01:58:13",
    "text": "that\u0027s what I heard Roberto I think you\u0027ll have the last word what the last four people said sorry what the last four people said thank you um so I think from what I\u0027m hearing we should expect a revised draft from you that\u0027s pared down perhaps does that make sense yes I would still I\u0027ve been decide shows obviously available there\u0027s a number of contentious issues well a contentious is not the right word I\u0027ve got I\u0027ve gotten no uniform rec feedback on a lot of these issues so I encourage some of that because I might even pare it down more but and that\u0027s what we don\u0027t need the issues to all be solved to adopt that we just need to have a good starting point in the web scope and from what I heard people have concerns about the the protocol portion of it yes impair that out focus on the model and then go from there okay and do some coordination with ops do some coordination elsewhere we\u0027ll figure it out okay all right great thank you so one more thing I think we\u0027ve got one minute left John did you want to speak briefly thank you I have slides during clothes the mic sorry I have you have slides up there on the thing if we have time if we don\u0027t have time it\u0027s fine I don\u0027t have them all right well the if while you\u0027re pulling this up I\u0027ll talk about very quickly Martin\u0027s Eamonn and I have been working on a quick Interop runner that basically automates interrupts testing among various implementations we introduced this at the interim and we had a couple of implementations playing at the inn at that time and now we have a larger number of implementations I can\u0027t remember how many we have at last con over six or seven implementations are now in the interrupt runner and they\u0027re all working with various tests we have I think managed to get most of the tests that currently are part of the interim suite in the Runner the value of using this runner is obviously that you automate all tests and people are exporting their implementation so you can run against anybody\u0027s implementation at any point in time that you want it generally it\u0027s logs it generates various things that you can look at for debugging purposes and we encourage those who haven\u0027t yet put their implementations into the runner to please go ahead and do so that\u0027s about it I was going to show a chart that it produces the matrix but that\u0027s yeah and there\u0027s a if you have any questions about it please write to me or to Martin there\u0027s also a slack channel that you can join what\u0027s the slack channel a quick Network sim I think it\u0027s called okay yeah quick - Nicole - then great thank you I think that\u0027s all we have so we\u0027ll "
  },
  {
    "startTime": "02:01:13",
    "text": "close the meeting hopefully we\u0027ll see a bunch of you in Zurich or if not there in Vancouver thank you very much you you "
  }
]