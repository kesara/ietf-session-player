[
  {
    "startTime": "00:00:06",
    "text": "yeah yeah yeah okay I can do that also there we go um yeah yeah of course you can always shoot me the slides and then yeah maybe it will appear here and I call you I will call your name maybe you're not what's the name of your project foreign [Music] so yeah You can conclude by 3 30 even better yeah but four is really uh everybody needs to be"
  },
  {
    "startTime": "00:02:00",
    "text": "okay thank you yeah yeah okay okay excellent okay so we're almost ready for the presentations for the project presentations the slides are being uploaded are on the data tracker and our meteco and just a brief reminder and a number of things so if you so you're a look well let's keep the presentations within three minutes because we are uh we're asked to leave the room at four because there is another meeting after this one so we really have to keep within the within the time given to us at four um so we try to keep you to the three minutes the other thing is um if you use the the mid Echo full client on your laptop don't forget to mute yourself so you will have convenient the slice in front of you but mute yourself so otherwise we get some nasty sounds um I'm just going one by one after the presentations as they appear at meter Echo so it's a kind of random order um other things I should mention Charles I think we haven't yeah we will keep time for you and give hands yeah give visual uh official feedback official good"
  },
  {
    "startTime": "00:04:01",
    "text": "um the first presentation I like to invite is for the skit project okay there we go sure okay you can use it yeah it's I think all right good right you can use the mic and just it does work okay all right maybe I can try it I do not yeah okay great so I get to go first uh partly because I gave up early so I uploaded my slides an hour ago um but we got a bunch done and we're gonna keep going so um for anybody interested working group meeting tomorrow the fancy slides you'll see here not in three minutes we'll do in a much longer session tomorrow so um look out for that but the um the main thing that we wanted to do with whatever 18 months or nine months old depending hey look at it uh I wanted to really make sure that we can deliver what's skit intended to deliver so this of course isn't everything but this is our headline statement of what we're actually for and wanted to make sure that we could um deliver all of that and a lot of this comes around the idea of what's in the standard and what's in the kind of application layers and the rest of the stuff that goes around the standard in order to build useful products um so what we'd planned to do was continue building we've got an open source interoperability client um we wanted to make more of that um so that more people can add implementations and stuff like that um but really looking at how we use it for real world much more messy things because Supply chains are very messy things ITF standards tend to be very concrete formal things um and those two don't necessarily go together terribly well and we had some hope for outcomes which we achieved so"
  },
  {
    "startTime": "00:06:02",
    "text": "although um certainly I didn't personally achieve everything I wanted to over the weekend uh We've proven quite a number of uh quite a number of points and the main thing that we were looking to do was to take this thing uh that uh dick Brooks one of our working group members provided a vendor response form which is part of supply chain attestations for security and and compliance and see if you can actually usefully get that into tooling that's used for software supply chain and we managed to do that um quite successfully so this idea of splitting out the application layer for things like searching which is definitely not a semantic property of skit and then routing that into formal you know crypto and and cozy envelopes and stuff like that that are absolutely part of skit um pretty much worked uh so you know the thing worked is is the basic um the basic outcome of that so um we did do a number of of other things so um AJ new member of the working group here um has been working on some some other uh use cases for things like software vulnerabilities and again making sure we get that application and and core split done um hanus has tried the open source client and identified some shortcomings that we need to fix up um but the basic thing um that we can discuss in more length uh tomorrow is you know basically everything works we need to improve the sort of quality and a bit of the Precision but we've got a number of use cases in real world Supply chains with application and and core stuff pretty much worked out so successful weekend um overall thanks very much [Applause] okay yeah just one thing I think we forgot to stress uh when you're uploading your presentation please make sure it's a in PDF format because because we need it to"
  },
  {
    "startTime": "00:08:00",
    "text": "be in that format so that it can be pulled in to meet Techo and rendered um the seaboor for DNS I think you guys have it in HTML if you uh if you could redo that one just re-upload in PDF oh Barry took care of it for you your mouth okay all right well thanks okay thanks next uh the IP mode success [Music] hi this is from skku this is our poster for this hackathon and this is our hackathon plan for this itf-117 first of all we try to make our drone flight more safe this time so we extended the Simi 5G infrastructure deployed by g-node B and ground ground control system so through that we simulated an efficient 5G based uh 5j 5 is raised uh simulation to make drone flight more safe so in addition we also implemented a drone to drone Network and Drawn to infrastructure Communications during that method we could we couldn't inter exchange the lightweight vehicle Mobility information there are two types of message in there first one is the cooperated context message for Mobility information exchange and another one is the emergency context message for Rapid Resurgence information sharing oh and this is the brief configure of our simulation as you can see there is"
  },
  {
    "startTime": "00:10:00",
    "text": "some ECM and CCM message implementation in application layer so true that in simulation we could exchange some vehicle information through d2x Network and through this hackathon we could learn that 5G cellular infrastructure can be used to handle safety message in the Drone Network okay oh sorry sir don't oh yeah so we uploaded our source code and demonstration video on GitHub and YouTube yep and next so we are planning to do some implementation the CCM and ECM as icmp version 6 labor Discovery options with IP version 6 over 5G v2x and this is our team members and thank you [Applause] um one moment please right now all right complete and we're back okay um next slides are for"
  },
  {
    "startTime": "00:12:00",
    "text": "Mimi linearized Matrix presentation yeah so you can use the arrows and the time will appear here so perfect uh hi everybody I'm Matthew Hodgson from The Matrix project The Matrix project and we'd like to talk about the hackathon we've been doing in integrating Matrix or linearized Matrix which is a subset of Matrix with Mimi which is the working group for more instant messaging interoperability so just to give a bit more context on Mimi and this is working group building and tropical messaging around the requirements of the European Union digital markets that's providing a protocol to go and Link together the big Tech messaging providers and one of the drafts which we've created is called linearized Matrix which proposes a subset of Matrix protocol that is effectively a hub and spoke model rather than for mesh in order to integrate these service providers together so what we wanted to do in the hackathon was to test interoperability with the various real-life implementations that exist today as well as try to figure out where to put the encryption in Mimi as there is a debate as to whether everything goes over MLS or whether you use MLS just for encryption and then update back into the drafts based on the above so there's a quick diagram of what a linearized matrix could look like as a way of linking together the big messaging providers as well as Matrix on the left hand side as it stands today and linearized Matrix basically being a compatible and dialected Matrix for the lasset so how did interrupt testing go Travis overall the interrupt testing went well there is a YouTube link there if you're"
  },
  {
    "startTime": "00:14:01",
    "text": "interested in seeing synapse which is the sort of existing Matrix Network implementation as well as eigen server which is a specific ground up implementation of linearized Matrix they all work together we also tested with Android messages from Google uh and uh you know they're just kind of evaluating it to see if minorized Matrix could work or could maybe not work depending on how that goes and uh kind of went uh pretty well um so the Android messages interrupt here uh we were able to get it working in at least one direction specifically from a linearize matrix over to Android messages and uh we are actively in the process of getting it working the other direction but it is almost there but how did the other uh testing go so here we've got equipped picture showing element web which is a matrix client talking to synapse the normal Matrix server Birches and Jill stamp modes then talking linearized Matrix through to eigen server which is a horrible command line client no offense Travis written in about 100 lines of JavaScript um and so on the Android messages slowed you can see again elements on the left hand side talking through to real messages by Google or Android messages albeit with a feature flag turned on so I've wrote that isn't available to everybody yet um also on the layering side lots of questions in terms of where we put the encryption um it looks as if we might end up with MLS below but that has a very hard dependency on MLS so we're going to be arguing with the rest of the mini working group um in the mini session tomorrow and that's about it lots of drafts flying around the place if you're interested come and hang out in the mini session on Monday or Wednesday thank you [Applause] thank you very much up next is let's see"
  },
  {
    "startTime": "00:16:00",
    "text": "um okay the soft open playground yep excellent yeah I'm online [Music] sorry remote a remote presenter okay yeah okay I'll shall I run the slides I think that's easy yes thank you [Music] um can I put you in yep please go ahead yeah okay all right hello everyone uh I'm leaving you very happy to share the slow open playground here on next slide please okay let's uh quickly go through the old way also open playground which is abbreviated that's how big uh it tries to build a virtualized network platform to enable either implementation of some mechanisms and it opens up now at the GitHub repository next slide please okay uh regarding the hacks on plan we would like to enable flexible our deployment or some rules based on the cell information base uh with some information collected from various resources under the cell mechanisms such as the rkf-based mechanisms and we would like to emulate the cell mechanisms on Cell op in the four scenarios case one uh limited the propagation or prefixes and gets to Hidden predict this K3 attacks by uh social address both in within a customer code on the case for attacks by Source address both informal applied or appear yes next please foreign"
  },
  {
    "startTime": "00:18:07",
    "text": "specified configurations of visualizer uipf-based mechanisms also op in the four scenarios and we are implemented a traffic generator to verify their behaviors of these Magnum scenes or false scenarios such as limited propagation or prefixes hidden prefixes and the text or by Source address or spoken within our customer cooling or from applied up here as next please uh work we had learned uh first uh Ubuntu system videos enables Low 0pf by default we need to disable it to make the sound op emulation environments work normally and the experimental results so that the emulated sound maximum how gaps in different network scenarios we use some Magnum minions need to be developed to solve the problems uh so op is a great platform to implement and emulate new cell mechanisms and can make Fair comparisons of these magnetisms currently in some scenarios that generated traffic not transmitted as a packet we are now are still working on this issue next please in promoting the project and feel free to share an ideas resource thank you very much thank you thank you [Applause] okay can I invite the um yarn push integration in Apache"
  },
  {
    "startTime": "00:20:01",
    "text": "presentation here in the room or remote okay remote okay [Music] hi um I can render slides for you please please go ahead um I'm happy to present to you our projects yam push integration into Apache Kafka and the people in participate in the projects are Sunny Francisco and Bernard class John Gilbert and me myself from Huawei and function from Huawei and Alex from Juan from Liam the pre the purpose of this project is to ins is to integrate yam push which is a new way of doing natural Telemetry into the Apache Kafka systems with this systems it enabled us to valid always validate the yam push messages that contain the Telemetry data into the uh into the young data store by by using the capcat serializer and this serializer uh um by using the Kafka stabilizer in the serializer and um we firstly we create we collect data from the router and then the collected Telemetry data is sent to bmacct um and then we use lip yarn pushed to pass the yarn notification message and uh and know the main module and its dependencies and we send get schema requests to the router to get the module to get the young codes of the module and then with this module uh with that with the main module and dependency dependency modules and codes we create schema to send to to send to the young schema registry through rest apis and"
  },
  {
    "startTime": "00:22:00",
    "text": "then we get the schema ID back with that schema IDs we we note which subscription the new the the received young push telemetric message is correspond to uh at this at this currently we focus on step two and step 3 which is to collect schema from the router and uh and create schema to the young young schema registry and get the schema again and get the schema ID back next slide please the current challenges we are facing now is find the dependency from uh through the complicated young model dependencies the dependencies of your module includes Imports Imports includes deviates and augments the first two are direct dependency while the last two are reverse dependency so the main module might have included some some container in the reverse dependency module while it's it does it does not even realize it's so we do we need to figure this out and then create a module for the yam push messages to register into Kafka schema Registries and on the right hand side there is an example and we are going to register the schema for from Top Downs which is firstly B module and then a module then a deviation then D in this example we are subscribing to the a container in the a module and then and we're required to fetch all the the main module as long as it's uh as well as its dependencies then we're going to register into schema registry next slide please the current states currently were able to fetch schema from that confusing.com2 and we're all we are also able to resolve all dependencies and generate payload for the schema Registries and we we have implements a"
  },
  {
    "startTime": "00:24:00",
    "text": "simulator that generates UDP native message based on net to po2 and the UDP nodes capits we're now on growing some there's now uh ongoing integration with PMA CCT and we and at the bottom are the drafts that are related and that's all thank you thank you very much [Applause] good next up are the go on um the hackathon results from the DNS table okay okay so we had had a plan uh or at least I had a plan and some plans emerged during this hackathon and this is a summary of it so we worked on DNS out of protocol signaling which is a mechanism that connects DNS with bgp actions right to start announcing the prefix that serves a Zone only when the zone is loaded handling encrypted DNA server redirection it's like the 303 response codes redirect response codes for privacy DNS resolvers and we talked about a very old RV uh from 2004 already 90 years old that needs to be updated based on a work of DNS resolve in IPv6 environment and about new dwarfs about"
  },
  {
    "startTime": "00:26:00",
    "text": "caching resolution failures and we had lots of excellent discussion and Chit Chats and good input for the DNS of work group tomorrow uh also we had a orientation for a newcomer Balu Zhu summarizing current ITF work in the DNS operations group so fresh blocks in the DNS working group yay we introduced momoko Yamamoto with DNS people I will come back to what she did oh yeah yeah uh momoka Yamamoto has a draft in V6 Ops about DNS resolvers in a IPv6 only environment and it turns out that the weak commendations in this 19 year old are feed don't hold up anymore you know we need to update it and there's really good feedback and also we talked about caching resolution there's a dwarf that suggests that resolution failure should be cashed for five seconds but we found out or we came to the conclusion this is too long that this might be good for you end users but not for uh applications and so the final conclusion what did we learn it's always DNS and these are the team members that were at the DNS table thank you [Applause] thank you all right next up is let's see the fecal emitter yeah excellent there we go"
  },
  {
    "startTime": "00:28:02",
    "text": "all right Deuces okay I appreciate that good afternoon everyone we're here to talk about the I uh The Matrix V con emitter uh so uh this is dealing with two specs here uh 200 drafts we're working on the first is um the vcon draft which Dan ably drafted and the uh the Mimi linearized Matrix draft uh and this is the second implementation of vcons emitted from a messaging system the first being one of our partners quick and we were seeking to learn and validate assumptions in the v con spec through wider implementation if you are vcons are A New Concept around here so let me just catch you up quickly the V cons are are basically a interchange container for human conversations based to carry um human uh personal details between uh security boundaries and across networks um and on the right hand side you'll see just a quick topology of what we got running here at the at the uh at the hackathon so we had a synapse Matrix server that was set up with a server API application API and we wrote a node application that would periodically go using that API to create vcons out of each of the Matrix brooms and then push them natively as vcons across the network into the conserver for its use protection and uh interoperation with AI service providers so what do we get done uh we got it working um so you can now attach this emitter to any uh uh synapse server and it will automatically Traverse the rooms and create be cons dynamically from what it sees um we have these V kinds being created on our boundaries one thing I want to point out is that unlike other media types like video and audio messaging does not have natural"
  },
  {
    "startTime": "00:30:00",
    "text": "session boundaries so we have to pick something to uh to bring their their beacons to a close uh quick in other chat systems happen to do that for you through dispositions um so this is the first time we had to do that uh we we put that there are also our second implementation of vcons in JavaScript so that's our our second one in the wild um that's this repo is now on Matrix V con emitter and we've been testing it uh so what do we learn uh the first messaging integration without session management so we talked about that um we also learned that Google bard could write a vcon library in a few seconds uh by the way that's not exactly true but it kind of is uh it really helped um generate This Guy's super quick and I think uh this is going to be a point for later on uh one other thing in the spec we noticed that when we started grabbing all the message interactions for Matrix it became very chatty extraordinarily accurate but quite chatty um this might be a really good place to mention the differences between analyzes and dialogues inside vcons where the analyzes make it more practical and the dialogues are more factual um and then finally uh Dan and I had a good conversation about whether or not we should be putting all the elements inside the V con and I think we agree they shouldn't be but I want to give one sort of quick uh quick summary for that when you give a v con into like Claude anthropic because all the properties are there it picked it up immediately the zero shot on Claude was incredible you give it a v con and say please write me an email thank you based upon this conversation it did it right the first time so that's it thank you so much [Applause] cool next is see there's a fee gone and now we are multipath quick interrupt"
  },
  {
    "startTime": "00:32:01",
    "text": "in group excellence hello this is the multi-path quick interop we have been testing multi-path quick we had five implementations on site here and remotely we had a quiche xcode Pico quick Rusk and Ericsson AI quick uh We've tested a bunch of features in the MP quick spec so connection establishment the negotiation of support validation of established establishment of multiple paths being able to send data over different paths simultaneously Etc uh also testing acknowledgment of data over the different paths we also looked at abandoning paths and doing path status messages uh so the results is that we had uh discovered a number of issues in the different implementations and could fix most of them and we could get interoperability among uh most of the participants here and the interoperability looks something like this we have a matrix here showing various features we have this path validation being able to send data etc etc and then we have servers and client implementation testing with each other so pretty nice results overall and I think that's good feedback for the work on this MP quick proposal and that's pretty much it thank you [Applause] thank you cool um we had a quick and now we are request OTR header hackathon results yep slides these are the correct um it's"
  },
  {
    "startTime": "00:34:01",
    "text": "fine okay okay this is [Music] Hill I'm Siobhan I'm Anton would you work at Brave browser we've been shipping support for this new HTTP header and we realize we don't actually have a demo website um so we made that over the course of the hackathon but essentially the idea is that um if um the like a site which is sensitive would like return this header it's a response header and basically the the presence of the header means that the site is requesting that the interaction with the browser be off the Record and um this is kind of what it looks like in Brave but essentially yeah you can see that this site just you get an interstitial um and browse in Brave which says that the site may contain sensitive content um and it's kind of like think of it as a private browsing mode or incognito mode but tied to one website um there were there's numerous issues um related to like local adversaries that um that we've heard about and there's research on so um the issue is that often folks forget to be in incognito mode or private browsing mode and it leads to like over hiding which is often a Telltale sign for for an adversary who has access and this is a this is a problem because browsers or user agents in general typically don't consider local attackers to be in scope of the threat model so this is kind of an attempt to change things around and um so that's the interstitial and then I guess in the demo website you kind of see the request OTR header it's just one or zero and um then yeah and then I've just put the zero zero draft that we have up which was being proposed in the HTTP working group and I'll be talking about that on Wednesday but um you just see like there's some ux"
  },
  {
    "startTime": "00:36:00",
    "text": "around um that indicating that this website is kind of in like a off the Record mode or like yeah it's kind of like some indication that this is a private browsing mode situation and all data will be wiped after the user closes the website or closes the tab the cookies order complete caches all that stuff uh yeah that's it thanks thank you good next up is um the tea coffee hackathon results are they in the room yep hello so T cozy is a open source implementation of cozy RFC 9052 and 1953 uh suited for iot and embedded uh uses um aiming for commercial quality it's this is the same slide from introduction introductory slide from the last ITF um the focus since the last ietf is based been on um elliptic curve encryption that's ecdh we've actually switched from implementing hpke to the ecdh specified in RFC 1953 it's because the customers are using T cozy have a suit and teep have wanted that so uh there's been a successful interop test with t cozy and the causeway working"
  },
  {
    "startTime": "00:38:04",
    "text": "group examples repository on GitHub so we're doing pretty good there uh just just got that running this morning um that was the it was myself Lawrence and honest doing work on this and then there's a there's a hex dump of like Jose encrypt message kind of overview of where we are on on getting this T cozy 2.0 out the door so we kind of have a clear set of features now we're aiming for um and most of that is running so I'm expecting to do an alpha release of that in the next week or two I was hoping to do it this time but it didn't make it and so the sort of the last thing uh coming in was the encrypt with ecdh and that supports multiple uh multiple recipients so um and then probably uh six months till it's consider commercial quality and then last just a note on the algorithms that are supported uh uh the new things since ietf 116 is the RFC 9053 acdh and then we've pushed out the hpke stuff for a subsequent release so that's postponed that code's still in in GitHub so that's around all right that's it thank you [Applause] thanks let's see you've done that okay okay next presentation low latency crypto are in the room or remote"
  },
  {
    "startTime": "00:40:05",
    "text": "[Music] yeah excellent yeah excellent you're welcome okay uh hi thank you very much from GMO cyber security by Era and this is my pasta of our project okay uh okay I start from background uh recent years uh there are new requirement of symmetry cryptography and hash function for example in nist public comment the security limitation of 128-bit block size like astgm like becomes concerns and in end-to-end encryption mechanisms as frame authentication Power Center is not provided because of the performance problem of hash function to solve this problem uh we focused on the low latency cryptalian is proposed by research team of University of shogo features of Aryan is as follows"
  },
  {
    "startTime": "00:42:04",
    "text": "early on is cryptographic competition based on AES introductions such as asni provides two functions encryption and hash function uh increase encryption of alien the size of block is 256 bit and uh array on hash is the most efficient latency among other hash functions in this hakason is to prepare an environment so as to everyone can try our own so we try to add Orion into open SSL as a result we successfully added encryption to open SSL so you can use new Cipher and new Cipher Suite by Aryan from the hackson results we found that it is worth writing an internet draft from the Viewpoint of the high security and a four month Prospect uh this is the next step of our project uh especially we need to discuss about application and we believe that Ryan could be useful for the topics in these working groups so if you are interested in Oregon"
  },
  {
    "startTime": "00:44:02",
    "text": "please contact us uh this is my team member thank you for your attention [Applause] thank you very much um next is SGA sorry schc of IPv6 we have to pronounce it differently that's remote or in the room okay thanks I can't try to make that quick oh you can use you can do this okay okay so um Chic is a compression protocol that was initially designed for uh using lp1s but now we have chartered a new working group to work on Shake as a general thing over IP or over ethernet so in that context we are defining new protocol types and The Ether types in interior now we are looking at how we could place the sheet compression of our IPS so that we started really from from the the Whiteboard and the context was the Chic architecture but also a new draft that came to shake about ipsec we compressed ipsec with shake so we needed the general context for for doing that for ipsec or anything else and so the first thing we did really was to define the formats that we would use and interestingly we found that we we need a Chic header"
  },
  {
    "startTime": "00:46:01",
    "text": "but probably the Chic header will never fly in the air because we are compressing stuff so it's actually an artifact so we are defining a header for IPv6 that hopefully will not if I will be placed in a packet do you cut on paper but it's it's an artifact that will happen during the the compression phase so we Define a real IPv6 header and then we compress uh possibly disciples Etc and everything else Beyond it so the and then we can place it of our udpr natively so that's pretty much what what we defined and then uh the other was to to start experimenting with this on the open Chic implementation we are not fully done with that but we have started uh creating this virtual later inside openshake to do the compression so in the end you you end up with a packet with that which has an IPv6 header then may or may not have UDP if you need to go through firewalls and uh then as the the whole sequence of this virtual leader plus whatever ulp was plus you know whatever else all in the compressed form so base that that's that's a very good base because that was an item we wanted to discuss at the shake walking group this week so we'll we'll use effectively the result of the work that we did here as an input to the discussion in the working group that's pretty much it [Applause] here we go the the c bar for DNS presentation in the room yeah there"
  },
  {
    "startTime": "00:48:01",
    "text": "yeah hello I'm Martin um yeah my contacts are on the last slide so um yeah uh for the hackathon I implemented a new content format application DNS Placebo which is currently discussed in the sibo working group the idea is basically to provide a sibo-based DNS message format for smaller messages in both Doh and POC doc stands for DNS over Co-op and yeah there's a draft for it you can see it there and our implementation is basically based on python uh using DNS python for the python parts and keyboard 2 for the sibo part and the encoder was already there it just needed some fixing and we also but we still needed a decoder which uh was actually implemented so the encoder is now done but it still needs a larger test Vector the test Vector at the moment is quite small so maybe there's still some fixing to be done um we also found the lip name thanks to Marco um before it had no name now it's called sibo for DNS um and almost done is the decoder which uh can already decode C board to DMS but when you have a packed sibo packet a message you can can't yet decode it um yeah we found some issues with the existing draft so some of the Illusions we introduced might need some rethinking because I was not happy about some of the results and we might need also some dedicated specs for Zulu resource records so for example options um so yeah that that's something we need to definitely work on the draft and then also I made the experience at"
  },
  {
    "startTime": "00:50:02",
    "text": "DNS python is a little bit hard to work with if you don't just want to parse DNS messages but only parts of DNS messages or want to generate them um so maybe I will also make a PR to that library to make this public and this also brings me to my last slide um I was alone for this session at least um but uh yeah you can find me on the data tracker on GitHub and on masterbahn um if you like and so yeah maybe next time I come with a larger team thank you [Applause] thank you Martin um next up is the you know right okay that's interesting so it's the quick in space presentation right excellent success okay hello I'm Mark so the rational of this work is to actually revisiting the possibility of using IP in space space agencies are actually planning to use IP on moon and planetary bodies such as Mars quick compared to TCP is actually a good candidate for space transport obviously IP in space has other issues to be fit to be looked at but you know let's start with transport um two things that our are specific to space Communications in general is that you have long delays you know from seconds to minutes to hours for example Mars is for four to 20"
  },
  {
    "startTime": "00:52:00",
    "text": "minutes One Way delay and disrupted Communications such as schedule and plan Windows of possible Communications because of the orbital mechanics uh quick Stacks have various assumptions mostly default constants that are not suited for this space use case obviously an example is the initial rtt which is usually in the 200 300 millisecond default and 200 milliseconds in space is kind of too short so the quick quick doesn't converge essentially um there was a a proof of concept using one stack from my co-organizer Christianity Ma uh Who provided very good results uh in relatively small changes so that was very cringing and was done a few months ago so the plan was to actually work more in terms of modifying quick Stacks to be suitable for space see uh set up a test environment with delays then learn lessons and maybe write some documentation or draft about the findings what we have done and actually a lot and not a lot because a lot of people came to the table and asked oh that looks interesting and then we started to discuss you know space and even you know geopolitical problems in space um so so most time was spent on having you know very good technical discussions on the problem and solution space not that much of coding um and we had competition because quick implementers were all in the competitive other tables here on quick so I suggest that the chairs that the next akaton there would be only one quick related"
  },
  {
    "startTime": "00:54:01",
    "text": "project and that will be the first to come in so quick implementers may come to my table to our table anyway um even my co-organizer is remote actually joined the multi-pad quick table uh so and that's kind of the list of the people who you know came in discussed having very good comments and uh we'll see you next time thank you very much [Applause] right we are now here at the l4s presentation sure thank you you can use this okay all right thank you all right hello um so this was the third iteration of the l4s interop at the ietf hackathon um first two were um great successes back in Philadelphia and in London so thanks to the hackathon organizers for creating great opportunity for us to come together and plug equipment together and and run tests so and also thanks to the ietf knock for supporting us with a network needs and connectivity and um subnets and routing static routes and all that all right so what problems do we work on today um or this time um uh we're focusing on testing uh very low base rtt connections so this is mainly thinking about uh fiber upon Network and where you may have Edge compute on one end of the pawn"
  },
  {
    "startTime": "00:56:01",
    "text": "and the client on the other and testing congestion control in those environments and looking at are the requirements in RFC 9331 sufficient and it provides sufficient guidance for those very low rtt situations also there's quite a bit of work going on on enhanced tools for testing l4s with iperf2 adding a lot of features for measuring one-way delays and round trip times and providing detailed statistics of that for l4s testing different congestion controllers also it wasn't um planned for this hackathon but we did do quite a bit of testing of RFC 2322 if you haven't seen the use of Roc 2322 in practice I highly recommend that you come over to the table and take a look at it read up on the RFC in advance so you know what that's about um and our network setup uh was brought by Nokia um it's a pawn emulation test bed oops one button quick diagram of that so the pawn emulator is in the middle we have all the servers on the left hand side and our interconnect to the ietf and then on the right hand side are various client devices that were brought by by different participants what got done um so um quick bullet points to point out um so we've tested 101 simultaneous extreme games in parallel on a 200 megabit per second l4s link all the streams getting approximately two megabits per second and maintaining ultra low latency while doing so looked at the low congestion window scenarios and quantization effects with seawind um uh we had a bunch of Raspberry Pi's that with TCP Prague installed and that"
  },
  {
    "startTime": "00:58:01",
    "text": "became a nice testing tool for networks and then all the work on I perf2 including UDP uh dissector for Wireshark that was written over the weekend as well as plans for TCP and we do plan to move into the happy hour space so um please come over and see us there um what we learned um mainly around the the congestion small congestion window scenarios um okay mid window two is something that uh implementers really should uh should look at um last list of team members hopefully I didn't forget anyone um sorry if I did but we do plan to move into the code lounge and continue testing for most of the week so um please stop by yep thank you very much okido the frr presentation is that on in the room or online oh yeah excellent I guess okay hi um at the frr table um I'm speaking representative of the patient by patient I mean uh the theme of the table was FR doctors the Champions being the doctors and bring your own ietf work to implement and uh the project we brought it in to have um help from the Champions were was uh bgp extension for mobile user plane"
  },
  {
    "startTime": "01:00:01",
    "text": "which is um signaling mobile information in pgp and we have a draft for uh sending new asafi information for that so that was the information we wanted to do what needed to get done was in the previous IET f116 um there was an interrupt for that uh draft and it went work uh well for many implementations including property ones and some OSS but the frr implementation no one was pretty familiar with so far our itself so this was incomplete so well this time we worked on that and where we started was um in this hackathon um so the work was pretty old so it's a couple thousands of commits behind the head so one thing we got done was we got that to uh the working up-to-date uh head for the master for frr so that's one thing done and the information station itself was broken too so the moment it received uh the whatever standardized it just uh pgpd just died so we got that part uh fixed to next thing so one type out of fourth in the draft was of completed in this hackathon so uh here are the team members and two people um me and takumi were working on the mob Park so thanks to the doctors and that's frr thank you very much all right"
  },
  {
    "startTime": "01:02:04",
    "text": "the tillers at the station presentation hey yeah that's me I'm online it's online okay there we go I will render the slides sure thanks uh so yeah I'm can you maybe speak up a bit sure okay yeah is that much better thanks okay right so I'm I'm units I'm I'm here to talk about taragon Els and another station remote touch station and uh bringing them together um we've worked remotely for this iitf hackathon um next slide please right um so our hackathon work revolves mostly around a prototype where we're trying to enhance the TLs 1.3 handshake uh to allow the two peers to authenticate themselves I'm using remote attestation so using attestation evidence or acceleration results as credentials um effectively we're working somewhere at the boundary between TLS and rats working groups so I'm not overlapping both of them so we have we have one main working draft which covers um TLS extensions for for this type of credential um and we started working on these at um at the ietf 115 in London and continued at 116. um and for all these hackathons we've mostly worked um on defining and implementing and bridging together the interfaces between the entities in this system so from the root of trust which in our case is a TPM and all the way to the verification service at scitf116 we had most of the tester pieces implemented so we shifted our Focus this time towards the verification and endorsement next slide please so we're happy to announce that now we"
  },
  {
    "startTime": "01:04:01",
    "text": "have an end-to-end prototype that section fairly easy to spin up and use um and we've we've had to essentially Implement uh this time the the endorsement and verification steps for the TPM 2.0 based attestation scheme and we can now provision the identity of the adjuster to the verifier and then we can verify the attestation evidence for the TLs endpoint that does the verification for this we also needed some more glue layers particularly around the on the relying party side um which in our case is the DLS server and they're allowing part you can now interact with the verification service to obtain attestation results which I can then parse to obtain the TLs client identity key uh we also have packaged all the components in containers and bundle them up together um on a dedicated Network to simulate the system next slide please so you can see here the main components for Prototype so we have the tester which is a TLS client the relying party it's a less server and the verifier uh yeah we focus mostly on the verification and the endorsement side and it's worth noting that we just thought we still have some backing functionality that we've left for a future hackathon for example um in the TLs handshake even though we can negotiate that the station scheme at the moment that's hard-coded next slide please and what we've learned so the most important lesson was that we have quite a lot of Shifting formats and interfaces and we needed to synchronize and there was a lot of effort for that but that at the end of it today we do have a pretty stable framework that we can use and extend quite easily next slide yeah this is our contact details and a few links thank you very much thank you [Applause] oh"
  },
  {
    "startTime": "01:06:00",
    "text": "[Music] the let's see up there we are uh the BMP hackathon results are they in the room remote uh yeah remote remote yeah can you hear me uh good enough yeah excellent thank you uh thank you um so hello everyone I'm maximusi researcher at insa Leon I will present our implementation of BMP enhancements to FR routing this work is part of a collaboration with swisscom led by Thomas Graf next please so uh BMP is the protocol allowing a router to monitor everything that happens in the b2p processor router um its first version allowed to describe the inter-domain pass received by a box so that's RFC 7854 it has been extended to describe the past selected as best by BG by the bgp institution process so that's RFC 9069 and uh to describe the past finally advertised to pgp neighbors of the box so that's rc8671 it also provides statistics on the activity of the PTP process uh last but not least uh no sorry in the um in the FR routing open source implementation of pgp and BMP we only had the support of the basic version of BMP so the first one seven eight five four our goal was to bring this up to date with the last rfcs and to provide the first implementation of current working group drafts in standardized ad group next please so the result is now the best pass selected by the pgp processor exported by BMP along with Statistics we have routes advertised to the neighbors that"
  },
  {
    "startTime": "01:08:00",
    "text": "are also exported so the edge about um we do not have all of the statistics for this one because some of them are tricky due to internal limitations of the software we have a first implementation of bmpv4 tlvs which allow for a modular encoding of of information advertised through BMP finally we also have a path marking draft implementation which allows for the advertisement of metadata about the logic applied by pgp during the application of the decision process we have most of the status codes and all of the recent codes implemented for pathmarking next piece we will be opening pull requests as soon as the routing is able to receive them we will open them for both FR routing features and the Wireshark dissectors that we implemented for BMP tlvs and path marking if you are interested in this project feel free to contact us and thank you our contacts are on the first slide thank you [Applause] thank you then we have the SRH results hackathon results yep me again sorry okay great there we go okay so uh hello again still Maximus is the researcher at in Italian um now I'll present the implementation of where shark dissector for srv6 SRH in ipfix uh this works still part of a collaboration with swisscom led by Thomas Graf again next please"
  },
  {
    "startTime": "01:10:01",
    "text": "so ipfix is the protocol that allows routers to export data plane information about ongoing IP traffic srv6 is a segment based routing protocol that allows to Route packets to um Road packets using IPv6 headers extensions to carry carry routing information so the drafts involved after ETF of the ipfix srv6 SRH this one allows the router to export information related to a service 6 SRH routing with ipfix uh we're using one of the first vendor implementation for the tests and our project is to introduce support for IPv6 SRH SRV 6srh data section in Wireshark next slide please the results are that now where shark is able to dissect code points now uh 492 through 502 related to the drafting question the code has been merged into the master branch of where shark and will be available in the next where shark official release um we tested it using the currently available vendor data but not all features were available and some Fields still need to be tested when done they're formatting may need improvements and sorry for the capture that's uh not on the slides looks like we uploaded the older of the site sorry thank you thank you again [Applause] we're nearly there let's see path tracing PPP"
  },
  {
    "startTime": "01:12:14",
    "text": "okay all right hello I'm Lauren from the earth University today I'm going to speak about our project that's pasteurizing BPP we what we wanted is we wanted to implement um bus racing in the open source VPP and also improved open source UV password implementation and documentation what was already existing was the midpoint and the sink um behavior and we added the source not behavior during this agathon into the main line of the of VPP what we did also we we added the API functions for the source node Behavior and and also we build a lab where we tested pass tracing end-to-end from prop generator to prop collector so just we wanted to there is a draftable pass racing and we wanted to do an implementation in the mainland of vpio or vector passport packet processing um so what we have we were go down is that uh we complete also uh successful tests uh what we you see with you see uh there were we had a lab with uh four ecmp paths and we were changing the delay of one of the path to"
  },
  {
    "startTime": "01:14:02",
    "text": "two milliseconds and then to one millisecond and we can see this um pass racing was reporting this we are collecting the probes with a collector and then what we do is that we we have a pipeline that is going to process those probes and deliver them in a Time series database where we can have a look at the results um what we have learned um yesterday we were struggling with our tests because we didn't see all the smps path but at the end we noticed it was a VPP um uh yeah VPP something that we had to to parameters that we had to change to allow the load balancing to happen and also what we have learned is that past racing is working in VPP it's a working as expected and um so the team I would like to thank my team for the great efforts um and we are going to be available tomorrow we are going to present uh yeah the ACT demo and uh many thanks for your attention [Applause] thank you very much um then we have the I think it's the post Quantum x509 group presentation yep excellent"
  },
  {
    "startTime": "01:16:15",
    "text": "this is this hello everybody so yeah we're the PQ and X 509 this was our third hackathon um it was great to get together again um yeah so the goals of our project is adding PQ algorithm support to existing x509 structures that's kind of how it started um three hackathons ago but we're also starting to to work on testing and are operating with new drafts mainly in the lamps working group but new draft standards that often support migration to PQ so that's one thing one of our goals also we provide an artifact repository so we have a GitHub repository there's artifacts that people can use for interoperability testing so encourage you to check that out there's a link at the the end also we provide or we're working on providing a comprehensive compatibility Matrix to show the results so that's a work in progress and we also provide feedback to the uh those standards groups about practical usage and you can see there's a bunch of drafts and we're working on and we keep adding more so it's a lot of fun so what got done so our group continues to meet even after the hackathon so we've been having monthly meetings those have been attended well we actually had to stop using gather because we hit the limit of 10 participants ietf has a limit I guess an off season that you can only use 10 so anyway we moved I think to teams now we've also discussed now having a virtual interim hackathon because we like getting together so much that we thought maybe in September we'll do it"
  },
  {
    "startTime": "01:18:00",
    "text": "again ourselves before the next uh ietf hackathon we had some new members join this time um Ali Becker Brendan zember Chris rodine Chris Brown and George tizopalus so it's great to always have new members so we also tested some new drafts or newer drafts binding for multi-off certs so the implementation of start on that interest in develop oh yeah there's interest in our group two developing a lightweight sn1 parser so some initial work was done on that okay I know my time's almost up thank you we're working on updates to the compatibility Matrix like I said one of the new people that joined is also working on integrating some wolf SSL code so that's a kind of a new provider implementation that we haven't had before so it's great to have that more diversity there we've also done some interoperability testing of the Delta certificates draft and we actually have started working on chems the key encapsulation mechanisms so so we've created some certificates in that one issue that came up oh you discussed a little bit was about csrs and chem pop and what to do with that so we'll probably use the indirect pop method where the the result that comes back is encrypted or um I guess you could sign up with an alternate key or perhaps a new draft is named for that so some discussion on that and also some chem work on CMP updates so some stuff that got done things that we learned yeah so we'll continue to update our await list because there's tweaks to the algorithms that happens and uh yeah so there's we learned a bunch of other things I guess one important things I wanted to point out that Charles pointed out to us is that because we've been doing implementation works for drafts we learned that we can actually provide a link in the draft there's a section in there you can go into provide a link to where the code is I think that's important so people when they look at it"
  },
  {
    "startTime": "01:20:00",
    "text": "can say oh there's code right so that's one thing that we learned yeah so we're yeah just to wrap up we have quite a number of team members we've had up to I think 22 people now we're going to have monthly meetings a virtual interim hackathon uh compatibility Matrix updates and there's our GitHub page so come check us out thanks [Applause] all right um yeah this for now lost so maybe I skipped one so there's one no so there's one last one Opus with dreads says here in the room or online so the web RTC presentation no one I don't see anyone online oh sorry yeah you were not planning to give yeah let's do it you can do it's describes you work hard all right um uh okay so this uh is an implementation rather an application of an already existing graph and a wonderful implementation uh in Opus um it's called red and the use cases that um in a network which is which has a lot of packet loss how do you make up for the loss package so uh this was proposed uh an uh basically a solution is supposed by dread deep redundancy uh to be part of the Opus codec which is the default codec of webrtc and um my objective was to analyze and see if I can implement it in let's say G streamer right which has"
  },
  {
    "startTime": "01:22:01",
    "text": "Opus as the base plugins um so these two were my plans uh first was to analyze for analysis um with the uh tools already inside the Opus repository I was able to um take a data set uh do run the dread computation see the before after results hear them actually very noticeable difference and also see the waveform uh and the uh the scores like uh psq although I'd like to add that psq scores and the waveforms don't give a realistic um uh you know evaluation of the quality that this algorithm produces so uh it's good to hear it and and then the second part the G streamer plugin this was a lot of work it's uncomplete um it requires editions on the encoder as well as the decoder side uh I happen to get through the encoder side but not as much on the decoder side the idea is to um send a stream um in gstreamer and induce a loss of 20 percent enable the The Dread to work its magic and then see the output through the other end so this is work in progress and I'd like to thank uh Jean Mark and uh Jean Booth from uh from the team that I was part of to help me do it and these are the links thank you [Applause] sir thank you did I miss someone here I think I present we presented all the uploaded presentations no then we're complete and then I like to wrap up let's see these slides I think we want to go here one moment this one so uh yeah thank you all for your"
  },
  {
    "startTime": "01:24:01",
    "text": "contributions and your presentations uh again I'm really impressed by all the results we have presented them you have achieved here during the weekend um I'd like to thank the sponsors for the running code sessions here as is Ericsson meta and I can they also made it possible we had nice breakfast lunch and and dinner thanks again um yeah we are asked to leave the room before four o'clock so we're doing fine that's also thank the presenters to keep nicely within the three minutes and that's it's I hope to see you all at bra in Prague for the next hackathon is awesome in November oh yeah and tomorrow evening at 6 30 at 7 30 the hack demo uh Happy Hour in Golden Gate two and three so please sign up if you want to present your well give a demo present your project etc etc thanks thanks a lot thank you [Applause] yeah I saw her coming in yeah"
  },
  {
    "startTime": "01:26:07",
    "text": "thank you foreign foreign"
  },
  {
    "startTime": "01:28:51",
    "text": "foreign"
  },
  {
    "startTime": "01:31:17",
    "text": "questions all right"
  },
  {
    "startTime": "01:32:25",
    "text": "foreign [Music]"
  },
  {
    "startTime": "01:34:48",
    "text": "all right"
  }
]
