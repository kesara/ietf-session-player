[
  {
    "startTime": "00:00:04",
    "text": "warning you continue to surprise ya with why are you with one yeah yeah it seems to be working it\u0027s Wow yes yes I can\u0027t afford for that to "
  },
  {
    "startTime": "00:03:07",
    "text": "happen so don\u0027t be traveling total system spending Thanksgiving in Geneva something important I know ITT study 12th performance and and body experience quality service mama is less than happy well it is but we\u0027re gonna do anyway I think it\u0027s third time we should get going [Music] I\u0027m gonna move this closer to get get it got it good this is horrible it\u0027s too high and it\u0027s too this should change as well but it doesn\u0027t so if anybody\u0027s really tall when you get up here feel free to make adjustments a hi everybody welcome to benchmarking methodology working group my name is al morton one of the co-chairs my fellow co-chair here it was not a fellow is sarah banks say say hi sarah this may be he has said hello so our session is starting now compliment it\u0027s late we have the two-hour session here and police move close to the front i\u0027ve even moved the mic close to the fronts to encourage that and if you are not subscribed to the BMW g list and you would like to that\u0027s the place where you can do it on this first set of slides the agenda slides so it\u0027s wednesday we have the note well slide which you should have seen a few times we work according to certain IETF processes and policies one of the most important which is you know the video recording and also because that\u0027s going on right now and then the disclosure of IPR which we asked you to do as quickly as possible and then but the most important thing is the thing I\u0027ve added at the top we work as individuals in the IETF and we try to "
  },
  {
    "startTime": "00:06:10",
    "text": "be nice to each other and that happens 99.9 percent of the time in BMW G so let\u0027s not break that record so here\u0027s our agenda and our first step always is to bash the agenda to make changes and it turns out we\u0027re going to do that a little bit today but first off we have Luis who has agreed to be our note Caton note taker please raise your hand there Louise so everybody knows who you are thank you and if you come to the mic to speak or make a comment make sure Louise can see your badge so that he can get the spelling of your name and where we\u0027re taking minutes today in the ether pad which is allocated to our working group so our oh yes so say your name like the little tag says and and and Louise will also be able to spell it as correctly as possible so we\u0027ve got the note-taker everybody can help on etherpad we\u0027ve had trouble with jabber in the past is anybody connected to jabber for this group yeah and I doubt that there\u0027ll be anybody there warned but yeah but but I appreciate that you\u0027ve helped us out with this in the past and and it\u0027s a big big help because we\u0027re supposed to provide it I\u0027ve just mentioned the IPR and the blue sheets are going around this is where you sign your name only one blue sheet because we\u0027re a fairly small group for sure you get your name on it and your company affiliation and and so forth so that covers the administrative stuff except for the agenda approval so we\u0027re first going to do the working group status we\u0027ll look at our charter charter and milestones briefly we have some sins to apologize for there and then we\u0027ll look to tim winters who I think is here yes hi Tim for presentation on the next generation firewall networks security device performance I\u0027m authoring a draft on back-to-back frame benchmarks it\u0027s updates for that in RC 25:44 so that gets us through the working group drafts and then we\u0027ll have plenty of time I think for the continuing proposals which include the methodology for vnf benchmarking automation a Raphael are you here Raphael is at lunch okay hopefully he joins in time we may need to shuffle that a little bit we have Wang bong Lee who is going to give us a presentation on the considerations for benchmarking in the containerized infrastructure right on topic and then a yang data model for "
  },
  {
    "startTime": "00:09:11",
    "text": "network interconnect tester management vladimir veselov is here he\u0027s he\u0027s had his draft available for quite a while and this is the first time Vladimir is asked to present it following a successful hackathon over the weekend and I think he also had the hack hack hack demo happy hour last what two nights ago right so I hope that was successful - I note that I apologize I didn\u0027t make it there as I planned but then the last sort of one we originally sort of wanted to do here was the benchmarking methodology for a VPN multihoming devices and restoration which we\u0027ve updated Jim Yutaro and I and then new sort of there\u0027s new comments on service density benchmarking but we don\u0027t have anybody here who can really take them so what we decided to do with this time is to give release a chance to talk about is 5g Benten Network benchmarking again and so that\u0027s an agenda change I\u0027m just describing it verbally and then let\u0027s see I think if there\u0027s time I\u0027ll talk about benchmarking and the common nfe i telco task force which is something newly created in 2019 and it actually has got a lot of overlap with the work that we\u0027re doing here containerized infrastructure the modelling work and and so forth so I mean but I\u0027m gonna I apologize I\u0027m gonna have to play search roulette to put that presentation together if there\u0027s time which means I\u0027m going to type C NTT no piano fee in the in a search in the search window and we\u0027ll see what comes up and I\u0027ll select I\u0027ll select from there so but it\u0027s just an informational presentation I want this group to be aware of a lot of work going on there any uh any bashes to the agenda seeing none seeing no one at the microphone we will move straight ahead uh Raphael is remote up here apparently so we hit the red button yeah actually it\u0027s my let\u0027s be my little oyster and we\u0027ll do the presentation for the vnf benchmarking automation because referral cannot make okay oh man well all right very good thank you for letting us know our why don\u0027t you give us a test a test one two with one two three four five to ten with your audio and we will adjust the volume "
  },
  {
    "startTime": "00:12:11",
    "text": "because it was blisteringly loud here yeah you ate him I guess you won the game by the way okay I think now it\u0027s working can you give me yes hello one two three yeah that\u0027s a much better volume thank you okay okay all right so thank you thank you for that agenda bash and for being ready to go here much appreciated and thank you for utilizing your audio expertise I should also introduce our area director advisor who is a Warren Ace Kumari here at the front address today like a like a strawberry but that\u0027s cool so very cool actually so good so let\u0027s go ahead with those changes so the quick status is you know along the way we adopted this back to back frame benchmarking and that meant we actually got some comments from folks which I almost forgot to incorporate so and they\u0027ve been coming in very nicely so I had to do was wait till the submission window opened again and so now there is a new version of that draft available I apologize for missing the regular deadline so I don\u0027t expect a lot of comments on that today but we\u0027ll talk about the ones we got and how will you were result them so the new proposals keep coming and if you don\u0027t see your name here it means I missed it somehow but but there\u0027s just the the point is that there\u0027s a lot and here\u0027s where we get to apologize and work with our area director to fix all our milestones which we keep forgetting to do so yeah yeah yeah so let\u0027s let\u0027s do that but these are all the things that in fact some of them for example methodology on evpn benchmarking we\u0027re I think we\u0027ve pushed the button on publication requested right and and so for that one we have a write-up to do the document Shepards right up all done oh cool cool okay so great so then it\u0027s an I guess it\u0027s in Warren\u0027s hands that that\u0027s fine that\u0027s fine that\u0027s a busy week I know so let\u0027s uh let\u0027s let\u0027s all be nice to each other as I said at the start no problem one so we we\u0027re willfully behind in fixing this but we will do it okay new RFC\u0027s none charter update none we still got a supplementary page thanks to Sara and you can go that go to this page and and read it if you\u0027re new to BMW G and let me ask the question if please raise your hand if "
  },
  {
    "startTime": "00:15:13",
    "text": "you\u0027re new to BMW G one to two people that\u0027s great so you\u0027ll find this group incredibly easy to join and the reason for that is we\u0027re all very kind to each other but also if you know anything about testing you can read our fundamental RFC\u0027s which will quickly find out from the list what they are and and get on board with what we try to accomplish here it\u0027s a laboratory testing data planes primarily sometimes control planes and so forth folks who\u0027ve just joined us the blue sheets have made it to the front and if you would please sign the blue sheet so that we don\u0027t get a broom a broom closet sized room for next time that would be much appreciated and let\u0027s let\u0027s leave that in the back of course so I just want to give you a verbal update if you go to data tracker and look at the BMW G milestones I think what we have here is an outdated snapshot oh really and I did sit down and do this last year and I looked and it shows with the exception of one all of our milestones are this month so we are technically on track for so only one well okay yes that\u0027s true but I\u0027m just saying technically speaking the clock has not run out August 2019 was methodology for next-gen firewall benchmarking okay um other than that everything is December 2019 cool cool okay well yeah well probably you know who try to keep some expectations realistic and that August 2018 one was always aspirational so okay I think that\u0027s oh yeah and this came up I just sent comments to the considerations for a containerized infrastructure author team we do have the standard paragraph that helps us get through security considerations review and feel free to modify it but always try to put something like this in because the key part is that we\u0027re activities described in this memo are limited to technology characterization using controlled stimuli in the laboratory environment you know we had a bunch of people and security go what the hell are you doing and and and then they finally get to the to the end paragraph and they go oh oh and they\u0027ve done a bunch of typing and it\u0027s you know it\u0027s better if they if they look at this first I guess I don\u0027t know so anyway it\u0027s a good it\u0027s a good starting place I don\u0027t think this is the final place feel free to edit this as you go and I guess that\u0027s it yeah so I just want to make a quick note especially for newcomers with new drafts BMW G are only issues I believe informational track drafts worse they are RFC\u0027s we are not on the standards track and I bring this "
  },
  {
    "startTime": "00:18:14",
    "text": "up because the last the last document that we just sent in for publication when in a standards track and Cynthia actually caught it and came back and said did you intend this or did you mean for it to be informational and even I missed that so it\u0027s easy to do because so much of the IETF tends to be on the standards track and so we tend to overlook that so I just wanted to call out hey while you\u0027re cutting and pasting that paragraph that I\u0027ll just had on the screen into your draft we want to make sure that the status is informational and if you feel there\u0027s some particular need for that exception I guess you could let us know but it should we would generally expect it to be informational and by the way the history and the reason for that is that there was at the time that was sort of decided this group goes back to 1989 by the way there was no process to move testing internet drafts or RFC\u0027s along the standards track you had to look for interoperability and prove that interoperability and deployment in order to advance along the standards track so in the IP PM working group IP performance metrics working group we figured out a way to get our drafts and RFC\u0027s on the standards track by proving interoperability in the form of measurement equivalence and we have a process for doing that and that process would very much apply to benchmarking methodology drafts we could modify it a little bit certainly apply it but nobody has really strongly petitioned to get their draft on the standards track and use some kind of form of measurement equivalents to to prove that it should be moved up to a standard so and we\u0027ve done that successfully with a couple of the key IP PM specifications let me tell you there was a lot of work but it was worthwhile in the end so this is there\u0027s something we could talk about some more when the last time I raised this one when the I ppm process was new people weren\u0027t so interested in it in fact our industry has been just completely satisfied with taking these informational drafts although they have all these requirements turns in them and building their equipment to satisfy those requirements so if there\u0027s no need from the community then we won\u0027t pursue it you guys tell us what you want to do alright thank you for that good point all right so let\u0027s let\u0027s go back to the agenda here for a quick look so Tim is going to be up next with the benchmarking methodology for network security devices "
  },
  {
    "startTime": "00:21:47",
    "text": "okay so I\u0027m presenting on a working group draft next-generation firewall performance testing we have a couple of updates we posted a new draft yesterday yeah I think yesterday a new one got pushed and I\u0027m gonna talk about some of the changes and just kind of highlight them um just a quick reminder this is the reminder slide we have going on here this is really creating performance testing for next generation firewalls the last IETF draft for benchmarking firewalls was 15 years ago probably time we updated most of the work hasn\u0027t been happening directly on the benchmark working group mailer it\u0027s been happening through a group of companies that have gotten together at net sec open forum and it\u0027s basically two labs three tool vendors and eight firewall members that have been working on developing all of the sections are inside of this so I\u0027m gonna report on the updates we have first thing is is we\u0027ve actually started beta testing so we have several firewalls that are in labs both at the UNH iol and a NTC that are actually running testing one of the things we\u0027re doing and it\u0027s going to come up is we\u0027re comparing measurements from multiple tools so we have multiple tools at multiple labs and we\u0027re finding it not everything surprise surprise was measured exactly the same so we\u0027re going through figuring out what makes the most sense you know things like time to first byte those kind of things we\u0027re negotiating on how to properly measure it you know one thing we want to make sure as part of this is that no matter where you go what lab you go to or what tool you use you\u0027re gonna get the same answer so that\u0027s a big part of the effort that we have right now it\u0027s a beta test and we\u0027re also comparing measurements from different firewalls to see you know what affects them and what doesn\u0027t affect them and I\u0027ll talk about more of that in a second some of the output of those that\u0027s all ongoing right now I think we\u0027re gonna wrap up probably in the next before the end of the year I think we\u0027ll have our first set of results to be companies to publish is where we\u0027re at timeline wise so I know in the Charter we have this date that we\u0027ve missed I think we\u0027re probably going to finish the actual testing and be able to finalize the draft probably by the next ITF will have we should have everything in a better spot to go to working group last call yeah why are you calling generally so when you go into UNH or yeah NTC it\u0027s paid and yet you called it beta testing so I\u0027m wondering it is there are going to split hairs I\u0027m just wondering is there something you think you\u0027re missing which is why you\u0027re calling it baby we\u0027re calling it beta because we\u0027re going through multiple runs so we do a run and then we adjust we exchange we exchanged emails discuss then you\u0027re gonna see two of the things that we weaved in a first round on firewalls and said oh thank you yeah that\u0027s really why we\u0027re calling it beta updated firewall configuration so this is two of them the original draft and now it says must had a should for configuring ACLs and basically what we found is that you know obviously that affected performance and realistically you know most firewalls out and will have some amount of ACLs so we said hey every firewall should do this so they all can be measured correctly and have the right ackles so "
  },
  {
    "startTime": "00:24:47",
    "text": "we\u0027re adding that that was one of the things you know one of the labs the firewall vendor didn\u0027t have them configured originally and the other labs did we\u0027ve worked that out another one that came up was traffic logging the original draft said all traffic which obviously is gonna have a big impact on firewall performance we updated it to say you know flows sue so it doesn\u0027t have to be every packet the first goes through the firewall you know it this was really the performance was going to drastically change every packet had to be logged for the actual testing one thing note when we do this testing we try to set up the configuration once at the beginning to see the security of the box and then we use that same configuration for every one of the test cases so this is the kind of stuff we\u0027re working out through the beta the other updates we made to the draft there are two main things that we made I\u0027m gonna talk about the second bullet first because it\u0027s just easier to talk about we had a lot of extra KPIs that weren\u0027t necessary and as we went through the beta testing we said this is this is of zero value so we removed a lot of those a lot of the original ideas we\u0027ve had we\u0027ve as we actually run the test and we find that there wasn\u0027t a whole lot of value so we\u0027re removing the extraneous kpi\u0027s if you do add if you can see which ones came out I gave an example of a couple of test cases where it just made more sense the other thing we removed that we weren\u0027t currently measuring was application transaction latency I wasn\u0027t sure this was the best KPI to measure things so we took it out and when we took it out we had a several places where we wanted to measure it we found better ways to measure different values so we basically took it out and found better ways to measure the different measurements that we have and we\u0027re going and using those going forward we think we think now we\u0027ve got it better and like I said we\u0027re hoping to wrap the testing up for the first set of firewalls and then it will be more turn the crank going forward yeah I think that\u0027s everything any questions yes okay yeah it\u0027s on okay Tim I\u0027m wondering how we\u0027re best going to transfer some of the discussion here yeah to the BMW GG lists I\u0027ve been wondering that as well I I think there\u0027s a couple of options yeah okay give me your ideas yeah well one of them is definitely to do we have a change log we\u0027ve made some decisions I think some of that should go directly to the list to the benchmarking list as we go forward as we\u0027ve decided some of these things are happening between you know between the benchmarking group we should be clear when we made changes to the draft what\u0027s going on I think now we\u0027re at the point where we should be doing that so that\u0027s something I\u0027m gonna bring up with the benchmarking working group I\u0027m gonna try to make an effort to match the two going forward so I think that\u0027s gonna be one of my goals going forward so we can help give the group more insight into what\u0027s that\u0027s kind of a black box situation at the moment which right and it\u0027s a I mean it\u0027s it\u0027s a "
  },
  {
    "startTime": "00:27:47",
    "text": "chance to get additional input yeah input on these I agree on these items I mean I I appreciate there may be a need to anonymize the specific pieces of equipment involved yeah that\u0027s fine to do that we don\u0027t really care who who\u0027s what broke this yeah and so forth it\u0027s really just about how do we clarify things so that measurements clear and it and it ends up sort of ensuring the the kind of multi device equivalent measurements that I was talking about that would be great yep and then one thing another thing we did we did start putting the draft and get to help us track changes you can definitely make that link available so that people can see as commits go in and pull request they can people can easily see what changes are made I will so that doesn\u0027t get at context but I think that will help I think the next you know the other thing we need to do a better job is when we decide as a group you know they get together once a week and as a group if we decide to change something based on the testing that we give that feedback at this point I think the drafts far enough along that we should be getting blow-by-blow at this point even even before you decide it\u0027s it should be a probably yeah we\u0027ve got an A and a B possibility here and what does the working group think I mean I think that\u0027s what that\u0027s the level of them okay there was a time when when you guys were just developing yeah we were deadly crashing a lot more I think it\u0027s what the beta testing and if we\u0027re at the point where you\u0027re probably right is I will make an effort I will bring that back to the group and say yeah look I think we\u0027re at the point now or when we\u0027re trying to decide these things we should just go to the whole benchmarking group instead of to the net SEC openers right right I mean I think that\u0027s fair that that\u0027s really got to happen otherwise I can hear you know people say you know this wasn\u0027t developed in the IETF so why should we take it through our standardization process yeah I even that informational model so let\u0027s let\u0027s do that okay only I will bring up feedback back to the courtesy so any any questions about this topic or the topic of measuring firewalls in general yeah thanks for the presentation Tim I think I wouldn\u0027t expect too many changes any more hopefully so yeah I completely agree we should have done a better job and we will try to do a better job in keeping the team WG mailing-list informed but I think from my point of view I would rather like to try and progress the draft towards like last call or something like that not sure what your advice is on that era pardon Oh last call Burton good let\u0027s call so yeah I know I "
  },
  {
    "startTime": "00:30:47",
    "text": "appreciate that Carsten yeah yeah it would be III don\u0027t think we\u0027ve had the list discussion yet to warrant that so let\u0027s get some let\u0027s get some reviews from the benchmarking community and then we can justify that working group last call I think and and I and I appreciate Carsten that you\u0027ve given us lots of car cementum that you\u0027ve given us lots of opportunity to do that I know that I\u0027ve provided comments I know that others have sort of held back let\u0027s let\u0027s put it that way to this point but we need a little wider review on the BMW G list I think that\u0027s fair to ask okay okay that\u0027s that\u0027s the one precondition that we need to meet and of course to get the draft stable and to verify it in orbiter pilot testing program or are there more preconditions I think the precondition for us is always to have the conversation on the list so we can get the eyeballs on it get folks weighing in and then as chairs we can say yep there\u0027s clear consensus here or rough consensus I suppose but some kind of consensus to move this along to working group last call so I realize I\u0027m one hand saying at that out loud I realize you probably already know that but it\u0027s not a I mean I guess that\u0027s an always precondition there precondition there\u0027s nothing special about it we just want to see it formally come over onto the list have more of that discussion and then we can easily move it along to presumably looking at how it\u0027s going right now moving this to working group last call would make sense at that point thanks Kirsten okay any other comments I don\u0027t see anybody else at the microphone so thank you Tim and Carsten both okay so al Morton is back again this is gonna be a brief presentation on the updates for the back to back frame benchmark "
  },
  {
    "startTime": "00:33:51",
    "text": "one is this one one up is powerful ah yeah okay thank you ah all right too many buttons let\u0027s see so there\u0027s been lots of comments on this including from the authors of the search search algorithm dress Maciek Ratko and and at the last meeting Tim Carlin from a UNH offered to provide some comments and so since the original submission deadline we have addressed vrak COEs comments and you can see all of that going on in the email on the list I\u0027ll and I\u0027ll briefly look at the diffs here in a moment and the comments from Tim also a reply on the list there so things to keep in mind this is one of several updates to the sections of RFC 2544 and I I realized that there\u0027s actually a lot of updates that we\u0027ve performed there so the previous updates include the ipv6 address space updates to reset and restoration MPLS benchmarking is kind of an update to 25:44 and also there\u0027s a latency measurement in 2544 which is based on one packet state-of-the-art of all the test equipment around is pretty much that they\u0027re measuring at least a sample of packets and very often all the packets and providing a minimum an average and a maximum so I mean that\u0027s a de facto change to what\u0027s in 2544 so so this is this is about measuring buffer time and trying to correct the measurement of buffer time that we get when we when we think we\u0027ve measured it and so we use the simple example of a traffic generator and the on ingress to the device under test packets are stored in a buffer there\u0027s a header processing function they\u0027re removing packets from the buffer and then sends a method at the ingress to the receiver and in the in the so in this form of testing ingress burst arrives at the maximum theoretical frame rate so initially the frames are buffered and a header processing removes them and approximately at the measured throughput rate some we\u0027ve previously characterized the throughput we know what this device can do in terms of that header processing rate frames that have not been processed are have been processed are clearly not in the buffer and so the size of the bursts that you send before you send too big a burst and packets or frames are lost it is actually reduced "
  },
  {
    "startTime": "00:36:51",
    "text": "by the header or the packet frame processing so that\u0027s the calculation we\u0027re trying to put together here and and we do that so that we get a more accurate view of the actual buffers buffer size and the time that\u0027s available so a a few just clarifications here in the text that we talked about with the previous testing so the number of back-to-back frames with zero loss reported for a large frame size was unexpectedly long for for large large frames this is cases where the large frames and their frame header rate didn\u0027t exceed the frame header processing maximum rate so basically there were few frames or no frames in the buffer when you were sending frames at these high frame sizes maximum that you could and the measurement devices would not necessarily detect that so we\u0027ve actually got prerequisite testing now to say anytime you\u0027ve got a test where you you send frames at a particularly when you get a throughput equal to them the maximum theoretical you don\u0027t test for buffer size there it\u0027s just not possible that\u0027s the way this it\u0027s one of the ways that this update improves things and then it\u0027s apparent that the let\u0027s see what\u0027s this way one here it was found that the actual buffer time in the dot could could be estimated using the results from the throughput tests conducted according to 20 section 26 one of RFC 25:44 it\u0027s apparent that the duds frame processing rate tends to increase the implied estimate that\u0027s what I\u0027ve just been talking about according to section 26 point 4 and a calculation using the throughput measurement can reveal a corrected estimate so this is the additional text we\u0027ve added and this is what that sort of what that that equation looks like although this is a new equation so in the reporting what we have is that we have a table where we ask over repeated tests of the longest burst length of back-to-back frames we ask that the minimum and maximum and the standard deviation be reported in addition to the average length and so we have a table that makes that possible and then of Ratko asked hey look you know you\u0027re sending these frames at this maximum theoretical rate the back-to-back rate on the ingress interface what if what if I my tester and I know that I want to understand the "
  },
  {
    "startTime": "00:39:51",
    "text": "frame time of a lesser rate and we talked about that a little bit this is the calculation that lets you figure that out so it would be the actual buffer time for a lesser than then back-to-back frame size rate and and that\u0027s the calculation there a report you can report this value as I says now in section 6 but properly labeled so that it doesn\u0027t confuse the the situation and yeah and so this is basically what I talked about here that there\u0027s two factors in creating this corrected buffer time the original implied buffer time where some of the frames had remove from the buffer we fight we figure out how many have been removed by taking the measured throughput over the maximum theoretical frame rate and that\u0027s the factor we reduced this implied buffer time by so I think that\u0027s it any questions or comments on the comments and questions that were raised seems not so I\u0027m not asking to advance this at this meeting or anything like that but Sara so if you go back to the previous slide he\u0027ll in 2544 I know this is so nitpicky in 2544 there\u0027s one instance of standard deviation I had to go back and look to see if it actually calls it out in they do and it says should be reported and I think or excuse me it says should be reported yes and I think your text calls for go back to one more it\u0027s a three times it should yeah Oh yours should as well uh not me 25:44 is may in yours is should it\u0027s not a huge nitpick I don\u0027t think I particularly care one way or the other I just wanted to call out hey there is a slight difference there\u0027s a lot of differences here so let\u0027s you\u0027re comfortable with shit yeah thank you the question is is the group comfortable with should so I see one nod so that\u0027s good and I think it\u0027s good to characterize the variability as well I mean I think that\u0027s a very often the difference between may and should it has been determined you know in this particular case twenty years ago by the ability to look over the individual results and I think that you know we\u0027re it\u0027s it\u0027s not a bad idea to make this a recommend it\u0027s still not must so yeah I think those tests gear equipment manufacturers are going to settle the the score on mayor should here anyhow "
  },
  {
    "startTime": "00:42:52",
    "text": "right I just thought I\u0027d ask you know that\u0027s good I\u0027m glad you\u0027re glad you made that check there\u0027s only a couple of I mean the the 26.4 section for a description of this test is extremely concise we\u0027ve now got like about a six page memo that goes into this so and and it\u0027s you know and it\u0027s doing a lot more than than 26.4 ever ever envisioned I think I can\u0027t I can\u0027t wait to get Scott Brad nurse review so I was gonna ask you that offline actually I wonder what Scott gonna think about this I don\u0027t know but we\u0027ll find out I guess I\u0027ll have to let\u0027s make sure he gets the OP stirrer review I think you\u0027ll I think you\u0027ll be glad to see this so any other comments no okay good thank you so that gets us through all of the working group drafts and now I guess we\u0027re gonna have the remote presentation from okay again just want to that\u0027s the mic work yes okay great hello everybody my name is mano coaster I\u0027m going to replace Rafael holder because he was not able to make it and I\u0027m trying to be present our and updates for our draft on methodology for vnf benchmarking automation which is now submitted in version 5 um if you go to the next slide this is basically what happened so far let\u0027s go briefly put you into picture and this draft is about automating benchmarking of virtualized Network function so it\u0027s it\u0027s not about and what measurements actually perform on these virtualized network function it\u0027s more about how to specify the benchmarking experiments and how to specify the results and and how to automate everything end to end because general idea is if we have our network functions entirely developed software we can make much more use of automation and run those experiments fully automated on the next slide we have overview why or what was updated in the draft first of all we are presenting in that draft and different models which describe on the one hand how the experiment should be performed those models are called INF benchmarking descriptors or short we have big E\u0027s those descriptors can then be wrapped or used by automation would actually run those benchmark well let me updated maybe n fvd specification and we also provide now young models which specify how such a descriptor has to look like and we started to also prevent the morale for "
  },
  {
    "startTime": "00:45:53",
    "text": "me and F performance profile which is in our case the term for describing the results from such an automated benchmark and also started to develop a young model for this problem we addressed comments which were sent to remaining.this by luis on eros and i think they were even more comments coming up on the mailing list and i remember comments from even when Rossum they not get addressed but there is upcoming number of reviews on the mailing list which we are working on if you go to the next slide yeah this are the main main points in our update this time first of all as I said this means F P P so this is basically a model which gives you the result from such an automated benchmarking procedure and it\u0027s basically kind of a template in which these automation tools can fill in the measurement results so general measurements are divided into tests subdivided into trails and so on and this model basically describes how you can um give those results in a structured manner so they become machine readable so you can define different metrics you can define how many trails are executed things like this and all this is basically captured by this model so you have a kind of a machine-readable outcome of your benchmarking then the next point are these young models as I said and those models are right now available on each F we put the link here so you can go there and check all those young models this is also something we have as a question we are not yet sure how to add those who are attached those young models to an ITF draw so we know that the IDF s there are the young modeling rules and we try to follow them and we know that in the data track up there are existing drafts which have young models designed so our question would be how how to do that how to get our young one attached to this so maybe we can get an answer to this later and in addition to the draft we also updated our two reference implementations one of them in young and the other one is TMG bench this was also one one issue which came up I think on ITF 104 that the journey opens go through was not yet available open source this has changed no suppose Huth are available and linked from the graph and on top of that we did first test run with both of the tools and which are results on the step test ones are also available on github and you can check them out the idea here is that we try to compare if we give both of our towards the benchmarking description let them run the experiment and how similar are the results obtained by them and do they really do the same when given the same information and the next slide just gives a brief example on this and basically on the left side there is a "
  },
  {
    "startTime": "00:48:53",
    "text": "picture of the model and on the right side there are the example outputs of two two routes so they are not 100% aligned but they are pretty close to each other right now we are looking into the details here and this is just to give you some examples I think we can go out they go to the next slide here and yeah that\u0027s basically on our to do list the BNF piggy as I said we check with our reference implementations and the same check needs to be done now author for the vnf peepee this is work to be done we are still trying to update those models a bit because we got some additional feedback from our colleagues so they might be any minor changes and I think there are a lot of synergies to other drafts in this in this working group especially the young data model for a network interconnection tester management so I\u0027m quite interested in in their presentation maybe we have near sand familiarities or can make our models compatible to each other or something like this so this is something where we think a collaboration might be possible and going to the last slide to recap 0.5 was updated loaded and comments are arriving on the mailing list we try to capture all of them and address all of them the reference tools are now finally available and from our stage yeah we think the draft becomes more and more stable and once we are able to add the young models to this ITF graphs in the data tracker and we would be interested and what the net next step could be if we should aim for having a last call or something like that that\u0027s more more like an over questioning and that\u0027s basically everything thank you okay thank you Thank You Manuel stay with us for a moment there um folks who would like to make comments please go to the mic now hi ya ibadi Whiteside instruments it is really relevant you\u0027re dropped to the meat to have a formal way to represent test results and the idea is good but I think you need some help with young the young models I have looked into them and they really need some review and refactoring so I can join the discussion and I think it\u0027s going to be a lot of changes but if you are dedicated to working with this draft I can help you this one thing ii think this is very easy to add the young code to the drafts if you just look to another draft that has young and just like i don\u0027t know if "
  },
  {
    "startTime": "00:51:53",
    "text": "you\u0027re using xml or directly write it as text probably xml so just check some of the sources it is a five-minute efforts and you can have your iran models okay okay to discuss and one more thing young you should write it with capital letters because it gives bad impression but i don\u0027t have focus on what you have as topic on your draft but it should be done well and you should put really effort into making it open because all the tests are going to be integrated into that so it really needs an effort okay i think it would be very very happy to see some feedback to the models as such because for them we never get received any feedback so this would be really really appreciated so and Vlad is is being very modest one of the drafts where you can look to see how a yang model is incorporated in internet draft is is his draft on a yang model for control of traffic generators okay so that\u0027s a that\u0027s a good place to start and it\u0027s right within our working group as a is a good example okay thank you very much for the pointer I noted and we will have a look then manual just just to close the loop on the comment you made on the previous slide with the testing results mm-hmm here I\u0027d be very interested to see when you guys dig into what the differences weren\u0027t here you come back with yeah what would be noticed and while all those experiments are testing a IDs system arm which is deployed as a knocker container and we run traffic traces through the system and the difference is on the one side of course the absolute numbers because experience might be performed on slightly different hardware we were more interested at first into seeing if the trends are the same and this is something we could confirm here and don\u0027t be confused because the colossi exactly is what is the blue in the one pot is an orange and the other plot that\u0027s a profit of the plotting library i guess but the general trends seem to be the same and this is what motivated us to continue and this work I think if you write or the goal is that if we run the experiments on the exact same machine because it always depends on your virtualization virtualization infrastructure that we then try to achieve or want to achieve the exact same result and I think from our methodology this should be possible but this needs to be confirmed with additional experience yeah exactly so I think one of the things that we\u0027ve struggled with in BMW ge the virtualization is how do we confirm the ability to run the same test over and "
  },
  {
    "startTime": "00:54:54",
    "text": "over and over and I know Al and I sometimes differ a little on this but on one hand you\u0027re usually looking to get if the exact same variables are run ten times one would expect the same result sometimes we don\u0027t and I think there\u0027s a lot of angst around virtualization where how do you confirm that hey I can run that same test ten times so that I have ten apples to apples comparisons and ten numbers that I can actually point to to say yep this makes sense and so because you\u0027ve done a lot of heavy lifting here and you said you were digging into it and I thought okay if you guys could continue as you update the draft and Vlad is helping you when you guys come back next time in Vancouver possibly and you present again hey just you know I\u0027d like to keep focus on that because it\u0027s our heritage and you\u0027re also helping us prove out and solve to say yep we can actually benchmark and here\u0027s how we went about it and here\u0027s what we\u0027re seeing as you\u0027re doing it which is exactly what you\u0027ve got here I just want to make sure you continue to do so yeah exactly yeah that\u0027s basically on our agenda that\u0027s one of the main areas of focus right now thank you so I\u0027ve got a question about these graphs as well men well you said this for an intrusion detection system yeah it\u0027s the ricotta I think it was version three if I if I\u0027m right I think this example graphs showing the number of drop packets and they are made up for different races with different flow sizes and so on so in the experiment folders of the github repository there we have specified the more the information is available which exact setup misused couldn\u0027t put everything on the slide okay all right well then we\u0027ll what take a look at that and and appreciate this results presentation a bit more okay oh yeah and and have you tested more than one type of vnf yes we haven\u0027t compared with those tools but at least 40 energy bench where I\u0027m mostly working on we tested not only the story Qatar and and intrusion detection system stuff that we we tested couple so snorts Wakata and so on we also tested things like HTTP proxies load balancers and recently we also try to do first experiments with some IOT like virtualized network functions or specifically different kinds of mqtt procas and to see if we basically can use our approach of describing experiments with very different kinds of network functions and that worked well even though it always needs to be some custom tailoring of the experiments of course and this is basically what gives "
  },
  {
    "startTime": "00:57:54",
    "text": "us input what might be needed in addition in our models so it\u0027s kind of our own cross-check you don\u0027t talk food at the context so so many well there there\u0027s enough there\u0027s enough variability across that list of vnfs that I feel I feel like you must be in some sense defining your own vnf specific benchmarks to measure as young as you do that so that\u0027s I mean that\u0027s an important part of our work as well and it\u0027s usually something that we have a complete complete sometimes a set of internet drafts in order to agree upon so for I guess for for a load balancer for example I don\u0027t think we\u0027ve done any benchmarking work on unload balancers it would be interesting to get your ideas on what the proper metrics are and what we can take for that which might be useful to the rest of the industry ok yeah we can certainly work on this and polish those work and and try to provide for inside Syria yeah and if in Vancouver we\u0027re always good testing junkie nerds in this working group if you wanted to share some of the output or graphs that you had generated from those those are always hugely popular in BMW G we would thank you for it and I realize you\u0027re going to refine this draft but to Al\u0027s point you\u0027ve tested a bunch of different types of being apps and how being what you were looking at and how you did that as future potential drafts would be hugely beneficial to us testing on our own in our day jobs right so I would encourage you to consider more than just a little balancing share any ideas that you have okay okay thank you thank you very much so so your work you\u0027re looking for working group adoption and in order to get there we have to have at least some people in the working group who have looked at the draft and I think you mentioned let me look back here I think you you guys did get some some comments from Luis help me out did anybody else provide comments on the list I know there was even on Ross on the guy from again sending an email I haven\u0027t looked into the details yet and it still needs to be addressed on those other two which I am way off so far and I think I provided some comments on a very early version of this but not since oh yeah yeah yeah so um I think I think before we examine a working group adoption let\u0027s get a few more reviews and sure yeah yeah so we have we have at "
  },
  {
    "startTime": "01:01:00",
    "text": "least two volunteers Sarah and Vladimir who will do a review in the interim and that will help help our case to adopt this okay great that would be great to hear from you anything else from the the group assembled here seems not okay well what one thing I\u0027ve I always want to encourage people about is one way that folks who are proposing new work can help each other is to read each other\u0027s drafts and perform reviews and even if it\u0027s work you\u0027re not familiar with you may learn something and that\u0027s good always a good thing so consider that as you come to the microphone today and then stand here boldly asking for the working group to drop your draft if you get some help by helping others so next up is the containerized infrastructure only will do the presentation and please go ahead sir yep thank you I\u0027m Alan Lee from HP their draft title is consideration for benchmarking natural polymers in contrast infrastructure I\u0027m presenting briefly the some minor updates for the huge page up and luma these part of the our interest in this rep team so so we are in this trip to we are trying to how to configure those things and then what impacts on those things to containerize the networks so we are still trying to find out and then in this a coat on so we are still try out those things to how to configure in them what performance issues from them just read to you some just some we are add some more explanation about huge pages in nuuma pages and some probably the container is as isolated in the application level and administrator can set which pages or growing wrapper but like like m kubernetes or us to use of 500 112 "
  },
  {
    "startTime": "01:04:04",
    "text": "megabytes and i\u0027m but we are still trying to for that value and then the next next resource being since Numa is we are still trying to find out what\u0027s going on from this hackathon we are still trying to verifying the cpu or location using current container container engines where - - techniques use : tix CP schedule and same K and then we are measuring throughputs with them - things with CP variations and next in some we are still trying to define a huge page values but and our results and I\u0027m our test environment the slides it\u0027s from them the web page so it can you can find out that and I\u0027m this is our basic a test pad you know so we can use the EM the turtle engine traffic generator for the tracks in some container networking technology TPK and then and we we use - m\u0027kay and kinetics natives and and then the pot won\u0027t party some for application we use the surrogate time and then we are more a simple one we use there just forwarding application and part of this testing we some some problems on the some point you know the the between two points and I\u0027m we will prepare interface and then part interfaces we have some peg drops which is some error checks the most packets are dropped on that point so we still know area and some we are regenerating him some traffic\u0027s and reinstalling some components and then after there\u0027s no know any visual so I\u0027m we finally we are we are you know the the change the interfaces the which is the Belarus 100 gigs but we changed the one Jake Intel interfaces it works so so we go not yeah just yeah that is to fear fuck we are find out in this eckerton and then you know yeah so next day be some you know with a new new interface or with "
  },
  {
    "startTime": "01:07:04",
    "text": "new interfaces and new test bed we are still keep trying to find out more and them you know some is our some learning from their hackathon and we are still keep trying to update new technologies and and then so now we still more find out you know what what\u0027s going on the Bala notes interface that\u0027s the problem on that interfaces but I\u0027m not quite sure but we\u0027re gonna find out so and so so next step on out the next step is some from your comments and then updates our thread and then next the BAM double Hector we will still trying to um our experimental things so finally you know in our dread to we are we are still trying to provide how to set the Numa Numa and memory things and then we are going to propose some test beds yeah that\u0027s it thank you thank you thank you very much any questions or comments about this benchmarking I mean this is containerization is going to be the kind of the future of virtualized deployments we\u0027ve got you know pretty pretty good understanding of the hypervisor based virtualization we have a lot to learn about containers there\u0027s a obvious advantages and some obviously a lot more things to learn about now making that work in general I think some people are very good at it but they don\u0027t talk about performance except in loading the images everybody knows that\u0027s going to be quicker so what one one one additional point I wanted to make is that your considerations draft and I think I mentioned this to you at the to you all at the the hackfest the considerations draft could include some information on a troubleshooting test setups I think you know your you guys are generally going to get some good experience doing that and some of the tricks and tools and getting a set up working things that you could recommend these are these are also considerations with a new technology that I think everybody is going to appreciate so feel free to add your experiences there I\u0027ll go ahead sir "
  },
  {
    "startTime": "01:10:05",
    "text": "I would extend that to say it would be nice to see the outcome from the hackathon and on one hand it\u0027s always frustrating I think when you go into the hackathon and things don\u0027t work perfectly but you\u0027re also experiencing I think a lot of what we are experiencing in the field right now outside of ITF just in our day jobs and so capturing a presenting what you\u0027re seeing in hackathon in BMW G would be helpful and then extending that to hey as you\u0027re learning things and troubleshooting through the hackathon adding that to in terms of your troubleshooting or things learned or best practices or and then thoroughly documenting the test beds I know you\u0027re going to present future test beds but formally documenting what was used is helpful because I think again we\u0027re seeing huge differences I\u0027ve seen huge differences depending on the NIC that I use and it\u0027s interesting you\u0027re saying the exact same thing and I don\u0027t think this is unique to us but again it helps we set up a test bed to understand off if I really need it to work at least I can point back to this draft and know uh here\u0027s what they used and here\u0027s what I saw and so it gives me some hope or a good sane starting place to go does that make sense yeah okay thank you thank you yeah we are shooting our results always from this website and I\u0027m will welcome to your comments thank you Thanks I\u0027ll just mention two I\u0027ll mention two that among our slides I put the the hackathon slides and it\u0027s sort of the next deck in the list behind this one and you know you can see there some of the additional experiences that this author team was kind enough to share in their in their three-minute presentation we all get three minutes but it was it was an excellent opportunity to spend some more time together with Vladimir and and and also with the whole containerized infrastructure team we sat together in a couple of a couple tables side by side and we\u0027re able to give little presentations about what we\u0027re doing and then subsequently the results of our tests I highly encourage that so folks who have the ability to use the hackathon as you know kind of a measurement experience exchange it\u0027s it\u0027s a great idea I was I can tell you last last year that here in Singapore two years ago in Singapore I guess it was I was struggling with a particular configuration I couldn\u0027t get it going and I got a lot of help but I had to leave without getting it going so in the next couple of weeks though I "
  },
  {
    "startTime": "01:13:07",
    "text": "did get some help and that was the kind of thing that made a difference so in any case it it helps to have more more eyes on what you\u0027re trying to accomplish this is a great place to do it Thanks right so like I said these are the these are the hackathon slides but we do not show you is today now we\u0027ve got Vlad it was also at the heck of my life I just mentioned and yeah and got to talk to us about the network interconnect tester and this is your this is your most recent version of slides yeah those are exactly as I want them text only except one just nobler experience talking to people Thanks sorry yeah so I just wonder if anyone is interested in the draft by the title or if someone has read it or is generally interested in young or test generators so a young model for test generator that\u0027s what this aims at so when you configure t-rex for example in order to generate traffic you do it with some interface if it\u0027s XML or a graphical interface this is just a way to configure a stateless traffic generator and analyzer with young so that it can be used in a net comp interface in the same way as a switch or router when you test them you won\u0027t don\u0027t want to use different interfaces at least until now if there are different interfaces without one need to use this skippy which is meant for free nc analyzers and things like that they use that interface very successfully actually that\u0027s one of the best interface you can get and that\u0027s outdated it\u0027s not for networking and I think young can that confess what has to come at some point so this is what this draft is about so this is giving a "
  },
  {
    "startTime": "01:16:13",
    "text": "summary of the deficiencies of the current approach by all the companies that develop traffic generators and analyzers in other words code network interconnect testers which is a term that comes from RFC 25:44 now there is no standard based major vaunt interface or those devices so it is taken from different industries and adopted to networking there is no multi vendor interoperability you can buy two different traffic generators and they will have absolutely different interfaces you can use a lot of time developing tests and then you cannot move to another company because you have used the interface that is absolutely different from everything else you don\u0027t have that choice 3 they don\u0027t have a transactional model definition which means this is what you can get with young in that conf and this can allow you to actually simulate a traffic generator in discrete event simulation so if you want to specify a traffic generator in a simulator you really can\u0027t do it with something that already exists and is standardized by the ITF so people in that industry are defining their own models to do that and there no standard for generating reports that document absolute any transaction that you do to those devices so he comes net confettis intentionally made to be readable by humans so that all the transaction with the equipment you can just walk to a file and you can use it as a legal document this is a big advantage so how does ITF young dot model for network interconnect estimation solve these problems a very important point is to have multi vendor interoperability tools can be reused you have a what-if net convenient tools available you will be able to use those with any generator and analyzer test programs you can write that that are going to be compatible the generator is going to appear just like a replaceable bricks so you can buy from different manufacturers and they will seamlessly be replaced and one advantage is that you can actually have self tests written in open source language so that you can "
  },
  {
    "startTime": "01:19:15",
    "text": "adjust parameters and verify that your traffic generator satisfies those requirements so if you have an Python script that does self tests you can change values and figure out exactly what it\u0027s jitter point is for different traffic patterns you can\u0027t do that today he have to just trust the manufacturer you buy a traffic generator from you just have no way of proving he doesn\u0027t do something right and you can do it but it\u0027s not easy so transactional nature if not confer also if you have common commits which ends every time it won\u0027t actually affect the device in a way now this is done with different commands start commands which are specific to the interfaces or - anything else with this you can do device changes in parallel so you send them commit to all the device in the network and they start applying the changes simultaneously you can\u0027t do it today if you have multiple generators you have to do the specific changes which started the traffic generation and you can\u0027t just automate it by sending commit to everything after you have prepared the candidate database and if that\u0027s the reason it\u0027s not scalable it\u0027s not easy to document and it doesn\u0027t have any support in discreet simulators so you don\u0027t have a model for each to test their in on that plus plus that you can just put with the configuration you will use on a real device all this can change with a standard model yeah that\u0027s this standard session that you can just capture and you have a ready document for the test you have performed so in the hackathon we wanted to demonstrate this concept it works so we took our C 2544 setup and we picked some real devices that generate nice traffic in hardware so taken with this diagram which is one of the the diagrams there we wanted to have Python scripts that takes the input in XML and produce the results in XML now we didn\u0027t accomplish that part because this is what the previous draft was about where you have standard common input for the tests and a common place to store the results what we did was it creates a physical setup this is the running hardware that\u0027s needed and we managed to make a simple "
  },
  {
    "startTime": "01:22:19",
    "text": "trail that complies with the twenty 5:44 RFC so when they discussed trails in the previous draft that they\u0027re going to be registered in that result XML they have to be described some somehow and that\u0027s what we do with that traffic generator model we describe a trail which generates the traffic so we have that in github these are the results and I think it\u0027s interesting for anyone who is wondering how this young is going to be used to write a simple Python script to configure things compared to what\u0027s available today that\u0027s the two pi two scripts that are they are using a young CI which makes young in that comes much simple you don\u0027t need to deal with XML on the command level you just do it on the replies that you get so I really recommend that for people doing testing and I used to come and whine and Skippy and interfaces like that and then you have the reports generated which I mentioned to it not confer so and you have a configuration which actually is based on this topology level specifying how all these devices are connected so that the test has the credentials to connect to each of the devices here\u0027s the models and can actually figure out things without you specifying everything on the command line this is how the test is run so when you want to run one trail sending packets from the one port going on the other on that switch that we used you use a set net command which initializes everything on that nuts with a fixed spread affiant setup in XML and then you start the tests which execute in this case it executed 64 bytes with very big interframe gap if you notice here and I\u0027ll explain why why we have to do that so the switch that we use for tests and was working very well on hardware mode when it was no no futures defined and our no puck is dropped actually you have to run Mary Wong sequence to get pocket walls and but when weakened fear it in a special mode which makes it up as open force which it does it in software and it is listed by the manufacturer this just experimental and it works but it drops most of the pockets as you can see you get you have less than one percent of the traffic and so that it doesn\u0027t drop pockets and that\u0027s simply unusable but it is possible to enable it and that\u0027s for my case just perfect so we we had a run which washes with nine "
  },
  {
    "startTime": "01:25:19",
    "text": "thousand this is 9 times 1 K and this is how the result looks when it is dropping so many pockets you get 60 seconds of run you generate a lot of pockets there is a lot of thoughts being dropped and these from the border before that it\u0027s even worse so when we get to 9 K of interframe gap between each pocket of 64 bytes then it starts working much better and in the next test with 10 K it starts working without doors so this is something that the bandwidth test would do automatically we did it manually because we didn\u0027t make the search algorithm and but the the positive thing is that we made simple scripts that does that and then this can be reproduced and code automatically but this you have to do in a in the next pass so this how it looks when it is not dropping any pockets it gets about one point two milliseconds of latency and you can compare it with this then it\u0027s yeah so the results are not particularly practical this is not something you would get on a regular switch but we we used net conf interface with young models on all the three devices and the switch was configured as a for capable device having a wrapper around the open for presenting it as an that convenient device so there\u0027s a pure young system based on generators and a breech which I I have been looking forward to accomplish for us for some time I\u0027m very happy that we made it even though yeah so that\u0027s about it that\u0027s the the references if anyone is interested in that topic I really recommend if you\u0027re doing anything with young and net conf and you\u0027re configuring devices in order to test them to walk into the Python scripts because you don\u0027t want a controller in your way when you are testing a device you want to have a direct access so that that\u0027s the device and not the controller and I haven\u0027t seen any good automation scripts around there so this is good experience and I recommend it to everyone who\u0027s interested yeah so that\u0027s about it it\u0027s really good the every statement you made about sort of the University of the yang model anybody who\u0027s been around IETF for a while should resonate with that and don\u0027t run away maybe there\u0027s going to be some questions or comments here for you I "
  },
  {
    "startTime": "01:28:19",
    "text": "think well you and I exchanged some mail on the on the mailing list and I think you\u0027ve covered those points the I was basically asking or kind of verifying where this fits in the sort of in the hierarchy of the the complete turnkey test device and what was clarified I think as Vladimir said was the yang model basically commands the the test equipment into one configuration but very often we want to run multiple trials that that can figuration so you\u0027d basically repeat the repeat the test and then if you wanted to use a search algorithm you would change those parameters and run it so as you said you were running it manually that\u0027s completely possible to do but a lot of people want to do this it sort of in an automated way and that\u0027s a that\u0027s logic that would operate and use this gang model to accomplish it right yeah actually I think the the search algorithm is not difficult to develop on this infrastructure is working the tireless days and nights to get this working going to actually dealing with issues with the young parser the net conf interface and now that it\u0027s ready I haven\u0027t spent a single minute thinking about the search algorithm logic but I think there are a lot of people that can implement this without investing time into the issues that I have been dealing with and they\u0027re poorly specialists who have already done this so they can just just take this function that returns them results and they can provide the parameters and they can just play with that if someone is interested I\u0027m their Institute to work with him we\u0027ve got actually several I mean several candidate search algorithms being discussed here those guys are the Maciek and Greko or the experts in their algorithms and I guess they\u0027re using the t-rex tool so they\u0027ve they\u0027ve already got those going but it would be good for them to kind of look at this and see how they can how they can help also I mean we have one let me just go back here for a moment because I saw in the picture Vladimir\u0027s excellent and transportable test setup is is what\u0027s dominating the picture here but behind it is my laptop and my little black bare metal tester that I was using in the IP capacity testing so you know I I "
  },
  {
    "startTime": "01:31:20",
    "text": "had a much more efficient fits in my backpack kind of set up for my testing but oh there\u0027s a search algorithm we\u0027re using there as well so that may be something we can look into because I think I mean there\u0027s there\u0027s clear crossover between what we\u0027ve learned in the benchmarking world and implemented in the binary search with loss verification when we went to do the production Network search algorithm that we use in this IP capacity testing sort of the access links so it\u0027s a there\u0027s a there\u0027s a good I think if you\u0027ve done an excellent job and left a good break point for others to to jump in with their expertise that\u0027s that\u0027s a good point one yeah yeah hello thanks for the presentation really cool so what I don\u0027t understand yet is you know what is the relationship of this draft going to be to existing test methodology RCS so typically I know from mother I kept working groups that yang model RFC\u0027s are linked to protocol Arty\u0027s so I wasn\u0027t sure whether that was registry or point here if you are trying to create an IRC for a young model covering RC 2544 or any you know related stuff or just everything that\u0027s question one and question two is the main problem from my point of view is not only configuration it\u0027s also reporting from its do you have any thoughts on those what was the most part of the question part of the question was the main one of the main problems is not only provisioning a test tool like understanding how to configure it but also how to get the results okay I understand a question the goal is very specific it is alternative to the current the existing interfaces to the interconnect testers so it allows you to measure things with interconnect tester it doesn\u0027t focus on how those results are going to be reported it doesn\u0027t even focus on RFC 25:44 the good thing is that 2544 is a very simple elegant algorithm using only stateless traffic and it is perfect much for what this interface accomplishes so you can implement 2544 algorithm using that interface the young modules they are extendable so they are going to be extended by different features different complexity "
  },
  {
    "startTime": "01:34:23",
    "text": "but they are presenting a stable base for for that so this is doing like the base for adding stateful generation more complicated analysis and custom protocols and algorithms so this is as simple as being able to specify a repeated sequential pattern with like precision and determinism that is needed for this kind of technologies that require it so in my case we were using an FPGA hardware to do that because that\u0027s why you need it you could use t-rex if you didn\u0027t really care about the determinism you can just generate the water pockets but if you really want to generate RFC 25:44 traffic which is equally spaced with interframe gap which is repeatable and doesn\u0027t jitter then really you need the hardware generator that\u0027s why people are buying those devices with this model you are specifying actually a configuration that goes into the hardware you can implement it in software as well of course but it is mainly targeting deterministic hard regeneration so you are specifying the table of of streams how they\u0027re going to be separated they\u0027re going to be a burst what kind of bucket is going to be generated and they otherwise your sight because there are two modules they otherwise decide specialized measuring latency sequins drops on our things for a normal normal counters we are using a ITF interfaces so input pockets output pockets the test is using the standard counters so in a way this module it\u0027s forcing also it implementation of the standard ITF modules so if anritsu for example Spirent sena networks tomorrow decide to use ITF modules to control their equipment this will be very positive for anyone who is used to those modules then you don\u0027t have to be familiar with their own interface to retrieving a counter then you can just use ITF interfaces in addition with the traffic generation modules which do that so I think it\u0027s a very simple concept I\u0027m not focusing on this being an RFC or standard truck just getting the the visibility and to working on it I think I\u0027m very happy with with with that so it\u0027s just I don\u0027t know if I made myself clear I\u0027m not sure with my question with regards to the results wasn\u0027t really answered or maybe I didn\u0027t understand it so you said ATF models or modules I\u0027m not sure if I understood it is those can be used for results interpretation or "
  },
  {
    "startTime": "01:37:26",
    "text": "results transfer so maybe we can take and so I\u0027m sorry we are five minutes over time so if we could please Carsten and black could you take this to the list awesome I\u0027m so sorry thank you alright folks thanks for hanging out the extra five or six minutes we appreciate you we will see I thought we were down to three we\u0027re done oh yeah look I I it was your sessions I thought maybe you\u0027re giving up the time so I apologize two hours all right so uh thank you all for hanging out late with us please take the comments to the list read the drafts as you\u0027ve seen when you read somebody else\u0027s draft they\u0027re more likely to help out on yours and then hopefully we will see you all in Vancouver and and police guys in the back who came in late signed the blue sheets Roland and your friend please do one other point which we forgot to mention is that we\u0027ve declared publication requested on the evpn we did mention that I didn\u0027t remember it at least I don\u0027t and I don\u0027t see it in the notes here either oh you did okay I thought it was I thought we\u0027d have to go in here where you have no scent okay okay got it got it good okay what\u0027s covered good good enough all right folks until next time please read the drafts thank you sorry Louise you "
  }
]