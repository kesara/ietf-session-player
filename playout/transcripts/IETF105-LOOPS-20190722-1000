[
  {
    "startTime": "00:00:35",
    "text": "[Music] [Music] okay alone people stem the clock [Music] so it\u0027s so it\u0027s about time for us to get started if we can work our way down to one boss in the room at the time at a time it will probably be helpful to the area directors I am Spencer Dawkins and this is Oh waitron we are your Pepe both chairs for the gluts pop if you\u0027re in the loops pop you\u0027re in the right place and if you\u0027re needing to be somewhere else we\u0027ll miss you this is a Bob at the ITF so it is covered by the note well which many of us have seen and references PCBs which all of us should have at least looked at once this is our agenda for the day and wanted to give a brief pause to do agenda bashing if anybody has thoughts so good excellent so we will go with this agenda please remember that this stuff is not working group forming which is means that we\u0027re thinking I wanted to do a little scope scoping for our discussions we\u0027re not replacing the internet quick or TCP we are talking about optimizations where things work but don\u0027t always work well we\u0027re talking about optimizations between network elements not involving hosts and your network might not need loops but somebody else\u0027s network might I think the first law of optimization is first do no harm and so that\u0027s one of the things I\u0027d like for people to be watching for in our path we\u0027re talking about a transport independent optimization we are not changing the "
  },
  {
    "startTime": "00:03:36",
    "text": "indian transport protocol payload and our goal for this off is that we agree on what happens so there\u0027s a lot of things we could talk about for two hours but I would like to direct your attention to helping us find out what needs to happen next our face to face time is precious this is not a work group forming both because for my other reasons the proponents were meeting for the last day and a half and they learn well they were learning a lot from each other what I think this means is that people are different people are working in the same space but since there\u0027s no IETF activity yet they\u0027re not doing things the same way and there wouldn\u0027t be you know anything they produced would not be produced providing the same services so it sounds to me like kind of a opportunity for us to avoid our experience with gnats where we said this is a bad idea but people did it anyway and they didn\u0027t do it here for the longest time people come to mini buffs debuffs for many reasons note that it\u0027s possible to watch a train wreck while looking down at the Train we\u0027re not going to ask if you came to see a train wreck but we are going to ask ya who consider yourself and this is show of hands kind of thing primarily a transport person more than anything else okay so about the third of the room you think cool so consider yourself primarily an Internet application person or Internet encapsulation person that\u0027s almost as many people as transport so we have the right co-chair application layer it\u0027s a smaller number but thank you for being here primarily operations we have we have we have we have to we have to we have to excellent cool this is double the number of the average profit primarily a measurement person yes that\u0027s okay yeah so at least like at least like four or five people in here without expertise primarily a security person we\u0027re seeing one hand two heads and I\u0027m pretty sure that they\u0027re all at the quick thing at a in our W that was a joke who\u0027s read the problems opportunities draft Wow this is where do you say a third of the room cool and who is working on a product that does local transport optimizations I\u0027m countin "
  },
  {
    "startTime": "00:06:40",
    "text": "eight hands ish yeah you know like more like ten yeah okay so maybe maybe this is not a proposal from one percent of group sorry Aaron fogg mkhaya are you product or a system I mean some people are not building trucks I don\u0027t understand the intention of the question so know that I don\u0027t understand yeah yes yes yes thank you for thank you for clarifying questions hi Cory hi Spencer I\u0027m taking notes do you want to say what you find out or do you just want to tell me afterwards I can send it to you afterwards but to summarize its one-third transport one-third Internet one tenth on the application to people on operations five people on measurement to one and a half and security perhaps a third of the room has read the problems opportunities draft and we have sort of 1012 people who are actually working on products in this area or systems in this area fabulous thank you so I\u0027d like to just put the questions to guide us between now and ITF world six up we\u0027re going to loop back to this slide at the end of at the end of our discussion time but this is these are questions that I\u0027m going to be asking or hums and my client if you\u0027re humming no to help help us understand why not and so I say you\u0027ll see the slide again but I wanted you to have it in your mind since we started the discussion so I think we\u0027re ready for Carsten good morning Monday morning is not my time I defended my PhD on a Monday morning so quick question who in this rule was not in one of the previous loop side meetings we had at the last word yes okay so it makes sense to say what is the room for pouring thank you so basically how can you do the incorrectly slide searching it\u0027s not doing first name yes yes thank "
  },
  {
    "startTime": "00:09:41",
    "text": "you okay so basically this is about packet loss if your network doesn\u0027t have packet loss you\u0027re probably in the wrong room more interestingly if you if Peck loss is not a problem for you you\u0027re probably also in the wrong room because all we are going to do for the rest of the morning is looking at optimizing things so we have less packet loss and I\u0027ve also mentioned that one form of pick loss for instances tail loss Michael has provided this nice demonstration of tail loss and so there\u0027s always a little bit of latency consideration behind that but what we are primarily try to do here is reduce packet loss and the the approach is to do the simplest thing that could possibly work which is we have a network path between two hosts that are oblivious to what\u0027s going on here and we have two nodes in the network that cooperate both are on paths they cooperate in reducing the loss and it\u0027s about compensating for losses that happen in the path between the two nodes so I think it\u0027s hard to do something that\u0027s even simpler than that so that is what we\u0027re trying to do here and of course there are things like retransmissions and FEC and and things we can\u0027t could do or could not do and that\u0027s possibly something that a working group could let to find out what exactly you want to do but right now let\u0027s try to understand the problem so the point is to recover packets locally so locally has two meanings it means close together low latency but it also means with no impact on the rest of the network and that of course requires a little bit of thinking how you really can make sure that there is no impact on the rest of the network but the main thing is doing it locally allows us to do it with low latency that\u0027s one of the objectives the second thing is we want to do it in the network so host participation is not required that doesn\u0027t mean that there shouldn\u0027t be activities with host participation that\u0027s fine but it\u0027s not what what\u0027s on the agenda today so we want to do this in the network and something because we we don\u0027t want the whole to participate we don\u0027t want to touch the hosts packets so traditionally peps have been very "
  },
  {
    "startTime": "00:12:42",
    "text": "intrusive and and have looked into packets and actually changed packets and this is not the objective the objective is that the packet that comes out of loops is the same one that came in it\u0027s just more likely to actually really emerge then it would be without loops and this of course means it works with any kind of IP packets so encryption is not a problem for for what we are trying to do so don\u0027t look and don\u0027t touch so with these three framing things copying things it\u0027s pretty clear that any solution would have retransmission forward error correction or both and right now we are looking at the solution that actually can do both and of course for retransmission you need some information going from the egress to the ingress which we call reverse information like X next whatever and you also typically include some forward information although Michael will talk about the case where you actually don\u0027t need that so if the terms reverse information and forward information I come up these are things that need to be done and these are the things that actually we want to send it as here so we can interoperate the same thing is true for forward error correction since that may not be as familiar to people it means adding redundancy to the packets so if you lose one out of a group of packets you can recover independent of which of the packets your us this has some latency advantages and it gets really good when you do a dynamic selection and adaptation algorithm for the parameters of the fact things like block size if you have a block size and fake rate how much redundancy do you actually add it helps to dynamically adapt there and to be able to adapt you need measurement and we will see a few other places where measurement is useful and finally it turns out there are some some hybrid approaches where you react to a neck by adding FEC so this is not not out of scope what we don\u0027t really want to spend a lot of time on is things like protocol setup negotiation and so on we\u0027re assuming this that this happens in an environment where we have some controller thing that does these things for us and we are hand waving there this is not meant to be part of the effort but of course we need to understand what information needs to be in that setup so maybe in the end there will be a yang model or something like that ok the "
  },
  {
    "startTime": "00:15:44",
    "text": "other part as I said we don\u0027t want to influence what\u0027s outside there and and the most important thing is we don\u0027t want to blow it up and this means we have to be careful about concealing packet losses because if you completely conceal all packet losses then of course the end hosts will ramp up and and you get into all kinds of problems because you will increase congestion so a necessary component here is congestion feedback to the end hosts and yeah the preferred way of course is easy and we have a way to do congestion feedback but for those flows that cannot use Sen we also need a fallback for Beck so we don\u0027t get an deployment problem the permanent disincentive everybody is waiting for easy end actually some informal measurements make me very optimistic about ecn about the percentage of traffic that already is easy and caliber but that\u0027s maybe not for this of to discuss and the other observation is we assume the transfer protocols on the hosts will improve over time and we want to play the puck a little bit to what where they will be yet not where they are now so we are assuming more easy and we are assuming more time-dependent loss detection stuff like in rec instead of packet number dependent loss detection and so on so there are a number of improvements that may may shape the optimal solution of things for loops but since we are not picking anything today that\u0027s just something to keep in mind yeah so in summary we want to do the local recovery thing we want to do some measurement both to set recovery parameters like when do I stop retransmit ring and also if we have to signal a congestion by actually dropping packets we want to do this as little as possible and maybe measurement can help us understand whether a loss was was a congestion or a non congestion loss and we have to do the actual congestion feedback what\u0027s not in scope but what maybe at some point some people want to do is adding multipath to the picture well traditionally I would propose adding multicast mobility and security that\u0027s always the three things that make things interesting but multipath is joint that list and also we are not we "
  },
  {
    "startTime": "00:18:45",
    "text": "into diagnosing that path segment we have ways of diagnosing paths also IOM and so on this is not really what what we are trying to do here we are seeing the path segments as one thing we want to do some measurements on it but we don\u0027t necessarily want to understand which of the nodes is which of the links is causing the losses MTU handling is not something we will be the first to solve I mean it has been tried before and we know that there are a number of solutions that are not always very satisfying but we will just live in that thank you and finally since this needs tunneling we probably want to use some tunnel encapsulation this is not about defining one and not not about choosing one but really we want to be able to use any tunnel encapsulation that that\u0027s out there and there are some sketches to make sure that\u0027s possible but these are proof of existence sketches and much things to choose from there are a couple documents out there for the problem opportunities draft as Spencer asked about there is a strong and proposal we will spend a couple of minutes on later they even is a charter proposal for a new working group but we are not working group forming buff so we are not going to discuss that and there is a groups mailing list you may want to join on what you may want to consult you okay ten minutes can I ask a question yes lucky chose democracy I\u0027m the co-chair of the network coding Research Group where we have a tunnel where we do per per segment coding where we have dealt with the issue of hiding and hiding losses and not breaking the internet where we do have error recovery and I\u0027m wondering why we need another group to do that so the one possible one possibility would be standardizing it in the IETF okay yeah we\u0027ve been a research group but yeah because a lot of the problems that were stated here are things that we have been addressing for what five years or something like this yeah this is why we have mops this is good thank you a lot of people in this room have been working on this for five or ten or fifteen years spending the last ever since I graduated from college and looking at my old age you can imagine how long that was so so what I would say that yeah there\u0027s "
  },
  {
    "startTime": "00:21:46",
    "text": "already a lot of work done in a research group that could actually profit this absolutely absolutely and then have some slides about it later but everybody in this room can can go home comfortably thinking this new work is a spinoff of the work that did it before so this will be a NW c RG spin-off if it becomes a working group if that helps I booked Brisco independent I I just will an answer to this question when you move from a per link retransmission to an overlay retransmission you stop being able to tell whether it\u0027s a transmission loss or a congestion loss when you\u0027re on the purling you know whether it\u0027s a transmission loss or not but once you go away from that you don\u0027t so the the statements you made about wanting to avoid hiding congestion loss don\u0027t square with the scope of the of the both as far as I can see because your your honor you\u0027re definitely on a multi-link scope so tying the recovery scheme to the link helps you but I don\u0027t agree with the other half that if you would not try it with the link you cannot say anything I don\u0027t agree with it well how do you know the difference between congestion loss and transmission loss if you\u0027re not on the lane well maybe the delay window maybe the delay went up okay so you\u0027re then starting to do but that\u0027s something lot of things we have to look at and there is a number of things you can do relatively safely and there are a number of things that may be a little bit aggressive and then we are right there in congestion control and where we have a number of algorithms and mechanisms to choose from and there will be BCPs and and everything I think this needs to be examined I just want to point out um we might want to do that might come back to say real quickly here one of the things one of the questions that it\u0027s on our list of questions is how much you know how much of this is what\u0027s research and what\u0027s engineering so we you know we are kind of headed towards that question in the first couple that have come up and I wanted to thank you all for helping us to understand that that one of the questions so tender than it is most you all david black as a transparent group chair or one of the chairs want to quick get up to do two quick plugs from labor at first for all bob Brisco who just sat down has written a couple of drafts that are that are mostly done in the working group headed for IETF last call soon of important interests of this group is that they explain a bit about how to handle EC and a tunnel a tunnel ich egress and particular bob has written "
  },
  {
    "startTime": "00:24:47",
    "text": "some text on fragmentation that might also in might also apply to FEC if you don\u0027t look at it look at at the details to closes on cars looking that at those drafts one of them has Easton and cap my name the other has RFC 6040 updates shim in the name we apologize for the not exactly intuitive draft names and then having mentioned tunnels there\u0027s a long-suffering draft in antic area on tunnels please read that and don\u0027t reinvent it thank thank you David just and just those are both TST WT working group drafts right the interior one isn\u0027t no yeah there\u0027s there\u0027s there\u0027s 2tsp WG drafts one sec and cap the name one has RFC 6040 updates shim in the name oh and there\u0027s an indie area draft on tunnels and of the 3d interior draft is probably the most important because it reflects a bunch of things learned learned along to over a long time the hard way about tunnels Thank You Ted lemon so to me so I\u0027m a little frustrated by what Carsten just said because to me the most interesting problem that that needs to be solved in this space is the is the problem of the edge device the leaf device talking to the border router between and I a constrained network and a bigger network and so if that problem is out of scope then I actually have no interest in this work that\u0027s not to say that I don\u0027t don\u0027t think it\u0027s a good idea it just I personally don\u0027t have interest in it so and I\u0027m not saying that you should change your mind I\u0027m just making I\u0027m just raising that point to point it out to you thank you sniffing Vega one thing one thing that came to my mind is I think this this problem that was described here is at least for many more tricky links solved in proprietary ways by basically everyone and I think it\u0027s also quite common that the that said when you have a satellite link that your satellite uplink and your satellite downlink and the boxes attached to it where something like this has to happen are from the same vendor and they do them and a specific thing why is that not sufficient anymore are we are we standardizing just for the sake of standardization good thank you next presentation thank you so I\u0027m going to present a use case so hopefully some of the questions can be answered when we have a very specific use case so here here is the usage scenario we are trying to introduce thinking about "
  },
  {
    "startTime": "00:27:48",
    "text": "intercontinental when past for example from Paris to Beijing either over NPSL over Internet but here we\u0027re trying to focusing on over the public Internet so we find out as the default path does not always keep the latency we required or the best latency so what we are trying to do is look at the small square here we create the workload from multiple clouds in different geographer sites to build a better web pass via the overlay nodes those square boxes actually the overlay notes record crowd the Internet network science or something so we have put this virtual nodes or cloud routers globally then we have experiments based on 37 cloud routers then we find out wisdom we have 71 percent chance of finding a better path in terms of latency so what\u0027s next we find out even we have a selected path gives a better latency the loss still exists then there are some pretty well-known negative impacts of packet loss in Longhorn Network the Longhorn Network here we refers to the long pipeline at least like tens of hundreds of milliseconds so there are at a loss problem for short flow which possibly caused by the timeout possibly a few seconds at the sender or it may take an additional Artie T for T spirit transmission in so the long flow completion time is is expected in this case and for large flows the throughput is the large flow I mean the cares most so there are chances that the TCP sender actually reduce its sending rate even when the loss is not caused by a persistent congestion so in summary the packet loss negative impact most because of the internal transmission it takes time especially in long-haul network so too have some further study on the packet loss pattern we we have this picture sorry syllabus little bit more but for those is in Chinese but you can guess there there are locations I mean they are Shanghai by Eugene I think there are Silicon Valley and like San Paulo or somewhere so each pair of them there\u0027s the small square here actually captures the loss rate so it can be easily identified that the loss over past segments has very different characteristics some Dom them the loss is is persistently high and some some of them the loss almost can be ignored in "
  },
  {
    "startTime": "00:30:48",
    "text": "some random the laws vary over time for example higher getting higher over the peak peak hours yeah something like that then another finding is the loss over a single specific segments may affect the end-to-end loss significantly that is to say the loss detected by the end-to-end pass actually can possibly be contributed by a short single segments so in our usage scenario there are at least two opportunities to new opportunities we have now with where we find out that can solve the packet loss problem the first one is in this cloud internet we have overlay nodes they partition the whole heads into shorter segments naturally and we can enable the per segment operation for example quicker recovery from loss comparing to entry and also we can do the adaptive recovery so the adaptive here means for each of the segments we can decide whether we should enable the local recovery or not always should use the retransmission or we can enable the FEC with different level of redundancy another opportunity we find out is the overlay nose nowadays have computing and memory resources so are capable of provides providing the complex features like detection recovery measurement is a marking others things so here this pay trying to show a little bit how the segment based merriment can help us help determine the cause of a packet loss look at the picture here the left-hand side actually I think is from where Frankfurt or Shanghai on the right side from Frankfurt to Shanghai and the left side is from Shanghai to u.s. West so the blue is the loss rate the red is the RTT so we can see there is a strong correlation in these two cases so that somehow in ties if it has such pattern the high correlation pattern then there is a loss then we check that at that time the delay is high then we it\u0027s highly possible that losses caused by a congestion otherwise it\u0027s possible that caused by a non-contrast reason so why we care about this remember the slides that are shown by Caston somehow we want the feedback the congestion information to the sender so that\u0027s how the segment based information helped us I believe in the solution sketch presentation may have made touch more on this so to summarize I have introduced that is a particular scenario in the overlay "
  },
  {
    "startTime": "00:33:49",
    "text": "nodes allow us to improve the loss the packet loss over some specific channel based path segments in we are requiring mechanism to be defined to achieve the local recovery and at the same time minimizing the undesired side effects we I kind of think the loops buys too should buy to existing overlay tonneau insulation we do not want to invent a new ink encapsulation that\u0027s or for this quarry Gouri first and cartwright question so we we have these effects going on at multiple layers so I write I put my operator hat on I\u0027m doing stuff that late to mail maybe layer three then I\u0027m doing routine control to try eliminate these things I\u0027ve got transport protocols running over the top I see real dangers that we have too many layers trying to cross optimize the same things over slightly different time scales is this something that you\u0027re considering okay for this one I am it\u0027s highly depends on their deployment because for this one we are thinking there are some underling nodes and it\u0027s not under control of the operator who provides all the small square boxes so this is an overlay note managed by somebody else so that\u0027s why we have layering so naturally they\u0027re not doing traffic at you are they not looking at the BGP tables and considering how to optimize this this um you I\u0027m trying to say actually there are some underlying optimization that that\u0027s the I mean operators are trying news right guys I I think it\u0027s possible but that part is not the I mean they\u0027re the provider with this layer will be worried about and from some of the experiments will show actually the latency I mean they the unrecorded underlay actually the underlay latency given by them is not satisfied so that\u0027s why they\u0027re the middle layer operator I want to do something by themselves Aaron Falk Akamai thank you for your presentation was very clear I thought it was very helpful could you go to the slide that shows the delay and loss rate and I think this is a the point that Corey was making which is at every layer that you are implementing loss recovery you are converting loss into delay because each layer is doing some sort of loss detection and then recovery to ensure successful transmission so that\u0027s happening at the link layer that could "
  },
  {
    "startTime": "00:36:49",
    "text": "be happening between routers you\u0027re doing it between your cloud routers so what that\u0027s going to do is that\u0027s going to mask some of the signal so if you are using an indication of delay to say correlated with loss to say that this is congestion related loss you may be may be incorrect in that because what\u0027s happening is that a layer underneath you is converting that loss that it\u0027s detected into delay so what we are trying to do is at least we need to do no harm so this is just an example to show in case there is a strong correlation what\u0027s possibly we can do but if I mean if people really have worries about this we can just do the local recovery and then let the sender - as they usually do I mean if one they want to decrease the sending rate so just as a conventional TCP sender but at least we are to doing no harm this can you go back to the slide with the graph and that shows that topology the topology graphic so this kind of makes it look like the majority of the transmit path is the long-haul which in regards to the latency seems like that would be where the most delay is so if local recovery is over the largest part of the path I\u0027m not sure that that\u0027s going to be very different than and recovery so that\u0027s in your comment on that yeah that\u0027s fair I think that\u0027s a fair comment so from our experiments we normally we have at least three segments I mean so so as the previous presentation in custom showed if there is a longest segment that is our TT is almost equivalent to the end-to-end now I don\u0027t think we should enable loops so you break it into smaller segments the advantages of localization but then the obvious problem becomes what if I have lost it each segment and they\u0027ll have additive delay which is making the problem even worse oh it\u0027s just some of the things I\u0027m sure you\u0027re thinking about these things yeah so so that\u0027s why I mean during the solution considerations I think we want to make the recovery mechanism more adaptive so some sources for certain segments maybe we don\u0027t want to enable it at all for some of them maybe retransmission okay now for some of them if you see with different redundancy might be applicable so that\u0027s yeah but we don\u0027t have very very specific solution right now but because this is known working group forming both so that\u0027s what I\u0027m thinking Spencer Spencer Dawkins speaking as individual contributor so one of the things I wanted to be sure and say was "
  },
  {
    "startTime": "00:39:49",
    "text": "again I\u0027m glad that Aaron stood up and started talking Aaron and I co-chaired the pilk working group which produced the advice for subjects sub network protocol designers a long time ago and one of the things that\u0027s in there or is about being aware of reach you know retransmissions we did that so long ago that people are still running IPO for x.25 you know in the end people were still saying that they want to say your hops that were completely reliable completely reliable so those kinds of things so we\u0027ve had the ITF has done work that required a you know that that tried to help people be aware of that problem and I think what we\u0027re saying now is that that problem is at more than one layer down you know it\u0027s more than one layer for the two layers that could be arguing and so I think being aware of that is going to be really important and this is kind of what I was thinking about when I was talking about performance implications of path characteristics at the at the IRC talk thank you and Rebecca you pointed in the same thread it\u0027s in the same thread it\u0027s returning to the previous point about doing no harm with the correlation named Lillian sorry innately Andrew McGregor if you hide or smear out in time the correlation between congestive loss and the delay you\u0027re doing harm end of story because it reduces the ability of the congestion control to see what\u0027s going on if on the other hand you have some level of non congestive loss then papering over that is purely a good thing the question is can you tell the difference and that\u0027s the that\u0027s the key problem in all of this yeah and the reason works layer too by the way and you know there\u0027s probably more than four instances of an algorithm that does exactly this for per person in this room running is that you know that it\u0027s not congested was right Wi-Fi you dropped up you know you have an error rate that\u0027s rather high for an indifferent internet going you dropped a packet because of that we\u0027ll find just paper over it right whereas you know if you don\u0027t know on a long-haul path whether it was congested or not you should probably leave it in the string so let me answer that quickly the point of the congestion feedback is to not lose the information now let me answer the other question which is essentially we have survived the last 30 years why are we doing this now there are a number of things coming together and the cloudy stuff that you talked "
  },
  {
    "startTime": "00:42:50",
    "text": "about is maybe one aspect of it but I think the important observation is this is not supposed to reply we\u0027ve replaced the existing Internet this is a particular performance optimization that you can employ at specific places in the network that have the characteristics to make this useful and having a sizable part of non congestive loss probably is a precondition to to make this really worthwhile so there is an assumption there is a controller somewhere that is looking at the network and has already has some measurement data and that helps you decide where to put a loop segment and and we are not to put one and the third observation is the the blue segments work best when they are shot so this is not supposed to be an edge-to-edge thing this is supposed to be in the network deeply in the network and the final observation when you think about this problem try to strike from your minds that a retransmission scheme has to do resequencing so most people who want to do that something in this space don\u0027t want to do resequencing many link layer solutions today have to do resequencing because the link layers are you find to be sequence preserving and also the the tunnel based solutions often do resequencing and this is pretty much about exploring the space where where you can have performance improvements without resequencing okay Thank You Joan and Yuen long you\u0027re next so that\u0027s one more presentation on use cases for this problem and then we\u0027re going to talk a little bit about solution sketches just in a matter of time keeping we\u0027re running a little late but I think this discussion is very useful and important to understand the problems but at some point we\u0027re going to you know draw a hard line and ensure that we get off questions answered as well so you\u0027re enforcing and forcing MTU size on time slots good job the problem is that the questions have come up make me think I need more in five minutes so anyway so I\u0027m going to show you a couple pictures about satellite use case so basically you know today it\u0027s TCP we put a pep in there over satellite to optimize one of the things that optimizes is recovery from loss over the satellite link a particular thing that makes it a little different than what was talked about earlier is you\u0027re still going to be latency there even with a loose based solution but the key thing we\u0027re looking at though is with the move "
  },
  {
    "startTime": "00:45:51",
    "text": "towards things like quick we can\u0027t do split TCP anymore so we need some kind of underlay as was pointed out you know we actually have proprietary solutions now so one of the questions a couple why are we looking potentially a sterilised one well one is maybe we can leverage open source solutions especially with respect to solutions that include more advanced FEC the other thing is for my future thing which is out of scope I think Ted brought it up even though right now we\u0027re not looking and going to the end host you need this this part in the middle to get there because I would like to optimize recovery over that Wi-Fi link at my remote site also so you know in the longer term I want to build on this solution to get to the point where I can actually recover because that\u0027s another thing that pept does for me is it gives me the local recovery at each of the three spaces so that\u0027s kind of where we\u0027re looking at it you know terms of why we\u0027re interested in this from the satellite what have you so I kept it under the 5 because I talk fast there any questions fantastic you\u0027ll recover two minutes oh no I\u0027m going to create the problem here actually again with the chair we\u0027re actually having two drops that actually want to put fvc inside quick to deal with losses without having another layer so how do you go well how are you going to deal with essentially two layers of FEC one below which is what you want to do in loops and the one that we already have inside quick why do we need to loose well I I\u0027m actually very interested in that solution also because I actually because it can learn something about the network and be very specific to the transport protocol this is more generic but also you know hopefully I would say I would set this up to be intelligent enough that I wouldn\u0027t use this one if I didn\u0027t need it if if it was there or maybe I use this one you know quick still going to have a learning curve to figure out that I\u0027m going satellite-linked so I think they could play together but they are actually there\u0027s two different approaches and I\u0027m actually interested in both solutions towards us the FEC inside quick is very interesting to me you know I think what I hear is that there seems to be a gathering of a ton of different pieces of information that come from a ton of different groups and research groups and I don\u0027t know one task that you guys want to to take is actually to see what exists and what has been done and what can actually be used here next slide set ok well thank you but what I\u0027m saying is that yes there is "
  },
  {
    "startTime": "00:48:51",
    "text": "going to be FEC inside quick and I hope that who do not work against one another yeah I guess one of the problems I have way you just said that you said there\u0027s going to be its research is it really good I have to say the reason that our draft is not in the quickly in the quick working group is because they are focusing on delivering the first version of the product yeah and we didn\u0027t want to come in too quick and with this FEC proposal and things up well and actually I will tell you that the way the draft is being structured right now it is not structured that their research draft it is structured as a working group draft but we\u0027re holding on to it so that lures can start sleeping at night and not figuring out that we have these people coming yet another add-on to quit that will the last two hours of sleep I added so yes it\u0027s inside the research group right now but it is not to be a research paper the strategy is the minute that these guys issue version one or whatever the stable version they have we are coming in the in the working group thank you okay yeah and I hope that\u0027s the way it works out I was trying to hedge my bets yeah cuz I I just wanted to say again we want to play the part to where the entrant protocol will be so of course yes we are considering if you see that is being done end to end so that\u0027s useful stuff going on and what loops can do is provide FEC in places in specific places in the network where it\u0027s needed and not having the overhead in other places so this is 100% complimentary and yes the fun part will be getting the to dynamic adaptation algorithms work together correctly that will be enjoyable and I\u0027m looking forward to it well I don\u0027t have the research for that yet but again there\u0027s a difference between a protocol and a mechanism and we can standardize things at different times so when we understand good mechanisms to do this optimally we should send analyzed those and we should define a protocol within which we can do these mechanisms investigations actually I should probably mention that we\u0027re kind of getting towards the discussions that we would have at a chartering time for a working group which it\u0027s now is not be honest out the conversation we\u0027re having here but then it is stuff that we have to think about and probably stuff that has to appear in the Charter but it\u0027s just not necessary for us to know what to do next after "
  },
  {
    "startTime": "00:51:53",
    "text": "noon today Lars Eiger chairing the quick working group so we don\u0027t have fact on the agenda at the moment on the agenda on the Charter at the moment and while there is significant interest in having some sort of effect in quickly at the moment it\u0027s it\u0027s if they\u0027re all individual proposals right and and there\u0027s no working group consensus on what to do with this I will know that that fact was actually part of Google quick at some point it was removed at least one particular way of doing effect and quick because it didn\u0027t deliver on the promise a new proposal for doing second quick might be different thread and better and and - to cause it to perfect at the moment or if it is no such plan on the charlie thank you can have this visual image of the new flick that the hordes are hiding against the castle gate and as soon as v1 drops we\u0027re gonna be I don\u0027t wanna sleep now but I fuck I so I think that you know I came here to try to get a better understanding of what the problem is that that the blue who have used cases feel they need to solve I think that will inform some IETF activity maybe it happens in a new working group maybe happens an existing working group and also to learn about some existing proposed solutions to try to understand what the solution space is you know what\u0027s changed and what are people doing so I think that the network coding is an important piece of that quick is a piece of that the the overlay stuff is a piece of that so I don\u0027t see you know this is an informational bar so we\u0027re just we\u0027re not making decisions about what\u0027s gonna happen we\u0027re trying to understand the problem space and so I don\u0027t think we need to have the argument about where the work is going to happen we get to do that in a we\u0027re going to performing Bach Jinlong you\u0027re you\u0027re next morning everyone this is John from China Telecom and like I like to present a petition scenario that loops could be applicable as its mentioned in the draft I will talk about a zombie six and base that Enterprise one connection his kiss for loops after say I will take a brief introduction about the background China is the largest public Internet backbone network in China a melon provides Robin Internet and a cloud access was for public users and enterprise users their entire network devices are ipv6 enabled and we plan to support SRV Six Sigma routing of ipv6 to provide the path selection to me services array however when we deploy some services of the internet for example enterprise usually "
  },
  {
    "startTime": "00:54:56",
    "text": "require network connection between the branch offices or between branch offices and cloud data center over Geographic distances the problem we encounter is that the traffic over the Internet a subject to lose during the best effort networks so there is a urgent need to do network optimization to provide high quality internet for specific service that needed the reliability of data transform the following in the use case as the picture shows there are two branches of the enterprise which access the internet through visa Vee for one connection and recipe connects to a cloud-based pub which further directs the traffic to the PC for cloud access you know we see PSO and they favor two node in the network so it can be enable with some whining I did services to be provided from providers work so we can see there are three typical services deployed the yellow one the yellow line represent one connection and the green I represent the cloud axis and the red line represent the DZ interconnection so obviously we can say one we see p2 another vase EPE recipe to a cloud-based pub pub to pub can be over a long distance which could be divided into multiple Szabo paths based on a sorry six segments but some of which must have packages generally so this is the will be of opportunity for loops which can be enabled for the segments of the scible paths to solve packet loss and provide the better for path selection with with this deployment we can provide her County internet connection in terms of loss rate so do you think it is so applicable use case for loops that we also should focus on and I think it can be applied to the enterprise one connections an area apart from that s our v6 provider provide the path selection naturally so it could be a specific encapsulation protocol for loops so it could be considered in the following work so if you are also interesting this topic welcome more common and discussion thank "
  },
  {
    "startTime": "00:57:56",
    "text": "you okay thank you very much so the next presentation is by Michael giving us some ideas or solutions can look like the Spencer has definitely started trying mercy do my best to be yeah double time here alright quick overview of how loops could work I got the impression from the discussion already that some people tend to have a specific image in the mind of how a loop system is gonna work like it\u0027s definitely going to affect or it\u0027s definitely gonna do resequencing and I think none of these things are none of these things are decided yet so this is just an overview of the possibilities that that we have you know some things that we thought about a strawman of the information that would have to go between an ingress and egress so that this whole thing could operate that\u0027s you know the context for the for the following details you know we have data going into an ingress we have data that\u0027s possibly encapsulated not necessarily there are two possibilities here and I\u0027m going to explain what\u0027s an egress the egress is gonna act on AK or both and the ingress is gonna reach transmit or it\u0027s gonna use fetch or both not probably not but we transmit or use FAQ and then well the end goal is that much better data and leaves tigress I mean more data less death less testicle there so the problems that we\u0027ll have to try to address loss detection and regions mission we need to somehow do something about loss we need to well probably work on fact then the will also be a need to detect congestion that happens on the path segment they will need to be some measurement that will need to be some congestion detection and we\u0027ll need to think about how congestion is signal towards the end hosts if it was if it was detected can be done by dropping a packet which is against the whole purpose of loops but you could drop you know a better packet in the last packet could be done using ecn which is preferable some concrete ideas on how these things cooperate are coming now but it\u0027s just a straw man the two modes here that I\u0027m going to present to you the first is tunnel mode which is I guess closer to what most of the things are that you\u0027ve seen so far step one of the steps that you that you\u0027ve seen is encapsulation you would on the ingress side encapsulated in something we don\u0027t specify how yet you know there are the document has caches of gooey and of genève and how it could be possibly done but the point is you would encapsulate and add some information that is necessary such that "
  },
  {
    "startTime": "01:00:58",
    "text": "we can reflect for instance sequence numbers we can use you know proper X so you need obviously right you need to identify packets you need the sequence number we identified also some other information Tunnel type an actus arable flag I get to what that is about quickly next slide and whatever might may be needed by a key so regarding exact desirable flag there are two blocks that are currently being envisioned for the feedback this box would be just sent in some way right it could be interspersed it could be repeated they could be piggybacked on packets but the point is that there are two information blocks that are transmitted from the receiving from the ink from the egress back to the ingress one is an optional bottle both are optional they don\u0027t always have to be included in every a key one would contain the PSM this sequence number and an absolute reception time such that we get the delay signal that could then be used for as a congestion indicator and the other one building would contain an occupied map that\u0027s based on the packet sequence number and a delta indicating the end of the the last psn of the bitmap so that\u0027s the feedback and then getting the feedback the ingress would do something right it gets max or it gets it so it learns about missing missing sequence numbers from from this occupied map or about catenaccio make a decision that\u0027s somehow related to the congestion estimate that it\u0027s taking possibly use this young you know if that if that works to somehow influence the decision calculate late severe variation from the timestamps in feedback blocks and well and then it would either retransmit or sent factory pair packets depending on how design goes the egress on forwarding it but you know effect is used it would defect and it will have to inform and holds about congestion if needed so there is an opportunity here to make it you know to to distinguish between between congestion corruption loss or some some other form of loss loss that happens that isn\u0027t congestion if we can do that something that I find personally interesting about this as people were saying you know this is what introduced delay and it would you know if you can\u0027t you know in the worst case you know you\u0027ll have to you have to inform the aunt systems about a lot loss here I see that as an opportunity to make use of ezn signaling you have an systems today that uses yen and basically no equipment inside the network that makes use of ezn so here there will be some equipment I could you know basically you could turn a loss notification into an easy end notification with this right if you have "
  },
  {
    "startTime": "01:04:00",
    "text": "easy and capable sandals you can tell them so that\u0027s a summary slide of the information exchanged in tunnel mode on forwarding the packet sequence number tunnel type actually terrible flag that would inform you that occasionally you want to have this timestamp included anything that\u0027s needed perfect and for backward these two blocks one that contains the timestamp the other one that has this occupied map now just to show that this whole thing could be done in a much less intrusive way as well and a very different way we get to this transparent mode that\u0027s in the appendix that\u0027s a bit more radical and the point here is to to have the least intrusive possible thing the goal is to never delay anything and to not even tunnel just I\u0027m just just discussing retransmission you could do the same with FAQ you could have all kinds of variations in between the spectrum yeah but in the simplest case you know you would on the on the English side just forward and keep a copy of the packets with the hash of a packet so I you could identify it so it\u0027s just taking a copy but forwarding not adding any header or anything the hash calculation made it many to include data beyond IP but this is not relying on a specific protocol anything it\u0027s just taking the bytes and the egress would answer in this idea here bodek it couldn\u0027t neck right because we don\u0027t have consecutively growing sequence numbers we just have hashes and the AK format could be similar to the tunnel mode now the ingress upon seeing that there\u0027s an RTO for one of the hashes that it has it could make it make a decision to retransmit packets that could also be that should be done based on a congestion estimate as before the cost of a hash coalition in this whole thing is kinda low because what that would mean is you mister retransmit opportunity if you if you have a hash collision you just can\u0027t store it in your cache so you\u0027ve reduced the probability of being able to reach and submit something at the egress we\u0027ll just forward so that that\u0027s you know in that particular case that\u0027s all they would be doing there wouldn\u0027t be any reordering I think sending things on without resequencing I mean yes you have modern TCPS that can handle that well you have rack you have experienced loss detection mechanisms but I think it\u0027s important to keep in mind that for TCP s that don\u0027t have that or any mechanisms that don\u0027t have that you know the worst thing that would happen is that you don\u0027t have the benefit of the region\u0027s mission right it\u0027s not going to be any worse if you just forward you just don\u0027t have any benefit in in the worst case then they\u0027re all done would be you udp-based transports all kinds of transports that might you know not have a big problem with the reordering anyway so there may not always be a need to "
  },
  {
    "startTime": "01:07:01",
    "text": "delay packets sequencing to summarize this on forwarding you wouldn\u0027t add anything extra on back or backward you would have roughly the same thing as before this blocks one and two they would have to look slightly different block one will be limited in some way because this act is Arabic flag doesn\u0027t exist we don\u0027t have any forward information right yeah and then everything is about hashes so black two can\u0027t really have this occupied map you know we could maybe you have a bloom filter or something like that some interesting way of encoding X and that\u0027s that so the point is there\u0027s a spectrum of possibilities here we\u0027re not trying to nail it down to one specific mechanism just yet rather the idea could be that we could have a framework that would allow to implement several mechanisms in all cases it could be pretty beneficial when the RTT on the segment is much shorter than the end-to-end rgt that\u0027s already well I think these things have been said you know while this next use that fact and well I believe in the benefit of reducing Talos yeah clarifying question I don\u0027t I don\u0027t think that I mean we\u0027re getting close to this lot of longer discussions anyways oh yeah all right [Music] in excellent work on time management thank you okay so so there are a number of questions that come up with and again and again some of them already have come up just to answer a few of them so one one misunderstanding you got early in the process was that this was only for encrypted traffic well it\u0027s for any traffic and the message is that we can work with encrypted traffic and loops does not peak beyond layer three well maybe the part numbers but not beyond that so that doesn\u0027t mean that an implementer couldn\u0027t apply some secret sauce they still have from the pet days and do wonderful things by digging forward and combine them with groups but we\u0027re not going to standardize those so the solution we are discussing here is based on don\u0027t look don\u0027t touch how do we actually know which of the packets in an aggregate are worth worth recovering and the answer is Lukas doesn\u0027t have a "
  },
  {
    "startTime": "01:10:03",
    "text": "way to find out but there is a little bit of an assumption that the the setup mechanism the controller based setup mechanism that you use for installing a loops pair somewhere in the network might also have a way for for the ingress know to sort between the useful recover ones and the ones where where you wouldn\u0027t care Korea how how would he have an insight into which ones were better to recover well it might be part number eighty-eight oh no so there may be ways in network you know oh this is an important customer so we are going to to support their application and this other customer hasn\u0027t paid their dues so we are not supporting their application itself called Project something for coming this completely out let\u0027s go out of scope for this third question how do we transport the measurement related information or actually any reverse informations so any measurement related information that is going in the forward direction probably would be put into the encapsulation as a form of an extension together with the sequence number so if you would need to send a timestamp for some reason we would put it there we\u0027re not currently advocating for that and the the reverse direction could be done the same way we do with the AK information so again that depends a bit on the encapsulation if you have a bi-directional tunnel you might be able to piggyback it if your tunnel is Julie directional you have to send several packets for the X anyway and you can include measurement information there and you do the fullscreen thing again code screen holds mean fullscreen carsten yes David David black real quick real quick note on your second FAQ which says this is an l-3 only mechanism I assume that\u0027s that that\u0027s intended to scope for whatever whatever comes out of here is that correct yes okay one could point out and I apologize not doing this during during the second presentation and the satellite presentation if you look at what a satellite pepper does it does two things one is it does some things here to to deal with losses as soon as you can figure out the size that something has not bounced off the satellite the other thing that it does is it MUX with the transport protocol to grow the window historically this was needed because endpoints just didn\u0027t have enough buffers to fill the pipe up with satellite and back the former it would be within scope for loops the latter would be out and have to do it in the "
  },
  {
    "startTime": "01:13:04",
    "text": "transport protocol itself somehow okay the question that comes up loops has some cost even transparent load has some cost because you have to send forward and back the ancillary information how do you know that this cost is actually worth it and again we assume we have some some Network intelligence some controller thing that understands what\u0027s going on in the network we may want to put something in loops that might actually enable the protocol to dynamically be switched on and switched off to make this quicker if the assumption is something is providing the information and providing the monitoring that allows making that call yeah and I think the the final question has been answered but just to repeat we need congestion relay we don\u0027t want to lose information in this tunnel so we need to do a dropping for non easy and capable transports and yeah we can do this by by dropping we can probably more usefully do this by simply not doing retransmissions when we know those would be dropped for organization feedback anyway okay so let\u0027s talk about related work for a moment Cori has a better idea I\u0027m looking forward to him telling me after the meeting so of course as we said many of us have worked on systems that did something like that some people have first sent mail about interesting papers about this we know that link layers are doing that for us all the time and if we look closely at these link layers these are often tunnels so yes this is being done and an important part of the actual work will be to get a better overview of what\u0027s going on there does a custard so I\u0027ll note that there\u0027s a lot of related work as you say in the ITF but but the the most sort of common thing that was brought up today are pets and those we don\u0027t have any idea because the vendors of those boxes have had no interest in an IGF standard ever right so I you know has that changed it so bill those vendors participate here or your are we are we standardizing something that then we\u0027ll never get actually shipped well I can so I\u0027m also about pimping is the interest from the vendors that traditionally this is very close to a pet box but we don\u0027t standardize those here we never have not for lack of trying simple because the vendors weren\u0027t interested has that changed at "
  },
  {
    "startTime": "01:16:05",
    "text": "other vendors that traditionally have shipped these boxes for customers do they want common standards in this space now you think that\u0027s very much a business decision for them well if they decided that it\u0027s in their interest to so what do you think that\u0027s a prerequisite for doing this work yes I don\u0027t things that is relevant here is that that\u0027s a really good question for a working group charter time but I don\u0027t know if we\u0027re going to be able to figure out the answer between now and twelve o\u0027clock that would guide us on what we do after twelve o\u0027clock so I would encourage everybody to not have a food fight about business models and things like that but it is an important question for us to talk about at charter time I mean my answer would be that time is playing for more and more software based networks were much larger variety of you know vendors are coming into play so the opportunities I think are something that we can try to leap onto right now I don\u0027t think that traditional hardware vendors might be the first ones to pick up after the experience was correctly recited but that\u0027s not the market anymore alone today all right Aaron Falk I want to respond to largest point I think that I think that what we\u0027ve heard here is expression today of operators who see this as a problem that they want to have solved the fact that a set of vendors doesn\u0027t want to solve their problem for them is irrelevant right somebody they want somebody step forward and solve it they\u0027re asking you if you have to do it if the ITF doesn\u0027t do it then they\u0027ll find some other solution that\u0027s what is what the pet benders did so the economists word is this is disruptive we don\u0027t need the agendas that might be more discussion or question no no we speak about pets but this discussion is also relevant for all the software define one equivalents that are in the market today that are not interoperable so if we want to standardize something we may want them to be to work together but there are already lots of solutions that do this kind of things and also something that I think is missing if the discussions now needs to distinguish whether the scope is enterprise networks or public access because as soon as we have public access we have all these they\u0027re true mechanisms that will break whatever we just adding another layer on all the existing layers okay I just want to give "
  },
  {
    "startTime": "01:19:08",
    "text": "a very specific example following tallest comments regarding why we want to standardize this for example we have current we have an EMV function we have vcp and the v8 way so they\u0027re possibly provided by different different parties so that\u0027s why I want to stand out hi Stuart card critical technologies I just have a couple of points on scoping there\u0027s a focus on loss mitigation and there\u0027s an assumption that we can really only help when the round trip time on the path segment is significantly shorter than the end-to-end round trip time neither of those need be the case if you think of path segments as essentially being transfer functions and different path segments having different statistical characteristics they are different transfer functions and so the end-to-end transport protocol is presented with a composition of functions that it may not be well able to handle and so the different transport protocols with which we are familiar makes certain assumptions about those statistical distributions and congestion versus non congestion losses and so on it may be that by simply taking a segment that exhibits a different statistical distribution that then the end-to-end transport protocols are anticipating and causing that segment to conform more to the expected distribution we may enhance end-to-end performance even if the segments that we are mitigating has a long round-trip time and even if the underlying problem is something other than laws yeah I think that\u0027s particularly true if the other segments contribute something to how the decomposition feels in the end the other segments segments are completely lossless completely clear you are not winning a lot Tom Harper so thinking about the use cases this actually looks a lot more like a piece of QoS to me so we\u0027re basically offering a well it does in the sense we\u0027re offering a path with more reliability or lower latency or something like that so if you view it as that it sounds to me like this could be considered one type of QoS for a path and then something like the pan or G or some of the other efforts to make qos aware networking might be applicable so the application or the transport layer may in fact know about this information it could then adjust its transport layer no you want to keep it transparent to the end host but there actually could be advantages if you could somehow expose this to them yeah there should could be advances to a path away networking we are not solving this problem in this room well I have a slide on that one comment I know you want to "
  },
  {
    "startTime": "01:22:11",
    "text": "keep this completely independent and all layer three but the second you have any sort of multi path where you have you can take possibly two segments you\u0027re gonna have to make sure that you do that per flow at the transport layer so it\u0027s it\u0027s inevitable you\u0027re gonna have to look beyond layer three or use the flow label or an ipv6 or something like that I just do one come up again when i was III Brian Crandall my energy co-chair had energy say it said like three times so I was summoned um I would say that the problems that we\u0027re trying to solve here in loops are actually kind of overlapped with a lot of the problems that we\u0027re trying to solve energy the approaches that we\u0027re looking at energy are entirely different in that the energy we\u0027re looking at taking the this information whatever measurement information you get from the path that goes into the deeps ingress point we\u0027re actually taking it and taking it all the way to the endpoint right like so we have a completely different name we want to modify the endpoint so that it can do paths where sort of stuff that being said there\u0027s a big question going on in panner G as to what is an endpoint is a tunnel ingress midpoint also an endpoint maybe I don\u0027t know so one of the outcomes of this lake so things that are a little bit less engineering uni a little bit more research he could certainly come over to panner G and be digested a little while and then come back to the idea I think that\u0027s that\u0027s a way to do it so I Aaron Falk again I just we shouldn\u0027t lose the sort of initial insight from your you\u0027re opening science which is that the concept here is to fix packet loss close to where it happens which is not what and in fact or energy stuff is trying to do now maybe there are other benefits but that\u0027s part of the trade-off space right that if you know you\u0027re you have a good put increase if you are able to do that so I just think we shouldn\u0027t lose track of that thank you okay now to my presentation have really sad yet I wanted to quickly point to four pieces of work inside the aisle I eat EF and actually in one case inside the IRT F that are interesting in this context one of course there\u0027s lots of work on measurements and we want to stand on the shoulders of those people and not on their feet there is actually some work already on ER loops like recovery thing going on which you have noticed yet because it\u0027s happening at the internet layer there is the the network coding Research Group work and the TSV work in particular on sliding-window IVC I\u0027m "
  },
  {
    "startTime": "01:25:12",
    "text": "singling this out because it seems to be the next thing we want to touch but there of course other things we want to learn yet there and there is something called tunnel congestion feedback so let\u0027s talk about these four things quickly I am or Institute OAM is used to collect information within the package why the package traverses a path between two points in the network so it\u0027s about hop hop hop hop information it might return the measurement to a third party using postcards and yeah my observation would be loops is really about an ingress and egress pair and not about lots of hops so at some point we won\u0027t may want to mix that in some form so rubies may be able to make use of information that i ôm provides but right now this seems to be a little bit different i also uses the generic information model approach which is not new in the IP PM community so we can certainly learn something from there so we can map our protocol to multiple formats and speaking about formats the data formats that the IP PM people have developed and maybe some measurement methods are of course things that may be applicable so that\u0027s rated rogue number one related work number two the 6lowpan fragment recovery word came up in 2008 in the 600 plan but in a world where I was to chairing it I have spent the last 10 years mainly and in trying it not to make sure it doesn\u0027t happen but at some point the 6lowpan group was decided to replace but the 6-2 working group and so on and this is now no down it has passed working with last call in the 6th over Europe and we\u0027ll hit the iesg soon now this is a little bit different because it\u0027s about fragments within a packet it\u0027s not about packets and and a number of parameters constrain the situation a lot so that actually may be more attractable than it would have been in the global Internet and yeah of course again the congestion control issues the the interesting one and the question about the control loops working against each other so this is work that\u0027s going on and I would expect other pieces of work will be going on in the ITF at some point when it\u0027s really needed so I think it would be good to bring these things together in groups I mean I don\u0027t mean stopping this work but just learning "
  },
  {
    "startTime": "01:28:12",
    "text": "from it and going forward the sliding window fec I think is interesting which has has left the network according research group and is now in TS vwg draft and that\u0027s certainly something that will go into a good loop\u0027s solution and finally there is the channel congestion feedback framework well yeah this is one one more of those TS WG drafts they\u0027ve like mentioned a few more ones that we may want to use there is an IP fix mapping in there we may want to use that as a source of information elements that need to be part of loops okay I\u0027m doing this really quickly I just want to say what is really out of scope of loops and really the the litmus test here is do you need host participation to make this happen and well Panaji is about host participation Erin sorry I just I just want to challenge your framing of this question because it seems to me that you know we\u0027re motivating this by several operators who say they have a problem you know I think would be they haven\u0027t said that the host participation is impossible from their point of view that it is that it is a it\u0027s a requirement that the host cannot participate I\u0027d be interested in knowing whether that\u0027s actually the case or not yeah maybe I should have been more specific because in the slide that John showed you have this leaps loops thing in one of the end hosts but the interesting thing about this loose thing is in an actual implementation this would be in the VPN layer it would not influence the transport layer in the host so you\u0027re talking about the solution not the problem I\u0027m trying to understand the problem right yes I don\u0027t care whether loops is the solution yet until I understand what the that is trying to get off like if I could just do it your interrupt here it would have been reasonable for us to say at the beginning of Carson\u0027s presentation that this is Carson\u0027s view and these are the things that the we could talk about a chart you know and probably really a charter time so it\u0027s not necessary for us to to figure out what all the linkages are really but to figure out where we need to be with you know with observations like Erin\u0027s so thank you yeah thank you that thank you so it\u0027s almost like that did I hear you it\u0027s out of scope from my current of "
  },
  {
    "startTime": "01:31:12",
    "text": "three years yeah but I mean why because we want to solve the tractable problem first before we do the interactive real ones and how do you make the judgment call about what\u0027s tractable or not shorter time yes I\u0027d say I mean there is there there is no reason to try to constrain you know the specification of the solution to something that you must not deploy however you figure out also on the Intel\u0027s right the point is that this thing works best if there is not a deployability block that is caused by hosts this is really what I\u0027m trying to say nobody said you must deploy it on the host the the the the way I perceived what you were saying is that you exclude the you know option to even do it on the host or the host is a node I think the question has been noted you end the community needs to be aware of that question as we discuss things further so I think this really helps clarifying the concern yeah so the point is if we do this right it doesn\u0027t require host people to do something now there is one other thing for instance the the spin bit discussion in increase if that creates something that could be used that\u0027s great if the problem that you\u0027re trying to solve with loops is on the last or first help to the host how do you solve it well maybe solving it second the difference between the the in network case and the case where the host is involved is that with the host a number of additional considerations come in like how do you actually do the setup what are the privacy considerations and so on know as you yes you just brought the example right if you basically simply do it sure implementation questions decide just you know as part of the network layer in the host stack then you\u0027re having exactly the same architectural model you\u0027re just also able to include the first last hops yes in the solution so I don\u0027t think we should go beyond that but that option certainly shouldn\u0027t be excluded so I think we are actually moving past the end of Carson\u0027s last slide and into technical discussion so like to thank you Carson program leaving this section of the are for sharing the maps and gaps analysis that you\u0027ve done so far very helpful and I think we are - open mic time we have a timer running for just a little under 17 minutes for us to talk "
  },
  {
    "startTime": "01:34:12",
    "text": "and then we have ten minute we measure will go off and we\u0027ll have like 10 minutes to talk about humps and things like that so please make please make your comments please make them succinct Brandon Williams Akamai just one quick thing about the previous talk for completeness Network coding research group is also looking specifically satellite use cases it would be valuable for for you to track that as well thank you but Briscoe again I just wanna I said I might come back to this and I\u0027m coming back to it I\u0027ve not heard an answer to the question I don\u0027t get why you want to do something on an overlay that\u0027s relatively easy on a link and the link if the link knows it\u0027s bad it do it because they want to sell their technology so why try and fix something that someone else has got the motivation to fix anyway and they can do it really easily and it\u0027s really difficult to do just slightly above that layer it just doesn\u0027t make sense to me that\u0027s actually interesting because in a rational world you would be right but there\u0027s a bad coming years if there\u0027s a ssin may not be the person that owns the name yeah that\u0027s the answer to the question are you talking equipment build a person or operator person yes both but what I was saying is that those that develop technology have a standard idea at they are chiefly or whatever link technology they they have a perfectly good motivation to do link layer retransmission if it\u0027s going to make their link better so I\u0027m no longer a satellite person so John can stand up and correct me but just use a satellite link as an example but it you know any any physical layer right when you design the data transmission for the link you basically make an effort I\u0027m going to try so hard to get the data through and then at some point I\u0027m going to give up and there\u0027s sort of an economics they\u0027re like you know how much data can I consistently get through under what conditions you make an assumption on how that link is going to be used by the person who designs and runs the link often knows very little about the "
  },
  {
    "startTime": "01:37:12",
    "text": "application and within the application owners or the various parties that are in between the app the the end application user and the link designer may have very different ideas of how that link is going to be used and if if the link is better than they need nobody complains except maybe about price the only goes worse than they need then you then some other party has to try to improve the data throughput right and that\u0027s what we\u0027re talking about now right the in going the assumption here is that the link is not good enough right otherwise you don\u0027t deploy this at all yet once the link is if the link is good enough then we don\u0027t have this conversation [Music] Danny the other case that you talked about is we are that the person who wants to make the optimization sees a path that person doesn\u0027t have access to all the individual links okay has the part and it once said they want to optimize the usage of their path but I actually wanted to give another example we are what you said it\u0027s not working either net is standardized by Triple E and wireless Wi-Fi is kind of trying to be like either and there is one constraint in Ethernet that IP doesn\u0027t have which is even as the sequence preserving IP is not sequence designer so we can do things at layer 3 that you came up to weight layer 2 which is weird but it\u0027s the current situation yeah I was just thinking - Aaron had said no I was thinking that they big change that you\u0027re proposing needs to be split into two parts the other I power on the sequence not preserving pop and and and once the link people know they don\u0027t have to keep the thing from sequence preserved then they\u0027ve got a different way of fixing their links you know currently they do it to a certain level and then they think I can\u0027t wait any longer to get this retransmission because I\u0027ve got to keep everything in order I\u0027m buttering up a receiver but if they can relax that constraint then we don\u0027t well the paper I sent on me on the loops list a couple of days ago says how you can now know where the racks being used or not and so or something like something that\u0027s less order okay so Cory first and we said was it a transport thing if you start fiddling with ordering and changing the transport properties of your path and this is certainly a transport topic Tom Herbert so to me it seems like the biggest now use case of something like loops would be a long path delay say over the "
  },
  {
    "startTime": "01:40:14",
    "text": "Internet where one of those segments within that is low delay but possibly high loss and to me it sounds like that would be a mobile network satellites interesting but that seems like that already has a long delay so I\u0027m wondering or guests asking are there applications in mobile world where we do have that situation like at the last hop or Radio Network getting to that point that could be that low low delay high loss is there value for loops in that scenario or is everything already covered by some layer to retransmissions that\u0027s not an issue Spencer Dawkins speaking as an individual contributor I like Tom\u0027s question and I would offer as a semi friendly amendment what if there are two what if there are two network segments like that and and that that you know it seems to me that we can\u0027t really guarantee that there would there would only be one and so to the extent that there is more than one I think that changes the way we look at the problem well look at it this way what\u0027s the most common use case so we have our mobile phone connecting to a wireless network eventually it gets into the intranet and goes to Google or whatever so I\u0027m assuming that that later part is already pretty highly reliable but the longer latency but I\u0027m really interested in it is that short path where we could definitely have high loss and to me if Luke\u0027s is optimizing that and it seems like the key here is if we\u0027re going to do these retransmissions it has to be so fast that that really doesn\u0027t affect the end-to-end view of delay so if you can slip this in and save a packet loss as opposed to increasing delay then and there\u0027s a value yeah I would also maybe observed that when Aaron and I were co-chairing milk the B common case of what people were optimizing for was like 56 kilobits links so you know I think we should probably think towards the future as well it\u0027s Ducard kernel technologies just a specific example of such a low latency high loss case I Triple E 802 that 11 P wireless access and VA theater environments dedicated short range communications especially when you\u0027re handing off from one access point to another totally sacred I missed the beginning so I\u0027m not quite sure if the scope was more about you know dealing with congestion loss on on congestion loss right what I would say is that traditionally you know the non congestion loss is something that you know subnets try to get rid of but you know if we look through the industry that hasn\u0027t always been very "
  },
  {
    "startTime": "01:43:15",
    "text": "successful so I think one of the questions would really be you know how awaiting the scope of you know congestion laws local solving and non congestion loss local solving right and I think it would really be nice to have something that\u0027s more generically applicable to all type of subnets if you have a shocking subnet where it doesn\u0027t you know the provided mechanisms of that layer to submit are not good enough to deal with the loss it has the non congestion we\u0027ve cleared the mic line which I find amazing we have about 17 minutes until we\u0027re through so it may be time for us to move back to the questions to get us right so the biggest one do we understand a problem and I don\u0027t know Spencer do you think we should have a discussion on each of these or should we try to do humps as we go we have 17 minutes but we\u0027ve only has 6 already 6 16 minutes but we\u0027ve only got 16 minutes let\u0027s do humps and see if we need to do a discussion on the no that\u0027s wrong okay prepare so those who think that we do understand the problem can you please hum now thank you and those who do not think we understand the problem please hum now okay - yeah 6040 perhaps but yes we so so we made it we made the right yeah we made the right choice by having it now worker forum Bob hi Aaron Falk again let me try not to kill you what I think I heard because this was exactly my mind in thinking that this question which is we have identified a bunch of problems I don\u0027t think we\u0027ve identified how they group together to become the problem there\u0027s a bunch of there\u0027s work that\u0027s going on there\u0027s a lot of history here there\u0027s stuff that is kind of outside the scope of the IETF and it\u0027s that there\u0027s mechanisms that are happening way down in the staff and in the applications and I have not come away from this discussion with a clear idea of the thing the thing that\u0027s unaddressed that there needs to be work on so that\u0027s that\u0027s what I heard I was trying some 70% policy modulation "
  },
  {
    "startTime": "01:46:16",
    "text": "I understand the problem so I think it very much depends on a lot of the scope details right so I haven\u0027t heard you know just vague sub sensation of trying to differentiate between different traffic right obviously congestion control expectations of this adhesive e are different from TCP right would we be willing to do that and the whole discussion of why the heck would we want to exclude the last thing so understanding comes a little bit through the refinement of the scope and I hope that we can solve this for me 30 percent remaining I burn caramel no hats at this point the so I hunt yes because actually I think we\u0027ve understood this problem for the past quarter century and we\u0027ve had the problem for the baryon supporters entry and we\u0027ve come up with a bunch of bad solutions for it right so the the the thing that I\u0027d like to see a refinement of is one a little bit of the refinement of the scope but to a little bit more of the fun none of us not the scope of the problem but also scope of the solution great like so a little bit more discussion about which exact subset of the we do not have complete clairvoyance for every past segment of transport problem do we want to solve here and then a little bit more of the the reducing down the solution space to something tractable I think this this ball was a very good sort of start to that and I\u0027d like to see you continue but yeah that\u0027s why I hummed yes and still came up with a mic line and thank you to the presenters and everyone who participated for that yeah given that we half of us don\u0027t understand the problem yes should we see what they know so one one way for us to rephrase the question now is that I think I heard assertions from multiple people out of the research community that at least some parts of this are engineering so as long as some parties can answer engineering to the previous thing because there was some comments on the microphone that made it an important distinction between the program and the scope of the problem I think 60% of the room answered the question do we understand the problem in 40% and such I don\u0027t understand the scope of the problem and can we so so if I was going to do a friendly amendment to the question that\u0027s on the screen I think I would be suggesting something like is there engineering are people ready are there things that we talked about today that were ready to do engineering that don\u0027t need additional "
  },
  {
    "startTime": "01:49:16",
    "text": "research and I was thinking in before the buff that if we had enough people show up saying I\u0027m working on this now that that was at least some people have thought that but the microphone lines are open as they say yeah you\u0027re caught too quickly looking at the first bullet I was actually humming with the question in mind whether we have a common understanding everybody may have their own idea of what the problem might turn out to be useful to have a common one and I\u0027m I haven\u0027t Gilly that hasn\u0027t come across to me Colin Perkins with with no hats [Music] is this Engineering or is it research I would say that big chunks of this are engineering and parts of it are probably still research but I think that\u0027s okay this could be a good topic at the IRS GE dinner I mean you know I mean to expand a bit I think there\u0027s enough of this which is engineering that there is a useful IETF work we can do there are bits I think we don\u0027t know don\u0027t necessarily know how to solve I think we don\u0027t necessarily need to know how to solve them all to do an initial version of this yeah it wouldn\u0027t be the first time the ITF has chartered a group but we don\u0027t have all of the answers at the beginning so stiffening up I come back to that question which I had originally I read here is this engineering or is research required blah blah blah I would say absolutely there is research required maybe not technically research but I think I think base insufficient input on whether there is actually a demand for such a standard for standardized solution that I do not see personally david black i hummed no on not nourishing a problem because basic please come what I heard some matches mine which is a bit concerned about the scope is our problem here yeah that\u0027s probably more than one I\u0027ve heard discussion wander back and forth across levels two three and four and I think I want to see a focus a clear focus on one of the levels with a clay defined scope to change my hum from no to yes thank you Aaron Falk again so I think what I heard very clearly was a proposed set of requirements for a protocol something that operates over a subset of the path doesn\u0027t involve the endpoints works on IP is transport independent and doesn\u0027t modify packets as they go what I\u0027m not clear on is a "
  },
  {
    "startTime": "01:52:20",
    "text": "how important is that how useful is it how what what set of problems it solves having said that you know I\u0027m not opposed to seeing somebody go and build something like that and try it out I don\u0027t know if I would recommend that it be used on the internet or what problems it\u0027s going to be useful for but so to me this is even with that statement it\u0027s not obvious to me it\u0027s it\u0027s in the the gray area between the IRT F work in ITF work I wouldn\u0027t actually be opposed to it in either place I\u0027d kind of like to see the thinking of how this could work move forward I would also like to see it not interfere with some of the other ideas for improving things like effect and quick and the panel G stuff so I you know I say if people won\u0027t work on this they should be able to work on it I wouldn\u0027t stand in the way I don\u0027t think it\u0027s necessarily a bad thing just don\u0027t think we should over promise what its gonna do was hurt occurred I say I guess with my IAB had half kill turd because I have questions I\u0027m not a statement or iam so I the whole point of the IRT F and I\u0027m very glad that there\u0027s people here that are working on that part of the area if it\u0027s not me the whole point of the RTF is to eventually transition work into the IETF for Standardization and I think that this this whole baath shows that there is no an effort or desire to to transition to something that might actually work I do think that the proponents and the research side need to get together and seems like there\u0027s sort of a split between groups and they really need to sit in a room and say okay what elements are ready for transition and what it\u0027s still in research and if solutions exist great now is the time to to push those forward into standards so they can actually be deployed and and put into interoperability the one concern I have is whether the research community in particular agrees that there aren\u0027t issues that are hiding where even though the engineering side may say we think we have a Ellucian the research cited say no you know we haven\u0027t actually figured out like the whole house congestion getting away and how are we going to make sure that we\u0027re not actually building adding that the engineering solution doesn\u0027t add to the problem that\u0027s just my thoughts I think you know the list of places that we need to look look at for this work in addition to just what we\u0027re thinking about here I think that\u0027s going to be not a short list thank you Andrew Berg Riga I think the answers to the first two questions very strongly depend on what the scope turns out to be because there are things in here where I\u0027m sitting there is research required "
  },
  {
    "startTime": "01:55:20",
    "text": "in the potential scope of this and there are other things which you\u0027re like yeah sure we can do that that\u0027s fine so yeah it really does require a very careful discussion on scope so Carson has been standing there for a long time you wanna go now a lot of people who think researchers required some of the questions that came up today I\u0027m really hearing that people think there is research required on the things that we\u0027re trying to do sorry yeah I look a control loop response reply you know yeah control it yeah I\u0027m I\u0027m still not very sure about how all this interacts between different layers so there\u0027s this transport questions and there\u0027s ops questions and I guess this routine questions here and I\u0027d like to see which ones of laws actually have concerns and by whom because the the use case we saw was simple but our people signed up against those two use cases or do they have more and so so I see questions here and I think these are research questions that we don\u0027t see data now with the answers let me clarify this what we need to do is standardized protocol what we also need to do is understand how to correctly use that protocol all the mechanisms so TCP was standardized in 1983 or something and 76 how you look at it and we are starting to understand the mechanisms now and I think we can go ahead and do a mechanism the mechanism work do protocol work excuse me on loops now and fully understanding that we will have five years or so looking at all the research questions that finally go into DBC piece on how to best one it\u0027s on I continue to believe that a basic version of loops can be built today so there are some existence proofs and I didn\u0027t understand that the purpose of this path was to find out whether there\u0027s commercial interest or we would have done more working so yes there\u0027s lots of interesting research waiting for us that is going to go into busy piece at some point but the protocol stuff should be possible to grow the first version of that so if I "
  },
  {
    "startTime": "01:58:20",
    "text": "could do an ad interrupt everybody stay at the microphones that still at the microphones Magnus asked if I could do a hum if people believe that standardization in this space is required is required or if if it\u0027s not and if you think that it\u0027s not a few hum does not feel you know feel free to hop up to the mic lines we\u0027ve got about men and I have to go but we\u0027d be interested in hearing could I ask for hum of people who think that standardization in this space is required can we clarify the question yes standardization in this space required required is a strange way of phrasing this little wait a second if you don\u0027t get to change the question the chairs ask the question would it be beneficial we standardization be desirable of beneficial I think right so those who think that standardization in this space is beneficial or desirable can you please hum now and those who do not think it\u0027s desirable or needed please hum now okay we are at 25 seconds left to go in our time is I\u0027m doing it so let me bring up an important point right so nobody talked about I think analyzing what\u0027s already out there in the market there are a lot of proprietary solutions to do these things they may cover a lot of IPR but they may also set a good amount of references of you know what we could achieve and you know showing what we want to achieve compared to to that stuff so it\u0027s ugly work to try to do that analysis but I think it would be very helpful thank you and that\u0027s actually it\u0027s actually where we hand the mic to the ad so on this last frame who\u0027s actually willing to do active work of looking at what\u0027s doing and working on the scoping and we have some hands okay we have some 15 hands that\u0027s good great so my conclusions here is that the scoping etcetera in small discussion we have the loops but loops mailing lists to do things so please if you\u0027re not already subscribed go there and let\u0027s have some discussions about scope etc and what\u0027s what\u0027s available or not and let\u0027s be done okay thank you everyone see you on the mailing list "
  }
]