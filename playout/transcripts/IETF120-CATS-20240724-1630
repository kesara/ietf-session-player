[
  {
    "startTime": "00:00:01",
    "text": "I recommend others to make a test in case in case. Hi, Chess, this is Kohan. Can you hear me? Yes we're going to hear you All right. Thank you Right, it's time So welcome to Katz I'm adrian farrel, Pongliu, my co-chair is remote and Jim our AD, is also unable to be here And, well, if you look at the mic camera the remote folks you'll see that either breakfast is really exciting or lots of other people weren't able to be here either. All right right while out and about earlier in the week I discovered that Vancouver's the place for cats so obviously we will do good work and or drink coffee It's an IETF meeting. You're halfway through the week. You really should know this. Remember that you need to participate well. That means following our IPR policies, that means behaving nicely and being respectful. If you don't understand what this slide's about please take some time to read it offline and check out on those BCPs"
  },
  {
    "startTime": "00:02:04",
    "text": "In particular, try to act like a mature adult and just be professional Trivia do the METECO thing If you're in the room, please make sure that you're signed in to Meetecho so that we capture your presence and so that you can participate and get in the queue when you want to speak Chong is going to help with the minutes He's remote, so it's a bit of a challenge and you may have to go back to the recording to fill it all in. So please help as you go along, in particular if you make comments at the moment make sure that they've been recorded properly Yeah, when you're in Meetecho, obviously turn your audio and video off if you're in the room and if you're remote, turn it off unless it's your turn to speak Join the queue. Don't just go and stand at a microphone Um, Well, sorry do you ask me? Oh, yeah, that's good Okay So this is for our database and milestones We have adopted the use case and framework documents document"
  },
  {
    "startTime": "00:04:01",
    "text": "and we are going to refine them of course all drafts are welcome, but please to remember to post them in the Datatracker and discuss them on the list So for the solution drafts, in other wing groups, our protocol work is fine if it has use case at the moment motivation. But in case, as a motivation is premature And note that we have one IPR, this disclosure and if you have any comments please send it to the main list And maybe next So here's our agenda We have four presentations about the use case and the trials on CDN cloud rendering V2X, and also for the use case about that net and we will have one presentation about the framework updates, and two about the compute modeling and metrics which is the most important work currently and next please please And then we will have for the mid-hole networks presentation and for the last two will have for the Midhall Networks presentation. And for the last four presentations, please remember to keep the time. We just flash it and to note people to read your draft So any comments on the agenda? i just want to note that it's uh it's a full packed agenda and I'm going to try to be brutally strict on time"
  },
  {
    "startTime": "00:06:01",
    "text": "Okay, maybe let's talk our agenda. First one is the use case Yeah, so I believe Jim would like just a quick word while I sort out the slides. Yeah, so thanks, Adrian. I just wanted to let the working group know that if you don't already know, Adrian is planning to ride off into the sunset in Dublin and do some fishing I believe, so I have taken the decision to add a third co-chair as an entrance step to replace Adrian in Dublin that will be med boot Buchadere. I will send an email to the list but I wanted to let everybody know And I also wanted to take this opportunity to thank Adrian for what he's done for this working group It's been a really excellent job. So thank you, Adrian And that's all I had Okay, thank you for Adrian So Kehan, I have your slides and I'm trying to remember how Don, you're in the queue, has you got something to say or have you just been clicking all the buttons? That's all right Okay I try, can I go ahead? You can go ahead Okay, everyone. Yep So the first presentation about the working group document, the CATS problem statement use cases and requirements So this is the third version of the update. So next step please So the primary updates from"
  },
  {
    "startTime": "00:08:00",
    "text": "revision zero two to zero three some technology update on competing service because there are some discussions in the mailing list before And also the most important thing, in this revision is that we have added some complementary use cases for CDN, for cloud rendering, and also internet vehicles, and just for some informational sharing. So this part is complemental and temporal. It's just for facilitate the discussion on the cast matrix and how to use this matrix for CAS deployment And also a notification that just like AD set, GM set said, the Matt volunteered to be removed from the author's list due to a number limit limitations, so we thank a lot for his consistent contract And next slide, please please So just a quick inform on the terminology change So we have addressed some colleagues from the list because there are some questions originally from the meeting in Brisbane about the surveys in SFC and also was computing service. So we have made some discussion in the list. We have the service in SFC and also was computing service. So we have made some discussion in the list. Here are some summarization update on the computer service. So we have basically changed the basic definition and has also provided some complete information because we think there are some differences in similarities between service and computing service and service is packet-based packet-based. Well, computing service is transaction-based application content is exposed"
  },
  {
    "startTime": "00:10:01",
    "text": "within a computing service, and also the similarities is that both service and computing service can be on path or on endpoint, depending on the service logic or computing service logic that are defined by the provider. So these are definition is agreed on by the list and author of the co-authors. So if it's is agreed on by the list and author of the co-authors. So if there is consensus, I suggest that the definition can be adopted and updated in the other working group framework document And next slide, please So here are some complement use cases we have summarized and we have been doing and making some implementation and deploy in China, China Mobiles Network, CMNet and also China Unicom network. So I will just present on the first two use case, and then CATS for CDN especially for 4K video delivery. It is being deployed in two provinces in China now and also cast for cloud rendering in one province in Georgia, China And the third use case will be presented by China Unicom later on Internet of Vehicles. Next slide, please please So here are the cat-trane for CDN and Cloud and Rendery. Next time, please Here is the open overview of CASS deployment in 5 five provinces. We have around five provinces for different use cases and TASBAT in China and China Mobile network. For CDN 4K videos, we have tested about two approaches. The distributed cats"
  },
  {
    "startTime": "00:12:01",
    "text": "approach has been deployed in 10 cities in Henan and the centralized approach is for CDN a 4K video delivery is deployed in Jiangsu and cloud render is being implemented in hybrid approach It's deployed in four cities in Georgia and also we have done some entire cloud rendering is being implemented in a hybrid approach. It's deployed in four cities in Georgia, and also we have done some intelligent detection. It's primarily using some like GPUs at the edge to do some object detection and video processing And so this demonstration has been also been down in two different approach and they are done in two separate provinces, Gondon and Hebei so in each city we have deployed like a cast ingress, and egress routers in different cities with the network network link all set to like n times 10 gigabytes Next slide, please so here is the first use case, the cat for 4KVD delivery So we have analyzed carefully about the service. So for CDN, we have already know that it's very mature and it has very widely deployed in every country And but you know for 4 key videos with that with that it's a little different because 4K videos and even 8K videos they are bandwidth-sensitive. And in CDN, mode, its service has a very interesting working mode that the client side, it will be fashion data chunk every 10 seconds and then store locally and repeat. So we find that this might, this"
  },
  {
    "startTime": "00:14:01",
    "text": "service mode might impact the how cats can behave. And there are already some service level requirements in Falki Video delivery, like people need smooth experience they want no lag, no mosaic, no waiting when they drag the scroll bar. So we map this service level requirements to network level and computer level requirements that means that we need fast connection of first packet and we need congestion avoidance and we don't want to exceed the upper level of network link bandwidth and server IOS bandwidth. And also we need fast recovery from congestion and in this case, just as I mentioned, the clients fetch data chunk every 10 seconds from you know, they can be fetched data chunk distributedly So in this case, instance affinity might not be needed. We have set some experiment benchmarking, like the app average size of data chunk and fulking videos, is about 25 mega have set some experiment benchmarking, like the average size of data chunk and fulking videos, is about 25, you know, MPPS to 30 MbPS. And we said that in the experiment, we said 300 clients per video requests simultaneously and the peak value about these traffic is run 705 giga GPS to 9 GGBPS. And we set the B peak value about these traffic is around 75 gigps to 9 GGBPS. And we set the BGP update about the matrix the time duration is about every 15 seconds, and the every 15 seconds is quite similar, quite close to the time duration about of the client side fetching the data chunk So I think they can match each other. So in these case, the primary matrix we have used"
  },
  {
    "startTime": "00:16:01",
    "text": "is that on the computing side, the average server load, they can be the represented by CPU utilization and in percentage, and also the average utilization of IO bandwidth of each side also in percentage And also in network site, the primary matrix represented by link utilization also in percentage, and pack loss rate. So in these cases, the delay is not the most important matrix because at the client side, the video or data chunk can be cached, but the bandwidth is most important matrix. Next side, please please So here with the overview and the overall data deployment of these testbed in CMNET in Hearnan, China it covers 10 cities. We have deployed the client side and two ingress node in cheng zhou, and also the egress node and the edge side in each of the other night cities. Next slide please please For the same application, we have the centralized deployment and Jiangsu. In Jiangsu, we have deployed in three cities, in Wushi, we have deployed the client side, also CATS ingress, and the controllers, and also some source station and management nodes and the egress node and the service site are deployed in Xu Zhong and Suu, respectively Next slide, please Though here are some test cases set for 4-key video delivery"
  },
  {
    "startTime": "00:18:01",
    "text": "and some preliminary results So the test cases is basically based on two major metrics. The first one is CATS based on server load So the test procedures we set the three major steps. The first one, and firstly, we set 200 clients, fetch data chunks, and get connected And then after that, we choose one site to improve as set 200 clients, fetch data chunks, and get connected, and then after that, we choose one site to improve, to increase its CPU utilization to make it like this side to work You know, when your CPU utilization is very high, may, you know, send a alert and need to distribute the survey to other sites. And then we newly add 20 clients to see the result The results shows that the different of the city utilization rate between different sides is under 5%. It means that the service of each client is well guaranteed And the second test case, the CASP based on server IO bandwidth, utilization. And firstly, we set 200 clients by data chunks and gather connected. And then we newly add a we set 200 clients, five data chunks, and get connected. And then we newly add 20 clients and we repeat the second procedure for five times to, you know, we can to see that the client network traffic become increased in, you know, their are constantly increasing want to see the result I ensure that the difference of the number of session connections between sites is under 5% It means that the load balancing is the result of the load balancing has been well achieved Next slide please So another application we have down is"
  },
  {
    "startTime": "00:20:01",
    "text": "cat for MiGu Cloud Rendering Here we want to first show that the Mi'u is digital content sub- subsidiary of China Mobile. So it provides some apps applications like cloud rendering and other digital applications in, you know, they do a lot of applications so we choose cloud rendering offered by Miwu as a primary application for cast deployment, so these applications rendering jobs will be down distributedly in real-time So for this case, the service level requirements, it will need fast rendering typically the end-to-end delay is within 100 milliseconds, and they need batch processing. So mapping to network level and computing level requirements, the first one is that the cloud rendering need GPU and they need to consider both transmission delays instance processing delay, and client side delay. And IO bandwidth also need to be considered when packing high-resolution videos, when we have done some rendering. And also, in this case, the instance affinity is required Primary matrix in this case, for computing site the primary one and the most important one is processing delay The delay are complex, they include encoding delay, encapsulation of the time one and the most important one is processing delay. The delay are complex, they include encoding delay, encapsulation of the packet delay, and interframe delay They are measured in milliseconds. And second one is GPU rendering capabilities. The capabilities in this case, we measure in frame per second That means we don't want to, you know, one is GPU rendering capabilities. The capabilities, in this case, we measure in frame per second. That means we don't want to grab the ability of GPUs in very raw matrix"
  },
  {
    "startTime": "00:22:01",
    "text": "but we want to abstract them in frame per second, the ability they can generate. And the third, metric on the computing side, the average is utilization of IO bandwidth of each side is shown in percentage On Nectual side, unpack loss rate and transmission delay are the two important metrics And also in this case that the survey site there are some other matrix that may be needed to grab It's the amount of service calls which may impact the batch processing in this case So we may use this three different levels of metrics for decision making of the path selection And the next slide, please So here is the basic overall of the deployment. So it has been deployed in four cities in Georgia The ingress node is deployed in Hongzhou and also the command controller and also the MiGu Cloud Platform. So each and the other three cities with ingrat node and also the service site. In each service site, there is a rendering instance and also some management instance The computing matrix at each site that means the rendering capability of rendering instance, will be first notified to the management instance, and each management instance will tell the MIGO cloud plan capability of rendering instance will be first notified to the management instance, and each management instance will tell the MIGO cloud platform and upload it to an Amigo platform platform management instance will tell the MIGO cloud platform and upload it to an Amigo platform will open an API for each other network controller for passing the computing-related matrix to the network domain, and then the controller"
  },
  {
    "startTime": "00:24:01",
    "text": "will download all of these information to the ingress node for decision making It's a hybrid approach Next slide, please So here is matthew quick summary of the two years ago cases that are being implemented You're well over time now. So what I said suggest is the next step are have a look at this more and progress it and discuss on the list and then we just need to move on to the next presentation but sure so you sorry sorry agent yeah sure. And welcome discussion in the list. Thank you Okay, Xinxin Hello. Hi go ahead. Okay, uh, hello everyone. I'm Xinx from China Unicom and my topic is the use case and solutions for the high-speed Internet Internet of V-H vehicles. And the next please Go Today I would like to introduce the new product and the Apollo in the autonomous driving in China. It is a second self-driving taxi service now available in male Chinese cities, including Beijing, Guangzhou, and Shanghai. Through a mobile app, users can book rides in driverless car that navigates city roads at a non-manence at normalizing, regulating traffic stimulus, and managing compact scenarios"
  },
  {
    "startTime": "00:26:01",
    "text": "Corrusioning these vehicles feature remote operations capabilities, enabling operated to take control in emergency ensure passengers' safety for example consider a case where a vehicle in contours unexpected of there of stakeholders like charging or pets on the road. Remote operators can immediately take action, snowing or stopping the vehicles until the situation is safe This function requires reliable network connected with lower latency, higher bandwidth, and strong stable duty for real tank model transmissions The next part is the network there real tank on the transmissions. Next is the network diagram of remote driving is showing in this finger. The server requires different vehicle accesses the base station through wireless signaling interstellar UPF for traffic, passing, and stability Then it is forwarding to the cloud for service processing and goes to the remote console. The remote console operation according to the received real-time schedule, of the vehicle and return these control instructions to the vehicle In this process, there are two issues need to be considered considerant. First, IP packets are parristen after reaching UPF, therefore the starting point of traffic stereo is at UPF But we are not changed with the vehicle movement in this way when the vehicle is driving"
  },
  {
    "startTime": "00:28:01",
    "text": "under the same UPF, the route is parts will not be changed and an optimal service site cannot be found. Second, a vehicle carries a varying observation of service. In addition to remote driving, there are other services like audio and radio. The requirement of these services for computing and the network are different so maybe the smart driving service should be giving private Next please So there are two considerations Yes. First, the location of the traffic exhibiting can be changed the closer to the vehicle In this way, as the vehicle moves the starting point of the traffic stereo also moves. So the route switching can be achieved as the vehicle moves. In addition, it is necessary to design a solution that can meet multiple types of services Next, please So we provide a solution for the international vehicles. First, a device behind the base station is added which suppose the traffic splitting and distributed the routing decision. This device needs to calculate the past based on real-term computing status and network studies This needs to use some protocol extension to advise the computing status In addition, in order to meet the different requirements of various servers, their centralized routine decision should be provided at the same time Also, next please This is the hybrid"
  },
  {
    "startTime": "00:30:01",
    "text": "solution we proposed annual be provided at the same time. So next please. This is the high-high broadcast solution we proposed earlier. And the have analysis and verified the hybrid solution for many aspects. Next place First, we constructors simulation test in the lab Yes, this is a comparative analysis of the computing advancement method The black line is the distributed method, which is realized through the protocol extension between devices And the red line is the centralized method, which is realized through the protocol extension between the device and the controller We can see that as the network scales expands, the protocol extension between the device and the controller. We can see that as their network scales is bent, the processing, the processes pressure of a device in the distributed method is greater. Because the device needs to establish the connection with each note and the centralized method is very needs to establish the connection with each node and the centralized method is better because the device only needs to establish a connection with the controller So next In addition, the analysis of the routine decision position was performed The red line is the scope obtained by the making routine decision in the centralized controller and the black line is the distributed routine decision at the increased case forward We can see that the CATS servers quality scores of these two methods have their own characteristic uses The distributed method basically around 19 points and while the score"
  },
  {
    "startTime": "00:32:01",
    "text": "of the centralized diversed on stable. When the network status, is really relatively stable centralized model can provide higher quality routine decision based on the global view When the network changed the grid, all services are highly sensitive to the network quality. Distribute model changes provide a higher switching and efficiency So next please In addition to simulation test next chair please Yeah in addition to simulation test in the lab, we also constructed in the real scenarios for the verification on the current network in Hebei, China And this finger is a network downward of the solution for the Internet of vehicles And these pictures are taken during the remote driving test in the Xionghehe Hebei Next please The vehicles are driving in Xiong Park and the remote control console are respective in the Zhongcheng and Ani, through our solution traffic scheduling, can be carried out well so that vehicles can access a better remote company so where we have next place So we have updated the use case graph with this vacation work and some content in the hybrid draft has also been updated and any comments and suggesting are welcome. I thank you"
  },
  {
    "startTime": "00:34:01",
    "text": "Thank you and well done on timing We've got a question from Daniel Yeah, Daniel ZTE It's very good task in the use cases, and I am just a clarification questions I'm wondering if in your test, the cats, ingress altar will be resided between the radio access and the UPF and the worst will be, would determine the GDP product protocol Yes, yes, we actually the device to do something Thank you Yeah, thank you. Excellent, thank you So next up is Paul Hello This one. Okay. Yeah is Jean-Purgeon Jung. Today, I will shortly introduce the use cases for computing aware, intelligent transportation systems Motivation of this draft is I try to improve our current CATS problem statement use cases, requirement draft especially the ITS intelligent transportation system case, they have a nice sum point, but I believe with my previous two works can enhance use cases for IT So two cases is context-aware navigation protocol, and the H-assisted cluster-based MAC protocol, even though"
  },
  {
    "startTime": "00:36:01",
    "text": "we approve concept using specific protocol but this protocol can be used to design our CATs though we approve concept using specific protocols, but this protocol can be used to design our catch for ITS use cases So as you can see nowadays, software aware of the because STV is very popular. You can see nowadays Autosa, they are providing other advanced some mode, providing high computing services for you can see assist advanced driver assistance system ADAS. You can see the driver. So we can overcome non non-line-of-sight, some obstacles. We can exchange a message through a CAT's IT use cases. We can avoid accident So you can see OTHSA, they providing the, you know, operate the system for ADAS or other you know the autonomous speaker system Also, European project Eclipse SDV-day are providing some the cloud-native services for st.b application development So we can see this figure shows the vehicle netto architecture, so the big vehicles can communicate with each other, we to avoid they can get some health from V2i access at the suburb so our catch, you know, in these cases we can want the service in instance to get some help. But my point is some safety driving in autonomous driver or 80s service incidents to get some help. But my point is some safety driving in autonomous driver or ADAS scenario. As you can see, context aware navigation protocol case, this figure you can see, the STB1 hit some obstacle The following vehicles using a line of camera, they detected this accident situation and they disseminate this information"
  },
  {
    "startTime": "00:38:01",
    "text": "to following vehicle. They can change the lane over adjust the speed, and then they can avoid accident or minimize the impact of the time So the catch case we can see in order to these kinds of service, we need to get some help because the vehicle is moving in the highway, they report their mobility speed or some direction or driving the behavior to edge side. So etchi, you know, cloud has some edge or central but our catch case more focused on the edge server right? So they calculate and behavior, they can construct the cluster and also they can adjust some the like this kind of extant scenario they prepare for that kind of some avoidance of accident over the powder, some damage. So in order to that so the vehicle is interactive with the vehicle at the side and then sometimes happen and then clusters especially cluster header appointed by an edge and then they can avoid accident. Second, in order to these kinds of context-aware navigation case, we need to provide some timely or so, you know, reliable communication between the vehicles So in order to that, we proposed the MAC protocol at assisted cluster-based MAC protocol. So basic idea is the B-Curs reported their mobility information to edge server, etch server like the vehicle law software defined, you know, the controller. So they can make cluster like the previous"
  },
  {
    "startTime": "00:40:01",
    "text": "the CMP protocol, and then they can allocate the channel and time slot according to their situation So the basic idea you can see, Beaker has some accident happen, they can communicate using previous algorithm. So in order to do that, we need to allocate the channel or so time slot So this one is so my point is our current IT the user case is very nice sketch, but we need to put this kind of the requirement in problem statement also use case case we can add this two cases so next step is I try to improve this text in terms of you know the requirement of problem. So even though I have the, yeah, two specific paper and the reproof concepts, and I believe we can enhance our current problem statement, use case draft okay that's all thank you any question comments Thanks Paul I'm sort of thinking about this use case compared to the other extreme, which was the CDN use case that Kihan presented and it seems to me that the record requirements and so the metrics are very different Do you see any easy way? that we can pull those? requirements, or are we just saying different use cases have different requirements? Right, yeah. So because this is a kind of autonomous driving safety issue, so the time communication, so in that case, edge server can provide the scheduling for chat and time slot, that also"
  },
  {
    "startTime": "00:42:01",
    "text": "important thing also another even though we have these kinds of real-time communication, but also the context aware navigation service case, Edge can also construct a cluster. In the past, the BQAdown network, case, they are using the decentralized way the forming for cluster take time also vehicle moving along the lamp side or intersection side, so we need to help the etche. So I believe, you know, catch it structure is very important for autonomous or ADAS scenarios Good, please. Okay any others? Yes, hi, this is Dirk Cross and Huawei. I'm one of the remaining courts listed on the U.S case trial. Going back to Adrian's Carmen, I would argue about adding use cases to the document that already has quite a number of use cases, does make sense particularly when it has an angle on the additional requirements he would pose. So I would really ask you to focus on the additional set of requirements you may have, but the other use cases have not brought to the discussion because otherwise we're just adding interesting text to the document but with no real added value Thank you okay president thank you okay so current our use cases from a statement case, I cannot see the problem statement and also some specific use case for these kinds ADAS, even though some paper is a horizon but I read it through, but still not, yeah, we can't use that reference. Also, we can add into references and"
  },
  {
    "startTime": "00:44:01",
    "text": "we can enough that is my purpose Yeah. Okay. Sorry, sorry maybe as an addition yeah okay so sorry maybe as a as a as an addition I generally I didn't I didn't mean to suggest that I'm not supposed to of adding this I do I do believe your use case actually does add additional requirements. I'm just asking you because you are the main proponent and probably would be the best person to focus on really teasing those requirements out. That's all I'm suggesting. I'm quite supportive of these use case. I like it. But please do focus on and teasing out the issue additional requirements, because otherwise we're just adding use case text That's that's all I'm in. I'm generally supportive, but just keep that in mind right so that that sounds to me like your homework Paul is to try to suggest the text that would go in as the merge because obviously they're not just going to take the whole of your draft and cut and paste it. Right, yeah. So if you can then make that suggestion to the authors of the use case document, they can work on merging Okay, how to you merge, right? Yeah, okay, I see. Thank you Hello, can you hear me? This is a test Yeah, go ahead, tell Hello, everyone. I'm a photo from China Academy of Information and Communications Technology. I'm very glad to report this draft on behalf of the writing team We want to study the application of Canada technology in the industrial internet Next, please First, let's talk about the connotation of industrial internet. Basically, it's a combination of information technology and information"
  },
  {
    "startTime": "00:46:01",
    "text": "manufacturing The industrial internet is a new infrastructure application mode and industrial ecology with deep integration among the new information technology communication technology, and the industrial economy As showing in the figure, industrial terminal edge computing, and cloud services are interconnected through the factory network, forming a deployment structure of two levels and a three domes as algorithms because more complex, the connection between industrial terminals and various computing power facilities will become closer. This further leads to the increase the importance of collaboration between networks and computing Procession manufacturing is particularly important in industrial settings Industrial production tasks are time-sensitive which put forward high requirements on networks and applications, and the needs to meet the deterministic requirements in terms of delay Jeter reliability, and so on Next, please Based on the above understanding in this page, I introduced the problem statement of industrial cats Firstly, we need to introduce industrial problems surveys Application services are demand dynamically adapted to industrial scenarios, tasks and resources, the computation that devices participate in evolve"
  },
  {
    "startTime": "00:48:01",
    "text": "from simple control logic to compute big data decision making In the application layer of industrial internet, a deterministic service is the combination of network communication process and the calculation process It refers to a closed loop from the by one or more application communication links and control links. Therefore, industrial manufacturing requires high real-time performance. Secondly, industrial production service needs to be time-sensitive. It's necessary to realize the deterministic management of computing power and network resources based on cats necessary to realize the deterministic management of computing power and network resources based on CASS. The concurrent processing of multiple services must ensure the strict requirement of network performances. Thirdly, towards services must ensure the strict requirements of network performances. Thirdly, to address the above needs, determines the tests is adjusting network forwarding configurations according to the computing requirements The traditional network can only control the wrong run-trip transmission process if the edge side blocks the task due to multiple services, the processing delay of the computing processes will increase. Determin needs to case manages both the communication process and the calculation process accurately ensuring the indicators of the entire virtual inspection process from the perspective of an industrial activity. Next, please please Now,"
  },
  {
    "startTime": "00:50:00",
    "text": "please please Hello? Yeah, we're updating here Are you not seeing the updates on your Oh, okay Next, I will introduce some youth cases. First is the computer of air industrial robots. The automatic manufacturer of software materials has always been a difficult problem in industrial digitalization. For the sake of unpredictable deformation of the materials, it brings difficult to the traditional equipment unless it can recognize real-time states of the default for products. Furthermore, product lines needs to accurately perform operations and correct negative effects of the deformation. The excuse of complex assembly tasks is in intelligent manufacturing requires the cooperation of multiple robots. The total time is mainly limited by the recognition accuracy and recognition delay. If the computing power results are enabled through the edge muting and the certainty of net delay, if the computing power resources are enabled through the edge muting and the certainty of network edge communication cells self-learning, and image, recognition is ensured through application deterministic control the processing complexity folding speed, and accuracy of flexible objects"
  },
  {
    "startTime": "00:52:01",
    "text": "can be further improved From the perspective of production process, network and computing jointly affect the efficiency of management process. Next, please Next is computing aware virtual cloud termination use case. It means shows that cloud services are control functions migrated from physical devices to industrial cloud, data center or edge dramatically reducing production line costs and it also will need to control network resources and computing resources to save the time next please Next, use case is about multi-application collaboration. It means the company of machine learning, big data, and other technologies with the production line It's mainly direct deployment and simple interconnection and the role of advanced algorithms in research optimization education in the life circle of industrial products is still not fully reflected reflected Deterministic cats can solve these problems through multi-application global scheduling in order to ensure the certainty of the entire production business. Next please Based on the understanding of the wall, application scenarios, we have summarized"
  },
  {
    "startTime": "00:54:00",
    "text": "the requirements of industrial tasks We have adopted the architecture within CAS group. In this draft, we present six kinds of requirements requirements First is the requirements for determinists management of computer network resources surveys And then next is for networks, the second is for internal factors computing. The fourth is about external factory computing Then we need global management refrains factory computing. The fourth is about external factory computing. Then we need global management, refer to manage various devices and their resources and achieve collaboration interfaces between devices Next up, please please Our next plan consists of three parts, first part is to enrich and improve the use case Second part is to supplement the requirements and the third part is to its explore caste technology in the industrial internet Next, please This is my first report in this work group and we hope to collaborate with more interested researchers This is all the content of my report Thank you. I'm a little nervous Sorry about that. No, thank you You were fine. Let's take a very quick question from Carlos, please. Yeah, Carlos, yes Bernal, yes, a comment. I don't know if you're aware that is a industrial requirements draft in the then networking group, that it may be good that you take a look at that and maybe contribute to that because there are synergies, obvious synergies between this work and and your work so so Carlos I found that hard to pass, so I'm suspecting that Tower had it"
  },
  {
    "startTime": "00:56:01",
    "text": "had really hard trouble. Try loud and very slow. Okay I'm just saying that there is a draft in the dead net working Group on industrial requirements working group draft. I'm one of the authors and I a draft in the Deadnet Working Group on industrial requirements, working group draft. I'm one of the authors, and I'm just suggesting that he take a look at this and also contribute to that because there are overlaps between that draft and this one Perfect. Thank you Thank you for your question I need to start this for a while, and I will reply you with an email Very good, thank you. So we move on to Mr. Lee Okay, it's Mike 10 Can you hear me? Yep it's good. Yeah, thank you. So, Johnny from Huawei next place So the presentation is quite simple and clear, so it mainly can include two parts. The first one is about a change since last IETF meeting and then we can discuss the next step and the plan of this draft. Yes, please So the update summary from the revision, zero to zero to zero two well, you know, we mainly address the comments from the working group adoption call, right? So we address the comment regarding SFC from Jim, and then we also address the comment from Zhong regarding SFC from jim and then we also address the comment from uh uh zhong's comment i think that is uh you know editorial comment. And then we also address the comment from Joe's, some editorial modifications and some you know, technical comments. Yep so that is quite simple yep next"
  },
  {
    "startTime": "00:58:01",
    "text": "please We still have a lot of, you know, comments or issues to be addressed. I would say that that is great because I see Zhongpeng just create more than 10 issues just before this meeting, which is very good because that is the right way that we can record all the comments we receive in the working group adoption call and anytime, right? so personally i will recommend you to share your comments in the mailing list or to the you know give hub repository directly Anyway, just know it down, right? And we can adjust them one by one So to me, I would say by the end of this year, we will have a stable revision of this draft, I think think So, yes, next please So the next step will be, you know, we will, the others will work together to address the comment one by one. So, you know, first of all, the other record comments or issues in the GitHub repository And if you talk about it specifically, that would be like adding some text to, you know, following some sections like section 3.3 4.1 for 4.5, and section 5, which is about the security consideration, right? So, yes. And according to the milestone in the charter, we will have to some this draft to IESG for publication in next year, right? So let's walk together and try to achieve that as a soon as possible. Thank you yeah thanks trong that's that"
  },
  {
    "startTime": "01:00:01",
    "text": "reporting From a chairing point of view, I'd like to encourage you to push out new revisions more often. Don't just use GitHub to track and olave issues, but when you've got a bunch of resolved issues, put out a new revision so that people have got something clean to read and work with we do yeah okay yeah otherwise your timing looks good I would like to encourage the people who are talking about the use cases and in particular putting prototypes together and experimenting I'd like to encourage them to come back to the framework and check that what they're doing matches the framework or maybe the other way around the framework matches what they're doing so that we don't get late surprises as we try to last call this in the future okay Gotcha, yep. Okay, there's no nobody lined up in the queue So thank you. You've gained us a little time Thank you too, yep. Bye-bye All right, this takes us on towards the metrics part of the meeting which is the bit that I think is probably most important Hello everyone this is please I will present the draft update on behalf of my question Sabine Jordi and Roland. So a bit of recap about the motivation of the draft was basically with the part of the point that in"
  },
  {
    "startTime": "01:02:01",
    "text": "IETF, network information is quite well documented but it was not the case for the for the computing formation So with that in mind, we just started to work on how to, yeah, try to identify computer-related metrics that could help us to cover new situations, new scenarios of deployment of services and operation of services There was some ad hoc work in ATF, for sure the working cuts also some some initial working out and also in Opso, apologies for the typo So for instance, the MIP about the virtual machines and hypervisors and these kind of things And for sure there are other documentation in other fora external to IETF, like Lignus Foundation, etc H.C.N.F., and so on so far so different inputs and well the point here was to try to identify what could be the metrics that we could apply to a scenario related for IT far. So different inputs, and the point here was to try to identify what could be the metrics that we could apply to a scenario related for ATF. The problem space that we initiated to cover was the service deployment. So consider metrics for facilitating the service deployment in a way that we can combine compute metrics together with network metrics, and also the service selection that would be basically the focus of Katz. As a kind of a spoiler for the next version we also try to cover the service assurance as part of the all the service life cycle and as said we will include this in the in the next version All right So going to the to the updates, well, the draw was presented already in ITI-118 and ITI-119 Now we are in version 06. We have added in this new version a section of focusing on Kubernetes We comment later on with more detail on this And we focus on Kubernetes because it's in this cloud native approach, way of delivery services and so is probably the leading effort from the cloud side so we are starting to look at it"
  },
  {
    "startTime": "01:04:01",
    "text": "with care in order to understand what could be the metrics that we can leverage from Kubernetes we also move to a specific section towards the annex and so the references to a specific solutions for exposure. So we will comment it in not in detail but we have a reference in the previous versions to alto as a mechanism of exposure but could be one of the possible mechanisms. So it's not the emphasis of the draft to look at the exposure or the ways of exposure information. So this is why we somehow move to that specific section And then we also cover some fixing, so the editorial fix or the ways of exposing information, so this is why we somehow move to that specific section. And then we also cover some fixing, so the editorial fixings that are always a matter to do. So well, give me back because this is the previous deck. I will just comment on the Kubernetes section, so what we detail was a basically understanding what are the Kubernetes metrics what we can obtain from Kubernetes as today. Also, to comment or describe the kubernetes architecture, so how it could be integrated with the Katz, let's say, framework And also the metrics at the different levels both node and cluster so continuing with the update of the DRAB, new version will be submitting in this way, hopefully So the new version is now in the GitHub the GitHub. So it's just a matter of submitting In this new version in 07, we will it's now the new version is now in the in the githab so it's just a matter of submitting in this new version in zero seven we will consider the service assurance as i said before it's not in zero six but will be in zero seven and also we will provide some refinement on the metric dimensions to be considered and for sure new digital fixing because there are the typos and so on so far so next steps we would like to collect feedback from the working group So the feedback was already for the zero six version requested to the chairs and to the mailing list. For sure, we expect feedback today, also in line with the other presentations of metrics"
  },
  {
    "startTime": "01:06:01",
    "text": "so for sure there will be feedback to to incorporate to the draft and our idea is to prepare a new version for next IETF we are considering to go into details of metric, compute metrics from other solutions apart from Kubernetes and yeah, in system problems in the in the service insurance phase and also somehow provide context of the metrics that we are reporting with the other metrics that are reported in in other drafts so so somehow that we can have such kind of overall view or overarching view of the metrics that are in the different drafts as today. And this is all from my side now, thank you Thanks, Lewis. Joel raises a point in the chat which I think bears some attention and he's essentially saying that we need to be very careful if different cats applications require the cat's edges to know about a whole range of different metrics, different metrics for each application, because that's going to give us implementation and scaling challenge So I'm hoping that as we move forward with this and this next draft on the agenda, we can start looping back into the requirements and consult what metrics we need for CAC as a generic set Okay, got it. Thank you Cool, thank you The queue is still empty, so we'll move on on back to Kihan especially if I can find the slides There we go And hi, Asian, can you hear me? Yep, it's all good. Okay"
  },
  {
    "startTime": "01:08:01",
    "text": "so, so this draft is about cast metric description and definition Sorry, this presentation, so it includes about two drops. The first one about computing modeling description, basically includes the consideration about the problem of defining computing related metrics and how we use it. The second one is the new proposed draft on the cast metric definition. So we have proposed initial framework for defining matrix and want to see if a comment from the working group. Next slide, please So basically, the update from the previous version on the computing modeling description draft, we mainly modify section 3 and 5. In section 3, we have rereading the problems. We have an 5, we have updated the consideration of how to use this matrix in Canada domain and how we have also like summarized some high level design principles for defining these CAST matrix Next slide please for the background that for anyone who are not deeply involved, the discussion before. So current status about cast metrics, so what we're facing now, the problems, two problems here is that one is the computing resource heterogeneous That means that there are a lot of computing resources We need to grab a matrix from and also there are problems that we are facing from service diversity That means service specific matrix are very hard to define So what we want to do now is to make decisions based on the choice of some default metrics"
  },
  {
    "startTime": "01:10:01",
    "text": "for cats, and we need to define them And we have got some consensus from previous discussion in the mailing list That is the computing matrix in Katz should be simple and the number of them should be few. So only matrix that are needed in raw selection should be notified to the network And we have got some candid matrix which I will talk about later. Next slide, please So we have also summarized some design principles about metric definition, and the first one is simplicity That means that the computing matrix in cats should be filled and simple, so as to avoid exposing two minds information of the service points. And second one is about scalability. That means that the computing matrix should be evolvable in the future for future extensions. And the interrupt interoperability is also very important especially for the you know, the vendor, this would be vendor independent and also OS independent And also stability is another aspect which we think is very important because the computing matrix should not incur too much over to design protocols We want them to be stabilized, and we don't want to be redesign protocols in the future And another aspect is about accuracy that the computing matrix should be effective for path selection for decision making. So if we you know, the raw matrix might be accurate but if we, they are very, complex, but if we abstract them to be very high level, and they might be not very accurate. So we need a treat off between this the the accuracy and the simplicity. Next slide, please"
  },
  {
    "startTime": "01:12:03",
    "text": "we have also, and there are some candidate matrix we have some you know, basic consensus on The first one is the predicted computing delay It means that the estimate of the duration process have some, you know, basic consensus on. The first one is the predicted computing delay. It means that the estimate of the duration of processing inside the computing service instance. And the second one in the server capability. You can see it as an abstraction of the capability For example, abstraction value. For example, one server may support 100 simultaneous sessions and another can support 10,000 simultaneous sessions. You can view it as a kind of capability. And also the third one is the status indication For example, like an indication, please stop sending new sessions instance A. So we see this, the third one as a control value to note notified to the cast domain. Next slide, please So we also update some considerations of how to use these metrics in custom So primarily in Katz, the core function, core function make decisions is in CPA the CASP path election model is located in the INC ingress node. So two kinds of raw policies may be applied in the ingress. The first one is backup mode so we have only one active route and others for just for backup. And the other one is low balancing mode, like we can share in several routes for tool for flow load balancing and they are active and the same time and each have a weight. So the most important thing in ingress, we need to update these policies based on the matrix So we have some we have proposed some initial mechanism for use"
  },
  {
    "startTime": "01:14:01",
    "text": "this matrix and to dispute this matrix in case domain and update policies in Ingress. The first one is a this matrix and to distribute this matrix in case domain and update policies in the ingress. The first one is to match the backup mode. We use the predict computing delay and it will trigger the backend mode on the ingress and lead to a potential minimum latency for client. And the second approach is for the load balancing mode. We will set a load balance on weight which can be a cardinal value has been discussed, proposed by Dirk in the Middle East. So it can be mapped to server capability and trigger the load balancing mode and the ingress for selecting appropriate routes for the metric distribution and sorry for you know to steer the traffic to appropriate service note. Next, I plead so based on these considerations, we have proposed a basic framework for defining this cache frame matrix. So here is a hierarchical framework. We have three levels of metric definition from level zero to level two So level level the role, we call it raw matrix So the matrix without any abstraction So what these metrics are generated, so you can grab what matrix, like, CPU frequency and networking bandwidth and storage, write, read and write speed and also and some delay so the raw matrix all have physical meanings and the second level is normalize the matrix in categories So in this level, we may have some appropriate abstraction on each category"
  },
  {
    "startTime": "01:16:01",
    "text": "We will get normalized values in each category, like in networking we have a normalized value, and also in computer storage, and delay In the normalized value, they might not have some physical, you know, detailed physical meaning but just some value And the top level is fully normalized matrix. So in this level, it's one-dimensional and highly abstracted. It might be unwitting sum and values, different values So you don't have to know how matrix are abstracted In this level, you just have a very simple value We can avoid complexity. Express So it is hierarchical view of the metric definition So next slide, please down some comparison of these three levels from different aspects like complexity, extensibility, stability and also accuracy. So all of these different aspects also mentioned in the design principles We can see that from a level two level zero to level two, they're complex are decreasing but their extensibility and stability are increasing While the accuracy from in level zero, they might be good, but when all the metrics are abstracted, the accuracy might be decreased. So we need to have a trade-off between different aspects And we have some, you know, intuitive we have some suggestions in the also in the definition draft like intuitively level to metrics are recommended because of its simplicity extensibility, and stability"
  },
  {
    "startTime": "01:18:01",
    "text": "for implementation. So, and we think that its accuracy can also be improved by design proper decision-making algorithms Next time, please so for next step and a quick summarization, so can we agree with making some matrix as the default ones for Katz? which means that all cast node must recognize them so that enabling the basic and default action. And also easy a proposed cast definition and classification method appropriate for this decision making. So if question one is accepted, can we agree on some matrix to be default matrix that have been discussed before that is predicted computing delay and also the load balance weight, and we will come forward discussions and comments from the list because this is very important work currently and also for you know facilitate the work for matrix distribution and also other works. Thank you Thank you, Kihan I have to say, from a chair point of view, I'm really, really pleased to see this work We were struggling, I think, a few months ago, and you've come in and saved us daniel huang a question. Yeah the categorization of the three levels service metrics is good And as far as the nevote, zero, there's actually just a set of networking metrics, such as latency in bandwidth with accordingly to algorithms so it will be preferable to use the same matrix as to the networking actions such as latency. So the algorithms"
  },
  {
    "startTime": "01:20:01",
    "text": "as well as the metrics could be reused in terms of the protocols, routing protocols Yeah, so the never three actually the raw metrics should be avoided when we're talking about the propagation of the existing routing protocols Thank you. Sure. Agreed yeah we we want to we're just a existing routing protocols. Thank you. Sure. Agree. We want to, we're just in this document, we will we will, we want to show on high level overview of all matrix, and then we can decide what matrix we want to define and choose which is best for a cast decision-making So there's a lot of chat in the chat window. Please read through that because I think there's important information Something which several of us caught on your slide four was to look at all of your shoulds and see whether they are really must because should kind of says, well, it'd be a good idea, but we could do something different and I think many of the cases, you just need to be a bit firmer and say, this is a must. Sure sure, I agree with you and agree with the chess. I think maybe for simplicity and also like interoperability, I think we can change it to be much and change the tone to be strong because this is really very important for, you know, for cats and also I think maybe for accuracy of the last one"
  },
  {
    "startTime": "01:22:01",
    "text": "I can maybe steal maintain shoot because up to now I'm not so quite sure if it be must So for the other like scalability and stability I'm not sure, but one of, you know, a solid state for more comments. This is my personal view right now. So, and I think I will look into the questions after the meeting and have some internal discussions with other co-authors and have put into the list. Thank you Yeah, thank you. Jim Yeah, just one comment as a speaking as an individual contributor rather than any hats. I find the number four to be a little bit problematic and you might want to think about that a little bit, because it's very subjective in terms of, you know, what do you classify as too much overhead in protocol? design? You know, to me, that's kind of a little bit of a meaningless statement because it's very difficult to quantify that so you might I don't have any great suggestion for you, but it's something that you might want to consider because if you make that a requirement, then just remember that any requirement is really there so that an implementer can actually implement the thing but if they don't understand the requirement then it becomes problematic Okay, thank you, Jim So I think it's great to be doing this work in separate drafts that can be a focus for discussion. As we go forward, I wonder whether we that can be a focus for discussion as we go forward I wonder whether we're going to end up putting metrics to discussion in the requirements and framework or whether"
  },
  {
    "startTime": "01:24:01",
    "text": "we want to keep it separate. And I've got no clear opinion on that, but I'd like everybody to be thinking about that as we move forward Cool, thank you We'll move on which is back to Lewis, I think Thank you Hello, this is Luis again I will present this the date of this draft on behalf of my co-author, Mark And the idea here is to analyze the applicability of cats to mythical networks So a kind of quick recap where we are talking about So we are departing from the scenario where the distributed radio access network follows this radio functional split. So it's a challenge radio access network follows this radio functional split. So it's such a way that we can take part of the processing of the functionality in the a node bits in a node B distributed along the network right so somehow taking the the radio unit, the distributed unit, and the centralized unit in separate deployments and distributed deployments at the end So what we are focused on is in the mid-haul interface so also call f1 interface in three terminology, and here is the point where we want to explore the applicability of cats So the Katz framework of applicability for MeatHoles, how it summarizing the figure that you can see on the right of your on your right so essentially considering the distributed unit being deployed on top of servers or computer facilities, and the same thing for the centralized unit. In the centralized unit, we can consider centralized unit for the control plane and for the user plane So essentially, what we are referring here as this distributed part will be the user plane even it's not"
  },
  {
    "startTime": "01:26:01",
    "text": "explicitly set in the figure, but with the C UP so here the point will be to along the service is running and according to the different metrics that we can observe to this UP. So here the point will be to, along the services running, and according to the different metrics that we can observe, to decide what would be the steering path between the DU, instance and the CUP instance. We could have different CUP instance the services running and according to the different metrics that we can observe to decide what would be the steering path between the DU instance and the CUUP instance. We could have different CUs deployed in different sites. So the essentially that would be the decision to decide what the steering path to the different CUP instances along the time this could be done from the this decision could be done as a kind of application running on the service and management orchestra of the Oran architecture, leveraging on the functional entities proposed by CATS, essentially the path selector and so We can consider to have monitoring age both in the network and in the computer side so the CNMAs and the CSMAs so following the same architecture of cuts And here, just to reflect the metrics that now by now, Oren is considering its CPU average utilization, memory, and energy usage for each of the cgupis instances in the draft we simplify the steering decision leveraging on the network framework from IETF, the RFC-9 9543. So this is what we are describing in, basically, in the draft So I think, okay addressing some of the comments received in the previous presentation in Brisbane, we incorporate comments provided by TNG, we provided this in the draft this protocol encapsulation view So as you can see on the top of the figure, we will have the connectivity view between the DU and the CU UP so traversing a number of network elements route basically. And that would be the scope of the proposal, so how we can solve that connectivity between these two instances"
  },
  {
    "startTime": "01:28:01",
    "text": "We added a protocol view, but discussing with TNG, we realized that it's not correct at all so we will correct in the forthcoming version. And the idea essentially the applicability of cats would be what you can see at the bottom of the slide So basically solving that connectivity, that traffic steering is simply here with a VPN and PLS NPL-based VPN, but could be wherever other kind of solutions. So this is just an example. So we have a incorporated this view, but yeah, we need to correct because it's not exact at all. Also, we have included in the draft some examples using the IETF never slide service so considering how to define the category paths leveraging on the network slide service or essentially considering a hub and spoke VPN solution as an example, where you can see the connectivity matrix let's say, between the DU on one hand and then the different instances of the CUP And then also in the bottom part, an example of how could be the enforcement of the participants steering, leveraging on the match criteria that in this case would be the IP prefix of the CUUP So, in summary, the decision of the path selector would be essentially what would be the match criteria to be applied so that we can leverage in one of the parts of the language slides for the specific CUP instance So next steps, we are progressing in parallel an effort of describing the culture specific CUUP instance. So next steps, we are progressing in parallel an effort of describing the as a mechanism in the Oran working group line specific Working group nine is the working group in ORAN dedicated to the transport network, to the X-hole segment We may be considered that a liaison statement could be useful for progressing the work so that we can work in parallel. So we are doing this informally, but maybe it could be interesting to have a formal binding of both works We would like as well to collect more feedback from the working group"
  },
  {
    "startTime": "01:30:01",
    "text": "We already had from tianji jiang the past, but we would like to have more working group to understand it this is interesting, useful and so And yeah, basically we expect to prepare a new version. We would like to keep working on the interplay between the Oren orchestration framework the SMO, and how it could interact with the CATs entities. Thank you selector, the CNMA, CSMA, and so on so far And maybe also could be interesting to consider if the adoption of the document could help on the task of considering Katz for Oren So that is the case what idea would be to go to next IETF and ask for adoption but yeah, for sure this is something matter of it cuts for Oren. So, if that is the case, what idea would be to go to next IETF and ask for adoption, but yeah, for sure this is something matter of the chairs to decide. Thank you Thank you. We put this where we did in the agenda because we felt that this is less of a use case and more of an applicability But please, nevertheless as you do this work, try to feed back into the requirements and the framework if there's something that doesn't sit right or feels odd Tenji odd. Uh, Kenji, uh, yes, uh, Kenji, same as they say, uh, Louis May a lot of discussions about the work here And then I think of the, all right because I have quite a few colleagues in O'run O-Run Alliance as the T-Sem members, I talked to them about the O-Rung, the current SPAC colleagues in the O-R-R-R-R-A alliance as the TSE members. I talked to them about the O-Rung, the current spec. The current spec, although it's using, so far it's using the static map mapping, but they told me it does not prevent that the O-Rung, the current spec. The current spec, although it's using, so far it's using the static mapping, but they told me, it does not prevent they're going to use the dynamic mapping between the DU and the CU. So this is a valid case for the case scenario The second thing is also are involved in the 6G discussion because in the 6G, there are some you know for 5G there's like disaggregated for core network. And then by the first 6G,"
  },
  {
    "startTime": "01:32:01",
    "text": "the similar things might be considered. Actually, it's being considered for the run side. So when we have the disaggregation on the rent, this one will also play into the picture so i think this is some of that case. Yeah, thank you So I've taken an action that the chairs will talk to the AD and work out what the best way to communicate with O-RAN is thank you Right. So the red of the meeting is, is like we did last time, much more of flash talks which you could see as, here's a quick brief on what my draft is, and please go and read it a little more So, Zon Peng Can you hear me? Yes good. Okay, thank you. Hello, I run everyone. I'm Zongpantu from China Mobile and this is a draft about aggregated metrics on the e-virus node and the corresponding routine mechanism In this draft, we do not talk about how to merge them metrics, but we assume that metric has been aggregated on the igres, and it will call some problem about a routine Next page, please and in this page, we will talk about the general procedure of kites In the first step, the client will send some packet with a destination address as a SID or called the service ID. It's a first step, the client will send some packet with a destination address as a SID, or called the service ID, it's any cost address and many places in the network"
  },
  {
    "startTime": "01:34:01",
    "text": "for example, the MEC1, MEC2, and MEC3 all support this service and the service point different service points. They all can fulfill the job and the invoice will do the load balance job and choose one of the service point for the client and next bit please And for the step two, we have two detailed steps two detailed steps and the first is that the email ingress will select a proper egress and turn out the packet to it And after receiving the packet, the egress will need to forward the packets for a proper service point. Next page, please And we have two options here. One, the first one is that we have only one load balance point It's to see the ingress. It will decide both the equal and the service point and the tunnel the packet to the egress with the proper end point X function It's a SvR V6 function and we have a draft for it is a case data plan segmented routine mechanism and we also have another option here. The Ingress can only decide the igres and the igres is responsible for selecting the service point, locally connected Next feed, please And for this option, we have two load balance points The ingress will do the first load balance job and the igres do another"
  },
  {
    "startTime": "01:36:01",
    "text": "round old load balance job It will select the service point locally connected. Next page, please please And if we use this option tool, we need to assume that the igres can aggregate the metrics from different surveys side. In case, we have three levels of computing metrics can be considered. The first is that we can report the metric from a service point. And the second level is that we can report the metric or graveted in the service site level And we only focus on the third point We measure the metric at the ground site level. And we only focus on the third point. We measure the metric at the graduality or igres node level. And this third one is for option two described in our drawing It is of course a more complicated, but the quantity that is a client reduce the metric information that I need to be announced in the network. Next page, please Our next step is one to call for comments and contributions That's all. Thank you Thank you. Good timing I see two things going on in this draft One is about the packet marking with service ID and how that's forwarded, and the other is about metrics and consolidation of metrics. So please have a look at the discussion that's just been going on in the chat window about metrics. And"
  },
  {
    "startTime": "01:38:01",
    "text": "also think about whether you can take some of your thoughts about metrics and move them into the draft we had earlier that we're discussing metrics Okay, thank you Okay moving on onwards Thank you hear me? Yes, go ahead. Yeah, this is Taiwan from New H3C This draft is about the source metric distribution based on BP. Next page, please Yeah, so background as a show, in these pictures, very centralized models are distributed models that transmission of search metric is crucial. Next page please Here is the list of current way to dispute those magic information. First, API interface method. The source metric can be transmitted using rest for GRPC and YAM protocol. This method is suitable for centralized models Second, service discovery and registration center method, such as LISPR. This approach lag models. Second, service discovery and registration center method, such as LISPR. This approach lacked material application and has a limited scope of use Certainly, routine protocol method we can return BP to carry the search metric by adding new BP attribute or new adjust family extension to support the transmission of service metric. This document will discuss how to return the BP to support"
  },
  {
    "startTime": "01:40:01",
    "text": "distribution service metric Next page, please I will expect why the new BP address family was chosen based on the following for us new BP address family was chosen based on the following aspect. Firstly, in terms of scalability CSID can early be any cluster addressed for original BP address family, and so's magic can early be expanded through BP pass. Second, in turn of isolation, the period update of social match will affect regular route update. When a regular update and the period update of search magic will affect regular route update. When a regular update and cast load are updated at the same time, and the cast route is in the middle of the regular route the converse of the regular route will be effective Certainly in terms of performance, period changed in service metric costs the most service magical to be different. Thus make it impossible to pack, multiple cast looters in one update message About the limitation of the original address family can be optimized by defining a new address family. Next page page the cycle of the new BP address family are as followed. First, it is Next page, the cycle of the new BP address family are as followed. First, it can optimize the impact on the existing looter propagation. Second, services ID are not limited to any caste IP address Certainly, it can improve the effect of sending periods service metric update First, it is supported on demand sending and could"
  },
  {
    "startTime": "01:42:01",
    "text": "control the propagation scope of service metric. The table in clear showed the difference between the new address family and orange original address family In summary, the new address family offered the the difference between the new address family and the original address family. In summary, the new address family offered better isolation, scalability and performance compared to the original family Next page In brief, the new address family is more extension in terms of NRI design Next page thing By using different type of routers, the new service address family could work flexible the dynamitic service metric route capability can be achieved Next page This use case shows how the new address family works Yeah, next page Thank you. Any questions, comments? are welcome. So we have Linda in the room just making her way to the microphone So it's Linda Dahmer from Future Way So you are aware in IDR, there's a working group draft on the metadata past attribute, right, which can carry the service metrics for a particular service Uh um, uh, um, p draft and then compare with that because there are lots of concerns"
  },
  {
    "startTime": "01:44:01",
    "text": "when you are adding service metrics for a particular service, a particular service ID and not only that you carry the information because the goal of carrying those information is really for the Ingress router to make part select right? So, um, um, IDR's past attribute is one way of doing it and I think it's better to compare with that and see the pros and cons. Thank you So Linda, maybe you could send a note to the mailing list with a pointer to that draft. Okay, I will do Thank you. Yes, thank you Thank you, chuanfa wang I've just got lost. There we are green challenges in canvies Okay, can you hear me? Yep, that's good. Okay, so Adrian Hello, everyone. This is jing wang from China Move-Bet I'm here on behalf of all authors to report the draft about green Challenge in Katz. Next slide, please Okay, compared with version 01, Zer1, a co-author from Huawei was added to the version 04 in addition we mainly modified the section 3 Next slide, please Okay before, uh, introduce the new challenges, let's review by considering green ink casp As we all know, reducing carbon footprint to net zero is one of mankind's grand challenges with continuous development and progress"
  },
  {
    "startTime": "01:46:01",
    "text": "of the internet, a large amount of computing resources is required to complete data processing, which would produce a lot of energy consumption Cass is about the process of selecting solaris incidence for directing traffickers of energy consumption. Cass is about the process of selecting surrogens for directing traffic to base on observed metrics for both computing and networking So greencast is worth exploring Next slide, please Okay, there are six green Chinese in cats The last two challenges are new additions The first is evaluation of computing equipment, energy consumption, performance. The second is using of green energy Next slide, please please Okay, let me introduce the first new challenge The first new challenge in evaluation of computing equipment and energy consumption performance The energy efficiency level requires requirements of computing equipment also be considered when performing traffic thrilling The higher energy efficiency level, the less energy is consumed by the same surveys The lower the energy efficiency level, the more energy is consumed with the surveys provider, wants to provide energy consumption, it can see schedule the user request to the service in instance with the highest level. But there is no standard as deficient"
  },
  {
    "startTime": "01:48:01",
    "text": "of computing equipment energy efficiency level. Therefore, it's difficult to consider the computing energy efficiency level of computing equipment when performing traffic theory Next slide, please the second new change is using a green energy you know, green energy also known as clean energy reference to energy that doesn't mean pollutant and can be derived used for production and dairy life including nuclear energy and renewable energy Renewable energy renewable energy, reference to energy resources that can be regenerated from raw materials such as high jewelry power, wind power, solar energy by energy geothermal energy and tidal energy, renewable energy doesn't have the possibility of energy depletion Therefore, the development and utilization of renewable energy are increasingly valued by many countries, especially the with energy shortages The development, of Greencasts can be supported from the use of green energy The more green energy is used in cash The least carbon footprint is"
  },
  {
    "startTime": "01:50:01",
    "text": "emitted. And the greener it is So consider the of the consumption of green energy for equipment in traffic steering is incomplete and the future research is needed Next slide, please please We will consider how to use green energy in cats Welcome more people who are interested in the bagel. What's more? there is also a green ball of the day It can also be discussed in combination later, if necessary. Thank you Any discussion and comments? Thank you for that. Thank you for flagging up the green boss which is after lunch today I just want to note that the green metrics in cats are currently not in the charter but I think it is worth having this drama going on and working on it in the background so that we draft going on and and working on it in the background so that we're aware of what could be done and how we might extend the Charter as we go forward Oh, we have two people in the queue. If you can be quick, please, Daniel Yeah, Daniel, I done and how we might extend the Charter as we go forward. Oh, we have two people in the queue. If you can be quick, please, Daniel. Yeah, Daniel, I'm ZTE. I think it's interesting and Katz is designed to the steering traffic upon some strategist It occurs to me, the working group is now working on is experience prioritized the steering strategy But I think we can add the green priority strategies into CATS steering strategies Thank you"
  },
  {
    "startTime": "01:52:01",
    "text": "Thank you Thank you. Lewis. There's one great comment from my side. In the previous presentation, I made about the orange use case, the one interface the meat hole, I refer to the fact that in Oran, the energy consumption is also considered as a metric. So it could be an example of the usage of this green metric, so maybe we can explore that particular example. Thank you Thank you Okay, thank you, Jane And last on our agenda Hello? Can you hear me? Hi There are your sides. Okay hello everyone, I'm 221 from Chinese Unicom, and I will give the presentation on behalf of my co-author I Yifu. And our topic is security considerations for computing of their traffic steering Next page, please Our first concern is about secure paths and service requirement. And we suggest that the service and the next is about secure paths and service requirement, and we suggest that the service and the network metrics may include the security related capabilities which could be used by the KASP selected to compute paths with security guarantee. So the clients with high security requirements, such as bank, hospital, government, etc., could choose the service with desired security attributes and then they can achieve dependable forward wording on top of only devices that satisfy certain trust requirements"
  },
  {
    "startTime": "01:54:01",
    "text": "and it will avoid the risks of the traffic if dropping system data leakage, etc Next page, please Our second concern is about requirement for absentecity and inquiry protection magnetism of service announcement. We suggest that there might be a mechanism that provides protection about the integrity and service of authenticity of the messages in the service announcement So because it could be because with protection, it could be exploited by malicious service to reload the traffic and it will, it may lead to some incidents such as the dose attacks efficient attacks of sensitive data leakage etc. Next page, please please Our third concern is about the requirement for our authentication and integrity protection mechanism in CES communication Because a manager's case, forwarder could temper the messages in the communication between forwarder to forwarder or forwarded to C-SMA, and this will may have a report effect of routine and the past computing of CPS So we suggest that the CPS solutions could support authentication and integrated protection mechanisms between the communications, such as between the CSMA and CBI CPS, or between the CPS and the Ingrid cast forwarders"
  },
  {
    "startTime": "01:56:01",
    "text": "Next page, please So our question is that does Cass need to consider security issues? simultaneously? Thanks for your listening and more comments are welcomed Thank you Yeah, so thank you I saw several things in there that are interesting. One of them is making security capabilities and status yet an another part of the metric that can be folded in and normal So please look at the discussion in the chat that's just been going on about normalizing metrics. It's a very similar discussion to green metrics and is at least initially out of scope, but something we should be watching but the other part of that is secure and the whole of our work from requirements through framework and solutions when they come desperately needs to consider security and we've really not been looking at it. So please see if you can help there there Right, I want to thank everybody for being absolutely perfectly rigorously on time It gives us exactly two minutes, if anybody wants to say anything, come to the queue, make a general comment Otherwise, you can have an extra minute and a half for you lunch going well to the queue, make a general comment, otherwise you can have an extra minute and a half for your lunch. Going once, go in twice Okay, well, then I'll leave you with a homin Do not make your chairs depressed by waiting and I'll leave you with a homily. Do not make your chairs depressed by waiting until two weeks before Dublin before doing really really good work that's helpful. Please"
  },
  {
    "startTime": "01:58:01",
    "text": "try to actually do stuff in the interim as well so that our stress levels are reduced. Thanks and see you in Dublin Thank you"
  }
]
