[
  {
    "startTime": "00:00:34",
    "text": "[Music] rich it\u0027s falling and trying to get it to work we\u0027ll keep playing with it but if you write it\u0027s 9 this is the net cons working group meeting I don\u0027t see anyone exiting the room so I guess you\u0027re in the right room then let\u0027s get started with the meeting itself right here\u0027s the note well if you haven\u0027t read it before of course and you can read it right now on the screen just to be sure that you\u0027re aware of the fact that any thing you say or do in this group is a contribution to ITF we have couple of people who have volunteered to be on jabber but if you know how to run jabber would appreciate your taking seat near the mic so you can watch the jabber room for any comments or questions while you\u0027re up here use the box around the mic and stay in there while you\u0027re speaking the blue sheets have been handed out I see on this side it\u0027s sitting on the front row so someone if can pick that up and pass it down that aisle we also have etherpad up on this linkage if you want to quickly take a look at it and paste it into your browser either bad tools that idea that are slash notes / - ITF - 103 - Netcom I\u0027ll give you guys a few seconds if you want to bring up the ether pad we would appreciate you adding comments or Corrections into the ether pad as you see people speaking will use the minutes recorded in the user pad and of course validate them with the audio stream or any actions that are taken in the working group before you proceed in full disclosure I did want to let the workgroup now that I\u0027ve had a change in corporate affiliation I am now working "
  },
  {
    "startTime": "00:03:36",
    "text": "for VMware just so you know okay so just going over the status of current chartered working group items the zero district of course is left the working group it\u0027s been submitted for isg publication not sure what the current status I think it\u0027s been there for a month now did you want to add in any update to this thickness thickness bonus zero touch document will proceed quite soon the next upcoming telecheck is already full so that will be beginning of December when that goes into that so from a review perspective there are few needs but nothing serious great thank you them now and then there\u0027s the yang pushed suite of drafts there\u0027s for them yang push subscribe notifications Netcom event notifications and rest cough notif all of these drafts have just completed their last calls and for the most part waiting for shepard right up we are of course there\u0027s the closing the window the submission deadline window which has just reopened and some final dotting of the i\u0027s and crossing the t\u0027s hey to occur but for the most part they\u0027re moving out of the working group to Shepherd right up state and I I it will be the designee designated Shepherd unless someone else would like to volunteer to be Shepherd the only reason that you that someone wouldn\u0027t maybe like to do this would be because for myself it probably incur some delay I won\u0027t be able to get to it until mid-december possibly early January if it were to be myself I took Nostradamus again so I would really encourage somebody from a working group stepping up into that and probably we can have couple of shepherds this is because the documents seem to be mostly ready and it\u0027s understandable that you have many things on your plate so we might even have some with you who is rather new to this process and kind of try to train them into that so if somebody is interested in that please please raise please you put your name forward yeah reach out to the chairs or even Ignis great ed shares I think is probably appropriate reach out come we send us an email next there\u0027s the Netcom restaurant client-server suite of drafts these are still works and progress we\u0027ll be discussing them today okay and then also there\u0027s a you to keep up channel also a working group document then there\u0027s the yang push notification capabilities draft and also another draft notification headers and bundles draft both of these are works in progress but neither are being presented today primarily because the authors are "
  },
  {
    "startTime": "00:06:36",
    "text": "the same authors working on the yang push set of drafts and they wanted to focus their attention on those drafts rather than these other working group documents okay from the agenda perspective first they\u0027ll be the prison presenting presentation of the client-server drafts followed by the gang push set of drafts followed by the you to be public pub/sub draft and then a couple non-cluttered drafts which would be subscription to multiple stream or originators and the in line action capability for Netcom and then other area business I should say that we have plenty of time this schedule I think with two hours on the schedule but from the amount of time that the authors were requesting we may have 50 minutes remaining so lots of time for discussion and if anyone else wants to you know to bring up something that\u0027s not on the agenda there\u0027s plenty of time for that as well okay hi Kent presenting the client-server graphs since I 102 in Montreal all the drafts were updated and submitted at a set twice most of the issues that we discuss in Montreal have now been resolved and a few extra issues were made as well there are two remaining issues from that we discussed in ITF one or two one being wanted with that which was called should algorithm identities be moved from the IETF SSH client TLS common crypto type modules sorry modules to the crypto type module and the other being add how do we add support for TCP Q lives so this presentation only focuses on those two issues as a quick recap the there is a set of drafts and relationship between the drafts as it is on a screen I showed this last time as well the only new thing is the lines that are in purple because if we call one of the issues where should we move some of the groupings that were in the keystore module to the crypto type modules so those movie those groupings got moved and so those purple lines are just representing the using of those groupings from the SSH and TLS "
  },
  {
    "startTime": "00:09:36",
    "text": "client-server graphs to the crypto type draft all right so first we\u0027ll just begin discussing the first item you know should algorithm identities be moved from the SSH TLS common module to the crypto types module for this issue you might recall we reached out to sag in the security group several times requesting health cryptology experts to help us with this particular item and last time we were fortunate enough to have some individuals from Huawei volunteer to help us with this so I spent the last two or three months probably engaging with Frank and how long from Huawei and actually I\u0027d like to turn it over now to Frank to present this particular update how we\u0027re doing in this issue and I should mention Frank is now a co-author under strap hello everyone his friends are from Hawaii and I think he\u0027s we\u0027re happy to work with Kanda we can we can proceed at least this series of draft follows that so I try to give a very quick deduction although this time what we have done on these drafts in general we have updated a freak so from my side I have updated as recharge the the basic way is the crypto type straps it includes several categories of the basic oh cripton great accordance and between used for other applications for infinite comp country we used we apply the physical a Korean on the net console based on the SSH and the net net convict or TRS okay so this has a street rafter we are updated we are updated okay so so firstly the crypto type traps like I just mentioned we we reference a lot of existing and very widely used applications such as IPSec and a key version 2 and the T is 1.2 pantry and ssh we do our sorrow story and analysis of this draft and abstract of the widely used crypto evidence and also very important they are also very safe safe algorithms and we try to divide them into six categories so there you can see Oh okay you can see the first one is hush Aryan okay the second is the symmetric second symmetric encryption algorithm and the Mac algorithm and the asymmetric "
  },
  {
    "startTime": "00:12:38",
    "text": "encryption algorithm and the signature and the key keeps changing okie negotiation so our basic idea is that we want these categories to be atomic and cover most also widely used basic algorithm and then can combine together where is really for not only from that conf we think that in future they can also be used by other applications so so you can you can go you can look at our our tracks for the detailed definition of the every algorithms identifier in each each category okay and okay and that\u0027s all for the crypto types but of course this time we still have some problems they need to need to be solved okay the first one is we already have the six categories of basical crypto evidence but but for how to defy identify a public key pair and the certificate how to define there they are ever even type for the public key pair and an eSATA Kate usually it should be a combination of equip ssin and the signature right like what we always say the I say Michael didn\u0027t or the ECC so but can read you can see we already divided the other algorithm into very very atomic very specific or categories so so I say it\u0027s not it should be as it should be a combination of the some of the basic algorithm so we are still not not decided that sorry we haven\u0027t decided how to how to represent the public keep here algorithm or the certification arisen of course there are two way Rama is a fine great way we can use our existing everything combined into the present I say or if you see other way maybe we can just very simply to the predator so I think this is a problem we still need to solve in the future version so if you can help us we are working okay and after finish you the crypto types and then we we walked up based on those crypto types and and and those crypto types provided the definition of the possible used algorithms by the visor that comes over SSH so so the left of question for us is "
  },
  {
    "startTime": "00:15:40",
    "text": "that we already have got some key from the from the crypto types definition and we also need to define the algorithm we used for the Netcom for over SSH so there should be some compatibility relationship between the between the Kiwi we used from the crypto types and the definition we defined here in the SH or in the in the in that comes over SH just so to the Christ to clarify this relationship we add some tables to to justify what if the writer mapping what is yeah what is a great matting the left isn\u0027t the draw imagine okay so you can see that this mappings are aware is a very straight forward actually the left of the left side is crypto types we we use the on the key and the right side is that we what we have defied in the in the SH configuration so they should have be compatible so kind very easily because we because uh you can you can you can see that the s that comes always says configuration configure every atomic algorithms on its configuration so there\u0027s a one-to-one mapping between the basic core crypto types to the current SSH configuration so this is a very simple example we have for compatibility tables this is about the Mac symmetric encryption and the cheeks changer and the hash area and signature okay so they are all the netting they should be compatible with each other so following the same idea for the that comes over here is there should appear this kind of capability existed here so we also do the analysis on the TRS 1.2 and the TRS 1.3 and also we looked over all the tos and a page it\u0027s everything and a page so we know that for TRS 1.2 the cipher the year here at Stifel feels it\u0027s a most important part it includes all the all the cryptographic mechanism which is used over TLS 1.2 and the fourth tears went off three there are three categories of Crick grad pre-classical acquittance fault for it which is tra ciphers used here as signature scheme and tears upon groups so based on this survey we decide that okay we choose all these three "
  },
  {
    "startTime": "00:18:40",
    "text": "categories for post the key is 1.2 and 1.3 but what is 1.2 only the fourth one or which is the ti-84 suits can is useful for constructor the competitive mapping between the key and the key is the configuration ok so also for in a same way with the filer way we define the humidity a community mapping table independently 40 eyes 1.2 and the tea is one two three so the reason why we have so many tables here is that because you know kinda ITF chapter has the limitation of the 80 or 82 right 82 characters in one line so so because you can see the our our psychosis is too long or too long stream so we we can only divide the every mapping into a table so there are five tables for each category right the for example this is the hash and the and the signe and the signature evidence it\u0027s just a two examples also we have the equation we have the key exchange imagine okay this is 42 and this is 40 are three also they have the we have the PSI for a sting mapping and and the key exchange a mapping and other meetings in summary we want to we want to we want to we want to give our capability mapping between the key and the configuration of the of our net count client or soul so yes I think yeah that\u0027s all yeah yeah just going back sorry about that good thing we have plenty of time on our schedule okay right so back to this you\u0027ll see the back button works it\u0027s no good so the question was should algorithm identities be moved from the "
  },
  {
    "startTime": "00:21:40",
    "text": "ITF as safety less common modules to the crypto technological the answer is no we\u0027re going to leave them there those identities are going to be defined both in the SSH AMT last crypto type modules as well as in the crypto types module and we\u0027ve created these compatibility matrix matrices that are existing in the Association TLS modules to allow for the mappings to be to be performed and currently those matrices are only implemented in texts there\u0027s not a yang module level definition of these mappings we\u0027re actually undecided as to if it\u0027s even possible to create yang level mappings how would we do it maybe some very complex musts expressions but it\u0027s unclear how would we done but fundamentally the most important thing is in the texts that it says clearly what the requirements are so that module implementers can you know appropriately implement the requirements if the client submits configuration with edit configure or yang patch then the server can determine whether or not an acceptable pairing has been provided and provide the error if not so that\u0027s the fundamental approach that we\u0027re taking with this and I think on in addition to solving this question that way were also using the opportunity to expand the amount and number of algorithms being to the cryptid types module to be complete a complete set of identities for all cryptographic purposes would you say that\u0027s first Nathan is that ferris yeah yeah okay there is interest in from other working groups to have other modules depending on the crypto types module with this expanded set of algorithms and so that\u0027s where that\u0027s primarily coming from but general generally a good idea any comments or questions regarding the this direction that we\u0027re taking solving this problem okay thank you alright so now we\u0027ll move to the next question that\u0027s being worked on which is adding support for TCP key beliefs last time we discussed how discussions with the transport area folks concluded that there is a need for people lives at every protocol layer at the TCP layer at the association layer TOS layer even NAT Conklin rest cough layers if you wish to test for the aliveness of the application at her layer aliveness of lower layers or testing for the "
  },
  {
    "startTime": "00:24:42",
    "text": "aliveness at lower layers really says nothing about the aliveness of at the higher layers so there\u0027s one reason for why you may want to do both and similarly aliveness checks at an upper layer should not preclude the aliveness checks at lower layers and I think here Tim Carey was mentioning how you made there be like a degradation where some of the upper layer protocol has been corrupted or disabled but you can come down and at least do TCP keeper lives and see whether or not it\u0027s it\u0027s up at that level so the question that we\u0027re stuck on currently is how to configure the keep allows at the various layers we have not discussed this really at all on list since Montreal so here we are talking about it okay so I have an idea but you may not like it that\u0027s my disclaimer independent of this discussion for a few months now I\u0027ve been aware of gaps in our current solution specifically that we\u0027re missing the dependent or some dependent protocol layers you know TCP HTTP and HTTPS I withheld raising this to the working group because I envisioned much I rolling and general exasperation but now it seems like the time has come to broach this topic so I\u0027m proposing a draft restructuring of sorts specifically adding in the missing TCP HTTP and HTTPS client-server layers recall at the very beginning of this presentation I showed you a picture of the draft current draft relationships so in the light gray in the background is that picture though parts of that picture are in black so the ssh client server and teals client server or the restaurant client server were were in that other picture as well but new in red green and blue are the proposed potentially new drafts last modules that we could add to complete the picture all right so that\u0027s the idea what are the benefits well first factoring out these dependent layers would provide a basis for future protocol models surely there will be more TCP based models that folks in the IDF will want to define so actually defining that IDF layer would provide a placeholder for over them to make that extension similarly surely there will be more HTTP based models and HTTP based models and so factoring them out would be sort of goodwill to the community at large but that\u0027s not how we got into this "
  },
  {
    "startTime": "00:27:42",
    "text": "discussion we really are here to talk about keep a lives so back that issue distinct layers would enable the kippah lives to be configured at each layer the configuration of TCP key believes could be defined at the TCP client-server models the configuration of the SSH keep lives to be defined in the s8 client-server models and so on right so then we\u0027d have each distinct layer would have the configuration for how to configure the keep allows for that layer within its own model and hence the issue that I mentioned before that we got stuck on how when we go back actually how to configure the keepalive the various layers falls out naturally and so that\u0027s the idea and the question to the working group is whether or not people think we should do this or any other questions around what it wouldn\u0027t take to do it in terms of timing and effort anybody comments questions Michael Abrams I just want to say I like that we\u0027re not discussing if we should be able to set keep lives because I want to be able to configure it at all layer so fully support the effort and then exactly how to do it I don\u0027t have a strong opinion but this seems good to me so far Jason Stern AB I just trying to understand the the concept of having it like turn on keepalive and TCP layer is on a on a server you\u0027re gonna turn on globally and then it\u0027s gonna have keep lives for every TCP session or or are you saying that every TCP session that\u0027s using --neck --neck comp if the granularity of the control you\u0027re looking at well it\u0027d be in a configuration data model and these all these are really groupings so whatever you\u0027re grouping stack is in in the case of Netcom for instance it\u0027s using let\u0027s just pretend it\u0027s using the ssh client server grouping which itself had we used the TCP client TCP client-server grouping so you would inherit some keepalive configuration for the TCP keep alive from that grouping and then likewise some ssh keepalive configuration from that grouping and if ever we get around to it some neck off level keep alive from that grouping and it would only apply to that particular configured stack okay so that\u0027s not a combination so you\u0027d be turning on TCP keep lives for this net comp session correct and not not for the entire operating system yeah okay thanks so this is Tim Kari Nokia I will say I think you know the approach that to having keep a lives at every layer and makes sense because again last time we talked about it it\u0027s needed for that piece of it to answer you know Jason\u0027s question as well as is that indeed this is within the context of the net comp session you know from "
  },
  {
    "startTime": "00:30:43",
    "text": "the TCP that supports the next comp session but I will say that as we were doing this for for some of the stuff within the broadband forum work that some of the implementations are that when you turn this on you touch those TCP q4 lives it\u0027s actually for all the sessions that there\u0027s some limitations and some of the implementations not that the the approach still should be the con the context should be the Netcom session but sometimes the implementation says that the only the only thing that you can twiddle the bit that you can twiddle is on me all the all the sessions just on some of the implementations so the refactoring might concern what the refactoring is we\u0027ve got modules coming up I mean there\u0027s just a ton of modules and I just and I get what you\u0027re doing I just man I don\u0027t know you know I\u0027m saying it\u0027s just there\u0027s just a lot of modules now if you\u0027re gonna do if every every layer so I\u0027m just wondering if the organization and housekeeping gets beyond you know the the benefit if the work becomes more better than the benefit right and and that\u0027s what i meant by anticipating exasperation i somewhat worn out the welcome here in terms of the refactorings we\u0027ve done and i get it but i also see this as being the best way to solve this problem and we really we anyway Michael Abramson again so us there is a bit like in Linux there is a knob tutorials on this and wide so you could test that and see would whatever you come up with for TCP here fit into IETF system for instance or you know would it make sense there as well as like a test of is this module generic enough and if it is I would say yes displayed it out because I might want to support this or that assistant level as default settings for also and also just on the net called server sessions and so that the net con server would use the socket option to turn this on for just its sessions and I would also like in ITF systems model you know setting for the entire system both so so we could your ear in support of this and also modifying IETF system potentially I\u0027m saying at least spend 10 minutes on seeing is the the way you do the TCP part is that generic enough that it would be able to fit into a native system and if I would support an effort to do that for ITF system as well because as far as I know there is an system-wide settings and at least some operating systems to turn TCP keep relies on by default okay okay well look into it so just to speak a little bit to what\u0027s been said the okay so first off let me on this slide it said net cough keeper lives could be defined at the neck client server models layer so remember last time we discussed how would we go "
  },
  {
    "startTime": "00:33:43",
    "text": "about doing that keep lives for restaurant keep lives we kind of concluded it\u0027d be hard to do I mean the neck off our PC model and the notifications and especially when you take into account call home actually figuring out how to do that so it\u0027s really TBD and I don\u0027t actually suggest this effort should try to introduce Netcom for restaurant level keeper lives it\u0027s just a placeholder for if ever this working group wanted to define Netcom press comma keeper lives could such people iOS be fit into the model at that future date similarly oh wow I don\u0027t put TBD there there is such thing as HTTP keep it lives but they\u0027re really for HP 1.0 and 1.1 they it was by default she didn\u0027t have to configure it it was just by default and http2 inherited that behavior as well but but also there\u0027s kind of a misnomer in that HTTP when they talk about keeping lives they don\u0027t really mean keep a lives such as like actively testing the aliveness of the remote system as they do a hint that\u0027s being propagated to the server to not close the connection within 10 seconds it\u0027s more like keep keep the underlying transport open so with their religious that with a really balanced so I think HDPE keep lives is also effectively a TBD not yet defined and this effort would not intend to actually define how configuration for HP keep lives truly it\u0027s just the TCP association TLS where we would want to configure this and back to the picture so already we have the keeper lives in the current models that keeper lives are being defined at the Netcom client server and the restaurant client server so we effectively move that configuration from the Netcom press conf layers into the association TLS layers as well as into the TCP layer TCP all right so this kind of goes to the scope of the effort we really didn\u0027t would want to factor out TCP client server it\u0027s it\u0027s like primarily what we\u0027re talking how we got into this discussion is because Nokia observed that the open SSL doesn\u0027t implement today TOS level keep lives there\u0027s an RFC for they don\u0027t implement it yet there\u0027s a discussion about that they should implement it but it\u0027s still not implemented yet and they meanwhile they have to do TCP keep lives so so we really need that TCP layer and configuration of TCP keep lives do we need to have HTTP client server at all and you know similarly HTTP client server at all I mean as the IETF goes we generally are shunning non secure protocols so maybe we don\u0027t bother with HTTP clients are going to the comment made about the expanding a number of drafts so the that green light green drafts the HQ "
  },
  {
    "startTime": "00:36:45",
    "text": "client/server is one that I think is the least needed and also factoring out HTTP from rest cough technically not needed but you can see how it would probably be better to factor it out there will be other HTTP based applications and having it factored out would be very helpful for them as opposed to us bundling an insight at the restaurant player so to to that scope of the effort that there\u0027s are there are some opportunities to whittle this down pare it down a little bit and maybe do less than than the full complete solution but just want to bring it to the workgroups attention comment Rob Wilson Cisco so I think separation Rogers probably makes sense but doesn\u0027t mean SME has a separate Ross all of them so potentially you could bundle some of these modules together relatively small and that may reduce some of the overhead or process overhead here thank you and then yeah and then just last I think to to again to the scope of the effort I mean in thinking about okay you know I don\u0027t really want to take more work on for myself here but in thinking about the effort I would suggest that we define minimal module right so if we were to do TCP client-server it would just be the minimal IP address port number and a keepalive configuration any other possible TCP level configurations could be AB is some day in the future I\u0027m not really interested in solving that further scope problem same for HTTP I don\u0027t know how many configuration parameters there might be afraid to pee I\u0027m not interested in figuring it out I just want to you know have defined the little bit that we need to define to get this factoring out and so it\u0027d be the minimal effort I think at least that\u0027s the way I\u0027d like to approach this yes Michael Abraham\u0027s it again um I wouldn\u0027t I wouldn\u0027t even need it per connection or IP or something I just need a knob default on or default off for all sessions early system no for world for not conf the TSP keep alive for a net compensation zone I would just I don\u0027t even need that so I don\u0027t know is someone else express the need to do this on a per connection level I just wouldn\u0027t want like a default set the on and off basically that\u0027s what all that\u0027s all of what I need is someone else needs more than okay then we need to do more but I\u0027m just saying I would in a lot of scenarios I think you just want to be able to turn it on and off and you don\u0027t need to set it for destination or anything yeah understood where we would put a global setting like that is the question maybe ITF system but what leave had a door opened default on and off for the net called server for all sessions that come in I don\u0027t need it to do it per IP I just need to say the Netcom server should default up tcp keepalive on i don\u0027t need to say for this IP range or something like that robust and cisco "
  },
  {
    "startTime": "00:39:46",
    "text": "so definitely support your suggestion saying that if you do do this split out to keep the minimal and the future they need to be expanded that could be done in the future revision just trying to avoid features sorts of creeperface me right and actually already that\u0027s the strategy we\u0027ve taken like for instance with the cessation TLS we\u0027re really just focusing on the minimal necessary to configure the crypto stack so that we can do it but if you look at various a cessation TLS implementations there\u0027s many more configurable options we\u0027re not touching any of them so more the same in that regard yes so tim carry nokia just to make the comment from from Macau is that you know we\u0027re using it for various applications right so there\u0027s a TR 301 within the broadband forum that does call home that uses TCP keeper lives and so there\u0027s a the generic setting may or may not work I don\u0027t know not sure it works in that because it\u0027s on a stream based and we\u0027ve got multiple endpoints that we have to talk to but we\u0027ve also started looking at the augmentation because we weren\u0027t waiting what you\u0027re gonna do right and so I think we can work with you on on trying to figure out you know how to get the best adaptation possible to work in different scenarios actually if you know people could collaborate with me um you know it\u0027s pretty much me doing most of this effort but if I had some co-authors I\u0027d truly believe this could be done you know by 104 we would be talking about it being done and were there any other things that we forgotten I think probably be going to last call around that time frame so we\u0027re if we were to not do this then we still have to finish up the crypto types thing that Frank presented and also we would still have to figure out how to do keep lives and I don\u0027t have an alternative proposal that\u0027s the only proposal I have at the moment so we\u0027d spend some wheels I\u0027m trying to figure out what the alternative proposal would be we\u0027d be looking into February time maybe March timeframe anyway this I can see what we could do I don\u0027t think the effort is huge if the co-author could help me I do believe we could get it done really with probably just one more month worth of time so alright I think there were that was all the comments any more comments anything on jabber okay great thank you yeah so hello everybody this is Alex Alex come so I\u0027m going to give a quick update along with Rashad actually on this on the sub on the speak of the subscription "
  },
  {
    "startTime": "00:42:46",
    "text": "drafts and as also earlier really actually we don\u0027t have many updates for this this should be fairly this should be fairly short but I just take my time sure okay alright so basically again there are a whole lot of drafts that deal with with subscribe notification yank push and related things what are we talking about here are the four drafts there from the top the ones that are basically in working group that\u0027s called have to have just passed all the other drafts are basically dependent on this work and are yeah essentially pending until later so so for those drafts and some of the updates here so one thing in key to mention we had a slight name change for each of the titles of the drafts it just make it more clear that they are all related and related to the same for the same topic area so first pro strat is the draft ITF net con subscribe notifications and so working group last fall\u0027s complete and it is currently in well since since Montreal underwent three revisions we\u0027re now in V 18 which basically have all the group last comments addressed okay there\u0027s been the title change was an appendix use case be how to extend it for additional transports been added some minor knits like renaming the subscription identifier to ID to make it less verbose and that\u0027s so forth and various of in various in a variety of minor editorial text journal and so forth and tweaks and those sort of things and there\u0027s one upcoming v.19 that this I think we posted shortly after the obvious in all that they and that the site has been real for this and basically there was a thread in that mod concerning updating the description of the x-pyr yang object definitions are we do that as well as some text tweaks concerning basically the modification is eating of subscriptions as a requirement that they need to come from the subscriber and okay so that\u0027s that and thank you also actually for the extent of discussion and reviews that we received on the comment on on this and Asha and all of those drafts so that was very helpful so thank you second one is the draft IETF net conf yang push on this one also saying same sorry very group last call is complete it has undergone four revisions since last time we\u0027re now in be 20 again there have been minor updates to the to the text some clarifications and so forth some very mind very very minor updates to the yang module itself so points we changed the names of the object that have a sink in it to to not included age those sorts of things we and there\u0027s a V 21 also here coming up shortly to fix busy to very minor editing their errors and with this other remains I\u0027ll turn it "
  },
  {
    "startTime": "00:45:49",
    "text": "over to Rashad so the the changes to the net cons notifications draft also were relatively minor similar to some of the ones Alex presented earlier you know title change to so that to align with everybody else the renaming of identifier to ID there\u0027s been a few discussions about the examples in the appendix e dot two and a dot 3 and somebody I forget who it was had asked for you know subtree and XPath filter example so those are the changes which went Envy 14 and then G 15 which is supposed to go in very soon is I think it\u0027s only a spell and fix okay rest content occasion there\u0027s way more significant changes there I think because that document didn\u0027t get as much love as the others previously again thanks to all the comments we got from from the people on on the alias the first major change was removing the configured subscriptions that was the main topic of discussion - OH - in Montreal so we got rid of that so it\u0027s dynamic only now secondly the the document was very a bit of restaurant a bit of HTTP 1.1 a bit of HTTP queue so there was a fair amount of cleanup there to align with restaurant service and events for example we used to start the subscription we used to a post on the URI now it\u0027s a get on the URI to align with our C 80/40 we remove the bunch of H if you 1.12 specifics you see way more restaurants in the names in the various names now than HTTP similar to the net conf draft you know there was filter examples added there was a discussion on the alias past couple weeks regarding stream XPath filter how to do that can Jason fix a dot one exam appendix a dot one examples we aligned it at all with NAT coms notification so that\u0027s what\u0027s out there right now v09 and vita and what should go in today there\u0027s a spelling fix but also what was mentioned for the subscribe notification draft we there was various discussions about what does if subscriber or a client mean and there was a proposal for restaurant to tie that to a restaurant username so that v10 with that text should go in today what\u0027s next so the various authors believe we are done or nearly done based on the workgroup last call comments we would like I mean there\u0027s been discussions about this many times key before we would like those to go to the IHG as soon as possible as the process allows us to and once those are done I mean the first slide Alex "
  },
  {
    "startTime": "00:48:50",
    "text": "presented or the second one I forget is a bunch of other drafts which are dependent on those ones and then progress on those ones that\u0027s it thank you any comments okay I\u0027ll just make some comments Thank You Rashad for helping with the rest Kampf notif drafted it wasn\u0027t one of the original three that we had discussed but adding it I think was good mostly because it actually helped us find some other issues right in the SUBSCRIBE notifications draft so I had a sort of a trickle cascading benefit I think beyond just sort of enabling us to allow Netcom from rest count to move forward together which is a general goodness for the working group so thank you for that and and also to the working group as Shepard as soon as I received these drafts you know one of the question is in parallel to beginning the write-up I\u0027ll also send out an email to the work group just asking those who had posted comments to just review that their actual you know their what they were hoping to see was is there and you know to let let me know or they let the Shepherd know if it\u0027s not me there\u0027s anything amiss but otherwise great thank you thank you right so there\u0027s Alex of just one so what clarification so when is it busy so what is the process specially so meeting when is it being centralized G is it busy once the Shepherd review is completed the Shepherd write-up is there does it then Messi goat is sent to the IC review so is a busy serialize like that visits the process yes for the most part yes the shepherd does the writer and then and Shepherd isn\u0027t necessarily always the chairs but but then the write-up occurs and then the chairs discuss whether or not it\u0027s appropriate to submit for publication which is equivalent or synonymous to going to the is G so well but it almost happens at the same time so the Shepherd right up the concluding of the shipwright up and they\u0027re submitting to the publication or to dice G happens at the same time then what but what that really means it goes the ad Ignace in this case where it be ad right up and he needs to schedule or tell a chat which he just mentioned a moment back you know it could be a month out it\u0027s every couple weeks but you have to get on the calendar so it gets on calendar and then that occurs then there will be a number of discuss items right so the various ihe members will have comments all of them will ballot on your drafts they will be discuss items you need you will need to resolve all those discuss items this isn\u0027t really normally in the view of the working group it happens off the working group list the chairs and the shepherds who are involved in that process but that can "
  },
  {
    "startTime": "00:51:50",
    "text": "take as long as it takes it and I\u0027ve seen it sometimes go quickly a couple weeks and other times months just depending on how it goes then that concludes it goes to RFC editor and then there are Sierra will look into other issues and they\u0027ll be more back and forth sure those everywhere and I was busy mostly concerned about getting it really until the in front of the is G okay thank you alright so next presentation I think to run hello Iowa amateur Angela Omaha way and firstly there are many feedbacks from the working group what\u0027s the difference between the Marco stream originators and the you\u0027d be publication channel this to draft here is the relationship the multiple stream originators draft is distributed extension to the yunkish draft and the you to be public based the publication channel is an transport for that can be used for both young Busha and the multiple stream originators and this presentation we\u0027re going to talk about the unity based of publication channel firstly we would write i would like to clarify the design goal we want to produce a new TV base the transport for the carrier routers there are many advantages that compelled to UDP UDP compelled to TCP and here we list the some we also want to support multiple encodings including the binary and we also want to enable options for extensibility and want to facilitates the distributed data export we also get requests from lustre meeting to compare with some existing transport here it is firstly the IP fix is designed for the flow information export is it do not support mark or other encodings such as XML zebra and GPB so on and there\u0027s no Yankee IP fix encoding and no mechanism for block message fragmentation and no extension mechanism and that the other protocol is co-op we I think it\u0027s a it\u0027s an option for IOT and it\u0027s designed for resource constrained device and network it\u0027s not for carry router the message ID is "
  },
  {
    "startTime": "00:54:50",
    "text": "16-bit it will result in a frequent one not for a large amount of data when used on carry routers this this new version we add part on how to manage the UPC we augments the subscriber the notification model just like this and about now it\u0027s only apply for the configure the subscription we need to consider the dynamic subscription also here\u0027s the next step firstly we need to consider how to manage the dynamic subscription we may augment to the established subscription RPC with the transport and receiver information this this is not to existing in current subscribe the notification chapter and we also need to update the subscription model by adding the dynamic sub screen support and adds the encoding attributed to the receiver and we also well aligned the document name with other transport document so that\u0027s this sort so that it can be clear well what it is and is there any other suggestions so Kent as a contributor and so so well actually maybe first just a general clarification statement what we\u0027re what this draft is presenting is a notice model so we have like neck Hoff Noda from ruskov notice this would be udp-based transport notice yes how we might characterize this draft and like with all the other Notah for the current note of drafts they\u0027re really just providing dynamic subscription-only support because we never really got around to thinking that we would want to have configured Netcom for restaurant subscriptions but for for but we do want to have configured udp-based subscriptions and that\u0027s how this draft came to be adopted working group supported item and also I think having dynamics descriptions make sense as well so that\u0027s sort of the the the sort of the clarification of I think where this draft is second is I think we need to be clear that what we\u0027re describing here is a new protocol this would be a new binary protocol we\u0027re calling it UDP I\u0027m sure we have a name for the protocol yet you don\u0027t have a name for it then the name is the efface the publication channel Oh what do you think we do have a name for the we need to call it "
  },
  {
    "startTime": "00:57:51",
    "text": "something um but but it is a UDP based protocol it has a new it\u0027s defining its own message header or etc it can contain different encodings particular so anyway it is a new UDP based protocol with that work describing being defined as a notif so then finally getting to my question is defining a new UDP based protocol making sense relative to making use of an alternative existing UTP based protocol and I know you discussed IP fix and co-op I guess with IP fix one of the things he mentioned was that it doesn\u0027t support different encodings but maybe that\u0027s okay maybe just a single encoding would be okay for co-op you mentioned that the message ID was only 65 thousand and I think the concern there is that IOT devices their rate of transmissions would be very slow but a high-end router could send 65,000 messages within a single second so you would it would lead to many issues so so but there may be the if that\u0027s the only concern there is maybe there\u0027s an opportunity for this working group to approach the coop working group to ask them if there might be a possibility to extend that message header you know I know I\u0027m just exploring ideas other ways that we might be able to solve the general problem which the working group wants to solve is a udp-based notification message for subscribe notifications but how we get there I think I think we should still consider the solution space some more I think it\u0027s my comment thank you yeah hi this is Hank working on the concise yang telemetry draft and we are using coop and the message ideas for detecting duplicates so if you expect having a duplicate in a in a 16-bit space then you need a bigger message ID but I don\u0027t think that is a concern it can rewind in that scope if you don\u0027t expect duplicates in that dimension the association between the requests also the subscription to the stream is the coop token and that\u0027s eight bytes I don\u0027t think that\u0027s the problem so maybe message ID via sort of misinterpret idea I think I I don\u0027t see that it is a problem but on the other hand you want to have this inside system like I heard like between line cards or in this is not leaving the the data store system component I I have the feeling so maybe then having a listening server this is best Rest for co-op server is a "
  },
  {
    "startTime": "01:00:55",
    "text": "little bit over too much then you can just establish a UDP stream it depends on the application if it has it goes through the internet probably co-op is a good idea if it is just for high volume inside a system you can basically unpack all of the overhead tuned for Internet Protocol it\u0027s there now not not not being the devil\u0027s advocate at the IETF - just to say that we don\u0027t need internet for the courts here but but you can strip a lot of that off I was just explaining that IP fix just leave the box it\u0027s generator on the line card itself and it goes out the box to a collector yeah this is and this is of course correct but I thought IP fix was used in a different place yeah for this purpose and therefore has a different scope of application I think because of corn cooing I thought it was an encoding alternative well just add that conversation I\u0027ve also done udp-based logging where the log receiver was on the subnet to the to the line cards and it would receive all the logs and then do aggregation and compression and deduplication and then send them over the LAN yes oh so I think that\u0027s your point yeah that\u0027s my point it\u0027s over over the land you don\u0027t really have to tag it and besides if you miss one what would you do about it anyway even nothing - isn\u0027t that like the routers gonna keep okay my last comment is anything but binary representation doesn\u0027t make much sense inside if you\u0027re talking about burdened by TCP state I think being burdened by something else as a binary is even worse so I think it\u0027s rather obvious not to use human readable clear text formats like JSON or XML I think it would defeat the initial purpose I think I have the feeling of the concept of the block okay I should say those requirements are from our customers so we designed for them and they have the requirements here from Google I find that the whole section of this draft to do with any kind of reliable delivery and discussion of how you should only really deploy this over reliable networks is it\u0027s under specified so our operational experience of having tried to put something udp-based streaming into production is there are no reliable delivery channels like you have bits of your network where you can\u0027t possibly assume that all packets are going to get through or there\u0027s no congestion because it\u0027s just not like even the amount of bandwidth you can buy there is not sufficient and the the cost of having to assume that the channel is unreliable is the law of periodic replication of the data on there on the chat on the channel "
  },
  {
    "startTime": "01:03:56",
    "text": "so that you can deal with retransmission or dealing with retransmission I would go so far as to say as soon as you have to deal with retransmission you might as well use TCP anyway and TCP and then because you also get the advantages of knowing that reliably when you sent an event it got to the other end so you can reduce the number of times you need to stream data so we don\u0027t think that it\u0027s actually possible to do over an unreliable channel event based updates because any system then can\u0027t really rely on it and with any kind of latency so I think you should probably add some discussion to your draft as to what the cost of doing this over UDP is and really try and figure out how retransmission works in in this this model especially if it actually works to a line card which is kind of the motivation here right because you\u0027re assuming then that there\u0027s a cash on the line card to have any packet within some known window to be agreed to be requested my suspicion and operational experience of having a few thousand devices that run telemetry at this point across number of vendors is that you will just go to TCP again as soon as you have to deal with these problems which are kind of the operational realities so I don\u0027t really think we should be pushing the industry in a way that doesn\u0027t really work actually the reliability is the part of the industry after is not the real reliability as the TCP it\u0027s a kind of partial liability it\u0027s a trade-off to anticipate and UDP right but the the problem is now how do I build any kind of system that relies the data being there so I can if I\u0027m trying to do anything with interface statistics and I know that there might be fidelity loss because I\u0027ve got lost packets I can\u0027t rely on it if there you can\u0027t do anything event based because an interface goes down in my network and then you don\u0027t have any way to react to it you don\u0027t know that the state is there so the the natural requirement then is that you end up building a polling system to make sure that you have a current enough view or to Rican to reconcile and our scaling analysis kind of shows as soon as you do that you\u0027re going to end up with significantly more data than you would via TCP so this scalability argument kind of falls down so we\u0027ve been pushing this entirely tcp-based can\u0027t as a contributor don\u0027t just jump in for a second ooh what is the motivation for you udp-based is it the reliability or unreal I don\u0027t think that was it I so much as the desire to enable the line cars to send the UDP packets having the same source IP and port ordinary not port but at least IP address as the routing engine you know that they that for the other draft that we are about to present the multiple stream originators so the desire for UDP is to enable that distributed source so we\u0027ve looked to this I think that there\u0027s a there\u0027s a model whereby you have a distributed system that has different components that can each have TCP right like I think you\u0027re going to end up going that way if you ever care about reliability if you say this is a hundred percent unreliable then I think you can kind of talk yourself into this UDP model but if "
  },
  {
    "startTime": "01:06:57",
    "text": "you say I\u0027m one distribution because it gives me more scalability point to be proven as to whether that\u0027s really required and then you you can still do TCP it was a lightweight TCP protocol to the to the line cards and you\u0027re kind of inventing a new protocol here as you pointed out so you\u0027ve got a bunch of room to be able to design it exactly how you want the source IP and I would just suggest for debug ability it\u0027s kind of a challenge if you have n producers that are all producing with the same source IP it\u0027s kind of like it\u0027s we have challenges around being able to know whether you\u0027re actually in synchronization with that system if you\u0027ve got n different producers one line card stops producing data and you don\u0027t really know you\u0027ve got no metric to be able to alert on say of this source isn\u0027t sending mutator anymore I think we\u0027re jumping into the next draft but I think that draft is the idea is that the configuration model would allow you to configure the UDP to the system and then the system implicitly distributes to line cards and tells each of them you know it\u0027s implicit but if you do were to do TCP you\u0027d have to be explicit the configuration model would actually have to configure we use this IP address for that line curtain for each language yeah I\u0027m suggesting a bit of configuration pain is better for the overall system thank you hi this is Hank again if you are expecting to have congestions you will have UDP Datagram loss I mean apparently so so that that\u0027s a fundamental decision you have to make do you expect congestion with your dreams or not if you have that expectation which I think is likely then you have to deal with retransmits and then again you should not reinvent a fundamentally transmitted mechanism for UDP for every draft in the ITF there is a good template for that in coop that is a confirmable message you can basically make every message confirm overages big not not recommended or every thousands message and you can then see how many you lost and in that window can be transmitted messages that it\u0027s like a little bit like TCP but like the performance TCP advancement and also if you are ending up with TCP in the end again there\u0027s I call it a reliable co-op it\u0027s the name is co-op over TCP TLS and web sockets or something very long so I\u0027m there\u0027s that alternative also but then again I use mean there\u0027s a lot of things you considered here and my suggestion is to approach the thing to thing research group that is meeting here there are two drafts in development they are the serious pattern draft which talks about how to associate let\u0027s call it data items that are somehow and serious and there the problem of retransmits discussed "
  },
  {
    "startTime": "01:09:57",
    "text": "there and if you have a problem that is not solved in general and you want to solve it with your draft maybe we can create a general solution for UDP that other people can also use so that this effect of recreating some new things for UDP to make it some more look like TCP some our ends finally also that if you decide to go with co-op there is the draft non-traditional responses which can do it but basically every exotic thing you need that does not speak fire at the moment satisfied with co-op so if you need something you don\u0027t find and current are cease please trying to thing to thing research good for once and then to look at the serious pattern and the untraditional response props as far as I know current currently coopera is only used for IOT like domain but do you have any real replicas ample or real application that a co-op is used for outer saw something I example for co-op application is that we thought of working group it does DDoS protection working group we use a kind of our basic transport protocol for the for the scene or each other that\u0027s our application if you want to look at okay I would like to see and only because something is was initially intended to be used in the constraint in order environments doesn\u0027t make it unfeasible for the rest of the internet observation and can\u0027t as a contributor just a quick follow up on the discussion about retransmissions I actually when I first saw the message ID with the UDP I never thought that it would be for the purpose of knowing when or to request for a retransmission or anything like that I only thought it would be used for won\u0027t number one ordering of the packets received by the receiver because UDP doesn\u0027t guarantee order delivery so at least the receiver could do in order you know reorder at least have order delivery that was the number one reason or motivation I felt that was before the message-id and number two was for detecting gaps now when when a message was dropped but not not to request just to know that you lock they miss one and so I never would I thinking that there would be a desire to try to build reliability on top of a UDP based protocol here any other comments good prob again sorry I was a long walk and I think that that\u0027s a interesting operational like mode of mode of operation right so if we\u0027ve kind of said before and so with with SNMP I can poll the device I know I get some stats back yes maybe there\u0027s some loss in them but I know at what interval I\u0027m polling in "
  },
  {
    "startTime": "01:12:58",
    "text": "this mode where there\u0027s no reliability then if the device just shuts up you can\u0027t tell right because you don\u0027t you didn\u0027t get a sequence number to tell and it becomes quite operationally difficult to not assume reliability when there isn\u0027t when there\u0027s no no guarantee that the thing at the other end is sending data so this is kind of I mean we tried with this we looked at it as the preferred way to start with and this along with internal the collector deployment things about how how you know when it could can reconnect how you deal with redundancy between collectors and those kind of things I think it just makes more and more challenges here so that that\u0027s kind of why I would just I think the draft could do with some discussion of like how you actually operate the system like this I agree Justin sure just to interrupt comments I work for a company we use streaming extensively from thousands of devices don\u0027t quite some time looking at UDP or TCP and I also discussed with potential customers UDP us no no it has to be reliable otherwise you need to build additional layer to ensure it transmissions reliability you don\u0027t need this here benoît class so that\u0027s interesting because we were discussing the same thing that the discussing was IP fix for 10 years right yes the message ID an IP fix was just to know about the order and just to know that you\u0027ve been losing flow records so the point is that for IP fix it works fine records accounting right so you sell information if you lose one okay big deal by the way and expect a router to keep information neurons from Smiths sorry so here I think the key point is that if you rely on this mechanism for an event like Rob was mentioning it must be reliable if you just link to send like monitoring information you can use UDP yes just to add to pay no it\u0027s fine I think fundamentally yeah sflow IP fix have a different nature anyway because we know that there\u0027s n flows on the device we know that or n packets going through the device and we know that we only expect a sample of them therefore losing one we can never build a system around having get like that I don\u0027t know of any system that\u0027s built to say with s flow or IP fixed I\u0027m going to do one to one flow sampling and I\u0027m going to guarantee that I\u0027ll get every one of them whereas with telemetry data if we\u0027re building systems that now split the control plane across the device and off the device then we need it to be reliable just like you would need some of this data internally to the system like links going up and down to be reliable for routing protocols so but no again so it depends what you call telemetry right if it\u0027s telemetry I mean to push high frequency all information from it\u0027s like IP fix your sending flow records even if "
  },
  {
    "startTime": "01:15:58",
    "text": "they\u0027re not flow whatever right now if you condense everything in your telemetry so it becomes an event you can\u0027t miss it so this is Alex yeah just one of the busy in response to some of the items here clearly a different application like that maybe some application maybe but you require reliability others where you\u0027re saying you lose one record it\u0027s not a big deal and another question is can you how it is being used so if you use this for periodic busy for periodic updates you know basically that you are expecting updates for every period already anyway so if you have a period missing you would basically to infer some of some of those things well I do agree actually that we need to have the discussion busy of these operational things in the trade-offs in this but at the same time I think I think nobody is saying that this is the be-all end-all transport for all particular use cases this is one use case for certain scenarios where basically those operational scenarios that you described yeah would be applicable so Rob again just a response that I think there\u0027s a few challenges with those assumptions right so as soon as you say oh I\u0027ll stream everything periodically you\u0027re going to significantly increase the data that comes from the device and by hundreds and hundreds of times right so actually the to make this system scaleable you probably want to only send things when they change it gives you a significant advantage for large data sets it also gives you a significant advantage for interfaces they\u0027re down on systems with you know radix of a thousand or so which which is kind of common in today\u0027s networks so as soon as you say I\u0027ll send things periodically you\u0027re going to end up with these scalability concerns and you probably are now having to deal with worse scale on the device of your GP periodic than you would be the cost of doing TCP for reliable so yes I don\u0027t entually the other problem about periodic is that you don\u0027t actually know what they collect or what you meant to receive so if a whole line card stops sending did Glen Kyle get removed from the system what did was it meant to send so it\u0027s actually hugely difficult without lots and lots of other accounting to know what you should have been sent during that period so I I see why the the third thing I shouldn\u0027t say is we\u0027re inventing a new protocol here to send telemetry data let\u0027s know invent one that we know is flawed and only works in like a small number of cases because that that\u0027s just going to complicate things respond so regarding the unchanged versus periodic if we certainly on the basic trade-offs but actually they subscribe the subscriptions both can support either what I mean depending on the use case a user or they will decide whether they want to happy erotic or whether unchanged is actually more applicable for their particular application if you want to have a continuous and telemetry to do some kind of whatever whereas statistics trendline analysis all sorts of application you might still want to have periodic right not not "
  },
  {
    "startTime": "01:18:59",
    "text": "every use case requires or change that\u0027s true but the I guess the point is that there\u0027s some data and an underlying that you do want to sample like that right but that still can be the this doesn\u0027t mean that the system can\u0027t support sending data periodically is that there is a significant amount of data that does that won\u0027t need to be sent so why I would encourage people to go and look at is to look at the data that is being pulled from devices this is what we\u0027ve done and then look at what the proportion of it that is event based versus periodic and do some calculation as to what the data data volume is so we have this for some jet friends the scaling analysis in the gr PC based telemetry where we can show you know significant reductions based on this but even though that some data is being sampled and sent periodically because it needs to be sampled like that from undying Hardware sources for example related questions been a while since I looked at the draft but I remember there\u0027s previous message ID and that\u0027s how the receiver knows that so messages have been lost but if you\u0027re not receiving any messages how do you know that there\u0027s messages loss or we going can we\u0027ll have to do a UDP keep a live draft or maybe we can include it I\u0027m sorry I\u0027m not sure I\u0027m not sure maybe we need this kipper life information I don\u0027t know about this this is something we need to consider but we also have the in the other draft we have some mechanism to solve this problem partially solve the problem burn worthless so in IP fix we solve that with SCTP and get a perfect solution where actually you would have a stream which is reliable unreliable or partially writable so depending what you\u0027re sending it is monitoring it would be unrivaled you miss a couple of information fine no big deal you might be something anyway on a router partially reliable you do your best or reliable if it\u0027s event base that\u0027s how we solve that however a ctp didn\u0027t pick up and it\u0027s an issue online Kahn\u0027s right online counts of routers I mean again you have an HTTP session directly from all around counts or actually it complex you an operational issue right and I think Rob mentioned that how do you identify your device a router is like one IP address or it\u0027s a sum of IP addresses to one per line yards sorry I do not understand your question no question part it\u0027s not a question it\u0027s a no duration that we\u0027ve been looking at those issues like ten years ago it becomes like more an operational issue what do you want to solve right thing about that and then you will have the solution for your protocol there are several as we listed here there are several design codes first story we "
  },
  {
    "startTime": "01:21:59",
    "text": "wanna build a distributed data export and then we want to we want to maybe to speed up the the transport we may want the the hardware tool to encapsulate and to to process the packet so we need a simple magazine not simple transport not like TCP well again speaking as a contributor I think the message that I\u0027m getting from the working group is you probably need to look at the data set to see a Danida udp-based channel and if you if you need reliability then if you and you\u0027re gonna build reliability into this with the sequence number why not just use TCP so I think if I understand look at the data set look compare it between trying to transmitters revival II and unreliably and see what is the impact of losing packets and as benoit mentioned if it\u0027s monitoring data that you\u0027re looking at big game you lose a few packets but if you\u0027re looking an event you can\u0027t afford to lose it then you have to be built in reliability into the protocol what is the cost of doing that yes a cui any other comments just as a contributor just one more comment I heard or learned last night that the I guess it\u0027s a co-op working group but there\u0027s a an effort that\u0027s been going on for a couple years now to do a co-op based broker pub/sub mechanism I don\u0027t know much about it but we should learn more about it and and see how it might be usable in this space as well okay let\u0027s move on to the next presentation okay okay this is about the matos stream originators this one this one is a generic lattice to build extension to the yam push work we have some of the use cases the first one is the the router the Camerata is narrow and we want to push data directory from the line cars and the other use case may be useful is the IOT is narrow and the tractor first dream subscribe to the "
  },
  {
    "startTime": "01:24:59",
    "text": "border router and the distributed the requester to different route he knows and the Latinos can push data directly to the tractor here is solution overview the publisher contains two rows the master and the agent and the master have subscribed subscription server and the agent that contains the component subscript is over a typical typical operation is like that this the the subscriber first ascend the global subscription request to the master and the master will decompose this request into multiple component a subscription and send to the components of screen server then the different agent or master have pushed data directly to the tractor here we to achieve this there are many interactions necessary between the master and the agent for example the agent need to have a registration with the master so that the master is the well of them and and and manage the lifecycle but in Manzanero like like who we mentioned in in the career outer the interaction between the master and the agent will be an internal implementation so currently in this draft we consider its out of scope but we listed there some possible interactions one key point to to this idea is the subscription decomposition the master well assemble the disassemble the global subscription to multiple component a subscription and the distributed them to the corresponding temperature sauce too to achieve this a reference the implementation is like the the master may need a data structure and typically our resource allocation table to keep track of the mapping between the resource and the corresponding location of the subscription server and another another key point is the publication composition firstly the receiver will recognize data recalls associated with with one subscription according to the subscription ID and the second step the receiver assembles data "
  },
  {
    "startTime": "01:27:59",
    "text": "generated at the same time period based on the recording Hutton consisted in each data recall and in addition the server may need to know the number of component subscriptions so here we we propose to use a list of a publisher ID we will add this to the to the response of the establishes subscription and modify the subscription and also add this in the subscription status and subscription modified notifications and this part when they need a young model by augmented the existing subscription notification draft the other the other key point is about the subscription state change in notifications we know in addition to sending events or cause to the receiver the master must also send the subscription state change notification and we here we were away asked for all the subscription states change in note notifications must be delivered by the master publication channel which is the session between the master publication publisher and the receiver there when another tape is when the subscription in conversation result changed the subscription modified the notification must be sent to indicates the new list of publishers and next step we are going to add the young model to how to extend the existing subscriber the notification model and is there any other issues you consider to be added in this draft Kent as a contributor can you go back to your previous slide the one that said is the diagram and had the red box that said otoscope yeah why is it Eris cope as I mentioned in some instance Naro like the like the Carrie routers this this is the in this is kind of the internal implementation so I think must between the mainboard and the like house right okay so I think that this being at a scope is dependent on the conclusion of some of the operational requirements that we were discussing a moment ago going back to Rob\u0027s comment from before "
  },
  {
    "startTime": "01:30:59",
    "text": "a little more configuration complexity may be warranted if were for instance needing to configure TCP instead of UDP in which case you would actually it would have to be in scope you because you\u0027d have to be configuring what is the TCP interface at least for each line card to use so I think I think what you\u0027re saying is it\u0027s out of scope here because you\u0027re it\u0027s the expectation is that from using UDP the routing engine can implicitly can you know internally communicate the line cards and yes it hasn\u0027t okay so there\u0027s that assumption which i think is not is still TBD is what I\u0027m thinking okay but my concern is this this part is a little bit of complex and may vary vary from implementations so I\u0027m not sure if it can converge in English just that\u0027s my concern okay my she has a contributor if you could go down a couple of slides I think they you talk a lot yes sir okay now maybe the next one I think where you talked about being able to reliably indicate a change in the subscription I think it\u0027s either this or the next slide yes yeah yeah all the subscription state change notification must be delivered now when you say must that means you\u0027re thinking about a reliable channel hearing or delivering that change in notification that\u0027s an interesting question and from the messager they are no it\u0027s not we do not consider it must be a reliable channel so maybe in udb case maybe we need to consider this is Alex also hostile to add always he respond to that I would not mix this actually with the earlier transport discussion the gold certainly busy for the for the subscriptions per se it has always been to basically make this busy make this well make the fundamental mechanism reliable so that you can avoid having to pull things now obviously with this case if you have a new component subscription that was added or something that was removed that is be an event that you would needs to know or that you would want to know certainly as a collector therefore basically there\u0027s something that that that needs to be notified we\u0027ve had some this some internal schedule whether it should be subscription modified or whether there should be another type of notification but either way it is an event and suppose it should be foreseen vide as part of the control channel now if you want to have making this busy for the for the control part of this now for "
  },
  {
    "startTime": "01:34:00",
    "text": "the actually telemetry stream whether this is reliable on offensive that\u0027s a separate issue I would separate those discussions but this one would be needed for reliable control channel so to speak so Kent as a contributor maybe it\u0027s a chair I don\u0027t know the motivation for the working group particularly to adopting the previous strap this draft is not yet adopted but the idea that this draft was discussing was one that was presented at the time that we adopted the previous strap which was the goal to support line cards to be able to send messages themselves directly as opposed to trying to fold them to the routing engine in order to for the routing engine to to send them because from experience we know that that the internal backplane the fabric is not having enough bandwidth to transmit that much data it\u0027s just not possible the line cards have to be able to send directly themselves and in fact you know things like encryption actually it\u0027s probably problematic and so you know go into the operational requirements you know are we actually thinking that for these very high logging scenarios would the destination be an internal receiver something that on a LAN you know something that itself would collect the logs in unencrypted form do deduplication and and analysis compression even itself could convert it to binary or the need for binary you don\u0027t really need binary in the land you need binary on the WAM when we talk to customers you know their their costs for bandwidth over LAN is expensive that\u0027s when they care they don\u0027t care about the bandwidth on the land so so you know I think if we get our heads around what are the operational requirements what is the problem we\u0027re trying to solve maybe some of this would become more clear I still strongly support the notion ability for sending logs out the line cards directly that\u0027s important problem solve but the motivation for being binary the motivation for it being UDP even I think we should go back to asking if that\u0027s really important to solving the problem here yeah there\u0027s a comment Michael Abraham\u0027s and so it struck me the whole thing about line cards and it being on box i i\u0027ve the when use case where i might have a a Wi-Fi access point that basically doesn\u0027t have an IP address so i\u0027m speaking some kind of protocol to it or i don\u0027t want it to send any thinks it\u0027s "
  },
  {
    "startTime": "01:37:01",
    "text": "going through me but it\u0027s a different device and I want to like expose this in yang so that the wife it\u0027s like I\u0027m the nighttime room I\u0027m the Netcom server but I\u0027m configuring the guy over there and I still want exposed to my NMS that these are two different devices isn\u0027t that kind of the same problem you\u0027re don\u0027t want to like a more generic approach and how to expose this in Yang and net conf and how to handle this because isn\u0027t this the same thing and like if it\u0027s a lying it like line card that is like its own computer sitting in the chassis or if it\u0027s something else like you\u0027re acting on behalf of that guy I mean I\u0027ve seen many different scenarios where you need the same concept so can we make it more general yeah I think you provide a an interesting use case maybe similar to this new style tea use case and so we actually I think this this framework is like a generic one I think my problem is there are very like one we\u0027re talking about like okay how do we what\u0027s in the UDP packets the de stream is a telemetry it\u0027s it\u0027s not a that\u0027s not a different thing yes I know but but it\u0027s like so this here it\u0027s talking about subscription so but isn\u0027t this just configuration it\u0027s just it\u0027s not me specifically I\u0027m doing this for another guy that he\u0027s like near I\u0027m controlling him so it\u0027s not me don\u0027t we need like a more generic approach that and do we actually need to talk about what the configuration is instead isn\u0027t it like how do we do this generically isn\u0027t that what we should be discussing like it\u0027s talking about subscriptions here and so on and how to talk to that guy or what to actually configure but don\u0027t we actually need just a best comment this is exposing this entire concept of you know different devices managed through one net culture I have a response but I think Rob does as well it is for this question Rob yes please go ahead I completely agree so in the GRP sea bass it\u0027s about telemetry and configuration we added a generic way to be able to make a path be addressable to a certain target that they entered the managing entity deals with and it\u0027s used for both telemetry and for AM for configuration I think having case-by-case solutions is make the point I don\u0027t think it\u0027s optimal I think having a single way that you can say there is this management agent that is responsible for this other domain is is super useful for many many cases ok so up leveling the problem space great ok and I think my closing thought is not it\u0027s not really on this draft what kind of to the other one as well it is you know currently just the gang push and Friends drafts are almost out of last call and a Shepherd right up we as working group we\u0027ve only yet to find support for dynamics descriptions we do not yet have any support for configured descriptions this draft has honest path towards enabling support for "
  },
  {
    "startTime": "01:40:01",
    "text": "configured descriptions but I think that there may be other paths that we could explore that would get us there faster specifically HTTP based push mechanism is something along these lines I don\u0027t know maybe somebody would be interested in putting together an ID to propose another notice right so the nice thing about the way that we\u0027ve constructed the or deconstructed the the yang push notification drafts is that we do have all these note of mechanisms so it\u0027s kind of a Swiss Army knife it\u0027s great that we have a UDP based mechanism available certain deployments will use it for their use cases others won\u0027t because it doesn\u0027t matter use cases so I think though which should also consider other notifications that would enable us to have configured descriptions so that\u0027s sort of my closing thought on this um I think the idea is become Matua and the the solution and the scope is kind of clear so I am I\u0027m wondering if I can ask the working group to a doctor yes doc but um I think before we get to the point of adoption I think we probably need to address the question that Mike McAlister trays which is do we need to upscale this problem definition before we get to the question of adoption maybe you should consider all that first okay thanks great so our last presenter chin good morning everyone my name is Jim and I could show you attention to this a new idea actually this job has been around for a while we actually submitted in the last night a meeting I didn\u0027t get it discussed and ivory but we have some a few discussion on the list with Robo virgin and about this idea in nine action capability because here what we like to do is to use this capability to to provides a punk operation and can walk aways together it\u0027s the protocol position but some of many discussion about whether there\u0027s some Atalaya medicine we can use such as commission template and so we do some Alice\u0027s and and so before this meeting actually we prepare the draft updated I missed the deadline so we just post our new version so sorry for the late so for this chapter we want to recap a little bit provide several observation the photo "
  },
  {
    "startTime": "01:43:03",
    "text": "action actually met a couple actually doesn\u0027t specify how to handle this action the reason is because the action get introduced in young 101 after medical for work I window one get a puppy and when we introduce a young MTA and the option you know we add the constrictor for this action they only can be invoked on the original state datastore so we think is a very limited so we you know track the early discussion on these actually there\u0027s some statement you said actually from the robber weapon and then this kinda research can be relaxed actually can be applied to some other convention conversion latest also we that the motive like what motivated me to rise this job and so we try to investigate how this action can be applied to as a Korean datastore like wrong in datastore or start-up datastore so here is use cases and and we we have some men in this country about this I think the simple cases we bring here actually is suppose you configure the win and hacker branch on the champion the face and you may leverage is the conversion template if you actually configure the chung interface with vein and tank a value one by one actually that means that you may you know have a you may need to a lot of second in traffic actually you may but we have some other other way you because you you have the completion template and you can define young data model to to allow you to configure the trunk interface ways pedantic rng with such congratu you can maybe you can really reduce these sickening traffic \u0027you only need a one or the message you to carry these conversion data but still actually cause a larger packet size so so go to the face further actually you actually config chunk interface with several VLAN tag around you labyrinth a garage not a diss greater so in this case actually you may you know do a lot of beta retriever you know that cause a even a lot of the protocol message exchange so what do we like to do is optimize the network net called protocol to provide such a punk operation you view kimochi the VIN and tag arranged several Bananagrams into one we rent a grantee actually you only need the one protocol message exchange so what do we propose "
  },
  {
    "startTime": "01:46:06",
    "text": "here is a u9 actionability here these actually can be applied to wear a different protocol operation like edit config i did\u0027t paid her okay to date her and the idea is to introduce the operation attribute for example under the edit configure surely we can introduce two new operation attribute were called record emergency recorded split actually allow you to to merge the way number of in an attacker range or speeds up in an attacker ng if you can allow such kind of feature you really actually improve the Nanticoke for query efficiency and you only need actually one query to get all the information you needed here we gave the example for this operation attribute recall the record emerge actually without the u9 action capability suppose you need to configure the tummy in the face with to win and hack around you and but you really want to merge them into one when an attacker ranges so so you what do you can do with the existing solution for them or edit config actually you you need to delete research to win an attacker ranges first and then you created a new bin and tag arranged with this one so in our solution actually we if we with we have the win in i action support actually we can you know just the you know introduces a week Mergent attributed to indicate a new server to use the completion and temperature to merge the the renji into the into one range in their server side so also we want to compare the difference actually you know for without the in matching capability actually you need two more climb the computation because you need to you know figure out how to you know emoji several via an attack arranged into line ranges so that\u0027s a the overhead we really want to avoid another case actually is a recorder we call the recorders breed actually you may have when we nan tackle Reggie you want to split into three or four and with the existing protocol operation you we also use at config actually you may first I mean you need to delete the Divina tank of value and then you can and now you create a another two or three vinegar ranges so this actually is a cost actually you you introduce that other ways in my action capability actually you you only need to actually indicated a server to choose the VIN and tag arrange it may not attack a range it\u0027s oblivious "
  },
  {
    "startTime": "01:49:07",
    "text": "so these can be happen on the server side so so the advantage is you you don\u0027t need to rely on the kleiner to do the more Renji computation to speed at the ranch so this is a basic idea I like Joe your attention actually so the summarizes what we proposed here actually we want to use this in action to embedding into the protocol operation to improve the medical require in fishin see actually we call this a Bunco operation may be the solution the example we provide here is very limited but we think the intention is so you know really impose these kind of nano copy fishing with these pump operation we may introduce some propriety actually you can actually you know do the pump operation with with this kind of group so they can really improve the medical call for query efficiency yeah that\u0027s all yeah Michael a result so I don\u0027t know why I don\u0027t read the draft if I understood correctly is this only for when the will you change the configuration but the end result operational State does not change is that the only so you\u0027re splitting the range into two but the effective you know in effect configuration on the line card or whatever it never changes is it only for that type of configuration or is it also or is this also it like you split it and then you delete one and you do that in one operation okay so you had the example one two five and six is six to ten you can merge you can merge those and into one record yeah if this changes nothing in in real life I mean the line card the hardware doesn\u0027t get reprogrammed by that operation you\u0027re changing the configuration but the state of the device doesn\u0027t change is it only for that type of operation or is it also for for deleting one of the villains in the middle it\u0027s for both yeah I think we right now we really support both actually the motivation we can have the you know merger that is created several tag around into the one allow you to do the better medical query you know but actually we also support away we in some cases you may need to delete a some of the value from the VLAN tag arranges so we provide such capability in some cases actually we you know we need to support post and and then we can actually can you know optimize the actual to to merge several rent into the wine wrench yeah so yeah do you see this as a no is this a optimation in number of transactions or is it processing power on the server or on the client or whatever we don\u0027t want you add over here to the client actually maybe you just need a one transaction but this is actually transaction you know you send a request to the server server actually we are "
  },
  {
    "startTime": "01:52:08",
    "text": "actually you know using some existing contemplator to actually merge you the the range into the one actually all happened in the server side actually you reduce overhead on the client side robertson cisco so i\u0027m still not convinced that this is that this particular use case is actually a problem I\u0027m not convinced there\u0027s a scale issue in terms of configuration here even you split out the number of e lands over and there are hundreds of interface and then I still think the amount of config is gonna be a 10k 20k something that would be small in terms of mister size and I\u0027m consuming it so don\u0027t I\u0027m not convinced by that aspect that\u0027s a problem here to be solved in terms of if you want operations to do more advanced feed a manipulations ie breaking tags or inserting tags into into particular strings for example then yes that\u0027s okay but I think of those maybe just be our pcs potentially on a VLAN model is how I wouldn\u0027t prevent those so then coming back to the general inline actions I\u0027m still sort of conflicted is where this is a good thing to do I think this more generally is about transactions and saying I want to give a sequence of events to the server as one transaction effort to perform all of these things and either succeed or fail so that\u0027s the the guys I\u0027d look at this problem rather than just adding actions into configuration requests but even with that I still question whether that\u0027s a useful thing or not I\u0027m not I\u0027m not convinced this is a problem to be solved at this stage but a you say that you don\u0027t know we\u0027re giving actually we use a edit configure the exam preview you know you you really modify the VLAN tag around you to the merger and a split actually you may need because you may operate on some list that leads to the P key index cannot be deleted so you have several disk rider Renny up to you so you need to you know delete several discs where the rent arranger first and then you create then a new range with logic rent rent rent rent you know so that\u0027s a diffusion though the Nanticoke we think we really want to address this okay so that\u0027s a different problem potentially to solve and I think again I think need to look at the data model that you\u0027re talking about so the one I\u0027ve been through right if doesn\u0027t have that issue as in the VLANs interest information on a sub interface so it\u0027s not actually something where you have this concern it\u0027s just manipulating that string and the ability of a client to mangle VLAN IDs into string is it\u0027s probably bored beyond trivial to do I mean it\u0027s that\u0027s an easy thing to solve so it might be that your data model is different and then hence there\u0027s a different requirement commentary from that so I\u0027m happy to look at what your specific data model is to see what the changes was different yeah we do have such a model we can yeah "
  },
  {
    "startTime": "01:55:09",
    "text": "and show you of line about race yeah oh my Asia is a contributor adding to Robert\u0027s concerned fit why we might need this is the problem specifically for case where we\u0027re talking about a range like we\u0027re trying to specify whether we\u0027re trying to expand it break it up is that the specific use case that we look looking solution for yeah the case would give actually maybe it\u0027s kinda imitates but we really want to generalize this idea the general idea actually we can provide the pankration for Nanticoke for protocols you know so you can actually improve and then copy if you shouldn\u0027t say and here we gave the Gaddafi the VLAN tag arrange a value the value actually is interval type type maybe there\u0027s some other case actually in an attacker value actually is is a string type and you also do this a bit emerges operation you know so what other use case would you have in some case where you haven\u0027t bring bring up actually so you may transpose some learn completion into the into that static congregation or dynamic accommodation data by the way we sink yeah we we only you know talk about the focus on these cases but we have some other cases with haven\u0027t grown from prenup yeah okay I think maybe if you bring those cases make might help the workgroup appreciator and I understand the problem a little better yeah yeah we can do that yeah can\u0027t just a contributor I agree with Rob I don\u0027t understand the motivation for one insult like I guess scalability efficiency but it you know does it really get to the level of concern that we need to solve the problem that the solution seems like a very point solution and the fact that it\u0027s in that colony is concerning I would request that we have a solution that works for both the company and rest comp if it is truly just a transaction like mechanism I think that\u0027s what Rob was saying then maybe enabling gang push to be worked to be used by NECA would be another way of enabling something like this it going to Mahesh is coming right here if it\u0027s truly just for ranges then it seems like maybe we\u0027d have to have a data type a type def range and then this operation would be available whenever that type def was in play it\u0027s just unclear at the moment I guess going to my hashes last point two more examples data analysis it\u0027s it\u0027s currently it\u0027s not clear why we would want to pursue this yeah I think in tension we we provide such conservation Cober we can generalize this cancer we not only apply to the input but also can apply to the existing medical operation you know so not a limit to to the you know the existing network of further operation so yeah I\u0027m push you can we haven\u0027t "
  },
  {
    "startTime": "01:58:11",
    "text": "investigated how these can be applied to that young boys ship either that\u0027s that that\u0027s a case we think maybe first we need to clever the prominent Space Coast and then we can go into a tip Oh about that other other currency we don\u0027t thought about I think we should go Cody to look further to apply to that young boys year you\u0027re saying yank push but you mean say yang patch right yum push not a young patch no Hank push oh you meant you mention is young patch patch right patch oh sorry I miss Norris any more comments questions all right so we\u0027re at the top of the hour they\u0027re blue sheets are up here if anyone did not sign the blue sheets please come to the desk thank you and otherwise great we used up all the time thank you thank you "
  }
]