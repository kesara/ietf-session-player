[
  {
    "startTime": "00:00:04",
    "text": "foreign welcome to the tools interim if you are as you join if you can share video please share video we'll give a couple of minutes for people to finish joining in that case I'll go get some coffee in the meantime foreign"
  },
  {
    "startTime": "00:02:10",
    "text": "we're a couple of minutes in we'll go ahead and start I am expecting Jay at least um let's figure people will be joining as we go along this is a tools team meeting um it's being held as an interim the meeting recording will be posted to YouTube keep that in mind as we're going through the meeting if you can share video please do share a video we'd like to make all of these sessions as much like meeting around the table as as we can jumping in are does anybody have any agenda bashes I'm not hearing anything not seeing anything in chat so let me ask first is there anything that we need to do from a tooling perspective for 117 that is not already done or not already clearly in progress again hearing nothing so there's been a flurry of activity um on the tools discuss list as more people are running into the issues with the chair and group male aliases failing to deliver particularly to users of Gmail we are attempting to accelerate the rework of post-confirmed e which is the"
  },
  {
    "startTime": "00:04:02",
    "text": "tool that we have to address this um to both do a better job at not breaking dkim signatures which it will do in a few cases now and to extend the demarc rewriting into the draft end group aliases so we're hoping to have that work underway before the week is out whether or not we have it complete and deployed before we get to the meeting is an open question it is a um a big lift to move from the python 2 using the mailman python 2 libraries directly to wrapping the use of the libraries probably by avoiding them completely and just using the mailman T command line options to get the things that we need the rest of it um the move to Python 3 will be immediately beneficial because we'll get the um much more advanced mail handling libraries in the Python 3 standard Library compared to python 2. anybody have any questions about that one for the moment all right the next thing to report on is where we are on moving our domains into cloudflare all of the domains that are listed in the card in that link are both um they're hosted at cloudflare both as the registrar and the primary DNS provider we have as we made this transition went through a period where the um each Zone went unsigned for a few days and then became signed later with a much"
  },
  {
    "startTime": "00:06:00",
    "text": "more modern signing algorithm this went very smoothly the lack of signature went almost unnoticed we did get one inquiry from someone that was just curious why we didn't do the um follow the path where we kept the zones signed through the Transitions and we're helping to explain what was in the way so that um in the future um the state of what is available to you um users in general might be in a more amenable to keeping the signatures in place so in short for us as we were moving cloudflare just didn't support moving a sign zone so there will be people talking with text and cloudflare to see if they could improve that and then we were running into issues with moving off of a very old um algorithm for the signature that we had so as we were putting domains into cloudflare and enabling the cloudflare is the DNS primary we moved many of the names in the zones to the proxies all the names that were primarily related to http https um that had an unintended consequence for some of the bear domain names where we found that there were people using FTP and rsync against the bear domain name uh we've been addressing those as we've found them guiding people to using names that aren't being proxied through cloudflare"
  },
  {
    "startTime": "00:08:00",
    "text": "and providing better documentation for what to do with these alternate access mechanisms going forward as we make it through the it transition that's upcoming these services are going to be on completely different machines using a bear the bear domain name for them isn't isn't going to work so we have been adding proxying to some of the added domains focusing first on RSC editor.org and we're tuning the rules that come by default when we proxy through cloudflare to be appropriate to ietf and RFC editor websites um as we're discovering issues so we haven't had major issues they've been things like the RPC staff getting challenged because the uh uh much of the interaction with the the scripts that they had looked like um SQL injection attacks to the um default web application firewall rules and we just tuned those rules away um for people that were were logged in so we are also still working towards restoring um digital identity used to be Affiliates as the secondary DNS providers um this is something that cloudflare um advertises that we can do but it is not yet working so we have an active um ticket open that um we're tracking with cloudflare and working with digital identity to get this in place for all of all of our domains"
  },
  {
    "startTime": "00:10:01",
    "text": "any questions about that one do feel free to interrupt me I don't want this to be me just talking for however long it takes to get through these notes so foreign for the next topic archiving the older meeting wikis such as the um older docu wikis that are hanging off the registration website Alexis and I have been working to make sure that these are fully ingested into the internet archive that's the the plan for how these things will be archived um we're very close there's um a class of of assets that had not been scraped the last time Alexis and I looked at it and she was looking at what she needed to poke at the archive to get them to be scraped I'm not planning to report on this again at the next meeting um unless there's a problem you can assume by the time we get to the next one of these that this is just done so Robert on this Wiki thing what about the isg private Wiki archive no we thank the private Wiki still just exists as a private Wiki what we're talking about is archiving technologies that we're moving away from okay yeah so words private Wiki go ahead I am go ahead you go ahead please it seems like this will be useful because the knock had its own Wiki for quite a while and apparently that wasn't being archived anywhere and it did they're not deleted it and so like no"
  },
  {
    "startTime": "00:12:00",
    "text": "more knock Wiki all of that content went bye-bye so this seems like a good thing so Cindy where is the iesg private Wiki now as it moved to a Wiki JS instance or is it still yeah the isg private Wiki is in Wiki Js yeah but the new one right not every page I mean of course we have an IG private Wiki which is fine for the multiple reason but the archive that's what I'm I meant from the previous one is everything has been converted I know that many nodes I mean the informal notes has been converted for sure I wasn't the one who did the transfer of that particular Wiki but my understanding was that everything that was actually still relevant had been moved over I can double check on that though okay perfect thanks in advance all right because Sarah you want to um Talk briefly about the IB website transition yep an IAB for new library website that's temporary website available right now uh so we can migrate things from the website um this happens in parallel to migrating statements and other statements and minutes and other other things that we are going to transfer into Data data tracker um so I assume that when both are complete we can go on moving to the new website"
  },
  {
    "startTime": "00:14:02",
    "text": "credit problem yeah so the we're just starting work on transferring the appeals out of the uh um WordPress instance the the old ID website is using the structure of those appeals is irregular so there's a bit of modeling decision to make on how these will be represented inside the data tracker um they're not going to get moved before 117 I suspect that this will happen in the middle August time frame and it's a precondition for switching to the new IAB website so I suspect that at the earliest the switchover at least for the parts that rely on the data tracker would have to wait until the end of August I don't know what the current plan for moving the rest of the content is when when the when that's expected to to be done Liz or Cindy do you have a feel for that yet so yesterday was really the first time that I had actually had a chance to start moving anything over because this was delivered right as a bunch of meeting deadlines were hitting um moving the content itself I would expect would be maybe a couple of weeks the bigger issue is that there's a bunch of content that the IAB needs to review and possibly rewrite and that will take longer right all right so this is underway and it's probably in August September kind of um reveal is my rough feel go ahead Mallory just jump in don't don't bother with the queue perfect thanks um yeah I mean I'm now the rat from the iib the tool scene I've second time joining you all um maybe we'll get to have face to face time in"
  },
  {
    "startTime": "00:16:01",
    "text": "117 just to get to know each other better but um I'm taking notes so this has been a helpful update I have also met with Miriam just specifically about some of this stuff I think she was concerned with not all of the things we've requested from the tool team or the websites there's other issues that we've documented properly on our side so she's wanting to pass along those institutional memory to me so I've got sort of a page full of notes and all right to the IAB after this about progress so I just really appreciate you giving those specifics on timeline and like the road map I think is one of the things Mary identified as maybe wanting to have more clarity on um and there's nothing really I think that I need to flag for you that you don't already know um I think in addition to the content moving over I'm aware that there are some um issues in GitHub that are open still so I don't know if that is uh if those issues are wrapped up in the content migration and additional development it sounds like you want to get the content moved and then you want to close some of those tickets and if that's the case um website or against data tracker or something else I I just have notes so I do have a separate one just on the data tracker and this in the portion of my notes just on the website it sounds like miria has six open issues related to the website in GitHub and she said also that Cindy might have opened some as well and maybe during also the transition of content that you're doing Cindy you might uncover more but I just I'm suggesting that even in August September whenever we hit the next Milestone there may actually be additional development sure if it's fired in the tissue tracker yeah yeah this is all all iteratives so okay"
  },
  {
    "startTime": "00:18:01",
    "text": "all right I think that was it I I just yeah really grateful for the update and um we'll talk soon in a couple weeks before all right I'm gonna move to the next item Jennifer would you like to um walk us through what we discovered looking at the instrumentation that we added to the data tracker uh sure um well I hope my microphone is working I think this might be the first time I've used it good um yes so I guess since 116 we'd um switch the uh the UI for draft submission over to use an asynchronous processing back end uh using very similar to the APA I endpoint that we introduced uh prior to 116. um so we've been looking at uh the uh who's using which endpoints and how and the draft numbers coming in through those part of the motivation being that we are we're still seeing um some drafts being submitted using the old synchronous API which we would like to make it go away um and as we were going through that we also sorted um to look at the number of submissions coming in with XML and text and uh table to also parse out whether the XML is V2 or V3 and whether it's directly pre-coded as XML or converted from markdown using crandoun or a mark um and so in the notes page there there are the statistics that we got um I think it's just about a little shy of 1400 submissions since the 10 point 3.0 release came out"
  },
  {
    "startTime": "00:20:02",
    "text": "um and I guess 85 percent of those are through the UI and the rest through almost all through the asynchronous API which is great um still a handful of of submissions uh using the synchronous one and that number there is going to be nine of them some of those are multiple revisions of the same draft so it's a oh that's fewer than that looks like there um and it looks like um if you look at the um I guess I'm in the XML versus uh markdown division there in the third section um but almost 50 50 I think 55 to 45 in favor of people using direct XML over markdown um about a third of them are still writing in in V2 um and uh I guess that's what I'm seeing there and I have already sent direct mail to this um submitters that we're using the synchronous API and um with pointers on how to move to the async so thank you so much for those statistics as I wrote in the chat is really a good Insight what are the ordering tools I used may I or around or yourself present those at the isg meeting at the ietf I mean that's a thing it's really important and it's worth five minutes of our time there yeah sure no worries at all this is public information feel free to point to the notes page or just copy paste it out thank you oh if you want to be there for presenting I don't know"
  },
  {
    "startTime": "00:22:01",
    "text": "I haven't I'm happy to to show up if you want me there but I don't know that I would add any more information than what's already shown okay and the other point I see only eight XML first text but I just submitted a draft when was it of course a Monday right I get only the shows of XML so may I assume that XML please text using the API yes the only way to submit text right now is through sorry XML Plus text I think is only through the UI to the oui because I okay yeah this is the API it doesn't accept text well it's not important anyway so thank you again for the numbers I think it's very useful so I have a couple of questions I'm very curious um if we know the 153 text only submissions um how are they being produced or is it just people that are formatting somehow and then uploading only the text or do we have any insight into why they're doing that word translate I don't know nothing great so um it's hard to tell just from the text if it was used a tool that produced it there's not there aren't artifacts left we do know from a very small number of people that were having trouble submitting that they gave up and submitted a text version because they couldn't get their XML version well groomed enough to be accepted so um but I think basically weren't actually trying to format locally they just were editing and throwing it at us"
  },
  {
    "startTime": "00:24:02",
    "text": "they have may have been getting something to succeed locally that didn't succeed when it was fed into the submit tool all right so this is we've got an issue to improve the um quality of error that comes back um when someone does a submission and one person that we were working with had some uh attributes in the primary SVG tag that rsvt profile does not allow and they had not run it through SVG check before it hit submit and down inside the equivalent of SVG check is is run and it was airing out in the area that was reported was very opaque and this is an improvement that we will make before we get to the 118 submission cycle so trying to really ways to get insight into why something is being submitted text only I mean we could go as far as adding to the submission form if you're submitting text only a you know comment field that says you know please tell us why you're not submitting XML just a voluntary thing that people could like give us data on that would be useful I think um and I guess that looking at the numbers a significant amount of the XML submissions must have come through the async UI since there's no other big block and so I'm I'm given that Martin's um make file and upload directly for you I guess I'm really surprised that people aren't using it more no and I think that that's probably a lot of the async API the bulk of that"
  },
  {
    "startTime": "00:26:02",
    "text": "async API was stuff that was coming out of Martin's tool right but I'm asking about the other side like why are so many people that are working in XML submitting through the UI rather than through a makefall are they not using make files are they I'm just you know there's other stuff and and you may also be able to find some of the evidence of the make files in the form of the venue and other stuff in the that some provided um because I think that's a useful thing to know about the adoption and I guess I'm also really surprised at the number of mmark um not that popular uh the seller working group likes it um but um not to the tune of 55 submissions so that surprises me so any ideas that you have I mean feel free to drop by code Sprint or we can talk during the week um at 1 17 about ways that we can further mine the information that's there to try to identify classes of submission so we're basically at the block of what I ex end of the block of the the hot topics for discussion um the last hot topic that I had was um to ask the group whether or not we should um cancel the August 8th call we quite often do cancel the tools call it happens right after each ITF meeting so unless somebody has a"
  },
  {
    "startTime": "00:28:03",
    "text": "strong desire to hold that August 8th meeting and I will cancel it later in the week all right acknowledging your request earlier Eric for the read through of the the rest of this I think feedback I've gotten generally from other people is is that we can mostly just read it offline I do want to call in and make sure that people take the time to read the T paragraphs at the end of the data tracker report we'll talk more at the next tools meeting about the implications of some of the work that we're doing getting ready for RPC tool modernization um on the V1 API in particular we may have some users of the API that are going to be disrupted and I don't think it's going to be worth the expense to make that API backwards compatible as we go through this fairly major database structure change um the RPC has also been waiting on a rework of the author information um for several drafts the plan had been to regenerate all of the information I took a look at how disruptive that was likely to be and found that there is quite a lot of data that has been gathered over the decades correcting author information manually by the Secretariat that will be overwritten if we just did a bulk rewrite so I'm going to change course and I'm hoping that the release that comes right"
  },
  {
    "startTime": "00:30:00",
    "text": "after ietf 117 will have a button for the appropriate parties depending on where a document is in its stages of approval to just have it regenerate the um all of the author information and give the person that requested the Regeneration an opportunity to do a manual correction and leave a little bit more track in the database about what has been manually corrected or not so that in the future if we want to do a big automated pass we can do so um knowing whether or not data should be preserved as already validated by a human so the rest of the reports will take as read unless somebody that was working on them has something that they want to call particular attention to this will take us go ahead casara on XM at RFC uh the third third bullet point um so there's a draft PR that allows Unicode in all elements um for people who are interested have a look at it and you can check out that branch and run crops against it and see what's the output is yeah I don't think it's going to get much anytime soon but for your information all right anybody have any topics for open discussion Jay and glad you were able to join looking back over any of the things that we went through earlier"
  },
  {
    "startTime": "00:32:01",
    "text": "in the calls or anything you want to discuss so no nothing to discuss but if anyone has any questions on any of the bits that I'm doing like the infrastructure RFP or um uh anything else perhaps then I'm you can ask me now after all right well if there aren't any other um topics to go through I want to thank everybody again for spending the time providing feedback and asking questions during these calls I hope to see most of you in San Francisco those of you that are not planning to be there I hope to catch you online during the week at some point so thank you again and we'll see you all soon"
  }
]
