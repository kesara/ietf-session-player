[
  {
    "startTime": "00:00:24",
    "text": "the role is quite simple um whenever someone in java just says at mike or whatever just pop in the queue and relay that so people can hear it we'll do our best to keep an eye on the conversation as it progresses but it's it's easy to miss things thanks lucas appreciate it you have two scribes in the chat okay um when we get going uh welcome everyone to the the first meeting of the week mask thanks for being here um uh it's quite early for some of us so um hopefully this is a productive session nevertheless um typical this meeting is recorded"
  },
  {
    "startTime": "00:02:00",
    "text": "you've used this tool before if you use this tool before you know how the all the buttons work at the top but if you're not they're fairly it's fairly intuitive um if you want to join the mic queue just press the button you do have to unmute yourself uh to talk and share video um uh otherwise you know typical idtf rules apply in terms of uh queue management um and as a reminder as well um just state your name with the mic just so the the speaker knows who you are and the note taker can jot it down uh this is the notewell probably have not yet seen this this week uh because it's the first meeting um you're expected to be so familiar with the but what's here um i wanna take a moment to briefly uh call up the code of conduct um in essence uh what we are looking for is people to be you know professional respectful and courteous to others and how they engage and discuss technical details um we are an international standards body meaning that uh we do get people with different views different ways of delivering and different ways of receiving feedback um so we just ask as chairs to you know please please do your best to keep things and personal focusing on technical details um and uh and and and just just just be respectful generally um we've not had any issues in the past thankfully because everyone who participates in this group is our fine fine engineers exemplar and members of the ietf so hopefully we can keep it that way moving forward uh eric do you have anything else you'd like to add cool beans okay um here's some links uh the agenda is up it's also um here in the slide deck uh"
  },
  {
    "startTime": "00:04:01",
    "text": "we have a note taker thank you robin uh javascribe thank you lucas and here is our agenda uh first up we're going to talk about connect qdp and hd datagrams david's going to give those presentations and then tommy's going to speak to connect ip the unified proposal based on the two drafts presented during the last meeting and then as time permits we'll talk about uh two new work proposal items that is paying from ben and prioritization from lucas uh quickly pause here to see if anyone wants to do any uh rearrangements or refactoring okay if not let's proceed i will stop sharing and david i'll hand it off to you thank you chris uh let's ask to share slides all right can you see the slides yes we're all set awesome all right good morning afternoon evening absolute complete middle of the night everyone uh my name is david snazzy and we're here to talk about mask uh more specifically uh this presentation i'll be talking about both the http datagrams and the connect udp uh draft so ah sorry um first a quick uh recap uh for if anyone is new to mask in the room so the main goal of these two drafts is"
  },
  {
    "startTime": "00:06:02",
    "text": "to build connect udp which is like connect which is the tcp method for proxima sorry the http method for proxying tcp but for udp and uh on in our you know discussions of requirements over the the now two years almost that we've been working on this um we want this to work over all versions of http and across intermediaries and when we're working over http 3 we really want to leverage the quick datagram frame which is an extension to quick version 1 which is currently undergoing asg review and since as we started working on this this was all in one draft but we realized that there were other features or applications such as web transport that were interested in using datagrams of http but not specifically in connect udp so we split it into two drafts so some other working groups could depend on the http datagrams draft without depending on the connect udp draft so earlier in april this year we had an interim to focus on http datagrams and we kind of redesigned the everything uh after and had some discussion on the list and then we merged some pr's which was great and then at the next itf meeting we re-redesigned everything again which is also great uh but you know it is causing quite some churn in the drafts so hopefully our goal today is um to if we're redesigning things again fairly you know reach some point where we have something that everyone likes so we can then move on from there because there are folks who have this uh in production and it'd be good to get to a place with the dresser more stable if we all find a design that everyone likes um so as of the"
  },
  {
    "startTime": "00:08:01",
    "text": "connectudp draft 6 and http datagramsdraft5 we have three working completely independent implementations right now the uh cloudflare quiche one the ericsson one and the google quiche one uh and both google and erickson have cliented servers and cloudflare has a client and we reached successfully drop with all of these at the hackathon last week so good news uh things work [Music] then let's see where we were kind of based on these prior meetings so a big read a part of the redesign that we did back in april was to have a strong and tight coupling between http datagrams and http request streams so think of it like a sidecar where the main motorcycle the main thing is your http request which in quick for example those are on client-initiated bi-directional streams and the idea is that datagrams all are associated with one such stream they don't exist in a vacuum and that makes it a lot easier for everyone to reason about datagrams and where they live in you know regards to http semantics we also landed on the capsule protocol which is a way to send information end to end between endpoints as a even if there are http intermediaries along the way and the capsule protocol is as simple as you can kind of get it it's a sequence of tlvs it's uh inside the data stream and by data stream i mean the for http two and three what's inside data frames and it's uh in http one that's just the the the mainstream of data for a connection uh and additionally one specific capsule that we define is the datagram capsule that carries an"
  },
  {
    "startTime": "00:10:01",
    "text": "http datagram and in particular that's useful for versions of http that work over tcp so http one and two because you don't have the quick datagram frame there so that's how you convey http datagrams for those versions and then in terms of encoding for the quick datagram frame the like what at the quick layer is the payload of a quick datagram frame starts with a warrant so i rc 9000 style variable length integer which has the stream id divided by four and kind of the tweak of that encoding is because client-initiated bidirectional streams which are the request streams in http 3 are all divisible by four so we just divided by four and that saves some bits and finally because that encoding could you know potentially change that on the road and also changes the semantics of what we see in quick datagram frames which didn't have semantics before we negotiate that with an http 3 setting all right um now where are we today so we had some good discussion on the list last week thanks for kicking things off empty and one of the things that we realized there is while there are some parts that you know we're reaching good agreement on such as most of what i just talked about the um bits about um extensibility and how you demultiplex aren't quite clear or you know quite full agreement there so i'm kind of gonna walk us through what we're trying to do with those uh what our requirements are and kind of explain the current design and how we could potentially change it um so yeah i'm gonna go through that apologies if this is kind of a long ramble it is the complete middle of the night over here in california but i will try to be"
  },
  {
    "startTime": "00:12:00",
    "text": "as clear as possible um feel free to jump in especially with clarifying questions uh but then once i have gone through some set of slides i've definitely left a lot of time for discussion to make sure we get something that folks like all right um so this is a set of extensions that have been discussed in or around the working group of protocols that use http data grabs so to be clear i'm not saying that let's not try to figure out if those extensions are a good idea or if there's something we want to build they're just random ideas that exist and because they're out there and some people are passionate about them maybe like we should make sure that the protocol is extensible enough to allow building them down the road so we're you know eventually going to build connect ip and there is interest in being able to compress the ap header on connect ip um similarly in connect udp some folks have expressed interest in being able to speak ecn or you know if there is ecn between the proxy and target to be able to convey that on the encapsulated path between the client and the proxy or similarly if you if the proxy receives an icmp packet that refers to that five tuple being able to let the client know about that is an extension that someone wants to build otherwise there is interest in doing path mtu discovery for http datagrams so because the quick datagram frame can't be fragmented it has a maximal payload size so an mtu for datagrams and there is interest in being able to figure out what that is uh and that would be an extension so ben has a presentation about his proposal there in the end as time permits section so i won't need to go into too much detail but there's interest in doing this at the htp level as opposed to at a higher level and then over in web transport there's discussion of conveying priorities"
  },
  {
    "startTime": "00:14:00",
    "text": "where potentially instead of just you know you you can always prioritize uh any data as you're sending it but being able to tell your peer how you want to prioritize it is something that we might want to be able to do for you know different types of data grabs so the the reason i kind of selected these extensions in particular is they right now we're building you know a way to send http datagrams uh which you know okay we're sending these data payloads um but it sounds like there is interest in being able to send multiple different types of payloads at the same time and that means demultiplexing so let's say if i'm sending you know a connect ap um uncompressed full ip packet uh and i'm also sending one that is compressed i need a way to tell my peer uh oh when you receive it this one is compressed and this one is not um so that's where we get into demultiplexing we need a way to tell between these different formats that we have on the wire and you know a simple way to do that is by having an identifier that you send at the start of each packet but um what the the big question here that has come up on the list is why do we need to care now um can't we just say this is extend these are extensions we'll deal with them when we're done and that that is absolutely a reasonable approach we want to keep the core protocol ideally as simple as possible but we want to make sure that we don't paint ourselves into a corner we want to make sure that when we go to build these extensions we don't look at what we have and go oh if we had just done this bit slightly differently we would have been able to extend this easily but now we can't so i think it's valuable to have this discussion right now before we publish this to make sure that whatever the extensibility knob or the extensibility foothold if you will that we need is in the core protocol"
  },
  {
    "startTime": "00:16:03",
    "text": "so that you know as our favorite thing is a good segue into kind of requirements what will we want for these extensions um so the actual one second coffee so the the first goal for for this specific one is this idea of demultiplexing we can have multiple formats that coexist simultaneously and we want uh the receiver to be able to differentiate between them another requirement is you know we we're working across intermediaries here and often intermediaries don't get updated as often as endpoints so as we've seen you know with other protocols at the atf the fewer uh machines you need to update the more successful your protocol is likely to be take you know it was a lot easier to deploy quick than ipv6 for example because you know if you only need to deploy the modify the endpoints instead of everyone along the way you're in better shape so what the way that applies here is if we can have a way that we can deploy extensions by modifying the client who wants it and the proxy who wants it without having to modify all the intermediaries that's a big one another requirement is there is some interest like the mtu discovery extension for extensions that apply to multiple protocols so i'm saying protocol or application independently i mean like what sits on top of http datagram so that right now the main ones we have in mind are connect udp connect ip and web transform uh and there is some value like this one isn't absolutely obviously required but if we have a way to write this once and for all of them that could be useful uh and then another requirement that we didn't really set off with in the first versions of http datagrams but that became very clear this year was that uh we want to make this"
  },
  {
    "startTime": "00:18:00",
    "text": "mechanism optional um there are implementers that don't want this feature today and really want to get things out the door as simple as possible so they really want to be able to pretend that if we build the system into the core spec uh to pretend it's not there so that means you know not only optional to implement sorry but also that they don't need to reason about too many concept concepts to be able to implement the core spec and then a final design requirement is what i've been calling zero latency extensibility which is the fact that were to be to allow using extensions in the first application flight i'm gonna i have some slides to explain into more detail what that means exactly um all right so on the topic of you know supporting extensions uh one important property here is if something is not mandatory to implement or if it's an extension that means that not everyone will implement it and one of the design properties of http is when the client wants to send its request it doesn't know the full feature set of the proxy it's talking to and you can't use settings to negotiate feature capabilities because there could be an intermediary between the client and the proxy so and that's a common thing across all of http that is one of the design constraints that we kind of inherited from designing deciding to build mask over http and waiting a full round trip from the between the client and the proxy to get the ttp response which could negotiate the support for an extension is unacceptable like we're in 2021 latency is the most important like performance metric for pretty much everything we do and we need a way to be able to use things optimistically and fall back you know if they're not supported and without everything breaking we can't but"
  },
  {
    "startTime": "00:20:01",
    "text": "we can't burn a full round trip to to wait for these things um all right so what what do i mean exactly by zero latency extensively well what's your latency setup uh so this is a pretty standard scenario where you're just doing the client wants to do connect udp to a proxy and then inside those udp payloads it wants to speak quick to a target server and one of the design choices we have in connect udp which technically is also possible in connect but is you send your connect udp request and alongside it maybe even in the same packet you can send an http datagram that contains your quick initial to the target and if the proxy accepts it it'll send a 200 okay back to the client and at the same time it'll receive that quick initial and send it over to the target if the proxy decides to reject the request it'll just silently drop that quick initial so there's no harm no foul but you've just saved a round trip between the client and proxy you don't need to say request response and then send the datagram you can send it optimistically knowing that if for some reason it's denied it gets dropped not the end of the world and again that that is user-visible latency for that end-to-end quick connection between the client and target that is um being saved so big win there um so now uh ian what's up on the last one so um are you i'll just go back one slide a few minutes so um my understanding is this just requires the core functionality of of the draft not the like any of the optional functionalities is that accurate or am i missing that's correct yeah this part is just a standard one i have a another diagram in two slides with with extensions okay i just want to make sure i understood correctly of like which portions of these um scenarios that you're trying to enable like require the extensions and"
  },
  {
    "startTime": "00:22:01",
    "text": "which dome thanks absolutely that's a great question that is perfectly without any extensive vld multiplexing required tommy all right hello cool i think the audio is working now um just just to jump in a little bit to respond to ian though as we've been looking at the different options for how you communicate like if context are optional and stuff that does have an impact on how you send the early data and like what capsule types are allowed so it's just something to keep in mind like this should be possible with any of the setups but sometimes there are constraints on what you can send in this first flight depending on how you negotiate extensibility yeah i actually have some slides to discuss this in uh coming right up thanks tommy um so uh the kind of sorry the order of the slides is kind of a little bit of a mess i'm kind of jumping back and forth and i apologize for that um so as we were saying some of these extensions they want to be able to send multiple formats so what's the simplest way to do that you put an identifier at the start so when you're receiving you parse the identifier and then you know which uh which format like what parser you should use to parse this datagram like is this just a udb payload or is this compressed or does this have some additional data at the start at the end um and but if we're making this optional you end up with an interesting conundrum which is is that identifier at the start present or not should i be parsing this identifier or should i just assume that it's not there um and that that question is where some of these complexities for that extensibility design come from because in the original version where this was"
  },
  {
    "startTime": "00:24:01",
    "text": "always there it was a lot easier but but turns out we can make this work um so then this is what tommy was alluding to a little bit now this is when we want to do extensibility but without a latency cost so let's say you're a client you want to talk to a proxy and you want to use some extensions um your main goal is to do connect udp to a target uh you still want to you know send you have your end-to-end quick connection to your connect udp proxy but maybe you want to use let's say the ecn extension um you just don't know for sure uh if the proxy supports it at the moment you start so you kind of send your request and mention you know potentially with a header or something as part of your request that you're also going to want to use extensibility and you still send your http datagram you just need to make sure to let the proxy know that this datagram for example doesn't have a demultiplexing identifier at the start so there's no confusion even if the proxy does or does not support this extension and then it can you know seamlessly without a round trip forward that over to the target and let you know with his response that extensions are supported on this connection or sorry on this uh for this request all right so what is the current design we have and that's you know as we're always not set in stone uh what we have uh today is uh we been vinnie go ahead sorry slight understand can you just clarify a little bit um absolutely so the proxy actually doesn't know anything about that extension in that scenario you described it just allowed that extension to work and end is that correct uh so let me clarify that's a that's a great question uh"
  },
  {
    "startTime": "00:26:00",
    "text": "what we mean in this case by end to end because there are multiple ends in this protocol and it does make things confusing in this case an extension would be between the client and proxy so the client and proxy have to know about the extension so let's say for example in the ecn scenario this extension would allow when the proxy is reading udp packets from the target those could have ecn markings on them at the ip layer between the proxy and the target and this extension would allow the proxy to communicate those markings to the client as it's forwarding these encapsulated udp payloads like as it's sending a udp payload you could say oh this one was marked ect 0 this one was marked congestion experienced so in the context of that extension the ants are the client in the proxy they're the ones that need to know about the extension but if we have an intermediary in the middle between the client and the proxy that doesn't need to know about the extension ted uh so a kind of a clarifying question here on what you do then if you're expecting an extension uh to pass through the proxy and head on toward the target and i'm thinking here about rfc 5795 style robust header compression for ip headers so you can imagine using that in two different ways one of which is saying hey i'm going to use rock and my compressing ip headers to you the proxy or to tell the proxy that you expect rock to go end to end to the target so in that second case i assume from this design you wouldn't negotiate the extension through the proxy it would then just take the the connect ip uh payload and treated like it it was an uncompressed ip um packet send it out and if it failed that was on on the client for not"
  },
  {
    "startTime": "00:28:00",
    "text": "understanding that what it was sending is that approximately correct uh yes actually sorry ted some feedback um please use headphones or mute um so the extensions that are like transparent to the proxy in the sense that are client to target are kind of out of scope here because they're they'll work but the proxy doesn't even need to know so what i'm all the extensions i'm talking about are extensions between the client and the proxy um like for example in this case if they're extensions inside this end-to-end client to target connection the proxy doesn't need to know or care there and it can't even because they're encrypted inside quick so uh when i say extensions here uh to clarify i'm specifically talking about extensions between the client and proxy where both the client and the proxy know about them thanks for the question that was clear uh that mostly does i do think that there there may come some cases where the the proxy has to know that what's going on isn't malformed because obviously uh ip with rock headers and and presumption of context looks different from standard ip um but it probably doesn't need to do a lot to support it but i i think this is probably not the main topic so let's move on no thanks i think there's there's utility and value there but yeah that's not what we're trying to specify what i'm trying to specifically solve in in these set of slides thanks uh ian clarifying i think comment the proxy here is what echo referred to as a forward proxy and the target here is one or more reverse proxies machines application front ends yada yada that received the traffic right like just to clarify like like the target could be like one or more machines and we kind of don't care because it just should just all work because like reverse proxy providers need to deal with this stuff themselves is that accurate"
  },
  {
    "startTime": "00:30:00",
    "text": "uh absolutely so in this scenario let's say you're using uh connect2udp as uh like an ip blinding service um it from from the client in the proxy's perspective the target is just an an ip address on the internet and a udp port that you're sending things to and that you're receiving things from there's worlds of complexity and servers and machinery behind the target but from our perspective we don't know we don't care the is this could all be running on a raspberry pi on a corner or it could be you know backed by a giant google data center completely oblivious to us we don't care um but the the from the client's perspective there could still be an interpreter in a proxy which like in general the client doesn't really need to care all it knows is it's trying to connect to a connect udp proxy with a given authority um what we just need to build here is make sure that the if the entity that wants to deploy the connect udp proxy wants to deploy that behind a front end in other words behind intermediary that needs to work in practice it doesn't really change the protocol much but it just impacts some design requirements like the fact that we can't rely on settings for everything for example all right so all right why can't we rely on settings here because i i think i i'm not i'm i'm missing why we can't rely on settings no no no no on the contrary this is really useful because these are trivial points thank you the so you're in a in a given http deployment uh it interpret areas are pretty common so like take our setup we have the google front end and then we have back ends so mapping to like the the terminology here the google front end is an intermediary and the google backend would be the one implementing connect udp and which we the one that we list as the proxy and"
  },
  {
    "startTime": "00:32:01",
    "text": "that could be the egress to the internet in some scenarios the settings are hub by hop at the http layer whereas requests are end to end in that scenario where the end is the proxy you could be running something into that um but the request could flow through an interpret area and we have folks in the working group that wish to deploy that this way uh in particular for web transport so to walk back let me try to reset this in in more terms that like i am you know that are very focused on hardware infrastructure so like in this case like google is running like a target which is like you know probably at least two and sometimes three layers of load balancers uh stuck in in front of like an application front and you're saying that the first load balancer needs to make sure to communicate the right settings for all the things behind it because otherwise like bad things could happen right is that yeah so well yeah so so let's say i think the web transport example is perhaps a better one where you have a front end which is also a load balancer and you know you talk through that to a myriad of back ends as a client you don't even know that there are you know front-ends and back-ends you just know that you like the front-end sir and the or in other words the interpreter served you with the appropriate approved for the tls certificate and when you send your requests you gotta reply maybe you went through that to a different machine but potentially let's say some of the fleet uh supports the this web transport with extension some of it supports web transport without extensions um and the front end doesn't know all of these so like supported protocols features extensions of all of its back ends necessarily uh and so it can't synthesize a setting frame for you that covers everyone in the back uh you need to go and send the request and get a response to know fully what they support but just to like kind of really like slice this down to like the very"
  },
  {
    "startTime": "00:34:00",
    "text": "specific points so the so the the server the the um the load balancer needs to know whether say connect ip connect udp connect or web transport is supported because the way you load balance those protocols is just like transformatively different from standard http so like you're just not getting away without like having that knowledge of the the terminating um load balancer but still so i think so to clarify that um you need to and that's that's specifically what we're picking at so let me just clarify on what you're saying the intermediary needs to know how to proxy http datagrams and especially for web transfer where transport has other custom things that need to be proxied such as like custom unidirectional streams for example so the interpreter needs to be aware of this but if we for example want to add in the future an extension the the goal there is that this front end that was modified once to speak web transport doesn't need to be modified every time we want to deploy a web transport extension um that is the kind of distinction okay that makes sense to me i i think i i think we should just move on because i think we've kind of gotten it down to the point where i just wanted to get it to which is the yeah the load balancer does actually need to know like whether web transport for example is supported but it's it's valid to say once web transport is supported that maybe there's some other stuff you want to like um tunnel to the to the actual application front end that you don't want to make every single hop in the middle be aware of um so why don't we move forward through what the extensions are and then maybe that'll clarify everything for me thanks cool well dude thanks no no that was that was a great point um and that was what i was trying to get across but yeah taking the time to actually state it clearly really important so thanks for your help um so yeah the the current design how do we do this um it introduces the concept of datagram format types which is a okay this is the semantics of"
  },
  {
    "startTime": "00:36:01",
    "text": "my payload so for example in our current drafts connect udp registers the udp payload datagram format type and the client starts off by recall sorry by sending a registered datagram capsule that says hey i'm going to be sending udp payloads on here um good like those are the ones that you need to when you get the payload you then put that you write that into your udp socket to the target um and additionally we have this de-multiplexing mechanism which is inside this uh box on and so you you negotiate using the secu's datagram context's http header and the draft introduces the concept of a context um and the idea is when this is in use every datagram starts with a warrant that is a context so for example you could say okay i want to register the udp payload context and i want to register a udp payload with two bits of ecn at the start context for the ecn extension or you could register the icmp context extension so then when the other side receives um a an http datagram it knows it'll read this warrant off the head and then say oh this is just a udp pillow let me put this into my udp stack or this one oh i need to parse these first two bits for ecn or this one's kind of a separate sidecar of icmp or something and it knows how it can parse and what actions it needs to take based on this demultiplexing identifier at the start um and mt mentioned on the list that this is he he says that this is overly complicated i don't disagree and actually we had a good conversation with him and others uh last week and the fundamental um thought that mta got across you which i i think is very very reasonable is like"
  },
  {
    "startTime": "00:38:02",
    "text": "concepts aren't free when you meant a new concept you have to keep it in mind forever and if you ever got anything wrong in the definition of that concept you're gonna like pay it for for many years um so if we can get something even simpler that's better so so we have an issue to track that um and we we kind of came up with a new design that i just wanted to run people with and then as soon as i'm done running through that i'll have a slide and then we can like jump into a full discussion sorry so the idea there is um i initially thought that like the datagram format type was our best extensibility joint or foothold if you will to enable all this extensibility but it turns out after some more thinking and discussion um it's possible to get the extensibility we need without introducing this concept and um i think that that's a nice property we want to have an extensibility joint um but we kind of already have one in the protocol it's capsule types so as a reminder capsule is this client to proxy protocol where you just send a sequence of tlvs and the t there this type is something where you can mint new one they're registered with viana and that's a really good extensibility joint because uh proxies and clients will drop any capsule that it doesn't understand so a new extension protocol anything can define its own capsule um and so this this pro 115 the idea is we remove those registration capsules uh because we don't need them in the core spec we remove datagram format types then we we add some text to say okay if you're an extension you'll be able to use these capsule types as your extensibility mechanism um and so what what the with this potential design what you say is you send a header uh as part of your request"
  },
  {
    "startTime": "00:40:01",
    "text": "to when you're the client and you wanted this demultiplexing functionality you send that header and if the proxy replies with that header as well it means okay we both have like support at least one of these extensions we think there's value here we want this demultiplexing so when we've negotiated that now every single http datagram starts with this the multiplexing variant which we call the context id the idea there is that context id maps to a context for example let's say if you're doing a p compression and you're like removing the ip addresses this context would be a struct somewhere in your memory that contains the ip addresses that have been removed so when you parse the incoming datagram you could put them back in before you feed it into your ip stack um and the because we know this we wanted this idea of zero latency extensibility we add the concept of data we add multiple capsules for datagram for to to convey the ones that explicitly have or do not have context so the idea there is while you're negotiating the headers so as a client before you've received the headers you can't send the like regular quick datagram http datagram because there could be some confusion about whether that warrant is present or not so until you know for sure and have gotten the sort of response you use these separate capsules that are crystal clear they're self-describing in other words and once you've known the response then you know you both agree on what the format is you can send this or not um yes ian the shape of what you're describing sounds good one kind of wording suggestion or comment is we're using the word demultiplexing here at any point do you actually mean like an intermediary or a proxy or something like that taking a single stream and then sending it to two entirely different locations or are you really"
  },
  {
    "startTime": "00:42:01",
    "text": "talking about like um i might even call it like format conversion or compression or something like that where basically you've developed like a better formatting for whether it's like ecn or ip compression or whatever and the thing that terminates the proxy is responsible which is in some sense and hop um is responsible for saying like okay i understand this format and i know how to convert it to like you know edp or ip or whatever i need to pop out the other end and so it's it's kind of it's a format conversion it's a compression i don't know like some other so or is it actually multiplexing like a load balancer differently so so no that's a great question i i'm using demultiplexing to say [Music] separating between multiple things inside an incoming flow of things so that's horribly unclear what i mean by that is it's the goal isn't to say like let's say you're a connectudp proxy it's not to say these uh these packets go here these packets go there it's let's say your connect ip it's this packet came here that is an uncompressed ip packet let me just put it directly into my kernel ip stack this one is a compressed ip packet let me first decompress it and then put it into the stack so you're demultiplexing into your application parsing logic not too necessarily a different target i think what you're talking about david this is not demultiplexing in the sense of going to a different piece of hardware it's demultiplexing in the sense of going to the piece of software that knows what to do next with it yeah um exactly i i just wanted to kind of make sure that everyone was on the same page about that sorry another clarifying question please no no yeah those are extremely helpful thank you um cool and so what does this means in in terms of the like design requirements that we're talking about earlier um the so it's clear that this has"
  },
  {
    "startTime": "00:44:01",
    "text": "this has this multiplexing for the definition we just talked about it supports this well it's clear that intermediaries are not involved as part of this at all so we are you'd be able to deploy this later without having to modify the intermediary which is really cool um it allows you because it's done at the http datagram layer to have extensions such as benz mtu discovery extension that you can write once and then use for web transform connect udp and connect ip uh it has this view latency property thanks to that separate capsule but i want to insist a little bit on the optionality because that's been the sticking point for folks who don't want this concept to who don't want to implement it so i did i went through the mental exercise of if we took all this like the multiplexing context all this body of work and said and ripped it out of the http datagramsdraft and created like an http datagramscontext extension draft what would be the foothold that we need to make sure the we can like ship that later and the only thing we need is those capsules that allow you to send things before you know what the server supports and so right now instead of having just a datagram capsule uh in the draft you would need so you would move the datagram with context capsule to that extension draft but you're still left with two in the base draft there's the datagram one which might or might not have the context and the datagram without context one so conceptually you know maybe we if we split it out of the draft and we didn't want to have the word context anywhere in this draft we'd call it unextended datagram and we would just require implementations of http datagrams that are not extended to parse both of these capsules in the exact same way whatever you do you get one or the other you just take the payload and you parse it as a payload um"
  },
  {
    "startTime": "00:46:00",
    "text": "that's the only kind of foothold we need and an extension can kind of slightly tweak these semantics and say well the datagram capsule might have the context id if it's negotiated but the unextended datagram capsule never has it and that'll that's the little the kind of the hack that allows you to send things during like the um before you've gotten the responses so my general idea is we've managed to pare this down to kind of the simplest thing possible the only extensibility joint that we require that is a burden for implementation that don't care is that they need to understand two capsule types instead of one and put the exact same machinery so you would put you know two switch statements back to back uh when you're parsing um and i think yes that is the end of my long ramble about uh all these things now uh let's bring everyone in for discussion um in particular are there requirements that we've discussed here or that we haven't discussed that you care about and that you want or are there properties of this system that don't work for you for some reason or do you have any other random thoughts comments questions uh and i think like we have some agenda time i haven't been keeping too much track carrick you can tell me how much more we have but we have some time allocated for discussion here please come on up to the mic line go ahead eric so i think we're going to try to time box this to about 15 minutes and when we get to the end of that we'll see where we are if we've completely face planted we'll go from there and if we haven't then that's wonderful so let's try and keep comments as short as possible to let everybody get some time in vinnie go ahead uh you know ideally the the less complex this is the better so i like the idea"
  },
  {
    "startTime": "00:48:01",
    "text": "that you've kind of constrained some of these things um i assume just standard all the proxy authentication methods will work with with mask is that a correct assumption uh absolutely so mask uh in particular in this case uh connect udp but all there are things we're discussing are traditional http requests and responses uh like so connect udp now we're using extend connect we'll talk about that in a minute but you can send any http header alongside it including the pre-existing authentication headers so absolutely that just works that way empty not all right um i can't even see myself i can hear and see you though it seems it's uh dark where you are as well very dark mode as alan said so um this discussion do you mind going back to the last slide where we talk about the requirements uh this one or the one that has just this just has a summary right you've got a couple of points here um and there's there's a lot here that's bound up with the design of the different protocols that i can be using the h3 datagram stuff uh and i've been sort of convinced back and forth throughout your discussion of all of these things about the the virtues of some of these other things but ultimately uh what i think we want here is the ability to send a stream of data to the other end bi-directional and associate a bunch of datagrams with it and that's it the ability to fold stuff back in the ability to add extensions the ability to identify that this particular datagram belongs to this particular subcontext"
  },
  {
    "startTime": "00:50:02",
    "text": "is something those protocols can deal with and if the intermediary understood that protocol then it can participate in that if it doesn't understand that protocol then it probably has no business in participating in that protocol and we can have a much simpler design here and probably a much simpler design all over if we just have those capabilities that means no capsules period and that that would be something that i think we could probably make work so uh let's pick on that um one of the and actually i didn't talk about this in the slides because that part has been in the draft for a while um so we have a datagram capsule and the goal there is to be able to send datagrams over versions of http that aren't http 3 and a pretty common deployment model that people have talked about here is that you're going to have http 3 from the client to the first intermediary in other words your front end and then it's common for folks to use let's say http 2 from the that intermediary to the proxy and if as a client you're sending your datagrams in a quick datagram frame the intermediary is going to have to convert those into a datagram capsule to be able to send it to um the the back end in other words the proxy and i think that the idea here or at least in the draft as it's currently written is you have a capsule that is the datagram capsule and the interpretatory speaks that because it's going to need to do this conversion and and then kind of you're done that way you don't need to reinvent this datagram capsule for each protocol um is that what you're suggesting i'm i'm actually suggesting that we reinvent them because that"
  },
  {
    "startTime": "00:52:02",
    "text": "it's not reinventing them i think the idea is pretty simple uh but the the protocol that the the intermediary speaks that does involve folding datagrams into the stream or pulling them out again on a hot by hop basis is something that can be negotiated on a hot by hot basis this is something that what transport already does you're you're talking about lifting stuff out of these protocols that are specific to those protocols and and putting them in in a framework and then imposing that framework on everyone who uses datagrams in http and i think that's a poor choice so that makes at the end of the day were the question there is do we want to have a common way to do this across protocols or do we want each protocol to do their their out uh my general sense and i see more people getting in the queue so um is it feels silly to have everyone reinvent the same wheel uh when like suppo folks seem to like capsules because you know how can you get any more simpler than a sequence of tlvs um but yeah i i see that we're we have you and i don't necessarily agree on that one all right i'll jump to ben in the queue hi i uh there's a lot going on here i think that it is getting a little confusing because we're talking about multiple layers that are really quite independent here so i think a lot of people following this presentation um may not have have caught that the the datagram format types are pretty much unrelated to the capsule discussion um that they they run end to end and are not connected to that"
  },
  {
    "startTime": "00:54:00",
    "text": "um i do think that we need to be clear that there are there are two kinds of intermediaries that we're actually discussing here we're discussing essentially smart intermediaries and and sort of dumb intermediaries so we have smart intermediaries that that can do this kind of http version conversion magic with interleaving and de-interleaving to convert to like merge datagrams into a tcp stream or something we also have dumb intermediaries that just forward things directly and both of those are fine but the the case that gets you in trouble is dumb intermediaries that are trying to talk to an h2 back end so imagine that i'm an intermediary i've advertised h3 datagram support to my to to the clients because i do support h3 datagrams but uh there's one of the back ends that i talk to is h2 only a protocol comes in i don't even know what that protocol is i don't know if it uses capsules and so i can't forward these datagrams and i also can't signal that the datagrams have failed that's the that's the case that worries me the most uh and it i i will just float that if you think that all of this is too complicated um you know this complexity a lot of this is because we're effectively reproducing a lot of the functionality of web transport in my view because we need it and so if you think this is too complicated uh i i would suggest weighing the alternative which would be to run all of this over web transport all right thank you ben ecker"
  },
  {
    "startTime": "00:56:03",
    "text": "all right um so i think perhaps we have some disagreement requirements which is i don't understand how you get into the state then suggests which is to say you have been configured with the you'll be you've been configured with the url and settings of a of an endpoint that you're connecting to that endpoint that should not happen if there's a distribution embed suggests in which the european configure with that and then the back end doesn't work simply should not happen but you should not be configured with it and if it does the answer is within an error so it's not like only discovery here is happening in settings because we're not discovering like it's not like we're discovering that you can use you know compression we were talking about a specific service which configured the client either via some mechanism it was advertised by the server so what i'm saying is don't do it say simply not configure system that way and the problem will go away so um the the word intermediary appears in this document on 30-ish times it should appear zero times and the right answer is that the um that the front that the front end the thing which you initially quit connect to should um advertise only things that make sense and if and it is its responsibility to translate the things that make sense to it things make sense behind it and so i i i guess i i'm persuaded that any of this machinery is required um so i i guess that and so so i i think that would be my put um and um i i i think that probably that is that's preparatory to like any discussion of how to actually implement the functionality you should see the desiring here thanks i mean that's uh in the sense that um you know folks want to deploy this behind front ends so intermediaries uh one potential design is what you're saying is we terminate everything at that first hop and conceptually then there's no more intermediary because you say that any protocol that supports http"
  },
  {
    "startTime": "00:58:01",
    "text": "datagrams must kind of terminate that request it can send another request behind it if it wants but conceptually those are no longer the same one i don't think that particularly simplifies things and my main concern there personally is that it means that now you can't anytime you want to extend anything you need to modify the front end as opposed to just the client in the back end and given you know software update cycles aren't always the same on front end and back ends you that could prevent you from deploying extensions down the road and that so that's why i would prefer an approach where some of this is transparent to intermediaries which then means that there's a document needs to acknowledge that intermediaries exist i'm sorry i need to repeat that argument so the so let's say for for example let's focus on web transport folks want to deploy web transport on back ends through a front end i think that's that is going to happen um and there are two ways of doing that you can either say the request is end to end from client to back end and there is an intermediary or you can say what so that's like the design in the draft right now what you're proposing i think is to say the the front end terminates the request and if it and it then it creates a separate disconnected request from the front end to the back end um and so in that what that means is then you no longer have uh discussion of intermediaries in the http datagram's draft because then you have ngb intermediaries from client to front end and from front end to back end separately but then there is no sharing of state or anything between them but what that means however is if you want to add any extension to web transport you need because the middle intermediary needs to support support"
  },
  {
    "startTime": "01:00:00",
    "text": "that extension you need to modify it as opposed to only having to modify the client in the back end does that make sense that helps yes i and what i'm saying so i think what i'm saying is one way to do is to terminate and the other way is to have a private arrangement between that between between the intermediary the front end and the back end which describes exactly how which parts of the channel are clear on parts of the channel are not clear and that um and that the what's happening here is you're hoisting all that complexity on the client um because you know because you don't want to make that privilege and they put this between the server and and and between the origin and the immediate area but the truth of the matter is is that there are many such arrangements in many different many different configurations and that um and like and i think the tri the the the attempting to dictate the behaviors intermediaries has proven to be extraordinarily difficult in both hdp and sip and that um it's far so important when you're modeling this b2b ways and that then the bbx whatever the heck they want and it's simply not a non-memphis standardization so yeah i think that i think that that actually imports into a lot of complexity later but anyway i think i i see there's a cube behind me um so i'm going to stop all right thanks um all right folks i've heard of building i think we're getting either close to or already out of time so uh let's all try to be a bit quicker uh victor yeah i just wanted to say that like at some level uh the ways just document the way this model's extensibility for things like connect udp is that connect udp is a resource uh and fundamentally any extension to connect utps that you negotiate is a property of an individual resource uh as opposed to property of the connection uh and to comment on akka's point i do things that of proxy to back and require standardization because in cases like cdns those are uh the objects that are operated by different entities"
  },
  {
    "startTime": "01:02:01",
    "text": "and even in cases that aren't they're operated by same entities uh there often the software is implemented by uh different people like for instance me running nginx as a reverse proxy uh so i do believe that we are fundamentally uh do need to standardize those and that works for http so that should work for uh mask or what so thanks victor so to clarify what you're saying uh you you're suggesting that we have http datagrams function end-to-end from client to proxy in such a way that we don't need to modify the interpreter to terminate things on the intermediate area is that what you were saying uh yes i i believe that like similar to things like http headers that those should be also my thing tells me to stop talking so i'm going to stop talking awesome thanks victor um alan uh yeah so the timer just expired um and uh there's been a lot of discussion going around back and forth i think at this point it's fairly clear that there's a lot of uh different hot takes on you know what the straps should do uh and and what the requirements are um and what the what the simplest thing is moving forward so what eric and i would like to do is propose a design team uh to sort of resolve these particular issues um followed by an interim meeting between now and itf 113 to present the results um and hopefully drive towards consensus uh so if you would like uh to participate on this design team uh please either like send eric or myself an email or just you know drop a note in the in the chat and we'll make sure you're on it um [Music]"
  },
  {
    "startTime": "01:04:00",
    "text": "david since you've been so instrumental in moving this strap forward um wondering if you'd be willing to to lead the effort um and and help make yeah happy too so uh folks if you want to like i don't know apply you know type dt plus or something in the in the chat i'll i'll make sure to gather everyone's names uh and then we can have a side beating sometime soon um so or that are you can i better than i will help coordinate logistics uh to make it easier for you all to focus on the technical details rather than uh dealing with time zones and whatnot um so um thank you um uh in the interest of time al and lucas tell me if you have uh clarifying questions that still can be asked or um or you still like to ask of course you can ask them but if the things that can be punted to the design team uh later on uh i'd encourage you to do that all right thanks um all right uh lucas you're still in the queue yeah i just i just want to say that the decision like people have been arguing about getting rid of capsules but if we do that we're back to where this draft started is hb3 datagram the whole point of adding capsules was to support datagram over http 2 which was a use case people wanted and hb1 as well so if we're revisiting that it would make me sad but um and i'd want to know why and we can have that discussion in the design team or later ones so thanks cool um thanks lucas um all right um let me see uh where was i right so i had another question uh for this draft about uh wait no that's uh there was an"
  },
  {
    "startTime": "01:06:00",
    "text": "alternate proposal and a discussion on reliable datagram but i think i'm going to punt this to after that after the design team because there's no point going even resolving this until we know next so let let's kind of switch gears and talk about connect udp for a bit um so where are we with connect udp so the connect udp draft was kind of on hold for a while um while we were you know redesigning http datagrams uh and then we kind of since we landed on a vastly different design for http datagrams i took some time to update connect udp to reference that and also to update some of the discussions we had in the past and the the main change there is that um we connect udp is no longer the connect udp method it is now the connect udp http upgrade token which is the registry of things you can use with upgrade in h1 or with extended connect in h2 and h3 so we said we now say connect udp relies on extended connect which is uh rfc 8441 and h2 and a draft that's currently in the http working group for h3 and the idea is the server sends a setting to say i now allow a new pseudo header which is the colon protocol header and so you send a connect method with with a colon protocol and you send that with connect udp so that was the one of the major changes to the draft which we had discussed pardon me in the previous meeting um and it kind of simplifies things and people are saying that it'll also be easier to deploy given existing um infrastructure and then another important change was configuration of on the client so let's say you're you want to tell your web browser for example to use this connect udp"
  },
  {
    "startTime": "01:08:01",
    "text": "uh proxy uh before you would just you know give it a host import and now we say we use a uri template so at the bottom of the slide here i have like three random examples of how you would connect configure the uh client and conceptually what it means is that you send the target so the target again is the server that you want to proxy to in the uh in the path uh pseudo header uh when you're sending it and the important distinction there is so in almost every http method under the sun the authority is the authority of the proxy and then the path is how you tell what you want you know your actual target what you want to talk to connect was its own beast uh where in the authority it kind of in the authority instead of having the authority of the proxy you had the authority of the target of the duality sorry the host name and port of the target um a lot of folks were saying that that design choice for connect was odd and we didn't want to replicate that for connect udp so here we're back to a more traditional http design where the authority header contains the authority of the proxy you're talking to and then the target is encoded in the path um so right now we have in the draft is a uri template for this um uh so that said um the ui template was something that i forgot who proposed a few atf's to go uh when i went to implement this for the hackathon last week it was way more of a pain than i thought it ever could be um so for folks that i have read the rfc on uri templates they're very complicated ways of encoding uri templates and i mean it's okay don't worry it's not like anyone has introduced security vulnerabilities by having mistakes in"
  },
  {
    "startTime": "01:10:00",
    "text": "their parser before and so my thought was do we actually need a uri template here because the really cool properties that we rely on is the property that we have a your uri for configuration but it doesn't necessarily need to be a template because if we have a uri for configuration it means that the scheme is decided at configuration time and that also conveys the um authority of the proxy at configuration time which you obviously need and it allows you to rely on the path so for example you could have behind the same authority multiple paths for proxying and you could pass in you know as a http query parameter like the user name or whatever you fancy um and so the question is do we want to uh how do we send than the target post import that you want to connect to do we send it in the path with a uri template or do we say no the path is reserved for like just configuration elements and it's send in a separate header um i initially thought the uri template was really great but it ended up being way more complex to implement and that wasn't great and i'm not sure we should replicate this uh the so ui template really made sense for something like dough because it allowed you to you know just type in your query into like curl and get um a response like directly from the account which was really neat that's not something you're going to want to do for connect udp and the other property is when we so in the connect ip draft tell me we'll be talking about later we decided to mimic connect udp at the end of the day let's try to keep them as close to pos together as possible but the ui template parameters were different so i thought it would be really cool that you could configure your mask proxy with one configuration string but if you're using a ui template you can't really or you need all those"
  },
  {
    "startTime": "01:12:01",
    "text": "parameters in there so if we have a uri for configuration and not a template and we use headers you can then reuse them for multiple mask methods which i thought would be kind of neat so i personally would be inclined to switching to headers what do folks think about that empty here and why would you move resource identity to a header sorry the we you still need to wait like 10 seconds before your mic starts working can you repeat the beginning of that please so um i i guess the question that you want to ask here is what resource are you identifying here are you identifying a generic resource that's got the ability to connect to anything such that having different ip addresses um in the url would be a mistake or are you identifying a resource that has generic connectivity properties uh anyway and that's actually that that is exactly the question that we're trying to answer from a like so i was asking it in terms of like practical you know wine coding matter you're asking in terms of like conceptual matter but i totally agree it's the same question do you are we saying that we are like the the resource were you know in http terms the resource that we're going to is that the part of the proxy that handles connect udp is that the resource or is the target the resource and if the resource is the target then we want this to be encode like the target host and port to be encoded in the path if the resource is the proxy proxying capability"
  },
  {
    "startTime": "01:14:00",
    "text": "then we don't want to encode it in the path we want to encode it in a separate header uh that's the question we're trying to answer here yeah but might you want to have different access control depending on the destination that you're going to that suggests a uri i mean you can perform access control based on those other headers as well right you can do all sorts of interesting things with editors but when you start to use those headers to identify resources then they're no longer really headers anymore i i agree and and i guess conceptually i'm saying that maybe the the resource isn't the target the resource is the proxy inc capability um vinnie a couple seconds here uh can you just elaborate on how you envision header parsing being uh simpler than template parsing like i didn't understand that point they both gonna have the same kind of parser type bugs would happen in both right um no uh and that's a great question i guess i should have been more clear uh so right now on the client um so i need to parse the uri template uh so the the uh you you're gonna have to run some code on the client which as input is going to take the configuration and the target so let's say your configuration is a uri or ui template that's how you refer to the proxy and and you're going to take like the at the moment your browser is saying i want to connect to this target over there so you're going to take those two bits of information and combine them into an http headers frame and so"
  },
  {
    "startTime": "01:16:00",
    "text": "right now what you need to do is parse the ui template uh in order to like the technical term from that rsc is to expand the ui template into a fully resolved uri and so you're gonna need to if you're using a uri template look at the line at the bottom you're gonna need to understand that that that is like a level three uri template where you're gonna have to say okay well my authority is proxy example.org port 443 and my path is slash mask question mark target host equals 1.2.3.4 ampersand target port equals one two three four and that's that parsing that you need for a ui template whereas if we use the uri regular uri for configuration you wouldn't need that because you would take the uri and you would parse it just in order to split the authority off from the path you put the authority in the art authority pseudoheader you put the path in the path to the header and you put what separately you got as your target ip into its new header and your target port into its new header uh that also makes parsing on the server on the proxy side easier because now you don't need to go and parse some of this to get the ip address you just say well i look at this header and there it's there i don't need to split it out in any way echo oh right i'm waiting i forgot um so i mean i guess i don't feel super strongly about this but i also don't think that the arguments you're offering are very persuasive um no you have an s509 parser so like i don't think like i mean i don't think like the additional security like like like overhead of personal ui template is like is like that bigger crisis um i i i i didn't know i do i do know the comments but how complicated it is i think i thought i thought lucas's suggestion that maybe your profile level one would be fairly persuasive um the um"
  },
  {
    "startTime": "01:18:01",
    "text": "perspective like which i mean is not necessarily terminative the the header is wrong um i mean the verb is connect the the resource is the thing you want to connect to and if if the if there if the if the um if what you wanted to say was um that the thing you're connecting to is somehow the proxy then that reaches the proxy then the verb should not be connected to something else um and you know we already have this worked example of regular connect which is how this works um so i i guess you know that's like not disposed of necessarily um you know one could argue that http should not have been designed the way it had been designed but um but like i think you know for trying to if we're aiming for aiming for some full so i think that like i think like the argument you're offering that like this is like a pain in the ass like i think someone has a merit but i think the argument that like you know um that it's that that like philosophically it should be that i think i no i i agree with you uh i mainly care because it was a pain to implement at the end of the day that's what i'm trying to minimize for i'm an implementer the conceptual aspects of http are not my personal main concern ben waiting for audio okay uh so just to remind people uh uri templates uh mandate full unicode support so uh a uri template can contain any unicode code point which then has to be uh escaped and normalized down to the uri car set um that happens after substitution so you can have supremely weird uh interactions here like a you know like a rtl reversal unicode code point that like sometimes appears depending on the template contents or like there's unlimited weirdness there also ui templates can template any part of the uri you can like template the scheme you could have like template the port number you could have like the connect udp port target port port number"
  },
  {
    "startTime": "01:20:01",
    "text": "actually be the origin port number or you could have be a sub domain of the or even part of a domain you could register all 65 000 domains like anything is possible with uri templates um it's just a little bit of a warning i'll just note that there is an intermediary there's a middle ground option here where we say that that everything has to go in the uri and we actually specify the uri structure a little bit rather than just templating it cool thanks uh tommy waiting for audio cool um yeah so i think i agree with what people are saying um implementations that support dough already need to support uri templates um people who are doing mask probably also support dough so it shouldn't be too much of a new lift um to ben's point about weird uri template types i mean i think we you know if it hurts to do that don't put your things in the scheme we should probably have some constraints here to say like hey we're already using the scheme we're already using the authority in the port so like you can't put your target there sorry for connect udp i could i can see where you're coming from here but when we go into connect ip as you alluded to and how we want to kind of align these i think it's a stronger argument for why these properties are part of the resource because you know in something like connect udp i could very well have a generic vpn that doesn't have any constraints on what i'm connecting to it's totally open-ended and i have one that only forwards sctp packets or whatever and like those are very reasonably different resources than i'm"
  },
  {
    "startTime": "01:22:00",
    "text": "accessing and so i do think the logic is clearer there but then you can kind of back apply it into connect udp and say yeah this really is the resource you're connecting to and if you wanted to split up your server to think of it as different resources that you're accessing have different access control that way it it would make sense so i think we should leave it in the uri and maybe just add some constraints to the crazy things you could do with a template that are just wrong okay uh thank you yeah sounds like from the folks in the mic line there's some interesting keeping this in your eye templates all right moving on to our next and final issue for today um in so in connect udp since now we are uh so for for h2 and h3 we use extended connect uh with uh the pro the colon protocol uh pseudo header uh the method is connect the protocol is connect udp what do we do for http one um right now for http one we use uh the upgrade mechanism and we so at the end of the day this mimics websocket which is the only standardized use of extended connect that i'm aware of and so we say okay same as what socket you can do connect udp over h1 by using upgrade but the question is what method do you use because when you're using upgrade conceptually you don't look at the method you just look at what you're upgrading the only kind of purpose is to say oh what happens if you accidentally hit a server maybe who doesn't support upgrade like what flavor of failure would you prefer to have in that scenario um and so right now the connect udp draft"
  },
  {
    "startTime": "01:24:00",
    "text": "says you use connect with upgrade websocket says you use get with upgrade um which one should we use here i personally don't have an opinion uh do folks have thoughts all right well if uh no one cares we can uh keep it as we have it today in the draft and we can always uh change that later uh martin so if i understand correctly um if if we ran into a server didn't that didn't uh understand upgrade then we would just end up sending datagrams that would become random bits somewhere and a tcp connection coming out the proxy whereas with get it would just sort of return a 404 or something correct um let's see well with get you would end up sending a get with a body which is technically not allowed uh so yeah i guess that that would probably be it where with get you would end up well not necessarily a 4-4 because someone could sure yeah yeah some error code i mean that seems strictly better than like this undefined behavior with connect not undefined but just the sort of spewing random bits out yeah well i mean uh from uh and actually uh so connect uh you send a uh http one connect you send an authority without a path whereas here you would send connect with there would be a flash in there uh and now you know it's it's always hard to imagine what kinds of bugs exist but someone would"
  },
  {
    "startTime": "01:26:01",
    "text": "probably sending what's with this flash to get at her info or something so i'd expect that it would fail spectacularly at the dns resolution or trying to parse the ip stage as opposed to trying to create an an outbound tcp connection um just to that something well i i don't know we need to like analyze the failure path here but um and you know other people written more hp departures than me but like i mean i would just say just whatever has a more deterministic and less goofy failure path would be the way to go here thanks i totally agree because what we the new thing we build will work whatever the connect the method we use it's just if we hit right so maybe maybe we just need to do some homework and hit a bunch of existing servers with what it was this would look like and see in what way things things fail uh eric it seems like if we're going to be using extended connect for a bunch of things and we may want to be going to figure out what we're going to be happy with living with long term there and pick something and be consistent i guess another option here would be a new method like connectx um agreed i think we should be consistent between connect udp and connect ip and other things uh i would prefer not to create a new method because that's always work and um but yeah let's let's definitely be consistent uh empty so one option here is to ask http biz what the answer is because this is a they currently are examining in some part when with the http 3 integration or extended connect maybe this is a generic problem for http"
  },
  {
    "startTime": "01:28:01",
    "text": "and not one that mask needs to preempt that sounds great to me uh okay uh unless someone dislikes that idea i'm gonna take the action item to email the http list asking them what they think um and i see some plus ones in there perfect all right um and this brings us to the end of this presentation uh thanks everyone for listening and uh good uh good luck until dawn for everyone who's with me on the west coast all right thanks everyone and over to you tommy all right okay hello everyone um i will be presenting uh a new unified draft for ip um ip proxy support for http all right so uh connect ip i think we've heard this many times bounced around the working group before why why is this different and mainly the difference is that we have had many different versions of the proposals from different authors and over the past couple months those different authors and myself have tried to join forces and come up with a single proposal for what connect ip should look like so yay for unification so just to recap"
  },
  {
    "startTime": "01:30:00",
    "text": "the motivation for all of the connect ip work in general we want to be allowing you know truly generic ip proxy through an http proxy not just what we get from connect and connect udp which is limited to tcp proxy and udp proxy and this if we look at the requirements document which was adopted and worked on by this group a lot of these use cases are what we traditionally think of as vpns whether those are kind of just a user using a vpn for privacy or remote access into an enterprise site to site vpn that's a lot of the driving use cases that constrain the space but you can also think of this as just a connect-like proxy for an arbitrary ip protocol and to that end you can have a lot of similarities to connect and i think as the authors looked at collectively a lot of the differences in perspectives were because we had some perspectives coming from the purely vpn side and some coming from the uh side of saying this should be a connect protocol for arbitrary ip so i think we've tried to reconcile those two worlds and end up with something that is fairly simple and straightforward so as we discussed um with the authors as we were coming together here we um agreed on a couple things as the scope of this so you know right now it's defined as an extended connect protocol mirroring connect udp we believe that if connect udp changes its approach this should also change its approach so we just want to keep those things aligned as much as possible we want to follow the best practice there"
  },
  {
    "startTime": "01:32:02",
    "text": "for kind of simplicity getting the base of what connect ip is the proxy always is dealing with entire ip packets that are contained within the content of http datagrams compression could be done in some future draft but the base definition is always entire ip packets then another key thing that the authors agreed upon was the fact that it sounds quite simple when you think about it the connect ip document should be concerned only with things that exist in an ip header itself and that's the kind of the unit that they are operating on so the different endpoints can request and assign and route based on fields that exist in the ip header so that's the source address that's the destination address and that's the next protocol we could also add other things in if people decided it was necessary but these are kind of the core elements that make sense what is out of scope is trying to do any ip header compression now that should be an extension things like icmp signaling we agreed should probably be another document um that would be useful extension to have both for ip and udp connect methods and there are also fancy things we could do in which we could get a bit more next protocol aware and understand what we do for different port allow lists for different vpns but that should also be an extension okay so what actually is defined in this document and it's not too much thankfully first there's the um the upgrade or protocol token connect ip which mirrors the stuff that david was just talking"
  },
  {
    "startTime": "01:34:00",
    "text": "about as connect utp so that's really just a lift and rename currently it's also using a uri template to be able to scope things down if necessary now in this case it doesn't make sense to talk about a target name and a target or a target host in a target port because there are no ports instead you have essentially the target host that you want if you have one or you can have none and a target next protocol if there is one or it can just be generic and get anything there are a couple different capsules defined this is using capsules uh really as just a negotiation mechanism so that you can after the time of request over the stream be able to add and remove addresses and routes and so there are three capsules defined only there's an address assign which allows one endpoint to tell the other side you can send from this address when you want to generate a packet you can also have an address request which is i would like to send from this address or this subnet and then in the same way that address assign can define the source address for packets a route advertisement capsule defines the destination that a site is allowed to send so you can say you are allowed to send to anything essentially that falls within this routing table i'm going to give you and then the last thing that's defined in the document is currently it's called the datagram format because the http datagrams document still has these um but essentially it's just saying the thing that goes within a datagram is a full ip packet that's it extensions can do something else if they need to um one one of the concepts in here that"
  },
  {
    "startTime": "01:36:01",
    "text": "we discussed a lot that isn't necessarily um immediately obvious is that there are uses for limiting the routing and being able to communicate that you aren't able to route a full tunnel so a lot of the the simplest vpn use cases that we think about are essentially when a client device receives a single address or a prefix to send from and then it can send to everything in the world however there are a number of different use cases where that can be more restricted maybe you have a split tunnel vpn or you're just only trying to reach something very limited on the other end on the other side so there are different ways you can limit the scope of a tunnel you can in the request specify that you only care about a specific target and protocol either endpoint can also limit what the other can send from with its address assign and then the route advertisement capsule itself can limit the set of destination addresses that an endpoint can send to and besides being a good mechanism for access control and being very clear about what's going to be allowed this also allows a proxy um that's operating a bit more like a normal connect or connect connect udp proxy to be able to share source ip addresses between multiple clients so if one client really only is trying to talk to a specific host or a specific subnet um maybe it's it's not trying to open up a completely uh full tunnel scenario then you don't need the same type of ip address provisioning requirements that you would as a normal vpn so that's essentially the protocol as it stands i have a couple examples here so we can just see how this looks so the traditional vpn setup i have a client behind my proxy my vpn"
  },
  {
    "startTime": "01:38:01",
    "text": "server it has some ip address ipc that can go out to the world and talk to any arbitrary address so the way this would look is the client starts at connect ip currently it registers this datagram context that may and hopefully will change then the other side can just send back to 200 and say hey you can send from this address and you can send to pretty much anything um you want for that address family and then at that point the two sides can send datagrams back and forth to each other and those are full ip packets so this is quite simple you could also have a case where the client is only interested in talking to a single host on the other end maybe it's just trying to open up a sctp flow for some reason and in this case the protocol works exactly the same except you can get back um a very limited route um that only is the thing that you requested to connect to and at that point the payloads are still full ip packets but they're only going to be ip packets that are going to that one particular host and then the last example we have here is just showing um how you could use this even if you're connecting to a specific host that you can receive different address families to send from because we like supporting both v4 and v6 and you can get a routing table that supports both anyway so that's the protocol um sorry no not all that is supposed to be proxy not server right just making sure that no no yes trying to keep things less confusing i'm"
  },
  {
    "startTime": "01:40:00",
    "text": "confirming that you mean proxy there it should yeah we can change it to proxy it's it's the server from the for the master connection i understand that but really yes yeah i mean i think proxy's probably the terminology i've seen in current gdp it might be good to unify that as well to make sure we're not going yep that's a good point thanks all right so that's essentially the scope of this we've tried to keep it very simple so i think the questions to the group now are is this the right starting place for doing connect ip and if so is this ready to adopt or do we have other questions that we think need addressing echo yeah i think this is a this is a pretty good pretty good starting point uh i think it's uh uh probably good enough to adopt um uh i sent some testimonial comments in email um last night thank you for using them completely because there's not like midnight but um or something but um actually i think it was more like you know three but um anyway um yeah i i think you know uh uh um you know these are all things we could hash out in some later discussions so i i think this is a good starting point great yeah and yeah and i did see your comments thank you for them i think there's stuff we can discuss um i think we can go either way on a lot of them yeah i'm not proposing to discuss it now unless for some reason the chairs are like in time primitive any other comments david um i just wanted to say like i'm i really i wanted to thank tommy for all the work he's been spending as editor to unify the two connect ip proposals here um i'm very happy we've that we've landed on"
  },
  {
    "startTime": "01:42:00",
    "text": "something that like works for everyone so just wanted to thank tommy for all the hard work here i'd love to see this get adopted now that we have like kind of one proposal with the backing of a lot of folks as opposed to like two separate ones pulling in different directions like we had at the last atf awesome thank you all right and yep it sounds like in the chat people are generally supportive of this so i guess chairs do you want to do something now or later yeah so uh thank you tommy for the presentation and we're gonna use the show of hands tool so everybody find this tab and go find where this is but effectively the question we're going to ask is is this a suitable starting point for working group adoption and you're going to be able to raise your hand if you think that it is or you can actively choose to not raise your hand if you think that it is not so we're just going to do one show of hands where you can choose up or down and that should be open now give it a couple of seconds for people to find the buttons all right so we seem to have pretty strong support for using this as a starting point would anybody who chose to not raise their hand like to join the queue and potentially give any thoughts or reasoning as to why they made that choice and we'll take that as a no so we will take this to the list and confirm on the list but thank you all for raising your hands"
  },
  {
    "startTime": "01:44:08",
    "text": "next up we have ben are you ready alright if you requested it's the one immediately to the right of the cue button we do not yet have audio for you either yeah ben you're muted okay how are we managing slides uh you can share them yourself if you click the little share preloaded slides button uh looks like a piece of paper yeah the button is called ask to share slides for us non-chairs indeed uh okay can somebody tell me where that might be the joint up left just to the right of that okay ask to share slides all right you should now be able to pick your slide deck and then you can advance at will okay great thank you okay lovely we see so uh this is about this presentation is about an individual non-adopted draft uh that that i wrote in response to some previous discussions about path mtu discovery"
  },
  {
    "startTime": "01:46:01",
    "text": "and it's it's very much premised or phrased in terms of the in terms of the current uh datagram format and capsule system so to the extent that the design team decides to make changes there this also would need to change so ping is an http datagram format type and pings flow between a client and an origin or we can also call it a proxy intermediaries if they exist don't care about ping they are again in the terminology of the h3 datagrams draft these are opaque datagrams and they look like this each datagram contains a an event number and some padding and the response contains the next number and no padding very very simple they can go either way once you've established a context for them they can be sent and echoed in either direction okay why the main purpose of this is inspired by connect ip connect ip in order to be a fully compliant implementation of ip needs to be able to supply some minimum mtu and so this gets tricky if you're running over a link that's already at or close to the mtu with any of the links on the chain between the client and and the back end have have low mtu then what uh currently the way this needs to uh the way you can solve this is by by sending that datagram reliably well okay so we can get to that in a second but uh but basically endpoints need to be able to detect that there's some datagram that like"
  },
  {
    "startTime": "01:48:00",
    "text": "the ip layer is is officially able to rely on so like this datagram is less than 1280 in ipv6 so it is guaranteed to be deliverable but actually it's not because when you wrap it in all of the mask overhead it exceeds the underlying wire mtu so we need to do something we need to change what we're doing but in order to do that the endpoints need to know something about the path mtu and because of the presence of intermediaries using for example the mtu estimated by the underlying quick session is not going to be good enough and there are even more complicated intermediary arrangements like when the the back end is actually speaking to an intermediary over http2 uh so there isn't even really a there isn't really a relevant transport mtu at that's on that hop but this is a very general anything that uses datagrams needs in general to know something about the mtu of that datagram path and also it's very very common to need to know something about the round trip times and packet loss rates and so it's a very general problem and so it seems appropriate to have a general solution so this draft is seeking work group adoption in mask although i don't think it's ready to ready for that especially given the given the sort of turmoil and the underlying draft i think we're going to have to revisit this i think it's it's most valuable as a as a test case so you know these are problems and this is a this is the solution that kind of falls out from from one set of design choices about how datagrams and formats work and i think that hopefully that can help"
  },
  {
    "startTime": "01:50:00",
    "text": "inform the design team as as they consider that design space you know try to figure out well what what are you going to do about these mtu issues do you want a solution that looks like this datagram ping or do you want something else and another thing that's important to note here is that in the design as considered here it's it's important for clients and servers to be able to identify when a datagram needs this kind of protection it needs this extra special end-to-end reliability because it's too large for the path mtu and be able to send it that way and right now we don't have actually a mechanism in the current drafts that that really allows that and so we've had some discussion on the mailing list about do we need a mechanism like this or do we need to require intermediaries to adopt some more sophisticated behavior in order to in order to make it more make it possible to deliver those reliably or or indeed do we need intermediaries to to adopt a less sophisticated behavior that would enable that that end-to-end property so yeah that's all i have for slides magnus yes so i i think it's an interesting mechanism i don't think it really solves the the toughest case at all of the perfect discovery especially if you're going to run the plpd of your math tunnel you get the oh before i can tell if the actual flow is supported or not you're going to have a delay because first you need a probe what is the empty you supported and then you can make a decision about it so it's i think it has some significant downside to try to solve that issue but it may be"
  },
  {
    "startTime": "01:52:01",
    "text": "solving it faster of course means more complexities in the intermediary so yeah so there's there's this learning mtu is always asynchronous um you know it always takes you never know it before you start you always have to wait for it and the question is how long do you have to wait yeah but it's one cr cracks i think in this which is particularly the mask or any tunnel protocol in some sense in that you will know what empty you are for the first hop for the first quick cop in something yes you can quick on that on that first half yeah but not intermediate and forward until the end of the the peers let's say the mask appear that's the that's where you run into the trouble when you have intermediaries on the http layer so yeah but i guess it's for continued discussion of this i mean how we solve it and and i think it's one of these requirements that should be considered in the design team this quest is to include that mtu question there yeah and one thing that i would want to emphasize is i think this illuminates one of the questions that's um that's come up a lot with the design team like why can't we just use settings frames for everything um if you try to use for example if you try to use settings frames to communicate the the mtu of the h3 datagram so the setting says this this proxy supports datagrams up to this size then uh that implies knowledge of all of the paths to all of the back ends of that proxy so it's not just about compatibility with all the proxies it's actually also about all of the network elements that stand between them okay"
  },
  {
    "startTime": "01:54:08",
    "text": "ben we still have martin in the queue sorry martin yeah oh and um thanks for thinking this through i think if nothing else has been a useful exercise to exercise this as you said but um i guess it what i'm wondering is if you have been under if you have a protocol running over a mask yeah i mean typically these off-the-shelf uh protocols will presumably have their own plp mtud uh mechanism and they also have the advantage of not only probing the the mask mtu but also all the way to the origin server so um what is the actual utility of having this utility in mask itself sure so the fundamental problem here is that the iprfcs say that in order to be a compliant ip implementation you must have an effective mtu of at least 1280 for ipv6 and while transport protocols running over it are allowed or encouraged to use path mtu discovery they are also allowed explicitly to simply cap their datagram output sizes at 1280. if you never produce output greater than 1280 the ip specs say that you do not have to do any path mtu discovery and so if we want to be a compliant implementation of ip then we need to always provide functional delivery of packets of size 1280. that's a that's an actual if right we have the option of saying this is an almost complete implementation of ip and one thing that it doesn't quite give you is the mtu guarantees and so you actually need to do some some pmtud for smaller sizes"
  },
  {
    "startTime": "01:56:04",
    "text": "all right thank you ben and lucas is five slash four minutes useful or do you want to punt to next time i think i think i could squeeze in 15 slides in two minutes go for it cool oh no i'll push the wrong button uh i don't want to do that here we go uh okay um so this is about data ground priorities which is probably a low priority given what the mask working group wants to work on uh this was originally uh intended to be presented at the last meeting but got uh pushed off because we ran out of time hence why i just wanted to disease any time here to mention it and to see if anyone's really interested or if we don't care right now i have a draft an id um it didn't take much work to write up and it's going to expire soon so if no one's interested we can just leave it and maybe mothball it and pick it back up when when the time's right if that time ever occurs um so briefly there's a lot of background here we won't go into that but uh quick doesn't specify anything about prioritization of anything it says you probably should do it but uh it doesn't specify how the datagram draft that's now opposed to the uh w g lc is uh defines the frames but doesn't talk about priorities of them uh hp3 doesn't define any priority signals either and that's post working group let's call um and the the new mask http 3 datagram draft that we have also doesn't say anything so so we're kind of bouncing around we have different issues raising a different draft that have all been closed to say well you know the princess is in another castle kind of thing go go look somewhere else you've got people like pointing at each"
  },
  {
    "startTime": "01:58:00",
    "text": "other and saying well you know maybe we should but i think with all the drafts we have today we're fine actually we're not saying anything about priorities and so that raises some problems for anyone who's tried to implement something based on datagrams where they're being multiplexed with streams as well or even logical flows of datagrams might need different priorities and uh you know they have different needs and they need to be scheduled differently otherwise you know certain kinds of problems might happen so i wrote this draft just to get the idea out of my head this is based on the extendable priority scheme i don't necessarily think it's the only way to do things or the right one but it is a way um to do things uh we'll skip the the recap here the philosophy of this design is that datagrams may have a different priority than the stream that they're related to and this is only at the http layer nothing else so there's some flexibility here but uh sensible defaults there's no per context prioritization which kind of skips some of those problems that came up earlier um yeah the proposal is just a new parameter that gets defined a similar scale to this urgency parameter that's already in priority kind of decorates things and inherits from it this is all in the specification uh the question i was going to pose last time is should we adopt this but i'm thinking right now the question is who cares uh you know we could have an adoption discussion later on when people have actually read this um maybe mask isn't even the correct venue i'm happy if you know with whatever people might think if they've had any time to look at it so that's it thank you very much for your time uh i see tommy in the queue"
  },
  {
    "startTime": "02:00:02",
    "text": "yeah i have time for a clarifying question um you mentioned how you know explicitly this is a different priority than the one on the stream data just what is the rationale for not just letting this stream priority be the priority here because like for connect udp it's almost all going to be datagrams anyway uh it is if effectively allowed if if you say that you support this scheme as like a a server for instance and the client doesn't send anything the default is to inherit the stream's priority so this effectively just makes that abundantly clear that that people would go with that kind of flow you could equally say that without putting it in any specification okay all right um sorry to abruptly shut the queue but we're at the top of the hour at the end of the meeting and folks have to get to the next one so thanks everyone for your time comments so we'll follow up on the list with actions regarding the design team and um uh adoption of connect ip and uh we'll see you at the interim next meeting and on the list thanks all and thanks for notetakers"
  }
]
