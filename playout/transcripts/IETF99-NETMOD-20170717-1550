[
  {
    "startTime": "00:00:23",
    "text": "okay okay we\u0027re gonna get started you don\u0027t mind shutting the back door it so it sounds a little loud still out there from the break thank you welcome to net mod in Prague I\u0027m Lou burger this is Kent Watson we\u0027re chairs obviously and we have Michael Wang who\u0027s helping us out as have been helping us out a secretary as usual this will be shown again as usual we on our slide we show where you can find the different information on the tools page and that\u0027s the easy way to get to it you\u0027ll find that there\u0027s a jabber I\u0027m sorry there\u0027s a etherpad link and if you could join the etherpad and help us with collective note-taking we\u0027d like to take you that before we get into the session we have the usual note well but it\u0027s actually changed slightly the this was just updated based on RFC 81-79 being published some folks may have noticed the blog entry talking about the changes it\u0027s a new updated IPR policy for the IETF it clarifies some things the from my reading of it the most significant thing it does is clarifies what a contribution is and isn\u0027t basically if you say anything in a meeting or in a forum or even give any indication of your opinion that\u0027s a contribution the other thing it does is it points to an RFC the number of which I\u0027m forgetting which talks about if you don\u0027t follow the IPR process what are the steps a working group can do based on that that really goes to late disclosures this is a pretty fresh change it was just published in may may not have noticed that before you might want to take a look as usual we have neat echo we have audio and we do have some participants who are remote this time blue sheets are going around please sign sign them and again here is another way to get to the ether pad this is the longer form if you get to the tools page and click under minutes that\u0027s the sort of the easiest way to get there our agenda is posted we don\u0027t have any changes right now we did have some requested changes but we\u0027re going to just stick with it we have a couple of sessions so um at a high level the agenda is meant to be rather than going through all the working group documents "
  },
  {
    "startTime": "00:03:23",
    "text": "first on in the first session and then on chartered working group documents in the second session we\u0027re breaking it up so the first this session is primarily nmda focus with some other documents sprinkled in they may or may not be working group documents and then likewise the next session will be primarily focused on schema mount with some other documents sprinkled into it and this particular agenda has been ordered with the ACL draft being presented first so that the QA for the nmda would get at the end gives us flexible timing so if we\u0027re running at it short on time you know less than 20 minutes but if we have more time we\u0027ll be more okay from what\u0027s changed what\u0027s changed since the last meeting so we have one document that is sitting with the iesg although our ad looks confused by that maybe not so we have one document sitting with the iesg that\u0027s working through the process we have sixty eighty seven bits which is the guidelines document that\u0027s been returned from the IAS G primarily because of the update to NMDA guidelines that document that\u0027s come out the intent is is and we\u0027re going to hear more about this the intent is to take the guidelines and produce a distilled recommendation that ends up replacing the current section in sixty eighty seven bits and once that replacement is agreed to by the working group will submit resubmit sixty eighty seven for this we have a couple of documents that are in last call be good to take a look at those the last call was extended because it\u0027s overlapping with this week one of them the one in green is on the agenda the second one is not but please do take a look and send comments we have a bunch of other updated working group documents that we\u0027re going to be talking about over the next couple of sessions I already talked about sixty 87 this I think we talked about all of these except for entity so this document has been sitting out there for a while the authors thought the technical content the the hard part was complete but that it might be impacted by NMDA and and in fact it has them and the authors in github have a partial update already completed but it sounds like there\u0027s some work still left is there any of the co-authors in the room Martin who I think currently has the pen is not Andy is is a co-author but I think he\u0027s ducking Andy if you want to "
  },
  {
    "startTime": "00:06:23",
    "text": "say about this all right you would co-author an entity it\u0027s alright you don\u0027t if you don\u0027t want to say anything that\u0027s okay no I think the current status is that it it was checked by a couple people that it had the new objects that they wanted and I think now we have to look at what needs to be done to meet the new nm guidelines yeah and - Laura Martin we started editing and already push submit it so it\u0027s probably close to being ready okay that it\u0027d be great if we could see an update in short order so we can go to last call because I think I think all the issues had pretty much been resolved at this point other than you know and as you know City sitting business we talked about that already we do guidelines about so Tim karaoke can I just get a clarification sure please net so it looks like then entity will probably be the first draft that will see the data store guidelines if you will include it in are you talking about firsts a publication requests their first published I guess it will probably be the first publish then right or is it gonna be a small so there\u0027s been a whole bunch of internet drafts that have already been refactor to the format that MDA and so we\u0027re getting other working groups so that that work is like running ahead okay uh so I think we have good examples if you\u0027re looking just for an example and ones that are far more complex than this one this is actually a pretty simple model in terms of what we submit into the to the is G for publication I certainly hope that this is out very soon so yeah it would be the first one submitted by this working work okay thank you sure don\u0027t want less so actually it might be a good to some liaison statement to a different as do is doing like young models to explain our nmda right that\u0027s actually an excellent idea the one question I have a little bit maybe for you is is do we wait till we have agreement on the recommendation text from the working group which we don\u0027t have yet or do we go just based on the ad recommendation that\u0027s been distributed and maybe some other folks who work and other SDOs might have a view on this I know we have some folks from PDFs and folks who work in I Triple E where I can give us kid can\u0027t make a I Triple E statement but they still work there so I think we could do both right for example get an I Triple E iesg meeting this week and I forgot to mention that we could have an informal email because we have the contact then "
  },
  {
    "startTime": "00:09:23",
    "text": "one of our good text ready then we mentioned that so basically it\u0027s like okay warning it\u0027s coming that\u0027s a good idea so one thing I failed to do is to go on to etherpad and make sure we actually have people taking notes and etherpad we have just people raised hands if you\u0027re in on etherpad taking notes alright we need some people to jump in on etherpad please and take notes I am watching jabber though so I think Jim wants me to say something really I\u0027m lettin you start by saying your name ya William Lupton representing the broadband forum um so yeah absolutely we unwelcoming liaison telling us about an MTA but equally of course we\u0027re aware of it already and we and it\u0027s interesting that the maybe that it\u0027ll be applied to entity very soon because actually you know that is one of the the drafts that words are actually referencing okay great thank you I see we\u0027re up to eight in etherpad thank you for joining please feel free to join in and if you could put your sign and sign your name an ether pad in the upper right hand corner just so we know which name is which color so with the last comment I think that was a set up for the first bullet on this slide thank you we\u0027ve had one in Kim coming on the A\u0027s on it came in just recently and basically it\u0027s letting us know that this other organization the broadband forum is interested in reusing the work we\u0027re producing in the IETF and it called out entity as we just heard it also called out the alarm module the alarm module as it\u0027s been discussed a couple of times at the IETF privately it\u0027s unlist that one has gone over to see camp and we expect that work to be done there if you have any this this one is not asking for a specific response but if you have something you\u0027d like to discuss based on the noise on please just send it to the list with that we\u0027re gonna wrap up with milestones the I\u0027d like to highlight that one we have a few things are done we have a few things that are a little late but we\u0027re close and the entity we really need to figure out how to wrap up and so I\u0027m happy to hear that the authors are working that we might see soon see an update and with that we\u0027re gonna move to the next slot which is first presentation ACL okay so Mahesh "
  },
  {
    "startTime": "00:12:30",
    "text": "and I have worked on the enhancements from draft end to draft 11 so these Oh so so these includes basically support of combinations of ACLs of different address families and types and will also allow to state the reason why this was done there\u0027s also been inclusion of more match and action parameters and this was taken from after we got input from Netflix and there were also a lot of open issues that we found based on the review of a various Native models in so so these were opened up as as issues then with it and we documented it and we\u0027ve taken a eyes to implement this okay so why did we include support for if you\u0027ll address families so in the current model in graph number 10 if you see ACL type is not strictly checked so in an in an ACL you can have aces of v4v say and l/2 so this doesn\u0027t work for vendors who want to who can only support ecl\u0027s of a single address family type now this leaves if we haven\u0027t have a model like this this means that a vendor has to do strict has to do strict type checking and for most vendors this is not acceptable so what we did was to create so basically the model becomes very error-prone and we needed a way to fix that so what we did is that we took we focused on l2 l3 and l4 and we made different combinations of these types like different ACL types so when you have the exchange message you can specify which type the ACL conforms to and you\u0027ll only see part of the yang model that conform to that ACL type so there\u0027s no room for error anymore so [Music] okay so so what we did here was that we created so what I have on the right hand side are the identity feature and container statements for a particular ACL type and this is extended to all different ACL types that we support now the benefits of this enhancement are that you have very strict type checking "
  },
  {
    "startTime": "00:15:30",
    "text": "so for example if you support only be for ACL you will only see the header fields and ipv4 header fields that pertain to v4 ACL there is no way you can now configure a v6 ace within a way for ACL or an l2 ace so this also makes the model easy to extend because in case you want to extend it to have ACLs I don\u0027t know like an l7 ACL all you need to do is write the identity feature and container statement and that extends your model right away and you don\u0027t have to make changes to the main body of the model like you wouldn\u0027t have to do earlier so these are the identity and of these we have eight new types so since we focused on l2 and l3 you have a v4 HDL v6 the Ethernet ACL then you have a mixed v4 ACL I\u0027m sorry you have the mixed l2 and v4 ACL you have mixed l2 and v6 and then you have mixed l2 v4 and v6 and then you have something so we\u0027ve added something new for the any ACL so the ending ACL is basically a presence container that allows you to override your default routing policy so for example if you have a policy that says reject all packets coming in from I don\u0027t know some source you can have an any ACL that can say accept or accept only a certain subset of packets that come in so it\u0027s basically a presence container that lets you override any default policies you have on the Box ok the inclusion of match and action statements so this was nothing new so this is this was added after we got feedback from Netflix on because they apparently used these matches and actions so one was adding TCP UDP icmp and they also needed logging so this was just a small subset of matches and actions that we\u0027ve added there are there are a lot that are actually not present in the current native model that we have taken as an open issue some of the important items that we have as open issues are currently the model allows only a single "
  },
  {
    "startTime": "00:18:32",
    "text": "address and a single port to be specified in the address and port fields for source and destination addresses and ports and this is actually not scalable and it\u0027s not a good design because you\u0027ll have for one if you have only a single ace you have to have multiple aces representing a particular network that you want to accept packets from so most of the bigger vendors when I looked at their native models they support lists you know so so they will support a list of addresses or a list of ports and they\u0027ll support like a not equal to equal to or a range so this is something we are we are thinking of adding another bigger enhancement that we have in the open issues is stats collection how do we want to collect stats in on an ACL model so for example you have ingre stats and egress stats so currently the track number 11 it doesn\u0027t address this issue very well because you can even have stats that come in that are aggregated over interfaces stats that are per ace or ACL per interface depending on how much resource you have in teakamp vendors have different stats that are allocated so stats collection is one big issue containers for addresses and ports is another big issue the remaining issues are basically leaves that we don\u0027t have for like ICMP off or precedence things like that that we see in various native models so if we want to get a model that\u0027s you know that looks good and that\u0027s similar to a lot of the native models then we need to we need to add this in into the IDF model and make it competitive with other major models out there so so regarding the open issues there\u0027s going to be technical changes yes and actually adding the Santino\u0027s that needs some thoughts on how we want to do that yeah but I\u0027ve already gotten some ideas I\u0027ve spoken to various people okay so this one be the final version okay still how many people have read this version of the draft it is in last call so how many people have read this version a few okay and for those who haven\u0027t you know again please try to read it and provide comments and there will be another version well yeah we might at this point sent a message to the list saying that well we\u0027ll probably "
  },
  {
    "startTime": "00:21:35",
    "text": "send a message to the list saying that there is gonna be another version because it doesn\u0027t make sense to force folks to read it who would otherwise on not read it and then do another last call and try to get them to do it again so well let people know that doesn\u0027t mean don\u0027t comment don\u0027t read it\u0027s just that we\u0027re not gonna have a successful last call on this at this time and we\u0027ll do another one I\u0027m sorry Ben was asking when will the next version be available November November draft it 12 my history and Ani I think we should be able to do a little better than number I want to say within the next month or so we should be at least able to come out with an updated version and you\u0027re speaking as co-author yes this guide make sure everyone knows that\u0027s great yeah I mean if it really was November I know I be inclined to say okay is this one good enough but so that\u0027s good to hear that will have something you know a month thank you so I\u0027m not with them and I\u0027m going to be various talks it\u0027s worth cursed ones and updates on what changes we\u0027ve made to thee just let\u0027s go make it is that better yeah okay so so I want to give an update on on the datastore architecture draft what we\u0027ve changed there we think it\u0027s very close to completion actually so we would request people review it I know there\u0027s been some comments on the ATIS today I\u0027m not a chance to read through all those in detail but thank you for those and so weird lights are trying it finished fairly soon if possible so the quick reminder what we\u0027re talking about the whole purpose of the nmda architecture and the problem we\u0027re trying to solve is this separation between what an operator is asking your device to do I their intent the intended configuration and what is actually doing so the desire here is to very accurately reflect the operational state of device and to align the namespace of those as close as possible so that you can easily correlate between both the intent and the actual operational value as you\u0027ve probably all aware we spent a lot of sessions discussing and time different "
  },
  {
    "startTime": "00:24:36",
    "text": "solutions this problem I\u0027ve been invaluable ITF and we\u0027ve converged on this is the solution and the solution defines a new operational state datastore this has implications on the structure the yang models and they\u0027re not being simplifies simplified for nmda and I\u0027ve got a separate talk on on what that looks like and how it affects you and will also effectively be updating Netcom from restaurant as well that\u0027s what the pressure state datastore and there will be talks in the networking group covering those extensions effectively for those so we\u0027ve updated our canonical they doors picture and the the lines in rail effectively show you what we\u0027ve changed and there\u0027s nothing really this that\u0027s very significant here that\u0027s changed we try to align where information is feeding in with the origin metadata so the origin metadata is a way of annotating where data has come from so whether a values come from your intended configuration or whether it\u0027s coming from the system or is coming from a dynamic datastore or you come from a protocol so and we\u0027ve tied this up a bit and we\u0027ve tidied up the fact that dynamic data stores can feed in here as well and it could be one of those or multiple of those and they\u0027d be defined separately so this is summary of what\u0027s changed and this is since the - oh one version was presented in Chicago we also published an O - in the interim I feel that what we\u0027ve done is we\u0027ve improve the definitions of configuration of State and we spent a long time on this we\u0027ve pulled in clarified some the existing definitions of the existing data stores that defined in the net conf RFC so the intent here is this is a canonical definition of them we\u0027ve clarified the semantics of the operational state datastore in particular and got some refinements origin metadata and clarifications and XPath usage that wasn\u0027t in there before so I\u0027ll cover each of these four areas in more detail so as we\u0027ve said a long time trying to come up with good definitions and good terms but what can fuck what configuration is what state is or the different types of configuration are and we spent many hours discussing this to try to come up with terms that are both accurate and fairly concise and it\u0027s very hard tasks to define what some of these things are so as part of that we defined the term conventional conventional configuration data store which is like the start up and running and kinda that we have today and intended is also thrown into that category as well because it\u0027s sort of logical exists today even you don\u0027t see it we\u0027ve added a definition for learned configuration now that one is probably worth again I come a bit more detail and is worth thinking about bit more a bit more because some people have some concerns about definition so we could discuss that today and we got rid of the term static configuration which is good because none of us none of the authors liked it it was a bit misnomer because it could change yes as I said before "
  },
  {
    "startTime": "00:27:39",
    "text": "we\u0027ve pulled in the definitions of startup candidate and running and I am here just to have them all in one place rather than to change the meanings of what these dates are so we\u0027ve tried to clarify them provide extra text more accurate describe them but we\u0027re not trying to change the meaning of those existing data stores I ask you please you can to review these definitions carefully because once this has been published then hopefully there\u0027s be reference for quite a while going forward so getting getting good reviews that we appreciated so it\u0027s been first things discussed on the list one was the term of what configuration is and there was a concern about that the definition we were using differs from the one provided in net conf I think so we\u0027ve now tried to align that to be more to be more closely based on that and as you can see the text here the first sentence is based on the same as the net conf definition and what we\u0027ve actually really clarified here is that for in yang a configuration node is modeled by something that\u0027s conflict true and that configuration came from different sources the way I sort of like to think of this is the conflict true on a node means it can be configured rather than it it is going to be configured so something that could be configured through conventional mechanisms is how we are defining it the other one that\u0027s been more contentious is definition of learned configuration and this has been defined as configuration has been learned by a protocol interactions with other systems that is not conventional dynamic configuration so we\u0027re trying to find the label for the configuration data you might get from BGP or from one of your other peers systems in the case where they\u0027re overriding a leaf or a node that\u0027s in your configuration tree so an example of this might be a timer value you could statically configure or it might also be acquired through a protocol negotiation and so we\u0027re trying to identify your name to that sort of configuration comes into the system and also to make it explicit that it\u0027s not dynamic so the dynamic configuration is defined as what comes through any dynamic data store this configuration isn\u0027t coming through a dynamic datastore it\u0027s just coming elsewhere through the system and then a an open issue that we haven\u0027t quite resolved here is whether the learned origin can also apply to state note as well as so needs to be discussed my hunch is the art will be yes it can be that that the origin data is only about where data comes from and so it should apply there but that\u0027s the open question ma\u0027am it also what is your proposal for the handling of the term configuration in that compared at C are you proposing to replace it revise it delete it I don\u0027t know I guess we\u0027re "
  },
  {
    "startTime": "00:30:40",
    "text": "going to supersede it effectively that this would so we have here a new term definition we should be interested to decide how we want to handle the old term definition it can be deleted I mean in Netcom this RFC or the same can be used there too but copy and paste is not good which RC are you thinking about the Netcom protocol RFC so I think then it\u0027s a good question for the Netcom working group yeah but I assume you would have a proposal how to handle it so one option is that this document lists is updating that RFC and we can identify that the soul update is in the name the other option is that the documents that are headed the supporting documents that are going on in Netcom could do that so I would sort of defer to the negev chairs on how they would like to do that so there needs to be a discussion in Oetken for sure exactly it would be probably consistent to remove this term from Netcom this RFC and refer to NDMA RFC that\u0027s a fine solution but BK and then when you do the since that Biss will replace the other one that fixes the document sure that\u0027s perfect I you I don\u0027t think the semantics here is changing though so that\u0027s great yeah it sounds like a part of the plan proposed presumably as the net conf co-chair is a good one thank you and also add to that many times in drafts when they\u0027re importing terms from other drafts they specify which draft that are importing the term from so you know for the term configuration they could indicate specifically it\u0027s the old or the current Netcom RFC or the new revised Davis or I\u0027ve seen so it wouldn\u0027t be actually ambiguous in the terms of the draft ourselves so the second second set of changes is a refinement to the definition of the operational data store and in particular we wanted to clarify how defaults work in that data store because our intention is that we don\u0027t carry on using with defaults operational our aim here is to try and simplify devices and clients so the rather having this mix of different defaults you might support to try and converge and just have one one definition that everyone uses because it\u0027s a new datastore we\u0027re hoping everyone for work on the same thing so the idea here is that the defaults in a way don\u0027t apply to the pressure of state they\u0027d store the operational data store always gives you the values that are in use by the device so if the device is using a value whether it\u0027s a default always come "
  },
  {
    "startTime": "00:33:40",
    "text": "through configuration or some other mechanism then it logically exists and is a part of that operational state data store and hence normally if you query it you would get that data yeah David Lamm Patrick so I\u0027ve thoroughly hit my head on default values in schemas because it\u0027s not only the device that needs to be aware that the absence of the value is something different from the default value but it\u0027s also the client libraries and every single thing it passes through in the middle so I think there\u0027s a requirement here to kind of maybe not even have the default of the schema in the best case because otherwise you\u0027re still trading on thin ice yes so to answer in the particular case you\u0027ve got configure then a configuration node often has a default value associated with it and that configuration knows exists in the operational State they store as well so you have it often in the schema but Inlet what I\u0027m saying is in this case you would return that value if it\u0027s in use yes well I\u0027ve shown you Ericsson that\u0027s why we have the home with before sir draw RC because we couldn\u0027t agree how to handle defaults may be an operational we can well hope so because it\u0027s new it\u0027s a new date store nobody\u0027s got implementations of this thing most discreet Andy Biermann yet the reason for suppressing defaults was to improve the transfer efficiency yeah so if you have a whole bunch of stuff that\u0027s in the default value and you\u0027re wasting 60% of your packet with stuff that\u0027s redundant yes you don\u0027t get that efficiency so so now you\u0027re saying we don\u0027t care about efficiency we\u0027re gonna send all the values all the time no not quite so in terms of I\u0027ve said here we want to clarify what in use means I think we want to get a definition of in use that doesn\u0027t mean that we throw back a lot of irrelevant data but we try and find that so scope sensibly that the default values you get back ones you might be interested in so not a load of so if OSPF is turned off you don\u0027t return all the default values for OSPF that aren\u0027t of interest but it means that your nose gets turned on then you do return those values so that\u0027s I think we\u0027re trying to do is get up come up with definition use that allows well it seems that explicit mode is clearly not useful because you\u0027re talking about read-only data so it can\u0027t be explicitly set to the default value so only trim really matters which is if the nodes not there then it must be using the yang default and I think that definition is rather clear and yang 1.1 I don\u0027t understand why it needs to change now so the the other concern that I have is this ambiguity that if you don\u0027t return of you does that mean that the device doesn\u0027t know about it what does that mean the device is using "
  },
  {
    "startTime": "00:36:40",
    "text": "the default value now in the 19 yang says that if it\u0027s not there yeah you\u0027re claiming conformance to it yeah then it is using the default value no exceptions so if you\u0027re if you\u0027re well I want to get to this later but I think you part of the architecture that\u0027s that\u0027s completely lacking is a concept of conformance for data stores so I\u0027m reading a gang module I want to know what is a server that is conforming to this model supposed to do and you completely failed on on providing that information for data stores before we used to know this is candidate running and startup there were only three data stores there\u0027s no way to add new ones like the Acme operational data store which is now allowed so so really think it there has to be something in the yang module that that tells developers what the conformance expectations are and and the defaults as is it could be considered part of that but the problems that I\u0027ve been hearing about from customers with operational data is is how to make it more efficient you actually have not been a fixed yet because the problem with get is is if I get an entire list my NMS freezes while I\u0027m getting 10,000 entries okay so we\u0027ve had to add operations that make it much more responsive to iterate through a list and of course you need to iterate through a list without knowing the keys because operational data the keys change all the time so so I think you really should focus more on on efficiency because it especially with you know large routers which you have a lot of the getting lots of operational data is it needs to be efficient ok David Nutter again so unfortunately this being a completely new data store doesn\u0027t help with the defaults either because it\u0027s gonna be accessed using the same existing libraries and that\u0027s where the problem really is so if that library doesn\u0027t allow me to act even figure out whether the value was specified or it\u0027s coming from a default which does exist our library is where I can\u0027t tell if I had a default had it had a value or whether I\u0027ve got the default value then I can\u0027t actually access this bit of information so so I think your suggestion is better to return a value even it\u0027s the same as the default I\u0027m saying that if if you want to signal this bit of information whether the value is actually in use then you need to put that bit of information somewhere that isn\u0027t the existence of the value because the existence of the value is not something that you can reliably test for I\u0027ll chat with you after it\u0027s gonna show you a question yeah well angle Erikson and I don\u0027t think even the "
  },
  {
    "startTime": "00:39:41",
    "text": "absence of the value doesn\u0027t really mean that the default is enforced maybe some other protocol remove the default value and that\u0027s why it\u0027s not there can\u0027t we have that situation I mean the case our thinking of is if one of your demons has crashed and it\u0027s not returning any data then then effectively that doesn\u0027t mean that those values are now and turn into the default values that just there\u0027s no data to be returned there and either you hang the whole response or you\u0027ve got to compromise so that\u0027s why I think it\u0027s sort of nicer for a semantic point of view to always return the value it\u0027s in effect and I do take Andy\u0027s point and that\u0027s what we try to find the balance between is you don\u0027t want to then flood the messages with a lot of a lot of noise stuff that you don\u0027t care about so it\u0027s trying to find that a reasonable answer we can I think part of the problem is that yang tries to cover default values both in configuration and operational state and in fact in these two cases the semantics of the default values is quite different so yeah that\u0027s why it might be difficult we\u0027d like to come up with some reasonable definition and and handling of defaults I think in terms operational we regard the default value and yang models being guiding to the reader rather than meaning anything else so rather than affecting the actual date is returned so just a piece of information for you and for the working group or now it\u0027s actually taking some of the QA time but that\u0027s okay cuz this is Q\u0026A so it\u0027s okay with us if it\u0027s okay with you and the work group you have to what you\u0027ve had 20 minutes what okay I think that\u0027s okay so the third of the four sort of major changes we\u0027ve made on a major changes or refinements is to origin metadata and here we\u0027ve refined with and to remind you your enjoy metadata is about where the values come from so the idea here is that you can differentiate that the operational values come from configuration or it\u0027s come from a protocol or the system is instantiated that value like a system created interface for example or maybe it\u0027s been overridden by i2 s so that\u0027s the idea here is you can identify where this data is coming from and this applies to all the a nodes in operational and currently we\u0027re focusing our the thoughts Westing operational state datastore but it\u0027s possible it may apply to other data stores as well so with intended there\u0027s the thought that we may standardize some templating mechanism and again this same sort of idea of annotating where that has come from might work quite well with that to say whether a values directly the configuration or its templated expand it for example and finally our intent is that this is optional to implement because we appreciate that this could be quite expensive so so the "
  },
  {
    "startTime": "00:42:42",
    "text": "new set of origin metadata identities expanded so we\u0027ve got intended dynamic system learned default and unknown and these match the definitions we\u0027ve got in the only part of the dock intended is from the intended datastore dynamic means it comes from any of the dynamic data stores and these are identities so there\u0027s multiply dynamic data stores of IRS has different levels for example then they can be using separate identities underneath dynamic to identify which one of those potentially the system identity represents effectively configuration or state that\u0027s coming from the system itself so you\u0027re automatically configured protocol or a loopback zero interface that always exists for example would be system learned is this one that we discussed earlier that\u0027s slightly more contentious about theta it\u0027s learn from a peer and this is essentially stuff that isn\u0027t dynamic so it\u0027s anything that has come from another system it\u0027s not configuration it\u0027s not dynamic default value is a value that comes from the schema so either an explicitly for value in the schema or where you might have a description stain that describes what that value is circe fault and we\u0027ve got a catch-all unknown so the systems that can\u0027t identify where piece of data that comes from they can at least actually indicate that there is still some open questions I think in terms of what the best way of encoding this information is how to optimize for that I think one of suggestions at the moment is to mean that when you report a given node it was the same as the parent you can omit it for example rather than having to report every day for every tree and the last one to cover is refinement to XPath context and in essence I think what we\u0027re suggesting here is the fairly intuitive interpretation that if you the XPath expressions for data this in operational will resolve two nodes in that data stock they won\u0027t resolve two nodes in the configuration data sort of example XPath expressions are run in a configuration datastore will continue to resolve to the same datastore that they\u0027re in and the last interesting one is that we\u0027re saying that input output parameters for notifications are PCs and action statements again they evaluated in the context of operational so that doesn\u0027t mean that those operations necessarily have to just apply to operation they don\u0027t and we\u0027re saying that when parameter is evaluated that\u0027s the scope that they\u0027ll be evaluated in and the alternative to that is we don\u0027t even you don\u0027t like that would be to have datastore specific semantics for those those operations to identify and they apply to different particular data stores okay so open issues there\u0027s been as I said there\u0027s been a few more nailless to discuss about learned effectively origin and meaning of learned data and this "
  },
  {
    "startTime": "00:45:44",
    "text": "conversation about defining in use these two refinement in terms of what that means and also how to optimize the data return so we don\u0027t turn to too much noise there\u0027s been a question about guidelines should they be in the body this is for the guidelines for writing new datastore should that be normative text or not I think there was in the body before ban why we moved it to the appendix so I think he\u0027s meant to be text rather than a normative statements see could you go back a couple slides there\u0027s one thing I didn\u0027t like since I certainly expel sexist me thank you very much name is sue Harris I\u0027m interested in except for the drive identities I didn\u0027t find that when I walked through the text this morning dynamic data stores except for derived identities can you explain that maybe I just don\u0027t understand what you meant when you were running through that legs I\u0027m not sure I do understand either so I think is there might be a typo effectively what its meaning here is the dynamic identity itself is probably more likely to be abstract and that rather than returning that at your dynamic data store you derive from that you and your eternity right value okay in your yang model that\u0027s the generic I found thee they never get anything good stuff it\u0027s it\u0027s a generally defined identity it\u0027s it\u0027s not specific to a dynamic data store it\u0027s just specific to those identities so so the so the dynamic density that\u0027s in that file yes is generic yes you had a dynamic data store you would augment those identities well right from them effect so derive from those identities and with your base and you\u0027d end up with those being you know different young module associated with the only datastore I mean that\u0027s good I just didn\u0027t find you asked me to read the draft carefully I\u0027m reading it obviously with the IRS background with dynamic in mind and I never found that second sentence or the exception it is in it is carefully laid out in the appendix in the appendix for a femoral data source was very helpful and very useful and the XPath I think if I understood it also is generic and can work with dynamic data stores as well as yes I think so yeah so I didn\u0027t find any problems nicely done thank you thank you David on Twitter this is actually a good solution for the earlier key fault problem to make it similar to this I think because if you move away from whether the value is present and actually make it an explicit metadata on the item then you can just put have the bit there whether the values in use and then the system\u0027s actually using it and then you\u0027re done "
  },
  {
    "startTime": "00:48:46",
    "text": "so and then you\u0027re saying that if no value is returned by definition means it\u0027s not in use it doesn\u0027t matter whether you\u0027re returning about you the question whether it\u0027s in use is gonna be answered by the metadata so obviously you should return the value if you\u0027re using it because that wouldn\u0027t make sense otherwise but if you\u0027re not using the value it doesn\u0027t matter if you return one but you should put in the metadata better it\u0027s not in use okay so Tim Curry Nokia I think the problem with that is I think one of the reasons for the the default value as stated by Andy was that you were trying to save space yeah yeah so if I\u0027m sending metadata back must send the value back right I just want to clarify that that wasn\u0027t actually a purpose the purpose of the way we allow flexibility how he\u0027ll handle defaults was for configuration because we had implementations that handles handle it very very differently under iOS if you set configure of a configuration variable through the default value it disappears from the configuration under that\u0027s sorry Phil Schaefer Gino\u0027s 900 you know it\u0027s my baby if you put it there if you put a default value if you can\u0027t configure default value you remain because we think you knew what you were doing so so there you have two very different models of how to handle the fall baggage and that was actually the reason the space savings was less mission well angel Erickson actually we had three different methods of handling before the the other method is that if you have a default it gets there and you don\u0027t care any longer how it got there so 3-day different handling and I think if we have with defaults on get data that would solve the this capacity issue so why not handle that way the socially free and the the issue with that is that the operational the operational data store is to show you what the box is actually using and so if it\u0027s if there\u0027s a value in use you want to see that you can decorate it with origin default to know where it came from but you really care that it\u0027s that it\u0027s there in the same way if it\u0027s not in use you you don\u0027t want to see it regardless of whether it\u0027s the default value or not if if there\u0027s a if I have an interface and there\u0027s a default MTU and the interface isn\u0027t there I don\u0027t care about the default I\u0027m to you if the if the interface is down I don\u0027t care about the default into you it\u0027s not in use so that\u0027s that\u0027s really the the the value of having the operational datastore give actual in use values and I think that\u0027s really key "
  },
  {
    "startTime": "00:51:46",
    "text": "vodka I have another question that I already asked before but it doesn\u0027t seem to have been resolved and it\u0027s about templates the draft still mentions templates several times very very lightly but I understand that validation is to be done on the intended datastore but young also requires some constraints to be satisfied on all data trees and I don\u0027t know if if the idea is that uh none expanded templates or the data trivet on expanding templates which is supposed to be in running probably whether it is really necessary that all these constraints are also satisfied and if so I think it should be mentioned in the drought that only this kind of templates is under consideration or something maybe well Shannon Erikson I think this compacts what Andy says that if you are not forced for example to implement intended or some of these data stores and if you choose a set the specific combination of data stores that you are actually implementing each of the for each of these combinations what is compliance needs well which parts are validated how that the flow of information goes true for example for us the related question is that if we if have a model coffee to and conflict falls mixed up we don\u0027t show the called operational versus running differences so in that sense we don\u0027t implement the operational as a separate but still we will implement the config falls in operational do we implement this model or not so I think that to answer that question whereas before you\u0027re comparing like running with config faults you actually can you can return that is in a single get operation you returning the intent the configuration the operator is asking for the device is allowed to do nothing with and the operational States what is actually doing point in time so if you had a large company that had a system running a large amount of configuration and a large config change came in in your running you\u0027d see the new configuration and all the operational leaves the config for sleeves are actually related to what it\u0027s currently doing and those nodes that they need that need to exist for it to be able to to be as returned the data might not even be there in the new configuration so you sort of stuck with the existing model whereas with this one the operation of state they so it\u0027s obvious you the configuration is the applied configurations what\u0027s there and running in the system so the structure always logically exists I like your model so I like what you have done but you have to describe what it means if I\u0027m implementing part of it only because okay it will take time okay "
  },
  {
    "startTime": "00:54:48",
    "text": "so the other question was about intended for example the intended datastore just degenerates back to running if you don\u0027t have templates support or you don\u0027t do conked out conflict so whether you allow people to a get operation on that or not it should be relatively simple to code to just point to the same data as in running I take the question about in terms of models but about validation of templates I think that needs more consideration as to exactly how you address that Chris snaps those Telekom so Phil you just said something it confused me or maybe confuse me and maybe I so if the interface state is down do I lose a lot of my operational like I\u0027m thinking if I change it because we change our come to you is that something I\u0027m gonna run into where I\u0027m only gonna see it and intended if the interface is down no sorry that was a comment on operational it\u0027s always an intended intended is your intended configuration in operational you\u0027ll see what\u0027s in use yes if it\u0027s not being used you shouldn\u0027t see it so so it\u0027s clarify I think it depends on the implementation so I mean one implementation may say yes interest exists it has an empty program it\u0027s down another implementation may say well no it\u0027s not not part of the system and so that returners or more you know in a square box the problem is we don\u0027t have a definition for in use which was one of my previous slides so that\u0027s what I think leaning to the right please oh is empty you you know a value that\u0027s active even though the interface is how I okay so that yeah that\u0027s and that\u0027s and that\u0027s not a clear statement that\u0027s not it\u0027s not it\u0027s not clear right now because we don\u0027t have a fixed about a fixed definition for use Rick Taylor I\u0027ll try and keep this quick I\u0027ve become confused about the difference between dynamic and learned I\u0027m really sorry I can\u0027t think of anything that has an origin of learnt that isn\u0027t basically just dynamic it may only get set once right at the bigger you know your protocol may negotiate some value overriding your conflict intended value gets overridden by the negotiation shorty that\u0027s just dynamic but it only gets updated once so this this identity really means dynamic data store so maybe the name of that identity should be dynamic data store all one of those dynamic data stores so so what\u0027s learnt then learns is coming from a protocol that\u0027s not not one of the configuration protocols and not through a dynamic datastore so something that like it\u0027s your BGP peers or your therapy peers things when they return values that override your configuration that was what when we be marked as learned configure eight known values yeah I do understand that but it just seems like that\u0027s another not particularly often changing dynamic data store you could "
  },
  {
    "startTime": "00:57:50",
    "text": "express your I perhaps I\u0027m drifting into I I to RS and Susan way off there entropy so the idea is that is that a dynamic data store something inside this this ecosystem that we\u0027re building and learned is somebody else it\u0027s that it\u0027s that sort of division so learned is actually external something outside of your whole config model has set this value outside the box outside the outside the the system we\u0027re defining so DHCP you know DHCP you could conceivably make a DHCP daemon that that takes data and puts it into a dynamic data store and it comes in that way but you probably won\u0027t because you\u0027re gonna use the IC you know so so if your dish if you\u0027re a DHCP data comes in through a dynamic data store it should be tagged as dynamic because it\u0027s under this whole ecosystem init understands the rule to me I think if it comes in from from a traditional DHCP implementation it\u0027ll come in as learn because we want to say you know here\u0027s data we got yeah ok by the way that was Phil Shafer and Rick Taylor at the mic going too fast to say their names constantly this is Christian ops again so I do have a suggestion on how I would like to see that resolved the interstate interface down State thing it came up earlier in routing working group about failures being failures that happen later on after the system was said ok I\u0027ve taken that value right and I replied back everything went ok with that config value but later on I would have to detect a failure by looking into operational state to see if it changed right and that would be one way of detecting a failure another way might be a notification which was the case I\u0027m not working so as a suggestion for how to determine whether something is in use like MTU if it\u0027s not available condition I kind of expect it to be applied right so in other words if I if I even if I interfaces down if I change the MTU to 9,000 and and there\u0027s just no case where that\u0027s never not gonna work when the interface comes up then I want to see I think change it apply right because there\u0027s no reason for it not to yes yeah I think that that\u0027s probably a definition will end up so you know as long as the system is saying ok it has taken the 9,000 value and as soon as the interface comes up it\u0027s going to have an empty of 9,000 then I want to see it apply yeah yeah Jason Stern I just had a question back for you how about then the case if that line card is physically unplugged from the router it will expect to see any guy who\u0027s Leatherface now then it be removed from applied configuration Isis doesn\u0027t drop so if you\u0027re up or down you\u0027d still see it but if the thing is unplugged and you couldn\u0027t possibly apply it it\u0027s gone "
  },
  {
    "startTime": "01:00:50",
    "text": "from applied I mean you mean anything that\u0027s creatively up or operationally up Chris Hobbs well yeah I mean Mike particularly cuz I\u0027m thinking I was that I\u0027m gonna you know keep interface a lot of different vendors and stuff you take interface down and change some values and bring it back okay but not if it if the fiber is unplugged I think is still down I still want them to you all right before we leave this draft I know we are cutting into other time wins whoops one yeah now that we have open issues and maybe heard a couple more here what do you think is your timeline for resolving all open issues I don\u0027t know I mean the other office my lights comment as well I I think the job is quite close I think there are some things of these discussions we need to go through and revise those but I still think it\u0027d be good to get comments for everyone so I thought was to aim for last call in September yeah and we have August with vacations and July to do you think that\u0027s still an attainable goal I think there\u0027s a baby that\u0027s grateful I\u0027m not sure what that means [Laughter] okay so hearing otherwise I\u0027m gonna say as chair we\u0027d like you to continue to aim for the goal of resolving all your issues by September so that we can do a last call in art not by September in September so that we can do the last call then and be ready to send over to the is G in October Phil Schafer I think it\u0027s important that we keep that deadline because being lazy humans we will make it if there\u0027s not a deadline so I\u0027m all for keeping a rigorous deadline thank you do you want to move on to the next one yes target not deadly so the second presentation is guidelines effectively how do you migrate to the nmda architecture this is the same presentation I gave in your routine working group earlier today so you\u0027ve seen that so you can tune up with that problem definition or skip over that\u0027s the same as I\u0027ve just presented today in terms what yang models look like in various drafts and different bodies there\u0027s really three fundamental categories they fit into we\u0027ve got the ITF split config state top-level style and that\u0027s like the interfaces classes interfaces state RFC 7230 has that style and the the interface is the the config tree as all your configuration the state tree has may have the configuration "
  },
  {
    "startTime": "01:03:51",
    "text": "replicated again it may be slightly different it may also have the other config fall sleeves as well so in this particular case ideally they would marry up but they don\u0027t necessarily do that the second style of modeled structures we come across is the open config style that they\u0027ve been pushing forward and they\u0027re they have explicitly config and state containers directly above wherever the configurational leaves are so as soon as you have some configuration leaves in one of those models you create a config container and the UK create PA state container at the same parent and you put both the config nodes there and the state nodes there as well that uses a single tree structure and then the third one that\u0027s obviously I\u0027ve talked about here is the combined structure as well as the nmda style is a single tree but without any replication so as an example to try and illustrate this I\u0027m using a subset of the BGP model I\u0027m got for global leaves I\u0027m considering two in blue our configuration the ace number the reach ID and two estate leaves the total partook of prefixes I\u0027ve got for labor labor leaves as well and trying to put those that in to illustrate what a list might look like in these two trees two of those these config two of those are in a container and state notes so what does that look like so I start with the ietf split confidence state tree that\u0027s what this subset of bgp would look like on the left-hand side you\u0027ve got in blue you\u0027ve got the configuration tree named bgp with all the configuration on the right-hand side you\u0027ve got the state renamed bgp - state and in this case I\u0027ve copied all the configuration leaves across to that configuration nodes and then in the shaded orange boxes you\u0027ve got the config false notes from the schema so although the whole of the BGP state trees config faults the ones that are liked are the ones that copy for configuration and the ones that are shaded and those real sort of derived data operation state and in terms of how you produce this model generally you either have to replicate that structure by hand or you have to use groupings so you get the same structure between the beach piece are the the configuration side on the state side and in my experience the models I\u0027ve looked at you find that sometimes these state trees start to deviate from the configuration trees they\u0027re not an exact one-to-one representation so you can\u0027t always know exactly where a state Leafs going to exist and what we want you to move to is this so effectively you taken those config four state leaves ie the ones that aren\u0027t a duplication of the configuration and you\u0027ve merged them in into the appropriate place in the configuration tree so you can see like total paths and take the prefixes have just moved into the same place and configuration tree under the same parent would be and likewise with the ones limit out so this this has the advantage that the structure is guaranteed to be right because you\u0027ve only got one structure in the model you can\u0027t there\u0027s no separation to go wrong and it\u0027s and "
  },
  {
    "startTime": "01:06:54",
    "text": "it has other advantages that the India model that you produce is generally far shorter than the other examples either the split convict state tree or the OSI model yes vodka so here in this example one interesting case is this router ID because if I remember correctly in the routing data model base feature that makes this router ID available at the global level or something like that but some of course if this feature is off it doesn\u0027t mean that the router that doesn\u0027t have any ID it only mean that there is some algorithm that the idea becomes assigned automatically somehow so it means that basically in in this case so or some routers will have both outer ID in configuration and in Stata but some of those will have it all in stay later but if we keep this a feature for example on this router ID we need to distinguish somehow that this if you want to have just one they tunneled for both configurations data it means we have to somehow distinguish that this feature does is not does not hold for the state data version so things like this will will come up very often so I really I\u0027m not really big friend of this join join tree but yeah so say feature yes that\u0027s something you had a difference between the config and States then clearly you would that\u0027s other things it\u0027s the default value for example right but we\u0027re saying so effectively in this case we\u0027re saying that honey in blue saying it\u0027s confiture doesn\u0027t mean it has to be configured only that it\u0027s configurable and a and we\u0027re saying that if you configure a value and you end up using a different value then in your in the operational tree you\u0027ll see that different value and your seed origin that says it\u0027s a different value camera system whereas who\u0027s comfortable configuration will be see see this marked with the same values come from the intended configuration so I think other than the feature comment you\u0027ve made I think you could still get away with one node here and that\u0027s the desire that you look at it on the same path and you can then resolve with your configuration taking effect or or if not you can go and look as to why it\u0027s ten minutes yeah clarification question on that last answer the reason the router idea is there is because sometimes people configure on the BGP peer another router ID why they do that that different subject so there is the initial one that lotto is pointing to very nicely and then there may be a different one by understanding that\u0027s those are two facts my question and clarification because this can be set i believe it operates in the way that is expected in the BGP configuration "
  },
  {
    "startTime": "01:09:56",
    "text": "whether the that it\u0027s it\u0027s unique variable how its populated can it be populated from the base or what are you are you saying are you and a lot of saying something that has to be there from the data stories that just general logic you\u0027re trying to provide I\u0027m not sure I fully answered your question so I melt down a tree as well these things are bad for your pair for the roots ready some people want to play with the router ID that they announced to the peer a fine long story so they want to actually configure it that\u0027s why sometimes it\u0027s there so to answer your question then this is one of the cases I think the Phil described a sort of complex default so in the description statement of the data model under the router ID that\u0027s for the peer you would say if there\u0027s no value configured here you would pick up the value that is assigned to the global Brewster matter ID effectively okay and I said that the texture is that the default text that you were commits that would be in the description text because I think and I know the draft makes it quite clear that I still a default so that\u0027s still origin default would be reported back it\u0027s just that it\u0027s too complicated but in single statements okay so if it came from the origin from the base you would have an origin or and the other one you\u0027d have configured it be it would be origin default if it came from the base I was at the origin and configured okay that\u0027s very precise think of them three minutes okay so the other example I\u0027ll show you very quickly is what the open config model looks like so that\u0027s this again it\u0027s the same leaves here as I was mentioned before under or above each configuration leaf like the AAS and the route ID you end up putting in a config container and then as appear to that conflict containing you create the state container as well each level and then you put the state leaves underneath that state container as a copy both of learning configuration leaves and also the ones that are traditionally conflict falls today or derived so your additional state with this structure there are some limitations because it\u0027s sharing a conflict raise any one tree so in elements that are created on the system like I mean a system created interface you have to sort of bend the rules of yang to make that allowed because you can\u0027t actually it\u0027s not configured but it exists in a conflict tree in terms of a get operation for example so advantages of nmda I don\u0027t know it\u0027s worth skipping through the rest of this slide deck I\u0027ll bring this yeah I think this group is convinced of anyway so how to migrate obviously we\u0027re saying everyone should migrate their model is in Indian architecture and all the ones that currently published will be revised or one ones that need to be revised to nmda and in essence what you\u0027re doing as I said before is you\u0027re copying the config false leaves in the state tree into the conflict tree and "
  },
  {
    "startTime": "01:12:56",
    "text": "then you remove the food state tree it\u0027s an unpublished draft you mark as deprecated it exists and then you need to check the descriptions for some of these cases where a value the configured value and the description refers to a configured value and it needs to be massaged a little bit to be applying better consequence state and then the other thing I just want to cover is well can these modules be used on existing Netcom Prescott servers and the answer is yes but there\u0027s two conditions where there\u0027s a problem one is where you have there\u0027s no way of reporting the applied configuration value so if you had some protocol configuration like the MTU on that Chris mentioned earlier there\u0027s no way of reporting that IMG value is not in effect but for many cases like the MTU example it doesn\u0027t actually matter what you put in is normally trivially applied over some period of time so this isn\u0027t necessarily a breaking thing for people today and the other case which it can\u0027t handle as the system crated objects so this new combined tree of interface and interfaces States for example you be able to rate represent an interface a system created interface obviously when you have the nmda that comes along that\u0027s fine so we don\u0027t Lisa problem for most modules but for the case that there is a problem then you can easily mitigate this by creating a separate config false version through States version of that module so you just take the same module file the chef - state at the end you mark it all conflict faults and you reuse the type deaths to save having new types and then that\u0027s a way to something you can use until such times nmda implementations available but i like to stress that we only expect to be used when necessary put in the appendix avoid if you can and it waited over time yes sorry England with skin quality so I had this situation when I say when we migrated from basically I don\u0027t know how to handle without nmda situation like make before break say I configured something and and it succeeded so I can see if there\u0027s a applied configuration right then I decided to modify it and this new configuration failed okay so with the nmda architecture I can see the intended configuration my laid configuration and applied configuration which is currently in place right so if I\u0027m not using MDA right architecture so I don\u0027t know how how can I see this Delta what is actually configured versus what what was intended to configure and has failed so the answer is you can\u0027t that\u0027s point one that\u0027s effectively mentioned there unless you create this duplicate separate tree but in many cases you said there you can tell that when when you got a response back neck home you know the configurations applied you don\u0027t actually know that all you know is the system\u0027s accepted the configuration will "
  },
  {
    "startTime": "01:15:56",
    "text": "act on at some point in the future it\u0027s not guaranteed so there\u0027s lots of ambiguity as to what the actual semantics of net conf operations say today people interpret them as meaning the configurations applied and some operators are some devices act that way others don\u0027t so no consistency there where is what we\u0027re proposing here will be consistent so the problem is that when I try to do this make before break I don\u0027t know immediately that it will fail I learn about this in in sometime okay so they saw I actually accepted this configuration but during signaling for example their problem was detected that\u0027s no different from today and this device they could behave that same way it\u0027s up to the implementation to decide whether they delay replying until they checked it can be applied or reply and easily it doesn\u0027t it doesn\u0027t specify the existing specifications this was the same issue that came up earlier in the routing working group so we should come up with a good answer whether it\u0027s to take the approach being taken there which is to add specific notifications or something more generic yes also we have a question on Madoka so go ahead and actually we\u0027re gonna need to cut the line because after the meet echo sorry because we\u0027re really over and we worried we\u0027re gonna steal some time for the next one so this question and then okay we\u0027ve seem to have lost Eric yeah so if he shows back up we\u0027ll give him that in the interim I actually want to ask the question is share that the their key from all this is not only us getting in sync which is hugely important it\u0027s also getting agreement on the language that goes into sixty eighty seven bits what\u0027s I have an understanding of what the plan is should I relay it or should can you tell us what what the plan is among the authors how we get there well I think we need to have some definitive text just saying these instructions are saying this is how you mobile ads so my understanding is that the authors are gonna propose some text on the list that for what will go into sixty eighty seven bits yeah yes do you have a timeline for that what Ken posters well I\u0027m gonna my co-authors do it I\u0027ll do it in two or three weeks yeah okay that\u0027s great because we want to we want to get to some agreement obviously without text we don\u0027t know if we agree so once we have the text we can discuss it on the list and and hopefully in very short order have an agreement on what they recommend patience are and then be able to resubmit 60 87 vests yeah Andy Biermann I wasn\u0027t going to go to the mic but you started talking about this maybe I can talk with camp this week about the text but what are the guidelines for someone who\u0027s going to say well I want the the keys for this list to be different in operational state than they are and config I have one more key to add or they say the operational state value leaf is a different value set are we are we discouraging people from that and "
  },
  {
    "startTime": "01:18:57",
    "text": "forcing them to to use the same keys everywhere or and not expose a key that they wanted to put in there or so what\u0027s the guidelines for when the model is not this simple okay I agree we\u0027ll put the five guidance and that\u0027s it yeah so there there was a slide deck with some QA in it that\u0027s good to look at also there was a couple of questions that came in through jabber that didn\u0027t get it to the mic because we were cut I will copy in the jabber questions into the ether pad so that become part of the record and actually jabber is always available as part of record either way and sorry for not getting to the jabber people okay so I\u0027m William Lawton representing broadband forum I\u0027m the broadband forum Software Architect I\u0027ve got ten minutes and so I just want to give a quick update on broadband forum and what we\u0027re doing with the yang and sort of what principles were applying so I want to cover all this very briefly you know what do we regard as being in an out of scope what are we currently working on and what have we published how do we publish what about draft yank obviously where I remember organizations so our work is not all publicly visible and what about the yang catalog and then finally a little bit on sort of best practices and well dependencies on external young and best practices so our emphasis is on addressing our own requirements rather than on general solutions I mean we don\u0027t actively avoid general solutions but that\u0027s what\u0027s driving us which i think is you know a contrast force with Korres do such as ITF where I think the emphasis is more on providing something generally useful and our current emphasis is on we will call broadband access nodes so the equipment sort of between the home and the and the internet for example those of two of our main standards that are providing the requirements that are driving our current work and so will define in BBF yang where it\u0027s for things that we\u0027ve defined or yang where it\u0027s for things other people\u0027s have defined but they have defined but the organization is not interested in defining it so for example some of the first yang we did was four so ITU unphysical our standards and we will reuse yang from other organizations whenever it\u0027s possible so these are our current projects substrain the areas on the Left and sort of internal project names just quick description then you can see that the top right to the ones we\u0027ve actually published which I\u0027ve got a little bit more information on in the upcoming slides and then you can also see in bold there\u0027s one project for which we published draft yang and I\u0027ll also talk a little bit more about some draft Yin so I wasn\u0027t too good has up the blue sheets well okay this slide has actually lost a picture of but I think that\u0027s the next one give me an error message okay well okay it\u0027s lost a picture um it was a beautiful picture but I was never "
  },
  {
    "startTime": "01:21:59",
    "text": "going to go through the picture in detail anyway so these were the first ones we published back a year ago so these were the ones I just mentioned actually the itu-t ITT physical our standards for video cell 2g that fast and also some sort of associated sort of like for example handshake handshake protocol there that I\u0027ve got more of on dependencies on ITF but they\u0027re the main dependencies was was on the interfaces model and we\u0027re now working on some new features and I\u0027ll giving you some examples they\u0027re bonding in Reverse power feed then there would have been a picture that just showed the modules and their dependencies lots and lots of sub modules here actually these are quite complex standards but only a small number of module or I press the button too far below this is the other one which are what we call the common yang modules for access networks these have also been published so the idea is that these are applicants it\u0027s a little bit analogous with net mod I think these are these are modules that we expect to be widely applicable and so similar arm dependencies but also ITF system an RTO I tip Hardware there it\u0027s a draft obviously we\u0027re aware that we\u0027re going to have to think about how to apply the the data stores here so thank you for that we\u0027re also working on some new features there and I\u0027ve listed some there and no alarm management that\u0027s another dependency there I don\u0027t expect you to be able to read what\u0027s on that picture there but it\u0027s just showing you those are all modules as opposed to sub modules and it\u0027s showing import dependencies and it\u0027s also showing areas and it\u0027s also showing external organizations there are the various and containing boxes and colors so how do we publish it we have a software release registry which is a grand name for just a wiki page that lists everything we\u0027ve published including both draft and standard yang it all goes into this broadband forum area yang repository in github with separate areas for draft and standard and then it\u0027s also all available far the sort of de facto standard young models yang a repository via a sub module which just points to the above BBF owned module there\u0027s some examples in the background slides draft yang for some projects in fact only really one sorry we\u0027ve made draft young available for study purposes does have a different license and that\u0027s in that area of the of the github but we are currently working on making sure that such draft yang is available across the board for all projects and will be updated recently frequently I mean we wouldn\u0027t expect every commit to be visible we would still expect there to be some sort of decision to make it available but we want a very low bar on making that decision and also just as a plug really all the all the bots draft and standard yang is available in the young catalog so I\u0027m going to flip through these at the rate of about one every two seconds so you could go into the catalog and you could do a that\u0027s a "
  },
  {
    "startTime": "01:25:01",
    "text": "cunningly constructed regular expression search that only matches one thing and then you would get this and then you could click on the impact analysis and you would get there this from which you can see that some there\u0027s a draft BBF module which is is it green I\u0027m not sure I\u0027m Cala blonde which is dependent both on some published BBF yang Ananse and published IETF yang and you can see there are even links to the to the corresponding documents which is which is all quite nice and that\u0027s all enabled by the metadata so ok just to put it all into one place back to external Yang\u0027s so we do have a policy that that our modules must use external particularly iron and IETF young yang modules whenever possible I reduce or to said that but we did this isn\u0027t just this is intended to be letter adherence to the letter and the spirit you know we really would do want to be using these modules as they were intended to be used I\u0027m just to pull it all together those are the ones were currently dependent on directly and then I also mentioned this already but we the pub the the stuff we\u0027re working on at the moment I\u0027m also very much we intend to depend on the ITF alarms I mean this is actually a very active area at the moment that we\u0027re working on internally and then just finally we also have our own sort of version of our own sort of young best practices which is based on and adheres to sixty eighty seven bits as much as possible I mean in the future it could also equally refer to other SB o--\u0027s but right now it\u0027s it\u0027s ITF so it\u0027s a mixture of qualification two and extensions of guidelines that are in 687 bits but also there are some additional BBF specific guidelines we do plan to share that with you guys because haven\u0027t got around to deciding how best to do that yet and also there are some more detailed examples of guidelines in both those two categories in the background slides and that\u0027s it I\u0027ll going to fall snow a little bit we\u0027re left with two extra minutes but wait we have an ad coming to the mic so speaking so thanks for this so you heard about NMDA right so I guess at tomorrow we got the NMDA question answer by a rod where he\u0027s going to show the different RFC you know actually we did that today we used it rather than do it as a formal Q\u0026A session we took it just during discussion time so we we used all our Q\u0026A session our Q\u0026A time this session right but there is a list of RFC that will need to be updated right I\u0027ll bring that up right now okay maybe it\u0027s for tomorrow my point no it\u0027s not for tomorrow okay now the question is you know about an MDL right so it\u0027s a difficult question but you "
  },
  {
    "startTime": "01:28:02",
    "text": "meet plans there well right now no there is no this is not something we\u0027ve have raised in BBF yet right but we must and I think I mean off the top of my head our plans will go along the same lines as I mean I think the guidance that Rob presented I would think we would apply that guidance to our modules just in the same way that you\u0027re asking other eye you TF working groups to do that the particular implications for us will be the two IETF modules that we\u0027re dependent on that have this split which would be the interfaces module and the hardware module and we\u0027re just going to have to deal with it and I presume we will do it in the same way that we will I mean I know there\u0027s some discussion of exactly what deprecated means at the moment but we will I presume I\u0027m not sure which should be the core one the state one I think is the proposal so we would I guess is that right we would deprecated the config and and bring the config into the core or the other way around okay we\u0027re doing the way around we\u0027re requested to do it and just to take the hit on on how we managed how we decide to publish that and and so on I don\u0027t see that we have any option we weren\u0027t we won\u0027t ignore it all right perfect and one last thing I want to mention in the catalog we\u0027re going to have very soon I guess a week or two the the metadata on what is the three type that we have is this like an mga open config so it will how to see okay yeah so happily will support some additional metadata to go into the catalog yeah yeah back to the Q\u0026A we actually while we use most that time or all that time this time we have a talk that was supposed to be given that Alex isn\u0027t gonna be able to give tomorrow no no you said you are gonna give it never mind I was gonna steal your time oh well good thing you\u0027re sitting here now protected it alright we have 10 seconds left so we\u0027re not going to change conformance things like things that stuff like net comp state that was published as just monitoring now we\u0027re going to be configuring things so why would we move something that\u0027s purely monitoring into like make that a configuration module so so i guess this this slide needs this was right this was for discussion this is things that need to be looked at so Rob had looked went and identified some RFC\u0027s that bear some investigation this isn\u0027t our list as chair saying we are absolutely doing this this was input for discussion it the slides are there they were intended to get discussion going let\u0027s get the discussion going on the list all right with that thank you very much and we will see you at the next session which is Wednesday at 1:30 right back here [Music] "
  },
  {
    "startTime": "01:31:49",
    "text": "you "
  }
]