[
  {
    "startTime": "00:00:05",
    "text": "not be inside meeting but through the mobile my multiple personalities couldn't join the meeting at the same time okay okay concrete [Music] okay beautiful okay yeah so what i was saying is that in case of troubles just write me taco on the chat david okay okay shall we shall we start hello i'm quite sure we have my con good afternoon uh announcement which is not on the slides when you scan the qr code use one which is on the screen and not try to use the paper one because it didn't work for me i'm not sure if it still works maybe it works actually uh this is for energy so i hope everyone is in the right room finally we're here in person i'm very excited this is not well please"
  },
  {
    "startTime": "00:02:00",
    "text": "read it if you have not seen it before it's irtf specific note well which lists everything you need to know and it also reminds you to be polite and be nice to other people as much as you can and even better um housekeeping so yes i say please car scan qr code which would allow you to join the microphone key so when you would like to ask a question don't just run to the microphone but press the button in your phone to join the queue so we can have a the common queue for both virtual and in-person participants when you speak into the microphone please say your name so we know who you are for people who are not able to join us in person who are remote please keep your audio and video off unless you are speaking and then you can join the queue if you'd like to ask question and then you can say you probably should send audio but you may say send video as well so for speakers if you are remote please use share preloaded slides button and the miter echo and select your presentation and have control ah oh yes indeed usual thing we need a minutes taker i will allocate and agenda 15 minutes to find the minus taker next time so we can get to our slot please corey can you uh can i ask you to take minutes glory have you volunteered corey fergus will volunteer and glorify hearst will make announcement we the minute taker for tsvwg tomorrow"
  },
  {
    "startTime": "00:04:02",
    "text": "but i'll take minutes now i i would i would love to take minutes in tspwd but i'm flying out tonight yeah and i'm not there as well i'm sorry yeah next time next time okay so thanks gareth and also uh carsten uh will be helping you out beautiful thank you thank you very much so agenda for today uh we have pretty busy agenda uh time permitting section where we have spencer has been dropped spencer just told me so listen but i still hope to hear from you next time um so what's going on in this group since last eight year we published another secret nutrition brand thank you we have and so now we have questions we have things which you've done in the past wrong thanks to spencer summarizing them and we have one active document which is past properties which will be we'll be discussing next i guess so uh is it i guess it's the last slide and i do want to say something about the last part oh yeah uh i i see some faces in here who were in the um scion side meeting on i guess that was tuesday um there was a lot of discussion there about sort of how to take uh bits of scion some of which are are um sort of behind this path properties draft uh some of which have been discussed here and there uh within tanergy um how best to bring that into the irtf and ietf um i think it makes sense uh to have a virtual interim between now"
  },
  {
    "startTime": "00:06:01",
    "text": "and philadelphia um to dig into that question right like so we'd ask uh people um uh from scion and people with interest in this topic uh to get together at that at that virtual interim meeting and it'll be um a bit more of like a brainstorming thing than a um uh and a you know let's look at presentation sort of thing um we will follow up on the list uh to figure out the right time to do this uh and like any suggestions that people might have with respect to the format of that uh but i think there is an opportunity here to figure out which bits of that work belong in this research group uh and maybe provide that project with guidance for how to engage with with parts of that within boston and the ietf as well so uh yeah we can take comments on that point uh spencer is in queue yeah spencer dawkins i was just gonna say unless you can think of a good reason why this might be a bad idea i would encourage you to go ahead and schedule it as early as possible so that some of us who haven't been paying as close attention have an opportunity available so the next presentation is past properties draft so yeah uh well uh i um okay uh uh what's wrong okay yeah that's not now should work yes uh grand prix loaded slides"
  },
  {
    "startTime": "00:08:02",
    "text": "oh hello zero can you hear us hello yeah can you hear me as well we can how's that is that okay for people in the back yeah say something else cyril hello hello let's test okay good perfect um i'm not sure yet i see this light i think i gave you here you have to do the what is it well i gave you ah okay my fault my fault my brain is oh wait i uh sure yeah sorry sorry i my brain is not working as you might share share preloaded slides hold on sorry okay you have to stop sharing your slides yeah it's what i'm gonna go back over to yeah have you not done that i think i've done that that's that's my problem okay it's like uh what i'm doing wrong try this shampoo slice uh where are the pre-loaded slides coming from here are you are you sure you're not logged in twice no i can i can be locked twice i tried it's not possible okay uh uh okay let's do this okay oh yeah oh my god yeah there we go share and now i'm getting yes ah got it okay 10 minutes later sorry okay you should have control yeah perfect um yeah so today i'll give you a quick update on the path property draft i'm"
  },
  {
    "startTime": "00:10:00",
    "text": "sorry my voice is a bit it's but i think i should manage that 10 15 minutes um yeah i will try to keep the presentation short so we have some time for feedback um so the biggest change we did since the last version is that we replaced host with endpoint so we removed the standalone definition of host we had before and we now have a new definition of an endpoint which is defined as the first or last node on a path i think one thing that's interesting to note here is that actually in the beginning we had already the term end point in our draft this was when this was not an iot of irt graph by the draft of freeze but we decided to um go to use term host because it was not clearly defined but since the the draft has seen a lot of change in the last um iterations we think that now and we can finally have this definition of endpoint and it's also clear and correct and of course naturally from this definition of an end point we have the definition of an end-to-end path property which is simply a path property defined on both end points and the virtual link between them which is very useful since many concepts are defined using this end-to-end principle and as a result of this we replaced most occurrences of host in the draft with endpoint i think we left one or two where we thought host is more appropriate but most of most of them were were changed and then from the discussions we had previously we felt it was not clear enough um why um the definitions are context dependent so we added some short text to section 2.1 and what we want to express there is that even a single part where technology might have different definitions right they might disuse these terms differently"
  },
  {
    "startTime": "00:12:01",
    "text": "depending on the context so one example i thought of is maybe a scion where we have these path segments so the routing only works on these path segments but then for actual data traffic data plane then works on combined data of segments that are combined into paths so there the notion of a path will be different for one technology depending if you look at the routing side or the data plane side and then we added a new definition which is a routing domain identifier this was due to a discussion in the mailing list where this came up and we defined the routing domain as follows so path elements with the same routing identifier are in the same administrative domain use a common routing protocol and they communicate with each other using this specific protocol and the other classical example would be the as number and another example could maybe be an ospf area identifier and then we have a lot of minor changes so we added the discussion menu section which contains a link to the mailing list and a link to the github repository where we have the draft and where we have issues where we discuss all the changes and one thing that we realized when we updated the routing domain identifier was that the administrative domain property was kind of recursively defined which is a bit weird so we rephrased this to make it more natural and then we extended the acknowledgement section so that's already the end of my presentation i think what i would like to hear most from you is your thoughts on this new endpoint definition right we already had endpoint before we removed it in favor of host and now we reintroduced it so there i kind of have two questions do"
  },
  {
    "startTime": "00:14:01",
    "text": "you think it's sufficient so um does our definition now cover all possible um endpoints that you could think of or is there something that is not covered and um on the other hand is it necessary so do we is our definition too broad do we include um entities that would not count as an endpoint but they are still defined as an endpoint in our draft so what do you think how precise is our definition and uh another thing that we would like to do is to fairly soon finalize the main definitions and one thing that me and rhys thought when we discussed this is that once this main definitions are clear are finalized probably there will be very little thing left to do because the rest of the draft is essentially a non-exhaustive list of properties so we could keep it open for a very long time or we could just say this is the state now what we think is useful and the main definition will not change so we could would ask for a last call um yeah that's all it from my side i'm open for questions and comments on on these changes comments etc on the endpoint i will put my phone um hi cyril uh brian grahamel google as an individual uh i quite like the endpoint definition uh i think it is i think it's sufficient in that i can't think of a thing that i would think might be an endpoint in a pathway network that is not covered by it but i"
  },
  {
    "startTime": "00:16:00",
    "text": "mean it's just basically yeah it's a node at the end of a path right it's a pretty good and then node is also properly defined is it necessary um i think that the fact that we're having this discussion is is the indication that it's necessary right like if we don't have a definition for endpoint people are going to ask where it is right um so uh yes i like i think both of the both the conditions hold so thank you very much for um you know your patience uh yours and rhys's patience with going back and forth on this um this is you know hard stuff to pin down um i will reserve comment on ready for last call uh and let other people maybe talk about or maybe we should just do a razor like a show of hands poll for that yeah yeah i guess we can discuss last call on the list [Music] do you want to do it or should i do it let's figure out how this tool works i think it's like right here right all right okay uh if you know how it is i think so um so starting a session uh ray's hand means yes uh i believe path properties is ready for last call do not raise hand is no i think we need to um talk about something before we are ready to last call this document leave this open for"
  },
  {
    "startTime": "00:18:02",
    "text": "um would anyone who did not raise their hand like to put themselves in queue and uh let us know what we think is missing all right we'll go ahead and close that off i think we have we have a pretty good signal here but but i'd like to know what's missing for for people who did not raise their hands um just brian you might want to ask how many people have read a recent version because that might also help you figure things out ah yes good point yeah because this change or definition of endpoint is really recent this is from this latest draft so i think there might be some people that do not agree with especially this this part it's also nice and short so people can probably read it right now while they're considering whether or not they want to get into yeah this text-wise it's very little change spencer dawkins i one of the reasons i did not raise my hand was because i was still trying to figure out where the tab was where i could click on it and i mean i was doing email and stuff so please plus one to whatever you got thank you dungeon uh yes uh get you here so the rotting domain id just defined here well you know i you know in my my opinion it might be a little bit ambiguous for for something like for example in the the running product or isis it doesn't use the domain for some purpose so i'm not sure if you find this as a generic generic term uh well that conflict has some ambiguity with some special running protocols"
  },
  {
    "startTime": "00:20:02",
    "text": "yeah like as the domain does have its own meaning so thank you um yeah i would like that the things we define especially for example this routing domain identifier is um just uh kind of a generic identifier right definitely this needs to be defined um in like in specific when you talk about one specific um routing protocol like bgp scion or whatever so this is more like to give an idea what could be useful right and we think um a way to group nodes based on their kind of ownership in a way their administrative domain and that they can communicate with other is is useful and that's why we added this at this part property okay yeah okay yeah thank you just like to share my opinion about you know your generic term or some specific term i think i'd actually go back and ask corey's question now real quick just to get one more bit of data um so i'm gonna ask for another show of hands as for who has read the path properties draft roughly as many people have read it as think it's ready for last call so that's um that's cool uh max has joined the queue you're trying to raise your hand okay got it okay i think that's okay i think you my laptop is okay i'm gonna drive because you're a laptop yes okay good um so so of the 19 of you please uh consider"
  },
  {
    "startTime": "00:22:00",
    "text": "reading the draft it's quite short um and um uh you know speaking as an individual very entertaining um yeah and so the next talk is about service awareness yes versus passover so you need to [Music] share i need to share preload yes and it should be this one this one sure and then i need to go to presentation view okay and i will drive so just say next slide uh find a microphone right here [Music] where is that all over the place like like right here in the middle of the line when i go blind okay yeah there we go right there okay okay [Music] um right this title adjusted to the context of this group um is about how to use proxies and a new way of suggesting how you could maybe do it please next slide okay so the problem that this is about is that um performance enhancing proxies have existed for a long time people hate them they try to help out in tcp and in fact you know because well they sometimes do something useful right they have good intentions well intended but but you know terrible outcomes of ossification of playing tricks to tcp that they have to do and this is why we all hate them so quick has started encrypting the header large part of it which makes it impossible to introduce ossification and also makes it impossible to help the transfer"
  },
  {
    "startTime": "00:24:02",
    "text": "in the network which has the outcome that people are now making presentations about how quick does not work as well as tcp over satellite link i'm guessing i don't know if anybody's tried quick over millimeter wave but i'm guessing it just won't work so whenever you have anything you know in the network that that requires special attention but you're actually happy to have a proxy that is a no-go and uh so this is my effort to retrofit and this is probably where you want to throw stuff at me retrofit proxies into uh quick now okay first of all i claim that the ossification problem is probably at least partially due to the fact that these proxies are transparent right by their nature they have to lie to tcp they cheat they do things that are not supposed to be happening and that's why they make assumptions about the header that are not supposed supposed to be made and that's how we cannot upgrade the protocol properly using a proxy that is authenticated known signal tool things could be done differently in principle mask is a candidate for that uh thinking about whether it would be a good idea of adding pep functions there i guess some people might think yes some people might think no there is an obvious issue here that if we start adding a specific function then we build a reliance on that function in the network and not everybody may be happy with the outcomes of that we may reintroduce ossification if we don't do it right if we get it right maybe that could work here's another proposal next slide uh what we suggest is to do this differently using separation of concerns the idea is to use a separate protocol that we call sidecar strictly meant only for pep functions you would never rely on it for anything you wouldn't rely on this being you know giving you reliability in"
  },
  {
    "startTime": "00:26:02",
    "text": "in the data transfer for example but it's like an opt-in performance improvement it's hard to breathe while i speak here okay um yes and the non-criticality of that thing is is ensured by uh letting the main protocol explicitly opt in choose the service via an interface and that interface at least the way we think about it is that this interface would be on a local host only so on the host you would for instance talk to a library that supports that over an api and that library offers a service and you take it or you don't for a specific connection right and you may expect that this comes with a certain you know compromising anonymity for example when you know the directs in place but that's part of the contract so you deal with it or not depending on what the transfer is a plan is to minimize changes to the main protocols of the main protocol you couldn't really help quick much without changing it at all but the idea is to make it as minimal as we possibly can and if we get this right then ossifying the sidecar would mean that the performance improvement doesn't improve per se but which is bad but nothing really severe happens you will never rely on that for anything critical and the functionality of the pep they are the use case of these cycle protocols it's about providing a framework that that helps with these kinds of things next slide okay so in terms of functionality what this protocol can do right on the data plane what we can do is we can try to directly affect the main protocol in some way uh there's not so much really we can try and manipulate the queue just like a router does you know doing q management draining the queue at a certain speed something like that we can maybe retransmit packets but we would not pass the header because well it's mainly about quick the idea is to do this in a way that could work for"
  },
  {
    "startTime": "00:28:01",
    "text": "tcp for http for anything but we don't want to rely on that on the control plane we would have this local on the host communication exchange with the main protocol and the sidecar of course needs x because this is about proxies right so you have a proxy that needs to act something now maybe a receiver that needs to add something to the proxy and the idea is that these acts will be done using hashes over the transport header now we don't even know how big that header is but it could be a simple rule like saying let's say take 20 20 bytes starting from the ip header from after the ip header or 30 bytes if that's not good enough right it's about avoiding that hashes collide and hoping that hashes are different between different packets the x could be separate x and they could be piggyback for instance using udp options that seems like a nice vehicle to me because quick wouldn't even notice right gets stripped away if nobody doesn't want them and well i'm coming to two example use cases that illustrate how that thing could operate and then then we'll see what you think about it this is about quick but you could think about tcp acid to be anything the idea is that this would work independent of the protocol next okay so the first example is you're trying to communicate over that is let's call it a millimeter wave link right you have a link with fluctuating capacity between what here i call the sidecar proxy and the client you have a normal quick data transfer it's not interrupted i'm just showing a queue so it's like a router queue it's a queue it goes in and you have x going back and so we need to add something you know to make it work better next please begins with the entity on the server side where you have a service choice and this service choice here would be well if you tell me to increase my congestion window"
  },
  {
    "startTime": "00:30:02",
    "text": "i will right so this is something that if you perceive it as a danger if you think this side cutting is too fishy could be used for denial of service attacks or whatever you don't use it if you're willing to use it if you're willing to do that experiment right you pick that service next please and then what will happen is that on the proxy the site for instance it would take a hash of the packets you use the hash to act back to the sender side side car instance and using these acts it will be able to get a bit more data towards the sidecar proxy such that you if you implement a different kind of congestion control you have data available which is what you normally get if you implement the tcp connection splitter right you would act earlier and then when capacity becomes available you have the data there and in terms of the sending rate that would just influence the draining rate of the router that is something any device can do we can't prevent routers or any devices from doing this since this is a congestion control it would require a control loop so the sidecar in this case would also have to be on the client side to produce x just to the side car so that's independent of quick it's just looking at the hashes and producing x and the notification to the quick entity would be that a neck has arrived increase your congestion window right so that's that's that's the deal you like it or you don't you take it or you don't next please the minimal changes to quick that you would need in this case they're only on the server side it's local interface communication and if indeed you choose the service then you would have to increase the congestion window when the sidecar tells you to it's one case i'll have another one next time please this is something different just to illustrate that the idea is to be really flexible and do basically whatever perhaps normally do there is this paper that some colleagues"
  },
  {
    "startTime": "00:32:01",
    "text": "from trento university have done a long time ago this was work on tcp it's tricks playing playing tricks to tcp the idea is that on a wi-fi network any act that a client produces is really 2x right you have a link layer ack and you have a transport layout and then that transport layer probably produces another link layer x so it's so much traffic just for one ack now rather than having all these acts you could decide that the client doesn't need to hack anything and on the wi-fi access point you can just take a look at the packets as they arrive remember i forwarded this particular packet to the client and wait for the link react that comes back and when that link layer comes back link layer arrives i can associate it with the tcp header that i've just been forwarding i can produce the icon behalf the client now really you wouldn't want to do this for all x right you still want to have two packs you still want to have options but you could significantly reduce the number of eggs that are necessary which would save energy for the device it would avoid collisions and the idea here is to show how could we play that trick with with quick for example uh next please so here the service will be i will treat your side car wrecks like clyde x basically i accept them except that i said that we don't want to do anything really critical on this basis so the sender would keep the the data in the center for just in case until until the client cumulatively asks them but other than that you know proceed like normal when you get these eggs next please uh the sidecar notification will be an ack has arrived it's a very simple thing right it does a hash of the packet and the x and says okay this packet i'm now acting and as you can see you don't in this case you don't need to do anything on the client side in for the sidecar but of course the client would have to act less"
  },
  {
    "startTime": "00:34:00",
    "text": "so next please the next one is to saying that well the minimal changes to quick in this case would have to be that you have to signal to the client that it shouldn't be acting as much over quick probably and if you choose to service well that and also accept these sidecar acts again right it may depend i may not at all want that to happen when i'm talking to my bank but there may be so many things that are run over quick where i really don't care about anonymity or things like that where maybe this is okay it's just an example well two very different things that could be done but the idea is you could do any pep function next it's already the last one so what we believe is that this is a possible way forward to solve that dilemma that we now have between end-to-end encryption ossification and not being able to do any pep functions um it will require a lot of research right we need to consider how to limit the overhead regarding x and hashing there are several interesting things here like how how would you make a cumulative act when you have a hash um there are ways we believe there are many details here you know if you consider the use cases for example right let's take the link specific congestion control thing in case of tcp because the pep is invisible and transparent it can just answer back to the sender there's no need to even authenticate there's no need to even find it right because it's on the path and it answers to the correct ip address in this case it would have to be found now and and there will be a notion of trust right so the cycle proxy in principle just to give you a hint of what kind of you know steps would need to be taken the cycle proxy in principle you can just send sidekaix towards the sender you could start with one see if the device is there answering that yes there is a side entity on the sender side"
  },
  {
    "startTime": "00:36:00",
    "text": "but it doesn't really need to trust anybody it's just producing the hashes and decking the sender side sidecar that would need to trust the proxy right well otherwise i'm giving false information then again it's not easy necessarily for the proxy to be able to guess the hashes that put some weight on the hash function if a path changes well there can be different side card proxies they would just all start to act towards me then again you know if that if that is how we operated then we would have a string of we could have a string of multiple of these proxies answering without knowing about each other right so there would have to be some kind of negotiation phase to agree that this is the side car proxy i'm talking to so you know there are open things that's all i'm trying to say it's also not so clear if this can be really done independent of the main protocol but i think it's an interesting direction to take and i'm very curious what you think that was it i think the next one just says questions okay and i guess we like slightly slightly over time so we might have time for one quick question and we're happy to we probably discuss it on the list so anyone oh i said close the queue i'll get out uh yeah let's try to keep it to like 30 seconds yeah it'll be very quick so yeah i like the idea i like the because i'd like to ensure yeah peps are a way of ensuring that we get the maximum utilization of the available bandwidth so i like the um the concept of trying to do both yeah have the pep and avoid ossification so it's good work um yeah i'd like to see more um so thumbs up okay jake hi do you have that's on how the pepsi would be discovered am i kind of ideas on how to discover"
  },
  {
    "startTime": "00:38:01",
    "text": "do you know that there's one on past yeah so i mean you know maybe that's another time i mean like like i have it here right there could be a simple way to do it i mean just one of them could just start hacking sending one actually and if you if you get that on the center side you would see okay there is one acting i negotiate that you're the one and you keep helping us this is not a fantastic idea right but it's one it's one way kind of variations of that uh okay uh maybe i'd love to see some ideas on on that concept on the list a little bit maybe i'll i'll think about it but uh but you think they would just act anybody who's sending regardless yeah why not once and see if they get it randomly start with a knack and say okay you know i'm getting one so it means that there is somebody and i'm answering back maybe i could pick one of them you know like uh there were these things in multicast where you were able to pick out of many many possible receivers acting back you said um this is the one that's hacking from here i'll think about that okay as many qualities possible there's like interest to continue this discussion um like this is seems like a a potentially solvable problem and a good way to get there like discovery is hard anyway but um yes i'm sorry to cut you off yeah it's fine maybe next meeting we could spend a little bit more time on this uh yeah so uh marcus real quick all right yeah i just want to say real quick i think this is uh great work um we're actually in ericsson working on or we have been working on something very similar we call it lightweight pep and the multi-domain congestion control it has a lot of these ideas in there so it would be really nice to get in touch and sort of uh yeah maybe discuss this more offline we have a bunch of papers published on this we've also done simulations with the"
  },
  {
    "startTime": "00:40:00",
    "text": "millimeter wave and such send me an email yep thank you cool thank you very you very much next so it should be good start slides here yes it should be [Music] yes okay so hi my name is berta serracanto and i'm a phd student at ubc and i'm going to be talking about wide area networks uh for cloud auto scaling and yeah exactly um so i'll go quick over the agenda first i'll talk about the scenario that i'm presenting and exactly what is network auto scaling then i'll go over how about how we put the pieces together for prototyping and finally uh some plots about uh the results that we got from it next slide please okay so if we focus first this is the scenario which is built of three different parts the first one let's say it's a branch where all the users are connected the second one would be the cloud where there's the application that these users consume and it's cloud orchestrator and the third one would be the software defined network which is uh the part that brings together the users and the application and provides some connectivity so if we now look at the situation when an application deployed at the cloud suddenly receives an increase of requests um what the cloud does is auto scale and provide more resources to that application and it does so in two different ways the first one being horizontal auto scaling which is deploying more replicas of that specific application so the load can be balanced and managed more efficiently and the"
  },
  {
    "startTime": "00:42:00",
    "text": "second one is vertical auto scaling which is incrementing the resources on replicas that are already deployed uh such as increasing the cpu or more ram so if we now take a step back and look at the big picture again there's okay this situation there's an increase of load the cloud has done something about it but there's the problem that the network has not been modified and it might become the bottleneck so that's um when translating this auto-scaling term to the network makes sense so we define a horizontal network out to scaling which is um changing the overlay path and vertical network of the scaling which is changing the characteristics of the underlay path so let's like please oh that's the last one that's the next one yeah thank you um so if we go over first the horizontal network out to scaling case um as i said imagine that you have this traffic that's usually routed through the standard path and then suddenly there's the increase of load and then there's a way that the application is able to tell the network um hey i'm out of scaling i will need more resources because they are coming or this channel that you have is not going to be able to meet my demands so then um here's where the sdn controller can have a policy that defines okay now that we think that that's the case you need to be routed through this other path and in terms of vertical network auto scaling it's a similar case in the same scenario there's a cloud out the scaling event and then the network reacts to it um by adapting and in this case if there's only one connection vertical to scale vertical network auto scaling would mean"
  },
  {
    "startTime": "00:44:00",
    "text": "um adding more bandwidth if it's needed to end then it's an elastic thing it can go back when there's no more demand of that bandwidth so yes um i think a couple of yeah yeah it's light you're gonna go with the next one so here's the prototyping um you can see that both the users and the application have been deployed in public cloud and what's interesting about here is if you look at the purple boxes it's the way how the application communicates its requirements to the network so there's the cn1 operator which um let's call it a plug-in on the kubernetes orchestrator that monitors the application and what's happening on there if there are more replicas or if these replicas are increasing so monitoring the cloud auto scaling events are happening and it polishes these changes to the service and external service registry which is then continuously pulled by the cn1 reader which takes into account and says oh there's been a change and notifies the adapter which is the piece that's in charge of talking to the sd1 controller and the underlay saying okay network you need to do something about it and that's when the changes come coming yeah um yeah that's just a quick plot about the network um horizontal network auto scanning performance where we switch the traffic over both paths in a rate limited one and on one degree per second uh tunnel and as you can see here at this obvious when there's traffic in one path there's nothing the other one and we found that the delay obtained was not impactful so the change of routing was successful and just one place and on the case of vertical network auto scaling if you see the orange line"
  },
  {
    "startTime": "00:46:02",
    "text": "um it's where the cloud of the orchestrator says okay there's a number of labradors that is increasing and if you look at the green line it says it's the network auto scaling at the same time when proactively um meaning that okay the cloud is has had an auto scaling event and now the network has one too to go matching because then in the blue line cops it comes a traffic increase and since the network has proactively adapted that it's now able to take into account and don't have any problems and yeah and that's all for more details in the implementation or more specific results you can check out the paper or if you have any questions or comments just go ahead thank you thank you very much uh we have time for probably one quick question going once going twice thank you very much very cool stuff next all right next yes uh hello my name is rafael so i here to present the our solution polka that is a polynomial key based architecture for sas routing so next please so we are trying to connect watch banks problem solve uh penalties for problem solved in pog so uh we have noted that any points have little information about the perhaps over which their traffic is carried so and no contract beyond the destination address so next please so taking care about what sdn table"
  },
  {
    "startTime": "00:48:01",
    "text": "based solution so we have some next yes the s10 table-based solution approach uh suffered with the pav setup may involve several state configuration so once we have for example sdn table based we are suffering with this kind of uh out every time we need to keep states along the path so introduce for us a specific question how the sdn database solution offer pathway control and you have some problems about that for example largely number of scale that which means dealers for scalability limit capacity of tables directly and latest for path configuration please so look at this concept we are uh to just um connect with this street source routing the strict source routing is a matter of just only changing the source path so this the edge core the edge part so we don't need to keep all the states in the infrastructure only change in the edge so why you should use polka as a strict sauce routing polka rotting simultaneously meets some followed requirements for example topology agnostic so we don't need table in the core and we have fixed headers and also we're implementing program switches for a single path and multiplies so it enables a lot of a lot of applications in that case for example have expressiveness reliability and efficiency in telemetry so next please so how power work so we have three polynomials we have a rod id which identify and calculate"
  },
  {
    "startTime": "00:50:00",
    "text": "via using crts that's a chinese remain theorem we have a node id that identify each core node for so linud we use the radio shift polynomial and for the part id we have identified the parts for each core node so the forwarding uses a mod operation based at the minus of division between the route id and the node 80 next please so just showing a timeline in 2020 we got a paper published called polka and in 2021 we got a google researcher called scholar award and 2022 we got an intel intel connectivity research grant and also we recently published our paper book by spoke next please so how to implement polka poco trying to reuse crc hardware to offer polynomial model operation and extern mp4 languages so for example uh some of the stupid switch supports this is kind of extern that we offer us to calculate the mod operation in a polynomial way so the rainforest the red project as a open source full features relative on which we have network hardware for research and education so the data plane that's supported now is vm2 and tofino and and they did in the pdk okay so the control plane three routers use also standard distribute protocols and state and maps segment router index into the node ids so you can get available topologies into from a leak state protocols next please so show me just a small example how it works so for example we have a set of"
  },
  {
    "startTime": "00:52:00",
    "text": "switches we have switch 1 switch 2 and switch three and we have this polynomial for each switches that we have this is like a relative polynomial and you have output part as a polynomial as well so can you uh we're at like seven minutes of five can you yeah the last one so and go ahead so so you have the the route id and basically on each switch you calculate the mod operation by the remainder of the division between node id and port id uh do the id and the route id and you get the output part as in the final so next please go ahead so in the end you just then you pack delivered application in a transferred manner for the destination removing the the road id in the package next yes thank you thank you very much uh thanks for speeding up uh have a look at the slides we went a little bit quickly through the the last bits of how that goes on in each stage and uh raphael you're around for today yeah it'll be around today and tomorrow cool uh if you have questions please find raphael uh sorry we need to go to the next which is luis correct uh no oh luis is in queue no okay yes i think we have one more tour great luis can you can you ask your question in like 30 seconds elise is there hello luis contreras i would like to ask how the the protection is implemented in this schema so do you need to pre-calculate the the protection beforehand and so we we are able to encode a multiple path and the same encoding rotating so once this vector achieves for example you have some fail in one path when you go to the another path you are railing code that that switch needs to go to that part so it so you can have multiple paths in the same encoder that route id which means if this is not independently"
  },
  {
    "startTime": "00:54:02",
    "text": "one switch that another switch the result of them because they are calculated dependently so that's why we can encode everything together in the same rotate rotating in this case okay thank you sorry thanks a lot um i think you are a remote can you go ahead and yeah okay um mobile and this is a version of one of the 12 it's about a great base strategy strip between the endpoints and the intermediate node we have received some comments and we wish many sounds for that and we wish more comments about that uh the next speed should be i can control it our top packet is that we think that the bng working as a giveaway of the enterprise is able to maintain a connection per connection state and trust relationship for each user so based on this uh b3 or this png we want to make the endpoint trust the information from the ingress p specific uh intermediate node using this ingress pe can make some decision uh for the past to the equals p so it will influence the path of the current and the inverse p uh contrast the station from user for a user for example the underpoints in the client uh if if the client sends some suggestion for some information to the ingress pe the technology can trust them on the next page uh a initial magazine result is that from this english pe to the kind current"
  },
  {
    "startTime": "00:56:02",
    "text": "for example the university need to send some message to the hand it can for example make her as the nature for the message by using a private key so that if you look kind of receive it it can check it your the public key or the ingress pe uh if if the information is from the client to the ingress pe we think that the png can make a signature instead of the clan by using a private cave belonging to this png or the if the png between the bing and the english pe there is a ipsec tunnel it can send the uh traffic of the client into this handle so that the university can trust that the building have a check that is a valid user and the information is have been verified by the png so we think that if we have this gateway we can make it easier to have a trusted relationship between this client under the ingress pe uh then this thanks for listening and very welcome for commerce not here perfect and we have like three minutes for questions i guess luis you are you you're still in from last time yep no questions so great to be on time thank you all very much um so we are still working on the logistics of the um interim meeting on scion engagement uh expect announcements to the list shortly but this will be between now and philadelphia"
  },
  {
    "startTime": "00:58:01",
    "text": "um and uh i suspect given sort of like the engagement and all of the really sort of like interesting talks in the area that we've had this time that we will also have a meeting in philadelphia um you know a hybrid meeting in philadelphia um and it was great to see you all thank you all for um all of the talks in the discussion it sounds like looking in the chat it looks like um sort of michael's thing is halfway to being designed a group designed by people in the chat so we look forward to some um uh discussion of that on the list and uh to see how that develops at the next meeting as well okay thank you all very much and have a great rest of your idea thank you brian sorry this piece of crap tonight [Music] indeed"
  }
]
