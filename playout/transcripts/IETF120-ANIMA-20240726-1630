[
  {
    "startTime": "00:02:03",
    "text": "Thank you Thank you Thank you Testing my mic I'd hear you Yes, I can hear you Yes, I can hear you. Okay, so we are already on time. I guess we should just start Three minutes late already Hey, Shing, hey, Michael, when you're ready with the audio test, please mute yourself. I'm not sure if there's otherwise not too much feedback here in the room All right. Welcome I'm asking my microphone. Yeah. Okay Here in IETF 120, Enema meeting with a very fast switch over from Manet and I've already showed the note well please if you're not familiar with it, please take note of it oops wait a second oh it didn't upload the latest slide. Wow, okay I'd edit one more slide. I'm not sure why it didn't get uploaded here So if you're in the room, please, you must get into the on-site meeting tool so that you're registered for the room. Otherwise, next time we'll have to"
  },
  {
    "startTime": "00:04:00",
    "text": "do the meeting on the hallway Then also we have collaborative editing of the notes. So please, you know, if you have something to contribute, whether you're local or remote please go to the notes page and help edit the notes there So the active work in the working group has mostly been done on the working group drafts. So we have slots for and we just quickly wanted to use the chair slides to summarize the work of the other documents since IETF 119 we all had an interim in April 24 to discuss issues reported in those documents PRM and discovery And we have a lot of hopefully useful material if you're new to the IETF or ANMA about our procedures GitHub and all the other things in there in the backup of these slides but you two kind of trying to be conservative with the time, we're not going to go through them here. So what happened in the working group documents without slots? So we have the ANMA network service automatic deployment, which we parked and specifically said we want to give the authors more time to do something That was a refresh. I haven't seen an update from the authors. Sheng, any updates from your side? No, we are you know, because the authors also working on the grasp distribution with some from your side? No, we are, you know, because the authors also working on the grasp distribution, we think we should give the priority to it but for the second item, we are actually waiting the RA but we heard nothing so that make us miss the you know, the opportunity to do anything for this cycle Yeah, Mahesh is going to the mic"
  },
  {
    "startTime": "00:06:03",
    "text": "Ah, Mahesh yes, so this document originally showed up in Rob's queue when he was still the 80, but it does show up on my queue also. I know we haven't quite updated the documents. They don't get automatically updated with the AD roll but I have it in my queue and I will work on it in subsequent Thank you. Good So right so we had then the Brusky Cloud um Right. So we had then the Brusky Cloud. So I remember that when we're reviewing an IETF 119, we had 17 open GitHub issues. Now all the issues are closed, several commits, but no new revisions So I think the authors are just trying to make sure that everything is an order before they ref it on Datatracker Michael, can be one want to say something about that? I think, okay so I'll take a note TBD and ask the authors offline You're asking me to say something about Brewski Cloud? Yep please. It doesn't work I don't, I don't think this is working Okay, fine Let's go on so we've got"
  },
  {
    "startTime": "00:08:00",
    "text": "RFC 8366 BIS where we're punding the updates from the other documents as far as the impact the Yang model for the voucher and as part of that process with been driven from other documents the ional patients for it Yang model for the voucher and as part of that process we've been driven from other documents the ional patients for the SIT because we introduce now seabor encoding of vouchers and so that process just went through in the last month So in the SID allocation range for that, we removed 8366 which was already the last month so in the sit allocation range for that we removed 8366 which was originally in there but we're going to start a sit allocation only from 8366 BIS because that's also the first one with RFC's pointing to it using seabor And then we had various fixes, an example So then there was good on ongoing work on the constraint voucher A lot of GitHub issues closed seven left, mostly editorial And as a shepherd, I'll do another review round shortly. And then the document that's mostly in the waiting pattern since last year because of constraint vouchers to follow on to that, which is the constraint joint proxy and so we'll get to that when we're finished with the constraint voucher as author in Shepard. Okay. So that is what we had for the non-slotted working group documents. So on the agenda now we have an update on Brucey A.E from Stefan You want to share the slides yourself? yeah uh i just asked for the slides yeah yeah i think it's just and there we go. So you should be able to do that I don't see something on my side"
  },
  {
    "startTime": "00:10:00",
    "text": "So I requested again Ah, there it is. There is Okay. Yeah, just a short update on Bruce Key A.E. A.E for alternative enrollment protocols in Bruski Bruski So we had the, we had some comments from Mahesh, which we got in May, back in May so that was the AD review from him. So we handed the comments, most of them were editorial and edits that got addressed We also did the Gen Art review just shortly before the IETF cutoff meeting in June Also there, we just handled some NITs and basically we are now at Revision 12 So here we put a list of specific items that we changed in the draft based on the AD review by Maesh. Most of them, as you see on our editorial, though only thing that as a functional change is that we change the TLS general review by the enrollment protocol from recommended to mandatory to basically use the established TLS channel that is already there from the voucher request response exchange and not giving the idea that we would like to build up a new trend that is already there from the voucher request response exchange and not giving the idea that we would like to build up a new transport connection between the pledge and the register That was the only functional change in the document and then also then it's from the gen art review have been fixed. So thank you very much for all the reviews and so based on that working group last call is done young doctor three from the Gen Art review have been fixed. So thank you very much for all the reviews. And so based on that, Working Group Last Call is done. Young Doctors review is already, the pre-review is ready. All the different reviews that you see here are ready. So the current state is waiting for AD go ahead and based on the latest update the next step we see is IESG evolution"
  },
  {
    "startTime": "00:12:03",
    "text": "Any comments? So just your Q, Mahesh, I think Mahesh and I did put a comment on the whatever the chat tab in Meetecho So I do acknowledge that I did see the change and thanks for getting them together. I think, yes, we should be ready to, I do need to make one more pass just to make sure that everything is in order before I press the button to send it to IC need to make one more pass just to make sure that everything is an order before I press the button to send it to ISE. Okay, thank you. That sounds great Okay, so then I would ask again for slides and doing the next round with JW voucher Okay, so this is the update on JWS signed vouchers so just to have a short recap on that so RFC 8366 and also RFC 8366 BIS, they both specify CMS signed voucher CMS sign JSON for voucher artifacts What the draft does is it specifies JWS signed Jason for the voucher artifacts, so it's a very short document, it makes no changes to the 8366 as such And the approach or the encoding that is just described there is already being used in Burski PRM which I will give the next update then"
  },
  {
    "startTime": "00:14:00",
    "text": "then So from a status perspective, it wasn't working Group last call before IETF 116 We had the Shepard write-up by much Matthias Kovach back in July last year already. And then we for whatever reason, that someone slipped our fingers the individual comments from my hash that were addressed in the last version that we got in June So they basically related to some clarifications on the document scope and also some editorial improvements So what is open or to do here? is a Jana registration of the type value definition qualification, voucher, JWS, JSON and then the document as is is ready for the official AD review by my hand besides this individual comments that we already incurred and uh yeah as as always, we are interested in interp testing with others, most likely in the context of Brouski PRM So that's a short update on the JWSV voucher So did I hear something like we should do in IANA early allocation or for to help support the interrupt test? or can this wait with a normal problem? when it could wait for the for the normal process thanks Okay, so if there are on both further questions? then I will jump over to Ruski PRN I think three in a row is kind of fun Okay, so this is"
  },
  {
    "startTime": "00:16:00",
    "text": "the update on Ruski PRM so pledge in responder mode Meanwhile, draft us in version 14 Yep, so we had an interim anima working group meeting and we used the time in the meeting to some clarifications of the seat usage when there is no young definitions available for the objects that we use in the different prototypes and functions. So that was being discussed with Carson-Worman and incorporated accordingly for all the different CDDL examples that are in the document What we did afterwards was an update of the XI examples that we have in the annex, so the pledge voucher request the register voter request, and also the voucher to match the definitions that we have in the draft to allow testers to better test their implementations We added some clarification for cases when the clock itself has no synchronized clock how to handle the triggered voucher requests and also the triggered enrollment request, that there is not the same time, but that the time is being advanced from the trigger, from the first trigger message received. So that's being added to the draft. And we also added in the register voucher request for whatever reason we missed to include in the description of the IDAR valuation here, as it is described in RFC 899 so that was at least in one of the figures it was missing and it was inserted there so then afterwards that resulted in version 13 and then we did the final review or the final round of review from the Shepard. So Matias did i think starting from section six point something to the end of the document And the document has changed"
  },
  {
    "startTime": "00:18:00",
    "text": "from, yeah, the not for the functional point of view but from the structure. So it should be much better readable no specifically sections 7 has been restructured to describe the protocol flow, always using an overview description, the request artifact, the response article and also the return values. So that should read much, much easier now compared to the description before. What we included based on the Shepard Review, was a new section 6.4 that explains the necessary steps that are to be done or to be enhanced on the Maza site. We had that included for the pledge and also for the registrar and we had it implicitly stated throughout the text what is the expectation of the Maza and we put an old included for the pledge and also for the registrar. And we had it implicitly stated throughout the text, what is the expectation of the Maza? And we put an Owen section now in as we have it for the register and also for the pledge Then also based on the shepherd review, we had an alignment of the pledge status resource data. So that is specifically being done to rely on the same type of structure that we have in blueski so that means for the voucher status and the enrollment status, we are using this same approach and the same semantics and we added a new exchange for the pledge status where the reggae agent is able to query in which status the pledge currently is. And for the we also changed the utilized data objects to the ones that are used for the other status messages The only difference to Bruce is that there is in Bruski, the reason code is included as optional field for Brusky PRM. We require it as mandatory Last but not least, we included a new section on logging"
  },
  {
    "startTime": "00:20:00",
    "text": "hints, that's section 8. That's basically to give some recommendations, which of the events when there are error cases should be locked for audit So that's information section, but we felt that it is good to have it in Yeah, so far for the changes then based on the Shepard review, we have some food for thoughts, let's call it that way. One of the discussions we had was the Shepard was we currently have for the communication between the registrar agent and the pledge, we rely on HTTP because of with the Shepard was we currently have for the communication between the registrar agent and the pledge, we rely on HTTP because the objects that we exchange are self-contact so there are signed objects and there is no real need for a transport layer security underneath that connection It is recommended, or it is provided as optional TLS connection in the draft to ensure privacy of the connection between the red registrar agent and the pledge So for the case when for that one, we have a whole annex that describes the boundary condition and what has to be obeyed when using TLS between the connection of the registrar agent and the pledge because the IDID certificate that is used on the pledge side doesn't really can't really be used in the context of a TLS connection because it doesn't contain subject alternatives name and the DNS name So for that, the draft already defined to you utilize the X520 serial number and that the registrar agent shall be able to verify the serial number that is contained in the certificate when opening the TLS connection towards a pledge What we discussed with the shepherd was one proposal to"
  },
  {
    "startTime": "00:22:00",
    "text": "think about using a local name in the IDFID certificate because a pledge is discoverable via MD so if the pledge provides his local name via MDNS, which could be something like vendor identity, a pledge serial number that local then the red register agent would be able to verify the DNS, so the MDNS or the load name, which is contained in the ID certificate in the subject alternative field and that would enable the registrar agent to essentially utilize a state-of-the-art TLS in place implementation to verify the server-side authentication of the pledge. So we thought about that, and I also did some search through the CAP, CA Browser Forum requirements. So that one specifically doesn't allow internal names and the DNS name of the subject alternative field or component of the server site certificate But in that case, we use it here. It's not being used for browser-based access but for registrar-agent-based access So it's not necessarily a browser And we basically thought that we take that question and bring it to the working group to get it's not necessarily a browser. And we basically thought that we take that question and bring it to the working group to gather some input on that proposal. We know that if you use the local name in the DMB name of the subject alternative names, then this is something where we lose the verification part over a DNS server That is clear. But compared to checking the X520 serial number, it's essentially the same approach The pledge delivers both the X520 series number as well as the IDFID certificate. The same would be true for the local name in"
  },
  {
    "startTime": "00:24:00",
    "text": "the ID certificate any any thoughts on that Mahesh again, if you could go back, I take one slide Yeah, on the last item, which is the logging section I just took a brief look at that section and I don't know whether Buski has a format much like CISL does at most systems where you have different levels of logging information So what I saw was mostly info level information Are you saying that there are no errors? or other level of messages? that could be possibly logged? There could be further further locked. That is true. So we didn't use something like the severity field from this log to describe it in that annex. So it was just to give an idea what we would expect for the audit trail to be locked And then I would propose regarding the dot local if there are no comments and it would probably be good if we discuss that in the DC design team meetings or on the list and I can base basically refer to that as Carsonman then. I'll read the div before at Tuesday. So Okay, so we have included regarding the dot local we haven't included"
  },
  {
    "startTime": "00:26:00",
    "text": "anything in the draft because the draft also works without that but this is something to simplify access to a pledge and that's the reason that i just put in here a foot for thought so there is nothing included in the draft so far Okay, so then we have a second thing which came out of the discussion and the Anima design team meetings So currently, Bruski and all of the different variants like AE or PRN, they end the discussion in the Anima design team meetings. So currently, Bruski and all of the different variants like AE or PRM, they handle the provisioning of a generic LFID certificate So that one can be used to manage further LFID certificates in the operational phase, like applications LFID certificates or others It can also handle situations where the LFID certificates in the operational phase like application-specific LFID certificates or others. It can also handle situations where there's a handover between different domains, for instance, during and installation and commissioning. So in general, as Bruski focuses on the establishment of one generic elevator certificate, the intention was to you to So in general, as Bruski focuses on the establishment of one generic LFID certificate, the intention was to utilize re-enrollment options for the protocols that are used for enrollment and the same endpoints on the registrar to basically enroll for additional certificates This is something which is from a functional perspective available via those enrollment endpoints that are available on the registrar and it's not something which is specific to Grusky PRM. So what we discussed was the idea to put that as an enhancement in the operation considerations for the Bruski register to cut what we discussed was the idea to put that as an enhancement and the operational considerations for the Bruski Register to cover the case where more than just one certificate is being used during or shall be established during the onboarding time Any thoughts on that item? No, I was a talk about the team"
  },
  {
    "startTime": "00:28:00",
    "text": "but it didn't seem as if I was trying to figure out what, even if there is a good namespace to distinguish a different, you know key pairs and in result LDFs so that's what I'm a little bit worried about that you know, we've been talking about how we identify those in the team calls, and I haven't found a good evidence in the IETF yet for any namespace for that to exist. So, but so that's one one thing we can continue to dig in other working groups groups okay so then i'm jumping to the last slide so based on the current discussion and the status, we don't have any open issues. We had the working group last call before IETF 116 We had IoT and SecGear early reviews and all the young doctors early review. Meanwhile, the young doctors early review is not not necessary really because so Secure early reviews and all the young doctors early review. Meanwhile, the young doctor's early review is not necessary really because all of the young parts of PRM have been moved to 80s, 60 83-666-86 all of the young parts of PRM have been moved to 80s 60 63 86 so there is no young included anymore. Shepard Review and also the right young included anymore shepherd review and also the write-up has been done this week or finalized this week So based on that, we think that the document is ready for AD review Mahesh So I know you said the working group last call was done before one one 1116 Yep. Did any of the reviews result in any changes that you feel maybe a another short last call? may be warranted? This is more questions"
  },
  {
    "startTime": "00:30:00",
    "text": "for the chair so i'll take it as an a i between cheng and i to check the differences and see if a another last call is justified Okay. If you do the check do me favor. Keep in mind the whole structure of the document has changed, not necessarily the functional aspect okay I understand that that's the pain for us that when need to distinguish between really functional changes and that textual changes. The improvement, the textual changes themselves i don't think would qualify for last call So that's... Yeah, great. So I forgot to ask one question for during JWS voucher So the question is, right now the status is AD review, but that review is assigned to Rob. And I'm not quite sure of that it is also meanwhile in the list of my hash to do that official AD review Mahesh I think I just now updated the Datatracker maybe I did it for the other document grasp but I'll also make sure, as I clarified up in the big beginning of the meeting, that, you know, some of this is just hangover from the previous 80 I don't worry too much about it. It is on my queue, so I do see it and I will work on the document Thank you very much Okay, then I'm done thank you so yeah it is in OK, yep Yep, thank you"
  },
  {
    "startTime": "00:32:00",
    "text": "Okay. So this is the update on the Bruske discovery draft, which we adopt shortly after last IETF and which originated from pretty much outsourcing a lot of various discovery text from different Bruce-key extension drafts into this document to create a consistent and extensive flexible solution for that beyond what the draft themselves will maintain, which is for each of them pretty much one minimum MTI version. So I quickly wanted to go through what we had done here. So there was a lot of editorial work done We had in the intermediate meeting, we worked on finalizing the way on how to encode this in the core link format, which is one of the three discussions mechanisms that we are planning to support from the beginning on updated the document accordingly, and I'm going to do one more run through the text, trying to simplify it, maybe move a lot more of the explanation or so to the appendix that the main normative part of the document doesn't look as big as it is right now, but I feel the explanations are very important and would like to get to the state of asking for working group last call in or before Dublin So I've been trying to summarize a lot of the stuff so that the slides also are good way to get started understanding this because I would really love for more reviews to happen for the doctor I'm not going to talk in detail about everything that's in the slide So one of the important parts is really that we're having this concept of the proxies and when we do have different ways of registrars and pledge, to be compatible or incompatible with each other, we don't want to create more complexity by the"
  },
  {
    "startTime": "00:34:00",
    "text": "proxies also doing there. So one of the things that is incompatible with each other. We don't want to create more complexity by the proxies also doing there. So one of the things that the discovery does is to make sure that they're fully transparent and can pass on the information which registrar ultimately can be used by which pledge. And I think that will help very much to make the different variations that we may need to support painless So the outcomes of oh, this is not nicely formatted, I apologize So in the core link format, what we concluded on is the new name for the route targets, which is kind of the service name in CoreLF, Bruce key joint proxy, Bruce key RS for Registrar Stateful, and then Bruce key RJPI for the stateless proxy, which is new, which we didn't have in before in 89.95 because we didn't have the stateless methods format because that requires UDP, and that of course came with con constraint Fuski So as far as the way the document is trying to work, is ultimately it's meant to establish a registries in which all the information can be put so that we don't need to write for any extensions of discovery mechanisms, new updates to existing documents, create potential problems, but make that very easy And so the first thing is really describing the different contexts of discovery that we're interested in and what we're calling Bruceki is really the discovery of registrars by pledges potentially through proxies, which we have from 8995 and so what the registry is then going to do is to define authoritatively from here on out the service names used in the different product calls like shown here for Grasp, the good old A and join registrar, A& proxy, so those things that we had already defined, but now it becomes extensible when we want to add more"
  },
  {
    "startTime": "00:36:00",
    "text": "Same thing, DNS, SD, then C Brulski, constraint, Brulski, we're going to have three discussions mechanisms of interest from the beginning the core mechanisms i was just talking about dnsd going to have three discovery mechanisms of interest from the beginning. The core mechanisms I was just talking about, DNS, SD and grasp as well, depending on deployment environment that refer to the different ones In Brusky PRM, we also may want to be discovering the pledges That's another context, so that's agents discovering pledges So the context is the registry that defines really, you know, different discovery mechanisms to consistently discover one type of service in Bruske by some other entity So then comes within a Bruske connection we have identified different aspects where there can be incompatibility right? So on one thing, it's the whole endpoint that we're selecting. So so far we've identified that the normal way 8995 works, the registry responder mode, and then the PRM pledge responder mode. And, you know, a registrar may support both or only one of them. We have different formats for the voucher. We have the CMS encoding. We have the COSA encoding in both or only one of them. We have different formats for the voucher. We have the CMS encoding. We have the Jose encoding when we use Sebor and we have the Jose encode in Bruski PRM. So those are all choices of different implementer communities And we have potentially different enrollment protocols EST, 7030, RFC, and CMP, which is preferred by Bruskey AED deployment types. And then for reservation, just to show that there's a lot more, we're going to reverse SEP but we know there are others as well. And now comes these tricky things. How do we do that in the discovery mechanisms? so variation is really just a list of one value for each of the variation types right so brusky would be described as it's rrm plus cms plus EST. And to make that extensible"
  },
  {
    "startTime": "00:38:00",
    "text": "all this information is going to be in a registry And this is this second registry part, which defines the different variations type, mode V format. This is an just an excerpt, right? That's not the full initial registry Then the variation types, of course, the references and then also whether it's the default or not and then ultimately we get to the point, how do we encode it in the different mechanisms? and so when we came from pledges very small foot footprint, very, you know, difficult to diagnose software we said we're going to encode a full variation as a single string so that the only thing we need to deal with in discovery is, you know, a list of possible string, each of which defect a variation so the final and third part of our ready is going to be this list of variations strings, where we now have EST TLS or MPA empty string for 8995 CMP for Bruce G.E, PRM, Jose, for Bruski PRM and then empty or RRM Jose for constraint voucher. There are a lot of variations we can do, but the whole point is we're only going to add them to the registry when we have somebody asking for it so that we don't unnecessarily fill up the registry with things that nobody at this point in time wanted to implement It's going to be specification required so that we're it so that we don't unnecessarily fill up the registry with things that nobody at this point in time wanted to implement. It's going to be specification required so that way we can easily track when people want to start using variations So that's pretty much the concept I don't want to spend more time in showing me example encodings It's very easy to make all these encodings wrong There are a lot of crazy details not related to the variations, but I hope that the document will help you know, implementers that do the discovery to make them better. And so the red stuff is showing for the three different versions examples on how this is being done and explained the tricky parts"
  },
  {
    "startTime": "00:40:03",
    "text": "Mahesh, I think if you could go back to one or two slides to the INA the registry, the third, yeah, that one So, did I get? it right that currently? there is no registry? at least the entry for 89.95? That is the first line. 8995 is the first line and depending on which protocol we have there is a note down here it's either an empty string Some of the discovery mechanisms will not support an empty string. So then it's ESG TLS. So that's just defining exactly that variation 8995 And this is there today in the analysis registry. No, this is basically this registry is the is the main output of the document it is creating the registry okay so okay that was part of my question so is the main output of the document, it is creating this registry. Okay. So, okay, that was part of my question. So, currently you're saying 8995 has no registry definition and this doesn't exist exactly so someone who is going to go to 8995 only will not know... Will exactly find EST in GASP but it wouldn't find a really good information about DNSSD or if we wanted to, if somebody wants to do 8995 in an environment where the core discovery mechanism is he wouldn't know exactly how to do it, but he could basically just, you know ask for this to be added with CoreLF. So basically now these things just have to be done by extending the registry Yeah, I don't know from a process perspective what we can do to go back It's fully backward compatible, right? No, no, I understand. I'm just thinking from a somebody who's implementing does not know more than any of the other any of the registry entries is what I have thinking of, but maybe it's not an issue. No"
  },
  {
    "startTime": "00:42:00",
    "text": "It's all meant for forward compatibility because we've seen when we started to do the different variations here brusky prm bruskey ae constraint or so that we had to rewrite all the discovery texts and maybe just the subsets needed for that And then we always felt what is another implementer community another type of IOT network wants to use one particular mechanism but with the different discovery we've seen that particularly between um let's say, the IETF, who prefers CoreLF and then, for example, the threat group who prefers D We've seen that particularly between, let's say, the IETF who prefers core LF, and then, for example, the threat group who prefers DNS SD, right? So then basically what if we just have the IETF solution, they can bet example, the threat group who prefers DNS SD, right? So then basically, if we just have the IETF solution, they can badly adopt it, but with this registry that makes it for example, easier then. Okay, maybe then the only other question is this document does update 8995 I think yeah so I mean that's basically for up with we're through last call with the IESG review It's not any backward compatibility it's extending it so you tell me if up if an extension is is an update or not. So that's. Yeah. I'm just thinking from one way to kind of catch the fact that when somebody looks at 89.95, they will see that there's an update. I like the forward point I'm not sure if that's common practice in the IETF So there is no backward incompatibility or something So yeah, you tell me. I think it would be a good idea to at least mention that it does update 89. Yeah okay, all right So that was it. Please review review I'm I'm all for bartering, right? If you have something to review, I'm happy to do that as well. So you're up, Michael gibbs it working? Does it work? Yes. Yes. Okay. I was working"
  },
  {
    "startTime": "00:44:00",
    "text": "Can you put my slides? up and give me control? So I should oh, give you control. I haven't done that. Let me see. Just click on my name on the participants and you pass control. There we go okay the ACP implementation report, confirm your selection And then user management. Look on my name in the participants Pass light control, there we go Thank you, okay Good Okay, hi. I'm michael richardson here. I had a rough night I'm staying in my room to keep you all away from my gastric bug. And I'm going to talk about my implementation of really it's a 8994 but of course it has a bunch of other bits in it Who is List? There's a bunch of different components in my system and I'm talking most of the ones on the right hand side today many of you have used or used the components on the right on the left hand side. It's called animages. If you're a Harry Potter fan, you'll know an anime is a person who can change into an animal So it starts with anima and you may all know that Professor Minerva McGonigal, is one of the characters that can change into a cat And the goddess of Minerva is also the goddess of things So that's that's that's that's characters that can change into a cat. And the goddess Minerva is also the goddess of things. So that's that's that's the that's the nomenclature for you okay so uh this is a a rough architecture diagram i've tried to to come up with a good way to explain it brian carpenter asked me, why am I using Penrose diagrams that would otherwise describe black? hole space times? And he's absolutely"
  },
  {
    "startTime": "00:46:00",
    "text": "right. They do look like that, but they're not. They're just boxed So there you go. So there's three different pieces here and they use Linux network namespaces which is the component of how it implements containers but it doesn't use all the other pieces so it doesn't for instance separate the file systems or the process IDs or the user IDs. It could, but it wasn't necessary to do that So there's this one name space, which originally I was calling the dull name namespace, and I realized that was kind of very specific to grasp And so I'm now calling it the ab abutment namespace because it's connected, it's abuts the other piece. Then there's an AC namespace, and finally there's a system namespace and the key thing you need to understand about network namespaces is that each have their own for forwarding table, set a list of interfaces neighbor cache entries and all that kind of stuff so they're effectively different systems but you can in fact build interfaces for instance, you can build Ethernet pairs that you can put one in one namespacer and the other namespace and then you can have traffic between them for that. So in the bottom, on the bottom, you see this one called ACP 0 zero so you should imagine that is an interface that the system sees and it's got a, slash 48 route into the rest of the ACP. So the ULA that the ACP would be running on So a little bit more about how it works There's a main system. It creates this abutment namespace using an unshare system call. And then it actually has to start the thread and event-based runtime because you can't spread that across processes establishes some I has to start the thread an event-based runtime because you can't spread that across processes. It's established some IPC to, you know, be able to communicate options and other things about that uh creates an a cp namespace"
  },
  {
    "startTime": "00:48:00",
    "text": "similar kind of concept, runtime starts, and another IPC. And then essentially then it starts scanning the interfaces. Looks for available interfaces when it just discovers one that's new, it makes a pair pushes that interface into the abutment thing and that how you actually get the abutment connected to a physical interface and then when things are detected and tunnels are created, then the system creates this X-form tunnel and it sends it as the ACP names and that's where the Ripple Demon can then see the other piece ends of the tunnel So what it looks like with you have two of them there's two test systems minor are named Moira and Ovid and they're related in complicated way to Greek mythology doesn't really matter This guy does an M flood. This guy says, oh, I see you there, and I'm going to do an IPSEC Ike with you. And let's see how that works. And it's going to create an ACP interface to represent that tunnel that it's bringing up so then you get an ESP tom tunnel between those, the two, a button namespaces. However, the package that come out of that tunnel are sent to this ACP interface in the other namespace So the outside of the tunnel is in the abutment namespace and the inside of the tunnel is in the ACP namesp namesp which is essentially exactly what we want to have happened And then the ripple demon says, oh, look, there's a new interface. It's up, and it's going to send some messages on it, Ripple Dio's and DAOs, Destin, DoDag information object, and do-dag advertisement object that's the kind of back and forth, and you establish a mesh on top of it So a little bit of about it. So there's a demon called this what I've just described is a demon called Connect, written in Rust"
  },
  {
    "startTime": "00:50:00",
    "text": "started in 2020, but 55,000 lines of code. It uses a fork of open swan which was known as Free Swan and Libra Swan and a very long time ago, strong swan fork from it so that's you know going back 25 years ago for that And I just made a fork because I didn't feel like our arguing. But what? And I don't want any IQ on code or stuff like that, messing things up and then I have a ripple demon called unstrung which was written in C++ around 2009 there and I thought it was I think I'm probably the only person that's written all three demons and has all that technology in some ways in my hair at this point there's lots of interesting challenges along the way. One of them was that it turns out that if you let your you let your namespace kind of die on its own with this System B, then it gets really confused and kills things and you have to recruit your system So that seems like a real bug on I don't have time to pursue it there And then the major problem was that ESP packets don't have a way to connect them to the right interface. So while you can put IPV6 link local addresses on the outside, it turns out that you can't scope them to the right interface and packets go with the wrong interfaces and this was this was hidden a little bit because some of the earlier technologies caused other problems so for instance, you create a tunnel from A to B and it would capture all the ICMP neighbor discovery messages that means that you can't discover B and then things don't work if you do it in the wrong order. Um, but uh, the lack of V6 link local address was obviously in hindsight. I'm like, oh, I didn't notice that. But there B and then things don't work if you do it in the wrong order. But the lack of B6 link local address was obvious in hindsight. I'm like, oh, I didn't notice that. But, yeah. So the obvious thing was to well, we should modify the kernel to put scope ID"
  },
  {
    "startTime": "00:52:00",
    "text": "i'm like oh i didn't notice that but yeah so the obvious thing was to um well we should modify the kernel to put scope ids for this and that was a you know something like kept thinking it's a good idea and many people a couple people in which group were like yeah, how do we get it done? And then someone said last point said well could we just do this with UL8? instead? And I was like, i didn't want to do that because i wanted to fix it properly um And then I said, okay, well let's just try it. Let's just go forward and try it And the other reason to try it is that I'd like to build to run this code on what might be slight older switching platforms and writing equipment that have Linux kernels which for which we might never get a be able to patch the kernel properly. So it, uh, each system numbers, its interfaces, using a different ULA than the ACP ULA And let's say it's, you know, FDAB, one, two, three, four, five, six using a different ULA than the ACP ULA. And let's say it's, you know, FDAB, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, and then the next to the subnet ID, I just made it be the IF index number, which is at least unique within each namespace and then the lower 64 bits come from the interface identifier anyway for that And I'm trying to go faster here So the grasp changes slightly There's this announcement of, you know, instead of link local address down in the protocol description, it's a ULA I left the initiator to be the idea link local address. I think that works well And one of the things that you need to do, so these are 128 bit ULAs and it's interesting if you were in the room earlier, Fred talked about multi-link addresses and actually we could use those two and we use this as a demonstration really of using ULAs in that same kind of way. If there's someone's still in the room left over from Manette. So to make it work, you have to"
  },
  {
    "startTime": "00:54:00",
    "text": "put a route in. So there's a route you see in the 128 is implicit there and it goes via a V6 link local address with an interface identifier in which case it's called dull as I remember I would calling them dull 14 oh that's related to a number, so it's a unique name. And so you wind up with one in each direction going, or one for each connection that you're going to have and that's really no different than uh to a number so it's a unique name and you see wind up with one in each direction going or one for each connection that you're going to have and that's really no different than any a neighbor passion tree the same thing so one of the things I learned in developing this is that so let's has these things called Mac VLANs a number of other platforms have this, and basically the second Ethernet address, the same physical hardware underneath, and that's wonderful and it works great, except that if you have an interface that is also part of a bridge then it uses the same the two mechanisms use the same internal hooks so you can't have an interface that's both part of a bridge and has a MACV land And so it does the right thing for that. But, because we these interfaces are made up they get random randomized Ethernet addresses, which makes their least link local addresses, unpredictable which is kind of annoying because you can't hit up error return to resume your debugging you have to go and read what going on and you have to send the right thing to the right place Oops One of the other things that was really annoying is that each one of these ACP interfaces that it puts into the ACP namespace originally i was calling it a ACP 001, 2, 3, 4, whatever, you know, whatever and I'm like, oh, I can't sort which one is which So in the end, I gave them a name, which is the lower four digits of the, um, address, the of the link local address that connects them to so this is now an EULA, but it's still the lower four bytes and I sorted them in the way, so they're consistent across"
  },
  {
    "startTime": "00:56:00",
    "text": "the two or three systems that you see here and this is you know three systems that have a triangle mesh between them so that made it made that just like the number of times where you go to debug it, it doesn't work, but it turns out you're just being the debugging wrong. That reduced it by, you know, 10 times, like, okay, I'm actually testing this problem and you can see that there's an ESP packet in that gray box down there that's going from those two addresses So 8D4 to 3E6B. There's an ESP. It has a spy number and a sequence number and some of that stuff works What doesn't work, however, is still there's some issues with keying where both ends key at the same time the duplicate keying detection doesn't always work, and one end deletes the wrong IPSEC essay. This is above the same time the duplicate keying detection doesn't always work and one end deletes the wrong IPSEC essay. This is a bug and the end result is that there's a timing dependency and when it doesn't work you get this very difficult bug thing from the ACP In my testing I have typically three machines because that's the kind of minimum that's interesting When you put them on a land you get the kind of you know, picture on the left, where they both, you know, kind of connect to that and because of where they ripple works, they both wind up being direct children of the other node The more interesting thing is you put them in a series, which means creating a unique land between each one so that you'll actually get a deeper stack and a more interesting thing. And that machine, green machine, Wara still has to have two connections to the two places um actually get a deeper stack and a more interesting thing. And that machine, green machine, Wara, still has to have two connections to the two places. So one of the problems is if we keep the uLA that's probably going to need the going to need a short draft to amend eight that says do this I'm really, really hesitant to say do this because it's a hack that I think we'll just never go away"
  },
  {
    "startTime": "00:58:00",
    "text": "We can announce both the new the original and this mechanism in, in, in, um, grass, but of course if a note doesn't support doing ESP over link local V6 addresses, then it shouldn't announce that and so I don't know what the right answer is I would like to have it work on sort of every kernel out there but I would also like it have work it properly There's a lot of the debugging is seriously tedious, as I say, you get a lot of random numbers from things and it's hard to know what it is, what's what, and it would be nice to get a picture or a diagram, enough data to get a picture a diagram back as what's going on and that would be nice that we could have you know yang modules or something that that really turns that and something to draw a picture. That would be lovely And finally, one of the concerns I have ongoing is what if you have a lot of machines so you have a cabinet full of servers connected to a top of rack switch with does not speak ACP, then well you're going to get a lot of potential tunnels connected because you've got a full mesh potentially that would occur. We don't need a full mesh. We need, you know, two or three connections but you don't, Ripple doesn't get to prune the connections until after the tunnels are up so that's a lot of tunnels that are creating for potentially no purpose and so grass probably has to say some to prune the connections until after the tunnels are up so that's a lot of tunnels that are creating for potentially no purpose and so grasp probably has to say something uh about that and there's different ways we could do this and I don't know the right way. But we did do it something equivalent to 9032 for six tish and we could repeat the same kind of thing. And that would be such a well-outly problem to have, wouldn't it? I'm done thank you very much i'd like to comment on that link local stuff because it just occurred to me that we're not the only victims"
  },
  {
    "startTime": "01:00:00",
    "text": "But for those folks who've been following six men and there's all HDP BIS, there's been for years the ongoing struggle for support of link local eddb addresses and browsers, which kind of led to now maybe even retiring more of the basic link local support in, you know, your encoding. So it's a really pain that, you know, link local addresses are the correct way to do things but they're hard and they haven't been used much So a lot of the industry hasn't and doesn't want to adopt them correct So we're perfectly on the right track of that with the rest of the iat have to try to find a workaround unfortunately But so I like what you've done very much and I'm just wondering if we can find a way to use these some addresses, which are not heuristically clashing that are global and we're using them locally. So I I'll be thinking about that and I think as an outcome what we would have be beyond maybe these these of implementation considerations to document them is, as you said, some potential extent that we're really standardizing for a GASP Dow to allow the use of such addresses, right? Which is either a heck or if we can get it work without, you know, random collisions then I think it's not even a heck. It's just a recognition that the link local addresses are difficult Okay, anybody else? No, so we had one extra non-working group related presentation Sheng. What's your opinion on going open? or do we want to try to move it to either double? or an interim what's your preference if we could go over time we would like to do the presentation that's done by Norway maybe five minutes"
  },
  {
    "startTime": "01:02:03",
    "text": "okay that's fine it's not working group so from from it's yeah, please go ahead then Your arm um, oops Thank you so much I... I... Thank you you very much. I... I... I... Thank you give me the control? I can see the slide in my screen There is Yeah, let me try to see that I bring up this slides and pass all Okay, be quick I will introduce the last wish graph proposal by me and the shirt With the rapid developments, the IOT is urgent for staff management The animal grasp has great potential for self-management however, it is not an ideal choice for the IOT The main reason is that the grasp is built on T TCPIP and relies on the reliable transport services provided by TCP By the TCP and I is not a good choice for the resource-castry devices in the IOT Of course, both the TCT and IT are heavy. Second, the additional lengthening control overhead and memory consumption calls by TCT are inevitable"
  },
  {
    "startTime": "01:04:00",
    "text": "In addiction, the TCT performs badly in the wake network environment Thus, we have proposed the waste graph, which is UDP based based So there was two main changes for lightweight grasper over the grasper The first is that we have shortened the fixed fields in details the length of session ID is changing through 32 to the 60 the 16 weeks The object to identify is changing from the test string to the with indefinite less to the 8 8-biz objective number. The second, is that we have introduced a message-oriented building library magnetization, which enables the lightweight to work reliable over UDP with the 16-bid number that is announced attached to the message, the language message can be acknowledged and re-transmated either if time out For this, an app message and to you know options are newly defined In the lightweight grasp or the unit message must be acknowledged and so they must carry a direct-act option and can carry zero or more act options while the multi-cast messages are not necessary to be acknowledged, and they are not allowed to carry the either of the both new questions new options In addictions, we also discuss the possible IT in the IP-independence methods. Things that IP can never"
  },
  {
    "startTime": "01:06:00",
    "text": "are not always supported by the resources can still node in the IoT. The core is to select and define a new locator option and a new protocol identifier And an example, how to exchange the language graph over Bluetooth, low energy is given in the job Before this, meeting, we have received some comments from Brian with regard to his suggestion In the future, we intend to add a magnetion on the recipient side to detail possible duplication caused by loss of acknowledgement. And we like to pay more attention to the next you acknowledge and more security issues concerning kastry node and possible solutions solutions Is there any comments or questions and we will to know is the animal injected? this work. I'm down Yeah, we really encourage people to read this new draft and in last ATF I did giving very short introduction without draft Now we already submit the draft and we hope people could read and give us comments. More importantly, we would like to hear from the working group, whether this interesting work to adopt by the working group in the future and also whether it's in the milestone of the"
  },
  {
    "startTime": "01:08:00",
    "text": "animal working group. Thanks All right closing words. Thank you very much, everybody Please read, comment, review the working group documents and the other documents you're in interested in and use the mailing list and also see you back in Dublin Thank you all See you in Dublin Thank you. Bye-bye I have it as well. Yeah that's a quiet group Well, it doesn't have room and Scheng not having gotten a visa in time and most of the European folks being on vacation"
  }
]
