[
  {
    "startTime": "00:00:27",
    "text": "everybody so this is the network cooling sorry for the cutting for efficient network communication so troop we are on time but maybe we can wait one minute one more minute this is the first afternoon session so maybe it makes sense to wait just a little bit the agenda is not total fool we have 20 minutes belongs time at the end so if we need we can discuss just a little bit more it\u0027s feasible this time so it\u0027s wait a little bit before starting [Music] [Music] all the mics you get so good afternoon everyone this is again like as I was saying this is the coding for efficient network communications research group if you here for this great if you\u0027re not you\u0027re going to have a great meeting anyway and you\u0027re going to learn about something fantastic so um the goals that "
  },
  {
    "startTime": "00:03:28",
    "text": "we repeat at every meeting is that we would like to foster research in network and application layer coding to improve network performance and I would say that if I look at the people from this room a lot of them have been very successful at this we want obviously to focus on the codes themselves and the libraries to be able to implement them we want to look at the protocols beyond the codes with the protocols to facilitate the use of coding in existing systems and existing applications and we are welcoming all the time and you\u0027re going to see some of this presented today real-world use cases and work in progress in the field the note well which is the usual IRT F and the same actually we share it with our friends in the IETF it\u0027s about anybody who has issues and especially patents and things they have to be disclosed we have all of these wonderful sites and mailing lists and the slides that we have today and obviously will have a bunch of people on meet echo so I will say hello everyone on week ago I would say the interesting thing that you should know is that we\u0027ve started to make a huge usage of the github instead of relying on a week the wiki and you know a lot of stuff that was in the data tracker because we feel it\u0027s easier to manage and it\u0027s easier to collaborate was very difficult to update the wiki when you have two or three people doing it so you will see that if you go to the wiki by any chance you\u0027re going to see that essentially you\u0027ve been sent to the github and all the latest document and the latest comments including the code that we\u0027ve been developing over the weekend or there so Elizondo okay so the agenda is is kind of very simple after I\u0027m done talking we\u0027re going to talk about is what we did on Saturday and Sunday we\u0027re going to have a quick update on the satellite deck document that is very much ready to publish now frankly we\u0027re going to talk about another update of something that is very also very close to be able to publish which is the network coding on CNN and Jung we\u0027re going to have a fairly extensive presentation from Muriel and Karen who are on the meet echo on basically our LNC other random linear network code then we were going to hear from Hosmer Michelle about the progress that was done and also some of the work that we intend to continue about adding forward error correction to quick we\u0027re going to have Morton who is in the room talking about coding for low latency and finally and not you know finally but not not to be forgotten we "
  },
  {
    "startTime": "00:06:29",
    "text": "want to talk about what\u0027s happening about the the RLC ether but now we called it which is related to the swift codec and that the standardization related to it in the transport group and you know raising some of the issues obviously future meetings the hackathon will have another one we had so much fun we want to repeat the experience and and by the way you have more women would like to come to the hackathon that was like I wasn\u0027t the sisters lunch right now and we said that the problem with the hackathon it was like you could see huge amounts of men but they were not only women so I encourage more women although I\u0027m speaking to a room here also with this a strong not a strong number of women and we are going to obviously to meet in Montreal and if anybody wants to have any hints about material it\u0027s my hometown so send the email and without further delay we\u0027re going to go to the first presentation which is its Nico right H I know it\u0027s you for the hackathon it\u0027s true it\u0027s yes hello yes so the goal is to do a quick status of this Agathon project that we started in previous IGF 103 in Bangkok so the Aki phone is about this Swift codex which stands for sliding window FEC correct so as I said this is the second marathon we second time amid for this project the goal is to design an open source reference and free codec with as a first goal being able to do a noisy like codec and as a second goal an RNC like collect so for the first time we will only focus end-to-end communications one encoder one decoder and as a second goal we will add this oil NC Network coding with potentially the capability to do rien culling within the network so that\u0027s the goal and of course the the final objective is to add this technology easier to tests to integrate or to benchmark facilitate adoption another goal is to challenge our generic API internet draft I will come back on the spectrum so in during the first ITF 103 I was almost alone so this time there was a great team as you "
  },
  {
    "startTime": "00:09:31",
    "text": "can see it\u0027s almost balanced in terms of gender we had two women including my Jose and may not and our free eye so it was great we had a lot of fun and we made a lot of progress so we so we made a lot of progress I mean most a story that we managed not to finish the encoder but we are not very far from the end on the unclean site so we are capable of submitting new symbols and computing randomly not munitions on the symbols and closing the session strings like even it is some tests on going we are not very far from the from the end at the end so the encoder is the simple spots next time we will have to do the decoder in fact we started the decoder program but it\u0027s not yet very well against so we had this as a goal for next idea we also wrote a te client-server demo application that\u0027s also another way to test the codec itself with threads and we have almost finished this part of the work and we started a python wrapper on top of this on top of the api to add to add this the ability to integrate this c codec into Python applications I won\u0027t come back on the design principle of this correct we already discussed this in the past so the idea that okay this is just the cross thought of the FEC correct all many parts of it are left to the application so the signaling all this stuff is managed within the application so I won\u0027t go into these technical details something great with this a Catherine project is that it enables us to make progress also on the internet dot internet draft generic API thought so we as we do the the world technical work we I don\u0027t find a few problems we solve some of them so we made few fixes in this engine draft four or five and we also I don\u0027t find open points but is to say point as technical aspects that we need to figure out how to solve in the coming weeks so all of this is documented in this github document so if you want to other better look at more detailed view of what you have done and what remains to be done to address those open points then you can have a look at this document so next step will be to continue this work so it will be in neutral ID f-105 that time I hope we\u0027ll be able to finish the encoder and to have a working decoder so that we can do interrupt test between the encoding and decoding sites so that suitable we\u0027ll see if it is a "
  },
  {
    "startTime": "00:12:32",
    "text": "reasonable if we can achieve this but maybe it could be possible also there is a lot of clean up all the stuff of things to do on the side aspect of this codec but that\u0027s the goal for next ITF and then for the ITF 106 we\u0027ll start working on this we including capability that we want to add into these projects has to be a Island sea to have an oil and she like solution so at the end we will have both a support for algae purely Antoine and Kareem recording and Ireland sea with the capability to have this gray encoding within the network so that\u0027s that\u0027s all for this academic project just want to say something else - a sense yesterday an email asking for research group adoption of this document yeah I mean the generic API document this is something that we already discussed at procite EF so there was two positive opinions on doing that on cognition we have this not only one correct but the ability to test stress this API with two different codecs which is exactly what we want to achieve so if you have an opinion if you agree disagree do not hesitate to send your opinion to the lists the fact we have this document as a document does not mean that we necessarily need to publish it as an information or I see that\u0027s a side question we\u0027ll see that later on it\u0027s not very usual for ITF for at EF you have API document so we will see if it makes sense later on but anyway it\u0027s important I think to have both works interim since the mesh of the nation\u0027s major connections between the two so that\u0027s its if you have commands questions indicate okay so let\u0027s continue hello everyone that\u0027s a quick update on what we have been doing in this draft since the last IDF further next and only slide is basically we had lots of at the ATF we presented this document in front of the ttn working hope as well to see if anyone wanted to review it so we had lots of comments from riderhood and lots of emails I changed he had lots of good "
  },
  {
    "startTime": "00:15:33",
    "text": "points and try to sum up here what we have done basically at the beginning we wanted to have lots of people on board on trying to speak about what was actual deployment on network coding in higher layer in SATCOM systems we failed to do that so we have more focused on indentifying opportunities so we somehow had some words in the introduction that were not really accurate also we had no motive references which are not relevant for research document we had an economy list that was not up to date and we were not clear on whether fitty color coding were involved or not so basically we removed any mention to physical layer coating so we haven\u0027t had many feedback scenes and we believe the hoop is draft if still what happened for being published as an RFC is ready to do so that\u0027s what I had to say questions comments so we are first grade because since nice times if necessary infraction so you had many discussions with Lloyds was great because I think it made the document progress in the good way so if nobody objects maybe we can start research group last call on this well see left on the list anyway but it\u0027s really a list where these three weeks period for all research group last call and hopefully people will come and I will anyway does anybody intend knows that you will read and comment so this document during this last call how many people yes what great okay so at least or two is me that\u0027s great that\u0027s the minimum I hope there will be more people but anyways it\u0027s a good start yeah yeah perfect though thank you thank you movie yes no okay say yes yes you have to floss "
  },
  {
    "startTime": "00:18:48",
    "text": "hello I\u0027m in matters because he saw I\u0027m not so no from when I cheated so let me talk about a quick update on net recording for session and young requirements and the challenges so first let me talk about this draft of summary the main objective is to introduce research result related to this topic and established come on there\u0027s something about to energy for energy for network shishun and then again and is to clarify the requirement and also to describe the research challenges so by doing so we hopefully we provide a user for any sites to network need to code who try to implement network coding intuition and en you so distrust now are focusing on the requirement so describes a specific solutions and were mechanism out of scope of this draft so actual protocol proposal will be down in another draft so regarding mine applet we we addressed missing your content such as we added backward compatibility section because there is no description about about these two requirements so we describes recording comparability compatibility weights were a network operation with consideration for since my work - migration and also we added the content regarding security privacy and routing in the channel dissection so net recording operations and in network caching related to content poisoning and cache pollution attack and the net recording of may offer encoding vector modification by attackers protocol exertion is a real challenge to avoid them and also along with the context of the requirements section we added routine challenging how to achieve scale and efficient routing scheme to achieve on a high performance as well as to simplify the the routing process so today we we got used very good useful comment from Cedric sound from India so and after we address the comment we get we ask we want to ask RG first thank "
  },
  {
    "startTime": "00:21:54",
    "text": "you yes so thank you so what\u0027s your plan you intend to address these commands in the coming weeks before next site if any way but quite soon that\u0027s the Eid yeah okay last call like can I do rustico in the mailing list the we can wait for you to update your documents which is why I ask the question and then in your columns with Dave and the energy is a group we can organize this last call so I don\u0027t know how exactly to proceed so they were and what I see in our get your hat on I think that at this point we have some concrete comments there enough to Rhys pin the draft on once and there\u0027ll be simple my suggestion is just go ahead and do that now and then we\u0027ll send that draft around I\u0027ll make sure that it gets some review in the IC NRG see see if there\u0027s any further things that the ICA RG thinks and the NWC argue thinks and with the goal of turning into a last call well before the next IETF right see if we can turn this around in a month or two make sense thank you thank you okay so thank you thank you very much so yes can you put the slides on again because there\u0027s other people on the deck needs to see this like right now we just see your faces all right okay so you want me to put the slides on an icon and just close your just close your okay I can do it great thank you thank you thank you you guys see the slides yes you can what applause all right so on the first slide this is just really giving an update on what happened to Jeff Ida and w CR g Arlen c00 so remember just a little history here this was submitted every 2018 this document contained a large background and symbol it was focused on simple representation still is so we "
  },
  {
    "startTime": "00:24:57",
    "text": "submitted two updates to that document so we separated the background information on still pretty much simple representation so it\u0027s not complete in Arlen see background document and then the second one is dedicated updated the second one they have 0 1 and it\u0027s dedicated to presentation this is collaborative worked with an of code and Mossad all the way we are peeking in the name of all the Maryland are moving to the agenda slide though as I mentioned we split the document into the background information and simple representations itself in the updates in 1001 I\u0027ll just you know Cisco we have new definitions that are engines couples we have two important exceptions and then and then I\u0027ll cover them what we need look towards doing for the next version you to modifications mostly from comments from the list and of course if you guys have come in from this nothing will add them up and and respond to them so going to slide 3 so just I\u0027ll give another of the current changes we have here so in the first document informational as I said a general background it\u0027s supposed to be on Ireland see that\u0027s the goal its documents and development still now it\u0027s focusing on the really the background required to read the single representation so an important section was again which is really viewing symbol representation as an important standardization target we actually argue for that in this document and then in the second document which is a simple representation specification itself added definitions and and improve the figures most of these comments come from so thank you very much visit and and that\u0027s it let\u0027s go to slide four so on the definition symbol representation really we spelled out the definition you see there\u0027s a slight difference but basically the same we are talking about these little carrying data that means this is what you\u0027re gonna have on the wire it\u0027s not of course what\u0027s gonna be used in the encoder the decoder that\u0027s different so if you guys "
  },
  {
    "startTime": "00:28:00",
    "text": "have any you know comment on this definition this is a good time to say so on the disclaimer here most of the points I\u0027m gonna say it after this are really touching upon the some of the comments on the on the on the background section and also I\u0027m gonna cover what we added in the background section the the section about simple representation so you see here the figures is really the fundamental concept that you have in in the experimental a draft which is the second version are in c01 so in addition to changing the adding this definition we really just change the format to 32 bits that\u0027s all there is to it if you have comments on that draft feel free to send it on the list and we\u0027ll take care of those as they come in alright so I\u0027m on slide 5 now so the major argument for standardizing simple representation according to us is that there is a lot of flexibility in Ireland see and so we really need the standard I mean that\u0027s that\u0027s for sure but once we have it it\u0027s going to be highly reusable and so the point is of course that Ireland C is is very dynamic the structure is dynamic if the simple set is very reconfigurable so examples of reconfigurability are given we mentioned coefficient location you can cluster the locations at the front which is done actually the symbol representation you can do de-seed which is something completely different and you can also do an indexed representation where you if you have just a few coefficients you can put them you know really unknown juxtapose one next to the other each one of them having an index indicating which symbol they refer to basically so so there\u0027s a lot of flexibility the reason for this flexibility is that symbols and you know are LNC tailored can be you can operate on it you can use linear operations on it without actually necessarily knowing have the location of so once you put them there you can it\u0027s the same operations that are done tailored for the positions themselves which is a really unique aspect that adds that was point one the point two is the of course the number of coefficients is quite dynamic also the number of symbols so you can have dense curves you can have sparse codes and actually the sparsity can be even dynamic itself the Third Point of flexibility is a simple size clearly you can have larger symbols or smaller symbols I will define actually "
  },
  {
    "startTime": "00:31:00",
    "text": "some of these concepts later because we\u0027ve had questions about this that so you if you you\u0027re expecting in your network to have anything like fragmentation padding or even encapsulation which is standard procedure everywhere then you know it\u0027s it\u0027s this is very useful this flexibility is useful and then finally the field even the field which is you can think of as something fixed in most applications it can be flexible there are interesting use cases where you can make the field flexible you can control the complexity of the coding you can actually deal with different device capabilities some of them can deal with higher fields and others with just small you can have flexible fields and one of the interesting things about RNC is that the same operations can hold for different fields that\u0027s another discussion so this is what I have on this slide on slide six I was going to just tackle one example so as we said network operations will be affected by single representation so an example is fragmentation and it\u0027s very simple either you know where your coefficients are or you don\u0027t and if you know them then you can\u0027t separate the coefficients and do the fragmentation that\u0027s what you see in the figure the a code or a fragmentation you can actually run recoding and modify the code on you know different fragments and then you can do the decoding and if the coefficients are unknown so this can happen also I\u0027ve received comments on that on the list and reply to some of them though suppose you have a file which was precoded at the different layer so you know it\u0027s good but you don\u0027t know where the coefficients are then you basically have to if you need to do coding on the different fragments you have to add new coefficients and that\u0027s what we call by adding a new layer basically you have you don\u0027t use the same coefficients you\u0027re adding another layer of RL and C that you need to deal with of course at the decoder okay so if there are questions here attack we\u0027re happy to do to respond so I\u0027m moving to slide seven so here\u0027s slide seven it\u0027s still you know arguing for the standardization symbol representation and so the point here is I mean there was a figure similar to this in Yanis presentation in London Yanis mentioned and through that of course simple representation can be reused by multiple protocols simple representation also effects the architecture the linear architecture it affect it effects including topology that you can use alright we\u0027ve received some questions on this too so one actually architecture of course related architecture where you put the coding you can be using the "
  },
  {
    "startTime": "00:34:02",
    "text": "coding for routing you can you can just do the encapsulation as mentioned earlier these aspects are affected by where the coefficients are for example and other aspects so on the topology side we are talking about the logical coding topology and the good example is whether you need to do recording or not if you need to do recording then the coefficients need to be apparent if they\u0027re not explicit then you can\u0027t really do you\u0027re left with end to end if you can do the record and when you can do a lot more specifically mesh and cooperative operation right and of course the protocol as you mentioned generation versus sliding-window that\u0027s pretty obvious all right so now I\u0027m moving to the next section which is overview suggested changes almost slide 8 so on this we have received comments from Dave and Salvatori mainly seniority thanks and and also Dave Oran thank you very much multiple comments and on the first on the background draft we have we\u0027re looking at substantial changes so there\u0027ll be a bunch of definitions that will add there\u0027s a lot of networking terminology that needs clarification or correction to that there is they\u0027ve mentioned trade offs related to coding parameters we talked about that a little bit and of course a security section will discuss what we put right in the Security section on the RNC draft so there the second version of the symbol representation it\u0027s really just maybe some clarification of definitions that are required there so again if you have more comments on them to the lists so I\u0027m going to slide 9 so just an overview of the kind of definitions we\u0027re going to be looking into so first of all I mean before the definitions networking terminology so yes there is a little bit some a little bit of washi use of the word connection - as I mentioned also in an email just earlier link versus channel and the losses versus errors so most of this stuff comes from really any different backgrounds of people people working in communication theory maybe information theory versus networking different terminology so I I go back I mean I\u0027m gonna say from you know from the get-go that yes we\u0027re gonna look at the taxonomy draft RFC 84 of six and maybe connect our document with that a little bit more refer to that some of the definitions some of the terms that I think we\u0027re going to be using are going to say field elements rather than since "
  },
  {
    "startTime": "00:37:02",
    "text": "symbols is not I mean symbols is used in communication theory to mean you know it\u0027s related to modulation so so it really means field elements here we\u0027re gonna use field elements what we mean by symbol here is more than networking coding implementation term which is really the coding data units it\u0027s in a racial element raw data yeah I mean Yanis mentioned yeah this is a good term I think raw data it means anything like uncoded or systematic or assembles input symbols application data all of that has been used to check the taxonomy but you probably be using raw data so again I mentioned representation is what goes on the wire is different from what the input and you can have so this is not necessarily the data structures in here in the nodes it\u0027s really at what\u0027s on the wire we agree on that so coating layer is interesting though I mentioned in the example of the fragmentation and so you basically by adding coefficients and when you do new very new operation of coding on top of already coded data if you don\u0027t know the coefficient then you need to add your coefficients so it\u0027s as if you\u0027re doing the coding on basically new uncoated data doesn\u0027t make a difference so that\u0027s what I mean by adding a new coding there and I mentioned that earlier there is two other aspects we\u0027ll be mentioning next slide cutting vector which comes back to a point from Salvatori and also the concept of hidden coefficients which is related ready to the security so that\u0027s nice so slide 10 on the coding vector so I\u0027m just going to a little bit of detail so yes I mean I already explained all of this the raw vector is the clothing vector the coding vector is really what is used as in the encoder and the decoder so if you see the figure on the right which is the basic coding operation where you have the symbols lined in a matrix which is basically your generation or your window and then you have a coding vector multiplying that to get a coding symbol and all of each one of these symbols has elements so what we mean by coding vector is really what you have there on the Left it\u0027s the full vector including as many zeros as needed if you have sparse coding it\u0027s definitely knocking to you\u0027ll be standing on the wire it doesn\u0027t make sense if it\u0027s as far as code there are different representations that you can be using and that\u0027s actually an important aspect of the second drug that you can look at so I think I mentioned all of that yes yeah the two main aspects really for the representations you need to have the value of the coefficient but you also need to have the mapping between each coefficient and the symbol that\u0027s related to so that\u0027s so any way you devise of doing that is around and yes "
  },
  {
    "startTime": "00:40:05",
    "text": "neural is pointing to just the fact that I mean there are examples of representations so either you send the raw vector which is the whole thing if you\u0027re using dense coding if it\u0027s good then you can just go with the coefficient value symbol this is used for example for says there are nine the one of the references would give them in the document and yes you can send the seeds which is also specified in the simple representation job so that is on the cutting that decide on the called trade offs so that\u0027s an important point we have to say we try to avoid this a little bit because we didn\u0027t want to go into the other call but they are related to many of the parameters that are explained so so we agree I think we\u0027re going to do some at least the fundamental trade offs we\u0027re gonna mention so basically the field size you know having a larger field size meaning if you have a larger field size then you have higher diversity it\u0027s less likely to have dependents and it\u0027s higher complexity that that\u0027s a basic trade-off also you if you have a smaller field size you\u0027ll need to send probably more redundancy because of the denier possible linear dependence so you know you\u0027re working on that I think that\u0027s an important trade-off which is fundamental the the simple size in between and the generator in size is pretty clear so the larger the generation the higher latency you need to assemble your your your symbols your coded symbols before you can actually deliver to the application layer or to the next layer so so that\u0027s important so there is a latency through per trade-off there that we can explain there\u0027s a extensive literature about this too and of course the granularity of your redundancy of course the larger the generations are the larger the window is the more you can be specific with you with with your feedback so sorry I mean I mean with your redundancy so one packet basically is if you lose for example if you if it is you can have better granularity finer granularity to the words and we will explain that you will explain that and document so I\u0027m looking at the time and frankly I need to afford so other up trade offs we might touch but we don\u0027t think really unnecessary at this point is of course whether you do a block code a sliding window really is a design issue for the application we might brush on that but we\u0027re not sure on the fence on this systematic versus for coding sparse intense coding what it means and also using feedback versus nose like she does that really good to the application "
  },
  {
    "startTime": "00:43:05",
    "text": "themselves so we thinking about that okay so I think I\u0027ll let me I\u0027ll say a few words on that this would be an interesting topic so there\u0027s a huge amount of work that that\u0027s been done by group they don\u0027t survive some others on security and really what we\u0027re concentrating in heroes again just how this how this connects to the representation issue so we this is not a comprehensive view of security but the initial assumption that we have here is that we\u0027re operating for the security aspects within the coating layer so really just focusing on the coding operational aspects of coding specific so now we\u0027re coding operates course allowing for mixing of data and the natural question is what are the security consequences one are there extra vulnerabilities that open up but two what are the extra of possibilities also that this provides also you know one of the things that this allows of course is is data hiding the encoded data in the absence of decoded is of course actually a very well protected it is related to you know sort of sure style you know post respond up security actually strongly behind such as you know basically trusted stored over untrusted networks I think that people course sometimes worry about because of the work that you have the mixtures is this issue of pollution attacks sometimes more Byzantine attacks because insider attacks but it\u0027s inside the networks in it appear system or when you\u0027re recording if one of the one of the intermediate routers were colonized so then the possibilities run a detection and correction some of them automated the representation some of them or not you know a lot to go into all of those details so we can point about sort of an entire entire tutorial there is work on that the other aspect of course is a the aspect of verification just I want to say for the Byzantine attacks is of course you do both detection business school attacks either end to end or I didn\u0027t immediate knows even that knows that that don\u0027t have enough degrees of freedom to decode you can also do correction by combining "
  },
  {
    "startTime": "00:46:07",
    "text": "it with an error correcting code also verification is something where that touches upon homomorphic encryption I just want to point out that the don\u0027t necessarily need third of the more sophisticated elliptic curves verification with encryption but the the network coding aspect does does vary with hormone fizzle basically what you need is home office and after the linear operations of the and actually very simple discrete log systems elida phenomena perfectly compatible with that so again you know yes I will probably be something an intersection which is more than what you see here but but I mean it will not I mean we\u0027re still discussing how deep we\u0027re going into that so as I said one last point on slide 13 is yes some people on the list mentioned some added references definitely the terminology that needs to be looked at the RFC Percy 84 is fixed economy maybe a couple more references about related simple representation there\u0027s also a question in coda right we saw that from an oscillatory so all of these will respond to in of course definitely and of course if you have last slide if you have you know any comments questions or suggestions do not hesitate to send them on the list or just come to the microphone and tell us no that\u0027s okay thank you for this detailed presentation are there comments or questions on if they cope I have I have questions okay you mentioned on slide five [Music] on slide 5 you mentioned that there is this dynamic number of K of coefficients and symbols yes but if I\u0027m looking at the adder I see your four bits field meaning that you cannot exceed the 15 16 depending on how you count okay is it less flexible it really on what you want to achieve with which field size things like that that much yeah yeah I agree "
  },
  {
    "startTime": "00:49:07",
    "text": "that there are two actually there are two different sizes you\u0027ll see I think I\u0027m not sure both of them are just 15 but yeah I mean I\u0027ll look into that it\u0027s I thought that was a large deal in the small field for that particular number but yeah so I\u0027ll check that to make sure that I mean it we are saying I mean the point is maybe this symbol representation doesn\u0027t show that aspect but it is a aspect that needs to be addressed right yeah I just want to that also if you\u0027re using it as a seed then actually what you have is a very different dynamic there in terms of the number of choices sure yep which leads to another comment it\u0027s great to have this specification of full specification of the ideas but if we won\u0027t go into that direction then we may then we should make attention not to closed doors and by being too specific on this aspect so it\u0027s a difficult exercise to keep the eye flexibility of rnc that you mentioned I fully agree and at the same time specifying something which is very detailed in terms of either format but difficult exercise we need to discuss this unreleased more in detail because it is a key aspect of this yeah no problem there but again I mean this is one simple representation so what I mentioned what I said in Montreal is that we might end up with a with a couple three or four different simple representations each geared to class of applications so so I mean it doesn\u0027t have to be all full flexibility and it doesn\u0027t have to be also too rigid so and that yeah definitely a discussion for the list we agree and and just just to echo that you know in in our own work on network coding we have had different representations and different implementations that we have done again sort of depending a bit over on the application correct yes and is the goal to have those different representation specifying this document or is it open to also most how do you see the the way this document could evolve in terms of representations as you mentioned sorry do you intend to add more representation in these documents so not necessarily I mean I think representations can be "
  },
  {
    "startTime": "00:52:10",
    "text": "added in different documents I think it\u0027s not a bad idea to have maybe a certain number of of documents each addressing maybe a class of applications this is the first effort I mean it can go either way frankly so we can discuss it but as far as I see it now clarifying this one putting it down I think is useful and then we can take it from there yeah give him basically the edges to have a useful document here that\u0027s concrete in terms of the representations [Music] not to close doors to other representations but to provide a service of war one yep yep I agree since you\u0027re mentioning the possibility to other seed you means you have a PNG associated to this we also intend to provide a list suggestions in terms of PNG I\u0027m asking the question because the last item in the agenda today is about our experience on terms of 30 mg 42 I will have to come back on this but what you go okay so yeah so that\u0027s that\u0027s a good question we had it also on the list so we our initial thought was to have that part of the protocol specification and negotiation I think that\u0027s a natural place for it we are really really specific to the symbol representation here so yeah that can be I think that that can remain outside yeah I mean we\u0027re open to discussion here if you think it really has to be part of it I don\u0027t see now why it should be part of it that\u0027s all yeah I think again we\u0027re just trying to give a useful symbol representation which is serviceable and just it\u0027s it\u0027s a it\u0027s an arrow but concrete and we hope useful contribution okay I see you have expressed lines we have five minutes left if you want to you know that\u0027s right that\u0027s fine so those are for in case we had questions but it sounds like it\u0027s fine please send your your comments on the list I mean that that\u0027s really the best place to yeah start this yes and think so thanks for that\u0027s all Salvatori and David for their comments yes yes you\u0027re welcome is that is a comment or question in the room or else well Nick you know we are done okay so let\u0027s continue with the next presentation from a phone so thank you Gary and Noel thank you "
  },
  {
    "startTime": "00:55:23",
    "text": "so hello everyone so first is forgive me for my speaking and hearing abilities because I have got a cold that I just can\u0027t get rid of so I here present our work on implementing and father as a correction extension to the quic protocol so first a quick reminder about the equip protocol so this is a transport protocol providing a reliable and secure transports of data it also provides stream multiplexing in order to avoid problems such as head-of-line blocking so fake worst part of the only quick versions but it has been dropped due to bad experimental results from the only designs so now the reai bones but is only insured through the retransmission of loss data and now we will consider to add the extension again to to recover from losses without the need for retransmission so how does a quick packet look like it\u0027s just composed of header and payload the payload is itself a sequence of frames so let\u0027s take an example here we have three frames in the quick payload the first one is an ACK frame which acknowledges the received packets and the two others are what we call stream frames they carry user data for two different streams here the stream X and the stream Y so there is already a design for fake extension proposed by this research group and we started an implementation work of effect extensions have a protocol in parallel to this draft so we started when the current version was not released so we have quite a different design we will discuss the differences here so we have two implementations one using the quick go implementation which is based on the Google quick design and second implementation working on ICO quick which is based on the IETF quick quick design draft 14 so I will show some friend formats but we do not intend to propose it as a standard so we just want to discuss the idea is not the details of these frame formats so let\u0027s first take a look at what the term draft is proposing so we want to define what are the source symbols which are the the data unit that we want to protect and the draft proposes to chunk a stream into blocks of fixed size the size is called E and so we will chop the stream into several fixed charge size chunks and we will consider this equal size chunks as our source symbols so here on the figure we can see that we have ten "
  },
  {
    "startTime": "00:58:24",
    "text": "source symbols and the last one is synchrony because the stream is finished before the end of this track so there are some advantages of proceeding like this first we don\u0027t in we don\u0027t need any signaling to to identify those source symbols because the server and the client only have to agree on the size of the chunks and then they they don\u0027t need to advertise which part of a stream is a source symbol because it\u0027s implicit another advantage is that there is no control over head because we only protect the user data we don\u0027t protect any any frame header or thing like that we focus on user data so that\u0027s another advantage on our side we started to implement something extension with a different approach we decided to consider a packet payload as a source symbol instead of stream chunks so here you can see on the on the image that the packet header is not really part of the symbol only the the seconds and frames is the salsa mode so this approach also has some advantages first we don\u0027t need to agree on a symbol size because if two packet payloads have different sizes we can we can consider that one of those two source symbols will be padded to match the size of the other and as quick naturally handle padding this additional padding will be understood as padding frames and having not having to to agree on a symbol size also helps us to solve the silent period problem which was a problem that was pointed by the authors of the draft if you look at the figure you can see that the last symbol is not complete so we are unable to protect it so if this last symbol is lost we can recover we cannot recover it because we cannot add padding in stream frames because it would consist in adding data in the user data another advantage is that we can protect more than just the stream data so for example we can protect the flow control frames and we can also protect some other friends like the data grant frames that were discussed yesterday that will provide a message mode for the quick users we can also protect any of the frames that are not currently not part of the design because as we protect a quick payload we are agnostic of what it contains so this approach this packet based approach still has some inconvenience first we need explicit signaling to identify the source symbols because then it is not implicit anymore so for that we propose to add a new frame that will identify that this quick payload is considered as a source symbol we call it the source back pedal ie frame and it just contains one field which is a no back field and this field "
  },
  {
    "startTime": "01:01:24",
    "text": "will be populated by the VEX key it will identify the source symbol in the in the coding window another disadvantage of this packet based approach is that we have an increased overhead because now as we are protecting a sequence of frames we will also protect the header and so we are not only protecting the user data anymore and as we have an increased overhead we will more likely be in the case where so symbol we have a full packet size and so the Reaper symbol might not completely fit into one packet so you know implementation we we restrict a little bit the size of a source symbol to be able to have a Reaper symbol that fits into one packet so now so here we thought about the Sun symbols now let\u0027s talk about how we we send a Reaper Simoes so here we have an approach that that is similar to the approach described in the undercurrents column for quick specification so we add a new frame which will basically contain a Reaper symbol so I won\u0027t dig dig into the details of this frame but what you have to keep in mind is that it also contains an opaque field which is which is called the Reaper fact panel idea and this field will also be populated by the fax scheme and it will identify the Reaper symbol so that the receiver can easily proceed to decoding then we had to think about what to do when we recover a packet because in a transport protocol if we recover a packet we can do three different things first we can AK this recover packet so it will make the sender thing that this packet has been successfully received and then it will it will not retransmits the the lost data which is fine but it won\u0027t it won\u0027t adapt its congestion window so if this lost if this loss was due to congestion the congestion window won\u0027t be adapted the auto action that we can take is to just not ack the lost packets in doing that will make the sender thing that this packet was lost so it will adapt its congest however the problem is that we transmit the loss data even if there they have been successfully received so we propose a third way to react and this is consisting explicitly advertising the sender that we recovered packets so we we send a new kind of frame which is called the recovered frame and it announces the range the range of packets that have been successfully recovered in that way the server can can know that a packet has been lost and then recovered so it can adjust its congestion window but it can avoid to retransmit the "
  },
  {
    "startTime": "01:04:24",
    "text": "recovered data so the format assist of this frame is currently very identical to the format of an ACK frame just instead of announcing announcing which packet has been acknowledged it announces which packet has been recovered so now let\u0027s take a look at some experimental results that we have performed with our implementations so we are doing a simple request you have a question excuse me in eco document before you go to the results have you considered say Ming and Sen signal yeah so basically the record frame is really close to sending an ECCN signal the idea is that as we we can say to the sender that packet has been recovered it can also maybe adapt its code rates accordingly so we have a little bit more information than sending ECL information and you agree that you have more information you just may be complex to add new frames but you may use an actual existing vector too because if your objective is just to have an reduction of the congestion window it could be a way to do it yeah so yeah I agree so maybe we can we can discuss about adding a new frame or not yes so thank you so look at some results so first the experiments have been done with emulation using mini net and we are focusing on in-flight communication use case so it\u0027s a case where there is a high delay and high loss rate so we used a seed loss generator in order to compare more fairly the different solutions so here we have we have a graph showing the download completion time ratio between quick using faq and regular quick so basically if our results are smaller than 1 that means that then quick with like the transfer using fake was shorter and if we are greater than 1 that means that the transfer using regular creek was shorter than using fake and so if we look at the small request response we can see that for small sizes fake has a good advantage because if we lose a packet the receiver will will have to wait additional time after the end of the stream to receive the retransmission of the lost data using fake we can recover the dislodged data before we before the the wait for a rec transmission if we take a look at the bigger the larger requests responses like this one mega megabyte file download we can see that adding redundancy will need some more "
  },
  {
    "startTime": "01:07:24",
    "text": "time to transmit this additional overhead so it will have a negative impact on the download completion time and so recovering from the last the tail losses only had a small small gain compared to the additional overhead that we that we had to add to send a redundancy so for for large request responses there is an interesting disabling fake so with these results in mind we decided to perform our experiments without Pyke a quick implementation and we decided to only protect the end of the stream not the whole stream and so the results are quite similar the difference is that so for the small request responses the results are quite the same for the one megabyte download we can see that the negative impact of fake has been highly reduced because we don\u0027t send redundancy during the download so we don\u0027t have this additional overhead and we can still recover from from T styluses whether we still have a small overhead because we need some signalling we need to to send these different frames the source symbol friends and the repair frames so it has still a small overhead but it has been largely reduced by only protecting the end of the stream then we wanted to check the interest of sending this recovered frame congestion control point of view so we performed experiments when to through patrols are competing so we have one quick flow which is in background so we call it the background traffic and we have three candidates for the background traffic a regular quick download a quick fake download sending recovered frames and a quick fact download acknowledging the recovered frames yeah the recovered packets and we study the download completion time of a foreground regular quick traffic so we\u0027ll see how it competes with quick fake sending or not the record friends we don\u0027t apply media molasses on this on this use case so the only losses that will apply will be congestion induced so here we on this graph we show the download completion time of the foreground traffic for these three cases so we can see that in the case where the background traffic is quick fake sending recovered frame so it\u0027s the with RF boxplot the download completion time of the foreground traffic is very similar to the download completion time of when it competes with a regular quick download when it completes with quick fake only acknowledging the recovered packets we can see that the foreground traffic takes a lot more time to complete and it because the congestion implied losses "
  },
  {
    "startTime": "01:10:25",
    "text": "will be hindered by the acknowledgment of these recovered packets but we may need more experimental results to confirm the interest of the record frame because it\u0027s only one case study so we might need to perform more experiments to confirm this tendency so to conclude we can see that fact also has an interest in the small wicker request westbourne\u0027s news case like some API calls etc especially in high delay and high loss configurations we also see advantages in both approaches the chunk base the stream string based approach and the packet based approach but the experience that we did only consider the packet based approach so it might be interesting if somebody could compare these two approaches however the packet based approach is the only one that allows to protect other frames that then shoot friends like the new diagram frame and we also saw that recovering the packet must be on carefully in a transport protocol because if we send the wrong signal it could lead to it could lead to unfair behavior finally we would also like to experiment with real setups and some real time use cases in order to see some other advantages of fake in quick so that\u0027s all for me so if you have some question I\u0027ll be happy to answer if I hear them thank you yes questions modern pierson-el nice presentation I have had a question on the I\u0027m not an expert on quick at all but how how does the how do you know so basically what I saw was that when you\u0027re sending large chunks it\u0027s better to basically only protect there or large files it\u0027s better to protect only the end so sort of avoid this problem with the losses at the tail does a quick implementation know the size of the file it\u0027s sending or is that something that you implemented in order to get that information through the implementation so when we send stream data basically a stream frame contains one bit which is called the fin bit which says if this frame contains the end of the street so basically when we see that we sent the end of the stream we decide to send a redundancy and we also did it for when we are what we call application limited so if we have no stream to that have to send data at all so all streams are blocked basically by the application then we also flush these the redundancy and how would that work if you have something like again like if you\u0027re pipelining data like in in HTTP typically you you put more than you know just a single file on the same connection because you don\u0027t want to have so what what that mean that it\u0027s only at the end of basically when you close the socket you would you would protect that last piece of data or so "
  },
  {
    "startTime": "01:13:27",
    "text": "there are two ways to proceed when we want to send multiple files with HTTP either you use several streams one stream per file I mean in that way you you know when you when you send the end of a stream otherwise you can still do what what we did in our implementation if we don\u0027t have any more data to send so if you are application limited we send some additional redundancy but if you are if we are pipelining like concatenating many files one after the other in only one stream we won\u0027t be able to detect the end of a file okay do you know what is like what they are planning to do is if both modes are sort of gonna be can so it depends on the HTTP to marking with quick but I think that the recommendation will be to send one file by stream or rice frame only correlated file in the same stream and uncorrelated files in separate stream okay so yeah the the idea is to use as many stream as as you need yeah so and and my second question is did you where do you see an advantage in in in here it\u0027s basically integrating the effect into the transport right but but that they are now doing this new day extension and which would essentially allow an implementation to put the fake you know on top using the data Graham getting the encryption and the congestion control but but do you think that\u0027s a just which path do you see as the best one or should both be considered or what what\u0027s your opinion on that so I would say that it depends if your application has we strong needs and we depend strongly on the shape of your traffic there it\u0027s better to let the application handle the the forward correction itself but providing the fake on the transport level allows simple application to protect their traffic without too much implementation efforts so basically that I think there are there are use cases for both approaches but it\u0027s very good remote because yeah that\u0027s also what we think okay thank you thank you yes questions I confuse nice talk very simple question what is the round-trip time for this experiment so we perform many experiments with many different voluntary turns so as we consider the in fact communication use case we have a large laundry times which will span between 100 milliseconds until 700 milliseconds which is a really huge and we perform many experiments with many different 100 yes so basically this "
  },
  {
    "startTime": "01:16:37",
    "text": "is the aggregation of all the results so we follow a methodology which is called experimental design which consists in exploring many different values for the parameters like grtt the row straights those patterns etc do you have a separate reserve for different RTT in the people so we can you repeat we have a separate performance reserved for the and type a different RPG around playtime so we have it you know data but you know paper we don\u0027t show it in the in the dress but basically if the RTT is very large the Telesis will be will have a high impact satellite case if you have I mean you have a very big difference in performance yes oh yeah that\u0027s a nd I mean thank you thank you it\u0027s Nikolic you know again I have a question what is I may have missed it and I\u0027m sorry if I missed it what is the stacks you have been implementing this on sorry what on what quick code have you been implementing that so we have to implementation one is quicker and the other is Piko quick relying on 1240 thank you other questions no I have questions yeah but I want you to - no remaining questions in the room oil so thank you very much for this very interesting and complimentary approach for addressing this problem of adding FEC to quick as you said there are different design goals and different properties that results from those design goals and at this level it\u0027s very interesting because we don\u0027t really know what is the best approach or is there a single best approach it\u0027s still totally open so what we already discussed this with Francois of course and our conclusion for the moment was - as I said was to experiment and going to address both both types of solutions and see at the end in the future in the future ITF meetings once and see what\u0027s what seems to be the most interesting one of maybe me making both of them but you add some more complexity so I\u0027m not sure of that but anyway let continued this exploration experimental work and let\u0027s see afterwards what\u0027s what seems to be the most appropriate solution for before going to two quick working group in the future so that\u0027s very interesting and we will make reduce to Internet drafts I mean cutting for quick and I\u0027ll see "
  },
  {
    "startTime": "01:19:39",
    "text": "for quick but anyway we will include support from this approach or this packet based approach in both documents and in order to to be more to going to be loose technical details that are very interesting and assessing the consequences the key benefits on counts for each type of approach so thank you very much for this orientation of all you IDs thank you hi comment from Dave I ran I\u0027ve made this before I\u0027ll make it again just for the record I would discourage the group from baking this until quick decides how it\u0027s going to do multipath so I said I would discourage us from baking this too much and locking it in and so the quick working group figures out how it\u0027s going to do multi multi path because there\u0027s a strong coupling between how you might want to do this and how multi path works yes social okay and there\u0027s also activities a multi past week in the University of Leuven so I think you are in good position to her tree idea of how to do that our both techniques can complement one of the other or not yes Spencer Dawkins I were to strongly agree with everything that Dave Ferrand just said with the possible exception that the quick working group is not actually working on multi path as a working group right now even though it\u0027s a chartered activity and it might be that you all will discover things doing research that they would find useful in the working group as far as being able to move things forward I mean you know our TF research group so tone or idea for groups what to do but if you knew something smart that they don\u0027t know they might find that interesting topic yes okay seems to be thank you very much for so so next two keys from not okay so my name is modern Peterson and I I hope "
  },
  {
    "startTime": "01:22:40",
    "text": "this is not too much sort of preaching to the converted but I would like to to motivate a little bit using coding for low latency and reliability and basically try to make the case for why if we do not consider coding for this then we are missing some important performance opportunities so basically low latency and reliability is a requirement driven by the application that that is running over our over the transport way that we\u0027re using in different applications of course have different requirements and what we are seeing now so some of these applications are all right we all know video conferencing and they have relatively relaxed requirements to - latency and reliability but a lot of newer applications are appearing like a are via a chilly surgery with haptic feedback cooperative driving and these types of applications have much more strict requirements on reliability and latency and if we\u0027re going to address those those requirements we need to you know think about our different options for how we are implementing reliability and achieving low names and our applications so basically so before we go into the techniques its it there\u0027s some some fundamental properties about latency that\u0027s really important to understand basically if you look at the latency between between two given points there\u0027s a sort of that\u0027s a physical limitation so how low we can get it right so if I have two cities in the US Boston and Stanford the distance between them is approximately 4,000 kilometers and that means that if I do the calculation of speed of light through a fiber I\u0027m gonna get something like 21 milliseconds of latency one-way and that\u0027s not gonna change until somebody finds a way to improve speed of light so basically yeah just the data point the worst case latency if there\u0027s been a fiber cut is actually 190 milliseconds okay so there\u0027s some there\u0027s some basic desam there\u0027s also some references that are not showing and on the slides but you can if you find the slides data you can go in and read a little bit more about if you wanna sort of fully understand this but basically basically what it\u0027s telling us is that the link latency without the protocol has a lower bound right so if we\u0027re gonna sort of put our applications on these links then we have to take that into account so there\u0027s another maybe I think my slides are ok so there\u0027s another interesting thing which is from a taking from my famous "
  },
  {
    "startTime": "01:25:42",
    "text": "rant bias to a t-shirt whose basic who says it\u0027s the latency stupid and basically what he\u0027s saying is once you have bad latency you\u0027re stuck with it referring to this fact that you know speed of lights not gonna easy to change but but there\u0027s another thing and actually that\u0027s you know where the coding becomes interesting is that making more bandwidth is easy right so you can always take another fiber or you can you know buy another DSL line so we can always make more you know bandwidth but we are not going to be able to improve our latency so so so that\u0027s an important point when we think about adding coding as a solution to this so if sort of two brief the problem right is if you have two devices that need to communicate with low latency how can you achieve it right and what we are doing today almost everywhere if you go also to the different talks your diet if it\u0027s a IQ right and what is that what are you doing with a IQ you\u0027re basically trading latency for reliability in order to minimize bandwidth right you\u0027re always you\u0027re waiting to figure out which packets were lost and then you\u0027re retransmitting only the lost packets which gives you optimal bandwidth usage but you\u0027re paying with latency because you\u0027re waiting to figure out which of the data was actually lost and that can be really problematic for latency sensitive applications and then we have another trade-off which people which which we are advocating right is that you use coding for the reliability because what you can do that is you can trade bandwidth for reliability without hurting your latency so in theory you can do something that is you know even bandwidth optimal with coding but typically in practice right we have to you know anticipate the communication link or predict some amount of losses right and we put you know enough enough coded data onto the wire that the receiver will be able to decode the content without any retransmissions and thereby we are only having this one-way latency cost added so we have a few sort of to illustrate this point we have a few sort of visualizations you can go in and check that there where you can play around it\u0027s basically small simulations that are running in your browser you can go in and play around with them and and try to see you know what is the difference the latency difference between an a a cube based system and an a system that uses a code and you can try out with some different parameters and basically get a feel for the cost of the two different approaches so coding of course isn\u0027t the only answer right there\u0027s lots of other techniques like it\u0027s computing moving you know moving data closer to the people having empath retransmissions you can do other things but but definitely it needs to be part of the toolbox that people have when they when they are doing these kinds of things um also if you want to see a real "
  },
  {
    "startTime": "01:28:46",
    "text": "life use case this is a demonstration you can find on YouTube where basically there\u0027s a very latency sensitive application so what is doing is today\u0027s MA and more services are coming which are basically like Netflix for gaming so the game is actually running on a server in a data center and you\u0027re streaming the video of the game to people and they are then you know playing the game and they have to send back control input to a server that then updates the state of the game and basically you you can play new video games on your smartphone or something else as long as it has a video decoder right do you see these types of applications extremely latency sensitive and what we did here was that we basically tested those applications on the different sort of network conditions and then with and without coding and basically demonstrated the user experience improvement for such applications with coding compared to just using the standard reliability mechanisms of affair of the of the game streaming application so if when you walk around and if you look at the different drafts I have that\u0027s actually you know because of 5g and all this stuff that is happening there people I know sort of being becoming aware that low latency is going to be a fundamental requirement for many of the applications that are proposed for 5g and also a diet if people are thinking about latency right but nobody mentions coding as a potential sort of solution for this and that\u0027s a little bit problematic and of course you know we are here but there seems that we are not very good at communicating to the rest where these these kind of things so maybe maybe this is something that could be you know and a draft for the working group something on low latency or something like that to sort of describe how coding fits yeah so thank you for your time yeah thank you comments questions I think we all agree with the conclusion it\u0027s not a big surprise for us but as you mentioned it\u0027s maybe something that we that should be more communicating well we should find a way to better make people aware of this d\u0027amato limit and we\u0027re one way to reducing some to a certain point this Latin seeing Samir reliable or reliable communications yeah the two documents that you mentioned at the end the two internet drafts one of them is the one from Yahoo is now find out expired not the other one did you try to pass him yes yes I talked with "
  },
  {
    "startTime": "01:31:48",
    "text": "Linda yeah yeah and she was very open to adding stuff there to the document so I think that\u0027s something that we we would do yeah yeah sure sure sure sure that\u0027s a good yeah yeah yeah yeah but I don\u0027t know if it\u0027s something that you know this group should also have a document on low latency encoding or like yeah you mean oh yeah yeah okay it\u0027s implicit but making explicit perhaps is also something important yeah thank you thank you mother there is one presentation left for myself okay so it\u0027s a quick presentation about some rated work we have done and that is almost finished in the GSV working group where we specifically explained that using coding and particular sliding-window coding could help in reducing latency so it\u0027s part of this big communication on okay if he can\u0027t help reducing latency but this in this TSV working group and most specifically what I would like to talk now to the afternoon is about this what lessons we\u0027ve learned on by specifying this is e fe fee scheme and most specifically on the PNG aspect there are a few important things that we should be aware of it could help so a specification has been I would say a little bit difficult and long at the end for two reasons basically first of all we totally overlooked the program associated with the PNG that\u0027s a mistake that we\u0027ve made and we fix that only well one year ago around May 2018 we thought we would we were close to again but in fact we quickly over this PNG stuff the linear congruential PNG that we have been classically used for years is totally broken when it comes to generating con encryptions that\u0027s something we need to be aware of it\u0027s broken because it will basically produce for certain types of seeds the same first few parameters because of the way it works I mentioned this and explain this more in details in neutral meeting so unless "
  },
  {
    "startTime": "01:34:50",
    "text": "there are questions on this I wouldn\u0027t like to come back on it but keep in mind that it\u0027s broken so we had to find something else and we found this great another great PNG much more modern and more mathematically speaking correct that produces better to the random numbers but this second specification is based on source code on C source code so the specification is the implementation I would say the implementation is the specification there is no absolute code specification of this of it and it created several side problems that we found very difficult to source so this is what I would like to explain so basically the main problem is about a cooperating license it should make seems something quite easy especially when the source code is provided with a bsd-style license we in fact bsd-style license she\u0027s the one that ITF is working is using sorry but still there is a slight difference and the licensing aspect also the copyright I space story the copyright aspect is extremely hard to solve unless the authors of the source code are also offers of the internet draft so that\u0027s the only way the only clean way we found to solve this copyright and license program having those C implementation authors also be internet draft office that\u0027s the clean way otherwise you will never found a solution we we tried we asked our Spencer and Mia as the ITF legal department to we try to find another way to address this problem that was almost impossible so that was the first problems when it when we have this C source code reference implementation another problem is interoperability and determinism and we can back up this sometimes it can be quite subtle I was not aware that the C specification C 1990 11 DOS and uncie specification are a little bit unclear on how to for instance represent negative values so most of the compilers I would say 99% of the compilers and target environments you may want to use are using two compliments for representing negative values which is more or less the basic assumption you may have on this but it remains that it\u0027s not specified not mandated in the specification so you may found you may "
  },
  {
    "startTime": "01:37:50",
    "text": "find a situation where your compiler uses one compliment representation or something else and depending on this depending on the way you implement your stuff it may create deterministic problems it may end in different results so that\u0027s something we discovered fortunately the mechanic was aware of this and we mentioned this during the is G with you so it was great so that\u0027s that\u0027s so we end up with this 20 42 PNG which is from a mathematical point of view quite good it produces good quality to the random numbers as I said comes with a serie France in fermentations we specify we\u0027ve also specified three internal parameters you may found millions of such triples we found we we selected this one to make it easy to use but keep in mind that if you use a different triple then you end up in a different Suriname number sequence so that was what we specify this son we also made we have also been very careful in terms of determinism for some use cases determinism is not an issue when you want to create simulations well it\u0027s not a big deal if what you get on your laptop and what you gettin a different laptop ah a little bit different but in when it comes to FEC schemes then it\u0027s absolutely mandatory to have exactly the same pseudo-random sequence with the same seed so this is what we\u0027ve checked and we produces this table with 50 PNG to the random values that must be checked if you want your PNG implementation to be validated on your target platform so that we we made many experiments on different types of platforms 64 bit so - down to 8 bits target geni bolts using Mac OS or Linux or riot rate which is an operating system for IOT devices specifically so that\u0027s something important we clarify this once another point let\u0027s bullet this PNG produces pseudo-random 32-bit numbers so that\u0027s the goal of this internet draft and this PNG now in some situations you need to scale down this 32 bit address of a value space into something smaller like for instance with RLC we need pseudo-random numbers between 0 and 15 or 0 and 255 so in that case you need to "
  },
  {
    "startTime": "01:40:53",
    "text": "specify how to do that and we did it but we did it in the ex-king specification and not in the attiny MD 32 internet draft so if you want to use this and if you have such requirements then you have to provide your own scaling down function but that\u0027s that\u0027s not a big deal and the good news is that yeah Mon be reason why do you meter sorry why do you need that because I need a pure absolute or random number between 0 and 15 and 0 and 255 for the coefficient generator function but if you just generate the bits and use and you can just consider the bitstream right and then you just use you know however many bits yeah you may do that yes that\u0027s another way to do that that is typically what I call this function that gets the 32 bits so the random number and generate this let\u0027s say 4 bits or 8 bits pseudo-random number that you need for your specification so you have to provide this function that\u0027s one way to do that we use the different way but it\u0027s also valid but you have to provide this in some way yeah and and why the 50 is that just no no 50 is okay it\u0027s considered as a good value no it was also the size provided by the office themselves and last right so the good news that it\u0027s not yet finished but almost and we hope to have this I fish we\u0027re optimistic for next idea we\u0027ll see but um I think it\u0027s feasible it has the source code has already been reviewed by is GE and we clear out this licensing fee right it\u0027s it should be R feasible to have it available for next ATF anyway if you need the PNG this is a clearly an option you may find it\u0027s not appropriate for you but in that case you have to provide your own PNG and it can be as I said something a bit complex to achieve yes did you benchmark the the time it takes to seed the prnt because that\u0027s something that we experienced has a huge is very very different and and in if you if you have a very high throughput application which basically uses the seed as the way of generating the coefficients then you also need a fast way of seeding on the on the décor of example yeah yeah yes we did it we didn\u0027t I on finding problem but I agree with you it\u0027s something that should be considered in fact the way we use these pngs for random linear codes "
  },
  {
    "startTime": "01:43:57",
    "text": "in general is quite different from the way you use PNG for all the use cases in our case we need to generate a high number of small PNG sequences rather than a single very long PNG number sequence so the seeding thought is something which is important because it will incur some computing time that could be a non-negligible but in one case with this Union if I do the way it\u0027s implemented we don\u0027t identify big issues yeah it\u0027s going to be mandatory to use that one I mean in the if you have let\u0027s say he said it set up to the implementation or to choose I stand as this and this is recommended maybe you\u0027re well every implementation have to implement this specific no it\u0027s not mandatory unless you want to use this ipfx scheme so the oil Felix scheme non dates that this one be used bursts with those the function we provide to grow from 32 to down to 4 or 8 bits a value range so this is mandated in that case but if you want to use a different PNG as I said you you are free to do that but you will have to specify this PNG by yourself and depending on the weights which find can be a bit tricky become depends I was there with the transport area people were asking questions about this and they were extremely I would say strict in making sure that what was mentioned as a PRG was a true PRG they were concerned if I remember I don\u0027t remember who was sitting at the table but there was there was actually quite they a discussion on that so I think it\u0027s it\u0027s I actually think the work that was done there is very very interesting since we\u0027ve been talking about random coefficient in this group for quite a long time yes from them cuz research is not that easy to achieve you we need to pay attention to that okay so that\u0027s all I wanted to say thank you thank you sure I think any questions about the prayer any other questions about the presentation or not okay thank you thank you I think with that yes well done so I wish you all until next IDF "
  },
  {
    "startTime": "01:46:59",
    "text": "and the interesting work so as we said already we will meet in mantra and we will have this yes seoeon thumb and we will also have this Sackett own project so do not hesitate if you are interested you can participate times not physically or remotely both are possible I think we there will be fewer people there compared to this åkesson but from what ago I already get but anyway we will find a way to make progress on these interesting projects so thank you everybody thank you blue sheets yes thank you and I would like to thank David Oren for having taken to know "
  }
]