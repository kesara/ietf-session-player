[
  {
    "startTime": "00:00:39",
    "text": "while we're waiting um would anyone like to volunteer to be a jabber scribe and or would anyone like to volunteer to help robin with the note-taking today robin will be presenting for 15 minutes but beyond that uh whoever would like to dive in um they'll be very welcome see watson's volunteered thank you watson for jabba's scribe um yeah if we could get some d2 to assist with the note taking that would be very welcome too any takers we'll need a note taker to"
  },
  {
    "startTime": "00:02:01",
    "text": "make sure that uh we don't miss the notes from the q log bit um i might have to start asking people by name if we don't have any takers jonathan thank you very much you were the person i had in mind to to ask so i'm glad you did it first uh right then uh let's get started with the session um hello everybody um this is the quick working group session if this is not the session you intended to join please leave now um i'm lucas i'm one of the co-chairs matt who's just putting his video on is is my fellow co-chair this is the first session i believe that uh lars hasn't shared a quick session so um it's it's breaking new ground um i'm just trying to see as lars even in the attendees list maybe yes he is hello lars i thought you might have escaped permanently but it seems you did want to come back um so this is a quick working group session like i said uh we we wanted to go through the usual notewell and and etc which i'll come on to next but also give a little bit of an update from the chairs about you know what has the working group been up to since the last meeting and uh maybe the direction of the group so just to you know we we've delivered rfc 9000 and people are a bit fragmented across different drafts we've lost a little bit of focus but the working group is still active so we just wanted to keep people up to date um so the first order of business here is the notewell uh we're halfway through the week now you should be familiar with this but if you're not um please go online and look this up and follow the links and read things this covers the itf policies that cover topics such as patents or code of conduct and and how you participate in the ietf so this is important for understanding your contributions to this working group and the ietf in general so please please do"
  },
  {
    "startTime": "00:04:01",
    "text": "go and attend that we've also wanted to give some special attention to the itf code of conduct this time around um so the you know the rc7154 lays out some of the expectations for participants in the itf um you know we are just a diverse set of people from different parts of the world different experiences and and different viewpoints and that's good and we should celebrate that um but that we you know should have in personal discussions and try to be respectful of each other i'd like to say that the quick working group has got a good uh track record of being able to function and have constructive discussions on things so it doesn't hurt to remind ourselves that we should keep that up and i look forward to a healthy discussion during this session in terms of administrative year for this meeting we've got the notetakers thank you robin and jonathan the blue sheets are automatically taken care of now by meet echo so that saves a chore the chat will be by meet echo or java all integrated again no problem for av if you would like to present and or participate in the queue to ask questions or clarifying questions or make comments um we we're using the echo people should be familiar with that by this point in the week but if you're not there's several icons in the top left hand corner of the screen um you have the raised hand to get in the queue um when it's open uh we will be closing the queue at some points depending on how we manage time we can also unmute your microphone or your video for presenters we're going to go with the screen share tool built into meet echo today so uh when is this a lot you can click the page icon to request to share slides and it'll be done by me echo which is a little bit more friendly to people's streaming bandwidth um or if you really need to use share screen or we can have the chairs share"
  },
  {
    "startTime": "00:06:01",
    "text": "this the slides for you um and the chairs will be running the cube and so my glamorous assistant matt will be helping me on that front um but down to the order of business today just a recap of the agenda uh like i said we've got some chair updates after this administrator section um we have some working group items on the agenda so we've got the act frequency draft then we have q log then version negotiation followed by quick ld and then we're on to like a new work section so we're going to focus here on uh multipath extension uh mary will be presenting on behalf of a few folks that have been working on that and had a side meeting a couple of weeks ago and that'll be the bulk of our time in that section and then and as the time permits um we'll look at some some of the things here like receive time stamps uh quick v next whatever that might be or the zero rtt bdp um so before we we get started on the agenda in earnest is there any bashing that anyone would like to do i don't see anyone in the queue or any comments so okay um we'll just proceed uh so i'll take take some some spotlight for the chairs here um some updates since the last meeting in terms of the work that this group has adopted and is trying to to complete um hb 3 and q pack in case anyone's wondering they're still in the rfc editor queue we're waiting um the work to happen in the http core drafts which effectively a dependency for for those two in a way um and uh they're making progress they're doing okay there's a whole cluster um if you're interested you can go and look at but we're effectively waiting they've been there a long time um if you go look"
  },
  {
    "startTime": "00:08:00",
    "text": "they were submitted around february i believe so um we we're getting there slowly uh in case people aren't too familiar with the deployment strategy um if you recall a few months ago um as a group we we decided that people now that rsc 9000 was out which is a quick version one um that the http 3 alpn which is the labeled h3 um was allowed to be deployed on the internet and i believe we've seen some decent amount of um live deployments and interoperability on the public internet which is great so um i don't see those the specs um being in the rsc editor queue is preventing progress here um if anyone was um watching the mailing list so my issues have been identified um in the drafts while those things have been in the queue um they're kind of minor things um maybe edge cases but some of the resolutions were to normative text so a consensus call is still live i believe i need to check my dates um just on those uh for the working group uh at the request of our ad to make sure that um the proposals there that we're all happy with incorporating as as part of the auth 48 changes that the editors will do so we we've seen a lot of good feedback on that if you haven't seen them please do check them out and let us know otherwise if we don't hear pushback we'll we'll direct people to to incorporate the changes as and when needed um the op strats the applicability and manageability or an ad review um so thank you for everyone for the the feedback during the various rounds of working group last call and the editors for um working with people on that to get it done that's appreciated the datagram draft also passed working group last call and that's also an ad review and the grease bit working group last call is"
  },
  {
    "startTime": "00:10:01",
    "text": "completed we had some feedback um there's a few minor changes there so we're just waiting a new draft um and then we'll do our shepherd write up and pass that on to the ad so uh thank you and mine's just posted in the chat hill or having a date inbound brilliant um [Music] some related work uh sometimes it's it's easy to assume that the work that relates to crick all happens here and that's not true now that we are an rfc people are excited and they want to use this document all you know to be honest they've been excited for a long time so uh one of the things that did come to our attention around about in the itf was the dns over quick specification uh went to working group last call in for deprived and uh i think a few of us from this working group posted some comments um that have been uh incorporated um or proposals for addressing those comments have been incorporated so that's good at the itf we have the mask working group who met on monday in the web trans working group and on tuesday those things are related there was a side meeting for media over quick which is non-working group that was formed i see in the chat that i have the dates wrong so i apologize for that we had a meeting yesterday um jonathan just jumped in the queue and then left so i think he was trying to draw my attention to that um i hope i've addressed the points um this uh all of the side meetings uh in the ietf sidebeings calendar so uh please check that for the actual correct date and time and uh actual joining instructions so there'll be a link to it was zoomed yesterday so that isn't you know necessarily um strictly anything on quick we're still trying to figure out things in that group that may be you know what are the"
  },
  {
    "startTime": "00:12:00",
    "text": "requirements for using quick versus modifying quick and trying to understand if any work needs to come back here or not so anyone interested in that there's some healthy discussion there it's kind of interesting oh and robin also mentioned uh there's a aside meeting today um about openssl and it's quick support um for uh doing stuff so um if if anyone's interested in that again check out the the side meeting uh calendar because all the details will be there um and then talk about new work uh just to remind people uh this shouldn't be new information but when it comes to adopting new work items um we have a charter that's up on the data tracker um and just to kind of summarize that the working group is the focal point for any quick related work in the itf um the focus areas are kind of three of the maintenance and evolution of the quick specs as and when we need to to do things that you know improve upon or fix or iterate upon drafts that have been adopted items and and been published uh so that should be fairly obvious um other things about supporting the deployability which relates to drafts like ops strats or queue log or low balances those level of things so we can support non-protocol specific work items too if they make sense for us to do things and then new extensions to quick so datagram's an example of an extension and we've got another one coming up later in this session um but as i mentioned dns of a quick is an example of how an application protocol could use quick and that work was done outside our working group um it could be done here if we really need it if that suitable home couldn't be found but i would hope that most most of the discussion in such specifications relates to the application protocol and that we have an awareness of the work that's happening there so we can on"
  },
  {
    "startTime": "00:14:00",
    "text": "you know people from this working group can go and review with a with their quick head on and maybe give some feedback about um those aspects of things and then defining new congestion controls is outscope so please don't come with those things because we'll have to point you somewhere else uh but specifically to this session um and uh yeah we we're going to talk about multipath quick extensions from the background here uh without um trying to preempt too much of what mirror talk about later is that we had a interim focused on multi-path like a year ago um which you know multipath was in scope for the initial charter that this working group had and we d scoped it um into into the current form that we have today um and there was a lot of i think a lot of ideas around what multipath could be what different problems they were trying to solve um and so we had that meeting last year which i think helped but didn't get us into the right position and we still had a lot of work on z has gone on we we've we've cleared things from our our agenda and we have some more time but we also have a clear idea of the problems um and people have come together for a more unified proposal so um we'll see how the working group um think on that and we'll be taking uh the chairs will be taking an assessment about whether we think that work is is worth adopting in its current form um so i want to ask people to keep that in mind through the presentation um because that's a question we'll be asking at the end of it so that's the end of of the quick chairs session um next step on the agenda is ack frequency um so i penciled in jonah to present yeah but i guess maybe it might be ian too um which one of you is it"
  },
  {
    "startTime": "00:16:02",
    "text": "let me pull up this no let me stop sharing my slides ian are you you willing and able to present no no response all right okay should we should we skip to another session and maybe come back to that one uh let's do that i'll chat with you in the back um but if he's not able to run obviously i'm happy to do it yeah just a little bit noisy for me oh there he here he is uh i'm sorry about that i did my better lunch um uh let me get my headphones on would you like us to drive the slides ian or you find to do that yourself yeah i can actually yeah yeah let me just i don't know if you're experiencing echo but usually you do um cool i just asked this year so okay great um there we go cool um so uh yeah we're we're kind of hoping to wrap up the act frequency draft in a relatively near future there's one fairly substantial design issue that's outstanding that i'm going to highlight um in these slides but uh first i'm going to start with kind of an overview"
  },
  {
    "startTime": "00:18:00",
    "text": "of where the frame is at and um you know and talk through that and if there are any questions obviously feel free to interject um so here's the current frame format um obviously this a type there's a sequence number so if you receive them out of order this is allowed still to retransmit any frame you would like verbatim um is possible that a sender that does this uh could receive a frequency that arrives out of order so that fixes that problem the accolading threshold of course is the number of packets that um technically it's not the number the maximum number of active listing packets that the recipient of this frame can receive prior or before sending an acknowledgement um so the the key point is that that makes zero a valid um valid value and such so um just make sure that you you kind of get the wording on that correctly um and it's also the wording's been tweaked around a little bit um relatively recently uh request max sac delay um so that's the value you'd like the peer to delay an acknowled an immediate acknowledgement for sorry delay an acknowledgement for upon and perceiving an app listening packet um immediate acknowledgements are totally different uh uh yes sorry i need to do something later thanks sir sir um the uh the ignorancy field um is ignoring congestion experience um this was added both as a result of conversations about how one might use ecn in different or ecn marking in different contexts besides the the two that are current kind of currently kind of tcp style and class and qcn and then the ignore order is basically the same the same concept in both cases you're you're kind of ignoring a signal that may or may not be indicative of congestion um for a longer period of time in order"
  },
  {
    "startTime": "00:20:00",
    "text": "to you can have your video or multiple uh packets um so uh we did add some caveats uh there about like the safety of these and how you should really be using these and and um those are in the draft now so uh next slides um so the the design issue that came up recently was the latency detect packet loss um so kazuo pointed this out and um this is somewhat related to a previous issue i felt but i think kazoo is both freezing and and state problem statement were much better than mine was um and so the issue is that one act is sent immediately today just like with p1 um but after that the next act will not be sent uh until the eliciting threshold of the act layer hit and there's a lot of situations where that might uh slow down the packet threshold uh lost detection um so the kind of example is you have a drop you send an immediate act um and then you don't send another act for say 10 or 20 packets um it's it's pretty easy to hit a situation where you know if you send another act you know two packets later you could have immediately declared a loss and moved on but instead you're waiting say like a quarter rtt um rtt for the the time threshold to hit um in data centers this kind of could be worse unfortunately because data centers tend to have alarm granularities which are not amazing and commonly the um the thresholds we're talking about according to t and eight that are tv are literally unachievable in like a micro center i'm sorry a micro micro second scale data center networking environment so this this probably is actually a worse problem in a data center than the public internet but anyway that's kind of the outline um of the problem and the most important conclusion is that loss detection latency has the potential to be worse than in quick v1 um"
  },
  {
    "startTime": "00:22:00",
    "text": "so the the proposal here is to communicate the reordering threshold to the receiver instead of this ignore order that we we have right now and the algorithm comes down to that the receiver needs to send an immediate acknowledgement uh whenever they're missing packets um somewhere between the largest acknowledged value that has been sent in a previous acknowledgement mastery ordering threshold and the largest acknowledged in the that you know currently has been received at this moment um from a more recently received packet um minus the reordering threshold um so that guarantees that if they're basically any packet in that range that is missing um assuming that the peer is correctly communicated their reiterating threshold to you um that means that they can immediately declare a loss the moment they receive your immediate acknowledgement um so the result is that it reduces the number of acts when people packets are received out of order when compared to quickv1 uh while also improving uh the loss detection latency versus quick v1 because there's a number of cases now before i put feet one because you act every other packet it was possible they had a circumstance where um you you didn't receive that final packet threshold act say because the um you know it was two packets later not three or you know you kind of an off by one error um and it would increase loss detection latency or slightly uh versus this approach um so ideally this gives you the best of both worlds um the major you know the major negative is it definitely increases implementation cost by a slight margin uh because you have to implement this this algorithm right here um so yeah so that's that's the item to discuss um do people have thoughts this pr has been kind of out there for a while and as there's the issue um yeah christian christian please go"
  },
  {
    "startTime": "00:24:05",
    "text": "oh i can't hear you christian um i still cannot hear you should we skip can you hear me now can you can you hear me now yeah okay that's a weirdness with the microphone too many buttons um yeah i'm not sure i mean you're proposing to add a weirdo in threshold based on packet counts and i am not sure that's the right tool the the reason i say that is that we have tried a lot of that we are doing happens a lot in some kind of multiplexing scenarios especially if the network is doing equal cost multiplexing equal cost load balancing and and in that case it seems much more efficient to use delays than using packet counts so there is that i would agree there are circumstances where this is not actually a helpful mechanism um and so we did maintain the existing kind of ignore order functionality if you send a reordering threshold of zero basically means the existing order functionality um yeah i think it it really depends on the circumstance um so this i guess is really about giving the sender which as described in the recovery draft the last detection congestion total draft um there there are two essential mechanisms for declaring loss there right one is reiterating threshold impact accounts and one is in time and so this is giving the sender the maximum number of tools to express um sort of those two"
  },
  {
    "startTime": "00:26:00",
    "text": "mechanisms between the the ipad and the rendering threshold but but you're right that this may not always be applicable well no i i think that you're you you're using your you're thinking of the act delay but the act delay as as two functions there one of the aggregate function is the passing of x as i said i don't want to receive ads more than 10 milliseconds apart if everything is working fine what you're looking at here is a secondary mechanism to say please fire quickly if something seems wrong now something seems wrong for you can be expressed either as i am observing losses i am serving holes in the packet sequence numbers or i there is some some also mechanism now the packet sequence number is something which is very hard to use in practice because first i mean the the size of the loss in the packet sequence number vary with the conjugation window and second the it also depends on things like numbers keeping by the sender and so what you have there you have a primary arc delay you might want to have an acquiring delay or something like that yeah that's that's an interesting point um you are right that i'm mentally kind of conflating the two as being sufficiently similar to to serve both purposes and you're right that it's possible they're not sufficiently similar um but yeah okay okay i don't know johnny do you want to go next or do you should we let the queue go and have martin go is your response directly your response to the christian or john"
  },
  {
    "startTime": "00:28:00",
    "text": "if it's all right i mean i i think i don't i don't quite understand the issue that christine's having um at high level basically packet threshold is already there and the problem with this particular with with the with the act delays that we effectively did not have packet to show lost detection anymore and what this proposal does is it brings it back so it's not they were bringing a new new mechanism here we are simply reinstating a mechanism that we lost because of this extension does that make sense to your christian i'm not i'm not quite maybe i mean it's not saying we'll have to discuss this on the on the issue uh and others just bringing it up yeah we should we should have that discussion on on this on [Music] because i mean if we go back and forth i mean trying to explain that verbally it's gonna be long yeah and you've got like four and a half minutes to go here so um we're happy to have this discussion on the issue about how important it is but please look at 96 and we can talk about it then okay that makes sense to me especially given our time martin okay so wherever um i i think maybe i can understand what you're trying to do i'm not sure about the first subtraction here i'd like a picture because i'm not smart enough to do this the purpose of this discussion was so that people could understand what's going on and i suspect this is probably something along the lines of the right solution here but i don't know and so um that way [Music]"
  },
  {
    "startTime": "00:30:00",
    "text": "martin's voice broke off i suspect because of your mic being on yeah oh because of mine can it be the last part martin sorry request that you bring this to the list and provide some i guess better explanatory material than just a single slide with text on it but maybe it's just because it's a very long day in the middle of a very long week but i'm not smart enough yeah once again i think that the issue has some discussion on it but that's perfectly reasonable and fair i think part of our goal here was to bring attention to this issue because it's the only design issue that's left and pending and i think that either ways we'll be able to come to a decision on it once we get people's eyes and minds staring at it so um yeah i mean i think we'd be happy to do something on email if that's necessary um and you'd be a restating of what's on the issue already but that's happily done yeah yeah sorry i kind of thought i'd send this to the list but i must have failed to actually hit send on that email or something so apologies that's my dad uh oh thanks ian um i think it's better reordering threshold is better than ignore order this gives you a little bit more options than you know just true and false but as i i think christian what he said i think i agree with him so if there's a reordering threshold it can be either in time or in packets i i think maybe we can make this field either two fields or make this make a way to distinguish whether we are setting this in time or packets but the other thing i wanted to say was this is again the same prob same issue that i had raised with ignore order or ignore ce is what is the guidance somebody could set it very high and that just becomes the same as ignore order even if they're not selling it as zero they can still set it very high"
  },
  {
    "startTime": "00:32:02",
    "text": "so i'm not sure if the the guidance and the how how the sender is setting this if that uh there's guidance for how to set this in the draft i i think there's no additional guidance i thought we added guidance um recently janna i think wrote a pr to add guidance for other use cases and this would apply and so we'd have to make sure that guidance got kind of applied to this yeah i don't think we have i mean the pr the pr for this is not fully fleshed out yet i think that's that's definitely good feedback i think we need to have something that's more precise in terms of what does an endpoint do if they don't have anything better that they can use up they don't have having a a default in there is going to be very useful and i i think we can we can default back to quickv1 defaults uh but it'll be good to state that explicitly that people know what to do okay thank you i agree sorry hi thanks for doing this and i do see it progressing that's really good um i have two questions um the first one i think you've already touched on which i think there is some element of safety in here if you get these numbers wildly wrong then there is a congestion control implication so i would really love to see some sort of um safety considerations or recommended maximums or something we can maybe we can discuss that later on the issue does that seem reasonable yeah yeah we can we can either discuss it on this issue or on on other issues yeah let me yeah i'm happy it needs to be discussed i think we all agree i just want to make sure we get the right text in there and"
  },
  {
    "startTime": "00:34:00",
    "text": "it applies to all the various mechanisms we have and it's kind of a global like recommendation so i think we're all on the same page it's just a matter of making sure we actually get the right tax rate down um so yeah that's kind of why i asked that because i think it probably is better handles a separate thing uh once we've got the issues pinned down right yeah i think having one text section that kind of says like here are all the ways you could shoot yourself or the internet in the foot like don't do these things and here's why um it's kind of what we're we need to have and then my second point is is even more crazy than i think what video raised i mean i'm not convinced that ignore ce is in any way what the people who are designing l4s are imagining and i wonder what the impact of actually deploying an ignore ce thing without some very strong guidance would be on the whole l4s thing yeah we could we could add some notes about how that ignore c is not necessarily recommended for l4s specifically um yeah or we should just formula a little bit of um a separate issue that they can jump into perhaps on that one yeah i i think i might have time oh sorry yeah add something that quickly uh to gauri the this isn't ignore ce is not really designed to handle l4s it's more of an escape hatch for those for for for l4s in the sense that if you have if you don't have any acts coming back you don't have any accurate ecm feedback and so this this sort of currently defeats any accuracy that you might want to do so it's an escape hatch it's not precisely defined as a solution for l4s just to be clear we'll just discuss folks yeah we're at time here so i ask you politely to keep up this healthy discussion on the list and the issues um thank you ian for the presentation your last slide talked about working group best call um it seems there's there's"
  },
  {
    "startTime": "00:36:01",
    "text": "still a few uh well this design issue and a few more issues to go um another question the chair is probably asking is is about implementation and interoperability of the act frequency i know there has been some but um if if other people are doing that that would help us understand um how mature this draft is and and how good it is but beyond that i think we'll need to move on to the next slide so once again thank you ian you're welcome thanks robin's up next with q log uh do you wanna there we go the system works thank you go ahead robin yeah i'm intelligible i hope since we had a few issues with that on monday um so it's short other than kilo because not that much happened uh for the latest draft in the past three months the main thing we did was move to a different serialization format and just to give a little bit of context on that as you know we we use json for the main format which is very nice it's well supported the main downside is that it's quite not very robust in most of the parsers for example here if you would forget the final square bracket in this example most of the parcels would simply break they wouldn't even give you a partial result there this means typical json is not very usable for streaming cases because there you often might not have the option to properly finish the json file or let's say if your implementation crashes before they can finish the full log so what we did initially was define a separate additional format next to that for which we chose newline delimited json which is exactly what it sounds like you just instead of having proper json you just have each json object as a separate line and you can just use the new line as a delimiter which is"
  },
  {
    "startTime": "00:38:01",
    "text": "very simple works quite well the main downside there is that it has no official rfc so if you would use that we would have to define a lot of this basics in the queue log drafts themselves basically a smaller downside is that you can't have new lines inside of the json um itself which is a bit annoying if you're doing like manual grabbing or actually eyeballing the q log files because these these events are typically very very long if you do them on a single line so that's what we had last time and then i think it was martin thompson who suggested how about we move to rfc 7464 instead which is if you don't know it's it's called json text sequences and this is actually very very similar in uh in concept to new line delimited json instead of new lines you're now using the existing ascii record separator character so this is not actually a string so it's it's just because it's a binary character it's difficult to visualize in the slide so the rs with the brackets is actually just a single unicode code point uh indicating the record-separated character um so the nice thing there is this is properly defined in rc it's properly defined how to how to use it how it maps to uh um to um scratch that and we can have new lines inside of events which is also quite nice the main downside was this seems to be relatively esoteric it isn't as broadly supported as newline delimited json despite being a standard and so we decided we first want to get some practical experience with this before we uh switch the uh the q log format over to that which is what we did and so it turns out it's actually quite feasible quite doable"
  },
  {
    "startTime": "00:40:01",
    "text": "if you're already doing nd json it's very easy to move over to json text sequences in practice and we also tested various existing tool suites or tools that people were using for qlog like jq and all kinds of linux based text processing tools and they all seem to work just fine with this new format and so that's the reason why we decided let's go for it and uh so that's the main change in draft one we moved from ndjs onto this with that some fewer additional minor changes we have semantic versioning now we have a little bit of more information on using different file extensions for the different formats and also have some more information on the media types that you might use when when say sending these things over http um this was then picked up quite quickly we have support for this in the qvis tool suite and we also have several implementations that have moved to the newest format and everything seems to work just fine so two points i want to make there first it's not that we're moving everything over to this we are still supporting both json and json text sequences so non-streaming file based and streaming let's say but if you were for some reason waiting for this change to be made to update your own implementation i think it's fair to say that we'll likely stay with this streaming format so if you were waiting for this you can probably go ahead and start implementing that so that's since last time what are we planning for the near future by itf 113 we're hoping to mainly do some editorial work and the main thing there is that in the current drafts all of our events we've tried to properly define them which"
  },
  {
    "startTime": "00:42:01",
    "text": "fields are on which events and which type are those fields but for those we are currently using the typescript data definition format and here we have a very similar situation to nd json it's usable but it's no it's not really well defined anywhere and it's not an rfc and so here again we also want to make the move to something a bit more itf centric which is called the concise data definition language cddl as you can see it's it's very similar in concepts it's just mainly the syntax that changes a little bit but the main gain we hope to get from this especially down the line is that cdl should make it easier for us to automatically extract event definitions schema definitions in different formats and programming languages and also use those to build automatic validators for q log files which is something that we are currently missing a bit uh so the goal is there to hopefully have something like in tools like qvis that you upload a q log file and then it can tell you exactly if you have any errors in there misspelled fields wrong types or fields and so on and so forth which is something we've seen surface a little bit in the in the past months for some people so that's kind of the idea it's both to make everything a bit more neat itf style but also be more robust towards the future when we start adding new stuff so this is what i think we have in mind for next ietf 113 and then after that our main goals are to basically flash out what we have we are a bit lacking in tls and qpec stuff at this moment so we want to add those things and then we have a few events that need to be extended or touched up to be a bit"
  },
  {
    "startTime": "00:44:00",
    "text": "clearer and then there are some proposals to add more high-level generalized stuff like indicating which cpu or which tread a certain event comes from that kind of stuff that other implementations like microsoft use in their custom logging format that might be useful down the line and that's basically it like last time we we had i had in my slides um like a desire to have like a a global design guideline or or a design framework so that people could add new events and new protocols even to qlog and so on and so forth and since we've had a lot of discussion about that and i think most people there agree that this is a bit of a utopia that it would be quite difficult to achieve this and even if we could it's probably not something we want to do within the the the quick working group for for the current k-log effort and so the idea here would be to limit ourselves quite relatively to quick in http 3 and then look into all these other stuff later on which is fine for me but i think that means that we need a very clear idea of how to do that later on already now or at least provide enough extension points down the line to make this relatively possible and that's something that is on this slide and that especially lucas has been creating some issues for in the past weeks that we need to start thinking about versioning and versioning of individual documents individual event groupings we need to think about how to indicate which protocols and which events are in which file um how to uh make it possible to change existing events for example add new transport parameters into the existing transport parameter event that we have and so on and so forth and then we should also have a discussion about let's say we want a q log log events for rap transport"
  },
  {
    "startTime": "00:46:01",
    "text": "how do we do that is that a separate draft is it a fully separate thing where does that live and so on and so forth so a few of those practical issues those are not things that are very pressing at this moment but it would be nice to have an idea of what people think about this or to have some proposals of this by itf 113 so that we can start the discussion in earnest by then so that's what i have for you today please if you have any questions go ahead kazoo thank you for the presentation and thank you for making the changes uh regarding the file format i prefer uh choosing one rather than uh having support for two because in my opinion you know supporting two is always more complex than supporting one and writing a conversion tool to the other yeah but it's even if we have two formats it's still possible to just implement one and then convert it to the other if you uh if you want right i'm not sure i understand the question right i mean if if there's only one format defined then for example i can create a pool that only supports that format but if there are two formats being defined i i'm you know i'm forced to write a converter or write at least write a test to support both of those two and that's a complexity i think for everyone every other one so you would propose moving to just a single defined format um yes yep regardless of whichever"
  },
  {
    "startTime": "00:48:04",
    "text": "thank you oh man thanks hello now i can hear you yep all right uh regarding the uh rs separated keylog uh are they semantics of aggregating multiple logs into a single created log uh going to be understood by the tools or is it something that's undefined behavior yeah so that's that's one of the main reasons i would have two different formats i didn't want to get too deep into that with kazuo but i don't have a second question so if you have multiple if you have the normal json one we can append separate traces as individual objects that's much more difficult in streaming format if you want to do that in streaming format you would have to indicate for each individual event to which sub-trace it it belongs otherwise it's impossible to de-multiplex them afterwards thank you but uh finalizing on that that is something that qvis for example also already does it's not that it's very complex it's just a different way of doing things oh well um it doesn't seem like we've got anyone else in the queue um there's some some good progress here and some good progress to come i did see in the chat um christine mentioned multipath support i think you know sometimes defining these events takes some thinking but it isn't too hard it's more the um what should what makes sense to put in and what are people willing to implement"
  },
  {
    "startTime": "00:50:01",
    "text": "um because you can define everything and if no one implements them then you you can end up with some interop issues uh like like we found in the hackathon last week uh when we are consuming each other's um q logs so uh i think there's there's some some good work to come up and look forward to that progress in the future but if there's nothing more here i think we could just move on um for just for multipath i was intentionally waiting a bit for the unified proposal right um to know what what direction we're going and once that's settled down i i think it should be relatively easy to add at least provisional multi-part events and then also have some basic uh let's say cubist tooling around that to help with multiple debugging yeah cool well thank you robin um and with that we can move on to vision negotiation so david would you like to step on up please good morning afternoon evening middle of the night everyone let me find these slides all right can someone confirm that you can hear me and see the slides i can confirm cool thanks uh so uh my name is david kanazi and i'm here to very very briefly give folks an update on the version negotiation draft um so a very accelerated history uh we used to have vn in the core specs we then decided to remove it and split it to its own draft this is that draft we were went around in circles for a bit on it because it was too complicated then mt came around with a simpler design that folks liked that's in the draft today"
  },
  {
    "startTime": "00:52:02",
    "text": "and then the question is where do we go from here um so far the the new simplified design i've haven't heard anyone said they dislike it so we're in good shape uh we still have a lot of minor issues on the on the document it's more that um just the the editors uh haven't been focusing on it so we haven't made good progress on those um but like all the ones i did a quick pass on those last week and it really looked like there was agreement on how to resolve all of them uh the question is kind of what is the status with implementations uh for the longest time we didn't have one i just just on monday i implemented it in our stack not the compatible part but the at least the version downgrade part and it was very straightforward and kind of the question for the working group is where do we want to go from here do we want to publish this soon do we want to wait until we have another version so we can like test the compatibility bits at scale before we ship this uh we'd kind of like to get a some sort of a timeline because you know that if this needs to get published soon then that it's worth it for the editors to prioritize like fixing these editorial things otherwise we can kind of kick this can down the road until another version so thoughts questions what do we do now this is the end of my presentation crickets so if um one thing is please interrupt with my server i put it on the general channel of the slack um just want to make sure that you know we i implemented it correctly but apart from that uh given that there's not too much excitement about this i guess maybe we just kind of kicked the"
  },
  {
    "startTime": "00:54:01",
    "text": "can down the road a bit further uh matt do you have any thoughts yeah i was just gonna you know hearing the the deafening silence from the working group i think like everyone agrees this is something we need it but it doesn't seem like there's a lot of implementation appetite at the moment i think for something like this we do want implementations and interop before we like you know kind of shepherd it through so um just everyone keep that in mind that if if you want this in the future if you see this being something that you want in the future please implement it sooner rather than later um gianna did you want to say something um hey um thanks for the presentation dude just very quickly it seems to me that it might actually be useful to get some implementation deployment experience along with a different version so i wonder if the quick v2 discussion that we are about to have later might play into how quickly we move on this draft that that makes sense because if we have a v2 that is compatible with the first one that'll help us to use this at scale also we won't be able to ship a v2 without a version negotiation mechanism with v1 so like yeah maybe these become a joint cluster and uh i think the quick v2 is on the s time permits so in that case i'll just say let's punch for now but let's see what comes out of the v2 discussion all right and expect a similar two-minute presentation at the next atf then thanks everyone all right since i'm already on the mic uh yeah mark i've as we can see martin's coming up with quick lb so go ahead martin yeah"
  },
  {
    "startTime": "00:56:00",
    "text": "in the uh staying in the vein of um things that people sort of support but are a little bit can i get a clock reset please uh that think that people that things that people support but there aren't a lot of implementations quick lb um so uh at 111 i talked about a lot of uh technical issues um and basically that the draft had expanded to cover lots of use cases because we weren't getting a lot of useful feedback of what the most important use cases were um so uh the the the upshot of that was people thought it was too complicated too many choices and i agreed with that and then of course the other concerns there weren't a ton of implementations uh particularly on the server side and no interop activity to date that i'm aware of so some things have happened here uh christian uitima has been incredibly valuable and fixing the now very much misnamed stream site for algorithm into something that is a little more secure um uh we've kind of just cleaned up some of the nomenclature to kind of make it less three completely disjoint algorithms with just um three just three different sets of options to kind of the same core structure so it's just a simplification thing um an ad a couple drafts ago was dynamic uh server id allocation not preconfiguring that and um i think we've reached consensus that it's a little too cute and there's there's too many um difficult mechanisms associated with that that's gone again uh and then i've heard some good news about implementations but i haven't seen anything concrete yet again like i know there are a lot of server implementers in the room and that is where we are hurting most um if you have a quick server implementation many of you do and you would like to create some server some connection degeneration logic uh we have load balancers that can interact with you and that would be helpful there we go okay so this is kind of my my dream on how this can move forward um"
  },
  {
    "startTime": "00:58:00",
    "text": "uh chris and i have asked for a cfrg review of the the stream cipher algorithm um since it's since christian came up with something was kind of a variant of effect so we've kind of rolled our own crypto so we're going through that process now not sure exactly what the what the reaction will be um if that goes well and it shows that we have the same or similar security properties to the block cipher algorithm it's not clear to me what the value of the block cipher algorithm is there's an issue in the github if you want to weigh in on this but essentially you'd be getting longer c ids the only benefit would be fewer crypto passes which seems like a not that strong advantage um and then that would dramatically simplify that the document essentially have a like a plain text version and the cirtex version of the same thing so that would be um that'd be as simple as you could get um i really would like to split the load balancer portion of this and the retry service portion of this i view them as entirely orthogonal with each other um the load balancer thing's essentially version invariant with a few caveats and then retry service thing really is not and um i'm getting proposals for things like stateless uh reset offload and so on and they all just have like the common theme of middle box coordination but i don't know if that's a strong enough thread to hold these two things together i've also just kind of become enamored of the idea that like smaller drafts are better because people read them and when there's a lot of ancillary stuff that half people don't care about just makes things worse so i don't know if people's strong opinions about that i'll be happy to hear from it then after like if all this goes according to plan then we do another editorial pass then it'd be done as it's going to be done that's just the question of getting a couple implementations that are up in them and then we're done so let's see do i have another slide yes uh i don't know if you want to talk about the block cid stuff right now we can get into that if you want so i'll just open the floor for comments"
  },
  {
    "startTime": "01:00:06",
    "text": "ian uh i the only thing i had to share is that i now that we've kind of worked our way through our backlog of idea of quick work in other areas um we are very excited to hopefully take this on in the first half of 2022 um but there's still some details to be worked out in terms of who's going to do the work and everything um but the use cases are there and everything but that to be said to be clear that's like the stream cipher protocol with like the key rotation and all of those sort of mechanisms um the key exchange portion and all that stuff uh i don't we probably will support at some point in the future but that's like more of a a year from now or more probably sort of thing so i think that probably supports the idea that at least in our case you're gonna get a deployment on one of them a lot earlier than you're going to get deployment on the other half but i don't know are you talking about the retry service versus the the um load balancing yes sorry that's right okay yeah all right super thank you yeah i mean like that's the other thing like if we get a lot of implications in one i anticipate the implementations of one of those components versus the other to be very asymmetric and if one's ready to go i'd just like to move it um and at some point i'll i'll produce a mock-up of what these book things would look like when people shoot at it lucas hey martin um have you i'm just curious have you had any feedback to say that the proposed split is is not desirable has anyone kind of said that they wouldn't like that um i i i brought it up uh like a long time ago and got like i think it's like five or six weeks ago and got some negative uh like a little bit negative pushback i'm it wasn't super strong i'm become more convinced this i'm bringing it up again uh and you know i don't i don't think i"
  },
  {
    "startTime": "01:02:00",
    "text": "haven't really discussed this on the list much recently i will do so but this is my i'm kind of introducing the topic now frankly um to allow people to comment okay that's cool i think that the list is a good venue to continue that um i think i i i'm trying hat off in personal opinion if splitting them is going to help make some progress on on the one thing that people really do want to implement um that seems like a benefit but i'm i'm not fully okay with with lb to know what the potential downside might be for that split i mean they're functionally completely i mean they can in theory be implemented on the same device but there there's there's no real relationship between the two um they're together because they were again under the theme of middlebox uh cooperation um which is a pretty weak threat in my view so there's a comment in the chat about they missed the cfrg email that's because we didn't actually go directly to cfrg upon the advice of the security ids we contact a couple people directly um if other people like provide a crypto review of what of specific specifically section 5.2 the stream site for cid like that would be um very welcome i i just i received the advice it would be better to actually contact people directly any uh matt are you in the queue or you just um i'm mostly hanging out but i was going to say one thing which is that um i was curious what you're in from a chair perspective what what is your opinion on uh this necessity for interop for you know are you are we comfortable like because it seems like there hasn't been a lot of design issues or things recently besides the things you mentioned and so you know do we wait on interop do we wait on and do we have to interrupt everything or what and deploy it or what i was just curious what your"
  },
  {
    "startTime": "01:04:00",
    "text": "thoughts are on that so i i have like two concerns with the surety i'm beyond beyond just kind of my ideal path and how this proceeds i to consider my maturity number one is that the document is written in a way that it's implementable because obviously i knew what i meant when i implemented it um which it doesn't uh mean a ton and then the second thing um and i hope that especially google's uh intentions are helpful here like actually trying to deploy this thing and developing some uh like we have we have sort of a configuration model that has some assumptions and it'll be really nice to like test that against actual production somehow so i'm really eager to hear um to hear like what the what the issues are with google and like what the rough edges on sort of the assumptions we make on how to configure things and like what what what the pain points are i know that uh my my co-author nick banks has like been working with azure uh on this stuff and it hasn't gone super well in terms of getting them to to provide good feedback so um those are really those are the only reason other than just like the clean up in the draft that's those are the reasons those are the two things where i just don't want to like hit the wtlc button right now uh all right if there's nothing else i'm going to give back the balance of my time thanks thank you martin that's very kind of you um okay so mira is jumping in the queue it's time for the uh new work topic um samaria take it away on the topic of multi-path extension okay hello everybody um so yeah i'm amelia i'm presenting um a new draft here um but effectively this is not new work um there has been previously uh three different drafts and as you can see here on this new draft we have a set of authors that actually combines"
  },
  {
    "startTime": "01:06:01",
    "text": "the authors from the previous draft so that's the content um so let's move to the next uh i have to i can just control this myself okay yeah so what happened so far um lucas already uh mentioned that we had an interview meeting about a year ago where we talked about quick use cases mainly requirements and since then there was a lot of work and people have been working on implementations there were three different proposals and in order to move forward from here we somehow needed to agree what the right way is to move forward like combining those proposals and and getting one way out of this um so um i got in touch with all the authors from uh from all the draft and there was already a lot of agreement about what to do and everybody was like so um on board for having one unified solution immediately um so we had a site meeting only a few weeks ago where we discussed how um to move forward here and as a result of that we recently published this new draft which does take parts of the the other three drafts um so this presentation will give you an overview about what's what's the focus in the new draft and what's in the new draft and this is um the most important outcome from all the discussion we had is that the new draft is really focusing on the core components so in the other three drafts there were always parts which were like not core components which were things like um qe handling um address discovery and this kind of things and in order to move forward we really want to focus on those things that are needed to establish multipath usage of of multiple paths simultaneously so that means the current draft as a core component has of course the negotiation of a new extension it has a minimal set of path management that is needed about setting up inclusion close new path um or old pass in that case it talks a little bit about scheduling but that's really minimal at this point we probably need a few more words but don't want to talk about it extensively only what's needed to make it work and"
  },
  {
    "startTime": "01:08:01",
    "text": "then it talks about how to actually transmit and retransmit packets so that's it that's the core everything else that has been previously um discussed like more advanced scheduling mechanisms or unidirectional passes address disc discovery or any kind of qs handling and these are things that could come up later on in additional drafts or could be additional extensions on top of that so the other thing that we had like very broad agreement on is that one of the important design principles here is to use as much as possible from rfc 9000 and this is also kind of the feedback i not only got from the authors but from everybody else i talked like please keep this as simple as possible and that means make minimal set of changes here and we actually try to do that so what we don't change is past validation we completely keep it as it is in a quick version one and uh and as used for pass migration uh we don't have to change basically anything about congestion control because congestion flow was always per path so when you had migration you had to reset your congestion control and now you have to run multiple congestion controls in parallel for each path we didn't change the header format and also didn't change anything in the in the r0 rtt packet so everything that we do for multipass is done for one rtt packets there is another design principle which is kind of uh important is that we define a path as a four tuple that may makes some things some assumptions easier and it mainly means that you can only have one path before chapel so what did we change or what what did we add i probably have to say what we add is that we kind of not only want migration but we actually want simultaneous use of multiple path so that means that you can send non-probing frames on multiple paths at the same time so this is something that is not allowed by rsc 9000 and that's something we want to enable here"
  },
  {
    "startTime": "01:10:00",
    "text": "um so that's one change and the other change is that we now that you have like multiple open paths you also have to care about clothing those paths so that's some additional mechanics that we added here um but it's also not a lot of stuff i have to say and there are a few additional considerations about recovery and for example rtt estimation and these all depend a little bit about how you kind of implement acting and packet number spaces because you really need to figure out for rtt estimation and loss recovery in which packet which packet was sent on which path and depending on what solution you choose for your packet number spaces that might be easier or harder before i talk more about packet number spaces which is like one of the open points i just um show you on the next slide what we are proposing to do in this draft right now so what we have in the draft right now is that you can actually negotiate um either use of one packet number space or use of model packer number space or you can in indicate in the handshake that you support both if both ends support both implementations you will use multiple packet number space that is actually not in the currency or zero draft version but that's a pr we already merged into the next update because that wasn't clearly specified so what does it mean one packet number or multiple packet number um easy so with one packet number space every packet you want to send out gets the new packet number in order and then you decide to send it out on one or the other paths so you might send out packet one on one pass and pack it on the other pass if you have multiple packet number spaces the packet numbers are independent on each path uh and you can have packet one on pass number one and you can have packet one on pass number two but you have to identify which path this was sent on um we have those two options in the negotiation and in the specification of the current version of the draft but this is to able evaluation and implementation experience"
  },
  {
    "startTime": "01:12:00",
    "text": "and this is not is there's no intention to publish this kind of negotiation for the final version of of this extension in any rsc um but we proposed to actually take it on in a working group like this so we can get more experience here and make progress and have more um discussion about this so on this slide i try to on a high level summarize the current discussion about packet number spaces and why it's not easy to make a decision right away we had some discussion about this in the site meeting there's also a nice slide set from christian hittimer about this if you want to learn more but you know the high level message on this slide is there are pros and cons for both of the approaches um so i think i'm starting with the cons for some single number packet number space here so the cons for the single packet number space is actually it it's a kind of easy um the pro sorry that it's kind of easy to implement it's it's only a few um lines of code that you need to add or change um and and the other pros also that it does work with zero length connection id um the cons are that you can come into a situation where you actually increase your ag frame size um noticeably so especially if you have two paths which have very different latencies you might get a lot of reordering um you can be smart about how you schedule the packets or how you create your ex and try to reduce that but the problem or the con maybe is that you have to be smart it's not straightforward you have to do it right and maybe there's also more chance for doing something wrong on the multiple packet number spaces um you you don't have that problem so that's one of the big cons it's very um clear which packet belongs to which path there's no ambiguity about you know where the packet was lost or about when you calculate the round trip time or anything like that and your pack your egg frames are smaller and clearer and so the the logic that you have to implement is easier however you have to have more code"
  },
  {
    "startTime": "01:14:01",
    "text": "more lines of code and you have to have code that is specific for this extension only and might not be used in a single pass implementation or setup the other drawback of the multiple packet number space is that currently you we have to require connection ids in both directions to make this work but that is actually something that is under discussion and maybe um we come up with some smart ideas here as well um so but um effectively i don't think i want to discuss this topic here today i think what we need and what i said earlier is we need more implementation experience and feedback about this and then hopefully have this discussion further in the working group instead of making decision right here um yeah we have a few people in the queue um yes i was trying to look at this right now let's uh let's actually break here and take those questions yeah if you're okay with that mirror i'd like to keep this on for clarifying questions for for what's been said already um we'll have time for discussion at the end so um kazuho please fire away thanks for the presentation uh i have one question so one of the slides says that a path is defined as faultable being bi-directional does that mean that if you receive packets on path x you have to send out for those packets on pathx no it it it means that you have to be able to receive packets on that pat on that pass and and that's something that you check during past validation but where how to schedule packets and how to schedule their your x is is i think actually not specified that much in the draft currently that's left to the implementation so there's no requirement to set send the x on the same path thank you uh can you hear me yes yeah so i have reading you know the"
  },
  {
    "startTime": "01:16:00",
    "text": "emergency act so um i just got one comment so i suggest that maybe we can add some use quiz or some um some paragraph in the introduction to describe uh explicitly so how do we how how we can use that uh and be quick so the reason is so now you should know that uh the cpr um r18 has um has the release 18 has discussed the atss for a long time and several companies strong support uh to add the multi-pass functionalities into the attackers to achieve um you know the traffic splitting or even redundant transmissions so i think uh so i think one of the the valuable things here is that uh so perhaps we can if we can complete a uh and a quick work for just before the uh the completion of the release 18 and then we can we can try to uh to adopt this this uh rfc into the real estate team that's maybe it's it's it's it's a good way to uh to like to you know uh to make this drive you need to implement into the in the real world case so actually i stopped in a uh use case draft before for this meeting so i'm not sure whether i can share my screen uh for sometimes or i can just just simply describe that the the the draft we're sure we need to focus on the discussion here um yeah we need to just keep this to clarifying questions about the president okay so uh i just i i okay let me simply describe so i just have a point um i i agree with you i think this is a very important use case and i'm supporting that as well um and um we should prob maybe have some more"
  },
  {
    "startTime": "01:18:00",
    "text": "discussion in future but probably not in this meeting so i think in this reading we should figure out what are the basic concepts that we want to see in a draft and then move forward and and have this discussion later if that's okay for you okay so so perhaps uh yeah once we have um once we've upgraded on the uh on the basic setup quick shot maybe for the for the extension so we can consider to add some introduction and some descriptions about how to you know how to advertise the uh the draft into a different organization okay thank you yeah i think that might be a rather separate draft than something in the introduction yeah but um yeah something to consider later yeah thanks diana uh thanks a very quick clarifying question um maria you said that the decision between these two choices would require more implementation experience and matt said on chat that this would be the first design decision that we would make if this draft were to be adopted those two are very different points and i don't need it right now but it'd be useful to clarify what exactly the path forward would be because i would like to push against something which i'm not gonna do right now but this is asking for clarification for what that would be um so if you ask me um i think for example people deciding to only decide implement one or the other you know is good input for this group if we have everybody at the end decides to only implement one of the approaches then we have a decision we don't need much discussion about it but i'm also pretty sure that depending on the stack you're having your implementation experience might be different so more input would be valuable here because based on the implementations we have so far um we can see that the implementation of a single number packet space um is easier but we also didn't um evaluate a lot of the logic that you have to implement then if that actually works very well so more work is needed from my point of view but maybe matt wants to say more"
  },
  {
    "startTime": "01:20:03",
    "text": "uh yeah what i was going to say is that you know it i kind of agree with jonah that it's a design issue but you know it's it i think what you're saying is actually kind of the same which is that you wait mario what you're saying is you want input from implementers about which design they think works with their implementation not necessarily that you think everyone should go implement both and then be like oh i like this one better all right yep that's totally it spencer spencer do you want to uh sorry i was just waiting for somebody to to tell me if we were we were finished um i wanted to thank you all for doing this work uh a lot um maria um we i've been talking about a strategy of uh sending acts on different paths which you're leading leading up to the implementations for now and i'm not arguing about that my clarifying question was is that does that work with one sequence space multiple sequence spaces both or neither sorry does does what work uh sending sending acts on a different path um [Music] that should is completely independent you can you can even if you have a different packet number space you can send it to a different path all right as the act doesn't identify the packet number and space your your perfect item i am clarified thank you sorry i was trying to read the chat at the same time which doesn't work so you have to come to the queue and talk to me hello yeah um so what i want to ask is does the multipath quick also cover the data from"
  },
  {
    "startTime": "01:22:01",
    "text": "extension yes these extensions are completely independent so you can implement both and use both okay okay so you don't see special challenges here and the description of multi-pass quick is completely agnostic to that um okay nevertheless um my question is specific to the uh multiple r2 to the packet number spaces so as you know we are developing the multi-parts dccp which i think has a similar yeah kind of similar characteristics to the multi-path quick especially when we think about a multi-path quick with the data chrome extension because then we have an unreliable transmission which has some challenges to multipath and in that respect we explicitly decided to use multiple pn spaces for mpdccp because it has some positive effect if it comes to reordering so it supports us in our in our reordering approach and i think that's quite important or that you should consider if you discuss the packet number spaces if it should be a single one or a multiple one so have in mind that multiples plus data chrome has some special demands and maybe multiple pn spaces can support here yeah i mean i'm not i'm not too familiar with the details of dccp but i think it's different here because for datagram and quick you already still know when a packet get lost you just don't resubmit it because you have a packing number here oh yeah okay yeah that's the same in dccp so you are aware of a packet that's lost nevertheless you maybe wanna reorder packets without re-transmission without requiring re-transmission and then multiple pn spaces can help to to make fast decisions in the reordering process if a packet get lost or it's worth to wait for it i just gotta interject here's a chat this is interesting chat we can we can have this on the list and on issues it's it's kind of beyond the scope of clarification so uh thanks marcus but um"
  },
  {
    "startTime": "01:24:00",
    "text": "yeah we'll we'll follow up on that one um yep we're gonna if you want to progress through the slides mirror um yes uh let's go through many few slides and just to tell you what's in the draft not much left here so as i said there is something about path management path initiation um it works very similar than pass validation if you take pass validation as it is from rsc 9000 no changes the only change is that afterwards after the validation has completed you can actually send non-problem packets on multiple path um pass validation can also be only initiated by the client so that's a restriction that we could further discuss um in the working group but that's what's currently in the draft the thing that we did add was pass removal because with migration you don't need to remove the path you move over you close the old parts immediately uh with multi-pass support you have multiple paths so you have to care about how to close them there is a new frame here which is called path of button and but we also reuse the retire connection id frame to actually signal the that resources can be released and we also rely on timeouts as it's done in rf9000 um so basically um what we do here is we we from from a semantics point of view we have two new frame types one of the past bend frame this carries past identifier error code and reason frame and there is also a pass identifier type which indicates um if the pass identifier belongs to uh basically the source or destination id or to the current pass if no connection id is present so effectively you can send this frame on any path if you have a connection id if you don't have a connection you can only send it over the past that you want to abandon so if you have a connection id you have like more flexibility here in providing this signal to the other hand then we also have a new um egg multi-pass frame this is only used if uh if you have multiple packet number"
  },
  {
    "startTime": "01:26:00",
    "text": "spaces but this extension is also minimal it's really like the old egg frame it only has one additional field which identifies the packet number space um yeah so that's kind of what's in the draft again we we really try to focus on the core components that are needed to use multiple paths simultaneously and all the authors have agreed on some key design principles which is really try to keep it as simple as possible just add minimal stuff and and we are aligned with that i think that was also what came out of the site meeting we have this option to currently to negotiate multiple packet numbers space one or multiple number spaces but this is really for experimentation and so please if you go implement the site if you want to implement one or both of them and report back so we can make a decision for one of those approaches at some point but um i think this is ready to uh to take on by the working group and move the discussion back into the working group at the site meeting there was a lot of interest there was also people talking about implementation so i think uh i think it would be great to have this in the working group and so we are we are asking if this is ready for adoption yeah and just to add to that you know we've got some time for discussion now there's there's a lot of potential things that people could say about cool ideas they've got or potential issues they might see um but we'd like to keep the discussion here focused on on the question um about you know viewpoints on on whether we think this this brush should be adopted um or not um towards the end of the the eight minutes we have here we'll take a show of hands as well um before taking any any question to the list but yeah if people could keep it on the topic of adoption um that would greatly help the chairs so uh john is first in the queue please please go thank you for the presentation maria it was very helpful um at high level i"
  },
  {
    "startTime": "01:28:00",
    "text": "would say that the document that lays out all possible designs i would argue is not ready for adoption simply because it it it's a superset of all the things that you might want to do now i haven't read the draft yet so i'll admit that first um but can i interrupt you here for one second so we're not playing out all possible designs we really try to concentrate on the minimum but um it was and there was a lot of things where the three different drafts you look at like we actually found a lot of agreement and the authors are all aligned on these points it's really just a packet number space because as you have seen on the slide there's no clear good solution right so rather than trying to take any kind of choice and now and then maybe revise it later because we're figuring out this is not the right thing to do and we left those two options in there only for this one issue understood but it's a pretty fundamental issue i mean the backend number space issue drives a lot of questions really it doesn't it's really a very um detailed implementation thing it doesn't change any of the functionality or any of the principles you want to have in this graph it's really about implementation um so i would have to read the draft i suppose i mean i'll take that back to myself that's feedback to me however i'll say that if we can resolve that issue before we talk about our option that would be helpful because to me the the the ultimately we are defining a protocol here it's not rocket science and the protocol is about the details and the use of path id or not the use of a separate packet numbers or not actually again in it to me it should make a difference in big difference in how the protocol is designed so uh i would argue that uh take it for what it's worth but i haven't read the draft so i won't make it too strongly i would say that my point is we should resolve that issue before we really talk about the adopting the documents so point taking but also i think what we have right now is that and that was also"
  },
  {
    "startTime": "01:30:01",
    "text": "we have two specifications and they can work together we have identified what are the things that overlap and have described them in in the respective way so if you make a decision for one or the other at some point we just go ahead and remove parts of the draft and that's it it's not it's not like we have to redesign the rest because we separated those things nicely um so i think this is really a a small part only and rather than trying to um to kind of get ourselves stuck on this kind of minor implementation point i think we should move forward and we should uh make sure that everything is is in well shape and incentivize people to um implement this and and give a clear thing that we actually want to work on this and come to a conclusion um just based on some of the chat and that that we're having and jonah's point there about not having read the draft i'm just going to take a quick show of hands for who who has actually read this already um so we're going to use the echo tool for this um and the question is going to be quite simple have you read the draft and you can raise your hand um to say you have and i'm going to start that now and we'll run that give this like another 20 seconds or so you can click do not erase drafts but not this version like i read the ids before they were merged what should i answer maybe no because i think for this question it's actually important that you understand what the difference is okay i'm gonna i'm gonna close the poll now uh we have 20 raised hands and 46 did not raise their hands for a"
  },
  {
    "startTime": "01:32:00",
    "text": "total of 66 participants in a meeting of 168 people so uh thank you uh kazuo please regarding design support um is there a design principle regarding the efficiency of the protocol to give an example is then principle that multiple quotes should perform as well as quickbrilliant i might have missed that but would hope that that be clarified because that's what drives the design choices that we make um so i don't think we have this explicitly in the draft the design principles that we do list in the draft is what kind of what did lead the the author team to make the decisions right now it's not like a comprehensive list so if you want make sure this is captured in the draft then please open an issue yeah so i mean before adopting this i think i hope that we agree on the design goals i mean the the performance efficiency requirements that we want to meet because without agreeing on that it's so much harder to agree on what the choices that we have to take that's my i mean i think this needs more discussion because i don't even really understand what such a requirement would mean because um of course you have different path characteristics if you have multiple paths right so you might have one long delay and one short delay path and if you select the short delay pass for a certain application you have better experience than the longer past but it might be different for the other applications so i don't think this question is actually that easy i'm happy to discuss it more right but it's a fundamental different behavior so i'm not sure there is like a clear comparison to a single path approach well so what was thinking about a of a strictly uh inferior case like for example for fc and also recovery we"
  },
  {
    "startTime": "01:34:01",
    "text": "might need purpose signal back delays but that's hard to accomplish with single packet number space so that was the case i would think of it yes thank you i mean i'm also not sure if the answer to that is so clear because you just have to be smart about where to send when and where to send your ex so this is something we need more experience with thank you martin thanks uh yes i've read the draft i support this work export adoption although i'll probably personally not implement it um i don't think we need to resolve the pack number space issue prior to adoption i i will say the reason i support is i think there's a lot of um desire for multi-pass solution but there are a lot of big experimental questions and i think of all the transports we have i think quick is the best suited to do open internet experience because i'll actually get through the internet unlike all the other options um i would probably argue should be experimental draft we don't have to settle that now thanks tommy all right um so i i have read the unified draft and i definitely support adoption of it um i think that the work to unify the draft has greatly improved the proposal um as it's come together this is better than any of the individual drafts i think it doesn't have a lot of the excess bits hanging off of it it's focused and it's minimized and i think a minimal implementation is exactly the type of thing that we want to adopt here because otherwise we're going to spend a lot of time getting distracted so it's the right kind of starting point so if we think we need to work on multi-path let's do this and i think this is the time to start to work on multi-path mature implementations"
  },
  {
    "startTime": "01:36:01",
    "text": "are getting to the point where they need to use it our implementation really needs to start looking at this soon so having something that the working group is looking at is good there is an open question about packing number spaces i think that should be better addressed by the working group rather than having the authors try to come up with one thing and not listen to the whole working group so let's adopt it and figure out that question together so we're running on time but ian then yeah go ahead yeah i i support the last two two statements um in our case we finally finished like connection migration so i think we finally feel like we have like the bandwidth to really take some of this work on and actually contribute whereas before we didn't so i feel like now is the right time um i'd love to get the pack number space issue result but um i don't think it needs to be resolved before adoption but i also don't want to make everyone implement but um but i think we can hammer out like that pretty quickly in the networking group um the only other commenter that say is if we do this we may want to consider having like a separate one-hour meeting just for multipath or something real quick um because i get the impression there are some people who attend the quick working group who are distinctly uninterested in spending their time on us but i don't know you'd have to ask through about that christian i i definitely support uh adoption that's not surprising but the big reason i support adoption is exactly what tommy said we want the discussion to happen in public to the working group not in a confined mailing list that is between authors and if we support adoption if we get adoption what will happen is that we'll move the current github repo in which we're discussing will move that to the working group people who already sees it and will have change control and things like that and i think making the discussions public is a big reason for adoption"
  },
  {
    "startTime": "01:38:02",
    "text": "uh chana so i made the point about um not adopting this but i think that i i perhaps the spirit of the question to me now is whether we should work on multipath and if this is a document we can start from and to that my answer would be yes because there's only one document and i think that uh the work on multipath i think is it's a good time to start working on it as a working group so i would like to change my position that i said earlier to uh yes let's adopt it and let's hash out these issues okay and with that i think uh lucas is gonna we're gonna run two polls so uh lucas you want to describe the polls before you run them yeah i just want to thank people for their kind of feedback during this discussion um and the comments as well um you know this helps the chairs gauge get your opinion on on this matter so um to that end i just want to run a pole to see you know gauge interest in in who thinks that the working group should work on on any form of the multi-path problem and a multi-path extension to quick to resolve that problem so i'm going to start that poll now um if if you think if you agree um then raise your hand and if you don't agree then do not raise your hand and we're getting a bit short time so i'm going to close this poll soon um some results already coming in that look pretty strongly in favor of um that the working group should work on this uh the results are in the poll tool at the end but we have 52 raised hands and three raised hands um let's end the session there it it for anyone that that said that they don't"
  },
  {
    "startTime": "01:40:00",
    "text": "believe we should work on this uh do they want to make a comment at the microphone no okay um so in that case we'll do another poll um about adopting this specific draft um as the solution to this problem again raise your hand if you agree um that this draft should be adopted and do not raise hand if you disagree okay i'm just gonna close that poll too again i'll ask the same question we have two people who didn't raise their hand compared to 46 people that did if anyone didn't raise their hand it disagrees that we should have dropped this draft did you want to make a comment at the microphone i i don't see anyone um okay cool um we'll we'll take this away's chairs and speak to some people on back channel um and and do our thing um so stay tuned on the list um we've got martin duke um now we we've changed the agenda mid-session based on some feedback um and the version negotiation chat that was uh in david's slides so well it's going to talk about quick v2 or whatever we might want to call it"
  },
  {
    "startTime": "01:42:02",
    "text": "hello again everyone uh thanks to lucas from what was maybe a typo typing this t-o-o i've decided to like really embrace that because uh there's a bike shed about what the version number should be whether it's actually the numeral two or not so i'll be very brief um why is there v2 draft number one when we talk about greasing the version number people said we should roll up with v2 as quickly as we can and this is that uh number two to exercise versus negotiation framework as david discussed and then if there's any fixes we need to make some emergency patches to quick this could be a vehicle for that um it's a very simple short and simple draft it is exactly the same as v1 except for um the version number and the salt and the hkdf labels and sort of things you're supposed to roll for every version there are a couple of bike sheds about a lpn and what the version number should be uh though those were discussed pretty thoroughly in 111 and nothing's happened since then so i invite i direct you to that uh uh that the records of that discussion if you are interested in those in those questions um so i guess you know i i think it's about as radio dots as it ever will be um if people are want to implement this and and uh and take it to standard um we can do that so i'm happy to invite comments on that eric a clarifying question is there any reason that we'd want to include those couple of bike sheds because it seems like that it's kind of a no-brainer to do the first bullet point which is basically just let's rev the version number um are we trying to open up the scope to a bunch more than that or is it still in my view these are fundamental questions about what happens when you roll a new version uh that we didn't really decisively resolve in my view in shipping 9000 um again i i mean i don't"
  },
  {
    "startTime": "01:44:01",
    "text": "want to spend a ton of time on it i just refer you to the the the question just how do we number things and and and what is the status of aopn for new versions uh we have to sell it one way or the other david and there we go uh thanks for the presentation martin um i think it's not a given that we want to ship a quick version to with minor changes um because like that'll break a lot of things so for example like sure adding quick v2 support to my code base is trivial like you know if we assume it's a you know version that just has different salts and whatever um but if i do that then all of our tests will have to run with another version and it's like like the carbon impact of that is like more than all around the world which is just terrifying when i think about it but more importantly if we deploy this on our servers it means that now we need to support these things for longer we need more versions than alt service and we can end up with like compatibility problems uh take for example we still have middle boxes out there that like to extract the s and i of quick packets they will break some people will tell you that's a feature some people will tell me to roll back my change because they consider it a bug so there is a what i'm trying to say is there is a non-zero cost to deploying a quick version to and therefore is it the right move to do a quick version two whose sole purpose is to be version two or do we wanna take up some more work and fix some things that we want to fix as part of that effort uh but then we open ourselves to like second system syndrome so just wanted to put that option out there it's not free to do to do a version with a few changes thanks david i think that's a good point i mean i would say that greasing i mean that's kind of the nature of greasing"
  },
  {
    "startTime": "01:46:01",
    "text": "right is that you're deliberately breaking little boxes that are improperly um making improper assumptions about the the packet format but uh fair enough yes absolutely there's a risk of breakage um if people adopt this yeah i mean in this specific case uh i i don't think if the middle box is properly parsing quickview one packets and is making the assumption that it can only speak the version that was published rfc when they were code they're not technically doing anything wrong but but yeah thanks becker okay thanks for thinking this through um i guess i'm softly in favor of this um the um i think it'd be good i i i know i might as sort of shape the little box thing as others might be but i think it has some value i think increasing i think that getting some some experience in the machinery of negotiation would be helpful since we're actually going to specify it um i i would be against making any technical changes at all um really just on pragmatic grounds um you know we like opened up um you know we like we like opened up 84 46 for the purpose of you know um for the purpose of like removing the word master and um and making some technical and making some editorial changes and i'm still screwing with it like nine months later um and not really a position about any real changes at all so i think like you know like you know we get to publish this tomorrow more or less as it is um but if we like um you know but anything of my traditional clarifications just like you know like once you open the patient you just start to be like it starts to be like really hard hard to stop right so so to be absolutely clear i'm i'm also not in favor of like putting any nice to haves in here in terms of fixes i was talking about like actual like discovered security vulnerabilities and that sort of thing should they arise yeah yeah and i think like you know i think i i think we should put like i think what i would do and i still failed to do this with 846 is like put like a two month limit on like call for like things and they"
  },
  {
    "startTime": "01:48:00",
    "text": "have to be like really clear defense of some kind or another and then we'll just like fix them and go um i mean like you know i mean things like where it's obvious as back as just like you know like especially incoherent or it's like contradicts itself or like it's obviously wrong um but like i think you know the idea should be i think that um that like let me put it this way you're like it should absolutely be the case that like modulo these constants your code in the wire should not change and if color wires change then we like them like they're like we're probably like that's like bad news right um yeah so that'd be by my point thank you mt i need to preempt this uh so i'm also sort of soft on this i am maybe a little more supportive than echo support uh because i don't see us shipping the version negotiation stuff without something like this and so um i think we should do this um your discussion previously though uh made me think that you would you were doing like a biz document but it doesn't seem to be like that in its current form and i prefer its current form i think what you've done is is almost perfect for it so i think this is something we should adopt and try to get it out at the same time as a first negotiation draft thank you brian hello uh yeah so um everything martin said and everything ecker said i would add that i would actually go a little further than that and request that the chairs schedule a working group last call at adoption time um just to basically say there is an actual deadline to keep that to keep the um uh the temptation to stuff things uh into your uh down i i um like agree a bit with david's point we should consider the cost of doing this i think that the right way to consider the"
  },
  {
    "startTime": "01:50:00",
    "text": "cost of doing this is publish a document experiment thank you yeah uh like i i'm very intrigued i'm i i'm very sympathetic to the sentiment to just like ship it immediately i do think we have to work out this aopn issue uh uh and just decide what we're going to do will that take more than will that take more than two or three months i'm not saying schedule working group call to start at adoption i'm saying at adoption time also go ahead and say working group class call will start at this time yeah should it no but you know we've we've done crazy things before so will it is a different question yeah tommy um yeah i wanna i'll echo barton and brian i i think this is good to adopt i think it's good to do and the reason i came into the queue just kind of answer to david's point about it being expensive um i don't think we need to see everyone do this like we just need enough greasing that the internet sees the new version going by right and um there are there are places where we could do it like we have different stacks like we don't have like the stack that youtube uses doesn't have to use this um right now you know we're using quick uh for a ton of traffic with our private relay stuff on apple devices we could you know like we don't care about sni there we don't care about any of this stuff we can just like yeah if it breaks middle boxes let's figure that out let's find it out and there are places that could deploy this first that are safer than changing google's main stack so we can volunteer to do that thank you uh give it back to the chairs thanks everyone well thank you um thank you for the discussion i think uh we'll go away based on that feedback probably send an adoption call to the list um so encourage people to look out for that and provide further feedback there um that gives us some time for our as time"
  },
  {
    "startTime": "01:52:01",
    "text": "permits bucket um we'd like to go with the first of those items which is ian to talk about accuracy timestamps or is connor presenting i mean it's going to be conor m um feel free to ask questions of me as well but um he's kind of the expert on this in a lot of ways let me share the slides here yep europe take it away awesome uh so my name is connor i uh formerly worked at google developing congestion control algorithms for real-time interactive streaming applications such as cloud gaming in the form of google stadia and presenting this work in collaboration with ian and we're proposing a quick extension for reporting fine grain packet receive timestamp information meaning the receiver of the packets tells the sender when exactly each packet was received and is all with the overall goal to offer richer signals to congestion control algorithms built on top of quick for some brief context received timestamps were supported in the original g-quick implementation initially to serve webrtc's goog cc algorithm which requires it and so here we're wanting to kind of evolve and standardize that concept and also for awareness there's another timestamp related draft worth looking at which has a kind of similar purpose but achieves it by slightly different means and at a little bit different granularity there's quite a bit of existing work on using received timestamps to improve the precision of a network measurement and the foundational intuition behind these methods is to measure when packet ingresses and egresses the downstream network path model is a queue and then by observing the variation in that one-way q-reversal delay you can better estimate various properties of the underlying network"
  },
  {
    "startTime": "01:54:01",
    "text": "state and notably this doesn't require clock synchronization between the client and server because the q traversal time variation is measured always relative to other q traversal times probably the most widely deployed application of this concept is in webrtc congestion control which observes differences between packet inter-departure and packet inter arrival times at a frame level to estimate some state about the underlying queue and respond to congestion and there's also research like path chirp and associated methods like packet pair and packet train which similarly observe these send and receive time stamps for multiple temporally coherent packets to estimate at that network queue state and my team at google also recently submitted a paper which we hope to get accepted and published and share with you all detailing how we use receive timestamps for these kind of latency critical real-time media applications in in production so let me skip ahead at a high level we're suggesting a new accuracy timestamp frame type to be sent in the same manner as a normal act frame in the place of a normal act frame and it has all the uh fields of the normal arc frame but also includes additional fields to encode uh receive timestamp information in a efficient variant based format which we'd love we'd love feedback on we've defined two transport parameters to negotiate the the use of this frame the first specifies the maximum number of receipts stamps the end point would like to have reported back to it and so zero here means i don't want to receive these packet receipt timestamp reports"
  },
  {
    "startTime": "01:56:01",
    "text": "and the second parameter is the exponent precision to use when encoding the timestamp deltas much like octal exponent currently does where you can achieve better efficiency at some precision cost so that's the the super short version and maybe i'll hand it over to ian then at this point to talk about next steps yeah i mean i i i look at that design and it's it's kind of a logical design if you want to do fine grain reporting that you have to include that in a knack format now uh the um the reason the current extension doesn't do that because my puzzle doesn't do that is because i got the feedback in the working group at the time that we wanted extension to be composable that is that we wanted the extension to be outside of the arc format for example so that you people that use the arc format can go on using it but if the extension is present they can compose the extension with the arc format and and that's that's one of the subtle difference that you mentioned and whether it should be basically let's change the arc frame to have an ac plus timestamp frame or whether we should have a timestamp extension and parallel to the arc extension the arc frame that was really the big design question yeah thanks for bringing that up christian um so we kind of talked about this a long time ago there are definite advantages to"
  },
  {
    "startTime": "01:58:00",
    "text": "including it in the frame which is to say that the congestion controller gets to consume all the acknowledgement information simultaneously which kind of just makes it easier to write a congestion controller um but but you're right that there may be use cases for which this is less suitable because it is not composable um and so it might depend on the use case i don't know for example an example of composition is using these as part of the past challenges [Music] yeah and you could also use this i would think to get the same information but i guess but you would have to add yeah it will be quite it's not quite the same because i mean you are not supposed to act you are you are supposed to acknowledge the past challenges etc i mean it's i'll have to uh about that thanks uh would you want to go because we have one man um thank you um i wanted to ask about the just a clarification question so if there's an ack timestamp frame is it going to follow the same frequency as the act frequency frame or probably less than that and when there's you know compressed axe when you are acting maybe once per rtt that probably won't work for real-time transport so um yeah just something to consider i guess um yeah right yeah so clearly the the real-time congestion controller would have to decide what frequency of acknowledgement it needed if you used active frequency um and so i assume that it would want to use a value that's you know more canonically typical like a quarter of an"
  },
  {
    "startTime": "02:00:00",
    "text": "rtt half an rtt or less um but yes and and um i don't know i i guess i i feel like this is a tool that a congestion controller can use to get more information but um it's you know without each congestion driller probably needs to decide like exactly how much information it really needs and when so totally valid point no okay and is the timestamp the only thing that is useful for the real-time condition controller or are there something like rtcp what packet loss and other uh signals are used but they're i think they're not used for bandwidth estimation per se um conor might have more like information but um i think probably probably that's a um this was sent out to the list would you mind posting there since we have zero minutes left okay i think maybe connor can give you a longer answer okay thank you yeah thanks john you're zero man um thanks so uh two quick points first i would strongly argue for composing the reason being that the number of times that you want to repeat this information is different for an acknowledgement versus for a time stamp so a timestamp is advisory typically and you just need to send it once even if the peer does not receive it it's fine but with an acknowledgement information you may want to keep repeating the information so there's a lot of repetition that happens there which you can avoid entirely when you're doing time stamps um so having a separate frame that conveys that information would allow you to do that whereas it'll be tricky if you're trying to put that into the back frame itself second um the the reason that arc ranges exist in the act frame is because we can express a list of acts as a range it doesn't make sense to me to express a timestamp range uh i'm not quite sure what that means and what that really is so i would i would have expected to see a timestamp per packet that is being"
  },
  {
    "startTime": "02:02:01",
    "text": "acknowledged because that is really what wants to receive yeah that's what the format actually does um it's just that the range is used because um typically packets aren't received in order and there are not a huge number of gaps and the range it allows you to express uh ranges of timestamps more efficiently but what is the range what what is the range of timestamp though that's what i'm asking what does the timestamp range look like uh and this is going into the details but basically it's like you get timestamps for the next seven packets and um instead of folks we're like yeah we should go we should get along but yes yep we'll do it it's a framing thing not a not uh haven't distracted what the data is and what the framing is separately that's right yeah so so thanks for your time um we need to wrap this up now let's keep it short and sweet uh i'd like to thank everyone for this meeting and behaving well um thank you to our scribe and uh watson and our notetakers jonathan and robin um nico apologies we can get to you as time permits um we'll follow that up on that off off list um we have some chair actions we need to take we'll speak to the ads and various people in back channel so keep your eyes on the mailing list that's all i have i don't know if you want to add anything matt okay until until next time same time different place maybe different time goodbye"
  }
]
