[
  {
    "startTime": "00:00:04",
    "text": "Place. Starting about a minute. You wanna do this? Intro that getting things here. Alright. We'll wait for sure to get situated there. Alright. Well, let's get started. Welcome to the Friday sessions. At the IETF. Thank you for sticking it around. This is the MLS working group. We got 2 hours scheduled, usual, we pull together the agenda at the last second. So Hopefully, you're furiously downloading slides to read again, it's Friday. So, hopefully, you've seen this before. This is the note well. For IPR related things, it's kind of, if you know, something, say something, there's a bunch of other things that are listed up there, but any harassment, code of conduct, etcetera. Read it. Know it. Noted it well. Any questions you can ask the chairs or an area director? Note that really well. This is basically, you know, cheat each other with respect. And that's what we're hoping for. You don't have to like anybody have to love everybody's ideas, but you need to treat them with respect. Meeting tips. Please make sure to log in using the on-site tool or the fall. Tool to make sure that we get an appropriately sized room Friday, this seems to be about the right size room. So that's good. Colin is jumping in the queue. No. He's not. Okay. Good. And, So we're also gonna use this to make sure that we can moderate the cube with, remote dispense because we have a lot of people that are, in our in Toronto for real world crypto, and something that we'll be going shortly. Alright. Cool. Resources for Brisbane. Hopefully, you've seen this."
  },
  {
    "startTime": "00:02:04",
    "text": "This is our agenda. I put this in here so I can remember to ask for a notetaker, I do not need blow by blow minutes. Oh, awesome. Keep Alright. Cool. So blue sheets we gotta scribe, agenda review. This is where we're gonna bash it. So We have a couple of active working group drafts, big thing we have to get through, we have one remaining item left in the MS architecture draft. That we kind of need to decide today and then move on and then, our AD can hit the IETF last call button, and we can get it out the door. We'll discuss that. There's kind of 2 options. Then we got a couple of drafts. I'm not sure if we'll get updates on a a sentence or federation, but I've listed them there anyways. And then we have a bunch of individual drafts or ideas. To Hale's gonna talk about, post quantum, hybrid design trade offs, Richard's gonna do a little little a reminder about MLS credentials, which we've already talked about. And basically had agreement to, adopt as soon as we get our charter done. And I guess say that the charter getting done is kind of I should conditional on us getting the, architecture document done because that was the deal we made with the ISG was that we would get our 1st set of deliver before we moved on, it did a bunch of extension work, but that's life. Then with some Mimi related drafts, it's the first protocol that's gonna kind of adopt MLOS and run with So we got a couple there. We have some additional ones for know, how to make it lighter because that's what we do. And then some additional things from, Conrad about, virtual clients and paradigm loss. So we should have the time to get to all of these. So, I'm gonna jump back. Is there anybody that wants to bash us? Is there anything that's missing know that Rowan, you sent some slides about additional, extensions, but I think we can just kind of climb them all together and talk about them because pretty good about one slide, one thing, like moving on. So Alright. So on to the interesting stuff. Which is this MLS Architecture"
  },
  {
    "startTime": "00:04:00",
    "text": "question. So on the list, we sent a message out about, how we're gonna fix this problem. So we have a recommendation, for doing a cryptocropicgroupoperations. The interesting thing is the first protocol at the gate. That's gonna use MLS is not gonna follow the recommendation. So there's really 2 ways we can fix this. There's 2 ways we can fix this. 1, which is to change the recommendation. To provide more context around it, etcetera. This is something that we talked about at the interim. And the other thing is to provide some additional words and then remove the recommendation. I would like to say that I think this is not a hill in which anyone should be trying to die. But this is the last remaining issue, and I'm curious if there anybody that wants to add anything new to the discussion that's happened on the mailing list. Yeah. Sure. I wanna accept my own request for scared slides. And the last is it this? Nope. It's not that. I'm gonna allow it. Actually gonna try to show you the text. Of course, I Hit the wrong one. What is this? Explain the impact. Alright. Cool. Share screen. Except So I'm using this one primarily just because it's got all the text. There. So the text is on the left, and the recommendation is this thing that we prefer using encrypted group operation message deployed to privacy issues related to non encrypted signatures. And one suggestion is to remove the recommendation and provide a whole lot more text about it. Hopefully, you've had a chance to review these already. I really want read them didn't now. you to And the other one is to Keep the recommendation and provide some additional flavors around it, like other things you can do for mitigations. So I guess the question is, the mailing list, there seems to be slanting slightly one way. Is there anybody that wants to the microphone to you."
  },
  {
    "startTime": "00:06:00",
    "text": "Anything additional because otherwise, we're just gonna make the call and move on. I don't know. Is there anything in the chat room? Chat. I haven't seen anything. Sleepingeping. Hi. Hi, Diedra. So I think what we're gonna do is we're the the it's it this is extremely rough consensus This is kind of how it works in the IETF. I think we're gonna end up doing is landing 246 And closing the other one out and calling it a day. And so call. This hopefully will be in your lap shortly. Sorry? No. I I mean, like, I I don't know what Ecker's workload is like today, so, well, may do he it we don't, you don't need to hit the button before, Zach. And, by the way, I appreciate you dealing with all those a lot. I've been firing see. Alright. Cool. So we'll get get that issue closed, and now we can move on to the exciting stuff. And me stopping sharing my screen. So Britta. Oh, Ecker? To confirm, I'm gonna push the button right now. Or you're gonna press the mortgage button. Can you do the merge and then spend a new version? And then when Paul do it. He can do an ISF. So Paul said he it before, SAG. Is that what he said? wants No. He said he wants it after he wants it after sag. Okay. I I I can do that. Alright. I really appreciate it. Thanks, man. Alright. Cool. So, Britta, You are up. Do you wanna run the slides, or do you want me to? You can go ahead if you've got them. Alright. Cool. Post quantum and MLS. Here we go. Alright. Cool. Just say next want me to. when you Just good. Well, hello, everyone. We, the group of us, Joel, myself, Marta, and Susan have been taking a close look at post quantum MLS, particularly hybrid, post quantum MLS And what these trade offs are and how they can be optimized. So today, what we really wanna do is discussion on"
  },
  {
    "startTime": "00:08:04",
    "text": "where people would be most likely to lean in terms of implementation in regards to show a few options, and approach So, next slide. So approach number 1, this is, Rowan's current draft, dealing with basically a hybrid Kim. And it is great that we are taking us on, crossing Just as a first blanket statement, it is good to be moving on post quantum now versus waiting for, like, the optimal solution. But there are trade offs and we're looking at trade offs here. So, This hybrid chem approach is basically that you're having classic and a post quantum Kim Syversweet. And when you update, you are doing an update to both. Alright. So there is an efficiency cost that comes with us. And the question is, always willing to pay that or, of course, in some implementations, it could actually discourage doing up states, if it is too costly. So how could you potentially ensure that you're getting post security in your implementation, even if you don't want to charge that post quantum update all the time but you do need to rush to dig forward. So we're in this discussion, we're particularly in leave authenticity out of scope for the moment, of course, in this approach it is alscope, period, and it's focused on camps. So that's roughly approach number 1. Now press number 2. So next slide. So the second approach that we are looking at is what I'll call session combiners. Essentially, you can do this as you have 2, parallel in less groups, completely distinct. You have your traditional one quantum 1, and you post"
  },
  {
    "startTime": "00:10:01",
    "text": "and you are going to combine them by using orders. And we just discussed this in the interim a few trade off points. But we're we've delved into that more and hence this discussion today. This could, of course, not be a perfect match on the sets of participants, you could have the post Quantum group to be a superset So for example, maybe you have a post quantum group with all members of your organ nation of in it that rolls every once in a while. And you are going to use exporters from that as injects into all of the participant groups throughout the organization and all of these smaller traditional, groups, traditional and Velas groups. And so you actually are able to get some post content security in these traditional groups. Or you could alternatively match participants 1 to 1. So there are again some pros and cons. The a nice pro to this is that you can combine any 2 kimps. So we don't have to be locked into one Cypress suite now or if that Cypress suite changes that you only have you know, have standardized a whole new cyber suite. So you can combine any you, whatever your post quantum is, and whatever your standard is. It's also very efficient in the that you can do lots of classic only commits and updates. Without incurring a cost on your post quantum. So think about this in terms of, like, what signals doing now. Of course, signals doing a hybrid post quantum approach, but they only do that in the initial handshake. So if we don't do any of the ratchets, with post quantum, hybrid post quantum. So you're only getting that property has been very start of your session and nothing else after, And of course in approach number 1, you're getting that post quantum ratchet at every single ratchet. This is sort of landing more in between where your responder ratchet can be dialed like a turn dial to s frequently as you can manage or dial back if you can't handle that"
  },
  {
    "startTime": "00:12:01",
    "text": "overhead, but you can keep your standard ratchets going no matter what. Is also very nice as a pro that is modular we don't need to change it if we've gotten less, or Current designs they're in, It is really a matter of the delivery service getting pieces in play. Now the cons, and I see ruined at the buckle. On to the end of approach 2. And there is approach 3 if you wanna hold your thoughts until then. Through in that 3 of them to look at. But so the cons here are that your DS has to handle management of all this. Right. You've got potentially 2, or you might have a larger supergroup post quantum, and you need to be able to figure out what to export, when and as well as managing commits and stuff in between. Whether or not these needs to be synchronized and so forth. So there's a few decision points we're not kind of delving into all the decision points here. But there are the cons in terms of the DS. Ron, do you wanna take your question now or wait till after our first number Yeah. Hi, Rowan, Rowan made. So this is a clarifying question. So This would provide protection against harvest now decrypted for, even if the even if the The Post Quantum Group is has people in it that are not in the main group and vice versa. Right? It would still provide that that protection Right. So that depends. You know, if you wanna do a very, very strict version of HypersNow decrypted, you will to set participants. That doesn't mean matching ratchet frequency, but you just match the set of participants. If you're talking Organizational internal, and you assume that no one in your organization has a quantum computer they want to hack their, you know, neighbors group with then you could do the superset and still have that hourly."
  },
  {
    "startTime": "00:14:03",
    "text": "Okay. So in other words, if the attacker isn't in the group, then you're then you're safe from harvest 90 criblider. Yeah. The as long as your attacker is outside the Post Quantum group, your heart is safe. Okay. Thanks. And, of course, you can match participants one to one, if you want to just be outside of the group in question. Richard, do you wanna take that question now? Or wait till after 1st, number 3. No. Wait. He said, wait. Tark Go ahead. Wait. Okay. Then let's go to approach number 3. So, first number 3 really flips this on its head. It is instead of putting the weight on the DS. We're going to try to leave the DS mostly alone. And be more invested on nimbles. So approach number 3, you're essentially looking at 2 Kims, keys per note. And you get very similar properties in some ways with the, approach number 2 and the fact that you can combine any few kims. They don't have to be, set cycle suite. You can also do classic only ratchets, without having to do the post quantum ratchet, if you need to reduce the frequency of post quantum And there's a little bit of a bonus in terms of you only need to deal with 1 in session. There isn't a second session. So you in this case, you are absolutely matching participants one to one. Between the two groups, if you think of it that way. The cons, of course, are with that we get invasive with MLS. In terms of we actually have to make some change to what's the protocol, currently is us. Of course, we have to handle 2 Kim keys. Being able to know when one updates, when one of this culprit update versus 2 and so forth. So there's a few trade offs among these 3 approaches. And what we're really looking for from the group is where"
  },
  {
    "startTime": "00:16:02",
    "text": "is everyone's leading most towards. And again, I'm not addressing authenticity here yet. Harrison. I'll wait till the next slide. I'm going to take a quick pause for some discussion. But what sort of direction is going to be most useful in practice for the different implementers here. And what are the trade offs you're thinking? Richard looks like he's up first. So you still wanna Yeah. Yeah. I'll I'll I'll jump in now. So thank thanks for, this presentation, Brenda. Just for what it's worth, I went ahead and implemented, Cypress suite based on the X wing combiner, with mlchem and 25519 in in MOSVP and ran some experiments. Turns out that, like, it doesn't actually seem that expensive. In operations, in a in a realistic scenario where we had certificate chains, the ratchet trees and key packages only ended up like 60% bigger. Certificates are already so gigantic that the ammo, giant ammo, Kim keys are just more weight. And the processing times were like, I don't know, low double digit for percentage points, slower. So it's not a huge impact. The the main thing was that, remove commits got a lot bigger because of all the because there, you don't have key packages. You don't have certificates. So you so the you feel the the impact of the bigger public. He's a lot more. And the bigger ciphertext. So so You know, in in my mind, it might not be super urgent to to do a lot of this optimization, but it's useful to have these, is in mind. Among these approaches, I think approach 3 probably, appeals more to me. And I think We might be able to do this even within a single Cypher suite. You could put potentially have a single Cypher suite with 2 ciphertext formats where the sender could choose whether they're gonna send a, pqplusnormalplusclassicalcip, ciphertext or just a classical site for text, and then the receiver could handle them appropriately signal that in protocol."
  },
  {
    "startTime": "00:18:02",
    "text": "So I think we could do this actually pretty smoothly. To great feedback. Yeah. In terms of efficiency that really is probably put back to more when you're in those sorts of, use case environments where you really are counting bandwidth. That that that probably we are anticipating when get to the next slide is the I so we hit authenticity that is going to pop up. It's useful feedback about a person number 3 though. And we can discuss whether or not that flexibility with the 2 cams, maybe you won't pop up later again, but flexibility with that 2 cams, then if that's not so much of a bonus that's worth keeping versus having a single Cyprus suite. Yeah. My 2nd. Yeah. So I was gonna ask from the floor, but I'm lazy. So, I'm prepared at the front. Just the impact on size. If you're running 1, it's big. If you're running 2, Interesting. I'm just just curious to see what the actual data was. So thanks Richard for running that stuff. Run. Yeah. Hi. Rowan again. So when I was at wire, we implemented the We implemented the that that Kyber x5x25519 combined soforsweet and had basically, this was faster than our implementation of P56. So, in terms of speed, it wasn't a big deal. And likewise, buyer just to produced end to end identity certificates. So a similar you know, things got marginally larger compared to adding certificates. So Yeah. Like approach 1, I think we should we should absolutely do approach 1. And then the question for me is what else should we also do And It seems that for approach 2, if you wanna do approach 2, The only thing that you actually need from the MLS working group to do approach 2 is to register an an ML camera Kim."
  },
  {
    "startTime": "00:20:04",
    "text": "Cipher suite without, no, a non hybrid cyber suite. And that you could even use a combined Cypher suite because X25519 is so fast. You wouldn't even necessarily need to do it, you could just go and have the cipher suite from from approach 1, one group. And the MLS spec already lets you go and and do this. And it would just be like additional guidance saying, the security considerations were and when you should, when you should export the key and import the key at various times. I was also curious though, I know Joelle had expressed some had some, ideas that were sort of riffing off of approach 3. That would allow reuse of some of the parameters across across groups, I don't know if you wanted to comment on that, or if that's something we just kind of leave for future work. Do you wanna comment on that? Alright. So largely, I would I I think I agree with Ritter's comments. Namely like, obviously we should do one because there's essentially no work. In fact, so I don't think that having I don't think that having rigidity about the Cypress is a bug. I think it's a feature I don't wanna have a comic organization of Cyprus. So, I think it'd be I think that I'm having them be glued together as a feature on the button. 2, like, 2 scares me. Yeah. This seems like very hard, the reason about and hard to manage. I Richard's point about 3 being effectively like you know, effectively isomorphic to, isomorphic to to 1 And and, like,"
  },
  {
    "startTime": "00:22:00",
    "text": "is right. I mean, you, one could imagine back doing a new set for suite. That literally was just a hybrid and only had, like, and and and either an always active human key and sometimes it had an empty ml cam key. And again, that could be like more or less hidden from the implementation otherwise. So I think it really can be just contained inside for suite if we wanted to do it. But I would suggest the right thing to do is to simply do simply define, like, actually find the the same the same set of, like, you know, pairs everyone else is doing, as in to say for sweet and then see, like, how that goes. So So then the the question with 3 might might do. There's a note on here that 2. The 2 and 3 are under this long term plan thing that'll come in get back to the authenticity. But as people could use the injection queue. Are there any reasons why you'd want to do classic only upkeep in this hybrid construct versus doing it always as a paired uh-uh classic and post quantum. As far as I know, the only reason is it's, like, is is a is a small bandwidth Right? Is Well, yes, naturally. So Are there reasons like do you have use cases where you would use that? I don't. 2, this is Daniel Con Gilmore. Thank you for presenting this, range of stuff. Brita, and thank you, Richard, for actually running some tests. Great to have the data. I said this in the chat, but approach 1 seems like the obvious thing to do to me as well. I I really I think the kinds of complexity that we layer in with number 2 like, a whole other protocol on top of MOS, and I don't think we should be doing You got enough to worry about with MLS itself? And as far as this idea with approach 3 that you can sometimes use a classical only combination Whether it's precise or for computation or whatever, I can't imagine"
  },
  {
    "startTime": "00:24:01",
    "text": "certainly can't imagine asking the end users when they would want to choose those things. Just seems like a use user interface disaster. And I don't really see how you would set a simple policy for doing that. So, and it it just seems like it's a lot more mechanics to to worry about. And I I I strongly think that SIM. Simplify, simplify, and approach one seems simple. Not too expensive. Let's keep it that way. You for presenting all the stuff. Okay. So we have this rough overview that we're kinda liking and approach for 1, and we like a simplicity. Now I'm going to throw a curve ball into this mix, and then we'll go back to the left after I present the curve ball. So what about authenticity? So under approach 1, again, move tie these updates together. And the that sense, if we're planning for the future, eventually we need to be planning for opportunity. There is a natural first question that pre no. Is a prelude to all of this, which is how much do you care about authenticity? I imagine among the working group, there'll be a whole span. There'll be people who say, Hey. I'm going to do classic authenticity forever and ever. There'll be people who are going to look at post quantum authenticity, but really at the last possible moment that they they can get away with for their implementation. There will be people who say I want a world of post quantum authenticity now, but I really don't care enough about hybrid to be bothered in that case, you probably aren't using a hybrid can either. Right? And then there's the all the way down the spectrum to the Actually, we want both, hybrid or authenticity, whether that's in transition or eventually. And just like we're doing a hybrid Kim, approach in, like, approach number 1 we will probably whether that is now or you're thinking in 2 years from now when you know, standards are nicely cleaned up that you would be looking at having a hybrid"
  },
  {
    "startTime": "00:26:01",
    "text": "signature of some variety, whether that's 2 signatures or combined. And I'm going to the question of what a hybrid signature might look like, and just say in right now, I'm talking about you. So that's a spectrum between classic all way to through post quantum to pure combined. So, first that's the first thing on the list. 2nd is then all of these approaches change up a little bit once we put in the options. So assuming that you want to do at least post quantum signature, If not, hybrid signature, Now under option, our approach 1, you are going to always be using taking on the cost of those, hybrid signatures. Under approach 2, Now you can decouple them a little bit, and say I'm going to do classic signatures, most part, until I need those, respond to at the time I need them. And those signatures would be very separate the post quantum chain only has post quantum 6 and so forth. Under approach 3, you can do a variety of things you can still do 2 signatures, 2 different signatures. And updates separately. You could also do a hybrid signature so that you're Standard 1 is always taking a high, like, combine hybrid approach, which might defeat the purpose of going to approach number 3 and approach number 1, But at the very least, you could kind of decouple that a little bit. So then kind of probably going back to Richard's question earlier. I don't know if you tested with hybrids or post quantum sys in this implementation, but if we're going down this pathway, is that ever going to become a problem? Are we going to circle back to this in a few years time and say, Actually, we need to do something about post quantum 6 now. And we should probably have that our hybrid approach in did, you know, we wish we've planned for that earlier."
  },
  {
    "startTime": "00:28:01",
    "text": "What is our scope here. Where'd you first of all, where'd you land on the spectrum? And then Oh, Now we're flooding on the authenticity piece which approach is going to become more under that. desirable Browing me again. So Britta, do you think that the There's a difference between how important it is to to use post quantum signatures for your identity for your identity signature versus your ephemeral signature. For me, it seems this makes a this is a fairly big difference. So I think there's probably a time to iteration to that as far as how critical it is in time wise. Obviously, we talk a lot about harvest down decryptedator sort of things. And identity polymers less frequently. But then if we're talking far enough down the line, then maybe the difference becomes less. So that's that's that's we are talking here about big picture, you know, planning for the future. What would you be interested in. So back to you. Just that that hops here back to you. Yeah. I I I would say, like, you know, if I've got a key package that's valid for 3 months, that protecting the, you know, having a post quantum signature that covers part of the key package that that's more important to me than than signatures inside of the endless group where presumably I can, you know, once a week or once a day, I can, or once an hour, I can update my updo my keys and That I you know,"
  },
  {
    "startTime": "00:30:03",
    "text": "I would need a pretty a pretty fast adversary in order to to be doing quantum operations and you know, cracking my traditional keys in that time frame. So in terms of the questions I asked on where in the spectrum you fall and what approach you're looking at Did you run around this? Before I let you go from the mic, I guess the middle one eventually Okay. So I I feel like maybe we need to, like, be able to clear up a threat model here. Like, if there's a viable or could draft the relevant concomputers then Like, like, these push ones and just have everything. All the time. Right? Does everybody agree with that? Yeah. I think you Sorry. I said If there's a viable file on computer that can actually make a actually, like, is is, like, people attack our classical algorithms that all centers, centers of osteoporose quantum, right, So this is that goes for both the Kim and the church, I'm not going into the debate of, like, where on the spectrum of you know, development and post quantum, we were at or where when we're expected to have that, or the trade offs as far as what we probably won't have an absolute attack, but we can have sufficient partial attempt to exploit these, the fact that we're going for a hybrid kim already means obviously the group is concerned that there's a some leeway time that we need to be communist and tough. So in the frame of mind that we are already kicking on that leeway time that we're cognizant of, Now what about signatures? Well, as I was saying, there's,"
  },
  {
    "startTime": "00:32:03",
    "text": "that the the The the lead time for Yeah. Kim is because of harvest now to crypto later. Attacks, attacks, from our It's not primarily about, like, deployment timeline. So The I guess what I'm getting at is if in the, is there are 2 reasons why will my get ahead of the curve? Now on the signatures. One is if you think that as with the chem, that that things that are signed today will actually be an issue if there's a post quantum these are verified today now. Sign today now, We'll have an we'll we'll be risk security relevant in the future, and therefore, we're at this interbeing broken layer. And the other is to get a is is to get deployment ahead ahead of the car. And I guess what I'm saying is that in the Long term future, if we actually have a cryptographic goal on on a computer, the answer will have to be the everything we always want them and know and you won't be able to do hybrids all the time and postpone the rest of the time. You have to do it for all time. Right? And so the the the question is, were you getting by trying to do class all some of the time, post qualms all the time. And so that I think that's supposed to be asked to be being protected. And the and it seems like the assets to protect the assets to the last the 2 assets that are relevant of are 1 The key packages and things like that and the authentication for the group joining, And the second is the message is is is a message themselves. They they be able to create ambiguity about sensors and the messages. Right? But The second one is, like, a short term consideration. I want to they're sorry. The the the credentials or short term consideration, namely that that is that doesn't that having having this issue on my key package valid a year from now is not particularly useful. And the but they, but they cost me only a small fraction of the signatures of the signatures that are the security bound And so I don't understand how we're gonna get any benefit at all if we have folks running an interview by not signing the messages. Mhmm."
  },
  {
    "startTime": "00:34:00",
    "text": "So I think a lot And sorry. Go ahead. So one thing that should be considering here. Is the this case of New algorithms, your new post quantum, algorithms in that whole, hey, are they good enough? What surprises are in store? Now you already mentioned there's a post quantum or quantum adversary, we can assume that you can pretty much disbursed your classic side, right? But that doesn't solve the problem of do we fully trust the post quantum side yet. And this is that sort of niche area that everyone always discusses in, when it comes to signatures, but that does take us into that eventual threat model down the road that we're looking at. So suppose there is a situation that we now have a quantum computer and suppose that quantum computer is in an adversary's hands like a state adversary. So not in your average hacker's hands, on your average out of a serious hands, but there are adversaries around the world that may possess it. Now how do you protect against this? If we just say, okay, That means that our classic is Gong, we might as well strip and go straight to post quantum. You all your bets are naturally in that post quantum basket as terms of that state adversary. What about all the other adversaries that are in question. For those who may very well still be relying, in some degree, on the classic side because if that Post quantum wasn't as reliable as you would have liked, maybe you're you've lost as far as the state adversary goes, but you haven't yet lost as far as all the other serve. So, obviously, there's refinements to this, and you should implementations, your your Each implementation is going for a different adversarial case and a different concern. I think really what we're getting here towards here is In that, say, few years from now, where are those concerns gonna be?"
  },
  {
    "startTime": "00:36:04",
    "text": "Will any one of these approaches still be more attractive than the other? Like, is would you wanna push down and stick with it indefinitely? Or should we kind of have, a couple purchase, What is that gonna be? So Over to you. Yeah. I mean, I guess what I'm trying to get at is, what's expensive here is the post quantum not the classical hour from. We could afford of the classical hour of an perpetuity and it would make no meaningful difference. Given the curse of the post quantum algorithms, it made no meaningful difference in the of like how expensive everything is. So the question is under what circumstances do you use the post chronic problem? Whether it's in hybrid mode or a standalone mode. The expensive part. And so I guess what I'm getting at is, that the the versions of this where you're like, we're only gonna use the postcard of some of the time. oh, I don't think make any sense. Because the sum of the time, the thing that's off the the thing that optimizes it is not signing the messages. That's the only thing that's worth that's worth having long term security for. And so, and so I just don't understand, like, how we get to some of the So I'm trying to get out. Okay. And Next we'll do. Tyrgyzha. 4 simplicity's sake having PQ only Cypress suites for signatures might be nice to write down. This. For, The ones that want to agree on them for their for their groups, Just that was a thought. Also, are there any concerns with credentials being hard to rotate, between hybrid and then eventually PQ only cipher Suites. Okay. Own This is Richard. I, to do this question, I don't think that there's"
  },
  {
    "startTime": "00:38:00",
    "text": "any any Not obviously, there'll be much difference in credential rotation. Based on cipher suite. Actually, the reason I enqueued was to say that, like, The signature algorithms are not the only problem here. The question is also, like, what do the credentials look like? And that's a lot of why I think this is a problem for, like, I ETF 130 or so. Because there's there's a lot of, like, it's it is seeming increasingly unlikely that we're like, do X 509 with some different parameters and have, like, giant s you know, SLHDSA certificates. And just pass those around. The things like Merkel Tree people are actually doing some interesting innovation, what credentials could look like with these Merkel tree search stuff and whatnot. So, like, I I think the credentials are actually gonna pretty diff you know, there's a fair chance this credential look pretty different, when we actually get the PQ authenticity algorithms in. Now that said, the, authenticity algorithms are used internally to MLS is not necessarily coupled to the credentials. All the credential needs to do is talk about that key. Alright. So you could have an ECDH certificate whose subject public key is an slhtsa. Public key. Right. Right. Then you use the SLHDSA or or, MLDSA key in inside of MLS. That that's a little more plausible to me if folks wanted to go ahead and and start using that internally to MLS, but I I wouldn't worry a ton about the credentialing schemes, at the moment because I think there's There's a bunch of uncertainty there, what the credentialing ecosystems are gonna look in in in in the near future. Alright. Cool. If you train the queue, I think the discussions will continue Thank you, Brita. Alright. Certainly. And if anyone would like to weigh in on the list with this, Obviously, there's some trade offs that people will think about a little bit longer. And maybe there's something come back to you later, but"
  },
  {
    "startTime": "00:40:01",
    "text": "basically, that was our authenticity plan. And So far, it sounds like definitely no. We like approach 1, is that something that we should be statically holding to? Alright. Thank you very much, Sean. Alright. I think we're now going on to additional credentials. So that was a very nice segue. I don't know if we even plan that. Excellent segue. Thank you, Sean. So this is like an one slide presentation. You can go to the next one slide. So we talked about this, in San Francisco, 2 IATS ago. You know, there's desire there's a bunch of interesting work going on around verifiable credentials to make credentials for users, easier to issue off of things like open ID providers. So that was the the the genesis of this draft. And then it seemed like it might be useful be able to present multiple credentials, like one of these verifiable credentials. That proves your, you know, your SSO login identity as well as your identity within you know, the particular app you're using, certificate chain. So There's also a schema here for multi credentials. It has nice interactions. We were discussing in the chat now. You can use that to indirect things and have a little bit of signature flexibility. So, yeah, this that's what's in the draft. We had an adoption call after our ETF117, which indicated positivity. And I assume we'll just, I think you're gonna do you have a recall after the reach orders finished? And Yeah. I'll appropriately word it. So you you have to really object. But, yeah, I mean, because we basically already did it. So, it's it's essentially yeah, my mind adopted already, but, you know, we should go through the process. Like, we're supposed to go through the process. So this is just a reminder presentation for everybody. There's no change to the draft since last summer. So, yeah, There you go. I'm happy to take comment comments or questions if anyone has them, there's nothing new here. Alright. Oh, Rowan. I think you're, Roan, you're up next Make sure I get the right slides."
  },
  {
    "startTime": "00:42:03",
    "text": "Additional credentials, like, clients, virtual. Is it the is it all of it and the more MLS extensions? Alright. Cool. Next line, please. Okay. So I thought that Richard was gonna go before me with talking about extensions for me. To but but but but basically, There is a set of stuff that we described in in the meeting, we can work in group as possible MLS extensions for sharing room, room policy and participation lists among other things. And Richard has presentation to talk about this. In addition to In in addition to that, There was also 3 other areas. Where it looks like Mimi might want to have some additional Otherwise, generic functionality in MLS. So I already discussed briefly the key package context, the premise ATF. I also, A couple of ATFs ago described this self remove proposal. The main reason for the self remove proposal was to handle on a generic problem in MLS, which is that pending proposals don't show up in external commits. Maybe we wanna solve that more generically. And then I also had, AM. A sort of a draft fragment for how to how to have other"
  },
  {
    "startTime": "00:44:02",
    "text": "Other ways of conveying the information about the ratchet tree or, group info. So next slide, please. Okay. So the The key package context draft So this would be an extension that says I you only wanna use this key package in a particular context. For example, in the context of a specific MLS group Only for someone who wants to add this key package with the following user identity, only if, It's used by someone who wants to add you who has a user identity in a through domain or only someone who has who wants to add you that has a particular public key. So those were Some contacts that could be used And Brendan asked on the list, why would you, you know, why wouldn't you just do this at the application layer? The reason is that If you are going to Generate your key packages and upload them to to a server, You don't You know, you you may not have real time communications between let's let's say you have 2 users that are on different different continents and different time zones. And someone says, hey, I'd I'd like to invite you to the group. Could you please give me to add you to the group. And then a few hours later, this person they're they're offline and the other person wakes up, and they say, yeah. I'll I'll give you consent. And by the way, here's a key package. But in case in case I go offline, I need to I need to put that somewhere. So that, in storing a context with that key package and having it signed"
  },
  {
    "startTime": "00:46:00",
    "text": "And bundled into the key package. That could provide some value. I think it makes it makes these kind of, These kind of Settle subtleties about how key packages get used more, more explicit and safer. Okay. So I was hoping we were gonna discuss the that general, you know, app state thing first, but This could be done just as us. This could be useful in the outside of the Mimi context and just be be used as a key package extension, a key package extension, It could also be incorporated into the concept of app state in that you could have you could extend this concept of app state and say, we want to be able to add application specific state in key packages. In general, And then we would just do that once, and then you would use the sort of application ID to say, I'm adding app specific information to my key package with this application ID and this application ID. Becker. Yeah. I I guess I'm not finding this motivation particularly persuasive. I have to say, like, this seems like exactly kind of thing you want the application to do, and the application is I don't understand why you couldn't why you couldn't do exactly the same thing, but, like, but with, like, assigned out with the application layer. Okay. Let me ask you a test question. So if I have if I have a Mimi, application, So I have an application that is connected to a provider that that speaks me Yes."
  },
  {
    "startTime": "00:48:01",
    "text": "What? Do we what do we say in Mimi to the provider to make sure that the client gets this information safely. Where we don't where Mimi isn't specifying the provider to client. Protocol. Maybe specify some protocol between providers or among providers. Yes. Okay. So the they only found out a messaging format. Well, we, we can, we, the, the things which are specified by Mimi that are tween that are end to end. Are the message format and a profile of MLS. So if it's not, in the list. And it's not something that was encrypted with so you put it No, no, but isn't Christopher is imperative on loss. Right? Hey. How are you how are you planning this in the first place? What's this? What's your what gotta understand what your your plan you wanna convey something from Alice to Bob, right? Yeah. So Bob wants Bob wants to say, I'm I'm gonna allow this key this key package to be used only for Alice. For example, or only for Alice's domain domain domain. So If if Bob isn't, you know, this is this happens before any end to end encryption between Bob and Alice, obviously. Because this is about getting the key package that's used to bootstrap the end to end communication. So Mimi doesn't really have a you know, doesn't have a place to go and and say,"
  },
  {
    "startTime": "00:50:02",
    "text": "Yes. Between the provider and the client, this is what is what Bob needs to do in their proprietary protocol to convey this. But but maybe you can say, Here's a key package extension If you use this, it has the semantics. And if you want to have the semantics, you use this use this key package extension. I feel like I'm really understanding that the that the problem statement, so maybe we should take this offline. Okay. But until I do, I'm not gonna be signing on properly. Call. So I I I think that I would be sad to see us true. So Mimi has lots of things that you trust the providers to do. Lots of authorizations and things. The one thing you don't trust them with is to read your messages. But you do trust them to help set up the communications and form all the relationships together. So I would hate to see us try and embed the whole Mimi protocol in side of extensions in MLS. I don't think we should do that. I think it's a very bad separation. And I'm not really following why this particular thing can't be done, be secured by effectively. There's a TLS connection between the two providers. Because it's not really between the endpoints. Right? It doesn't have to be secured at the endpoint levels. At the threat model I'm thinking about in Mimi. But maybe I'm wrong on this. Like, I'm not saying I deeply understand that, but I I did try and follow that. I guess I don't also understand what a domain ends up meaning in the MLS context. I mean, if we're doing it, you know, This says the context of a domain, but I don't know what a domain is here when we're talking about an MLS extension. I was referring to a DNS style domain. So But what what does that have to do with MLS? Like, what's a good one? What's a bad one? What do you do with it? Like, How does this work? Well, in this case, this would be If the if the user and me me doing the adding"
  },
  {
    "startTime": "00:52:00",
    "text": "So it's a particular domain. Right? That's why that's why I just So I think this saying that this extension assumes something that isn't agreed upon on in Mimi, which you are arguing for, but isn't agreed there yet either. Right? So I don't know. I'm not I'm not finding this hugely motivational yet. Okay. I mean, the, the concept of, of users being of users having a domain associated with their provider that is in the arch in the MLS architecture. Which we talked about already you know, 2 ITFs, 3 ITFs. In any case, I'm gonna get just say one more thing about this, which is that You know, it's fine for Bob to be able to go and negotiate with Bob's provider to to say, Hey, I only want to You know, I only want this key package to be used in this context. But Alice also needs to know when Alice gets a key package, whether this key package is going to be relevant. Whether Alice can use this key package. And so that is something that needs to be coordinated across vendors, across systems. And that's why I think we need to have some mechanism to do that. That isn't entirely within the you know, within the purview of the provider client to client to provider interface. Agree. I'm just not fully getting observation that that needs to be secured by MLS. That contacts can be part of the application contact rounds once again. Look, I don't know. I'm I'm just sort of suggesting we look at that that that's what's confusing to me about it. That's Okay. Yeah. I'm, you know, maybe I'm just not smarter to see a way to do that using the available key information that we have with the no. So we can take that offline. Brendan. Hi. So I think I do understand your argument about needing some plumbing between client a and claim. Be to be able to communicate But I would ask In terms of the abstractions that Mimi has,"
  },
  {
    "startTime": "00:54:00",
    "text": "I feel like that plumbing should be client a communicates to provider a, their restrictions in a provider specific way. Then me and me has some way to communicate the restrictions in a standardized way between provider and provider B. And then provider b communicates restrictions to client b. In a provider specific way. 666 Is that not how Mimi would be meant to work? The from provider a to provider b, I think that that would need to be in Mimi. Certainly. And Yeah. I I've yet to see an existence proof that I think, can do that in a safe way. For a key package, because the key package is how we get the bootstrapping of the you know, you know, of the of the key material that we need to do most end to end things. So, Right. And Like I said, maybe maybe there's some maybe there's some clever way of doing this that I or even not so clever way that I I missed, but We can we can take this offline and try to figure it Yeah. I mean, there's no security. I mean, if there is a security reason, to have these constraints signed in the key package so that they're bound and so that they can't be forged that would That would be a really good motivation to actually put this in the key package. But without that, it feels like it could be communicated just alongside in the provider specifically, like I said, So Okay. Next slide, please. Alright. So a couple of ITS ago, I produced this self remove, self remove proposal extension, The original reason is that user a user removing itself can't guarantee that this is gonna be an atomic operation. User could send a remove proposal and then an external commit could come in and require that user to be able to go and send that some arbitrary number of times. And in"
  },
  {
    "startTime": "00:56:01",
    "text": "in conferencing scenarios, we actually saw saw this in a real implementation where Sometimes it would take 3 or 4 commits before the Be before the person trying to remove themselves was actually removed. Basically, this is, you know, like, on the hour, a bunch of people leave and a bunch of people join. And It ended up in some pretty ugly client functionality, So the self remove was a proposal that said that the external committee is obliged to, to include this in external commits, However, If we generically if we made an extension, which said, okay, this is means that generically valid pending proposals, Need to be available at the DS. And they, an external committer needs to go and and include those in an external commit. This would be a more generic way of solving this problem. And it wouldn't require a, you know, adding a new proposal in order to do this. It would be sort of a one time thing, And In in the cases that Mimi is using and 1 other other cases where you have an external commit. External committer already has to go and fetch a group info. So fetching a list of pending proposals is on not really a big deal. It's something we could easily do. Next slide, please. So just a note here this would not be a safe extension under the under the extension framework. Does anyone want to"
  },
  {
    "startTime": "00:58:02",
    "text": "say anything about this. Does anyone have an opinion about this? I would tend to wanna go and solve this prom generically, If there is you know, pushback that we don't wanna solve this generically, then I won't bother, and I'll just go forward with the self remove proposal. Alright. Good. I figured we were gonna get Richard up at some point. Richard, I I never really liked self removed, so I kinda like doing it generically better. The only thing that really gives me a little pause here is that, you know, allowing If if you look at this only within the MLS envelope, and what logic the MLS client is gonna apply. This looks like allowing arbitrary proposals in external commits. Which which feel air I think in the context you're thinking of it, it makes sense because you have you know, some semitrusted authority managing the queue of proposals that are gonna end up there. I just wonder how are you appropriately cabinet so that We don't open up. Arbitrary arbitrary arbitrary changes in in external commits. Although, I mean, maybe we can get comfortable with that. Even even I mean, I I think that there's a way to, in the same way that we have a in the in the commit section of the MLS back. That says this is the order in which you go through the commits and how you establish that these are valid and self consistent. And, you know, a proposal that on its own would have been valid, maybe invalid because other other other the existence of a pre of a previous previously validated proposal. I think we can do that same thing for this. I think we can do it safely and you know, Make a nice a nice clear explanation of what is and is not valid. And and also to your point about the"
  },
  {
    "startTime": "01:00:01",
    "text": "Like, this I can imagine a way to do this that doesn't have a sort of a centralized DS where you have sort of a, you know, You have clients where They sort of one of them take they take turns or one of them is sort of, you know, elected to become a the the thing that decides whether proposals are valid or not valid you could do it with that. And so you could still use this extension in that context. You wouldn't have to. And if you had something that was fully distributed, you would simply not use this extension, not advertise this extension. Brendan. So I was thinking that I believe canonically in MLS, The users themselves or the members of the groups or the members of the group are the ones that are able And this seems to potentially move to a world where the DS Is the one deciding if proposals are valid or not? And I guess one point in favor of self remove is slightly easier for someone outside of the group to be able to say, yes. All of the users agree this is valid. Whereas if you're including a bunch of pending proposals, you do have to trust the DS to properly enforce access control. But if you are in that world, then just as well. 6th, Alright. Next. Okay. This one, I'm gonna go over real fast. I submitted a fragment of a draft today, just be on the lookout for it. I'm not asking for any discussion about this, but Right now, we have A ratchet tree extension defined so that if you wanna include a ratchet tree, but the entire ratchetry of a group inside of a group info or inside of a welcome You can do that And It's"
  },
  {
    "startTime": "01:02:01",
    "text": "RC9420 says you can also have that information conveyed externally, but it doesn't specify any way to do that. And there, of course, as a result, no security and, you know, security considerations for doing that or any anything like that. Many vendors have have the the designed a DS that basically reconstructs the ratchet tree. N more or less we can struts most of the group info. With the exception of the two pieces that it can't get, which are the the group info extension external pub and the group info signature from the previous winner. So this just defines some objects, some some structs as sort of, you know, throwing spaghetti on the wall, is do we want to have a more formal definition of some of these other ways that a lot of vendors are implementing so people do them safely and consistently and we may also want to reference those and they meet me. Next slide. Heard already asked questions about post quantum. So guess the question is, if we ended up with ended up with you know, most people leaning towards alternative one in her slides, does this mean we want to know, pull for adoption once the trigger is updated That's good. Richard, did you have a question about the this or the previous Yeah. This one. Let's do it. To Alright. I'll count that as a pre early thing. I'll just say that this draft has a dependency on a that ID that has not been adopted. Yeah. Alright. Okay. Cool. Again, apologies. I think I did some presentations out of order here. So That's fine. Yeah. Alright. Richard? Well, I might minor amendment on prior comment. Let's do some hybrid chem"
  },
  {
    "startTime": "01:04:01",
    "text": "thing here. Like, if it's x wing, great. If it's something else that comes out of CFG, do that, do that, do that, Alright. Well, now we're gonna do, AppSync. Uh-uh. By the way, logo. good placement of the I've got a whole Google slides team now that, uses the official colors and everything. Allison and see Alright. Next slide, please. So Right. So, Mimi, you may have heard of is this grouper doing to do, messaging interop. Of the things you would like to have in a messaging situation? You've got a messaging room have a bunch of clients and users interacting. You'd like to firm that everyone in the room has the same view of who's in the room their capabilities are, what the state of the room is, etcetera. Now We're using, MLS for the intent security, of for these these Mimi rooms so the servers in the middle can't decrypt them. Decrypt messages. But MLS also provides this, group, state agreement property where everyone in a mo a lot of this group agrees on who's in the MLS group, what their credentials are, etcetera. So the concept here pretty for application state, as well as MOS state state, Next slide, please. So, yeah, the the idea here, the the way we envision the way this is in the current draft, the the MeetMe Working Group has has is on the cusp of adopting is that we communicate state chain. Yeah. We we attach a thing to the, group context extension to the MLS state that captures the state of a room Right? So"
  },
  {
    "startTime": "01:06:00",
    "text": "room has an MLS group attached. And so we'll take the state of the room in some format and put it attach it to the state of the mosque group. And then changes to that state. So adding a user to the participant you know, participant was in terms of users, not in terms of clients. And so adding a, user to the participant list is not inherently an MLS operation. Cause you're not talking about a cryptographic thing. You're talking about a permissions thing. But we've added, a, a proposal here called AppSync that captures the change to that application level, data. So you are you basically, this proposal for AppSync is a way to import changes into, at the application layer. Changes to application later state. Into the MLS control system. And by virtue of that import, that, that proposal now becomes part of the transcript once it's committed. And then flows into the key schedule. So the same confirmation stuff confirms everyone agrees on the MLS state also then confirms that everyone agrees on the application nurse state. Next slide. This is concretely how it's written up now. There's a couple of, you know, ways you could imagine designing it that I've got on the next slide. But basically, you make, a group context extension that describes the application state in you know, a couple of possible formats. It's either opaque or it's a map or it's it's a list. And then the proposal, this absent proposal, sends diffs on that state. So you send either, you know, a replacement, opaque state. You send some removed updated keys, if you've got a map, etcetera. You'll note also at the top there's an application ID. The idea is that you could have full types of application state that you're tracking here. And and and Mimi already, we have 2 types we wanna track policy document. We wanna track participant list and have, you know, separate parallel state management for those"
  },
  {
    "startTime": "01:08:01",
    "text": "But that that's that's the totality of the of the concrete mechanism. Next slide, please. Now you may have noticed there's there's a big select there. Like, are we gonna how how is the state structure Is it opaque? Is it map? Is it map? Is it ordered list, an unordered list. I think there's a basic question as to whether the state that the application is importing into MOS is intelligible or opaque the MLS. Which kind of informs what the API is that you need between the application and MLS. So if it's if the state is intelligible, then these come in in these app sync proposals. The MLS that can apply it to the copy of the state that it has. And go ahead and compute the new state and put the new state in the key schedule. And then just re kind of report out the diff or report out the updated state to the the app. If the state is opaque and the diff format is opaque to MLS, then MLS has to basically pass the diff up to the app and ask Hey. What's the updated state? That I should, import. Now you could just import the, you know, include the diffs in in the key schedule, not the updated state. That that may be good enough. But you might also wanna report back, you know, a hash of the updated state. As a result. So there there there's, you know, a couple of designs that you can envision here. We we, the current draft has the the left hand one where there's some intelligibility but there there's also some, you know, extensibility arguments for for having opaqueness. I think the last slide is The next slide is the last one here. Yeah. So so this is described in your in oh, yeah. Sorry. Go ahead, Edgar. Keyback, Yeah. So I don't think, unfortunately, Intelligible to get you out of this, bidirectional arrow situation. And the reason for that is that not all state updates are permissible. So imagine that so imagine that one of the things that you're updating is the user list have an ex control mechanism that's only allowed. Some people do kicks it out others, right, So you can't am situation where a non administrator can do a kick."
  },
  {
    "startTime": "01:10:00",
    "text": "And that means the state is a state proposal that MLS actually, what has to happen is it has to get rejected by the application if it's if it's invisible. Now now that that doesn't tell us necessarily how we handle as the MLS layer. My point is that I don't think you can just have, MLS thing. Like, you know, like, the like, just reports after the app changed, and unless you wanna, like, basically, fail destroy the group entirely, I'm not on on failure Are we or you can wrap wrap checks out. You you'd have to, like, wrap any permissibility checks around the outside of that. Yeah. I mean, I mean, I mean, like like, I mean, sure. Yeah. Hey, you can also have another box below that is likely is this permissible thing, but the bottom line is that application logic has to be involved in determining whether you're giving updates from those as far as I can tell. That makes sense. Rowan May. So The MLS already describes how you know, just just something like Alice removes Bob from the group, or Alice adds Bob Bob's client to the group, that that that, How application layer would would use, How how MLS would, you know, consult an application layer for authorization for this type of thing, and I think this is no this is no different. The question is, whether It needs to also consult the application to understand What is the if the beyond just, that's okay or that's not okay. It needs the application layer to say, and this is the the value of the thing that you're that you end up with including in your including in your, In your group context. Last slide. So this is just kinda capturing the state of the thinking where we are on this. We've got it, in a draft in the Mimi working group right now that the working group is"
  },
  {
    "startTime": "01:12:00",
    "text": "like I said, on the cusp of adopting, we had a nice positive adoption call in the room was being confirmed in the list right now. If the MeetMe Working Group ends up taking that draft, The Mimi working group is forbidden by Charter from developing MLS extensions. So will be getting a request in this working group to to do some work. Vaguely of this character that allows, application states be imported into the MOS key schedule for confirmation. So this is this is not not asking for for this work here to adopt anything now, but, It's looking like we'll have some work of generally this flavor, coming in pretty soon. That's Any further questions comments? okay. or Cancer. Don't go to. It makes the late credentials. Like clients. Like clients. Sorry. Yeah. We're gonna have plenty of time calling at Dorie. Medical. I can be pretty quick on this. So so next slide, please. This is this is some work I've been doing with, Franciscus Kiefer and and Karthik Barghavan Crispin, the problem we start from is scalability. In, A lot of applications were worried about group that have, you know, a 1000, multiple thousands of clients in them. And There are a couple, you know, while MLS is designed to be scalable in certain ways, there are certain things in still have linear scaling than and, linear scaling with constants that are big enough that it's it gets to be painful. The two things, that that get to be particular pains are that when you join a group, you have to download the whole ratchet tree and validate it. And then when you send a commit, only care about 1 AMLAS ciphertext in the commit, the one that has the path secret that's encrypted to you. But you have to download all of the the ciphertext that that are commit encrypted to the whole group. Order to validate And like I said, in in large groups, this gets to be pretty painful. So you know, a tree is, you know, it gets to be several megabytes"
  },
  {
    "startTime": "01:14:02",
    "text": "we we send them gzip, which helps us just search chains a little bit, but you know, only to an extent. And the point is, like, you have to download all of these megabytes before you can join the group. And so if you're joining a meeting, in doing this in a real time setting, you're, like, sitting there waiting for several seconds while all of these downloads and validates. And, this situation is less acute for commits, but you get, you know, similar sized things there. Next slide. Oh, that's all downloaded. And, of course, you have to store the tree once you have it. So you could imagine devices with small memory having problems with this as well. So solution we've we've sketched out in this draft is an idea of light clients. So a light client is, you know, a a variance of your normal s MLS client that behaves in a couple different ways. The major difference is that the light client doesn't doesn't download or keep a copy of the ratchet tree. That should cause you some terror. Pause. We'll come back to that later. It's a trade off. In particular, a white client can't make a commit. Because the client hasn't verified the tree to know who they're committing to. They can't process normal commits because they don't know where in the tree they are. They don't know, you know, what the structure of the tree is to understand the commit. Instead, what we do here is we rely on a little assistance from the DS. So a light client joins only from the welcome doesn't need any further information. It needs a little information I'll talk about in a second. And then when there's commits happening in the group to enable these light clients to follow along, The the DS is relied on to take a full commit with a whole bunch of ciphertext and slice out just the right stuff to send to the light clients. So we have a a light commit structure that has just the stuff that's, the life client needs. Now a part of there's there's a little bit of innovation here, period, because the, light client doesn't get the whole commit. And so it can't verify the signature on the commit."
  },
  {
    "startTime": "01:16:02",
    "text": "So that, instead of verifying the signature on the commit, you end up verifying the confirmation tag, which verifies that you've processed everything correctly, and you're in the same state as everyone else. Karthik and and company have done some analysis to prove that's okay. That's I'll limit the details for now. But the upshot of all this is that a light client is in fact light. It gets a welcome, the welcome comes with with a couple of proofs that that have login scale, but Like, instead of the usual login in the good case, and linear in the the bet, the worst case. We have a a hard order login down here. It's never more than log in. And so you have much lower, requirements in terms of the time to join, the time the downloads that you have to make, and the notice of you have to keep in memory Next slide, please. Couple of correlators to observe here. I thought were kind of interesting. You know, you can't have a group that's all white clients. You have to have at least one full client or else you can't you want, you can't you can't you can't commit anything. You could also envision some scenarios here where clients go between light light clients and 4 clients like you might join as a light client download the tree in the background and then upgrade yourself to being a client. Now you can participate more fully. You just have to download the tree and validate it. But, you know, the important thing is the client needs to the DS needs to be aware of which clients are light so that it can do that commit slicing and provide the light clients what they Next slide, please. Yeah. This is just kind of a cartoon of what that what that all looks like. You know, when when Bob joins as a light client, he, he just gets the welcome. He doesn't get the ratchet tree. And then the commit that adds Bob, you know, if there's some some light clients around the light client, just gets. You know, a commits, a diet and it should also be light. So di Charlie and Diana, the light clients get slices of the commits that are tailored for them, and Emma being a full client gets gets the full commit. Next slide, please."
  },
  {
    "startTime": "01:18:03",
    "text": "What are the nice little data structures that's in here? Oh, Conrad, did you wanna jump in? Oh, sorry. Yeah, just a clarification question. So That means, Bob will never recover from compromise. So if Bob can't update, there's no PCS, is that correct? That's correct. So so the light clients cannot, send, you know, you well, actually, You could send an update proposal, I guess. Yeah. I think the the light clients can send update proposals, and so they can, PCS update that way as long as someone else commits it. Yeah. That's a good observation. Okay. Cool. Thanks. Yeah. So one of the cool little data structures here, you know, Our our tree hash thing looks kinda like a merkel tree. It's it's got a couple little extra dangly but it it, broadly has the same structure. And you can do proof in that scheme, much like you you can do proofs in a Merkel tree. And so these light clients, even though they don't have the full tree, can still do specific authentication of specific numbers in the group using these log depths, proofs of membership up to the tree hash, the client gets in the welcome So when I say that the welcome, the light client gets us logged up, this is why because the welcome has to include a proof that the signer of the welcome is in the group so that you get, one of these log depth proofs for the issue of the welcome. Of course, the client would like to know that it itself is actually in the group. And so you get a proof down to that. So you, Yeah. We have some need for for some of these, but you can also envision doing some, you know, more innovative use of these as, you know, to have a client that is light and has, you know, minimal information but may still authenticate some specific other clients in the group that are meaningful if you're in a web conferencing situation, you might authenticate the active speakers. And not worry about everyone else who's listening."
  },
  {
    "startTime": "01:20:00",
    "text": "So this is this is kind of a a useful tool, for getting a little bit of authentication even though you don't have the full tree. Next slide, please. So, yeah, this is this is a a proposal to to make things scale even better to basically have Unlimited, you know, much much more unlimited scalability with hard login guarantees. At the expense of trading off on authentication Right? A live client gets much lower authentication guarantees about who else is in the group. Until they download, information to authenticate the other clients in the group. Technically speaking, the main changes we need, you you express the, you know, the the Skipping tree validation. You have this scheme for slicing up commits. And then we define this, the scheme for for tree slices for specific authentication of other clients and integrate that in a couple of different So I don't think this draft is draft is pretty 0. I don't I don't think it's ready for adoption today, but I would love to hear this is a problem of an an approach that seems interesting folks. Questions, comments. There was lots in the chat room. I cannot see the chat. So yeah. I can scan back through it in a minute. Alright. Cool. Alright. Okay? Alright. Alright. Alright. Oh, Daniel. Sorry. I just wanted to to mentioned something that I said in the chat there, which is that I would be worried about introducing this for what I would consider to be, you know, small to medium sized groups. Like, I can see why this is inefficient an efficiency gain for a very large group. And for a very large group, the idea of actually authenticating All 1000 other members seems may be implausible for me anyway. Certainly from an end user perspective, I don't know what it means. To authenticate a thousand people in the group, but I would be pretty wary if We were encouraging people to join small groups of size 12, in this light mode. I don't see that I don't see much of a gain if efficiency was."
  },
  {
    "startTime": "01:22:01",
    "text": "And I see a lot of a risk by comparison, And so if there's a way to cabin this, to something, you know, above a certain cutoff or something I'd be interested in hearing cut off a bit. Yeah. I I I think that's totally how I would envision doing this. Like, you would not use this for you know, a group that you can, you know, easily quickly download and easily fit in memory. Mean, I I think in fact, a lot of the ways I'm envisioning deploying this you only basically use these this light client ness temporarily while you're getting yourself set up so you can join the group fast and then, you know, bring yourself, let the authentication guarantee follow in a little more relaxed pace. But, yeah, I think we should absolutely have some clear security, consideration a dot, you know, the trade offs that are involved here because you do lose stuff. And, you know, when it's appropriate to take on those trade offs. Ebrahim. Oh, sorry, Bob. I did agree, with the with the Because I a specific use case where, as I mentioned in the chat, I have very low bandwidth spectrum. Be, being able and which is being used for telemetry, And now I need to add add in in during the operation, another member. There's a level of trust already for that other member adding in. And and the member does trust the groupies they're joining. This may make it possible for this to even be used or otherwise it would, MLS assist I have not really worked with at all for these very narrow spectrums that I'm constantly getting in discussions with. Yes, sir. Cases where we have broad spectrum, where we have 80211 radios or something similar, but there are also cases where Our only spectrum is 100 kilobits per second. And then that's for mostly for telemetry. So I can use something like this. Yeah. This could be, advantageous depending on what your your"
  },
  {
    "startTime": "01:24:01",
    "text": "you know, filer looks like and you're you're you're you're you're network layer looks like you know, if you have a broadcast you looking thing, then you your overall efficiency might be better to do commits if you have a bunch of one to one channels, and this is this may be smaller. Brandon. So there's one security issue here that I think maybe it could potentially cause an issue because you don't see the whole ratchets tree, you're not able to verify parent ashes. Because you're not able to verify parent hatches, you don't necessarily know just because when it's in the ratchet tree, if they are actually in the group or not. Like, people could forge groups and say, like, oh, someone's a member really good when they're really And so at at minimum that has UI constraints that it introduces and that you can't say someone as a member of the group unless you've actually seen from them. That's worth considering Yeah. It's it's a good point. And in fact, that's why there's a hard binary between light and full clients. I went I went back and forth with with Karthik a whole bunch, but, like, couldn't we just, like, download the co proof of my co path. Which would be enough for me to send a commit. And he had to keep reminding me that if you do that, you can't verify all the parent hashes and so you don't know that you have proper integrity to the tree. As far as the the utility of these these tree slices that is specific authentication. I'm I I will defer to, let me connect you and Karthik on that because he he did do some formal models on that. That I I think showed the things were okay, but we should we should dive into that for sure. Alright. We drain the we drain the queue. Conrad. You are up next, sir. Thanks so. Virtual Appliance and application messages. Yep. Yep. Okay."
  },
  {
    "startTime": "01:26:00",
    "text": "So, yeah, we talked about virtual clients, I last idea or one of the interns? Sorry. Can't remember, but, if you go to the next slide, we recap real quick. On what this is, what we're trying to do with it, It's it's essentially Allowing 1 or more MRS clients, to collaborate in in simulating kind of a higher level analyst client. And this enables essentially this, mechanic where you have a, an MLS tree with leaves and underneath the individual leaves, you essentially kind of have another, MLS group that well, emulates this, the, the client that's in the, in the leaf of the higher script. They use an MS group. To do that. And, if you go to the next slide, which I think just reveals, oh, No. There we go. And so the motivation for this, the the initial thought behind this was, okay, we can do uses for users where each user has a bunch of clients, and, this serves 2, two purposes, on on the one hand, it makes the trees smaller because we have fewer leaves, say we have a bunch of users. Each user has a bunch of devices, And So you have a bunch of, Leaves. In in the kind of high level group with multiple users. But if you you switch your clients, then each user is represented by only one leaf And you have these small individual groups for each user that is invisible to all the other group members and, you get away with more, efficient commits because the tree is smaller. But another advantage is also that it hides the metadata. So use case. We have a user with multiple clients. And now the other users in the group cannot actually see of the user's clients sends message to the group. Because the clients are hidden in this And subgroup."
  },
  {
    "startTime": "01:28:02",
    "text": "But the user one user multiple clients use case is not the only one. What you could also do is you could use this to, implements kind of organization hierarchy is where you have kind of a company level group, with the different departments and the leaves, and then each kind of department leave has its own MLS group, you have individual teams, and then it's trees all the way down, essentially. And, that can, again, make kind of these really big groups more efficient if you have stem service structure, behind them. And then, finally, is the idea of guardianship or paired MLS which, Alberta proposed in a separate ID as well where you have, kind of a strong and weak client that are connected and also in a separate way, I think, where they can maybe say more about after the the after these slides. They're connected using, I think, to share its RNG. But anyway, you have a strong and a weak client, and the the strong client can can do, computationally more intense tasks and kind of support, the weak client and and getting security. And then you can use to kind of con virtual plans conceptually to to hide the from from higher level groups. But, yeah, suffice it to say there are a couple of, use cases where this might be useful. And, again, if you think of of the post quantum use case, where updates get more expensive, the, the larger the tree is, and you have to store more, public keys, those are all the this is another situation where you're really benefiting from smaller tree sizes. Okay. Next slide, please. And so if if we if we're thinking of sticking with this kind of one user multiple client's use case, the the clients of the user now have to coordinate a little bit in terms of how they, what the virtual clients What's the virtual class? They're ambulating actually does."
  },
  {
    "startTime": "01:30:03",
    "text": "And so in most cases, this is already dealt with by the DS who is, which is kind of dictating the, the message order. And so you cannot, the, the individual emulator clients cannot to kind of cross this tree and do things simultaneously because the DS will reject 1 of the commit messages and and, the other client, will have to try again. And that the rejected client will have to try again. But there's only work it really works for, commits. So what do we do in the case of application messages? So and let's just imagine for a second, if 22 of these kind of user devices send an application message at the same time. It's gonna be the same epoch and the same generation. It's pretty bad because now they use the same key and the same nonsense. That's no good. And so what what can we do to to to fix this, next slide, please. And, Right. So, so there are kind of two ways of looking at the problem that that Brandon really kind of, worked out And that is, in you have a kind of functionality problem where, And you if you send 2 messages at the same time, then then then the recipient will only be able to decrypt the first message delete the key that they used to decrypt for for security reasons And the second message arrives, and they cannot decrypt anymore. Not a security problem. That's just a usability thing. Or a functionality thing where you just cannot decrypt the, the second message. And then the second problem is this kind of key non reuse problem. That might leak the message. Or that will leak the message, I guess. Okay, next slide, please. Hold on. Right. And so we, I think by now, and, and, we have, 3 kind of different"
  },
  {
    "startTime": "01:32:02",
    "text": "a solution for those problems, for this problem, and each comes with advantages and disadvantages And I just like to hear if if people are, interested in in this virtual client's concept Then like what properties or what advantages or disadvantages what you, like to see in a in a solution for. This application message problem. So the first one is that among the the u the first solution to this problem is that among the user's clients, they have a allotted kind of Yeah. Sorry. Ron, Uh-uh. Did you wanna wait until finish the slide. Okay. So so each client has a, hasn't allotted to kind of generation that they're allowed to use. So let's say there are 3 clients then the first client will use the 0th generation and then the third and then the 6th, etcetera, etcetera. So it's kind of modular, the generation modular, the the number clients. And so this means that clients don't kind of use the same generation. This is nice because it works with vanilla MLS. So the receiving client doesn't have to know a virtual client involved there the DS doesn't doesn't have to do anything. We don't have to use any extensions. The disadvantage is that the receive receiving client will have to ratchet quite a bunch of bunch of times depending on the kind of messaging pattern. So let's say the user has 10 clients, and only one client is really active, then after 10 messages, the recipient will have to ratchet it like a hundred times and keep all the kind of intermediate because they don't know if Those are messages they missed. Or if the other clients may send messages in the future. So that's submits of optimal from that standpoint. Yeah. Roland. Yeah. So in terms of the leakage, Even if this group is stable, The It's only if somebody sends multiple messages in a row that"
  },
  {
    "startTime": "01:34:00",
    "text": "It's really obvious with what the even the size of the of the the the hidden tree is. Right? Yep. So This doesn't seem terribly worrisome, and it seems like you could use decoy basically empty messages sent Randomly, That would That could make this even less leak you know, bleak even less information. So I like this one. Okay. Okay. Cool. I mean, yeah, you you could probably not go with a modular approach where you send every Ith message message, but instead you have some sort of seed where you kind of just draw randomly depending on your where you are in the group, which, generation Euro Science there's probably a more clever way to pick the generation that a client is is going to use So, but, yeah, and but but from this slide, you can already see The the advantages and disadvantages go along the lines of Can we use this with vanilla mls, which which would be really nice because then anyone who wants to use virtual clients can do so on the recipients don't really have to know anything about it. Then the second one is will DS have to do something to accommodate this this thing And then finally, like, okay, if we cancel the land, use vanilla analyst, can we just have an extension even like a safe extension, to to do this. And then finally, Do we leak do we still get this metadata protection where other client, the recipient doesn't really learn anything about the the subgroup, the, the user's clients, essentially. Okay, but let's move on to the next solution. And this is, essentially, Joelle and Marta."
  },
  {
    "startTime": "01:36:01",
    "text": "A proposal, And this is kind of re reimagining how application messages are sent. So instead of this secret tree that we have in MLS were at the you have, like, 1, which is kind of inverse of the the to chem tree where you have one lead for each participant, And under each of the leaves, you have this this ratchet, instead of doing that, do you help out, PPRF. So the the tree is is is a bit wider. And, whenever someone sends an application message, they do is they, create a the challenge and the challenge includes stuff that disambiguates them from other virtual clients. So let's say it would include the the index and the the subgroup where all the users' clients are, and maybe the group ID and all that's cached so that there's no collision between application messages sent by client of the user and another client of the user. Then they can use that challenge to, derive a keen on spare from this puncturable PRF. Essentially, this the secret tree, they would just go down one path and the half might be, I don't know if they have length of the hash function 32 bits and, 32 bytes and that would be the says of the tree, and, then you can you arrive at the bottom, you get a keynote pair, that's going to be distinct from anything that other clients of that user might use. And, This kind of solves both the functional security problem and, kind of might make the secret tree a bit more flexible in any case because you don't have to do the stretching anymore and you still get forward secrecy but this is not compatible with vanilla MLS. You need a new kind of tree design, if you will, And it's also going to require a new wire format. Brandon. Yeah."
  },
  {
    "startTime": "01:38:04",
    "text": "So one clarifying question, because this is a puncturable PRF. I assume that after you use a certain input pair to the PRF and you get the output, puncture so that you can't evaluate that anymore. Does that mean that each client's private state, grows linearly with the number of application messages they send. Did you PPRF works, but Yeah. And not just the sending plan, also the receiving clients. Right? I mean, they it's it's matter. So everyone would have to puncture it the same way. Yeah. That's that's a good point. So in in that, the the trade off is a bit different than than the Original Secret Tree. But, yeah, yep, thanks for pointing that out. So that's another kind of disadvantaged or or another trade off that that we're making here. Okay. Next slide. Okay. So this is the the 1, to to Brendan proposals, propose on the list, and Brent, for free to correct me if I'm misrepresenting this year. So here, we kind of really split this problem into the functional kind of how we approach the functional part of the problem and how we approach the the security part of the problem. And for the functional part, we, for now, we just punt it to the the the s and say, the gas is going to take care of preventing clients from sending sending an application message with the same generation and the same epoch, and the same sender. And then we, tackle the security problem and, well, sorry, maybe to elaborate a bit more. You could do that by either by just kind of tacking onto the MLS message, the sender, and generation, which of course, it's suboptimal because you would leak the"
  },
  {
    "startTime": "01:40:02",
    "text": "the center data that we otherwise would encrypt, but there's clever more clever ways to go about it can hash it and see that there's no no collisions and stuff. Sorry, Brent. Good. So so for the the functional problem here at preventing Key reuse, I don't think this requires anything necessarily special of the delivery service. Basically, if you have a strong and consistent delivery service, That delivery service already provides you the ability to make sure that you have read all of the messages that have been sent to the group. Before you send your own message. That's all you'd be doing. You would have to like, getting a new metadata that you send to the TS that is outside of what you would normally send. But it only does that for commits. No. I mean, Not necessary for application messages. I mean, if if, yeah, if you have a strongly consistent yes, then application messages are gonna be ordered absolutely. And so a client can go through and see all of the messages that have been sent from their clients. And ratchet it they're user ratchet as far as they need it to. But that would, So that the DS doesn't have to be aware of it. The DS is just providing an order and telling us all the messages that have been sent So we can, move our own ratchet as far forward as we need to. But if but if 2 clients send at the same time, then, like, both of them fetch all their messages. And then both send a message at the same time thinking, oh, I have received all the messages. I, I, I can. So you surround the problem. No? That is a race condition. Yes. But I would argue that would still be solved by a strongly consistent yes. Because You've kinda got the ability to read all of the messages and then send your own message. And so if there's like race condition where someone else could have read all the messages and then, like, create a fork. It's not really strongly consistent."
  },
  {
    "startTime": "01:42:05",
    "text": "I mean, I think in this slide, what this says is basically the DS is providing a mute which is I can I can lock the thing? I can read all the messages. I can write mine, and I know that that's serializable. But but that's but isn't that an additional requirement on the DS that we don't like, we we have a strongly consistent TS4 commits normally. No. Right? I mean, this this is a, like, this is not what, what, this is not in the, and the architecture talk are are something that, that we require that DS normally to do on. Or I'm just I'm just understanding this here. That's a good question. We might not Require application messages to be serialized. For strongly consistent, yes? I'm not sure. Okay. Anyway, I think I think I think we agree what the requirement is. It's just a matter of Is is this kind of the architecture dog, or is this something that that the DS would I don't actually do anyway. Yeah. TKG. Yeah, Brandon, maybe you don't wanna go away from the mic yet. Brandon, what you were saying sounded to me, like, you aren't thinking of the DS as part of the, threat model here If the delivery service is part of the threat model, In terms of breaking confidentiality, And the delivery service is the one responsible for ensuring that there isn't this simultaneous resend of messages using the same, key and nonce, Then the DS can simply allow the 2 clients to send messages with the same key announced, and then Do its own work to break the shared the this is the key reuse scenario. Right? So that's a great question. The delivery service is responsible for well, So you're absolutely right that the delivery service can intentionally not you that someone else has sent a message so that you will encrypt two messages with the same key from 2 different devices. What that will not do is cause nonce reuse. Because of the"
  },
  {
    "startTime": "01:44:02",
    "text": "the reuse card, basically, idea that I that I wrote about in my email? So the Do yet. you wanna quickly explain that? Because I I didn't get to that Right. So what different devices will do is they will all guarantee that Basically, no device will use the same reuse card. If you remember from, the the MLS protocol, the reuse card is this little 4 byte value that's export into the notes before it's actually used for encryption. So, all of all of the devices that user has have a different, basically, space of reuse cards that they're allowed to use. No two devices will ever choose the same reuse card, which means they'll never they'll they'll never choose the same nonce. So what you will do is you will have 2 different messages encrypted with the same key but different nonces, and that is still secure. So then we're back in the soup from solution 1 of the the If the different clients have the same have distinct spaces of the reuse card, Then that's make isn't the re used card then visible to all other peers in the group? Because then that allows the peers to redistinguish the clients if the that's the reuse card. Partition is a secret partition for now. That's exactly right. The reuse card partition is secret. People who are not in the subgroup. The virtual playing corresponds to can't look at a reuse card and see which partition it comes from. And there's also the efficiency aspect of the reuse card. So with solution 1, or you're ratcheting forward through a bunch of keys and not using all of them, creates an obligation on, all the other members of the group to hold on to all of these keys who weren't used kind of in the middle of the ratchet, with the reuse card approach. You can use step of the ratchet after the other, after the other, you don't have this huge set of keys that you use to hold on to. So that that makes a lot of sense to me. Thank you for explaining it. I'm not sure I understand why we need the DS"
  },
  {
    "startTime": "01:46:01",
    "text": "assistance in this case then. Like, why not just the reuse card? So that The reason that you need the DS assistance is to help avoid key reuse because without TS assistance, two devices can send a message with the same key at the same time, which will have different nonces. So it's secure. But, they'll use the same key. And so each device, when they get the others message, they will likely have already deleted the encryption key. That that that they use. So, they would feel to decrypt each other's messages. Got it. Thanks. You for the reexpect information. Okay. I mean, this is this is the last slide. So I just want to do kind of get a feeling with the different trade offs that we have here. In terms of metadata leakage also no MLS compatibility, and maybe a bit more of flexibility in the in the with the challenge based approach, What do people feel? Is worth exploring what is covering if more use cases, so yeah, just to give us who are thinking a bit more about this problem and trying to maybe come up with a document that will eventually maybe adopt some guidance on where this working group would would like to go to go. Alright. Anybody? We can also take this to the list. TKG. Yeah, thanks. I just wanted to say I I really do support this work. I think this is greatly important. I think it's a mistake that MLS as designed as fundamentally, leaking the number of clients and identity of the clients,"
  },
  {
    "startTime": "01:48:00",
    "text": "To The rest of the group It's So, that first use case is, I think, a really important one. So I, I really, I hope he can work on this as a group to sort out would need to be done to do that safely? So just to to summarize some of the discussion that we've had on the list already, also may not be possible for us just to choose one of these. Because if you think about the use case of you have one who has a couple of devices, and they wanna use all of their devices as one client. What's really important there is you need the privacy aspects of not being able to know which device sent, which message. And so it's most likely gonna be solution 2 or 3. Then between solution, 2 or 3 you would probably, in my opinion, go with 3 just because it's simpler. It requires no changes to the to the MLS wire format. That would be nice. But people have also been talking about Other use cases for this kind of virtual client subgroup idea where where It's not one person who has a handful of devices, it's maybe, like, an organizational subgroup. And so you've got, like, 50,000 people who work in your marketing department or something, and you want them all to be able to be added to a single no marketing mailing list. And in that case, you're gonna run out of entropy in the reuse card. So there's not enough room fit all of those people in your four bytes. And so in that case, you probably would have to go with solution 2 because it has much more room to fit people and, entropy, entropy, Those other use cases, sound to me like they directly contradict the goals of MLS in that the goals of MLS are anti encryption among people who can identify who else is in the group and I recognize those are not necessarily goals that we can described fully at the protocol or wire format layer,"
  },
  {
    "startTime": "01:50:04",
    "text": "But if the expectation is I'm using MLS, therefore, I know who I'm as they're going to, And now we're talking about message is going to groups that I have no idea who's in them, I think that actually violates the the Cognitive expectations. We want you just to be able to come away saying, This uses MLS. I know what it does. So I'm less keen on those other use cases. Okay. Alright. Well, I it seems like, discussions will continue. So let's go ahead and wrap this up. Basically take it to the list. And if we can't do that, we can, try to have an interim maybe to talk about this particular issue because keeps coming up, and we gotta figure out how to decide which one or 2 to use So, again, thank you for sorry? Sorry? Yeah. Just wanna say thanks for the discussion and then Thanks. No worries. Thanks for coming out. I appreciate it. Think we're gonna bring the meeting to a close. Thank you very much. Yep. Thanks, everybody. Oh, and thanks to Jonathan for taking minutes. Appreciate it. These ain't corrections. Yes. Rowan and Ecker. Going back and forth and I too was having trouble following. So cool. Alrighty. Exactly. They don't think of anything. And he's like, go to the wood style"
  }
]
