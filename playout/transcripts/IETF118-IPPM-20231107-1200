[
  {
    "startTime": "00:00:12",
    "text": "Okay. For this Alright. To Okay. We are about ready to get started. This is ipPMipperformancemeasurementat IETF 118. If you're not here for IPPM, if you were here for PPM, you were in the wrong room. If there are people in PPM who are here who are there for I PPM, I hope they I hope they get here. Alright. So before we start, we will need a note taker again, Can we please get a volunteer to help take notes if, I'll also do remember to sign in to meet echo here so that we know how many people are in the room, again, we are going to need a note taker to help out before we get started. Market is very kindly added all the agenda items into there. So you just need to fill out The discussion points and who says what. We're going to need to get a note taker before we get started. And what The more time we Ben here, the last time we'll have on content. Alright. Anybody, can we get a note taker? Ideal to get someone who just not otherwise presenting"
  },
  {
    "startTime": "00:02:06",
    "text": "It really makes me earn the cookies in the break. A second. Anybody Frank, could we get you to help out? I'm just Could someone help patch the end of the meeting. Frank starts it at back there? Was it in? Oh, yeah. Okay. Okay. It's, if you go into me to go through the note taking tool, it's also accessible off of the agenda. And I think we have a link later in the slides. Okay. Great. Thank you. Okay. So Thanks a lot for taking notes. So please, everyone, also take note of the note well. This is an IETF meeting, and we operate under the note well. It provides guidance on things like IPR and your code of conduct. So please familiarize yourself with this if you haven't. Thank you. Yep, meeting management, we have a note ticker, so that's great. I have a quick suggestion. Because often we have people in the meeting room for the first time. We were not familiar with the tools. Are you able to bring up the web page? Just just because the way I access the meeting notes is through the agenda. That's the way I find it easiest. If you know how to access the agenda page and you see the little icons there next to each meeting One click will take you into the meeting. Page. For notes and and it's a it's it's a really nice collaborative editing tool. So even though we have one volunteer, If other people who haven't done it before want to follow along and learn how it works,"
  },
  {
    "startTime": "00:04:01",
    "text": "just click that link, bring up the editor, if you see somebody make spelling mistakes, or misquote a question, you can help by fixing it, and it's a great way to get involved with the IETF process and make a contribution and not just being the room playing minesweeper. That's an excellent suggestion. Thanks a lot for that. Right. And please everyone, log in either using your your your mobile device using this QR code or log in to the meet echo tool in on your laptop. Queuing management will be handled throughout this tool. So if you wanna if you wanna make comments or questions, please enter yourself to the queue in the system here before you, go up and talk at the mic. All the slides for all the present presenters are loaded into the system here. So, they're preloaded and we can drive them or or you can drive them with this thing, hopefully. Any way, but, there's there should be no need for sharing external screens or anything like that. I'm not sure if we need a specific JabberScribe or if we can just we can just follow follow along there. Yep. Okay. So, we have an agenda for today. As usual, we will be starting with adopted working group documents. So we have a set of documents here. We have the newly adopted hybrid 2 step. We have some updates on encrypted PDM data integrity, responsiveness in stamp, PA. And then As usual, we will also be, following up with, documents and items that have, been discussed extensively in the group, but not yet adopted. So we have a of interesting talks here, interesting documents to to go through. And these are usually given a little bit more time. And then we will round off with a set of lightning talks. So these are working group,"
  },
  {
    "startTime": "00:06:02",
    "text": "This these are internet drafts that are, new to the working group, and have not yet had much discussion on the list. So it's a way for for for the authors to to quickly present their work and try to gain attention from people to to to, facilitate more discussion. And usually these lightning talks wanna keep them very brief to one slide, just presenting on a high level overview of your work to basically gain the interest of the community. Do we have any comments or any bashing on the agenda? Great. Come up to present, Greg. Yeah. Thank you. Great. One other just minor note I'll mention, the ISG has since the last time announced that they're gonna be restructuring some of the areas And so the plan is for IPPM as a working group to be moving from transport over to ops starting in the next meeting cycle. That won't really change anything as far as how this how this runs. Maybe you'll, make the scheduling a bit better for people. Just letting people know about that. And that we'll likely have some shifts coming up in the responsible ADs after next meeting you wanna try this or you want me to? That's right. Okay. Okay. Okay. So, yes, thank you for, your comments and support, during the working adoption poll, just because It was, so close to the meeting. So still working on, addressing the comments, but, that will be coming shortly. Okay. Just, Okay. I don't know where to put it. A very good point. Okay. Okay. So, the protocol, what's the purpose? It's proposed, method for collecting, on path telemetry."
  },
  {
    "startTime": "00:08:03",
    "text": "From the host to versing the following their, packet that is equipped and enhanced, with their information, that makes it a hybrid method. So, one of the advantages of that is that the collection, even though their, information is, very useful, but cannot be collected out of ban. Comparing to their, data flow that being monitored. So that's, it follows the same physical path but can use a different, class of service so not to consume the same resources. combination with the IIM direct expert or with the alternate marketing method. So and, again, that could be done either for raw data or for aggregated statistically process walk according to the local policy data collecting them. So that simplifies that correlation of information that, for example, the same note participates in a a number of, monitoring activities for different, data flows. As well as, downstream collection mode, this protocol allows for the upstream note. For example, if, it's beneficial to have this information being deliver it to the source. Although, one of the ideas is that, following the lmap, architecture their, processing of on path telemetry information is done by the collector. So you have an agent measurement agent, and then you have a collector. And then you have a controller that coordinates and orchestrates all their activities."
  },
  {
    "startTime": "00:10:03",
    "text": "And Lmap is a working group that existed. And, produce their, measurement, in a large scale, excess net 6. Okay. So, because, the information is important. This protocol allows for, integrity, protection using H Mac And each of the nodes participating signs it, but because it's a aggregated, collectively downstream or upstream, So there is no need that each note knows of their HMAC, of their any, other nodes. Only their, collector that processes the information. So the next slide, please. So, again, this is part of their active, measurement protocol in a hybrid. So in a hybrid, we know that it's a combination of passive measurement and exit measurement. And, here, there's, there are packets being injected although there are not face sharing in terms of the cost of service. So they they follow the same path, but not the a class of service. So resources are, less, impact on the net next slide. And as mentioned, so it could be, used for direct export or alternate marking method, Next slide. So and here's here's an example of one of their, uses of, hybrid, 2 step is that, we have, a trigger packet that triggers, their creation of injection of the HTS packet. And it uses the same dataplane encapsulation Although, it could have a different class of service,"
  },
  {
    "startTime": "00:12:00",
    "text": "And, then, thus, it follows, the path of their, trigger package. And, one of the advantages is that it overcomes their MTU limitation. So it can, actually have no bound by the amount of information can be collected. Because what HTS protocol does, it constructs the sequence of packets that carry, relevant telemetry information Next slot. Also the, HTS can be used in a, multicast environment without unnecessary multiplication and duplication of information collected upstream. So you can see here it's just, an example of how it works in a multicast environment. And next slide. So and as well as it can work, upstream So, that package will traverse back the path of being traversed by the trigger pack. So I I used my time, and, that was just refresh a memory. And as I mentioned, again, I appreciate all the comments, that it, was received during the working group adoption poll. And, our work on addressing them. Shortly. Thank you. Any questions, comments on that? Alright. Cool. Cool. You for the summary again, and we look forward to the updated version. And Okay. Hi. I'm Melanie. Next, please. Yep. This is gonna be really short. We had, sent the draft over to sec dear."
  },
  {
    "startTime": "00:14:00",
    "text": "For an early review, and it came back. They had a bunch of suggestions. They said, wanted us to change how we were doing the attacks and use the limited threat model, RFC to address it that way. So we have done that. Same thing for privacy considerations is the way he had, we had formatted it was not, could have been done better. So we did that also do for our encryption We had not, picked a default cipher suite we have since, done that. And, there were a number of other simplifications for, sightings, like, doing things. Like, there's no need to repeat stuff that's already defined in HPKE. We did that. And, so now we're gonna go ahead and get another sector review. And that's that's where we are. Any any Alex, Questions? Otherwise, as I say, We're just looping through sick deer. I have people in the room read the latest update after this any hands of, yes, you have. Yeah. Okay. So I think we wanna encourage folks to do a review of that. Maybe, that maybe just, like, in, in parallel with kicking off another sector, we can as the chair is gonna ask that people review that. I mean, where where do you think you are in terms of getting towards, working group last call I feel like we're pretty good. What I wanna do is Would we wanna do that, like, in parallel with or do you think? Well, that's a very good question is what I'd like to do if you guys are okay is have, this the reviewer do a private review in case, you know, because because we asked him to clarify what he, you know, that I just wanna make sure we understood"
  },
  {
    "startTime": "00:16:00",
    "text": "what he said. So have him do just one final look over. Then we'll officially and and once he says, Yes. You've understood what I said. Yeah. And then we'll ask for a formal sector review. And then I suppose we could call for last call. We have an implementation that we've been working on side by side. So So, yeah. Yeah. But I I don't know what you said, sir. Yeah. And as far as just confirming with the previous sector review, is that something that the authors will just directly Yes. Yes. Yes. Yes. Yes. I will just talk to them. Okay. So maybe once that's done, then we can kick off Perfect. Can you just email the tariffs directly? Yep. Sounds perfect. Okay. Yeah. Anybody wanna we yeah. We're happy to share our implementation with anybody too. It's a lot of fun. It's an ebpf. For the implementation status. So you have that, which is great. Are there other folks working on implementations as well It was just just kind of like a a one Yeah. Yeah. You know, that's really super interesting because we have seen PDM being used in the wild where we did not expect it. And, you know, I want I wonder, I suppose does I PPM have a you know, like, a Wiki where we post implementations We might want it. I don't we haven't done that formally as a whole working group. Now what we have done because we can tag specific documents with a link to either yeah, a wiki or list of related implementations or, you know, direct links to, GitHub page or whatever for that that are labeled as implementations. We've done that for things like the responsiveness project. So I would certainly encourage doing that is one thing that we can point to particularly, you know, during the shepherd write up in IETF all of saying, like, look, here are the implementations. Here's the documentation of that. And I think this goes for all of the documents we do Yeah. Yeah. In general. But"
  },
  {
    "startTime": "00:18:01",
    "text": "That that would be good if you wanna use that tool. Yeah. Now we'll do we'll do that because we've talked to the people too. It's a little con it it, like, the cipher suites and stuff. It gets a little gets a little headachey. But but it's a lot of fun. So Yep. So anything else then? Thank you so much. Okay. Thank you. And some time back too. Justin. Hello, everyone. So this is an update on the integrity of IOM data fields. Next slide, please. This one's gonna be pretty quick, actually. So, there is only some, you know, editor changes since the last time in San Francisco, mainly, one sentence that was added in, the tread's description based on on email we received privately. And the other one is, to add you know, the last code point, about the integrity, option type for the decks. So based on, I had a conversation with remove the label suggested next to the code point. But the most important point is maybe this one that Swister waiting for a sec deal review. So we were not as lucky as not any So What I suggest if I may is maybe to have, you know, working room blast calling parallel. That could force, you know, people to read the draft because if I remember well, we had, like, 1 or 2 people, that's not that much. And so maybe we could receive you know, the review in parallel or with the last console, I think which probably should proceed right now."
  },
  {
    "startTime": "00:20:02",
    "text": "No. The other thing besides, re asking the, sector reviewer, which we've asked several times, is we need just ask the security director to assign a different reviewer In this case, which which I think would be fine to do. So maybe we can take a note of the action that we we may wanna do that and ask for a new reviewer. I appreciate it. So that's it. Sorry. Thank you. Responsiveness. So I think, you know, since people are here this week, we can take the action to reach out to the security 80s or sector and just figure out what if there will be a way to move it along faster. And if we can get that soon and get that input great. And I I think we can just decide when's the right time to do last call. I think We we should do the last call before the next IETF. Either way, ideally getting the sector review as soon as possible, but potentially having be in parallel. Shall I start? This I'm Stuart Cheshire. I'm here. Speaking on behalf of my co author, Kristoff Parish, who is back in California where the middle of the right middle of the night right now. Just you could do it for me. Short answer is we think we're done with this draft. It's been through a few rounds of reviews and good feedback and suggestions"
  },
  {
    "startTime": "00:22:00",
    "text": "both in the wording. And in the algorithm, We started this work in 2020 when Lots of people working at home because of the pandemic and video calls didn't work very well. And, That's now 3 years ago. And we think it's time to move this forwards, I think it's ready for working group last call. I think it's important that we advance this. And I'll actually explain why For the last 20, 30 years of networking development, We have all everybody in this room has used IPerf to measure throughput of their network connections. You upgrade from 10 megabit ethernet to 100 megabits, or you pay more money to ISP to upgrade from a 100 megabit to 500 megabit at home. Is the first thing you do? You do a speed test to see if you're getting what you paid for. Even though we should know better, We're all guilty of that. I did it too. And in the last few years, when those was working on improving network user experience, and that means consistent low round trip time when the network is busy, not just when it's idle. Idle networks always have a low round trip time. It's not difficult. To do that. You've gotta be really trying hard to do it badly for your idle network. Have a bad round trip 5555 but maintaining a good round trip time when it's busy is the challenge. And and we know how to do that. When we talk to engineers, chip companies who make Wi Fi chips, assuming we can explain the issues to them and they get on board and they They agree. That it's important to fix it and they agree on how to fix it. What we realized is that They need a tool. To tell whether they've done the fix correctly."
  },
  {
    "startTime": "00:24:00",
    "text": "Because when they say to their management, we're going to change how we design the wifi chip because it'll make it better. They need an objective measure. And That's why We, we could have just written a tool and, and, and, shipped it but we actually wanted the feedback of the whole ATF community. To get agreement that this is a useful measure the number of reports is a good correlation with subjective user experience. And we wanted it to be multiple implementations. So if you go to the next slide, think we've achieved all of those things. We've had lots of discussions with lots Had lots of feedback and refinements. We now have 3 different Independent Implementations. Those of you with Max have one built in already. The it ships by default. There are also 2 open source ones available for other platforms. And we wanna make this tool available to engineers working in the, in the industry designing hardware, when organizations like the FCC are creating regulations around around around What does it mean to call something broadband? Right now, their definition all in terms of throughput. Is it a 100 megabits? Is it 200 megabits? And I think everybody in this room knows that it's not just about throughput latency matters as well. But the FCC cannot make any sensible regulations unless they have a measurement tool to point to that actually gives an objective measure. So that's why I think it is very timely right now that we move this ahead to publication. So that's my request. That we can safety. Agreement on starting the last call on this. Yeah. Thank you. It's great to see the progress of this document and that we're in the state. Oh, we have Lucas in the queue. Please speak."
  },
  {
    "startTime": "00:26:05",
    "text": "Hi. I'm Lucas Pardo. I just wanna say, like, this great work. I've been reviewing the document as it's been going. I have a few open issues, but I think we should just try and address those during the working group last call process. If you have open issues that you have time to type up this week, then I think we'll try to incorporate that and and get a a a 04 out and and then we could use that as the basis for the last call. You gotta give us something to do in last call. Well, we gotta have some comments in there. I I've been wanting to to offer some text on my own as well on that. Okay. Take I've taken tasks, and I just not had to cycle. Though. So let's I'm willing to sit down with you this week while while we're in the same place. A a I think, we should improve the document. I want the document to have all the feedback and it'd be in the most readable state. So that when everybody else who reading it, they're not pointing out the same knits and the same mistakes. So let's try to get that done in the next few days. And kick off the last call. If we can, and I just don't wanna block progress. I think it's ready I think it's in a really good shape it's good work. So, well, it's Tuesday now. We have until Friday, so let's get it done. Okay. Just we got a couple So security, Good. I'm sorry. I haven't read the document. But I did wonder if this is going to be used more formally Is it possible has anyone done the analysis of gaming the system? So pretend or doing something that appears to give good results on a network that is actually not so good. That is a really important point I'm gonna make the open's request as Please read the document and and give us the feedback if you think it doesn't explain that. But the point you're making was something that was really important to us right at the start."
  },
  {
    "startTime": "00:28:00",
    "text": "And It's the reason we took certain decisions that might have seemed odd to some people. We don't measure the round trip time using ICMP echo. Precisely because There are no applications that communicate their data in the ICMP echo packets. When you look up the weather forecast for Prague, it's coming in an HTTP get. It's not coming in ICMP echo. Yeah. So So the test does an HTTP get to measure the end that the application layer end user round trip time to actually get data from a server So it includes TLS overhead TCP overhead and those overhead shouldn't be big. But but they are included. And by by accelerating, ICMP I'm not helping this. Exactly. If if the benchmark is using ACMP, that gives an incentive for vendors to cheat. And they might not even cheat knowingly. These things can happen sort of inadvertently because some manager says to some engineer, our score is too low on this text test. Make the score better. And the engineer figures out that prioritizing ACMP makes the score higher Yeah. They've done what they were asked to do. Right. But it doesn't help end users. Exactly. So we tried to create a test where the only way to game it is to provide really good internet service. And if that's how you gain the test, then we both went Yeah. Okay. Thank you. I will read the Alright. I put put myself in queue just for question on the update One of the ones you mentioned was about the the well known URI. Which is good. Glad we have it. Just as far as the like, the name for that? I know it's like a very short n q, very brief and concise I just wondered, like, of of how do we pick that? Do we know"
  },
  {
    "startTime": "00:30:00",
    "text": "like, have we talked to the the experts froball known URI is that something that is that the deal. The same question I can't answer, have we talked to the experts? I don't know. I'm actually not sure who those experts are. As to why we pick that. We We didn't want to call it latency overload or working latency or other variations on that. Because Our goal is to measure that to equality. And to focus in version 1 of the tool is application layer responsiveness under normal network working conditions. In other words, sharing the network with capacity seeking flows. That is an important thing. It's maybe not the most important But it's not the only important thing. Probably is the most important thing, but not the only important thing. So as this evolves, I can imagine the network quality tool measuring other aspects of network behavior, like does it support ipv6? Does it we could make a long list of things that we believe make for a good network, does it support path MTU discovery? And in this community and this working group, we could figure out some weighted average to put all those numbers together in some aggregate network quality score. So the intention is that when you fetch the JSON blob. From this well known URI. Right now, you get back the configuration about how to do the responsiveness test. But that could be involved in the backwards compatible way over time to to do the other testing that we want. So that's that's kind of the idea. It's a approved. Okay. Makes sense. So I did look up. So Mark Nottingham is the one expert on that. Okay. So it may be worth just talking looking at the current registry there, there are some that use very abbreviated in names and some that write it out."
  },
  {
    "startTime": "00:32:00",
    "text": "And, you know, since the URI, is not necessarily a constrained space. I'm just wondering, like, could it just be network dash quality or or or maybe worth asking case there's any opinion. For for for the dinner serve discovery, service type, it was NQ. Oh, okay. Because those names are more constrained to be 14 characters or or or fewer. And I think this was picked to be the same for consistency, which and that to keep it the same. Mark and I Mark nodding him. Chair of OTT to be this, I think. Alright. Alright. Thank you. Alright. So I think was that Greg again? So Yang. Step. Felter Okay. Okay. Please help me. Okay. Next, Okay. So, the document temporarily expired, but I appreciate the Rakesh, taking effort. And, it's a real example of community service reviewing the exported document. Thank you. I needed that. So and, as well, Rakesh agreed to join as a call for on this work. So, we'll now work together. To improve it. I have renew the document. It's not final. But it already has, some constructs that I think that will be useful in the model. And, I appreciate your inputs. Take a look. These are, related to, our agreement to include, stamp extensions, into the model"
  },
  {
    "startTime": "00:34:03",
    "text": "So that's our extra padding, class of service, direct measurements, HVAC TLV, what else? Access, reporting, location TLD. So, these are all in, I think it's rfc8972. So, that we agreed that will be, part of the Stampiang, model. And, as I mentioned, so we work on it and not let it expire again. Okay. So, so you see that, features listed that I mentioned, and, all of them are now, formed as a container. But again, this is work in progress. So, take a look at the latest version and, share your comments on the list. Here. Next. Yep. Next. So Just, these are examples. It's it's not, everything that's there, more changes. Okay. So, hopefully, we'll have, the good table version, before their, next meeting. And, will ask for young doctors review. We had the early. Yeah. And doctors review, I believe that those comments should be addressed. But, now need to do, stamp extensions properly. Thank you. Do we have any questions, comments on this work? Otherwise, people please, have a look at the document now. Make your reviews and, yeah, look forward to seeing you. Reviews comments, questions. And still open for cooperation. Thank you. Thank you."
  },
  {
    "startTime": "00:36:08",
    "text": "Moving on to stamp good afternoon, everyone. My name is, and, I'm presenting this 00 version of the draft, it's a step extension for IOM So IOM had, this active measurement, text in the in the RFCs, and this is basically using stamp for IOM, there are, many generic applicability of it as well. So we'll look at it. There's some good discussion on the mailing list as well. Next slide, please. So agenda, we look at the requirements and scope. Summary of the procedure and the next steps. Next slide, please. So requirements is it is, the a foremost measurement using a stamp. Is basically, leveraging the IOM work that's done by this working group, to do you know, hop by hop or s 2 edge measurements, The goal is to leverage the existing implementation that's out there stamp has a requirement for, asymmetric packet size. Until the work that, Greg completes for the asymmetric. We try to avoid the protocol extensions for ipv6 PLS site. And we make the stamp year, we generic, such that, we kind of future proof for all the, extents and headers, you know, 6 and MPLS. The the scope is, stamp, stamp extension, IP with with 6, options and then PLS, M and A sub stacks. So there are various IPS 6 options. That's"
  },
  {
    "startTime": "00:38:00",
    "text": "applicable, including the IOM or alternate marking or the slicing, for ipv6andmanda. How they are used. We we can discuss it later. Next slide, please. this is an example for the ipv6 data plane. So So idea is, is fairly simple, straightforward. Asymmetric stamp like a size. So, basically, sender will add empty stamp TLV. These are, just the same size as the ipv6 options in this example. And it's empty, because the reflector will copy the data from the absence into that and, send it back to the sender. So this is, a way to get, IOM data the forward parts back to the sender. And, again, the reflector will add, options in the reverse direction as well. So this is the very basic, idea next slide, please. And works the same way for MPLS data frame. There is a M and A substack, Extensive header kind of work. It's a working group document. So we would do the same thing with the MPLS data plane as well. Next slide is. So there there there were good discussions, on the mailing list for comment, Greg Mentioned that, maybe we want to do the measurement forward direction, but not in the reverse direction. So there is, some work that Greg is doing as part of asymmetric packets. With the reflected test packet control TLB. So, one idea is that, we can add a sub deal. We and say, it's an extension header control, sub TLV. So where reflector will only insert those, excess and headers, if it's, requested to do so, otherwise, it won't So this is one idea. It's not in the draft, and welcome your, comments on that. Good thing about this approach is that stem packer size is still, symmetric in both directions. Next, sir, slide please."
  },
  {
    "startTime": "00:40:04",
    "text": "There is another comment, from, basically, to say why not combine stamp TLVIS into 1 big stamp TLV instead of having it per per op, ipv6 option, for example, the other comments, or the, the the discussion is that maybe reflect that doesn't want to reflect all of the extents and headers. So sender doesn't want to reflect all of them. And it will only insert the MTTLVs for which it needs the data back. So, this was the, idea suggested as well. If you have any comments on that, please let us know. This is not in the draft both comments, we have not addressed yet. It's still under this case. And next slide, please. So if you go if we would have to, INR request. 1 is the empty stamp TLVs. For ipv6 1 and 1 for m m and a. And another would if you go with the asymmetric, packet, still an individual draft, but if you go with it, then we would have a subtile bit for it for the extra header control. So we have Sean name in the queue. Do you wanna take your question now, or do you wanna take questions to at the end. I think this might be the last slide. Okay. Let's take the question, before we go there. This Hello, Charlene from CTE. As I, replied on the mailing list, I'm not convinced that, the multiple, stamp Tovs, is the better choice, for, this function. I can think of, application scenario if I'm, a stem center and I want to the statute of effect, to to effect, some fields outside of the"
  },
  {
    "startTime": "00:42:02",
    "text": "just, like, IPV 6 option. Like, ipv6flowlabel, And, how can, this mechanism work for that scenario because I want to monitor the the flow label relationship between the flow label and the actual forwarding pass of the stamp test packet How can I achieve that? So I think, it's a good discussion. And CNN is also, here. So maybe we can have a a meeting with 3 of us. And we can, make progress, that way. Okay. Thank you Yeah. I hear you. I understand, you're you're comments, sir. It's a good comment, by the way. Thanks. So just wanted to take this opportunity to also, socialize the, couple of other drops, for stamp. There's one in the spring, where we have a, extension use stamp. There, there's look back more defined for stamp as well as as loopback mode, which is adding time stamp and forward the packet. Some something like IOM concept there. It's an interesting, extension there. And the second draft is the using, the MPLS, generic resources and channel types defined. We are presenting the draft in MPL assessment on Thursday. So both drafts, welcome your, comments and suggestions. Next slide, please. So thank you, Greg. Ken Ran, you mean, for your comments and suggestion, has agreed to joined as co author. So welcome, Imran. We'll update the draft with the suggestions. There are some good comments. So we'll update them. But welcome your additional comments and suggestions, and, we would be working, working with production for Right. And that sounds like a good"
  },
  {
    "startTime": "00:44:00",
    "text": "time to do this. So we can start by just, a simple show of hands in the room here, like, how many people have read this document already? Okay. That's quite a bit. So let's do, I'm gonna use the show of hands too to see to let people indicate whether you think this, work is, is useful to adopting the IPPM working group. So and the 2. Yeah. And the 2. Let me just see. Where do I find there? Show of fence? Let's see if this works out So, yeah, please indicate whether you think this document is ready for working group adoption. And, if you don't click anything, it means you have no opinion. So you're defaulting to that. We'll give a little bit more time. 5 So the sense we get that there's quite some favor of adopting this, but we have two people who who click no here. It would be very interesting to see if you have any comments you wanna make about as to why Sorry? It's, 5. Yes."
  },
  {
    "startTime": "00:46:00",
    "text": "2, no, 54 without opinion. Richard foot. Hey, footer, Nokia. I like the work. I like where it's going, but I think it's too early to adopt it personally. I think it's got a ways to go. You've got some comments still to discuss and some work to do. So I just think it's a better I like the work. think it's too So you think the it's too much work to handle through an adoption call. And I Yes. No. That that's useful feedback. Yeah. Anything you wanna say about that or So we have couple of comments that's, another discussion on the mailing list. So we'll resolve that and we'll update the draft. And, we'll come back with the revision. Right. So so that that would be a good approach that, yeah, Yeah. Handle these comments, provide a new revision, and then we can talk about when it's appropriate for Yes. Sounds good. Yep. Thank you very much. Thank you. We have stamp extensions for hop by hop. Yep. Hello, everybody. I'm presenting on behalf of the quarter. Of the stamp extension for hop by hop data collection. So next slide, What is the motivation for this draft? Yeah. You all know the stamp perceived and that enables active measurement of one way around trick performance between a server and a reflector. Anyway, the performance of intermediate nodes are not available. So considering the reference model, defined in the RFC 8762, we want to add a new recommend that is the intermediate notes. This document, therefore, this document introduced optional TLVs to enable this whole bio performance measurement on each intermediate. No."
  },
  {
    "startTime": "00:48:02",
    "text": "And the format follows, of course, the standard TLV, according to the RFCA 89 signature. Next slide. Yeah. These are the TLVs that, the documents define, So the information is collected at each intermediate node. And then sent back by the reflector to the sender. We, we started with 4 TLVs, the hop by up delay TLV, the times to record the ingress and egress time stamp at every intermediate node. The hop by op loss Tlb that records the number of the pockets received and transmitted by having intermediate note. The help by our bandwidth TLV that records the bandwidth utilization, and the interface errors still weak. Of course, this is only a first proposal. We are open to add additional TLVs or to improve that one. So we are open for feedback. Of course, this DLB can be activate selectively according to the need and what we want to monitor. So, we don't need to active all the TLVs together. Next slide. So, yeah, in a few words, if we have a stump a session between a sender and and a reflector, and we have different intermediates node. If the intermediates node can handle the these extensions, the draft introduced stamp without bio capabilities in order to measure the different bio delay for each intermediate node and what are the the advantages this simplify? The configuration of the node on path. And also, it is quite collector independent because the add the node can quickly get the collected data. Next slide, I think, is the last one. Yeah. Just, the changes about from the latest version. So we had some comments"
  },
  {
    "startTime": "00:50:02",
    "text": "at in San Francisco and on the list. The draft has been revised to cover only the stamp extension because in the first question, we all we we also covered the IIM data extension, but now the IRM data is covered by the draft that was presented previously. So we clearly separate the scope and focus only on the hop by hop extension here. Next slide, Okay. Comments are welcome, man. Yeah. There's a shrink. I have one quick one, and I've not wrapped the draft, but how do you do integrity protection for the T OEs? For now, we We consider the security of stamp. Of course, This is something that needs to be improved, the security part. And, yeah, Okay. Actually, yes, I I grew Giuseppe. Stem has, HVAC TOV that can be used for TV, identity protection. So it doesn't have to be Stamp authenticated mode. So basically, stay can be used in unauthenticated mode. With HMAC TOV using to protect 2 of these. But, I have an different question. So since, as you mentioned, that, you intend to, discuss I am use use of stamp and I'm in combination in a separate document. So how you envision that stamp, supports hub by hub. Because, Although stamp can have, destination port of well known 682 over UDP. It's as well, can be used from the Martian port. Range. So, basically,"
  },
  {
    "startTime": "00:52:03",
    "text": "then, how the transit node will, recognize that this is a tier v pack. Stamp packet. We we didn't define this yet, but I think that it can be configured as for the stamp. The base stamp. 80. We can add this new element. And by configuration, we can defined that this new intermediate node can list them on that part and can be configured to handle that kind of Yeah. Because, you know, when my my understanding of this proposal when it combined with I am I thought that I am provides this hub by hub, elementary information. But if you foresee that it will be a different document then, I think that it will be bet good to have, more clear, at explanation of how you want to do hop by hop with the stamp and alone. I agree. I agree. That's why in the figure, I put the intermediate node in the stamp framework. To see that the intermediate's no need to be part of the stamp extension in order to to be configured to read the TLVs. Otherwise, I agree with you. It's something that also for security issue Okay. So, okay, so let let's see. Next versions. Thank you. Let's discuss Wolfgang Beck. I have a related question. Who sets the egress time stamp it a control plane or the data plane or who is supposed to set this time stamp in in the hop on hop high up on intermediate notes. It's also depend on implementation on intermediates node. We can consider that It can be quite complex for the data plan to get into a TUV"
  },
  {
    "startTime": "00:54:01",
    "text": "yeah, somewhere in the packet. So you put it in the control plane, it's not accurate. Yeah. Should should probably should be control plane, but it's up to the implementation. So for now, we we didn't investigate this part of the problem, but, of course, we can consider. Alright. Thank you. If no more coming, thanks a lot for presenting this. I think there are some interesting issues to keep working on, and, we look forward to see more updates of this document. I think it would be interesting to to think a bit about, security properties and how to handle authentication and integrity protection. Yeah. Okay. Good stuff. Thank you. Thank you. Then we have quality of outcome. There's Wolfgang in the queue. Was that a comment on the previous, or you're fine. Yep. Just remove you. Yes. Alright. Thank you. Name is Birnie Wertagen. I work with the Domos, a latency management company. And I'm here to present, 2 drafts, actually. So next slide, please. These are just the links So next slide. Okay. So this is the first, the first draft at least, requirements for a network quality framework useful for applications users and operators, And the objective of this is to outline the essential features. That such a framework will have to have to meet the needs of these 3 different stakeholders. And as we see it the main"
  },
  {
    "startTime": "00:56:00",
    "text": "needs of these 3 stakeholders are for the end users. That's something that is easy to understand and int intuitive So a simple, score of the network quality For application developers, we think the the most important point is to have something to have a language to express requirements so that if because different applications have different network requirements, there needs to be a way for those differences to be articulated. And for those specified requirements to be compared to actual network measurements. And then for operators and vendors, we think that having something that is, useful, for troubleshooting and optimization are the most important points. So what this document does is to list a bunch of different network all the metrics, and evaluate them on these different requirements. And we conclude, basically, there are no frameworks that capture all of these needs at the same time. And we identify a metric that is doing a very good job at at the operators and vendors part. So it has troubleshooting and optimization. Sort of figured out already. But it's lacking on application developers and end users. And that brings basically brings us to the next draft. So next slide, please. I'll go into little bit of the the metric that we identify as as a good potential to build on. Which is the Broadband Forum standard, on quality attenuation. And this standard specifies a quality metric, how to measure it, how to report it, it has in my opinion, 2 features that are, are very desirable."
  },
  {
    "startTime": "00:58:01",
    "text": "The first is that it's compostable. So you can measure different segments and add them up. Or you can measure the end to end and split it up. So they'd and that's a very, you know, good feature to have if you want to identify the specific link or component in a chain that added, or that contributed most to an end to end problem. Or if you want to analyze the effects of upgrading parts of your end to end chain. And the other very useful, feature in addition to composability is that it's based on probabilities. And that's important because some network technologies are inherently random like Wi Fi. And others are them because your performance is affected by the behavior of or the other users of that component or link or router or whatever, whatever it is. And so the best we can do in terms of describing the behavior of that component, is to model the distribution of of likely outcomes, basically. So this, quality metric is both compostable and based on probabilities, which in our opinion are make for a good foundation for this this framework that we want to work with you on. So next slide, please. So this is basically the project for the quality outcome draft. We want to find a middle ground between this quality of service, how, like, measured specific metrics in the network and, the quality of experience of the end user. That involves the two steps. We have to figure out how applications can express or how to express the needs of different applications, whether that is us making that, choice or the application"
  },
  {
    "startTime": "01:00:00",
    "text": "themselves. It doesn't matter. There has to be a language to express network requirements in a way that can be compared to the actual measurements taken in the network. And then we want to make that so so that we can both do that and also create a very simple score that we can present to the end users and say, like, this is the summary of what we've what they found. Next slide, please. So this is the the the details of what we are proposing. Before I describe what you're looking at, I I wanna emphasize that this is our first attempt and a suggestion for how this can be done And we recognize that we can't do this alone, and we shouldn't try to do this alone, which is why we are, bringing it to IPPM. We want feedback from the community, from, the application vendors, from from people working on network quality from from the entire ecosystem. To contribute so that we can make it work in, as many different scenarios as possible. What you're looking at here is on the x axis, we have latency, and then on the y axis is a CDF. And the blue line is is the measured delay or quote attenuation, if you will. Of of a link. And that's the actual measurement from the network. And then the application language for describing the requirements are visualized here as these black horizontal lines. And the idea is that if the measured delay is lower than the 100 on each of these lines, Then we say that the application is happy with the network, the application, basically says that if the network is this good or better, then we can assume that the network is not degrading their their user experience."
  },
  {
    "startTime": "01:02:02",
    "text": "And then on the other far end, on the right side, where the zeros are is basically the application saying if the network is this bad or worse, then we are absolutely sure that the network is now causing issues and they are the end user is having a bad time. Basically So Big So the the language for the application requirements here is basically a list of of for each percentile or for a set of percentiles, what is the Perfect. What is the useless latency, and then different applications can choose different percentiles here. And different thresholds for each of them. So this is a very flexible way to express, requirements. And it can be compared directly to the latency distribution of the actual measure measurements taken. In the network. Alright. Next slide, please. Oh, sorry. Go back. I forgot one thing. And the way we we can translate this, so Here, we have the the call it a measurement. We have the application, requirement. And then the way we arrive at something that is intuitive death the end user is basically looking at if the measured if the blue line measured delays, are worse than perfect, but better than useless. So that means it crosses at least one of these lines at some point. We basically just take that point interpolate between 100 and 0 and report that as a score. And that gives you a nice 0 to 100 number to report to the end user saying this is how good your network is right now. Next slide, please. This is the implementation status. We have,"
  },
  {
    "startTime": "01:04:00",
    "text": "a C Library, and we have, an implementation in the Go responsiveness client. That Will Hawkins is maintaining. Which also does the the responsiveness metric Stewart was talking about. Next slide, please. And this, these are some other implementations that we have, made Dumos. So we have in the teams. Teams has an app store. And if you go to the team's App Store and search for network X-ray, you will find an app that measures your network quality alongside your team. Team's calls. Calculate the score for a network requirement that we've worked out ourselves. Basically shows you your network quality in real time. And if the other people on your call also has the app installed, then they're scores are reported as well. So you basically get real time network quality for each of the participants in the call. And then we also have the same thing for, crow as a Chrome extension. If you go to the extension store or whatever, search for network X-ray, you'll find this plug in that ops up in your meet calls or Webex or zoom and, shows you the quality of your network connection. And so this is just to show that we are using this with with some applications. And we are trying to tune everything so that it it, the the score that we observe actually translates well into the user experience, and we're having some some good early results with that. Okay. Next slide, please. So we propose, working group adoption call for this. And we welcome all contributions and criticism questions and, Yeah. Yeah. I'm excited to to work with the the IPPM group on this. Thank you. Thank you for your presentation. And we did have, okay, Let's start with some questions and comments. We have Luis"
  },
  {
    "startTime": "01:06:01",
    "text": "Yeah. Hello, Grace from Telefonica. One question of your this would be could be useful also for measuring the impact of the terminals. I mean, because you are referencing continuously to the network part, but I guess that those, I mean, also the contributor of the terminal, the PC, or the the mobile also could be also assessed with is kind of too bright. Absolutely. If you can If you can instrument it and do the time stamping at each point, then, yes, any any step in the end to end train from the application to the server and everything in between ads delays or packet losses, If you can count them, then you can use this framework, basically. Okay. Thank you Thank you. Right. I had a just a question, not as a chair, just of curacities. On the on your, score metric here. So here you show an example of crossing one of these lines. If you were to cross multiple lines, how would you output score, would you would you would you sum up the interpolations or or Good question. So the way we have chosen to do it now is to just take the worst one Okay. Yeah. That makes sense. So but that is we found that works fairly well, but it's I wouldn't say that's, necessarily the the final version of that. Violence, Muran? We can't hear you. Can't hear you yet. Alright."
  },
  {
    "startTime": "01:08:00",
    "text": "Okay. You know, madam, you may wanna check your microphone alternatively. If you wanna type into the capped. I can relay what you wanna say here. Yes. Okay. Yeah, we're we're not able to hear you. So if Oh, and some video. Yep. Okay. Yeah. Please either drop something to the chat into the or, send an email to the list on that. K. Right. And just just one other question I had you know, I noticed, like, in the visualization of the tool, you had, you know, this network quality and earlier we heard from responsiveness, which is also calling it to the user as network quality. How do you see those things being complementary or not and and and the differences also in your mind how you would describe that. Excellent questions. So the way I see it is responsiveness is an active test that you run I mean, you can run it often if you want, but it's an active test. The net the network latency monitoring that's, defined and, and standardized by the Roman Forum is, designed to use a very low bitrate background flow. Or or a few. So that can be run like as a 20 fourseven monitoring thing. And So they're complementary in that way where the the responsiveness thing measures responsiveness during an active speed test basically to generate, congestion Whereas, this tool will work with basically monitoring latency alongside the background"
  },
  {
    "startTime": "01:10:01",
    "text": "traffic that the user is generating for their just normal day to day threats, connectivity needs Could you calculate your, you know, quality of outcome graph for particular application with either data source, though, like either a passive or, like, active. Does it Yes. Okay. Yeah. We can view it as that. And correct me if I'm wrong, but it seems like know, the graph that you have here, these are based on parameters specific to this application of this application saying I have these constraints And therefore, this is how I successful I will be given the quality as opposed to having an overall quality of network score that is application independent. Yes. That's a that's a good point as well. Yeah. Stuart, would you like to you made a comment there, and I I thought it was worth adding on to that because it is something that comes up favor people some people have got the impression that the question the network quality test. Because it saturates the network. Mhmm. And there are these other tests, like you said, the broadband forum, can run 24 hours a day in the background with a very low data rate. And I'm gonna be, you know, sort of humorous hair, but The problem that a lot of people face is they're on a video conference call. And they download an app. And that video conference call goes to help for 30 seconds because their network can't do two things at the same time. And Now, We we have built her Datagram based packet switching network that's supposed to be to share a network between multiple clients, but the reality today is it it can't do more than one thing at a time. So are lots of these tests that I describe as they tell you how well your network works. You're not using it. And knowing that my network is great while I'm asleep, it only sucks when I'm using it."
  },
  {
    "startTime": "01:12:04",
    "text": "Isn't really helping me. 99% of the time, my network might be perfect. And if the only one percent of the time it sucks is when I'm doing stuff on it, being told it's 99% perfect. It's not helping me. So the network quality test is precisely focused on testing. Does this network stand up when you push it? Not Does it work fine when it's not being pushed So I just wanted to explain. I I know you understand that, but just when this comes up, I I sometimes hear people get the impression and say, well, that's not a fair test. But in fact, just last week, Greg White from cable ups was giving a talk at the Wi Fi Alliance. And the response you got from the rumors well, well, you can't expect your networks to work well while you're doing a download. Right? Yeah. I totally agree with Stewart as well on this. Yeah. Imagine if you are passively measuring at the 99 percentiles is someone is downloading. That will be captured somewhere in your graph. Passively, but it Yes. And, I mean, the timescales of this does matter. If you you do one CDF for the entire, like, 24 hour of a day. Then it's gonna look better than it really is when it's at its worst. You could do something like take the worst 10 seconds. Or take the worst minute or something like that. Depending on on your use case and, then you'll get more, realistic results. Great. So we did have one adoption call for this. Work, and, I mean, last, you presented it last IETF, and we saw quite some support in the room. We did an adoption call, and it was a little bit, of silence there. We got a very good review from Greg and good partners that were very thankful. We would like to urge everyone who is interested in this work and who thinks this this work is useful for for the APK and working group to to take on to to actually read this, read this work and and,"
  },
  {
    "startTime": "01:14:00",
    "text": "provide your feedback. And we think we should reopen this adoption call again. But please, please the opportunity to read this work. Yeah. Thank you very much. And if anyone wants to discuss any part of this, please reach out to me. I have, time to to spend talking on this. So Thanks. And Let's see. what's the next? It's Okay. Please Hello again. This is about the alternate marking deployment graph. So, yeah, this is the first update after the first version. So next slide, you know, just few words about the background and motivation, you all know that the base documents about the alternate marking were already published as standard documents. So I can mention Fc9341,934 29343 for the ipv6 option. This draft aims to provide guidance for the real deployment since sometimes when we talk about alternate marking in IETF, Always people ask about deployment issue, how to deploy, how to manage. So these draft things to clarify all these aspects. Related to the deployment domain, the measurement notes, the type of measurements, and especially, so the main focus is about the manageability and configuration aspects. And that I spoke So regarding the configuration, of course,"
  },
  {
    "startTime": "01:16:02",
    "text": "you can use young model, PCP, BGP, and that I export, we are working to the AP fix extension and to use young push. Next slide. So, yeah, the first the the main points, of this draft is to clarify the applicability in a controller domain. This is already explained also in my 3411343 according to, RFC C8799. And the, we also clarify that the typical deployment domain is normally an overlay network where traffic is a cap encapsulated that one domain border and encapsulated that the other domain border. The domain, of course, consists in a marking notes and and and and marking notes that are the border router of a deployment domain, and we also have transient nodes. If you want to make a question, please. Yeah. Well, maybe, this is Frank. So I think you probably remember the, the hoops that we went through with IOEM on limited domains. That that that 8799 is not an IETF document. It's an individual draft. Yeah. Yes. And, so the the recommendation is to define your own control domain. So there's no such thing as a domain and and the likes. So given that there is a little sympathy at the ISG level, for 8799. I would strongly suggest that you No. No. Thank you. Thank you for calling the instead of referring to a document that not considered an IT. Thank you for better than that, Matt. We already did. It's more of a of a of No. No. No. No. What we need to do right? So it's more. Now it's good that point that out because we have the same we have the same problem with the 9341 and 9343 And we definitely we have already defined the controller domain in 90 41, and then 343 If you look at the RFC 9341,"
  },
  {
    "startTime": "01:18:02",
    "text": "that is a standard document, we have defined. And I know that you did for IIM. So and we have the same problem. I just put CRF C8799 because it explains let's say why this kind of on path measurements should be done in a limited domain, but I fully agree with you Yeah. I I agree with, Frank, that, the question of, limited domain comes up, too often. In the discussions. And the best of my understanding is plans to do something about it. Yeah. That's what Just one short comment. Try to make use of the queuing tool when you up to speak because it helps him. Yeah. also to answer Greg point, but Again, we already addressed this point in the alternate marking RFC. So we already explained, and maybe we can reuse that definition. Without referencing any more the head of CIT 799. So to continue with this slide, we also explained the type of measurement that can be done by using one flag and 2 flags. So and what's is the measurement that we can do. And in particular, we they find the kind of information that can be derived the measurement frequency and the computational load in order to give also more tools more, information to decide whether it's better to use one flag or 2 flags. Next slide. Yeah. Regarding the configuration aspect, we basically referenced the work that we are proposing in IPPM as well and is a lightning tool later. That is the young model that can be used for the definition of the named Mark Datta for Net Conforesconf and also the control plane mechanism to achieve this"
  },
  {
    "startTime": "01:20:03",
    "text": "capabilities. So in particular, we are working in IDR, for the SR policy for BGP extension, the BGP feet capability extension and the PSF extension. Regarding that export, we are we are also proposing the IP fix extension in, but, I guess, also, a PPM should review this draft. In addition to epifix, also young push can be used. We also specify that and additional information that must be included in data export is the period number in order to make the collector, aware of the period ID, and this can allow the the correlation aspect of the marking. Of course, we also add more information about the available encapsulations and security aspects. Again, don't worry about that. If C8799, I would okay. Next slide. Yeah, just, I summarize changed from the 00 version. So we got several reviews and comments from Chang Fan, Greg Thomas, and Masimo. We, the new section in on configuration, we revise lots of the part on that export. And new section also in, implementation parts. Next slide. Okay. Yeah. We consider that this draft is quite useful. There is also related draft, where there is an IOM deployment. So we believe that this draft is also important because give the full picture of the deployment part. So, a reader and possible people that is interested in this methodology can have a single document"
  },
  {
    "startTime": "01:22:00",
    "text": "with all the information about deployments or comments input suggestions are always welcome. So thank you. Alright. We have Martin in the queue. Martin Duke, Google. So do you guys have a like, a data plane for this Because I mean, I remember in 1941, and it was you know, here's a way that protocol developers could add these bits if they wanted to add them. Yeah. Then we have some has somebody actually added them? That data plane is the RFC 9343. That is the aipv6 extension Okay. It can be used for a PV 6 or for a service 6. are also that is RFC that is already Okay. We So there's an extension headed deploying these things. Yeah. Yeah. There are also other extension, but they are already they are still in progress, not yet progress as a Fc. So the only, let's say, data plane extension is the ipv6 station. Okay. And the SRV 6, of course. So, I mean, I I just was looking at your laundry list of, like, stuff we're doing, and it's kinda thought we we did a lot of those things in 1941. Like, a lot of, like, hear things you can measure mean, I mean, I've been I've been obviously I've obviously not read your draft. I'm little disappointed that we just did 9241, and it feels like there's a lot of cleanup that needs to happen. It's my my impression from your talk without having read it And that's And that's Not great. Not great. Frankly. We we what we want to cover here is only management, especially the management part, because, you know, if you you helped me a lot with 9341. Yeah. And you know that we didn't cover how to configure. Maybe you also asked several times. How to configure, how to export data. Okay. And this is what we want to address. Yeah. Explain now to do. Of course, sometimes we also only had the pointer to other draft because we cannot define the PB6 extension here."
  },
  {
    "startTime": "01:24:03",
    "text": "Yank that model in this draft. Yeah. Okay. Yeah. Doing yank models is is fine. Like, the configuration is fine. There's a lot of bullets on one of the slides about things that you were I read is being addressed in this draft. I thought already addressed in 934x. But, okay, thanks. So, Right. Could we have a quick show of hands? How many people here have read this document? Quite few. So, yeah, we could, consider moving forward to a working group adoption call at some point. And get to come. Thank you. Alright. And Greg? 3rd time the chimney. Alright. Okay. So, this is update, to the, work we presented first in San Francisco. Good. Next word, please. So, their original thought was that to do, control the reflected, packet control, from the, session stem session sender in order to, enable, rate measurement And for that, So we need to be able to their size of the packet. So, different from their symmetric size. But at the same, rate and number of packets, reflected by, session reflector. So, next slide. In in the course of discussion, we realized that if we set the number of reflected packets to 0,"
  },
  {
    "startTime": "01:26:03",
    "text": "then stamp turns in a one way measurement protocol And then, the data, the measurement data raw data or process data can be fetched or, process according to local policy So one interesting, use case for this. Next slide. Rakesh mentioned that, and we discussed it on the list between the meetings that, in combination with this, using, the return path as a sub TOV for the reflected, test packet control TOV. They're packet can reflect it to, what's characterized in lmap. Our texture as a collector. So thus, this information can be raw data sent to the, collector for the, network and elite in processing. Again, might be an interesting use case. Optional. Next slide. So the rate measurement that was our primary interest in starting this work. And, as you can see, So, what's expected of their measurement mechanism by our 7497. Is this, extension is conforming to that. Provides, all the controls that are necessary to, do the rate measurement. Next slide. So, as we've, mentioned in meeting in San Francisco. This extension can be used in, testing in a a multicast environment. And, already that version that we discussed in San Francisco, has, some"
  },
  {
    "startTime": "01:28:04",
    "text": "subtos, to do the filtering on there too and there are 3 information to minimize the amount of, responses being sent. To the session. So in this, version, we enhance their security consideration specifically for that. And one of them is that their source, the identity of the session sender must be, protected. So that can be achieved by, several documents, for example, session reflector can use, access control lists. Also, stamp can be used in authenticated mode. Or, HVAC, TLD can be used to protect the integrity of their TLB extension, staff extensions. Next slide. So, with that, I think that now the document is more complete in order to just to present, their proposed solution we welcome, your comments reviews and, ask for your consideration of working group adoption. Thank you. We are Rakesh. Rakesh Gandhi, Cisco Systems. So I have read the draft well written. I think it is ready for working to production. I have very 2 small comments. Actually, thanks for addressing comments from the last, idea. One comment if you go back to the slide for the one way It's very early. Yeah. Yeah. This one. So we just, publish RFC 90 50 3, and it has a control code as well. And, I think it has a value if you share this value, then no reply packet is sent. So that's also another one way of doing stuff. So just to"
  },
  {
    "startTime": "01:30:02",
    "text": "just to maybe clarify the interactions and stuff. Okay. Just wanted to highlight. And the second thing, if you go to the next slide, please. Yeah. So this one is sending the the packet to, uh-uh, controller, I think. So There was a security consideration basically, the destination address, is there is a tax 99503. There are 2 texts. One is that the destination address is a local on the session center. And then in the securities, uh-uh, consideration, it says that, the address that is, the destination address, that you sent to is controlled by an ACL. To avoid any, attack. A spoofing kind of stuff. So just to con it is a valid use case. It's good just to say you may wanna clarify the security. Yeah. Actually, We will look at this, but, we took example of your discussion in this, newly published RFC. Congratulations, by the way. And, So that's why we said that their identity must be, protected. But there are several, methods to do, including ACL including use of authenticated mode and including Hmac TOV for integrity protection of extension. Okay. That's perfect. And thanks. Thank you. Welcome back to telecom. If you look at stem document, there's always this ominous management and control plan above the stem components, why can we use this control plan instead of instead of, using as a stamp protocol itself for control of a Yes. Starting with us. That's a good question. Of course. Yes. Some can, think of augmenting stamp, yangmodel"
  },
  {
    "startTime": "01:32:00",
    "text": "to do, this particular, mode of, Test session. But at the same time, this is not our options. You know, it's like there is not one way to slice the bread. Okay. But, yeah, absolutely. Your your suggestion is a valid suggestion. So with regard to the security requirements, you have young, you have already or some other integration management plan. We have security measurements there. And you don't have to reimplement it in the in the process. Well, Actually, Again, there are different approaches to, configuring, session reflector. Because, some prefer to make, like, a promiscuous mode. To creating, sessions on session reflector. So without specifying explicitly, the identity of the session sender So Again, people prefer different ways to do things. So But, yeah, I agree. It's can be done differently. Not necessarily only one way. Rakesh? Rakes, just to answer, I think the one reason did this written part, was, there is a full reflector and there's a stateless reflector. And I think a lot of this thing, was for the state less reflector. So you don't have a lot of states lot of control. So the this is why this work, is is useful for the stateless Right. I I grew the Rakesh. So, basically, it's in in in the way we can consider it to be this, using options to do, data path can so to control the test session in a data plane."
  },
  {
    "startTime": "01:34:00",
    "text": "Similar to what's being done with service programming using, segment routing, for example. Don't know if this analogy works for you. Alright. Thanks a lot, Greg. Yep. So again, welcome comments and appreciate your consideration working group adoption. Thank you. We will now move on to the lightning sections. And version of vision of hello, everyone. I'm Xiaoming from ZTE this presentation, it's a performance measurement for necessary, please. This chapter was submitted to a new 3 working group, and now it's moved to RPPM, because, you know, mbo3workinggroup is keeping, the flow is keeping low and, in this job to, stand is you used as the performance measurement, test packet, for tuning a tunnel. So when only this worker this working group, And the Here, you you can see, the encapsulation, for stamp over IPUDP, over, And in this draft, in this figure, the stamp has packet can be, stem searching standard test packet all the stem, session factor, test packet at And for the, stem session, demarketbalancing, if, Sam, searching ID in the stamp, test packet, you close to, 0"
  },
  {
    "startTime": "01:36:01",
    "text": "then, that you need, you VNI number and, in their IP header, should be used for the demultiplexing. If the, stamp session ID is a nonzero, value then the same session ID, must be used, for the de multiplexing. And that site is I hear, This figure shows the, step over, ethernet IPUDP over to need, encapsulation. And the the stamp, de multiplexing mechanism is similar with as the 1, for details, please read a draft necessary side. Yes. We asked for more reviews and comments and the way our revise is charters to remove it, to improve it, and, maybe ask for a working group adoption 10. Adding, question comment. No. Thank you very much. Sure. Thank you. Next up. Sophia? Yeah. Hi again. I can be quite fast here. Is related to the previous draft on the deployment. So we aim present the young data model for the alternate parking meter. So next slide, and just prepare this line. So, yeah, what I want to write here because there is already a draft on the young data model. That was proposed a few months ago, but we proposed this new young data model just because we want to follow the same structure that was already consolidated with the IOM, young model. So we believe that following the same structure, we can in some way, facilitate"
  },
  {
    "startTime": "01:38:03",
    "text": "the deployment of this zone path parameters and see since the IOM that the model has already been adopted is approaching also the, the publication. So we believe that following the the same structure can help, the implementation. Just few words about the the detailed information. So, of course, we need to specify the profile name, the filter, the protocol type, not the no action, the fluid identification, the measurement mode, And if you want to enable loss measurement and delay measurement. So please review and any comments and input, are welcome. I want also to keep the okay to invite the outdoor of the other alternate marking data model to join this work and to join our effort to, put this work forward. So Thank you. You. I I'd be get particularly curious to hear from some minutes, the author of the other document. Please. Shamil City, we have, submit young model for the ultimate market. You know it? So I I don't know. You mentioned it. Yeah. Maybe Webex can talk about it. I I mentioned, and I I I propose to March to work together to move it forward. Okay. That's right. Thank you. Thank you. Great. And then, yeah, as chair, certainly support merging the efforts here. However, I would note, note, we have frequently had some, Author count. Problems as we merge. So if we can please pick, like, one author from each document and have them be co editors. I mean, you have 2 authors on the merge document would be fantastic but please do, work together, and I think we would want to see a unified approach before we try to do any shit here. Yeah. Yeah. We can manage that. Thank you."
  },
  {
    "startTime": "01:40:00",
    "text": "Thank you. Hello. Yeah. This is, uh-uh, Alex Tim, then briefly, basically, a new proposal on an aggregation trace option, for in for IOM. This is John Burke with Lohome Metzka from OC, Next slide, please. So, the motivation of what this is about is And the the fact you signed with IUM. IUM does allow to collect certain telemetry data across hops along a path However, basically, any of the processing of the data, these are, of course, occur offline and also issues that that we need to contend with as we basically collect data from multiple hops and of all that the packer size may increase, and also that the data needs correlated in support process it processed further. One Now we do have a couple of use cases in which we would actually really like to aggregate where we don't really need to have the individual data point but where we are actually more interested in the aggregate. For instance, the average for the minimum or maximum to find out as you where's the bottleneck or where's the extreme along a path or also simply to sum things up for that if you want to add up, sorting latency information across path and and this sort of, item. And in order to accommodate that, we are proposing a new option in this draft aggregation trace option. Yeah. That would allow us to aggregate data during a traversal an aviation means minmax some average, increment these types of operations where basically the aggregate at each property is formed by taking a simple operation,"
  },
  {
    "startTime": "01:42:03",
    "text": "aggregates a local piece of data with the aggregate that we had so far. Next month, please. So, this this depicts basically the the the proposed data structure that we have here. Essentially, things to to to to notice, certainly we have an aggregator that is indicated, space the function that we want to use the and then busy met the metadata or the data being the aggregate itself as well as some auxiliary information such as load ID and to hop count. Anyway, so we we'll leave this compromise. I nicely, and this seems to be the right clinics or Thanks. 2 g. Hi. This is, Peter. Do here. I think that's definitely a very interesting working here. I actually have, you know, like this patch. I have, like, a similar, like, proof transit work, but definitely the most criticism that I have is that it gives more cost to the packet. And I think this, you know, with, just, you know, an overall, you know, not HIPAA help, you know, record could be, like, have many interesting use cases I think, this is for example, like choosing determining like, what are the carbon emissions of a path or, you know, minemax I think that's very interesting for many use cases. All. Thanks. Yeah. This is Frank. With with second, that is as useful. It's been proposed before and discussed before, and people I think right now are implementing this using this opaque steak snapshot or whatever we call this. Because it gives you the freedom to go and define whatever you you want. But I think if there is more people that need this, then I think it would be worthwhile to go and do this as a standard Thank you."
  },
  {
    "startTime": "01:44:02",
    "text": "And then Right? Sir. K. So the next one is a draft that was is actually currently in opsAWG, but we figure actually, it makes more sense. Like, can you put this into IPPM? Because this follows up on work that we had, here on the position availability rigs that Greg has, and has been also on where we currently have a draft and from a from IPPM in the ISG review. And, essentially, this work here of what this draft defines is it's it's complement or extents that work, concerning well, I mean, the the context, again, precision availability metrics And as a reminder, I believe you have seen this diagram before. The idea is that you have certain precision network and services defined by very fight service level objectives, and you want to make sure and you want to basically maintain statistics or keep track of whether or not these this this metric or this SLows are being violated or not. And if they are being violated, then effectively your high precision is not available unspacing precision availability metrics. And, essentially, what we want to do with this is we want to keep track, well, at key there, the key there is keeping track of intervals during which violations of this metric, of these metrics occur. And, so so basically we have this other draft this earlier work, which defines these metrics, but how to collect, retrieve and export those metrics was not defined there. And, certainly, this this draft comes in, it basically proposes a solution to extend IP fix to export these precision availability metrics. And basically use it when I prefix, why I prefix"
  },
  {
    "startTime": "01:46:01",
    "text": "well because it's finally used by operators to follow export flow statistics and why not basically having well, this is kind of like a natural complement to that. Next slide, please. So, and therefore, at the core of the document is really a set of new, I could fix, elements basically following the 2 categories, 1st category, basically defines information elements for the different, position availability metrics that have been defined busy in the in the other draft. This includes positive things such as the violated integrals, found violation free, violation free intervals found and so forth. And then in addition to those, we need to have it 2nd category, to reflect basically manifest information that provides the required context because, obviously, what is a violation or not depends very much on the a low, depending on how that is defined. And so therefore, you do need to keep track of the context of that so that you know what the violation is or not. So So that's basically the 2nd complimentary set of information elements are defined for that. And, yeah, so currently, Dine Information Elements defined. We did present this in IETF117 in opsAWG because we thought proximity to IP fix, which is an ops. This work is there. The feedback there was Yes. But the domain expertise sits more with ITPM. Hence, hence, suggested to bring this Yeah. Obviously, we would need to resubmit this with a new name. Depending if this work is welcome here. So I think that is all that I have. Next slide. Okay. Well, Thank you. Well, this is Frank again. I have a very stupid question. So, Have you implemented that, or and do you have ideas on how applicable that is."
  },
  {
    "startTime": "01:48:02",
    "text": "Because what we typically see is that we move out of precision if there's something going wrong and if there's something going wrong, the last thing that you care about is ip fix. Well, you didn't well. So to your question, just wondering that do you have any experiences with with actually building this. Okay. This, Greg, do you wanna respond to that? Yes. If I may. Alright. Thank you, Alex. It's a good question. So again, I think that, the precision in this terminology might be, somewhat confusing. The idea of precision availability metric is that it is a combination of, metrics, of potential metrics, number of, performance, thresholds that being defined for a service. So, applicability is for their multi SLO environment. So when SLA is composed of, several requirements for, various performance metrics So, that idea is that, be operator may in combination with the, service user can define, several metrics. And then they can detract as for the violation, which, exposes or, detects, the trend of, deterioration and then, constitutes breaking, this, service, basically, when the service deemed, unavailable. So that reporting is primarily targeted for, this critical area. So it's not that talkative basically reporting their benign information when, performance metrics are within bounds."
  },
  {
    "startTime": "01:50:00",
    "text": "So Okay? Notes. Thomas Glass Swisscom. So I have some experience in IPV implementation, and I can say that basically what your posing here is I don't see any problem to be implemented in the IP fix aggregation. Of export process. Thank you. Thank you. Alright. Of it. Alright. Last one. We're fine. Stewart? I'm gonna try to disappear. Yeah. I don't see this typing. Yeah, it was sent to you. Good afternoon, everyone. Thanks for, for staying until the last 5 minutes of decision. So my name is. I'm from Cisco Assistant. Okay. And today, I will, I will presenting, the, bus tracing solution. In behalf of the course or the of this draft. It's, this is a revision 5 of the draft. The first revision was submitted at IEGF113. And we presented there. So many thanks to all of the people who provides the you come in. Some of them already has been and, addressed in this, in this draft and the other one will be happy to, to talk more and, and address them Next slide, please. So quickly, because it's a lightning talk, what is pass tracing, So what it does, provide you is a record of the packet pass as a sequence of interface ID. And in addition to that, you, we provide record of the end to end the delay. Per hub and also the load on each egress interface along the packet delivery bus."
  },
  {
    "startTime": "01:52:00",
    "text": "A very key element of, of frustrating, in, presented in this draft. Is basically the design that was made for the hardware implementation in the pace, forwarding pipeline. So in order to achieve that, we see the minimum MTU overhead and every node along the path is going to record what is called midpoint compressed data. With just three bytes of data that include and the interface ID a truncated time stamp and indication of the load. Also another element to be able to achieve that, hardware line rate implementation is the optimization of the header. So we minimize the variability in the headers to make sure also all of the note along with the packet pass has to do the same editing it doesn't depend on, at which point in the past you are. It's the same, dataplane behavior. And it's important to mention that since this package since this draft has been, proposed that I ETF in, 113. We have 5 different ASIC nouns that implement this solution. And coming from, 3 different vendors. And we have, many open source stack and and softwares. Then when it comes to to the packet header, so if as you can see, there is a there is an example, asterisking, packet. So in past racing, we basically differentiate between 2 different types of note. The first one is called the PT source node. Then the second is called PT midpoint, and the third is called the PTC. Here, what you see is the packet generated by the PT source node. And it includes an ipv6 header then I hope I hope, header and then a destination option the IB V Six header will be used for transporting the packet from the source to the same"
  },
  {
    "startTime": "01:54:00",
    "text": "then we get the hub by hub header. It's a new ipv6 option. Defined for pass tracing to be carried in the ipv6 hub by hub header. The option, right, for that header is still to be defined and the lens of this header basically defines the size of the NCD stack. And the MCD stack is basically the place where each midpoint going to record its information. And just to remind, it's 3 bytes of information that every node has to record. Then the second header is a destination option header for pass tracing. So this is again a new ipv6 option header and thanks to some of the reviews that we got, when we presented the draft basically, in the past, this was an SrhphosphorusinTLb, and we updated the draft and we updated this header in in the latest draft. And the header, the option type for header is still to be defined. And it includes, 64 timestamp field. Plus the session ID and the interface ID and interface law. This header is going to be both used both by the source node when it it generates a packet and also buys a sync, you know, before sending the packet to the collector for, for processing. This slide, please. For the next steps for this draft we welcome the review from and the feedback from the IPPM working group. Especially because we get some feedback from the spring working group. About if that work would be more convenient to be, how to say standardized here in the IPBM working group. So we welcome the feedback from the group and, IBM it shared. And, we will ask for an early adoption for, reallocation, sorry, for, the hope by hope and destination and headers for this implementation. Thank you. Greg, you wanna do"
  },
  {
    "startTime": "01:56:08",
    "text": "thank you for bringing to a VPN because I agree with you. This is the community that that, can provide, helpful input. A couple of things. So My understanding is that, your current scope is for Services. That's, an an interesting question because we just get an email on the Miller that about how to say extending the scope of that solution to be any ipv6 network. So Yeah. That's It's a very it's a very interesting point, and we definitely Yeah. That's that's where I I would like to point because, as with the discussion of alternate marketing method and IIM applicability. I I believe that community decided that that should be a generic for ipv6 rather than specific to a service and use only SRH. Yeah. Thanks definitely conclude this one. for the feedback. And, we would, Thank you. There is another question or Right. Deutsche Telekom. There are several proposals. I I like this work, and I like the proposal, and it should be adopted by suitable work group, I think. That's the first statement. The other one is, there are several proposals how network nodes at the bottleneck should give feedback on utilization and, I don't know what and some coded by 3 bits, other by 4 bits, and some bone layer 2, other some layer 3 or layer 4. I'd appreciate if the IETF community would come together and standardize all these features"
  },
  {
    "startTime": "01:58:03",
    "text": "to the extent possible. I don't wanna exclude anybody on any layer. That's good. Might be nice if at least the codings are standardized. If if, a node level is three bits here and four bits there. It's it adds up at some point. And that would be Great. And I think you also are aware that there are several proposals. Having at least similar parameters. Thank you. Thanks so much again. Well, We're we're gonna go run one quick question. You mentioned, being adopted in an appropriate working group. Do you have an opinion on which group is appropriate. I'm not the office. So it could it should be spring, I think. And I wonder why they didn't do That's my honest opinion. K. Thank you. It's chairs if you wanna get feedback on that. Footer with Nokia. Sorry. Am I next? You're good. Okay. Yep. Sorry. I I think with the the updates in the latest draft, this is not specific SRV 6 anymore. This is generic. If you leave the SR age headers optional, So I think it's already generic to ipv6 or SRB 6. There's nothing that makes it specific s rv6 anymore. Is that correct? It's partially because there is an SRV 6 endpoint behavior. They said, that forward the the packet to the to the controller. Okay. Cool. Thomas Kraft Swisscombe, just following up on the comments. Also, I think important is the data export. To be considered. So I would like to see some consistency with the other, iOS. Thank you. Yeah. The Thank you. Alright. We ended just on time. Thank you everyone for a productive meeting. And we will see you on the mailing list. Thank you to the note takers. We captured all of the various actions we need to"
  },
  {
    "startTime": "02:00:00",
    "text": "Appreciate that. See you next time."
  }
]
