[
  {
    "startTime": "00:00:49",
    "text": "good morning this is TC p.m. so if you\u0027re not interested in T CPM you might not be in the right room okay so my name is Michael Jackson um I\u0027m the other Michael I\u0027m Josi co-chairing of this meeting this is the note well you all read when you registered for this meeting and applies for the ITF and applies to this meeting in particular so we do have a note-taker thanks Cory if you go to the mic send your name senate\u0027s say it slowly say your name say it slowly so it can be taken down on the notes and if you are in the future sending submitting a draft which are you think this working group is interested in put T CPM in the name so we can see it I\u0027m going to the add gender so I will present the working group status at the beginning then we will have some presentations regarding working of documents the first one is the AIF document then we have accurate ECM TCP rack then some about the tea CPM converters the the TCP converters and then we have a presentation by Fernando are you here yet so if he\u0027s if he if he makes it in time you will see a presentation about the back in the TCP spec we will have an update on TCP fast open deployment and if time permits we will look at our the last draft on this list which already had some discussion on the mailing list so working group documents finished between the last ITF in this one is the RFC described in cubic and these are the working documents which are active the first one I\u0027ll turn off back off is actually in working group last call still we just figured out that we don\u0027t have a milestone for it so we have to restart everything now that\u0027s a joke but we really don\u0027t have a milestone for it we are trying to fix this then we have TCP IDEO there was an editorial update but it\u0027s just updating typos fixing typos and that stuff Joe said they are trying to get implementation experience RTO consider is a draft which expired so we haven\u0027t seen an update and "
  },
  {
    "startTime": "00:03:51",
    "text": "it\u0027s actually the document is actually expired accurate ecn as a document we have seen an update and we see a presentation on it the same is applies to TCP req no updates is on the RFC 793 bits document TCP M generalized ecn also hasn\u0027t seen an update but it\u0027s still both are still alive the TCP converters document we will have a presentation today so most of the documents of Specter okay so this is these of its last chest light so Michael can you come up and tell him tell us about the current situation it is smart okay good morning next please that\u0027s a boy we had a review from Microsoft before the working group last call I\u0027m just mentioning it cuz that was just before it and we updated the draft in working group last call first Richard gave a few comments also market auctions essentially saying the same thing about some of the idea references being RFC\u0027s already so that\u0027s an easy fix we\u0027ll fix that and he asked if some generic rules of thumb about the better loss versus easy an adjustment will be in order our answer to that was that this really depends on the congestion control our draft us ref does recommend 0.8 for Reno type congestion control and for cubic there is a bit of text somewhere already that says the results of our tests indicate that cubic benefits from 0.85 but there\u0027s no actual actual specification in our document about this number next then we got a pretty long list of comments from Marco some of them are pretty easy to deal with first of all there was a wrong statement in section 4-1 related to the timeout that isn\u0027t really about our C system I mean some argumentation on why I use ecn to vary the degree of back off and we decided that this paragraph can really just be removed so this isn\u0027t this isn\u0027t really specifying anything then secondly he wanted us to specify what happens when Seawind is as a thresh because I document now says this is only for congestion avoidance but according to I receive five six eight one it\u0027s not clear whether you\u0027re in congestion avoidance or when Seawind is at Thresh so our suggestion is to be conservative and confirm with the previous versions of this document which say that you only apply this when in congestion avoidance "
  },
  {
    "startTime": "00:06:51",
    "text": "now this is only definitely the case when cement is bigger than ssthresh and in line with what Mark walls has suggested we could explain that there is a gray area there is a sentence in RFC five six eight one talking about something being in the gray area which says that this may benefit from additional attention experimentation and specifications we\u0027d like to say that about the case of cement being as this rash as well as serum being smaller than SSO ash because that is also something that is worth looking at we looked at it but we don\u0027t spec it next and then there was a concern about the lower bound of two SMSs being introduced in in this RFC now that comes from it\u0027s an editorial thing really it comes from having to be explicit about what we do with as as fresh whereas the original text just says reduce it you know in line with being the same as loss we at this point I just want to say that we never intended to change anything about the EC and behavior except for this calculation factor so we\u0027ll just fix the text to make it very clear that we\u0027re not changing anything except for this calculation factor if see when can be reduced below SS Rashed and so be it we\u0027re not we\u0027re not trying to change anything about the RSC 3168 rules except for this factor and that\u0027s it any comments in the room so I left the working group last call open for this meeting so that if you have a comment you can bring it up now Praveen does Romanian Microsoft in terms of testing I saw that there is a research paper and a bunch of measurements on test setups has there been any measurement on the internet or any kind of deployment of this yet and has the source code being absorbed into any OS yet for the first question not that I know of for the second question I think we are in the very last stages before that is shipped in FreeBSD for changing the behavior of easier by HIPAA by default changing the behavior of how it responds to easy on marks I think it\u0027s off by default okay any other comments so if that\u0027s not the case then I sent up send out a note today that I\u0027m closing the working of last call and ask your office to submit in your document and then we will progress it and decide it or your changes so we don\u0027t need a another working group last call probably wait until we have a milestone we\u0027ve requested okay thank you thanks Mia "
  },
  {
    "startTime": "00:10:07",
    "text": "yep so accurate easy and we have this draft already for a while and we\u0027re trying to close it up so in the next slide there is a quick recap of the problem statement the problem was that the classic ECM doesn\u0027t provide you enough information if you have high levels of congestion basically if you see more than one marking in a round-trip time you wouldn\u0027t know at the sender side so accurate ecn is just changing the feedback from the receiver to the sender and providing you accurate information about how much markings you have seen in the last round of time next slide accurate Sen provides capability negotiation Inspectorate compatible compatible with classic Sen and it has two ways to send feedback one is using three bits in the TCP header so basically reusing the East End bits that are already there from the classic is in and also the previously the the bit that was probably known as the nonce easier nonce bit that is now deprecated or not in use anymore and then it has a second way to provide you even more feedback with the TCP option but as we know TCP option might not always go through the past so you have liked this part in the in the header that you receive for sure and then the option is kind of optional next slide that\u0027s how the header looks like so you have and you will still have as accurate is the end we have the two easy inflex called easy and cwr and then the flag that was currently known as NS the non spec will in future probably be the AE flag the accurate is the N flick and that\u0027s like what you used during the handshake and then later on if accurate easy and was negotiated this field is used for these three bits are used as a field to provide you a counter next slide this is how the option looks like also very straightforward we have like three fields for for three different counters the difference is that the counter provided in the TCP header is a packet counter and the counters provided in the option field are white counters so basically what this also means is that the packet counter does include control packets which don\u0027t have any payload and the white counters don\u0027t include control packets because they don\u0027t have any payload so the this is all actually pretty simple the the only complexity is actually when to send the TCP option because you don\u0027t have to send it with every packet that would be a little bit of too much overload so basically what the draft says is that you have to send a TCP option and if the information that you receive basically changes or if the code point changes then if you see a row of congestion experience markings the drafts that you should send the option more often because that\u0027s the part of information that you really want quickly "
  },
  {
    "startTime": "00:13:07",
    "text": "and then it says you must at least send three options per round-trip time which where a little bit of the implementation complexity comes from because you never really know how much more packets you will send in the round-trip time and how to distribute them nicely over the round-trip time next slide so there is an implementation this implementation provides the basic functionality but it doesn\u0027t cover all the fallback and in special cases so it\u0027s kind of a proof of concept implementation it\u0027s not a full implementation but it works it\u0027s also a little bit an outdated kernel version I believe what the implementation does it uses the easy and sis ETL that\u0027s already there and just sets it to different value to enable equities yet so the internet interface also stays the same and what we\u0027ve done so far is that we have this implemented was an experimentation option so we we have the the value for the exploitation option reserved in the respective registry next slide so just to recap from the from the discussion we had last time last time we had a discussion about what to do with the TCP flag because the problem here is that the registry actually says the policy is standard action and this is an experimental type exploitation of document and we had a hammer in the room with the conclusion that we want to assign the NS flag in the TCP header sorry the ACE a II flick in the TCP header right away with this publication of this document to be clear what this flag is used for and then the process would be with I used a approval and that\u0027s what the document currently says so basically the status is we got two more reviews since the last meeting from Gauri and Myka\u0027s thank you very much I try to address most of their comments put some little changes in there there are a few more things that need more clarification and I think then the document is ready thank you questions so this is Michael speaking from the floor so most of my comments are purely editorial about the wording but there\u0027s one comment that I\u0027d like to raise again and this is about how to end this experiment if there\u0027s partial deployment because I wonder about because we experimentally are signing the flag if we do a PS spec that follows so how do we do that if the PS spec is different from the experiment and this comes down to the negotiation and as far as I can see there\u0027s no way to do that so this the negotiation mechanism is not future-proof in that sense maybe that\u0027s a downside or any solution that I could think of would burn a TC up TCP option "
  },
  {
    "startTime": "00:16:08",
    "text": "or whatever so maybe it is the right thing to do it that way but I\u0027m concerned that this mechanism is not future proof and I think this at minimum must be documented and recent why to discuss it a of the the header it\u0027s not possible to decide Robin ago she ation mechanism and I think this must be documented because it\u0027s a downside of the mechanism and as I said I see a risk as a road reduce your risk that we have to burn another head a bit later and we don\u0027t have many of them so it\u0027s different to do options we don\u0027t have many header bits and I think at least this must be documented and this is not only an editorial change of some words it\u0027s something inherently about the mechanism and its downsides yes um my take is that the things that we flick as questions we have for the experiment are not things that change the mechanism basically in itself it\u0027s things that if you change them in a in the standards Trek spec you can just implement them differently and it\u0027s no problem no compatibility for example the question about how often to send the TCP option there\u0027s no real I know that the this the receiving end point doesn\u0027t have to rely on a specific rate it gets or whatever it\u0027s really just one who sends the option has to decide on it so I don\u0027t see for those questions we have in the experiment that we have flag out there so my hope is really that if we see deployment with this negotiation that means we\u0027re on the right track this is used and the changes we can do we can just do the other case is that we don\u0027t see any deployment and then the end of the experiment would be like we don\u0027t use it yeah yeah fully agreed but as I said I mean you don\u0027t know what will happen as part of the experiment we don\u0027t simply don\u0027t know the future I have no specific concern right now it\u0027s just my point is if we run into an issue that requires a change we have burnt a bit yes and there\u0027s no way to undo that if there\u0027s partial deployment and I think at least that must be well-documented that that is in it\u0027s in property of the design and it must be documented you can document it Michael can I can I just ask you good to know of you before you go away in case I\u0027m just trying to understand what you mean by burning a bit and this is Bob Brisco for the scribe because we\u0027re we\u0027re using a bit that\u0027s already been used so in a sense we\u0027re we\u0027re not burning a bit and we\u0027re also reusing it where we\u0027re using it for negotiation and we\u0027re repurposing it during jegichagi honest it was not used in the city yeah they\u0027re two different aspects first the split was probably never used it was document it was a documentation for a proposal how to use it probably was never used but okay we can decide in this group we will use it in future that\u0027s not my problem my problem is if you do a PS spec of this and we have to change the protocol as outcome of the experiment you have to burn another bit "
  },
  {
    "startTime": "00:19:08",
    "text": "and I\u0027m concerned about the second bit not about this one here this is the second one that I\u0027m concerned about but I think you will have no matter what you use all these bits all the few remaining bits for you will have always the same problem like if you as soon as you sign a bit and you start deployment it\u0027s really what you taking that there would be a way for I mean I\u0027ve not done the design but there would be a way for example to use the bit and all this in together with an option and then the peer spec you remove the option and then you would be able to distinguish whether you run the peer speck of the protocol or the experimental one so that there would be ways to solve it but it ruins bits elsewhere in the header so that\u0027s the downside pravin Microsoft I had a question so the draft says that some of the usages of the auction are a must still so it doesn\u0027t leave room for an implementation to not implement the option if it chooses who chooses to and so I did my not change their actually because like we had in mind that it\u0027s a receiver site decision to use the option because if you know you\u0027re an environment where options don\u0027t use then don\u0027t use it right so we reflect this out a little more explicitly that was like a hidden assumption we had in mind and I added a sentence somewhere that hopefully clarifies that part it still says that you know you still must parse the option if you receive it right are you you must pass the option if you said no you must pass the option if you receive it like you must have you read my email yesterday not really okay Bob let\u0027s go yeah there\u0027s a statement in there that the if you like the data send are the one that\u0027s receiving the ACK must be able to muster have the implementation to be other as an option even though it\u0027s not it\u0027s only assured to send an option yeah yeah so that if if one end has implemented it the other end can use it I think that\u0027s okay with you isn\u0027t it because because I thought your problem was that you didn\u0027t want all the complexity of having to deal with sort of the failure of the option and that study was sending it but if you do get it through from from the receiving end I mean I think it\u0027s it\u0027s it\u0027s correct to say and I\u0027m not sure what the exact wording I think it\u0027s correct to say you have to have the implementation to be able to pass it if you if you add another kind of switch to say it\u0027s implemented but I already know I don\u0027t need this information though you don\u0027t have to pass it it\u0027s like an implementation decision only it would be nicer if you made it assured because then it leaves it up to the implementation so but I mean like this is this is part of the TCP stick and it\u0027s a generic protocol so if you don\u0027t even provide the code to ever pass the option that\u0027s not what we want I think if you have a specific connection where you know that you don\u0027t need to read the option let something else okay I think we can take this further on the mail you "
  },
  {
    "startTime": "00:22:08",
    "text": "know I look up the exact wording and make sure it\u0027s clear definitely yeah I suggested wording in this email yesterday yes we had a problem like this with a sac RFC actually that the negotiation was an ambiguous and somebody shifted an Immelmann tation that would say will sac and then never said sacked and so in fact the actual negotiation in the code is will sac indicates that you can receive sac I\u0027ve forgotten the detail but you don\u0027t actually turn on sac until you see a sac option because there were half implementations that were fielded you say be careful be very clear about it right yep got it I think overalls will be nicer if an implementation could just choose to do the whole implementation without having to deal with the option it\u0027d be nicer to leave that open in the in the outside so I mean like what\u0027s here what\u0027s your use case here because like I understand that for someone in data centers now you don\u0027t want the option but you have the code in your in your implementation because you use a standard implementation that hopefully already has the code and you never use the code you never run so that code pass is that a problem for you you know I think it\u0027s it\u0027s more about not having to implement fall back and all that complex logic once you implement the option so you can\u0027t just implement the option and not to dealing with all the problems that result from so but then your scenarios basically you don\u0027t use a general purpose of a writing system that has implemented an accurate easy and for all use cases and you like you actually customize it for your use case right is that really what you have in mind I\u0027m saying that the negotiation part and the part that you can get some feedback from the network without having to implement the option is still a viable option for illumination Bob Brisco again I don\u0027t see the problem with I mean obviously it\u0027s work doing the implementation but if if you cause an incoming option you don\u0027t have to have any of the code that does any of the they fall back because you\u0027re not sending an options and all effect for back as if they were sending it no yeah yeah that\u0027s a fair point I think if it\u0027s only about parsing one received then it\u0027s fair okay I come back to you any other comment so I guess I need to be a revision I think we would like to see at least a couple at one more review on on the document from okay yeah okay so when we have another one then and it\u0027s and the issue so address then we can go to a "
  },
  {
    "startTime": "00:25:08",
    "text": "working group as well okay thank you serac is next hi everyone I\u0027m Neutron I\u0027m here to present the draft update for rock this is the third update this is work done with my colleague neon and Tita empuje at Google next please so this is a quick snapshot of Iraq in the sort of natural rock is you can imagine that having a timer on every packet you have sent instead of just one timer and then basically this timer is updated as you get an AK and you get a better idea of the RTT and you use that to determine and adjust the time out for every packet this is sort of a best way to picture what Rack is doing like the example on the right is simply showing this say you send two packets so the second packet gets an AK or sac so you get an update of the RTT and then then you just wind up the timer for the first packet and based on the most recent RTT you get you can sort of put an arty T plus some window to deal with reorder and that\u0027s all the implementation details and configuration details but that\u0027s the basic concept of rock so doing time-based instead of counting dewbacks next please on another sort of combined feature with rockets called the tailless probe and the problem to deal with this that today when you have a tailless you have to wait for a time out and tell loss is occurring common and especially short connections they say you send two packets post get lost and here your serial might be 100 but you only have three packets to package or three packet to send and often lost and then you would you see went to one according to the RC and which is like a big penalty because literally you sensory packets and the last to get lost so you take a time out the tail loss idea is that okay on this kind of occasion you can just after a round-trip or two we transmit up like a pro packet what we do here is you simply we transmit the last one and if the last one is quickly act within an RTT then you said it\u0027s really just like fast recovery there is really not that many packet loss because you know things are sort of coming back it\u0027s not like the entire flight is lost for a long time so you perform a fast recovery instead of like a four time I\u0027ll reset Seawind "
  },
  {
    "startTime": "00:28:09",
    "text": "style so that\u0027s sort of the tail loss probe idea and that works great with rack because it\u0027s we saw this time our base recovery you can just use his probes RTT to adjust the time of the other loss packet next please so that\u0027s the basic idea of RAC and in this IDF we have just uploaded the cert revision which we add a few things one is I talked about a time the reloading window basically when you wait for how long do we will wait before you declare a package lost you can just wait for an RTT that\u0027s too aggressive so you add some cushion and that cushion what we call is the reordering window is they are usually they might be reloading so I wait for something and in the past it\u0027s a static value in the new draft we make it dynamic and another thing that\u0027s new is called a Dewback special mode which now rack can be like almost identical like the two back fresh approach and I offer a sound like like the compatible mode to for staff who want to deploy rack but also want to base on some kind of due back special approach and also there is a example of a fast implementation and like congestion control interactions that some people along the list has make a very good observation that rack can interact with congestion control belly I\u0027ll talk about details later and in terms of deployment in the Google server kernel we have complete sort of we place all the doop a special approach with rack so today in our server production colonel there is rock TLP and the standard time out mechanism which is required but that\u0027s it you don\u0027t see other like a FAQ or sweet you back or yeah yeah there are quite a few this is completely subsumed next please so what is this dynamic reordering window so in the previous draft the reordering window is simply set to a quarter of RTT very very simple deals with most of the losses reordering because a lot of reordering that we are seeing is just a very small scale let\u0027s say you know the packet that you sent in the next is delivered just a little bit quicker than the packet that you sent earlier so the reordering degree is small but there are cases in when the reordering window can get pretty large especially on Wi-Fi links where it\u0027s the Wi-Fi retransmission that costs the reordering and Wi-Fi link retransmission is highly dependent on the channel "
  },
  {
    "startTime": "00:31:09",
    "text": "status and in this case rack will perform a spoof Schloss detection you say okay this packet timer has fired and this package should be consider lost so if you use lost based congestion control then it\u0027s gonna take a hit on that and in this case initial idea we have is alright this precisely measure the reordering degree but it turns out to be really complex because when you want to do that you have to remember the per packet timestamps even when the packet has been acknowledged right so usually in TCP stack when a package cannot you free the the packet because it\u0027s been delivered in this case you have to keep those extra state simply to do this precisely and we believe that\u0027s not really worth the effort what we do is we look at this option that have been created a long time ago called the bouquet sack and what it does is when you receive a packet that covers a sequence that you have already received you simply return the sack option says hey I got this duplicated sequence and it has been on implemented in all the major stacks like Linux iOS and Windows since all on by default and that\u0027s a great indication because it signals buoys which transmission Jenna you have a question there clarification question why do you need to remember the per packets timestamp after the packet is acknowledged because even outfits act right you are trying to gauge okay this packet has been act and there is some more packet that\u0027s been sort of in flight and the Reis the way you measure the reordering degree is you have to measure the two right yeah so that\u0027s why you have to keep I know I get that but you would you would discard everything only after everything is cumulatively acknowledged up until that point that\u0027s right yeah so sorry I think I made me say it\u0027s not the act it\u0027s the thus act so that\u0027s fine let me clarify yeah that okay that explains it yeah all right go ahead okay yeah so the basic idea is we use this act as a signal for aspies retransmission and we increase the reloading window when you get some of that and you decrease when you are doing loss recovery when you don\u0027t observe further these acts it\u0027s a very simple one next slide all right so yes they do name supports Gilligan what I don\u0027t understand is you\u0027re saying what you do but not why you do it or what\u0027s your objective what do you are you trying to get nospherus transmissions or are you trying to get "
  },
  {
    "startTime": "00:34:12",
    "text": "sort of yes oh great so the objective here is to say you want to adjust this sort of reordering window essentially the time now for the packets to accommodate higher degree of reordering so if two packet being we order more than a quarter of minimun RTT then today the previous version couldn\u0027t catch that and it will cause a spools sort of loss recovery yeah but what I\u0027m asking is how important is it to you not to have that in other words if you get some spurious retransmissions do you care you know in other words where where was what\u0027s your objective between those that trade off because that depends what algorithm yeah so again if you use a last-place congestion control especially if you also don\u0027t support TCP I fail which is the TCP undo mechanism you know then you will see the you know say Reno keep dipping the congestion window because of reorder yeah yeah yeah I know I know that I\u0027m just saying but trying to completely remove spurious transmissions is impossible so what\u0027s your trade off what do you say I mean it\u0027s I have an answer to that and and that is if you take your favorite very very complicated recovery scenario and then insert in the forward path something that shuffles every four packets does it still work and the answer is no because you can\u0027t do the logic in sequence space you want to do the logic in time-space and so that the sort of the limiting case is allow every packet to have an independent delay okay and and but so you\u0027re correct that there isn\u0027t specified a reordering threshold or an implicit reordering threshold but you want to be able to design that independently you don\u0027t want the algorithm to have built into it assumptions about how much reordering what is the upper bound on the amount of reordering of the reordering distance and so making the algorithm support arbitrary levels of reordering such as you can then put in a policy and optimization about how much reordering and how much spurious retransmissions you\u0027re willing to deal with and that and that\u0027s important because the the problem I see with adapting to the level of reordering you find is that networks will just cause more reordering and then you\u0027ll that\u0027s more well it depends how much at whether it goes beyond a round-trip time yeah so the next I\u0027ll put more detail but basically the idea is to accommodate reordering up to an RTT further than that Rach couldn\u0027t do it because in the end of the day if you have to pass one send it to them over the moon and one is a local network there is no way we can accommodate we ordering like that yeah Provine Microsoft so I wanted to know kind of which scenario led you down this path did you actually see reordering "
  },
  {
    "startTime": "00:37:13",
    "text": "practically in cases where RTD by four was not good enough oh yeah this is actually triggered by when I studied the traces I have seen particular environments or like Wi-Fi or is this more general it\u0027s hard for me this is service I traced so I don\u0027t know all I know is this angle Comcast you know network a ASN yeah but since severe we all drink on that I\u0027m gonna go back to my question and a human game Jen Iyengar sorry I\u0027m gonna go back to the question I was asking and I can I\u0027m happy to talk to you afterwards if it\u0027s up here you said that the correction there was after the packet is sacked in that case it\u0027s not be allocated in the stack it\u0027s only Delocated after the packet is cumulative yeah so I think I give that you know forget what I need to modify this right this is about what happened is that in the TSO processing when you say you have you know they say package seven eight nine that gets sacked right in linux they\u0027ll be collapsed into one sort of packet buffer if you call that yeah which you will lose the timestamps of individuals and the time time the collapse and lost okay yeah and and then then you have to keep your extra times then when they are doing the collapsing and that\u0027s a very complicated change go to the essence thank you please so this is the more detail of this dynamic reordering window so all the wielding windows still the initial stay is quarter of Menotti and for every round trip that you observe some design option uses equipment by a step essentially you buy another quarter of monatti it\u0027s important that it you don\u0027t increase it for every D sack because you could get a lot of D sack doing we ordering in a roundtrip so we only do that incremental E and again this could still miss that right let\u0027s say the reordering degree is actually 3/4 of our TT so for the next round Ferb you still going to cause some spewed we transmission and then you just have to learn again so it takes some round trips to attempt to a level that\u0027s I can accommodate the current reordering and then we don\u0027t want to keep this high reordering for forever because the problem is then your timeout gets too long and if there is no reordering you don\u0027t want to delay your fast recovery that long so what we do is another heuristics to say if after 16 magic number 16 last recoveries and we see all the recoveries are done without seeing further defects then we just reset it and just repeat this process and all this design is there\u0027s a lot of ways to make it more fancier more adaptive but we just trying to make it simple and good enough in our test cases "
  },
  {
    "startTime": "00:40:15",
    "text": "and then doing fast recovery we will temporarily we set the reordering window to zero to be very prompt in fast retransmit so the idea is to be conservative in the beginning but once we decided okay we need to go into loss recovery then we are very aggressive in marking the packets we could have cost a lot of spirit retransmission but with that decision but it\u0027s sort of a trade-off that we have to make and again all this reordering window will be kept under the smooth RTT so any we are doing further than that we cannot catch that you will cost buoys with transmission but I would order I would argue that for any kind of case that would be always reordering there it\u0027s you cannot do that perfectly like Bob next like lease so this is just a showcase of the two algorithms you know on the right on the left its the O one and on the right the new one where this is not a this is in emulation where we deliberately we order packets to hell and the sacks are in the purple color you can see we are triggering a tongue of sacs including the D sacs and in the over chin it will just keep trigger all this false recovery so you will see the stupid is only 60 mega bits per second but in the new one you\u0027ll see initially we\u0027re still now ramping are very good but we are learning and increasing the reloading window once the reloading window is pick enough to accommodate the reordering then you don\u0027t cause further spoof retransmission and even under severe we order you can zoom up on your speed very quickly so this is just to show that how this dynamic we ordering window works under very severe reorder and if on the right hand side the new one if I look at a longer time scale you will see after the while that we essentially the reordering window will rewind and you will Constance police retransmit but you will read nirn and then pick up again thanks like lease so the last thing is the dupe a special emulation mode do back special can still be very useful especially in ultra-low our titties why is that because in rack I talked about a time out for every packet right and but in say they are sinners the oddity is less than 100 microsecond a lot of time but your stack timer tick might be much bigger than that say 1 millisecond or even 10 millisecond so in this case let\u0027s say you\u0027re reloading time is reality 300 microsecond the fasted timer you can fire is say a millisecond then this will cause "
  },
  {
    "startTime": "00:43:15",
    "text": "something like so case the counting simply counting the do Baxter\u0027s offer a good advantage and we can easily support that by saying if the lumber of the VEX ratio is bigger than or equal to 3 then just set the reordering window to 0 there is some very subtle differences if you want to be pathetic about how this dewbacks reso is sort of trigger or used because you need our c6 675 says that in order for a packet to be consider loss you need to have at least three packets that been sacked with higher sequence but for Rocky it\u0027s not such a strange strict requirement you just need to have three dewbacks and at least one of them having higher sequence there\u0027s this example you send 10 packets and package three five seven are sacked in the standard RC only one and two are will be consider lost but in rack all the lost ones until the highest stack point will consider loss which one is better I think it\u0027s really like a minimum is not worse that like diving into all this details because yeah it\u0027s too bad special which I find that a lot of implementation don\u0027t quite follow the RC exactly anyways so this is a rich after Canada is that statement actually true I mean I was under the impression that in the example with RC 6 to 675 you would enter loss recovery after the sack of packet 7 but once you\u0027re you\u0027re in loss recovery the entire point of 66 75 was to recover all these four packets right now if you read RC very very carefully you have it does say that you need a leash rehire sack sequence packets to trigger the dewbacks ratio I can point you it\u0027s like one sentence if you Alec this is Josi from Mike and then about the 66 75 you are right one two pocket has been considered as a roast that\u0027s know if there is any window size we can send that packet six because now we in order to in a pro but this might be a rose but we\u0027re not sure but now we can send it just in case and then we can get feedback from yes you absolutely right I didn\u0027t put even the second if condition because we\u0027re getting into really super minor subtle details but yeah you\u0027re right it\u0027s possible there is an optional mode in the artsy trigger yeah I think that this exact example of you give was "
  },
  {
    "startTime": "00:46:15",
    "text": "the behavior of 34:17 so the old sack recovery and I believe that was the was the way that we wanted to address in 66 75 okay but this is again in the is it it\u0027s an optional mode it\u0027s not like in the standard I think we can take it offline we can look at this you know are see live I lion determine what exactly is the right I wasn\u0027t yeah Jenna Inger what\u0027s the intuition here for considering six as lost why don\u0027t you think six is lost when is three five seven are loss it could be reorder it there is always possibility that\u0027s usually the argument right the only reason that 66 75 or any of the other C\u0027s have the three do pack threshold us for reordering and that\u0027s why you also have the reordering window if you remove the reordering window and you remove the three due back threshold for six they all could very likely be marking success lost too early you could yeah but again in my experience you either have most of the time you either have losses on all this sequence or there is some reorder is no loss so do you always need to wait for more two baths or sacks to confirm I think it\u0027s really yeah so this seems I mean again a little uncertain about I\u0027m not pushing back I\u0027m just trying to understand what the intuition here is because this seems like early transmit is getting folded in in a strange way because early they transmit tries to do exactly that right if seven was the last packet that was sent then early retransmit would fire recovery of six early retransmit will apply here because he required in fly size of four or less that\u0027s correct yeah but I\u0027m saying that if seven was the last packet that was sent then that is what would happen mm-hmm so so if you don\u0027t use this to pass ratio mode in this package sequence the pure rack without this boat well in the armed timer instead of we transmitting it on the cert packet yeah right it just seems more natural to me to mark one two and four as lost not six because there are more acts that are on their way back eight nine and ten haven\u0027t you are arguing if you pass fish how it should be one on some cases I cannot disagree I guess that\u0027s my Indian it\u0027s it\u0027s I think worth pointing out then that the do pack threshold here for six is in fact one because that\u0027s what\u0027s happening here right yeah okay I think we are getting into the very well-defined do pass ratio it\u0027s very different than what he was written a long time ago in the very first because back then there is no not "
  },
  {
    "startTime": "00:49:16",
    "text": "even sack surely that\u0027s fine I just think that the the spirit of what is reading there as three six six and referred to me is accurate and that actually captures the intuition of what I think about as the reordering threshold and and that\u0027s what I was trying to point out next slide please um so the last one is interacting with congestion control there is the case when on a single AK when we receive a will update the RTT and Rach can trigger a lot of packet that\u0027s considered it lost the simplest of they say you sent 100 packet right only the very last one made it and in this case Rack will get an update of the RTT and for packet 1 to 99 it\u0027s going to arm a timer right once the timer fired they say after a quarter of RTT later it\u0027s going to mark 1 to 99 packet lost so the in fly will drop or come from 100 down to base essentially zero from 99 to zero so that\u0027s a big change of the in fly and if you just implement the current reno congestion control which always sent an fast recovery first it reduce the Seawind by half let\u0027s say 50 right so see you in is 50 or SS ratio is 50 and the in fly is essentially zero so what do you do is you burst 50 packets out and without pacing you is very likely to induce another round of loss which you have to spend to recover so Linux doesn\u0027t have this problem because it uses this proportional reduction which what it does is that during the fast recovery you either do packet conservation for every packet sex you say one more packet out or you do slow sir for every packet sack you send two packets out so it does have this situation so we will recommend using this fast recovery approach proportional reduction when you implement rack and another helpful one is you can do TCP placing so that you don\u0027t send a big burst that would be the most convenient solution for a lot of other situations too next piece so the development how frog has is near the end we don\u0027t plan any further sort of algorithm changes of course little tunings is always possible and Linux BSD and Windows all support that and I think the author\u0027s for authors see the racks the latest draft is fairly complete and we would like to ask for "
  },
  {
    "startTime": "00:52:17",
    "text": "like a final review and maybe a last call if the chairs and the group feels it\u0027s ready okay thank you um one clarification question you say Linux FreeBSD and Windows support rec so I understood that Linux supports version 3 of this document as far as I get previously might support version 2 but not version 3 is that right yep and Windows Provine Microsoft V support actually draft one or not two or three so we don\u0027t actually support the three extensions that were already later so you support the dynamic stuff no no version 2 version - yeah yeah I think it was version 1 but not this version not this version ok thank you Mike Aversa I I may be asking something very strange because this isn\u0027t I\u0027m a I don\u0027t know so the thing is I\u0027ve been playing with a variant of this and that is really not quite the same it\u0027s a bit more drastic in a certain way well just something that I experienced that I\u0027m just wondering if the same thing could happen here but I probably not but I\u0027m just wondering so let me ask something I experienced is that with the logic of using time to decide what has been lost on what hasn\u0027t been lost well the were cases where I ended up terminating recovery and I was basically over and had just reach and speeded everything but I was lost I was left with a large window that I\u0027m now able to basically burst out immediately so I what I needed to create is a phase of pacing that is after recovery I don\u0027t know if that sort of thing can happen to you because I think a proportional rate reduction would operate within recovery so I I don\u0027t know if you need to have something at the end of recovery where you but you can you know because basically the a clocking always allows you to send out another packet so you keep the a clock and you spend your window but if you don\u0027t then you may be left with a large window at the end of recovery and I mean it happened in my case but that\u0027s really not exactly the same thing right so I don\u0027t know um so I definitely agree your observe a shink as we see the same thing that\u0027s why we recommend using FQ pacing for basically in general don\u0027t just do that but for the PR are this really for just the fast recovery but again TCP is inclined to cause burns because of the Seawind in fly differences and it\u0027s sort of this is sort of out of scope of the loss recovery it\u0027s not just after the recovery right they say you\u0027ll see when "
  },
  {
    "startTime": "00:55:18",
    "text": "it\u0027s 100 and now you have 100 packet that you want to send you you push them out it\u0027s just it\u0027s a general problem in in TCP not specifically apply to only I guess I mean that depends on how quickly you pays out stuff during recovery so if you haven\u0027t been fast enough in sending out stuff during recovery you have this credit after recovery so if you\u0027re not sending out new packets right quickly enough then you may be repairing your losses and all the losses are finished and everything is fine but you have this credit of PAC estate you still allowed to send after because according to the congestion control RC after recovery your C 1 is always SS fresh right that\u0027s that\u0027s the standard yeah sure yeah and then yes you may not have much to send so you would later cause a but I mean if she went is then much bigger than what you have sent right I mean it may allow you to send out a large number of packets at the end it may but I don\u0027t know why this is tie to loss recover oh just it is a loss recovery because if you\u0027re not if you\u0027re not sending during loss recovery fast enough then you have not you have not spent here your Seawind right so if if you\u0027re sending too slowly during that and you don\u0027t have I mean it depends on how many packets you assume are implied so if you don\u0027t have so no matter the you use rack or not during loss recovery once the the lost packet have been repaired c1 is always set to this SS fresh and the in fly is also not affected by whatever always am you use so I guess I don\u0027t okay it seems like this is either way so I started out saying this is something I saw and it\u0027s probably not even related to this you know okay leave it at that pravin Microsoft so this recommends that we keep time stands per package sent right that\u0027s why in our implementation we actually chose to keep it for sequence number space because for example if you do like the TS or LS o then it\u0027s a group of packets that are transmitted at the pretty much the same time so there\u0027s some implementation efficiency gained by tracking this per sequence base rather than per packet which also means that we can\u0027t track the original packet and the retransmission separately so and the other thing I found is that there is one case that you talked about tail drop which will not be triggered if an implementation chooses to do this based on sequence numbers it might be useful to comment on this in the draft I think I think the trap already that\u0027s exactly why we put t.o.p "
  },
  {
    "startTime": "00:58:19",
    "text": "there because in the end rack recent acts still requires some ACK right and so for tail drops where you don\u0027t get any ACK there is just nothing you can do in using these time stamps you you have to send something to trigger an ACK to sort of cost more recovery actions so it doesn\u0027t matter how you put the timestamp in in a sequence base or in the packet boundaries yeah okay another question so you talked about the inter with congestion control and then you said we linux users prr to make sure that it doesn\u0027t flash the entire you know that\u0027s right in flight packets again is this just about making sure that you\u0027re only inflating in-flight by the sacked packets is that the part of prr that is implemented or their other portions of PR or that are applicable is that or is that just that part no so it\u0027s PR is not just that part yeah but part of this idea of PR is instead of bursting packets out you want to do this sort of you want to paste packets out and gradually reduce the congestion window instead of reduce it at instant and then cost first yeah but but my question is like the safety property would be just obtained by doing the the correct inflation of the congestion window right the pacing is an optional part because today for example without pacing like you know the conventional loss recovery yeah similarly inflates the condition window so that as long as we guarantee that safety property then the other portions of PR are not really needed for track so what I\u0027m saying is that you can use either one of the two Linux use pose it\u0027s a car like a pill and suspenders but during fast recovery but if you already have pacing and you don\u0027t need to implement prr okay okay yeah okay so I would say give the implementers a bit of time to catch up with version o3 okay so hoping that whoever has implemented version over to has interest in version oh three can report whether it works whether it\u0027s implementable in a good way or if they have any comments so get some feedback before starting a working group last go on that sure sounds good to me yeah Oh Bob Brisco I\u0027m wondering whether this draft whether what you\u0027re trying to do is standardize the algorithm you have thought of or whether you\u0027re trying to standardize allow people to use different algorithms and you you need to "
  },
  {
    "startTime": "01:01:20",
    "text": "describe what you were trying to do as a sort of black box do you see what I mean because it\u0027s the former Saints right yeah so it\u0027s it\u0027s documenting one algorithm that\u0027s right rather yeah yeah it does not prevent other better algorithms yeah obviously yeah right okay that you you might want to say that and and I think the draft would benefit from having what the algorithm is trying to do not just what the algorithm is okay can you repeat that again what the algorithm is trying to do not just what the algorithm is in other words what are the objectives you mean to put more explicit wadding and in the documents in like not warning just you you\u0027ve just you\u0027ve just made it like reading a user manual about something that says this button does this this bus and as this this button does this but um says what you\u0027re trying to the machine is trying to do as a whole okay this is a draft up based on presenting the business that the whole draft doesn\u0027t say what what it\u0027s aiming to do it\u0027s aiming to reach okay how about that can we sort of in I\u0027ll fly that figure out what whirring you would like to change so I can make it more yeah okay oh yeah I\u0027m just trying to think of other people who you might want to come up with different algorithms in a standards body we also need to agree what is a good aim for all of us not just what is one algorithm to meet that aim you said I mean I see so you\u0027re saying there should be some consensus of the goal so this always only just one approach toward that goal I\u0027m closing the line of the journal and I\u0027m asking you to be quick pravin Microsoft sorry one more question so you said the implementation is almost your implementation is replaced all over the other loss recovery with RAC is it a goal for the draft or the RFC to say that an implementation should do that or are you going to leave that open for implementations to do both if they chose to do so to do both yeah I mean I mean do a Dewback Thresh as well as time-based yes we recommend that you do enable this as a pack or culpability right Jenai a very quick suggestion that this is a working group document so I think you should take input from people who have specific suggestions about motivating text and so on specifically speaking to Bob Bob you write very well I didn\u0027t be wonderful to actually have what you\u0027re suggesting but I would I would also say you know such as text yeah so I think I already mentioned that will work offline to improve the document yeah okay thank you "
  },
  {
    "startTime": "01:04:21",
    "text": "okay so while the blue sheets and has everyone signed it so if not please catch one and do better so the next one is the TCP converter okay so so this presentation is both the first presentation of the contractor draft in front of TCP M because it was already presented in mp TCP in Prague last year but we did not have the opportunity to present in TCP I\u0027m in Singapore and then an update of the draft after the working group acceptance on next slide please so the initial motivation from the convertor comes from the work that has been done in MP TCP working group and in MP DCP we see that there are more and peaty speak Lions then MPT MPT CB servers and there is a benefit of using MP TCP in the access network to be able to combine different paths even if the server does not support MP TCP so that you can go to a controller that\u0027s reports and P TCP so that you can benefit from the two paths in the access network even if the converter has not yet been upgraded to support MP TCP next slide please so what are the objectives of the TCP converter which has now been accepted by the working group is to aid the development the deployment of new TCP extensions and if you look at the history of the different TCP extensions we\u0027ve seen that extensions are first deployed on the clients and then they are deployed much later on the server side and in enterprise networks and service provider networks its there is a possibility of deploying converters to aid the deployment of some TCP extensions so the TCP converters they act like proxies and they will proxy connection initiated by clients and the objective of the control to draft is to do this proxy without requiring additional entities and one important point of the converter Draft compared to other solutions is that the converter has the ability to inform the client of the options that are supported by the server so that the client can detect if the server supports and P TCP for example then it can decide to bypass the converter so it means that you only use a converter when there is a benefit of using the controller next slide so just simple use case if you want to do NP TCP in the access network from a smart phone to a server that does not support an P TCP you just use n P TCP to the convertor the tax as a TCP proxy and then you have a regular TCP connection to fine observer next slide the next slide "
  },
  {
    "startTime": "01:07:21",
    "text": "and next again so what are the basic principles for the converter so it\u0027s an explicit TCP proxy between the client and the final server so the client knows the IP address of the TCP proxy the client will send comments inside the TCP byte stream so you can see that as an evolution of Sox for example or refinement of Sox and to be able to achieve 0 et we just put the teeth the comments of the proxy in the syn and during the initial and shake and the comments and response are encoded in TLB format to simplify the parsing and the processing of the options and there is a way for the converter to inform the client of the TCP option that are supported by the server to enable it to bypass the converter if the server supports the required extensions next slide so now I have a set of examples to show you in principle oh it works and the shim add in all the figures you will see there are three colors the green color corresponds to the IP addresses the blue colors corresponds to the TCP header including the TCP options and the red color is the information which is added by the converter protocol and this is part of the byte stream and it is encoded as a set of tlvs so let\u0027s do an example so the client wants to read your server to be able to read your server where the client will do is that it will send a syn with the TF or p on to the converter and we use the TF option to be able to put data inside the scene and the data that we put inside the scene is the IP address and the port number of the final server so the convertor received the syn and thanks to the TF o cookie that it has provided to the client it confirmed that the sin is legitimate and what it will do is that it will initiate a connection next lightly to other server and it knows the IP address of the server from the connect TLD which was part of the original scene then the final server will reply to the scene with a cynic next slide please and so the connection from the converter to the server is now established and the converter next slide please will confirm with a cynic that the connection to the client has been established so with the connect TLV we pass the information of the final destination to the converter hi Olivia Lars I got a quick question you stick the IP address into the payload not the DNS name in the current version this is the IP address because we want the converter to be fast and if we put the DNS name in the TLV then it means that we have to do dns resolution in the converter yeah I sort of worried about were thinking about scenarios where the clients DNS resolution might be limited and the proxies might not be so it just the possibility to add the new TLV where "
  },
  {
    "startTime": "01:10:23",
    "text": "you put a dns name instead of an IP address in the current version it\u0027s only an IP address because we want to be fast on the conservative side and next slide so as I said one of the benefit of the converter is that you can detect whether the final destination supports are give an option so let me take an example with MP TCP but it would work with other TCP option so the client creates a connection request through the converter with the and here we are using an T capable option which is shown as NPC and we are using the RFC 68 when T for bit so just MP capable without the key to the converter next slide the converter will try to establish an MP TCP connection to the server the server is MP TCP enabled so next slide it will reply with the MP capable option and with the key which is selected by the server and what the converter will do is that upon reception of the simply Zak what it will do is that it will extract the TCP option that has been returned by the server and it will send them in the payload of the synthesized next slide please to the client so that the client by just passing the TLV which is part of the byte stream of the TCP connection from the converter to the client will know that the server supports and P TCP and knowing that the server supports and P TCP then the client for the next connection can decide to bypass the control and go directly to the server so that\u0027s a generic way of enabling the clients to understand what are the options that are supported by a given server and it means that you can bypass the converter for this specific destination and next slide please so to be able to use TFO from the client to the converter you need to be able to know what is the TFO cookie which belongs to the converter and for that there is a bootstrap connection so when the client starts it has to initiate a connection to the converter just and the scene with an empty TFO and a bootstrap TLV and the converter will reply to the client next slide to indicate what is the TFO cookie that the client has to use to reach the converter and what are the supported tcp extensions that the client supports and allows to do a conversion so that\u0027s a way to learn the capabilities of the converter during the bootstrap procedure next slide so now we know the converter cookie and we can use it in the client to reach a converter so next slide yeah next slide again so what is the tricky part is how can you do TFO to reach a server while you are already using TFO to reach a converter and the idea is that we have done the bootstrap since we have done the bootstrap we know the cookie of the client of the converter so we use that in the TCP options that\u0027s the blue color so we use the cookie that we receive from the converter and we want to obtain the cookie from the server so inside the "
  },
  {
    "startTime": "01:13:24",
    "text": "connect TLV that we put in the byte stream in the establishment of the connection we have a specific TLV that indicates that we want to send the TFO option and apt in an empty TFO option to the server so when the converter creates the connection to the to the server what it will do is that it will send a syn with the antitype MTTF or option that comes from the connect tlg of the original sin of the client so the server now knows that the converter is trying to create a connection and request a TFO cookie the server will reply with the TFO cookie so this is the cookie is assigned by the server so this TFO cookie assigned by the server is returned to the converter and what the converter will do is that as with the MPT CP example we will just take the TCP options that have been returned by the server and this TCP option that have been returned by the server we put them as TLV inside the synth music which is returned by the converter to the client and the client can pass the TFO option which is which is included in the byte stream and from knowing the TSO option which is included in the byte stream it can detect what is the cookie so SC that has been provided by the server and the client can cache this cookie for the specific server now on the next slide we will see how the client can open a TFO connection to the server so now that what it will do is that it will go to the converter use the connect TLV specifying the tcp open option part the TF o which has been supplied by the server so this TF o is copied by the converter in the scene that it sent to the to the final server next slide so you see the TF o which has been allocated by the server the server recognize the cookie that is provided to the IP address which is TD IP address of the converter and it accepts the data and then you can do the syn ACK and the converter does the cynic as usual so the solution works with TF o as well just by using the information in the connect yield so next slide please so this was the the introduction of the converter and this is basically what I have shown in Prague last year now I will try to describe what we have done since the working group at AG adoption which was three or four weeks ago so we did lots of small little changes to try to clarify and simplify the text and we have looked at out other TCP extensions than TFO and NP tcp could be supported by the converter so next slide please so first we look at the we would say the base tcp options so the options that are part of RFC 793 so end of option list no operation and maximum segment size for these options we don\u0027t see any of doing the conversion of these options on the converter so what we propose is that the converter does not provide the conversion services for these kind of options next slide then there is window "
  },
  {
    "startTime": "01:16:27",
    "text": "scale so the window scale option is really a property of the tcp implementation and in the converter we have a TCP connection from the client to the converter and another TCP connection from the converter to the final server it makes sense for the client to request the server to you the the converter to use Windows scale but we don\u0027t believe that it makes sense for the client to request a specific window scaling value for the converter so the idea is that we don\u0027t want the control the client to be able to impose a specific window scaling on the converter so this should be the property of the converter for that are you familiar with the rounding hazards with the window scale option with so there\u0027s some hazards in the window scale option that you can\u0027t avoid retracting the window if you\u0027re close to the end close to the end of the window space and the rounding is such that you cannot specify the boundaries at the actual window the actual window you want to announce I\u0027ll take it offline okay there\u0027s there\u0027s some deep traps lurking here so next slide then we have time stamp selective acknowledgements and we\u0027ll keep a CCP we believe that for these options they can be supported by the converter so this is true for timestamp for sec permitted and for multipath CCP and of course of kind 5 the Selective ik option it cannot be advertised in a scene so it doesn\u0027t make sense to support it on on the converter next slide then fast open so I explain how we can support fast open so this is a part of the design of the converter draft next slide TCP use a timeout so there is an option which is related to TCP use a timeout kind 28 but it\u0027s unclear to us whether this option is already has really been implemented or not so we know that the socket option is implemented but we don\u0027t know whether the TCP option is implement so is someone aware of an implementation of the TCP option for the TCP user timeout if you are well let me know and then we can think on how to support it and whether it would be useful to support it next slide then there is a TCP authentication option well the objective of this option is to be able to detect modifications to the TCP header and the TCP payload this option is in principle against a proxy in the middle so it does not make sense for a converter to be able to support TCP authentication option then the question is whether there is a benefit in trying to support the in the NAT extension of the TCP authentication option and we\u0027d be interested in having feedback from the working group on on that so my understanding is that the TCP authentication option is mainly used for bgp sessions and for for that use case "
  },
  {
    "startTime": "01:19:28",
    "text": "it does not really make sense to go through a proxy because you want to use a TCP option also to detect failures and so it doesn\u0027t make sense to go to a proxy and next slide and then we have the experimental TCP extensions this is the list which is registered by the Ayana in the current graph we do not consider these experimental TCP extensions and our suggestion is that those extensions should be described in a separate draft otherwise we will have a draft that will need to be updated every time there is a new experimental TCP extension next slide so to conclude we started from a proposal that was focused on multiple CCP and TFO because there is a clear demand to be able to support converters for multiple CCP but the discussions within the ITF convinced that there are other use case for other tcp extension so in the draft we try to take into account all the comments that we have raised doing the email discussions on the NP tcp and the tcp and mailing list so we have an application level protocol we still need to have a service name or code to be reserved by Jana so we use zero ATT through TFO and the client can bypass the converter if service supports the extension so on next steps will be to improve and fine-tune the discussion of the other tcp extensions based on the feedback from the working group and we will get back from implementers and do interoperate tests as far as I know there are three implementations that are being developed for this solution matter so I may have missed it but has there been any discussion of how this interacts with TLS so what happens when you do TLS from the client to the server so you have you have to rely on the certificates that are provided by the server and so the server will authenticate the connection and so you have so you it since you encrypt everything and you authenticate everything passing through a proxy or passing through a router doesn\u0027t change anything because the TLS is working at the at the byte stream layer and not at the TCP header so the only issue are the IP addresses and handling the certificates and handling the certificates you tone chain and still find hard to convince myself about the motivation seems like the motivation slide is to support multi pass inside the access network yes but the most useful MP TCP feature a usage I\u0027ve seen "
  },
  {
    "startTime": "01:22:29",
    "text": "is to do the pockets of the parking lot problem where you launch the use MP TCP across both Wi-Fi and LTE interface on on your phone our Saviour interface it doesn\u0027t seem to match this case because then where do you put the converter it has to be very close to the server so could you put more detail some example scenarios of doing MPT CP InDesign access network what\u0027s the benefit what motivates them to do that so just one motivation for example if you look at what has been explained in Korea about the deployment and the usage of the Sox proxies in Korea 2x2 Bond Wi-Fi and LTE together there are the use case is to put the proxy in the network operators itself so you have a network operator that provides Wi-Fi and LTE services and the proxy is inside the operators Network okay so essentially the the access Necker is doing both Wi-Fi and cellular service okay but that sounds is I feel it\u0027s very limited at least doesn\u0027t apply to the case in u.s. of course maybe in Europe but I don\u0027t know how many eyes P are providing both services together like they have a large user so how many ISPs are providing both Wi-Fi and LTE yeah and cellular services so if if you are an incumbent operator typically when you have you will have mobile services and then if you have dsl then you have Wi-Fi access point on your DSL Network and many networks are providing solutions such as fun or others to share the Wi-Fi access point from multiple users so this is pretty common okay is this part in the draft that what you just provide the example the example you just provided no no so there are examples about if you look at the draft on the use cases for MP TCP those examples are in the RFC I think it\u0027s 60 41 at least use cases and deployment experience with NP TCP okay there\u0027s the draft site that RC I sound yes okay thank you state your name Jonathan modie sorry I violate the height requirement evidently I had two comments my first comment is that I found some tension in the draft between this idea that the client should have should be able to specify exactly which extensions it wants to use and therefore the purpose of this is to enable them to use those extensions when they want to at least up to the convertor that supports them versus the what seemed like much less control the "
  },
  {
    "startTime": "01:25:31",
    "text": "client has over what the server though the converter talks to the server it seems like there was a lot of things where the draft says well the client can say client can request something but the actual the actual values are dependent upon what the converters stack supports and it struck me that there was a real dichotomy between the fine-grained control you want to give the clients and the lack of control they have over that other TCP session that\u0027s the first thing how would you answer that and I have yeah I see what you mean so the draft comes from a solution to support MP TCP and then we were asked to extend it to other TCP options and what we need to do is that and but we did not have time during the working group acceptance between the working group of acceptance and the draft deadline to look at all the TCP options in details and to see how the client can use each of the TCP options and to to build a table with all the combinations that would make sense but this is something that we plan to do but the idea is that we want to let the converter specify I would say I support this TCP extension let\u0027s say I support MP TCP and sac and I\u0027m able to do the conversion services for MP TCP and sac and then for timestamp same time I\u0027m implementing 73 23 I will do timestamp for all the TCP connections that I will open to the final nation anyway and so this is not a conversion service so there is a there is a tussle between what the client is requesting and what is the basic policy of the converter TCP implementation and this is something that we need to clearly specify in the draft and this is related to your question I guess my second comment is that I think the draft really needs to explain why or how you\u0027re going to avoid all of the normal pitfalls that we see with middleboxes I mean you\u0027re essentially adding a middle box here there\u0027s all sorts of inherent concerns with that and I think that you your draft really needs to explain how you\u0027re going to avoid all of those so so we are aware of the issues with middle boxes because they they played a key role in the design of MP TCP and we had to pass through all of them with an P TCP and we managed to patch all of them in with an pcp I think the difference between the existing middle boxes and the converter is that the converter is explicit so you know what the converter will be doing doing to your TCP connection and this is a major change compared to the middle boxes and then we can add a section looking at if we have on the pass a middle box that would remove TCP option "
  },
  {
    "startTime": "01:28:31",
    "text": "here is what will happen we can have a section saying if we have on the pass a middle box that removes information in the scene payload this is what will happen and and so on I\u0027m not sure that this really is different than the middle box though it in some ways it is different because you explicitly know it\u0027s there in other ways it\u0027s not different it doesn\u0027t solve all of all of the concerns that are there sure it\u0027s not trans at that point it\u0027s not transparent and so you have a maybe the problems are different but they\u0027re still potentially problems that are there and concerns that are there and so I still think that there\u0027s I still think there are considerations that should be addressed and we talk more about that awful well we can extend the middle book section so there are two parts of the middle book section the part between the client and the convertor I think this is the one where we should have the focus and then there is the part of middleboxes that would sit between the convertor and the final destination but this is part of the existing TCP extensions for that so I would focus on the client converter path and the presence of Mir boxes on those paths do you agree with that or do you want to discuss as well what happens when you have middle boxes between the converter and the final destination what I\u0027m concerned about is that when we see middle boxes we have problems because the middle boxes can go stale they may support slightly different versions of various drafts you also have a buffering that occurs there that you need to deal with people are trying to measure with timestamps get different results and there\u0027s a lot there\u0027s all sorts of things that occur at middle boxes and you\u0027re introducing the middle box now it\u0027s not a transparent middle box but it\u0027s still a middle box and there\u0027s still considerations that make us typically not like middle boxes being there and you need to make sure that you address those as part of your draft and say how the converter is not going to cause those problems or how it\u0027s going to work around the the problems that are inherent with little boxes yeah so if I have to propose right in my head then the big difference is that you\u0027re actually connecting to the converter so the destination IP address is the destination IP address to the converter you open an enter and TCP connection to the converter which is really not the same as a middle box so a lot of those considerations we\u0027re worried about really does not apply because it\u0027s an explicit thing the client decides to do "
  },
  {
    "startTime": "01:31:34",
    "text": "pravin Microsoft so I I in your slides you showed the success case where you know connection was successfully established what about the error cases where you know the server sends a reset back or it might be doing like DDoS protection it might be trying to validate the client\u0027s source address ownership how would all those things work so what happens if the server refuses the connection that was trying to be established by the client through the converter then the server will send a reset to the converter and the converter will relay the reset to the client so does it relay all TCP packets is this like converter trying to just relay all these B flags and is that what it\u0027s doing or is it no no so we have two TCP connections so there is one between the client and the converter and one between the converter and the server and so if the the connection which is attempted by the converter to reach the clock the server is refused by the server then the converter will refuse the connection to the client what we do is that we only send the converter will only send a syn ACK once it has received a cynic from the server because we want to be the client to be in a position to be able to detect whether the server is accepting the connection or not right what about like source address validation for DDoS attack prevention in that case the server would challenge the original sin how does this get relayed oh do you relay service validation with what kind of source address validation do you want you might be doing like Sinatra you might send a challenge act back or you might drop the syn to validate that the client actually you drop the sin yeah and you ask the converter to retransmit the scene right but on the converter you are trying to open the TCP connection to the server and so this there is a state on the converter that will retransmit the scene yeah because you are and this is this just seems like it will trip up all kinds of like DDoS protection algorithms because now this one IP address is trying to open like so many connections on behalf of so much so on this slide there is one IP address for the converter one for the client for the server but the deployment could use a block of IP addresses on the converter and have one IP address which is directly mapped to each client so it doesn\u0027t mean that all the connections will go through this true a single IP address from the converter so the converter could have a block of IP addresses here we go to clarify that in the draft if it\u0027s not already there hey Jacqueline my concerns are similar to chains I think the I had the the draft says no the configuring the list of converters in the clients is out of scope I understand but are there any configuration strategies that are known "
  },
  {
    "startTime": "01:34:34",
    "text": "to work like if you have for example when the Wi-Fi is in one network and the LTE is and another then it you know the draft talks about the routing would be configured such that only certain client IPS would reach the converter right so when when some of the paths are out of scope with the client is the client able to tell I guess besides not seeing the Cenac I\u0027m not sure understand what you mean so you are discussing about deployment where the client has multiple paths to reach the converter where the client has multiple paths and perhaps some of the paths do not reach the converter but if some of the paths do not reach the converter then you are trying to open a TCP connection and you can apply something like IP eyeballs or whatever to detect which path is able to reach a converter because the converter is an IP address and so you can test whether a specific path will reach the given converter okay so this is just our clients problem to determine whether bootstrap which allows a client to try to open a connection to the server if it has multiple paths then you can try to do bootstrap in parallel over the different paths and to see which path which is the server that it wants to interact that it wants to interact with and once it has created the would shrug to this converter then it knows that this pass is working to reach the converter okay so do you have a list of sort of expected characteristics of the discovery mechanism for the list of converters do you mean by expected characteristics I guess so we just validate the establishment of a TCP connection to the converter and we get the TFO cookie of the converter okay I can take and we learn what other capabilities of the conversion kind of the same and set me a cool event by the way and so you have an IP address so if your your passes I connect it to the Internet you should be able to reach the IP address it\u0027s not it\u0027s not like that the the converters somewhere on the path that you have to bypass you actually explicitly send your traffic to the converter so yeah if you if you try to connect to the converter and the converter try and convert it decides it doesn\u0027t want to support you as a client then it says like no not UCP connection for you you have to connect to the server directly right my name is Tim Shepherd as people have been asking more questions I get more confused about what exactly this is and I think perhaps there\u0027s another part of the story and that you also need a converter that is inside the client operating system "
  },
  {
    "startTime": "01:37:37",
    "text": "somewhere I don\u0027t know whether it\u0027s in the kernel or in some library but I was trying to imagine does the app have to be reworked so that it knows to come to connect to this converter instead of connecting directly to the server it could so it\u0027s and it\u0027s just like sucks we sucks you have libraries that will implement sucks and there are applications that support sucks yeah so this is this is much yeah so some of the person who I forget who was asking you know you have to talk about middleboxes this one view of this is this is much more like a socks proxy yeah it\u0027s a nice if so and then one of the somebody was asking about TLS earlier it\u0027s sort of like if if you\u0027re if this connection is being initiated the TLS would be between you could also there\u0027s two possible TLS is there\u0027s a TLS session with the converter and there\u0027s a TLS session with the well you might want to TLS session with the converter I don\u0027t think we want to have a key listen to the converter because we want the solution to operate on the bite on the TCP byte stream and put your some of the some of the payload of your session is actually communication with the converter and you might I don\u0027t know if but only the beginning of the payload so this will be stripped by the converter and there is so if you are there\u0027s no original session if you do a TLS session deterioration will be with the final server so you you\u0027re saying you would never want to secure the connection with the converter at this point in the draft no yeah but anyway so but all of this was unclear to me I guess is my real point as to what exactly you\u0027re talking about doing and maybe it would help if I read the drafts so looking at the TLS case so the the TLS case when you create a TLS session you know the IP address of the final server in this case you would have to change a bit the TLS implementation on the client to say that we reach this final server which is part of the connect tlg via an explicit proxy and it would be some I guess I\u0027m speculating it would be similar to doing a TLS session worth of some server out there or the net through a Sox yeah yeah your guys will sock your connection to the Sox gateway as one IP address but the u the TLS session would understand that it\u0027s not actually the TLS session is not with the same IP address that we\u0027re sending the packets to that we\u0027re opening the TCP connection to you yeah so thanks for helping clarify that a little bit beyond midst of Apple other question in regards to the TFO converter functionality here I would imagine that in a scenario where the access provider is deploying converters large-scale there will be many many different converters sort of like a load balance scenario maybe and I could "
  },
  {
    "startTime": "01:40:39",
    "text": "imagine that the outgoing appeared rest from the converter to the actual server might be changing in which case you might not get much benefit out of converting TFO because that relay cookie won\u0027t be valid anymore it depends on are you will manage the IP addresses on the converter but if you look at IP v6 for example with ipv6 you could have a deterministic way of mapping the client address onto a converter address and I think this solves your issue and the other point is that with the bootstrap procedure the client is able to connect to one specific converter and so there is some stickiness in the relationship between the client and the converter so you don\u0027t go through one converter or another from HTC from one TCP connection to another you just when you boot your client you select one converter and you will stay with the same converter for some time for some time but typically T of a key on lifetime might be longer than some time but whoever could go out of business could go into maintenance and then you might have to select a different converter breaking TFO to the actual server is just a minor command it\u0027s not yeah but then when you go to maintenance then you will detect that you are not to the same converter because your cookie to the converter will be refused by the converter so you will know that all the cookies that you have learned you have to on the client side you have to delete them because they are not valid anymore because you are not sure that you are using the same ip address with your final server but this is part of the client implementation yes but not of this if the converter was a low balance converter that you don\u0027t know what you connect actually to user connect to the same IP address which might be preferable yeah but then there are there are questions on all you want to deploy the converter and all you want to do load balancing for the converter you have to take special care because this is not a standard web server this is something apps you can chain and I think it would be really helpful in a draft to have sort of a walkthrough of the process they say a mobile phone client trying to use this feature and wants to go to su TPS youtube.com how does he get the converter address and how does he initiate those connections and I think that will help a lot of this sort of related problem of middle boxes and deployment schemes because right now we\u0027re trying to infer that based on what you presented and that\u0027s why you get so many questions about yeah so we can write this as an appendix but there are multiple deployments that are possible so we can find an example where for example you would have a DNS name that corresponds to the converter but this is not the only possible deployment and so we can just provide that as an example but there are many deployments that are possible yeah I think an example will "
  },
  {
    "startTime": "01:43:40",
    "text": "help and therefore you can say this is not the only way to use that but it helps a lot too we can just end the scale thank you you can ask clarification questions since you are talking about implementation so can you can we implement this everything on the user and what do we have to modify TCP stack so the main issue is on the convertor side if you want to implement that solution when we receive a sin we don\u0027t want the TCP stack to reply immediately with a cynic so we want to delay the acceptance of the sin until we have accepted the connection from the server side so this is not totally a use of space implementation so you need to extract the sin put it in a buffer while you are trying to open the connection to the server and once the connection to the server has been confirmed then you can put the scene back in the stack from the establishment of the connection okay so then so someone is working on implementation so what\u0027s kind of platform they allow so there are three implementation that I\u0027m aware of and the plan is to discuss with the implementers and to try to do some interrupts test before monreale and get back in Montreal with results from interoperability test okay thank you so if there are no further comments then thank you and continue the work so the next one is Fernando doing this remotely and it looks like he wants to use his screen let\u0027s try this finale so you think you need to go to the mic if you heard hear me then we can accept you here he is okay we see you and here you are you going to see the slice from my screen or are you going to show them from your screen I can show them from my screen and it would be nice if you could you are very loud in this room if I could okay calm down where\u0027s the sequence number stuff okay "
  },
  {
    "startTime": "01:46:45",
    "text": "so hello this is going to be a very short presentation about an idea that we wrote with David Orman next slide please so I assume that you have read previous versions of this document essentially if you look at 793 there\u0027s essentially a bug in the sequence number validation essentially with the rules that we have in RFC 793 there are three scenarios that would actually fail one of them is the TCP simultaneous open the other is the TCP simultaneous closed and the other one is the case of simultaneous zero window groups essentially all of the stats that we know of have fixed these issues like many many many years ago but the relevant standard 793 was never updated in the respect next slide so what\u0027s the goal of our document well first of all document the bug second propose a workaround for it third to document other implemented workarounds like we proposed one of them but for example Linux differs from that one and formally update 793 and it\u0027s like so essentially when it comes to the difference of what we\u0027ve proposed versus what some other stocks have implemented essentially with a simple change that we proposed to 793 which is for example what has been implemented on bsds for like tens of years essentially we accommodate Windows groups of one bytes whereas in the case of Linux they do like a more let\u0027s say more general test in which they allow for simultaneous zero Windows proofs of any size not just one bite I mean one byte is the de facto standard but they accommodate like Windows zero window groups of any size next slide so essentially what where we wonder what we should do with this document a couple of years ago when you know the last time that we had committed time on it some folks have argued that we should be documented what other stacks are doing so so far our Eddy contains done so the "
  },
  {
    "startTime": "01:49:46",
    "text": "our question to the working group is whether you know these should be adopted as a working group item or or what\u0027s the proposal way forward any comments this particular button is Matt Mathis this particular group of bugs are in the category of things that caused me to may not encourage being about any new implementers that there\u0027s a lot of really important details and implementation that are not written down you\u0027re getting them written down would be a major step forward and actually get a completely self consistent description of the protocol itself you John Chen can we just merge that into the 793 piece is so this is Michael speaking that is certainly one option that we could discuss however formerly when we adapted 7n Cerebus we actually decided that we will only adopt changes that have ttpm consensus or even IETF consensus to be precise so we would violate our procedure having said that it\u0027s certainly one option and that we have as far as I know ves has at the moment an informational comment on this problem already in some non Cerebus I mean changing the equation according to our previous consensus we would actually need a standard strike specification for it as I said we can discuss what we do exactly but if we would change seven months rebus in this respect we would probably have special care specifically on this change because we don\u0027t have the RFC for this specific thing so since I the way I understand your the suggest sequence is first we need to have consensus that this is indeed a problem we want to work on and then decide whether to put in our sees the best ORS or a new RFC yeah I mean for sure 479 Cerebus the most important thing would be to agree on if other than acknowledging that there is a problem if there\u0027s agreement on on one solution several solutions and possibly on recommendations to implementers because it\u0027s already understood there\u0027s more than one solution to the problem but the key question is is do we know that there is a minimum solution for this or is the only thing we can do with documenting or set of recommendations to implementers how to work around that back and that actually is something that this group has to decide so so my question is what\u0027s wrong with 1x0 window probe I mean that\u0027s the problem it\u0027s not that "
  },
  {
    "startTime": "01:52:50",
    "text": "it\u0027s wrong the thing is that you could actually send Windows proofs of any other size so it\u0027s like a the one by window probe is a de facto standard but nobody requests you or requires you for this zero window prove to just be exactly one byte you could do zero window proofs or five bytes if you wanted so but so you want to relax the current standard to allow that or no no no actually what we proposed in our document is to accommodate this see no window proofs of one byte okay now when it comes to see to see the window proves there\u0027s nothing that requires you that they had to be one byte so what Linux did which is not what we are necessarily recommended is accommodated we see no windows probes of any size that\u0027s not there we actually what we do in the document is just accommodate the case of a one byte 0 window probe because that that\u0027s the de facto standard but Linux they made it more general I guess that they said ok well if there\u0027s no requirement that those have to be one byte then we should accommodate 0 windows proofs of any size and that will cause some problems if Linux is doing that today no no at all okay I guess I\u0027m not clear what problem we try to solve here other than improving the arms changing the RC No so you have a problem the problem that we have now is that there are three scenarios that fail with a car what the text that you have in 793 those are simultaneous opens simultaneous clothes and simultaneously the windows proves so that\u0027s the problem we had that we are trying to solve now we have one proposed workaround for that which you know solves all of those problems accommodates you know Windows proofs of one byte those are the different two standard okay now Linux when they fix it this problem they made the fix more general and they say okay we want to below zero windows pros of any size not just one byte which is the de facto standard okay now I understand a problem I think I need more time to asses how important or series these problems are micro tricks unless an individual I think what this document is missing right now is documenting the solutions used by several operating systems so you describe Whitely how Linux is doing it but I think it\u0027s agreed it\u0027s a problem in the specification we don\u0027t know what all the implementations are doing so I would suggest reach out a couple of implementations and document what they are doing I\u0027m willing to offer help for FreeBSD but reach out also other ones and document this in this industry what we "
  },
  {
    "startTime": "01:55:50",
    "text": "propose you know what ID is what BSD stuff it be as these two actually uh it might be my David Bowman himself that implemented the fix in BSD but I might be wrong but what the world we propose is what the is these do so this is not stated in the document and reach out other operating systems as well so that we have a that we can see okay it\u0027s out there the other point is I\u0027m not sure I\u0027m not fluent in the RFC\u0027s but I my impression was that your window probing is tied to one additional byte you can\u0027t over booked by 10 MSS so I don\u0027t know about that but reach out implementation status lot of tigers I think that fixing the bakken in 793 is sort of a no-brainer and we should we should do this and um whether that means that we do Narada against 793 after we request consensus what should be in the Nevada or if we put it in 793 piss which will eventually obsolete 793 I don\u0027t really care right but I think fixing this is a good thing um I would also sort of I think this is going towards what the previous because I said it would be nice if whatever we did wouldn\u0027t render major strikes immediately out of compliance because you know we are late here they have all fixed this so if we can if you can write text that um the documents what mail major stacks have already done and and doesn\u0027t force them to change what they have been implementing for the last couple of years that would be nice so that means allowing certainly the one-bite thing that vsts are doing but maybe also permitting the multiple bites thing that linux has been doing um not that linux lengthy would really care a lot I think if they all of a sudden didn\u0027t follow this new RFC anymore but it would be nice I think and similarly to Michael\u0027s point on understand what the stacks are doing before we make a recognition this is step one to that but yeah this seems like a no-brainer to to do and it shouldn\u0027t take very long quote unquote okay so I think the the question was adopting this as a working group document so my view is we should first get the document getting information about implementations and and this stuff I\u0027m not we are not asking about working up adoption right now what we would like to have a show of hands who is who thinks that it\u0027s good to address this area this problem space or who things it doesn\u0027t matter so can we have a show hands on our Fennell Fernando is coming wait a minute um yeah the connection with that I just want response to would large Lars mentioned I agree with that and you know while the document right "
  },
  {
    "startTime": "01:58:50",
    "text": "now proposes like world work around the to you know we could you know propose like to alter they walk arounds and that\u0027s fine regarding you know whether these should be fixed or not I\u0027m curious myself if you could actually move seventy seven hundred ninety three bees to standard if you actually don\u0027t fits it because you have the requirement to actually face known bugs on that one as I said I think there is already text on this known issue here and so and the only thing that at the moment is missing I think in seven landscape is is a change of the equation so I mean I think the text already states that there is a known problem there and there are known solutions for workarounds and as this community could agree that that\u0027s good enough but can you actually move the document to full standard if the document has no problems well we my understanding of the process is that Semillon Cerebus would be proposed standard but I don\u0027t know what the process sort of fine but I think it doesn\u0027t move directly to full standard if it\u0027s a bit ok but anyway I mean this document actually it has a different scope that not a seven lines rapist so because it also removes a lot of content in there it\u0027s only the base specs so I don\u0027t think we\u0027re safe from our problem here but of course I mean having a back in a dis document is certainly not perfect I think we all agree on that I think given that it\u0027s clear that there excuse me that the that there are bugs in 793 excluding them from the scope of 793 bist seems kind of artificial it is what the words were written back when the planning was done but this bug feels to me like it\u0027s below the horizon for being a scope change blow the limit for a scope change and important enough to do that as an exception I really am uncomfortable with the idea of leaving 793 containing a bug that we know about that we\u0027ve known about for too decade so okay coming back to the show of hands so who thinks it\u0027s it\u0027s a good thing that\u0027s this working group deals with this issue not saying that this document has to be a working group document that work on this so who thinks this should be addressed who is against Ted okay thank you I would say for the note taker I\u0027ve seen probably of the order of twenty hands and no objection "
  },
  {
    "startTime": "02:01:53",
    "text": "TTP fast open hello everyone this is a talk on how the experience with deploying fast open on the internet has been going so far I present with some information that the last IETF this is more update since then can we go to the next slide please a quick update so we enable this by default in the fall creators update which has been out in the market for a while now it is the significant majority of all Windows 10 devices at this point so the way we could enable fast open was to build a fallback algorithm so when you know there are middle box problems how do you safely recover from those so for that first we built a middle box that simulates all those known problems so it also serves as kind of a regression test if you want details on what kind of test cases we added it\u0027s in the previous presentation so and then we ended up implementing a passive probing algorithm when I say passive probing this means there\u0027s actually using active user traffic I should have used the word active but it\u0027s actually using user traffic to figure out if TFO works on the network last time we found that around 26% devices were successfully using Tier four and did not fall back and then we also did a AV test to see if there was any correlation statistically significant code with page navigation failures and we couldn\u0027t find any problems which mean which meant that the algorithm was actually working fine we did find that you know there were failures that were correlated with both specific networks geographies next slide please this is again a recap of that fallback algorithm I wanted to quickly go over this so this is limited passive probing so the goal here is to not impact user experience so when we do probing we want to make sure that we don\u0027t sacrifice too many connections so this is the way this works is that because establishing that TFO does work on the network requires multiple connections to the same server which means you need multiple probe connections but we only allow one probe connection to go through at a given time on a particular network it\u0027s think of it like a sema4 so if you are browsing to let\u0027s say xyz.com then you need to go to that site again but it may not necessarily trigger the probe if the previous connection was still active the next probe will not go out so this is sequenced in time the other important thing is that we wait for the connection to be close reach the closed state before we can figure out whether the probe was successful and then it has to match all these other conditions that you know no reset was received in response to sin no sin time out the connection didn\u0027t fully timeout data was exchanged in both directions the connection wasn\u0027t cancelled by the "
  },
  {
    "startTime": "02:04:53",
    "text": "application and no certain are TT increased during any time in the connection lifetime if all of these kind of conditions match then we mark the connection as probe is successful and two of these probes have to succeed to the same server for us to say hey TF or succeeded on the network if we hit a fallback on any of these probes we persist that information and never attempt it again if we hit success then we continue using tier four for that boot session so this was the algorithm as implemented in the follow creators update there are some shortcomings here the the goal here was to be very conservative we wanted to avoid any problems with the user experience so the algorithm was you know very conservative one of the problems is that the sin timeout heuristic is actually a large fraction of you know the fallback use cases we see in terms of you know if you look at the pie charts the sin timeout is is a pretty large chunk of it and that could be because there is just connectivity issues and we also don\u0027t persist success which also is very conservative because you know if it\u0027s succeed on a network is highly likely that it will succeed again we also assume that the problems are closer to the client and not the server and then there are possibly long delays before we can figure out 50 over actually works like if you have a long-running HTTP 2 connection then it for it to reach the flow state it might take a very long time and then you would delay enabling fast open and for that duration because of the CMOS order that I described earlier the other cases like you are the connection to could take a very long time out of the outlet II was very high there is also the problem of the the worst case middle box like the middle box just sees the TFO cookie request and then just blocks all traffic from that IP address that\u0027s like the absolute worst case for tier 4 and this algorithm doesn\u0027t really help you know the user experience is still bad if that happens an X light please so in the next version we are actually making the algorithm more aggressive firstly we will persist now both success and fallback so if we do see probes succeed on a particular network that is kind of remembered forever until until we decide to you know object the operating system again essentially we also will start off every device to probe again because this is a different algorithm so we are starting with a clean slate so when this update goes out to the devices they will all start probing again the because the same timeout was so aggressive we\u0027re actually now only turning off TFO if the syn with the TF option failed in the subsequence in succeeded this kind of tells you that it was not because of you know network connectivity it was because of the option and the probing is because of this change now the probing does have to be restricted to Internet "
  },
  {
    "startTime": "02:07:53",
    "text": "connected networks you could exercise tear flow in a private network if you wanted to one more case that Rose found is that in some places TCP options are just reflected back to the client so if you send a cookie request the server sends you back the cookie request option I mean that\u0027s just weird deployment so we just again use this as a condition to turn turn the feature off next slide please some more data so this is kind of the overall population right now retail devices out there this is from the fall Korea\u0027s creators update with all the spring creators update is not yet deployed 45 percent of devices complete TFO probing which means they go to a TFO compatible server multiple times in that boot session is a clarification question on the previous slide very quickly he said when the subsequent syn succeeds you only fallback your sin fails on subsequent one succeeds how do you define subsequent in addition to the fact that it\u0027s happening after this is the timeout and a retransmission yeah so that sin has to succeed it\u0027s a retransmitted sin yeah without the okay yeah very cool thank you so off those devices then we find that overall about 46 percent succeed and 54 percent fall back so if you look at like your overall population it\u0027s about like 21 percent because the number of devices have grown the other shortcoming I did not explain was that because we\u0027re not persisting success it is possible that if they\u0027re correct if T failures later the overall device population might taper over time because we\u0027re not persisting success so if you do it as in time out subsequently a device that previously succeeded could eventually fall back we do expect that these numbers will improve in the next update because the aggressive same time out logic is going away we do find that there are some really poor success rates in some geographies China for example only 3% devices that completed proving succeed with Tier four and in India it\u0027s about 18% though not great numbers and then we repeated an a/b experiment on the retail population which is we have a much larger device population right now and again no significant correlation with page navigations which tells us that the algorithm is working as intended next slide please looking ahead this algorithm is really complex so what we are looking to do is whether we can simplify this it seems to us that you know one of the better ways of doing this would be to actually use active probing which means that you know we don\u0027t end up using any of the user traffic to figure out if tier 4 works this solves those three problems which we haven\u0027t addressed yet which is like it could be long delays before you figure out if tier 4 works you know user "
  },
  {
    "startTime": "02:10:53",
    "text": "experience could still suffer if something bad happens and then this simplifies the whole algorithm and then the the other remaining problem is if the problem is closer to the server side and there you could do some form of happy hours this is all like looking ahead we have not yet actually done any sort of implementation for solving these problems one of the important things I wanted to ask is that other browsers should now consider enabling Tia phone windows because the operating system has fallback algorithm the browser\u0027s do not need any kind of complex logic to detect if this feature works the safety is provided in the TCP stack itself so it should be pretty safe for browsers to turn this on and rely on the built-in for all back algorithm in the operating system the questions I want to try and with is seven four one three seems like an important RC to me given that you know yes I realize that quic is you know gaining more traction but then there are networks where it will not work and you would want to achieve zero oddity with TCP so it seems to me like something I would recommend that this group consider whether to make it Sanders track and then if we do go along that path it might be useful to document possible fallback algorithms for dealing with metaphors problems Jenna Inger thanks of the presentation that data is great there\u0027s a quick question on the data and the previous slide if you can go back to that you so I know that there\u0027s one particular error that the Apple folks encountered and I don\u0027t know if you\u0027ve thought about how you might be able to provision for that and this was when a TF of sin was sent the entire IP got black hole yeah have you thought about that yeah so I actually covered that as a shortcoming with this fallback algorithm we cannot recover from that case so regardless of whether you do active roaming or this passive probing algorithm you can never recover from such a case and yeah yeah we are actually not seen any kind of problems in the deployment so far which means you know such a bad case is actually not happening out there all right it might be good to see if if it\u0027s if it\u0027s an a/b experiment if the total number of connections that are failing it is in fact different like the total population of successful connections with fall back without fall back every yeah we we correlated this with navigation failures in the browser and there is no such statistics statistically significant correlation so which means yeah it\u0027s not like turning onto your first causing pages to start failing to load that\u0027s good to know although unfortunately the Apple experience still seems to suggest that even if it happens on a tiny fraction of cases it\u0027s quite it\u0027s fatal effectively it\u0027s it\u0027s tiny enough that we can we can "
  },
  {
    "startTime": "02:13:53",
    "text": "chalk it off on the next slide so I\u0027ll just finish this one thought before I give it back to media I believe that this is still I believe it should see all the experimental track I absolutely believe yes fallback algorithms are critical to the success of anybody implementing this so I absolutely think that fallback algorithms should be documented and I believe that the experiment that people conduct should include fall back as well as the restorative of thirteen and we should come back to the question of whether two standards track after we\u0027ve had more data on both the fallback and on this from of vendors but yet be very supportive of having the fallback algorithms in there kudamon are any of your data also for connection about mobile cars yeah this is a mix again I can\u0027t tell you the distribution like the mobile footprint of Windows is not that high compared to other operating systems so yeah I mean I don\u0027t have the exact breakdown but yes this covers all possible devices including Xbox consoles and see if there\u0027s different between mobile networks and break it down by network yeah it would be good to do that breakdown but I think like another vendor which has a bigger mobile presence will need to do similar data collection too to be able to give you a better answer for that so in this case I agree with Jana that we would need more tighter especially from abandoned or soup to move to standards track and documenting fallbacks also +1 I guess see if I was special but some of the forwards might also apply to like every other to TCP option we have probably yeah for example easy and so yeah Christophe Apple I had a question what do you do you have like any plan for handling the unknowns because the way TFO can fail or middleboxes can mess up TFO is basically the the number of ways that they can do it is basically in finite for one example is we found one mailbox you send us in with data it gets acknowledged you can send a lot of data you can receive gigabytes of data until you stop sending that the traffic stops for 10 seconds after data connection breaks and it was due to TFO like that which is why we we on our side we are still very conservative and don\u0027t there yet to enable it globally Oh if you experience I mean so if you look at the conditions for this probe to succeed they are very exhaustive right so connection should not timeout that is one of the conditions right so but do you have a 10 second idle period in the connection the probe connection may not you\u0027re right so yes if the our connection does not experience this then yeah there is no guarantees that you will be able to recover from such a failure well this is again like we cannot cannot cover like infinite cases "
  },
  {
    "startTime": "02:16:54",
    "text": "absolutely well I\u0027m basically saying is that there are things that we can\u0027t foresee and they still happen so this is Michael speaking from the floor this is just to share my personal opinion on that on the last question that I\u0027ve said before privately I think we are already relatively close to the data that we knew it would need for proposed standards here because the one thing is you see here now and pretty impressive data already I mean for sure we can ask for more and that would be good but already we have experienced visits so that that\u0027s one of the prerequisites that we typically have in eCPM for moving to standards track is from my point of view already closely fulfilled the second thing is we see other people using TFO now and this is typically our sign that there is some value in doing this and this would be to me another reason that this is actually clearly a candidate for PS and PS means proposed standard it doesn\u0027t mean internet standard I would agree I think this is critical critical work because TCP is here to stay whether you know even even if quick takes off I mean you will fall back to PC Mag Mathis I wanted to suggest that at this stage that a single data point or very small number of data points that are really bizarre is probably not too worrying because they\u0027re probably from handcrafted boxes for instance specialized security appliances that are hand curated in front of no such agency and they can have outlier bugs or outlier behaviors that we don\u0027t expect because they\u0027re defending against attacks that we don\u0027t know about and I would bet devices that for instance exhibited this black hole behavior no longer do that and so I would argue that once we get to a critical mass all the devices that do really strange things will disappear kind of low population yes I agree I mean when we did window scaling we there were stories of like routers rebooting and whatnot so unless you deploy this you\u0027re never going to move the ecosystem forward I also had a conversation with somebody who said yes please deploy because I\u0027m trying to get my management to replace these damn things gen-i and god I think I\u0027m partly echoing what Matt just said which is we can\u0027t I don\u0027t think it\u0027s sensible to even look for 100% coverage it\u0027s completely reasonable to have some failures and I think that\u0027s natural normal and it ought to be expected but I still think it should be I mean it\u0027ll be an experiment and I think the the fallback is absurdly critical but I yeah I guess I just want to record matt said is your see from from macro Mike about the making RFC 74 "
  },
  {
    "startTime": "02:19:58",
    "text": "awesome to post one three proposed standard I have little concern about it because no we cannot use therefore any kind of TCP connection if we can be used with T areas that\u0027s fine but it\u0027s sometimes not the case then we have a problem for it impotency and draft 74 fun something already mentioned such concern para if we make it proposed standard we have a very sorry little guy trying or applicability without such things it\u0027s too risky to make it proposal standard that\u0027s my opinion that\u0027s nope yeah absolutely I mean we need to document the dangers of 0 et this applies to more than three or four and then yesterday like Windows implementations always doing this only on TLS connections you Junction here I\u0027m not sure I agree your point about TFO being a standard because when he avoids proposed as the experimental people already make it very clear that I have two documents that the TFO requirement particularly barb here that TFO is only good for item potent applications and that\u0027s already clearly documented so if you want further warning we can improve that I don\u0027t think this should be a barrier to the standard tract and that was this is Bob this is what I was coming up to support you chung because as i don\u0027t think you should not say something can be a proposed standard just because it\u0027s got limited applicability otherwise tcp wouldn\u0027t be a proposed standard because you can\u0027t use it for unreliable connections by definition all of the work we do is limited applicability Jahangir I had a question actually I did want to also ask something else I forgot earlier about the data it\u0027s very interesting that it\u0027s the that you have such a ridiculous skew in geography you said only 3% of connections were successful in China and 18% in India do you have any more insights into this because that seems like that seems surprising to me 18% is a ridiculously low number but it\u0027s half of what you were seeing otherwise all I can say is that it\u0027s not like one ISP we see this across networks in those geographies so it\u0027s probably some middle box it could be the firewall I don\u0027t know we don\u0027t have those details at this point do you have data on the type of failure that was encountered like was a dissent which of the which of the failures that you listed up there was encountered yeah I don\u0027t have the data right now but it we I think I\u0027ll try to dig that up for you offline I\u0027m curious in the next IETF because right now the the one of the problems is that sin time out here restrict which is because of just bad "
  },
  {
    "startTime": "02:22:58",
    "text": "networks you could hit that all the time and that would be one reason why the success rate is so bad and now that is going away in the next update we might get different numbers and yeah I will get back to you I had a similar thought about the the subsequent no this no subsequent but connection timeout after handshake sacked after handshake success which could also be something too mind it might be I don\u0027t know how to think about beliefs in the data it might be worthwhile look not normalizing that against what the normal connection timeout is for that regime for that region or for that particular grouping whatever you have just to understand if that\u0027s actually a causal or not yeah that\u0027s a fair point so again like the goal here is to be not very aggressive because we are using user traffic once we do active probing you know we might be more Mia more aggressive than this I was trying about in terms of analysis rather than in terms of actual mechanism sure yeah that is useful data point together yes thank you so any more comments no so I think it\u0027s a looks like okay so we want to do is run one small comment - my column yeah alright suppose anger I was wondering whether you have any analysis of happy eyeballs as well and I\u0027ll be helpful to know how you guys do happy eyeballs in and to give some guidance unhappy eyeballs easy we don\u0027t so we we have a custom implementation of happy I was not the algorithm in the RFC for ipv4 versus v6 for TF over there is no happy I was because yeah we just used the user connection to to probe so if if the connection was v6 which is preferred usually we would do the probe on the v6 connection say we want to do a short show of hands who is in favor of evolving this into a PS direction so for the note taker I would say 15 anyone against it none okay so for the last presentation we had planned 10 minutes if they are available we have five minutes available great thank you hello everyone my name is ginger from Molly I\u0027m here to present our job to a new eat Mike okay I\u0027m here to present the draft a new congestion control in bandwidth guarantee network "
  },
  {
    "startTime": "02:25:59",
    "text": "my co-author Tim presented a draft called invite signaling for transport us at last ITF so one suggestion will receive from lhasa ETF was to write a separate congestion control chart so here we are um here these are the prerequisites to use this new congestion control algorithm is not meant to replace existing TCP congestion control so is only to be used for applications which has really like high-bandwidth low-latency requirement that current tcp Canal satisfy and then together with the invention link then you can use this new new algorithm so two important prerequisite first you have to guarantee the bandwidth before the data transmission you can either use out-of-band or invite signaling and then the second you om data is used constantly to monitor network state status more important it used to offer to monitor the queue taps once it reaches the pre config threshold it will send an alarm to say to indicate that the network might be congested so they slices the congestion window comparison between the proposed algorithm and the TCP Reno so important thing to notice is since we have the Ballet\u0027s guarantee so we don\u0027t have slow start in case of tcp start our faster recovery the transmission the congestion window can jump to say our rate right away and then um the OEM alarm together with the duplicate Ike is used together to indicate a congestion in that case when that happens with the congestion window size only chops to the ER in case only duplicate duplicate ACKs are received we don\u0027t reduce the congestion window size so this is important so we use OEM to detect whether it\u0027s really pegged the duplic package applied because of real congestion or because of a random failure okay so this is summary of the important changes so it\u0027s used for Perez guaranty networks we don\u0027t have slow start but young to see our directly and in case so the congestion window size stays between Sarah and MPR during congestion avoidance and important om is "
  },
  {
    "startTime": "02:29:02",
    "text": "used to indicate whether network is in congested or not so the next steps we want to collect more comments and we want to refine our POC to collect more data especially compared with other algorithms also to make our and be in basically hard work better with this algorithm together thank you this was really on time our scale is now over so that\u0027s why I would suggest put the get there discussion on the mailing list it already started there and then this concludes this meeting thank you for attending see you in Montreal and if you haven\u0027t signed the blue sheets do it now and bring them back you "
  }
]