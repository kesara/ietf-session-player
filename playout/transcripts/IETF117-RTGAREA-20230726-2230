[
  {
    "startTime": "00:00:26",
    "text": "Everything going alright in here. No technical Roblin's. defer the Okay. I mean, not. So much of a good -- Okay. Good. Well, have a good meeting. Yes. Hello? Cool. Woah. Sorry. Don't eat the mic. Woah. But the last meeting, I was at somebody did a literal mic drop by accident, and that was does pretty exciting too. So I was just gonna say, you know, hello. This is the routing"
  },
  {
    "startTime": "00:02:01",
    "text": "a open meeting. If you're just hanging out and back to chat with your friends, maybe go outside to chat with your friends. If you're here for the routing area open meeting, take a seat. Take a seat. Take a seat. Dan Rob, Okay. So Welcome. It's the routing area open meeting. We've got 90 minute for agenda, and I think we don't have 90 minutes worth of agenda. So Hopefully, we'll you all a little bit of time back in your afternoon, which we all could probably could use. we have a note well. It's the same note well you've seen before. And since You all agreed to it. It has important information, including about things like everything you do here, may you go into public record and what your agreeing to do with respect to intellectual property that you may know about and things like that. If you haven't read these documents, very boring and very important, and you should read them at least once. those of you who are working chairs are also used to working group chairs are also used to telling this to all of your working groups. I swear I took out that 5 minutes thing there, but guess they put it back in by accident. Yeah. We're like I said, we have plenty of time. So and not gonna try to stick to very specific time slots. So, we do have time for this to be an interactive session, which would be nice. So scribe selection, I I've noticed that there was a lot of talk on I don't know if it's the attendees list or the tools list about how robots can do all of our scribe work for us now. There's the"
  },
  {
    "startTime": "00:04:00",
    "text": "transcription that's running up the side and that's getting my words fairly accurately. So If anybody feels like taking notes for us, that would be nice. but I don't think we're gonna hold the meeting up otherwise, So If you do feel like taking notes for us, you know where the shared notepad is. is our agenda. This if anybody feels like they want to bash at it. Tony points out that I have the wrong name. That's a TVR. Ed will be presenting. Sorry for the error. Let's see. we will have a any other business after the You know, things that are on here, So if something comes to mind during the meeting, we can take it at the end. Yeah. So state of the area, we have closed one of our working groups, SFC. Thank you for all your work. we have two working groups that will be closing soon. Babble will be closing soon, and so will rock, raw's work will be moving remaining work will be moving into debt net. And we don't have any new working groups or any new buffs at the moment, which is okay with me. Okay with me. But we had a lot of action over the last few meetings. and we had a wanted to say a few words about author list and document quality, and I think Andrew is gonna talk to those. So yeah, thanks for all being here. authorists. This is something that's come up you know, a fair number of times over the lost while and Particularly in the last couple of weeks, I think the IESG has been looking at ortho list"
  },
  {
    "startTime": "00:06:03",
    "text": "quite closely. The current documents actually say there's a 5 author limit. and If you're going over the 5 awful limit on documents you need to actually justify it. We've had a couple of instances where the justification has come down too well because the authors want it. That is not a justification. It it simply isn't. So what we are now saying is that if you go over the 5 author limit, if you can't really give a solid justification for it. then it's gonna come down point an editor and move the people to the contributors, and we're gonna get pretty strict about this. the IESG used to be pretty strict about this, and then it wasn't. but we are now returning to a position where we really need to avoid these really long authorists, etcetera, and they need to be justification. So that's just note to everybody, so please be aware of it. issue. AC Lindem Labin. You know, I got a document right now that was emerging of a number of different r, techniques for ISIS fast flooding. and all the I can say all of the offers contributed. It's not it hasn't gone to the ISG yet, but it's in working group last call. I really don't Notful. You say you're gonna be strict, but you don't get into any reason why you're gonna right, on this. I mean I mean, I'm gonna continue if I think There's gonna be longer offer list, I'm gonna continue to put it in the shepherd's report. that all these people have contributed and list their contribution And And note what I said about sufficient justification and you can say, these are the people who have contributed, and here's what they've contributed. that constitutes a sufficient justification. So why how is this a change then? How is this any change policy that we've always had? It isn't a change."
  },
  {
    "startTime": "00:08:04",
    "text": "so what you described as best practice, not everybody has been following practice. Okay. And it's been devolving. Okay. So okay. I'm okay. I'm fine. I'm all settled down. If you can point to, like, paragraph fit like, this person wrote, you know, like these lines. That that's good. That's great. We we have you know, I know. Andrew was not I've seen them where they don't fit on one page. I know you're talking -- There's there's that, but we've also gotten documents, you know, recently. We're literally the justification provided was because the authors wanted it that way. That that's not -- Okay. -- that's not a PowerPoint. It's a quote. I agree. Okay. Okay. Yeah. So that's just the quick note about author of this please be aware of it. Yeah. Oh, and if you are getting up to the microphone, please put yourself in the queue. It just makes it easier. Then we get to the topic of document quality. Now this is always an interesting topic. what we as the as the ADs kind of feel is that we are prepared to commit the if documents have technical issues, we will balance the documents a lot more quickly, to avoid a long cycle rather return them, get the issues fixed, and we proceed speeds up the documents. That's on the technical issues side. We've also been getting a lot of documents recently where The drama, the spell checks, etcetera, or Not good. Not good. Not good. at all. and what we are going to be saying now is that if we start finding that We will return the document to the working group has insufficiently reviewed Insufficiently edited, By the working group, not properly checked. when it comes back to us, It speeds it up."
  },
  {
    "startTime": "00:10:00",
    "text": "And if the working groups do a solid job. Look, we understand that A lot of the documents, you know, if you've got non native English speakers for example, there can be mistakes, etcetera. But you've got a working group. The working group's job is to sure that the document that comes to the ADs is of sufficient quality, and If people want shorter queues and shorter turnaround times, it takes a lot of time for an AD to work through a long document with a lot of problems. So we're gonna get a lot more strict about document quality as well. you know, it's It's been a long time since I saw documents being kicked back to working groups. It does not happen often. I suspect you're gonna start seeing it a lot more if people are not you know, more diligent on on on those reviews and on the quality before they come to the eighties, not because we wanna be difficult but because People are saying queues are too long. It's taking us too long. this is the one way to sort it out to actually reduce the the the amount of time it takes to move a document. best. Yeah. And we have somebody in Jeff. Jeff. Jeff. That's Jeff, I was, like, gonna repeat something from the routing shares meeting because not everybody was in that meeting. flagging stuff is basically meeting language review. It's good thing because it means that when Spice is ready to detect review, their brains that short circuiting because of the grammar. And and these things can be flagged separately. The thing I'm strongly suggesting to everybody is that if we're gonna have process for this thing. This isn't something that anybody inside of a specific working group has to own. You know, there's gonna be a directory. It could literally be every to the hands that"
  },
  {
    "startTime": "00:12:00",
    "text": "you know, thinks they do okay in English. But to make that easy, we need to have a workflow that the patches can flow in nicely. And doing that against ID. Nits markup is pain in the ass. I'm going to strongly suggest to the ADs to consider making it processed, if we're gonna flag this sort of thing Make them stick it into GitHub, You know, I know it's an optional piece of process right now, but it means that you can take grammar is very easily and then incorporate them very easy and get review audit, very easily. I think that's definitely something we can have a discussion about John. I'd I'd probably rather discuss that further over beer than try to do it right now at the mic. but you know Thank you for the suggestion. You know, high order bit being like we can use tooling to get our cycle times down. This is a good thing. Agreed. Sue Sue, In my professor hat, we use Grammarly as a platform. to test grammar and spelling. is that an acceptable one? Sure. I'd I'd don't wanna be, like, you know, mandating a particular commercial tool from the chair here, but absolutely, I actually also use that and find it to be fairly adequate. Yeah. Just just one note. I I also use that a fair bit. I I would say that one of the things to to keep in mind with all of those is that I found is that Some of those pulls do also kick up a lot of false positives. So you you know, it it comes and goes. But, yes, they help. And I'm we're not gonna mandate any tool. All we're asking is that people, you know, do the checks properly. Right. Then this is not like a case of your your document must lint completely clean under some a case of"
  },
  {
    "startTime": "00:14:01",
    "text": "If we you know, if it doesn't pass the smell check when it when it gets sent to the AD, we may send it back instead of hanging onto it for a long time. purpose of Grammarly. if Sue wants to respond. The question was, it's one ruler that we might use that you're happy with. That's all. Tony, is also gonna suggest dropping it into MS word. or ChatGPT. can also proofread. Lots of alternatives, guys. There is no excuse. And this is strongly, strongly recommended if English is not your first language or even if it is. Tara. From my end, I just wanna say that I think if the IETF wants to invite, like, more people from the wider world to be able to participate I know that automated tools can help sometimes, but do have my doubts about, like, large language models, Sometimes they can introduce things that were unintended. But, yeah, I mean, I do wanna remind that, like, people who can help with copy, anything do exist in the larger world. I think maybe that's something the IETF should consider as a as a service to help, like, people by contracting someone some people to help people who are drafting reports? So so I will say that, you know, we have an extremely good professional staff in the RFC editor. but they end you know, they come in at the end of the process. I mean, I guess, you're saying, we we could have contracted people at the front end of the process too. it's it's we can take it back to the IESG and talk about it. it's it's It's a worthy suggestion. Thank you. That that was my suggestion. Thank you. Dan, you didn't put yourself in the queue, and plus Andrew wants to respond to this one, so hang on a second. Yeah. I I think one of the other things just to be aware of and This is due to no fault of the editors or anything else. but if you allow"
  },
  {
    "startTime": "00:16:00",
    "text": "Grammar errors, to go to the Oursi editor, etcetera. Keep in mind, that they're not the working group. They don't have the technical the deep technical knowledge. and there have been 1 or 2 instances where attempt to fix grammar by an editor like that outside of the working group that doesn't have this knowledge can fundamentally change the meaning of a document. And that can be a problem. So you yes. or associated to doesn't great job on fixing a lot of minor things. but you've gotta be careful of that risk because the in-depth detailed knowledge of what the document is meant to say sits in the working group, and that's why we prefer the working group to, you know, really do the checks in the working group. Yeah. I moved on to to raise the same issue because when you are drafting the first document, you really want to make sure dead Meaning, is well understood. that larger group of people, can't understand what is written without having ambiguities the document. And Me being a person who's English is not the first language, I have no problem when I right in my mother tongue, I write something, and they do literal translation from English. And then it's I'm sending a very ambiguous message, and people don't know exactly what I mean. So this is one important part that if you wanna have standard document, that we put in the effort as the authors to make sure that the that the document is well understood in the language that is is being written. not in the language that we are thinking know, in our head. Yeah. Just just one other comment on that. You know, one of the things that I found in the reviews that that I've done."
  },
  {
    "startTime": "00:18:02",
    "text": "When I get to a point where I look at a document and I go, Maybe I'm misunderstanding One of the things that I have done is go to my fellow ADs or other implementers that I know and go, I'm not gonna comment on how. I'm interpreting this. read it and tell me how you're interpreting it. If I see that my interpretation, their interpretation, and then a third person's interpretation of 3 different interpretations the document. that's a really good fun that we have a problem because it gonna lead to 3 different broken implementations. So I take your point. You know? You it it's gotta be clear because if you are getting multiple different interpretations same document. that's not good for standards. So just one comment on that. So I I I don't wanna give the impression that we we're just being picky here. We're doing for a reason. And I can based on Andrew's point, I can think of 2 documents in the last couple of months where we, 3 ADs, have had a discussion about a particular point in there, and all three of us understood differently differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently, differently So this isn't something that Andrew's made up. This is something we've had really seen in 2 documents. So so, really, the ask is, look, What you really want is for the eighties to be looking at these documents from a technical standpoint. But if we're spending lots of time trying to figure out what the documents actually trying to say, then you're not getting the service from the ADs that you as a community, actually, need and want. So so that's really why we're bringing this up as opposed to we're just grumpy today. Bye. I think I just got kicked off. ACLindum lab in. That's a good point about the RF see editor, possibly"
  },
  {
    "startTime": "00:20:00",
    "text": "correcting it wrong. We had a case where it wasn't a grammar thing. but it was where a non well known, Acronym was not the first instance was not expanded and RFC editor picked the wrong one. It went it was really late in the process Nobody saw it, and it ended up to being an errata. right. Right. Yeah. Okay. We can dem. There's no other comments. Right? That's it. So Have you ever used this thing before? shaft with us. Yeah. And the slots. So just before Adrian starts, so we we've asked a couple of working groups to give us a a summary of where they're at. There's something that we'd like to do as AD's in these meetings just to get awareness of what some of the other working groups in the routing area are doing that you may not be familiar with And Adrian has the the task for cats. the short straw. My cochair, Pang Liu, is in China awaiting a an appointment for a visa. So, yeah, computing aware traffic steering A little history. this this this this been a a number of drafts kicking around on this sort of topic. There were some Dunkirk"
  },
  {
    "startTime": "00:22:01",
    "text": "things and compute firstnetworking. which all got bundled up and renamed as computer ware networking. and that boft in March 2022. So 4 cycles back. And then presented a little bit sort of scattergun in in the IETF in Philadelphia. And then the ADs created a mailing list the routing they do is created a mailing list. to start talking about that. another buff in London in November 22. there was pretty clear interest in the room in doing the work, However, the the meeting was very unfocused. And I think they only got sort of a quarter of a way through the agenda, but managed to fill the time with with discussions Lot of Internet drafts got written. And Coming out of the both, a a draft charter was put together and and pushed around the community for re review we renamed to cats because of controller controller area networking, which is probably prior art. And then at that point, the AD said okay. We we've bopped enough. We've got a charter. let's just go and form a working group So we had our first meeting in Yokohama several days after the working group was formed, which was kind of fun. Some old drafts were renamed and and posted, so they just changed the canned cats. Right. What's the scope?"
  },
  {
    "startTime": "00:24:04",
    "text": "Services tend to get spawned in multiple places on multiple servers at different locations, and a single server may include multiple instances of a service. I hope that's not a surprise to anyone. We sort of say if you've got a computing platform. So your service is a bit more than just look up this piece of data or or or return this web page. It's actually doing some processing where calling out a compute service, And the performance experienced by a client service is obviously going to depend on The network on the way to the server, that's providing the service. And the capabilities and load on that server at the at the moment. So the the the question that cats is asking or trying to answer is how can the network edge steer the traffic, between clients of the service and the sites that offer the service. So the the 2 highlighted things there are kind of important. Many previous systems you're making the choice of compute server. either at the at the host. You're doing some lookup, getting an address, sending your crest off to that address. or somewhere in the network your request is is going through a load balancer. and being found out accordingly. What this is trying to do is say, the client says, this is the service I want. sends it off. And when it comes into the network, which is probably typically a metro edge, node. that node is gonna say, right. Now I'm going to make the selection"
  },
  {
    "startTime": "00:26:01",
    "text": "of the right server, service provider. and and routes towards it. So before the working group does anything related to solutions, it's got to do some basic groundwork. And that's probably frustrating to a lot of people because of 2 things. Firstly, they got their pet solution. They wanna push forward and and go. but, also, it's a lot easier to understand the problem space if you've got a at least a kite flown about a protocol solution because you can then can then look at it and understand the problem. Well, tough. We're not charter to work on solutions. We have to do ground work. that's the list of of the things that the charter says we should be on. but only one of those is explicitly identified as going towards RFC, and that's the framework and architecture. It's possible that the others will be such wonderful documents. We want them as historic RFCs just to to say this is what we were thinking. but it's not actually necessary as a as an outcome. Dan, I'm gonna take you at the take all the questions at the end. Yeah. So it's really, really, really, really early days for the work and grow You know, we've just had 4 4 months. And We haven't yet have a had our second meeting. That's tomorrow morning. But because some of the work's been around for a while, it. It it looks a bit lumpy. You can sort of look at the working group page and see all these draft, and it's not quite clear which ones are latest thought and which ones are are are old stuff."
  },
  {
    "startTime": "00:28:04",
    "text": "We've just adopted a a a draft for problem statement use case and requirements all packaged together. That draft is fairly rough still, but it's a good enough starting point that we can actually beat a bit more sense into it. Tomorrow's agenda has got some terminology stuff where MET is going to try and persuade us 2 to all say the same thing when we mean the same thing. We're gonna look at the use cases and see whether we are converging on a on set of use cases that are reasonable. the requirements that come out of those use cases, and then we're gonna start talking about Metric. And the metrics we have to talk about are how do you report on your ability to do compute pro in a way that is standard. I don't know I need to go through this again unless you really wanna know what it's all about. The point is that halfway down, the local network edge is steering traffic to the remote network edge. which then may also steer it on a little bit further to a particular service instance. and the choices being made on service requirements Capabilities and load of the server, capabilities and load of the network. So it's sort of traffic engineering plus service selection. the use cases that we have on the table, we're still firming up There's quite a lot of them that have been listed. and further ones are coming up. For example, we have a draft tomorrow on"
  },
  {
    "startTime": "00:30:00",
    "text": "the large AI requirements for processing on on multiple processes. You can look at this list and decide that some of them are realistic, and some of them are far in the future. And what what I hope we'll do is get down to a few killer use cases that really focus us obviously, not a complete list that we want to get to because that would be crazy. There are some differences but a lot of commonalities in our use cases They they will all have different requirements from the network in terms of latency volume of traffic and so on. But they all need to move data and have some kind of process in with a response. So the requirements are very much work in progress. but we see these 4thunes. You need to mark the traffic as as targeting a group of service instances. So you're doing some kind of selection to identify what service it is you want. and what type of service function you want executed. And there's been a suggestion to use in any chance to address for this. That's the suggestion. We'll see. Then we need to collect information from the network about topology and metrics. We already do this. Of course, We've been doing it for a few years. We may need to bolster that to get more information about latency and other performance in the network. but we we pretty much know how that's done. We need to collect information from the service instances"
  },
  {
    "startTime": "00:32:00",
    "text": "their locations, which is effectively their membership of this any cast group that you might be targeting. the capabilities and the loading. So that's the metrics that we're still up in the air, and we need to do a lot of work on. We also need to know some service demand requirements, So when you make the service request, you need it quickly? Is it big? That sort of thing. Do And we need a way of batching the packets into service requests. I can't really I I've been using the term transaction to try to explain this, but Clearly, you don't want a multi packet service requests getting sprayed out across different service instances because then nobody will know the whole story. but you don't need to bind all of the transactions between one client and a service function. always to the same service instance. You can move them around per transaction. Here's a pretty picture. The most important part of this picture is the little red box that says this is not consensus. Okay? This is in a in a first version of a an individual draft. It's a nice picture. but it might not go that way at all. What it's sort of shows, though, if you read it from the left is an edge site with clients that sends some traffic into an edge router that is making a decision somehow and selecting to steer the traffic towards a remote service instant. And then the other boxes here are are the pieces that collect the information from the network, collect the information from the service instances about their"
  },
  {
    "startTime": "00:34:00",
    "text": "capabilities and loading and channel that back together to some functional blob that makes path selection choices. I believe I did that faster than I intended. So good. Mister Bogdanovic. So This is a very interesting area, and it the is a nice layering on on the dead net. because these two things are combined So in the OT World, operational technologies. This is a new thing that I've learned in the past few year. are vendors who are looking to enable Industrial Automation And now they're looking before they were embedding all the logic on a single Machine. to seeing everything locally. And now they are looking how to have a distributed software load across different layers within their enterprise domain. So one of the thing for them is they want to keep everything within their enterprise domain. Yeah. I'm not interested in any multidomain solutions. They're saying need something simple. I go and talk to them. test work, within a campus or a smaller environment, like in a factory warehouse, But it has to work very real reliably, and then I know what I'm what I'm sending work. The other part is also that they are that they will what they're looking into it is the that multiple devices, will work on the same thing, it on the same end product. So it's a They are looking for a solution for mobile val welding machines. when those mobile welding machines are working together, on large sheets of metal."
  },
  {
    "startTime": "00:36:01",
    "text": "8th they are sending back for QA x-ray pictures to verify if the welding has been done whelming spot has been done correctly. and then they are comparing them if 3 or 4 or 5 of those machines have done it correctly. So it's like hierarchical state what they are doing. and If we could have some inputs from The operational technology vendors What problems are they facing? I know a few. but they're coming and asking those, like, you know, very specific. How can I have the deterministic connectivity that my application can that that my service can distinguish between data. If I lose the data, we'll cause a catastrophic event, it will cause a failure or who cares? Because that's how they're dividing and they're trying to process the data in a certain amount of time because they want to improve their productivity, So they can say, as long as I know, In what time frame I'm working with, this is fine, but it has to be sort of deterministic. Yeah. I think that's interesting with relation to this picture because there are 2 things. One is that blue network could be an enterprise that might be running detonet, And the other is that you might collapse the client box with the with the ingress Edge router. collapse the functionality. So I've got 2 asks of you. One of them is help us find the right people to talk to from cats. And the other is think about writing 2 thirds of the page of use case description to go in our use case document"
  },
  {
    "startTime": "00:38:03",
    "text": "So some of the companies are like Schneider Electric siemens, those are the companies who are making deep operational Technologies Samsung is making operational technologies that they are bunch of others, but They are the ones who know that what problems they're facing. Yeah. Just two two quick comments who firstly, in response to that, If you can bring organizations like that into the IETF to bring more thoughts and perspectives, I think it would be really welcome. You know? We always like have more variety in the IETF. So You know, God. encourage them to come along. You know? You could think. Edwin wearing no particular hats. I wanted your kind of thoughts on one of the things that I've seen with cats, It's the day seems to be a fair amount of ambiguity in the community about what represent cats versus what represents APN and where they mix together, etcetera. And I want to kinda hear from you whether or not you've kind of seen a bit of confusion there and how you see dealing with that going forward, etcetera, because it is something that is kind of come to me a fair bit. in recent times, but I just wanted your thoughts on it. Yeah. So there's there's marking that has to go on in both cases, marking packets, to say what Oh, yes. The landline. I just trouble. So that might have yeah. It's before us. So that might have just killed him. was the 1 it was the word application. Okay? So marking the packets to indicate what"
  },
  {
    "startTime": "00:40:02",
    "text": "What sort of processing stream there part of? them. so that they can get treated appropriately. APN is about processing those packet looking at that information within the network, to make per hop behavior type actions, CATs is about looking at that information at the edge of the network in order to do a once a one time only steer, which is to a destination possibly on a traffic engineering path. Cats is only interested in those compute type, Network Functions, APN, I think he is more interested in a different type of granularity of I'm a voice call. I'm a augmented reality thing, But they're both sort of thinking about, well, What I'm doing, needs low latency compared to normal traffic. Or what I'm doing is very big burst of traffic compared to to normal traffic. So that that there is there's a similar feeling, but I think that the architectural solutions are very different. You should also have asked about Alto, or I have meant. A outage should have been anomalous. So Alto is this thing in the transport area. which operates as a server that collects information from the network, And the client normally shown as being located at the host, says, well, I know what I want to do. go and ask Alto for the best"
  },
  {
    "startTime": "00:42:00",
    "text": "location to go to and possibly the best way to get there. given the things that I want to do. So there's there's a there's a clear kind of similarity except that's largely speaking, client based, and this is edge based, What we're going to do is see whether there's any commonality in metrics for compute because Altair may want to suck metrics from the network, and we obviously need to set metrics in the network. Adrian, I I I just wanted to make a comment. You mentioned earlier that cats as currently chartered is not to work on solutions. And and I think that was a very deliberate thing that we did because there is a lot of things out there and people that We we we wanted to avoid a rush to build something without actually understanding what the heck it is we're trying to solve. And what I really like about this working group is that the charter says essentially, let's let's actually figure out what it is we want to solve, and then we'll start talking about solutions. So what I'm hoping to come out of this is a you know, is a nice architecture that understands what are the metrics that we need, why are they used for? What are the use cases? and that's exactly what it's chartered to do. So I just wanna to reiterate that. And if I got that wrong, please correct me. No. That's that's my understanding. outstanding, and, obviously, people are writing drafts and and and bless them. but we're not finding any space in our meetings to talk about solutions, And if the mailing list gets clogged up with people talking about Zulu they'll be dampened, I'm hoping that there's a lot of technology out there already"
  },
  {
    "startTime": "00:44:02",
    "text": "We've heard DetNet the IGP has moved stuff around quite nicely inside the network. And as John knows, everything can be done with BGP. We we may find that we only need just little deltas. on top of existing protocols to do everything. But until we know what it is we're trying to do, it's it's gonna be a bit hard to guess. Thanks, Sue. Monday, I'm on to measure 1. You you can also ask me to click that This one is over Yeah. when we skip two slides or something. Hi. I'm a Ronald Infelt, dutch guy with a strange name or strange guy with the Dutch name. whatever you prefer. I'm Eco Chair. if the mobile network networking group We now there's now 3 of us. I'm coming to that. first, the refresher, what what money you work in Rupees, It's about mobile ad hoc networks. that involves wireless communications, Everything is moving. The notes are moving, maybe obstacles, obstacles to the movement or obstacles to the propagation The obstacles to the propagation might even be moving. and all those movements are neither predetermined nor predictable. And"
  },
  {
    "startTime": "00:46:01",
    "text": "This is a generic Note model, Although some of the protocols in there are specific, But with the drainage between A router, which does not have to be Uh-huh. a hardware box. It could be a a software function. because usually, the radios that are attached to the router. if such low. capacity or the or the links that they are using, you know, have such low capacity. that the number of packets per seconds can easily be handled by a a software router. and then we have the hosts that run the applications and are attached to the rotor. and there may be multiple radios connected 2. Hey, Ruther. and the routers run a mobile ad hoc networking protocol between them or among them. In this case, the one standardized protocol from the working group. is shown, which is always our version 2. RC 71, 81, I always like to remind people from the routing area that there are three standardized As far as I know, 3 standardized link state routing protocols. in the the idea of So next to OSBF and ISIS. There's also all those are in version 2. Yeah. This is the most generic model, within practice. things may be collapsed into for instance, a single Uh-uh. and held. device that is running the applications, doing the routing,"
  },
  {
    "startTime": "00:48:00",
    "text": "and also includes some form of wireless communications. Where are we? Well oh, I will have to say one more thing about this. because we we have cases where we have the radios and the rotor as being on separate platforms, There's a protocol between them. It's local. only local communication between radio and a router It's called DELAP dynamic links link exchange protocol. the basic spec is RFC 8175, there are a number of extensions. And DLab is what most of the effort of the working group as we spent on in recent years. but now we are at the point that we Mhmm. want to re recharter, because there are a few things on our current charter that are dead ends. I'll come to that later. some other things that we want to take on but are not covered by the current current current current Charter, charter, then there's the And As you have just heard, the Babel bubble work group is closing down. but there is always a need to be able to do. maintenance and extensions to babel, and maybe even some more new work. that's going to be folded into the new charter of the maneuver group. So We had a session yesterday, We had 2 presentations on new work that would fit potentially in the new charter. still to be decided. If we take them up, well, once we have the new charger, or the better they will be on the new starter"
  },
  {
    "startTime": "00:50:02",
    "text": "And then we were going to have a discussion, we start at the discretion, on the new charter, but we had started a bit late. And Yeah. the 1 hour that we had was up before we could really get into the re chartering discussions of the test to be initiate it on the mailing list, and then we will have an interim Anyway, 6 or 7 weeks for now. Then we, hopefully, before the product meeting, we will have a new charger. Starting point will be a long list of potential items, we have to bring that down probably in discussions with our AD do something manageable what is manageable will also depend on the horizon with the new charter. lost charter The last charter revision took place in 2016. So we've been going for a pretty long time without recharging. because bubble is going to close. moment is like has become what was the remaining chair of the paperwork group is now also A chair of Mene, might think that the IDs were maybe getting a bit ahead on themselves, but maybe not. These are a few of the remaining documents And These are about the second function of this d lab protocol The first function of DLAP is to let the radio informed the rooter about status of links and the destinations it can reach. But the secondary function is that DELAP can also"
  },
  {
    "startTime": "00:52:00",
    "text": "flow control the river, because the bit of Ethernet between the router and the radio would allow the router to completely overwhelm the radios. which operate atoneor2 orders of magnitude to lower link capacitization Usually, the the capacity of those links is shared. I mean, among all nodes in the network. This graphs have been for all kinds of reasons. been languishing much too long. in the working group But now we really want to really get them out the door, so that we can start with the clean slate for the new charter. There are also some things some new individual or not new but some individual IDs that we want to run an adoption call on. There will be a Deal it. maintenance and extension work item on the new charter so they would fit there. we don't have those finish those immediately. The idea about this about these drops is that they can be used In case you don't have anything better, DelAP only specifies the exchanges between routers, routers, and locally attached radios. They say nothing about how the radios obtained the information that they base the content of the deal at messages. That's it's outside the scope. But sometimes,"
  },
  {
    "startTime": "00:54:00",
    "text": "the link capacity is so low that there's really not much room for signaling among radios to inform them each other about link state and destination state. And then these physical layer parameters like a signal to noise ratio, link quality or link quality, and can be helpful. we want to So FDs as additional deal up extensions. And then there was 1 new ID, Individual ID, presented yesterday about sloppy topology updates, That could serve the purpose of energy preservation in battery operated devices. And we have to see whether we take that on in the new charter, not covered. by the current charter, It could be take the form of a over new route routing protocol, or it could result in changes to the existing routing protocols for instance, OZRFP 2 or VABL. but there was a lot of comments. There is also all discussion on the mailing list already. So I think the authors have to do some work before we go can go to an adoption call if at all things that we have achieved and not achieved from the current charter. obviously, we developed the dealer protocol we did see Flow Control, extension. That's nearly done. was another idea to"
  },
  {
    "startTime": "00:56:02",
    "text": "use stratification to Generate statistics. that was never really but never were really materialized. we were going to do some work on I don't know. multicost, maybe extending the simplified notes cost forwarding, mechanism, RT6621, which is an experimental RC was never proposed standard. with with so how Nobody picked that up. and there was another thing to documents best practices and challenges for deploying and managing many networks, but We came to the conclusion that nobody is very keen on Uh-huh. making public. How they do this? So that also Mhmm. Mhmm. did not happen. Then there's an implicit work item to to keep maintaining all those rf2 and it's supporting protocols. ADian was AD during the time that all the was was developed. we still remember that. There are some RFPs, that have experimental status like the directional airtime metric It's and in practice, that's the only metric that's being used in assisting implementations of all of our FE2 So maybe we should standardize that. And if Somebody thinks that's not a good idea, then I'd like to hear about alternatives to the to the debt metric."
  },
  {
    "startTime": "00:58:02",
    "text": "And there's also a multi topology extension that could potentially also be taken to propose centered from its current state of being experimental. As I said, deal up maintenance extensions, table maintenance and extensions that Those are no brainers. will end up in the new jar there is a whole list of things that he could potentially do, but that we are for further discussion. and this discussion has to start be started on the mailing list and then Mhmm. continues in the in an inter meeting. Yeah. We have been last year in field here. We had a combined session From row, money, and and babel. Babel was still alive, of course. thing. at that time. and we have to c there's anything from that session that we can if It's regard to multicost. that we can continue on the new charter. maybe Mm-mm. an approach inspired by the peer protocol although it will not be literally btbprotocol because that is not a good fit for mobile network. We think Reactive protocol, we have tried it in the past. was a bit of drama That's also something that Adrian will remember. And Yeah. if if there's really energy from some participants in the working group to pick that up z I cannot rule it out right now, but I think it's no likely that we will do this. And then"
  },
  {
    "startTime": "01:00:03",
    "text": "So these slides were not presented yesterday, but I'm presenting them now to potentially a wider audience. So the last bullet is if anybody has ideas, that you can pick up I'd like to hear them. We the chairs would like to hear them. And one thing I forgot to mention on this slide is that Uh-huh. apparently, it was something about satellite networking yesterday in the routine working group. And I wasn't there. has to go see what it was about. I have been warned that somebody is going to approach us to talk about this and of course, they're a welcome And that's it. Any questions Any questions about the picture? I think I think we're good. Thank you. Okay. prescription of Yeah. Who's next Was that? It's fine. a Hi. My name's Ed Berrain. I am the co chair of the TBR Working Group along with Tony Lee. Tony is the smarter cochair because he told me to present now. So thank you for that. I I I One of the things that seems self evident in retrospect when we talk about what our working group is supposed to be doing is to talk about the charter of the working group. but we didn't have a slide for that at first. So before we jump into the milestones, let me give you a little bit a an oral history of how this came to be what our charter is, then that will explain what some of the milestones are. At IETF 115, we started having conversations"
  },
  {
    "startTime": "01:02:04",
    "text": "related to the question, what happens if we know in advance that we will have an adjacency that is going to come up up or go away, and how do we plan for that? This is different than Mene. where it would be ad hoc. But what if we know in advance that we're gonna do a recovery or an acquisition or a loss. how do we do that? And of course, we know that there are individual systems that react to and make it part of their planning. But how do we standardize that? And what would it look like? if we were to put schedule information into a rib or schedule information into a fit, would it benefit our our our operations, and could we do this in a standard way? From there, we had a BAF in in London. and that went very well. It was very well attended. We had a a lot of interest from the community, and then from there, we had our very first meeting. This is one 17. So we were just had our very first meeting at 1 16. we're about to have our second meeting tomorrow. So I we're not gonna go deeply into some of the technical work right now because we're going into our second meeting. But if you're interested in it, come to the working group, tomorrow. and and you'll get as much of that as you'd like. So when we decided to charter or when the working group was decided to be formed and we put the charter in, we wanted to make sure that we captured was what were the interesting use cases where we would have this kind of planned change to the apology of the network in a way that we could react to. 1 of the 1 of the more driving use cases, of course, is mobility. If we understand the mobility of a device, or the mobility of the obstacles to that device, then we could sort of plan when things would come and go. But, additionally, if we started looking at cases where we would turn off our network interfaces to save power or turn off network interfaces or turn on our network interfaces to save"
  },
  {
    "startTime": "01:04:00",
    "text": "cost or transmit or some other sorts of metrics then all of those became sort of interesting cases. So we are chartered generally to look at what would schedule information look like? What is the information model associated with that? who would use it for what purposes? And then what are the requirements therein? And then at sort of the end of the this initial chartering of the working group is to produce those information model with the hope that we would then be able to provide those to other working groups in the routing area and elsewhere to say, how would we incorporate this information into the broadening protocols for others. So that's a little bit of the history and the charter for the working group. The way that that has been decomposed into a series of mile stones is to start with, what is the problem statement and what are the use cases? And so we do have our, you know, sort of first adopted document, which are what are the use cases for this? That's been interesting. because there are categories of use cases. know, categories for research resource preservation or mobility or cost metrics. and we have gotten into some pretty good mailing list discussions as to what represent new and different and motivating uses categories of that information, versus what are just two or three instances of essentially the same problem So we're trying to make sure that we don't have a use case explosion in in the work that we are doing, but separately make sure that we have all of the truly unique driving cases captured in that document. as we are progressing with that, we now have an initial initial draft associated with what are the requirements scheduling information and the requirements for the information that is captured with enough utility and and annotate of information to make them useful. And then beyond that, what are the information models,"
  },
  {
    "startTime": "01:06:00",
    "text": "and then the data models and how might we apply them, and then what are some overall considerations? what we are not doing in the working group is creating a new routing protocol. We are not trying to explain to other routing protocols what they should or should not be doing. are trying to make sure that we put together the reason and the rationale for considering time what considering time means? What are some of the common definitions? and where it could be applicable to others. It's a long first one. So If you were to come to the working group tomorrow, this is a a walk through of what that agenda looks like. We are going to be giving a a small update to the use case document It's on a dash 01ordash02revision. we are trying again to enumerate the classes that we are talking through. And then we have 2 different we have 2 different requirements documents, and we're gonna sort of look through each of those and try and understand whether we can merge them. And then we have a couple of different yang models to capture some of our information. The first two, this one draft cue TBR schedule Yang is a cut at sort of a link schedule from one particular approach. And then the second one, which is draft Kinsey TBR link availability is a second. What we've actually been able to do is is talk to each of those authors and say there's enough commonality here. would you be amenable to merging into a a single model offer link scheduling and availability. the authors are open to that, and one of the things we're going to present which is a little bit late breaking to this is sort of their their plan forward for. Here is our individual model and here's how we're going to try to bring them together under under one document. We are still talking through and and open some of the information that we're getting from Alto. And then We have a presentation for Mark Blanche, on on contact"
  },
  {
    "startTime": "01:08:03",
    "text": "planning, which is the idea of if we have contacts in the future for or what they would consider contact ref routing, then what would that data model look like and then generally some some other routing considerations. So there's there's a bit of There's a bit of a movement in a couple of in all directions associated with use cases requirements and data models, and it's been pretty good. So when we we look back and say, as we go into and look at our second meeting, We wanted to evaluate what do we think is going well and what are the things that we wanna watch out for. We had about 90 some people at the first meeting. We'll see how many come to the second meeting, there's always a sort of that initial interest. But what we what what has been going well is that even though we had, very large interest and a large number of people coming in. We've been able to get to a series of motivated authors that are willing to write drafts. In in fact, as we have put out requests for this, there there have been that sort of typically more request to present and more request for for editing than than we have time to present during the working group, which is, of course, you know, a reasonably nice place to be. and the authors have written large and good drafts in a reasonably short amount of time. So the motivation is there. The mailing list has generally been responsive when information has been posted. We seem to be on schedule for the milestones that we have. And by and large, the Discussions have been open and polite. So when we look at how is the working group going right now? Unlike the prior 2 presentations, I don't wanna go deeply into the technical work We really are looking at what does this look like from building a community around time variance and how we bring schedules in. That has been our primary goal because there is a lot of different of there are differences in how we use time whether we should be tracking time, whether we can standardize"
  },
  {
    "startTime": "01:10:01",
    "text": "a common solution for time or whether these are things people don't want to talk about openly. and the extent to which we would want to infuse time and schedule information into existing routing protocols. So getting a community where we have motivated authors coming forward where we are responsive to the mailing list, where we are getting open and polite discussion. me that we're starting to get the exchange of ideas that will help make sure that we're not pushing into a particular direction that will be harder to to infuse into other areas. There are a couple of things that we are trying to pay attention sure that we we keep that positive momentum. We do see couple of different competing drafts. We have 2 requirements documents. We had 2 Yang models for links. Like we said, we were able to get the editors for the 2 young models to talk about combining, and and that has been good. I think we'll wind up in similar position for requirements. We really wanna make sure that we keep our focus on planned schedules. Again, this is not ad hoc. This is not Mene. We have a working group for that. So it comes up periodically. What do we do with opportunistic? How do we deal with things go away when we don't expect it. And we're trying as best as possible to say, really not the problem we're trying to solve at this time. there there are a large number of questions as posts and approaches that we're being asked to consider. We just wanna sure that all of them are being heard initially as we start doing this initial filtering and converging onto the solutions that the working group is behind. And the last one which is sort of one of the more important as we look to transport protocols and the transport area, is there's a natural question that comes up that says, If I don't have a link now, but I believe that I will have a link later, What do I do with that information? And one of the things, of course, that you can do with that information is say, I will keep some of my information around. until I have that future link. And a standard way to do that from the transport area, is to use the bundle protocol However,"
  },
  {
    "startTime": "01:12:01",
    "text": "that does not mean that there is now a a 1 to 1 mapping between schedule information and the use of things like DTN or the bundle protocol. It's useful in some cases. It is not useful in other cases. we wanna make sure that this working group is not perceived as focusing only on a particular satellite use case or space use case or LEO constellation use case. wanna make sure that the working group is also not perceived as focusing solely on time variant information, because of the bundle protocol. It's an important use case, but it's not the only one and the work that we do really just has to be appropriately generalized. that's really all we have. in terms of trying to describe a little bit about where we are with time variant routing. We're making pretty good progress We're progressing against our milestones. If you're interested in the technical work, Please join the working group. Please join the mailing list and and make your opinions heard. and we're about to go into meeting number 2. And I see a question. Yeah. Just Thank you very much. this is kind of a strange question, no particular hats. Recently, we've been doing some work in the IT t u with regards to COP Twenty 8, and they're looking at efficiency stuff and, you know, sustainability and a lot of it to do with energy, etcetera. then effectively collating work that they couldn't look at it to include in the stuff that they're doing in COP 28, and I just wondered if you thought that there could be work from TVR that I could point them to and say, you know, this is also happening in the IETF. thoughts on that. So I'll I'll start and and say one of the things that we were hoping what happened"
  },
  {
    "startTime": "01:14:00",
    "text": "is that if we together to say these are all of the reasons why we might care about schedule information in the different ways that that would manifest that that would be the starting point. So if if folks were saying, is there something being done, or is there a driver for TBR that looks like a driver for something else. would start with having them look at the use case document and see whether they see their use cases represented in here. That's I think the answer is yes. Lou Berger, it's really funny you taught you brought that question up. On Saturday, I had a nice long discussion. about how the the work that's going on with the characterizing links could not only be used to predict future, but also might be able to be augmented to track power consumption in the past. and then the further than used by a controller group to bring in some policies how you how you might wanna modify the routing system. to do things in the future. So I fully am on on board with what you're talking about. Yeah. So thank thanks so much. I do what I think I'm gonna do is also just go through those documents, and then I will drop them into the relevant channels on the on the Slack where they're dealing with COP Twenty Eight. and, you know, point them to it and seaward dolls. Yeah. Yeah. Much appreciated. Otherwise, that's that's DVR. It's It's about time. Thank you. Okay. And then That is the end of our scheduled business. If anybody has any other business you wanna bring now's the time. Charge the mic or put yourself in queue. Otherwise, we are a assurance. Thank you very much, everybody. Hey, Joe."
  },
  {
    "startTime": "01:16:01",
    "text": "Do we turn this off? I wasn't trying I was in Okay. It's just not a place I normally want. And the presentation before the was a difficult visa or ISAD. or colon. I was at the Okay? Keep talking. I I They were one of their other trainers."
  }
]
